{"created":"2024-04-03 13:09:31","title":"Measurement of differential ZZ+jets production cross sections in pp collisions at $\\sqrt{s}$ = 13 TeV","abstract":"Diboson production in association with jets is studied in the fully leptonic final states, pp $\\to$ (Z$\\gamma^*$)(Z/$\\gamma^*$)+jets $\\to$ 2$\\ell$2$\\ell'$+jets, ($\\ell,\\ell'$ = e or $\\mu$) in proton-proton collisions at a center-of-mass energy of 13 TeV. The data sample corresponds to an integrated luminosity of 138 fb$^{-1}$ collected with the CMS detector at the LHC. Differential distributions and normalized differential cross sections are measured as a function of jet multiplicity, transverse momentum $p_\\mathrm{T}$, pseudorapidity $\\eta$, invariant mass and $\\Delta\\eta$ of the highest-$p_\\mathrm{T}$ and second-highest-$p_\\mathrm{T}$ jets, and as a function of invariant mass of the four-lepton system for events with various jet multiplicities. These differential cross sections are compared with theoretical predictions that mostly agree with the experimental data. However, in a few regions we observe discrepancies between the predicted and measured values. Further improvement of the predictions is required to describe the ZZ+jets production in the whole phase space.","sentences":["Diboson production in association with jets is studied in the fully leptonic final states, pp $\\to$ (Z$\\gamma^*$)(Z/$\\gamma^*$)+jets $\\to$ 2$\\ell$2$\\ell'$+jets, ($\\ell,\\ell'$ = e or $\\mu$) in proton-proton collisions at a center-of-mass energy of 13 TeV.","The data sample corresponds to an integrated luminosity of 138 fb$^{-1}$ collected with the CMS detector at the LHC.","Differential distributions and normalized differential cross sections are measured as a function of jet multiplicity, transverse momentum $p_\\mathrm{T}$, pseudorapidity $\\eta$, invariant mass and $\\Delta\\eta$ of the highest-$p_\\mathrm{T}$ and second-highest-$p_\\mathrm{T}$ jets, and as a function of invariant mass of the four-lepton system for events with various jet multiplicities.","These differential cross sections are compared with theoretical predictions that mostly agree with the experimental data.","However, in a few regions we observe discrepancies between the predicted and measured values.","Further improvement of the predictions is required to describe the ZZ+jets production in the whole phase space."],"url":"http://arxiv.org/abs/2404.02711v1","category":"hep-ex"}
{"created":"2024-04-02 17:59:10","title":"Segment Any 3D Object with Language","abstract":"In this paper, we investigate Open-Vocabulary 3D Instance Segmentation (OV-3DIS) with free-form language instructions. Earlier works that rely on only annotated base categories for training suffer from limited generalization to unseen novel categories. Recent works mitigate poor generalizability to novel categories by generating class-agnostic masks or projecting generalized masks from 2D to 3D, but disregard semantic or geometry information, leading to sub-optimal performance. Instead, generating generalizable but semantic-related masks directly from 3D point clouds would result in superior outcomes. In this paper, we introduce Segment any 3D Object with LanguagE (SOLE), which is a semantic and geometric-aware visual-language learning framework with strong generalizability by generating semantic-related masks directly from 3D point clouds. Specifically, we propose a multimodal fusion network to incorporate multimodal semantics in both backbone and decoder. In addition, to align the 3D segmentation model with various language instructions and enhance the mask quality, we introduce three types of multimodal associations as supervision. Our SOLE outperforms previous methods by a large margin on ScanNetv2, ScanNet200, and Replica benchmarks, and the results are even close to the fully-supervised counterpart despite the absence of class annotations in the training. Furthermore, extensive qualitative results demonstrate the versatility of our SOLE to language instructions.","sentences":["In this paper, we investigate Open-Vocabulary 3D Instance Segmentation (OV-3DIS) with free-form language instructions.","Earlier works that rely on only annotated base categories for training suffer from limited generalization to unseen novel categories.","Recent works mitigate poor generalizability to novel categories by generating class-agnostic masks or projecting generalized masks from 2D to 3D, but disregard semantic or geometry information, leading to sub-optimal performance.","Instead, generating generalizable but semantic-related masks directly from 3D point clouds would result in superior outcomes.","In this paper, we introduce Segment any 3D Object with LanguagE (SOLE), which is a semantic and geometric-aware visual-language learning framework with strong generalizability by generating semantic-related masks directly from 3D point clouds.","Specifically, we propose a multimodal fusion network to incorporate multimodal semantics in both backbone and decoder.","In addition, to align the 3D segmentation model with various language instructions and enhance the mask quality, we introduce three types of multimodal associations as supervision.","Our SOLE outperforms previous methods by a large margin on ScanNetv2, ScanNet200, and Replica benchmarks, and the results are even close to the fully-supervised counterpart despite the absence of class annotations in the training.","Furthermore, extensive qualitative results demonstrate the versatility of our SOLE to language instructions."],"url":"http://arxiv.org/abs/2404.02157v1","category":"cs.CV"}
{"created":"2024-04-02 17:58:27","title":"Jailbreaking Leading Safety-Aligned LLMs with Simple Adaptive Attacks","abstract":"We show that even the most recent safety-aligned LLMs are not robust to simple adaptive jailbreaking attacks. First, we demonstrate how to successfully leverage access to logprobs for jailbreaking: we initially design an adversarial prompt template (sometimes adapted to the target LLM), and then we apply random search on a suffix to maximize the target logprob (e.g., of the token \"Sure\"), potentially with multiple restarts. In this way, we achieve nearly 100\\% attack success rate -- according to GPT-4 as a judge -- on GPT-3.5/4, Llama-2-Chat-7B/13B/70B, Gemma-7B, and R2D2 from HarmBench that was adversarially trained against the GCG attack. We also show how to jailbreak all Claude models -- that do not expose logprobs -- via either a transfer or prefilling attack with 100\\% success rate. In addition, we show how to use random search on a restricted set of tokens for finding trojan strings in poisoned models -- a task that shares many similarities with jailbreaking -- which is the algorithm that brought us the first place in the SaTML'24 Trojan Detection Competition. The common theme behind these attacks is that adaptivity is crucial: different models are vulnerable to different prompting templates (e.g., R2D2 is very sensitive to in-context learning prompts), some models have unique vulnerabilities based on their APIs (e.g., prefilling for Claude), and in some settings it is crucial to restrict the token search space based on prior knowledge (e.g., for trojan detection). We provide the code, prompts, and logs of the attacks at https://github.com/tml-epfl/llm-adaptive-attacks.","sentences":["We show that even the most recent safety-aligned LLMs are not robust to simple adaptive jailbreaking attacks.","First, we demonstrate how to successfully leverage access to logprobs for jailbreaking: we initially design an adversarial prompt template (sometimes adapted to the target LLM), and then we apply random search on a suffix to maximize the target logprob (e.g., of the token \"Sure\"), potentially with multiple restarts.","In this way, we achieve nearly 100\\% attack success rate -- according to GPT-4 as a judge -- on GPT-3.5/4, Llama-2-Chat-7B/13B/70B, Gemma-7B, and R2D2 from HarmBench that was adversarially trained against the GCG attack.","We also show how to jailbreak all Claude models -- that do not expose logprobs -- via either a transfer or prefilling attack with 100\\% success rate.","In addition, we show how to use random search on a restricted set of tokens for finding trojan strings in poisoned models -- a task that shares many similarities with jailbreaking -- which is the algorithm that brought us the first place in the SaTML'24 Trojan Detection Competition.","The common theme behind these attacks is that adaptivity is crucial: different models are vulnerable to different prompting templates (e.g., R2D2 is very sensitive to in-context learning prompts), some models have unique vulnerabilities based on their APIs (e.g., prefilling for Claude), and in some settings it is crucial to restrict the token search space based on prior knowledge (e.g., for trojan detection).","We provide the code, prompts, and logs of the attacks at https://github.com/tml-epfl/llm-adaptive-attacks."],"url":"http://arxiv.org/abs/2404.02151v1","category":"cs.CR"}
{"created":"2024-04-02 17:49:00","title":"Emergence of collective spectral features in finite arrays of dielectric rods","abstract":"Periodic optical structures, such as diffraction grating and numerous photonic crystals, are one of the staples of modern nanophotonics for the manipulation of electromagnetic radiation. The array of subwavelength dielectric rods is one of the simplest platforms, which, despite its simplicity exhibits extraordinary wave phenomena, such as diffraction anomalies and narrow reflective resonances. Despite the well-documented properties of infinite periodic systems, the behavior of these diffractive effects in systems incorporating a finite number of elements is studied to a far lesser extent. Here we study theoretically and numerically the evolution of collective spectral features in finite arrays of dielectric rods. We develop an analytical model of light scattering by a finite array of circular rods based on the coupled dipoles approximation and analyze the spectral features of finite arrays within the developed model. Finally, we validate the results of the analytical model using full-wave numerical simulations.","sentences":["Periodic optical structures, such as diffraction grating and numerous photonic crystals, are one of the staples of modern nanophotonics for the manipulation of electromagnetic radiation.","The array of subwavelength dielectric rods is one of the simplest platforms, which, despite its simplicity exhibits extraordinary wave phenomena, such as diffraction anomalies and narrow reflective resonances.","Despite the well-documented properties of infinite periodic systems, the behavior of these diffractive effects in systems incorporating a finite number of elements is studied to a far lesser extent.","Here we study theoretically and numerically the evolution of collective spectral features in finite arrays of dielectric rods.","We develop an analytical model of light scattering by a finite array of circular rods based on the coupled dipoles approximation and analyze the spectral features of finite arrays within the developed model.","Finally, we validate the results of the analytical model using full-wave numerical simulations."],"url":"http://arxiv.org/abs/2404.02137v1","category":"physics.optics"}
{"created":"2024-04-02 17:44:45","title":"Quantum bistability at the interplay between collective and individual decay","abstract":"We study driven collective radiation of an ensemble of atoms placed inside a cavity, accounting for individual-atom emission to free space modes. We find that the steady state exhibits a dissipative phase transition, formed by a mixture of two collective quantum states corresponding to a bistable mean-field solution. One of these states is entangled and closely resembles a coherently radiating spin state (CRSS) -- the solution obtained by neglecting individual decay (Dicke superradiance) -- allowing us to analytically find the optimally achievable spin squeezing. We predict quantum switching between the two states, verified by quantum trajectories simulations. The switching rate tends to vanish with the atom number, as the Liouvillan gap closes. Remarkably, this suggests that the system may reside in an entangled CRSS-like state associated with correlated Dicke physics, even in the presence of decorrelating individual decay. This opens a path for a systematic study of the interplay between collective and individual decay, in both experiments and theory.","sentences":["We study driven collective radiation of an ensemble of atoms placed inside a cavity, accounting for individual-atom emission to free space modes.","We find that the steady state exhibits a dissipative phase transition, formed by a mixture of two collective quantum states corresponding to a bistable mean-field solution.","One of these states is entangled and closely resembles a coherently radiating spin state (CRSS) -- the solution obtained by neglecting individual decay (Dicke superradiance) -- allowing us to analytically find the optimally achievable spin squeezing.","We predict quantum switching between the two states, verified by quantum trajectories simulations.","The switching rate tends to vanish with the atom number, as the Liouvillan gap closes.","Remarkably, this suggests that the system may reside in an entangled CRSS-like state associated with correlated Dicke physics, even in the presence of decorrelating individual decay.","This opens a path for a systematic study of the interplay between collective and individual decay, in both experiments and theory."],"url":"http://arxiv.org/abs/2404.02134v1","category":"quant-ph"}
{"created":"2024-04-02 17:33:34","title":"FLawN-T5: An Empirical Examination of Effective Instruction-Tuning Data Mixtures for Legal Reasoning","abstract":"Instruction tuning is an important step in making language models useful for direct user interaction. However, many legal tasks remain out of reach for most open LLMs and there do not yet exist any large scale instruction datasets for the domain. This critically limits research in this application area. In this work, we curate LawInstruct, a large legal instruction dataset, covering 17 jurisdictions, 24 languages and a total of 12M examples. We present evidence that domain-specific pretraining and instruction tuning improve performance on LegalBench, including improving Flan-T5 XL by 8 points or 16\\% over the baseline. However, the effect does not generalize across all tasks, training regimes, model sizes, and other factors. LawInstruct is a resource for accelerating the development of models with stronger information processing and decision making capabilities in the legal domain.","sentences":["Instruction tuning is an important step in making language models useful for direct user interaction.","However, many legal tasks remain out of reach for most open LLMs and there do not yet exist any large scale instruction datasets for the domain.","This critically limits research in this application area.","In this work, we curate LawInstruct, a large legal instruction dataset, covering 17 jurisdictions, 24 languages and a total of 12M examples.","We present evidence that domain-specific pretraining and instruction tuning improve performance on LegalBench, including improving Flan-T5 XL by 8 points or 16\\% over the baseline.","However, the effect does not generalize across all tasks, training regimes, model sizes, and other factors.","LawInstruct is a resource for accelerating the development of models with stronger information processing and decision making capabilities in the legal domain."],"url":"http://arxiv.org/abs/2404.02127v1","category":"cs.CL"}
{"created":"2024-04-02 17:32:12","title":"3D Congealing: 3D-Aware Image Alignment in the Wild","abstract":"We propose 3D Congealing, a novel problem of 3D-aware alignment for 2D images capturing semantically similar objects. Given a collection of unlabeled Internet images, our goal is to associate the shared semantic parts from the inputs and aggregate the knowledge from 2D images to a shared 3D canonical space. We introduce a general framework that tackles the task without assuming shape templates, poses, or any camera parameters. At its core is a canonical 3D representation that encapsulates geometric and semantic information. The framework optimizes for the canonical representation together with the pose for each input image, and a per-image coordinate map that warps 2D pixel coordinates to the 3D canonical frame to account for the shape matching. The optimization procedure fuses prior knowledge from a pre-trained image generative model and semantic information from input images. The former provides strong knowledge guidance for this under-constraint task, while the latter provides the necessary information to mitigate the training data bias from the pre-trained model. Our framework can be used for various tasks such as correspondence matching, pose estimation, and image editing, achieving strong results on real-world image datasets under challenging illumination conditions and on in-the-wild online image collections.","sentences":["We propose 3D Congealing, a novel problem of 3D-aware alignment for 2D images capturing semantically similar objects.","Given a collection of unlabeled Internet images, our goal is to associate the shared semantic parts from the inputs and aggregate the knowledge from 2D images to a shared 3D canonical space.","We introduce a general framework that tackles the task without assuming shape templates, poses, or any camera parameters.","At its core is a canonical 3D representation that encapsulates geometric and semantic information.","The framework optimizes for the canonical representation together with the pose for each input image, and a per-image coordinate map that warps 2D pixel coordinates to the 3D canonical frame to account for the shape matching.","The optimization procedure fuses prior knowledge from a pre-trained image generative model and semantic information from input images.","The former provides strong knowledge guidance for this under-constraint task, while the latter provides the necessary information to mitigate the training data bias from the pre-trained model.","Our framework can be used for various tasks such as correspondence matching, pose estimation, and image editing, achieving strong results on real-world image datasets under challenging illumination conditions and on in-the-wild online image collections."],"url":"http://arxiv.org/abs/2404.02125v1","category":"cs.CV"}
{"created":"2024-04-02 17:18:48","title":"GINopic: Topic Modeling with Graph Isomorphism Network","abstract":"Topic modeling is a widely used approach for analyzing and exploring large document collections. Recent research efforts have incorporated pre-trained contextualized language models, such as BERT embeddings, into topic modeling. However, they often neglect the intrinsic informational value conveyed by mutual dependencies between words. In this study, we introduce GINopic, a topic modeling framework based on graph isomorphism networks to capture the correlation between words. By conducting intrinsic (quantitative as well as qualitative) and extrinsic evaluations on diverse benchmark datasets, we demonstrate the effectiveness of GINopic compared to existing topic models and highlight its potential for advancing topic modeling.","sentences":["Topic modeling is a widely used approach for analyzing and exploring large document collections.","Recent research efforts have incorporated pre-trained contextualized language models, such as BERT embeddings, into topic modeling.","However, they often neglect the intrinsic informational value conveyed by mutual dependencies between words.","In this study, we introduce GINopic, a topic modeling framework based on graph isomorphism networks to capture the correlation between words.","By conducting intrinsic (quantitative as well as qualitative) and extrinsic evaluations on diverse benchmark datasets, we demonstrate the effectiveness of GINopic compared to existing topic models and highlight its potential for advancing topic modeling."],"url":"http://arxiv.org/abs/2404.02115v1","category":"cs.CL"}
{"created":"2024-04-02 16:52:03","title":"Analysis Facilities White Paper","abstract":"This white paper presents the current status of the R&D for Analysis Facilities (AFs) and attempts to summarize the views on the future direction of these facilities. These views have been collected through the High Energy Physics (HEP) Software Foundation's (HSF) Analysis Facilities forum, established in March 2022, the Analysis Ecosystems II workshop, that took place in May 2022, and the WLCG/HSF pre-CHEP workshop, that took place in May 2023. The paper attempts to cover all the aspects of an analysis facility.","sentences":["This white paper presents the current status of the R&D for Analysis Facilities (AFs) and attempts to summarize the views on the future direction of these facilities.","These views have been collected through the High Energy Physics (HEP) Software Foundation's (HSF) Analysis Facilities forum, established in March 2022, the Analysis Ecosystems II workshop, that took place in May 2022, and the WLCG/HSF pre-CHEP workshop, that took place in May 2023.","The paper attempts to cover all the aspects of an analysis facility."],"url":"http://arxiv.org/abs/2404.02100v1","category":"hep-ex"}
{"created":"2024-04-02 16:35:52","title":"Already Moderate Population Sizes Provably Yield Strong Robustness to Noise","abstract":"Experience shows that typical evolutionary algorithms can cope well with stochastic disturbances such as noisy function evaluations.   In this first mathematical runtime analysis of the $(1+\\lambda)$ and $(1,\\lambda)$ evolutionary algorithms in the presence of prior bit-wise noise, we show that both algorithms can tolerate constant noise probabilities without increasing the asymptotic runtime on the OneMax benchmark. For this, a population size $\\lambda$ suffices that is at least logarithmic in the problem size $n$. The only previous result in this direction regarded the less realistic one-bit noise model, required a population size super-linear in the problem size, and proved a runtime guarantee roughly cubic in the noiseless runtime for the OneMax benchmark. Our significantly stronger results are based on the novel proof argument that the noiseless offspring can be seen as a biased uniform crossover between the parent and the noisy offspring. We are optimistic that the technical lemmas resulting from this insight will find applications also in future mathematical runtime analyses of evolutionary algorithms.","sentences":["Experience shows that typical evolutionary algorithms can cope well with stochastic disturbances such as noisy function evaluations.   ","In this first mathematical runtime analysis of the $(1+\\lambda)$ and $(1,\\lambda)$ evolutionary algorithms in the presence of prior bit-wise noise, we show that both algorithms can tolerate constant noise probabilities without increasing the asymptotic runtime on the OneMax benchmark.","For this, a population size $\\lambda$ suffices that is at least logarithmic in the problem size $n$. The only previous result in this direction regarded the less realistic one-bit noise model, required a population size super-linear in the problem size, and proved a runtime guarantee roughly cubic in the noiseless runtime for the OneMax benchmark.","Our significantly stronger results are based on the novel proof argument that the noiseless offspring can be seen as a biased uniform crossover between the parent and the noisy offspring.","We are optimistic that the technical lemmas resulting from this insight will find applications also in future mathematical runtime analyses of evolutionary algorithms."],"url":"http://arxiv.org/abs/2404.02090v1","category":"cs.NE"}
{"created":"2024-04-02 16:32:36","title":"Extreme plasmons","abstract":"Nanosciences largely rely on plasmons which are quasiparticles constituted by collective oscillations of quantum electron gas composed of conduction band electrons that occupy discrete quantum states. Our work has introduced non-perturbative plasmons with oscillation amplitudes that approach the extreme limit set by breakdown in characteristic coherence. In contrast, conventional plasmons are small-amplitude oscillations. Controlled excitation of extreme plasmons modeled in our work unleashes unprecedented Petavolts per meter fields. In this work, an analytical model of this new class of plasmons is developed based on quantum kinetic framework. A controllable extreme plasmon, the surface \"crunch-in\" plasmon, is modeled here using a modified independent electron approximation which takes into account the quantum oscillation frequency. Key characteristics of such realizable extreme plasmons that unlock unparalleled possibilities, are obtained.","sentences":["Nanosciences largely rely on plasmons which are quasiparticles constituted by collective oscillations of quantum electron gas composed of conduction band electrons that occupy discrete quantum states.","Our work has introduced non-perturbative plasmons with oscillation amplitudes that approach the extreme limit set by breakdown in characteristic coherence.","In contrast, conventional plasmons are small-amplitude oscillations.","Controlled excitation of extreme plasmons modeled in our work unleashes unprecedented Petavolts per meter fields.","In this work, an analytical model of this new class of plasmons is developed based on quantum kinetic framework.","A controllable extreme plasmon, the surface \"crunch-in\" plasmon, is modeled here using a modified independent electron approximation which takes into account the quantum oscillation frequency.","Key characteristics of such realizable extreme plasmons that unlock unparalleled possibilities, are obtained."],"url":"http://arxiv.org/abs/2404.02087v1","category":"cond-mat.mes-hall"}
{"created":"2024-04-02 16:25:30","title":"Advancing LLM Reasoning Generalists with Preference Trees","abstract":"We introduce Eurus, a suite of large language models (LLMs) optimized for reasoning. Finetuned from Mistral-7B and CodeLlama-70B, Eurus models achieve state-of-the-art results among open-source models on a diverse set of benchmarks covering mathematics, code generation, and logical reasoning problems. Notably, Eurus-70B beats GPT-3.5 Turbo in reasoning through a comprehensive benchmarking across 12 tests covering five tasks, and achieves a 33.3% pass@1 accuracy on LeetCode and 32.6% on TheoremQA, two challenging benchmarks, substantially outperforming existing open-source models by margins more than 13.3%. The strong performance of Eurus can be primarily attributed to UltraInteract, our newly-curated large-scale, high-quality alignment dataset specifically designed for complex reasoning tasks. UltraInteract can be used in both supervised fine-tuning and preference learning. For each instruction, it includes a preference tree consisting of (1) reasoning chains with diverse planning strategies in a unified format, (2) multi-turn interaction trajectories with the environment and the critique, and (3) pairwise data to facilitate preference learning. UltraInteract allows us to conduct an in-depth exploration of preference learning for reasoning tasks. Our investigation reveals that some well-established preference learning algorithms may be less suitable for reasoning tasks compared to their effectiveness in general conversations. Inspired by this, we derive a novel reward modeling objective which, together with UltraInteract, leads to a strong reward model.","sentences":["We introduce Eurus, a suite of large language models (LLMs) optimized for reasoning.","Finetuned from Mistral-7B and CodeLlama-70B, Eurus models achieve state-of-the-art results among open-source models on a diverse set of benchmarks covering mathematics, code generation, and logical reasoning problems.","Notably, Eurus-70B beats GPT-3.5","Turbo in reasoning through a comprehensive benchmarking across 12 tests covering five tasks, and achieves a 33.3% pass@1 accuracy on LeetCode and 32.6% on TheoremQA, two challenging benchmarks, substantially outperforming existing open-source models by margins more than 13.3%.","The strong performance of Eurus can be primarily attributed to UltraInteract, our newly-curated large-scale, high-quality alignment dataset specifically designed for complex reasoning tasks.","UltraInteract can be used in both supervised fine-tuning and preference learning.","For each instruction, it includes a preference tree consisting of (1) reasoning chains with diverse planning strategies in a unified format, (2) multi-turn interaction trajectories with the environment and the critique, and (3) pairwise data to facilitate preference learning.","UltraInteract allows us to conduct an in-depth exploration of preference learning for reasoning tasks.","Our investigation reveals that some well-established preference learning algorithms may be less suitable for reasoning tasks compared to their effectiveness in general conversations.","Inspired by this, we derive a novel reward modeling objective which, together with UltraInteract, leads to a strong reward model."],"url":"http://arxiv.org/abs/2404.02078v1","category":"cs.AI"}
{"created":"2024-04-02 16:21:42","title":"The Online Observation Quality System Implementation for the ASTRI Mini-Array Project","abstract":"The ASTRI Mini-Array project, led by the Italian National Institute for Astrophysics, aims to construct and operate nine Imaging Atmospheric Cherenkov Telescopes for high-energy gamma-ray source study and stellar intensity interferometry. Located at the Teide Astronomical Observatory in Tenerife, the project's software is essential for remote operation, emphasizing the need for prompt feedback on observations. This contribution introduces the Online Observation Quality System (OOQS) as part of the Supervisory Control And Data Acquisition (SCADA) software. OOQS performs real-time data quality checks on data from Cherenkov cameras and Intensity Interferometry instruments. It provides feedback to SCADA and operators, highlighting abnormal conditions and ensuring quick corrective actions for optimal observations. Results are archived for operator visualization and further analysis. The OOQS data quality pipeline prototype utilizes a distributed application with three main components to handle the maximum array data rate of 1.15 Gb/s. The first is a Kafka consumer that manages the data stream from the Array Data Acquisition System through Apache Kafka, handling the data serialization and deserialization involved in the transmission. The data stream is divided into batches of data written in files. The second component monitors new files and conducts analyses using the Slurm workload scheduler, leveraging its parallel processing capabilities and scalability. Finally, the process results are collected by the last component and stored in the Quality Archive.","sentences":["The ASTRI Mini-Array project, led by the Italian National Institute for Astrophysics, aims to construct and operate nine Imaging Atmospheric Cherenkov Telescopes for high-energy gamma-ray source study and stellar intensity interferometry.","Located at the Teide Astronomical Observatory in Tenerife, the project's software is essential for remote operation, emphasizing the need for prompt feedback on observations.","This contribution introduces the Online Observation Quality System (OOQS) as part of the Supervisory Control And Data Acquisition (SCADA) software.","OOQS performs real-time data quality checks on data from Cherenkov cameras and Intensity Interferometry instruments.","It provides feedback to SCADA and operators, highlighting abnormal conditions and ensuring quick corrective actions for optimal observations.","Results are archived for operator visualization and further analysis.","The OOQS data quality pipeline prototype utilizes a distributed application with three main components to handle the maximum array data rate of 1.15 Gb/s. The first is a Kafka consumer that manages the data stream from the Array Data Acquisition System through Apache Kafka, handling the data serialization and deserialization involved in the transmission.","The data stream is divided into batches of data written in files.","The second component monitors new files and conducts analyses using the Slurm workload scheduler, leveraging its parallel processing capabilities and scalability.","Finally, the process results are collected by the last component and stored in the Quality Archive."],"url":"http://arxiv.org/abs/2404.02075v1","category":"astro-ph.IM"}
{"created":"2024-04-02 16:07:50","title":"Red-Teaming Segment Anything Model","abstract":"Foundation models have emerged as pivotal tools, tackling many complex tasks through pre-training on vast datasets and subsequent fine-tuning for specific applications. The Segment Anything Model is one of the first and most well-known foundation models for computer vision segmentation tasks. This work presents a multi-faceted red-teaming analysis that tests the Segment Anything Model against challenging tasks: (1) We analyze the impact of style transfer on segmentation masks, demonstrating that applying adverse weather conditions and raindrops to dashboard images of city roads significantly distorts generated masks. (2) We focus on assessing whether the model can be used for attacks on privacy, such as recognizing celebrities' faces, and show that the model possesses some undesired knowledge in this task. (3) Finally, we check how robust the model is to adversarial attacks on segmentation masks under text prompts. We not only show the effectiveness of popular white-box attacks and resistance to black-box attacks but also introduce a novel approach - Focused Iterative Gradient Attack (FIGA) that combines white-box approaches to construct an efficient attack resulting in a smaller number of modified pixels. All of our testing methods and analyses indicate a need for enhanced safety measures in foundation models for image segmentation.","sentences":["Foundation models have emerged as pivotal tools, tackling many complex tasks through pre-training on vast datasets and subsequent fine-tuning for specific applications.","The Segment Anything Model is one of the first and most well-known foundation models for computer vision segmentation tasks.","This work presents a multi-faceted red-teaming analysis that tests the Segment Anything Model against challenging tasks: (1) We analyze the impact of style transfer on segmentation masks, demonstrating that applying adverse weather conditions and raindrops to dashboard images of city roads significantly distorts generated masks.","(2) We focus on assessing whether the model can be used for attacks on privacy, such as recognizing celebrities' faces, and show that the model possesses some undesired knowledge in this task.","(3) Finally, we check how robust the model is to adversarial attacks on segmentation masks under text prompts.","We not only show the effectiveness of popular white-box attacks and resistance to black-box attacks but also introduce a novel approach - Focused Iterative Gradient Attack (FIGA) that combines white-box approaches to construct an efficient attack resulting in a smaller number of modified pixels.","All of our testing methods and analyses indicate a need for enhanced safety measures in foundation models for image segmentation."],"url":"http://arxiv.org/abs/2404.02067v1","category":"cs.CV"}
{"created":"2024-04-02 16:04:31","title":"SPMamba: State-space model is all you need in speech separation","abstract":"In speech separation, both CNN- and Transformer-based models have demonstrated robust separation capabilities, garnering significant attention within the research community. However, CNN-based methods have limited modelling capability for long-sequence audio, leading to suboptimal separation performance. Conversely, Transformer-based methods are limited in practical applications due to their high computational complexity. Notably, within computer vision, Mamba-based methods have been celebrated for their formidable performance and reduced computational requirements. In this paper, we propose a network architecture for speech separation using a state-space model, namely SPMamba. We adopt the TF-GridNet model as the foundational framework and substitute its Transformer component with a bidirectional Mamba module, aiming to capture a broader range of contextual information. Our experimental results reveal an important role in the performance aspects of Mamba-based models. SPMamba demonstrates superior performance with a significant advantage over existing separation models in a dataset built on Librispeech. Notably, SPMamba achieves a substantial improvement in separation quality, with a 2.42 dB enhancement in SI-SNRi compared to the TF-GridNet. The source code for SPMamba is publicly accessible at https://github.com/JusperLee/SPMamba .","sentences":["In speech separation, both CNN- and Transformer-based models have demonstrated robust separation capabilities, garnering significant attention within the research community.","However, CNN-based methods have limited modelling capability for long-sequence audio, leading to suboptimal separation performance.","Conversely, Transformer-based methods are limited in practical applications due to their high computational complexity.","Notably, within computer vision, Mamba-based methods have been celebrated for their formidable performance and reduced computational requirements.","In this paper, we propose a network architecture for speech separation using a state-space model, namely SPMamba.","We adopt the TF-GridNet model as the foundational framework and substitute its Transformer component with a bidirectional Mamba module, aiming to capture a broader range of contextual information.","Our experimental results reveal an important role in the performance aspects of Mamba-based models.","SPMamba demonstrates superior performance with a significant advantage over existing separation models in a dataset built on Librispeech.","Notably, SPMamba achieves a substantial improvement in separation quality, with a 2.42 dB enhancement in SI-SNRi compared to the TF-GridNet.","The source code for SPMamba is publicly accessible at https://github.com/JusperLee/SPMamba ."],"url":"http://arxiv.org/abs/2404.02063v1","category":"cs.SD"}
{"created":"2024-04-02 16:01:18","title":"Digital Forgetting in Large Language Models: A Survey of Unlearning Methods","abstract":"The objective of digital forgetting is, given a model with undesirable knowledge or behavior, obtain a new model where the detected issues are no longer present. The motivations for forgetting include privacy protection, copyright protection, elimination of biases and discrimination, and prevention of harmful content generation. Effective digital forgetting has to be effective (meaning how well the new model has forgotten the undesired knowledge/behavior), retain the performance of the original model on the desirable tasks, and be scalable (in particular forgetting has to be more efficient than retraining from scratch on just the tasks/data to be retained). This survey focuses on forgetting in large language models (LLMs). We first provide background on LLMs, including their components, the types of LLMs, and their usual training pipeline. Second, we describe the motivations, types, and desired properties of digital forgetting. Third, we introduce the approaches to digital forgetting in LLMs, among which unlearning methodologies stand out as the state of the art. Fourth, we provide a detailed taxonomy of machine unlearning methods for LLMs, and we survey and compare current approaches. Fifth, we detail datasets, models and metrics used for the evaluation of forgetting, retaining and runtime. Sixth, we discuss challenges in the area. Finally, we provide some concluding remarks.","sentences":["The objective of digital forgetting is, given a model with undesirable knowledge or behavior, obtain a new model where the detected issues are no longer present.","The motivations for forgetting include privacy protection, copyright protection, elimination of biases and discrimination, and prevention of harmful content generation.","Effective digital forgetting has to be effective (meaning how well the new model has forgotten the undesired knowledge/behavior), retain the performance of the original model on the desirable tasks, and be scalable (in particular forgetting has to be more efficient than retraining from scratch on just the tasks/data to be retained).","This survey focuses on forgetting in large language models (LLMs).","We first provide background on LLMs, including their components, the types of LLMs, and their usual training pipeline.","Second, we describe the motivations, types, and desired properties of digital forgetting.","Third, we introduce the approaches to digital forgetting in LLMs, among which unlearning methodologies stand out as the state of the art.","Fourth, we provide a detailed taxonomy of machine unlearning methods for LLMs, and we survey and compare current approaches.","Fifth, we detail datasets, models and metrics used for the evaluation of forgetting, retaining and runtime.","Sixth, we discuss challenges in the area.","Finally, we provide some concluding remarks."],"url":"http://arxiv.org/abs/2404.02062v1","category":"cs.CR"}
{"created":"2024-04-02 15:59:11","title":"Long-context LLMs Struggle with Long In-context Learning","abstract":"Large Language Models (LLMs) have made significant strides in handling long sequences exceeding 32K tokens. However, their performance evaluation has largely been confined to metrics like perplexity and synthetic tasks, which may not fully capture their abilities in more nuanced, real-world scenarios. This study introduces a specialized benchmark (LIConBench) focusing on long in-context learning within the realm of extreme-label classification. We meticulously selected six datasets with a label range spanning 28 to 174 classes covering different input (few-shot demonstration) length from 2K to 50K. Our benchmark requires LLMs to comprehend the entire input to recognize the massive label spaces to make correct prediction. We evaluate 13 long-context LLMs on our benchmarks. We find that the long-context LLMs perform relatively well under the token length of 20K and the performance benefits from utilizing the long context window. However, after the context window exceeds 20K, most LLMs except GPT-4 will dip dramatically. This suggests a notable gap in current LLM capabilities for processing and understanding long, context-rich sequences. Further analysis revealed a tendency among models to favor predictions for labels presented towards the end at the sequence. Their ability to reason over multiple pieces in the long sequence is yet to be improved. Our study reveals that long context understanding and reasoning is still a challenging task for the existing LLMs. We believe LIConBench could serve as a more realistic evaluation for the future long context LLMs.","sentences":["Large Language Models (LLMs) have made significant strides in handling long sequences exceeding 32K tokens.","However, their performance evaluation has largely been confined to metrics like perplexity and synthetic tasks, which may not fully capture their abilities in more nuanced, real-world scenarios.","This study introduces a specialized benchmark (LIConBench) focusing on long in-context learning within the realm of extreme-label classification.","We meticulously selected six datasets with a label range spanning 28 to 174 classes covering different input (few-shot demonstration) length from 2K to 50K. Our benchmark requires LLMs to comprehend the entire input to recognize the massive label spaces to make correct prediction.","We evaluate 13 long-context LLMs on our benchmarks.","We find that the long-context LLMs perform relatively well under the token length of 20K and the performance benefits from utilizing the long context window.","However, after the context window exceeds 20K, most LLMs except GPT-4 will dip dramatically.","This suggests a notable gap in current LLM capabilities for processing and understanding long, context-rich sequences.","Further analysis revealed a tendency among models to favor predictions for labels presented towards the end at the sequence.","Their ability to reason over multiple pieces in the long sequence is yet to be improved.","Our study reveals that long context understanding and reasoning is still a challenging task for the existing LLMs.","We believe LIConBench could serve as a more realistic evaluation for the future long context LLMs."],"url":"http://arxiv.org/abs/2404.02060v1","category":"cs.CL"}
{"created":"2024-04-02 15:39:14","title":"Universal representations for financial transactional data: embracing local, global, and external contexts","abstract":"Effective processing of financial transactions is essential for banking data analysis. However, in this domain, most methods focus on specialized solutions to stand-alone problems instead of constructing universal representations suitable for many problems. We present a representation learning framework that addresses diverse business challenges. We also suggest novel generative models that account for data specifics, and a way to integrate external information into a client's representation, leveraging insights from other customers' actions. Finally, we offer a benchmark, describing representation quality globally, concerning the entire transaction history; locally, reflecting the client's current state; and dynamically, capturing representation evolution over time. Our generative approach demonstrates superior performance in local tasks, with an increase in ROC-AUC of up to 14\\% for the next MCC prediction task and up to 46\\% for downstream tasks from existing contrastive baselines. Incorporating external information improves the scores by an additional 20\\%.","sentences":["Effective processing of financial transactions is essential for banking data analysis.","However, in this domain, most methods focus on specialized solutions to stand-alone problems instead of constructing universal representations suitable for many problems.","We present a representation learning framework that addresses diverse business challenges.","We also suggest novel generative models that account for data specifics, and a way to integrate external information into a client's representation, leveraging insights from other customers' actions.","Finally, we offer a benchmark, describing representation quality globally, concerning the entire transaction history; locally, reflecting the client's current state; and dynamically, capturing representation evolution over time.","Our generative approach demonstrates superior performance in local tasks, with an increase in ROC-AUC of up to 14\\% for the next MCC prediction task and up to 46\\% for downstream tasks from existing contrastive baselines.","Incorporating external information improves the scores by an additional 20\\%."],"url":"http://arxiv.org/abs/2404.02047v1","category":"cs.LG"}
{"created":"2024-04-02 15:38:18","title":"Causality-based Transfer of Driving Scenarios to Unseen Intersections","abstract":"Scenario-based testing of automated driving functions has become a promising method to reduce time and cost compared to real-world testing. In scenario-based testing automated functions are evaluated in a set of pre-defined scenarios. These scenarios provide information about vehicle behaviors, environmental conditions, or road characteristics using parameters. To create realistic scenarios, parameters and parameter dependencies have to be fitted utilizing real-world data. However, due to the large variety of intersections and movement constellations found in reality, data may not be available for certain scenarios. This paper proposes a methodology to systematically analyze relations between parameters of scenarios. Bayesian networks are utilized to analyze causal dependencies in order to decrease the amount of required data and to transfer causal patterns creating unseen scenarios. Thereby, infrastructural influences on movement patterns are investigated to generate realistic scenarios on unobserved intersections. For evaluation, scenarios and underlying parameters are extracted from the inD dataset. Movement patterns are estimated, transferred and checked against recorded data from those initially unseen intersections.","sentences":["Scenario-based testing of automated driving functions has become a promising method to reduce time and cost compared to real-world testing.","In scenario-based testing automated functions are evaluated in a set of pre-defined scenarios.","These scenarios provide information about vehicle behaviors, environmental conditions, or road characteristics using parameters.","To create realistic scenarios, parameters and parameter dependencies have to be fitted utilizing real-world data.","However, due to the large variety of intersections and movement constellations found in reality, data may not be available for certain scenarios.","This paper proposes a methodology to systematically analyze relations between parameters of scenarios.","Bayesian networks are utilized to analyze causal dependencies in order to decrease the amount of required data and to transfer causal patterns creating unseen scenarios.","Thereby, infrastructural influences on movement patterns are investigated to generate realistic scenarios on unobserved intersections.","For evaluation, scenarios and underlying parameters are extracted from the inD dataset.","Movement patterns are estimated, transferred and checked against recorded data from those initially unseen intersections."],"url":"http://arxiv.org/abs/2404.02046v1","category":"cs.CV"}
{"created":"2024-04-02 15:37:09","title":"Ukrainian Texts Classification: Exploration of Cross-lingual Knowledge Transfer Approaches","abstract":"Despite the extensive amount of labeled datasets in the NLP text classification field, the persistent imbalance in data availability across various languages remains evident. Ukrainian, in particular, stands as a language that still can benefit from the continued refinement of cross-lingual methodologies. Due to our knowledge, there is a tremendous lack of Ukrainian corpora for typical text classification tasks. In this work, we leverage the state-of-the-art advances in NLP, exploring cross-lingual knowledge transfer methods avoiding manual data curation: large multilingual encoders and translation systems, LLMs, and language adapters. We test the approaches on three text classification tasks -- toxicity classification, formality classification, and natural language inference -- providing the \"recipe\" for the optimal setups.","sentences":["Despite the extensive amount of labeled datasets in the NLP text classification field, the persistent imbalance in data availability across various languages remains evident.","Ukrainian, in particular, stands as a language that still can benefit from the continued refinement of cross-lingual methodologies.","Due to our knowledge, there is a tremendous lack of Ukrainian corpora for typical text classification tasks.","In this work, we leverage the state-of-the-art advances in NLP, exploring cross-lingual knowledge transfer methods avoiding manual data curation: large multilingual encoders and translation systems, LLMs, and language adapters.","We test the approaches on three text classification tasks -- toxicity classification, formality classification, and natural language inference -- providing the \"recipe\" for the optimal setups."],"url":"http://arxiv.org/abs/2404.02043v1","category":"cs.CL"}
{"created":"2024-04-02 15:34:18","title":"A Survey on Large Language Model-Based Game Agents","abstract":"The development of game agents holds a critical role in advancing towards Artificial General Intelligence (AGI). The progress of LLMs and their multimodal counterparts (MLLMs) offers an unprecedented opportunity to evolve and empower game agents with human-like decision-making capabilities in complex computer game environments. This paper provides a comprehensive overview of LLM-based game agents from a holistic viewpoint. First, we introduce the conceptual architecture of LLM-based game agents, centered around six essential functional components: perception, memory, thinking, role-playing, action, and learning. Second, we survey existing representative LLM-based game agents documented in the literature with respect to methodologies and adaptation agility across six genres of games, including adventure, communication, competition, cooperation, simulation, and crafting & exploration games. Finally, we present an outlook of future research and development directions in this burgeoning field. A curated list of relevant papers is maintained and made accessible at: https://github.com/git-disl/awesome-LLM-game-agent-papers.","sentences":["The development of game agents holds a critical role in advancing towards Artificial General Intelligence (AGI).","The progress of LLMs and their multimodal counterparts (MLLMs) offers an unprecedented opportunity to evolve and empower game agents with human-like decision-making capabilities in complex computer game environments.","This paper provides a comprehensive overview of LLM-based game agents from a holistic viewpoint.","First, we introduce the conceptual architecture of LLM-based game agents, centered around six essential functional components: perception, memory, thinking, role-playing, action, and learning.","Second, we survey existing representative LLM-based game agents documented in the literature with respect to methodologies and adaptation agility across six genres of games, including adventure, communication, competition, cooperation, simulation, and crafting & exploration games.","Finally, we present an outlook of future research and development directions in this burgeoning field.","A curated list of relevant papers is maintained and made accessible at: https://github.com/git-disl/awesome-LLM-game-agent-papers."],"url":"http://arxiv.org/abs/2404.02039v1","category":"cs.AI"}
{"created":"2024-04-02 15:32:32","title":"MultiParaDetox: Extending Text Detoxification with Parallel Data to New Languages","abstract":"Text detoxification is a textual style transfer (TST) task where a text is paraphrased from a toxic surface form, e.g. featuring rude words, to the neutral register. Recently, text detoxification methods found their applications in various task such as detoxification of Large Language Models (LLMs) (Leong et al., 2023; He et al., 2024; Tang et al., 2023) and toxic speech combating in social networks (Deng et al., 2023; Mun et al., 2023; Agarwal et al., 2023). All these applications are extremely important to ensure safe communication in modern digital worlds. However, the previous approaches for parallel text detoxification corpora collection -- ParaDetox (Logacheva et al., 2022) and APPADIA (Atwell et al., 2022) -- were explored only in monolingual setup. In this work, we aim to extend ParaDetox pipeline to multiple languages presenting MultiParaDetox to automate parallel detoxification corpus collection for potentially any language. Then, we experiment with different text detoxification models -- from unsupervised baselines to LLMs and fine-tuned models on the presented parallel corpora -- showing the great benefit of parallel corpus presence to obtain state-of-the-art text detoxification models for any language.","sentences":["Text detoxification is a textual style transfer (TST) task where a text is paraphrased from a toxic surface form, e.g. featuring rude words, to the neutral register.","Recently, text detoxification methods found their applications in various task such as detoxification of Large Language Models (LLMs) (Leong et al., 2023; He et al., 2024; Tang et al., 2023) and toxic speech combating in social networks (Deng et al., 2023; Mun et al., 2023; Agarwal et al., 2023).","All these applications are extremely important to ensure safe communication in modern digital worlds.","However, the previous approaches for parallel text detoxification corpora collection -- ParaDetox (Logacheva et al., 2022) and APPADIA (Atwell et al., 2022) -- were explored only in monolingual setup.","In this work, we aim to extend ParaDetox pipeline to multiple languages presenting MultiParaDetox to automate parallel detoxification corpus collection for potentially any language.","Then, we experiment with different text detoxification models -- from unsupervised baselines to LLMs and fine-tuned models on the presented parallel corpora -- showing the great benefit of parallel corpus presence to obtain state-of-the-art text detoxification models for any language."],"url":"http://arxiv.org/abs/2404.02037v1","category":"cs.CL"}
{"created":"2024-04-02 15:23:08","title":"How much symmetry do symmetric measurements need for efficient operational applications?","abstract":"We introduce a generalization of symmetric measurements to collections of unequinumerous positive, operator-valued measures (POVMs). For informationally complete sets, we propose construction methods from orthonormal Hermitian operator bases. The correspondence between operator bases and measurements can be as high as four-to-four, with a one-to-one correspondence following only under additional assumptions. Importantly, it turns out that some of the symmetry properties, lost in the process of generalization, can be recovered without fixing the same number of elements for all POVMs. In particular, for a wide class of unequinumerous symmetric measurements that are conical 2-designs, we derive the index of coincidence, entropic uncertainty relations, and separability criteria for bipartite quantum states.","sentences":["We introduce a generalization of symmetric measurements to collections of unequinumerous positive, operator-valued measures (POVMs).","For informationally complete sets, we propose construction methods from orthonormal Hermitian operator bases.","The correspondence between operator bases and measurements can be as high as four-to-four, with a one-to-one correspondence following only under additional assumptions.","Importantly, it turns out that some of the symmetry properties, lost in the process of generalization, can be recovered without fixing the same number of elements for all POVMs.","In particular, for a wide class of unequinumerous symmetric measurements that are conical 2-designs, we derive the index of coincidence, entropic uncertainty relations, and separability criteria for bipartite quantum states."],"url":"http://arxiv.org/abs/2404.02034v1","category":"quant-ph"}
{"created":"2024-04-02 15:21:13","title":"Search for $C$-even states decaying to $D_{s}^{\\pm}D_{s}^{*\\mp}$ with masses between $4.08$ and $4.32$ $\\rm GeV/{\\it c}^{2}$","abstract":"Six $C$-even states, denoted as $X$, with quantum numbers $J^{PC}=0^{-+}$, $1^{\\pm+}$, or $2^{\\pm+}$, are searched for via the $e^+e^-\\to\\gamma D_{s}^{\\pm}D_{s}^{*\\mp}$ process using $(1667.39\\pm8.84)~\\mathrm{pb}^{-1}$ of $e^+e^-$ collision data collected with the BESIII detector operating at the BEPCII storage ring at center-of-mass energy of $\\sqrt{s}=(4681.92\\pm0.30)~\\mathrm{MeV}$. No statistically significant signal is observed in the mass range from $4.08$ to $4.32~\\mathrm{GeV}/c^{2}$. The upper limits of $\\sigma[e^+e^-\\to\\gamma X]\\cdot \\mathcal{B}[X \\to D_{s}^{\\pm}D_{s}^{*\\mp}]$ at a $90\\%$ confidence level are determined.","sentences":["Six $C$-even states, denoted as $X$, with quantum numbers $J^{PC}=0^{-+}$, $1^{\\pm+}$, or $2^{\\pm+}$, are searched for via the $e^+e^-\\to\\gamma D_{s}^{\\pm}D_{s}^{*\\mp}$ process using $(1667.39\\pm8.84)~\\mathrm{pb}^{-1}$ of $e^+e^-$ collision data collected with the BESIII detector operating at the BEPCII storage ring at center-of-mass energy of $\\sqrt{s}=(4681.92\\pm0.30)~\\mathrm{MeV}$. No statistically significant signal is observed in the mass range from $4.08$ to $4.32~\\mathrm{GeV}/c^{2}$. The upper limits of $\\sigma[e^+e^-\\to\\gamma X]\\cdot \\mathcal{B}[X \\to D_{s}^{\\pm}D_{s}^{*\\mp}]$ at a $90\\%$ confidence level are determined."],"url":"http://arxiv.org/abs/2404.02033v1","category":"hep-ex"}
{"created":"2024-04-02 15:08:35","title":"Large Language Models for Orchestrating Bimanual Robots","abstract":"Although there has been rapid progress in endowing robots with the ability to solve complex manipulation tasks, generating control policies for bimanual robots to solve tasks involving two hands is still challenging because of the difficulties in effective temporal and spatial coordination. With emergent abilities in terms of step-by-step reasoning and in-context learning, Large Language Models (LLMs) have taken control of a variety of robotic tasks. However, the nature of language communication via a single sequence of discrete symbols makes LLM-based coordination in continuous space a particular challenge for bimanual tasks. To tackle this challenge for the first time by an LLM, we present LAnguage-model-based Bimanual ORchestration (LABOR), an agent utilizing an LLM to analyze task configurations and devise coordination control policies for addressing long-horizon bimanual tasks. In the simulated environment, the LABOR agent is evaluated through several everyday tasks on the NICOL humanoid robot. Reported success rates indicate that overall coordination efficiency is close to optimal performance, while the analysis of failure causes, classified into spatial and temporal coordination and skill selection, shows that these vary over tasks. The project website can be found at http://labor-agent.github.io","sentences":["Although there has been rapid progress in endowing robots with the ability to solve complex manipulation tasks, generating control policies for bimanual robots to solve tasks involving two hands is still challenging because of the difficulties in effective temporal and spatial coordination.","With emergent abilities in terms of step-by-step reasoning and in-context learning, Large Language Models (LLMs) have taken control of a variety of robotic tasks.","However, the nature of language communication via a single sequence of discrete symbols makes LLM-based coordination in continuous space a particular challenge for bimanual tasks.","To tackle this challenge for the first time by an LLM, we present LAnguage-model-based Bimanual ORchestration (LABOR), an agent utilizing an LLM to analyze task configurations and devise coordination control policies for addressing long-horizon bimanual tasks.","In the simulated environment, the LABOR agent is evaluated through several everyday tasks on the NICOL humanoid robot.","Reported success rates indicate that overall coordination efficiency is close to optimal performance, while the analysis of failure causes, classified into spatial and temporal coordination and skill selection, shows that these vary over tasks.","The project website can be found at http://labor-agent.github.io"],"url":"http://arxiv.org/abs/2404.02018v1","category":"cs.RO"}
{"created":"2024-04-02 14:48:20","title":"An MILP-Based Solution Scheme for Factored and Robust Factored Markov Decision Processes","abstract":"Factored Markov decision processes (MDPs) are a prominent paradigm within the artificial intelligence community for modeling and solving large-scale MDPs whose rewards and dynamics decompose into smaller, loosely interacting components. Through the use of dynamic Bayesian networks and context-specific independence, factored MDPs can achieve an exponential reduction in the state space of an MDP and thus scale to problem sizes that are beyond the reach of classical MDP algorithms. However, factored MDPs are typically solved using custom-designed algorithms that can require meticulous implementations and considerable fine-tuning. In this paper, we propose a mathematical programming approach to solving factored MDPs. In contrast to existing solution schemes, our approach leverages off-the-shelf solvers, which allows for a streamlined implementation and maintenance; it effectively capitalizes on the factored structure present in both state and action spaces; and it readily extends to the largely unexplored class of robust factored MDPs, whose transition kernels are only known to reside in a pre-specified ambiguity set. Our numerical experiments demonstrate the potential of our approach.","sentences":["Factored Markov decision processes (MDPs) are a prominent paradigm within the artificial intelligence community for modeling and solving large-scale MDPs whose rewards and dynamics decompose into smaller, loosely interacting components.","Through the use of dynamic Bayesian networks and context-specific independence, factored MDPs can achieve an exponential reduction in the state space of an MDP and thus scale to problem sizes that are beyond the reach of classical MDP algorithms.","However, factored MDPs are typically solved using custom-designed algorithms that can require meticulous implementations and considerable fine-tuning.","In this paper, we propose a mathematical programming approach to solving factored MDPs.","In contrast to existing solution schemes, our approach leverages off-the-shelf solvers, which allows for a streamlined implementation and maintenance; it effectively capitalizes on the factored structure present in both state and action spaces; and it readily extends to the largely unexplored class of robust factored MDPs, whose transition kernels are only known to reside in a pre-specified ambiguity set.","Our numerical experiments demonstrate the potential of our approach."],"url":"http://arxiv.org/abs/2404.02006v1","category":"math.OC"}
{"created":"2024-04-02 14:42:52","title":"Emergence of Chemotactic Strategies with Multi-Agent Reinforcement Learning","abstract":"Reinforcement learning (RL) is a flexible and efficient method for programming micro-robots in complex environments. Here we investigate whether reinforcement learning can provide insights into biological systems when trained to perform chemotaxis. Namely, whether we can learn about how intelligent agents process given information in order to swim towards a target. We run simulations covering a range of agent shapes, sizes, and swim speeds to determine if the physical constraints on biological swimmers, namely Brownian motion, lead to regions where reinforcement learners' training fails. We find that the RL agents can perform chemotaxis as soon as it is physically possible and, in some cases, even before the active swimming overpowers the stochastic environment. We study the efficiency of the emergent policy and identify convergence in agent size and swim speeds. Finally, we study the strategy adopted by the reinforcement learning algorithm to explain how the agents perform their tasks. To this end, we identify three emerging dominant strategies and several rare approaches taken. These strategies, whilst producing almost identical trajectories in simulation, are distinct and give insight into the possible mechanisms behind which biological agents explore their environment and respond to changing conditions.","sentences":["Reinforcement learning (RL) is a flexible and efficient method for programming micro-robots in complex environments.","Here we investigate whether reinforcement learning can provide insights into biological systems when trained to perform chemotaxis.","Namely, whether we can learn about how intelligent agents process given information in order to swim towards a target.","We run simulations covering a range of agent shapes, sizes, and swim speeds to determine if the physical constraints on biological swimmers, namely Brownian motion, lead to regions where reinforcement learners' training fails.","We find that the RL agents can perform chemotaxis as soon as it is physically possible and, in some cases, even before the active swimming overpowers the stochastic environment.","We study the efficiency of the emergent policy and identify convergence in agent size and swim speeds.","Finally, we study the strategy adopted by the reinforcement learning algorithm to explain how the agents perform their tasks.","To this end, we identify three emerging dominant strategies and several rare approaches taken.","These strategies, whilst producing almost identical trajectories in simulation, are distinct and give insight into the possible mechanisms behind which biological agents explore their environment and respond to changing conditions."],"url":"http://arxiv.org/abs/2404.01999v1","category":"physics.bio-ph"}
{"created":"2024-04-02 14:22:54","title":"Predicting the Intention to Interact with a Service Robot:the Role of Gaze Cues","abstract":"For a service robot, it is crucial to perceive as early as possible that an approaching person intends to interact: in this case, it can proactively enact friendly behaviors that lead to an improved user experience. We solve this perception task with a sequence-to-sequence classifier of a potential user intention to interact, which can be trained in a self-supervised way. Our main contribution is a study of the benefit of features representing the person's gaze in this context. Extensive experiments on a novel dataset show that the inclusion of gaze cues significantly improves the classifier performance (AUROC increases from 84.5% to 91.2%); the distance at which an accurate classification can be achieved improves from 2.4 m to 3.2 m. We also quantify the system's ability to adapt to new environments without external supervision. Qualitative experiments show practical applications with a waiter robot.","sentences":["For a service robot, it is crucial to perceive as early as possible that an approaching person intends to interact: in this case, it can proactively enact friendly behaviors that lead to an improved user experience.","We solve this perception task with a sequence-to-sequence classifier of a potential user intention to interact, which can be trained in a self-supervised way.","Our main contribution is a study of the benefit of features representing the person's gaze in this context.","Extensive experiments on a novel dataset show that the inclusion of gaze cues significantly improves the classifier performance (AUROC increases from 84.5% to 91.2%); the distance at which an accurate classification can be achieved improves from 2.4 m to 3.2 m. We also quantify the system's ability to adapt to new environments without external supervision.","Qualitative experiments show practical applications with a waiter robot."],"url":"http://arxiv.org/abs/2404.01986v1","category":"cs.RO"}
{"created":"2024-04-02 14:19:30","title":"Zero-Shot Multi-Lingual Speaker Verification in Clinical Trials","abstract":"Due to the substantial number of clinicians, patients, and data collection environments involved in clinical trials, gathering data of superior quality poses a significant challenge. In clinical trials, patients are assessed based on their speech data to detect and monitor cognitive and mental health disorders. We propose using these speech recordings to verify the identities of enrolled patients and identify and exclude the individuals who try to enroll multiple times in the same trial. Since clinical studies are often conducted across different countries, creating a system that can perform speaker verification in diverse languages without additional development effort is imperative. We evaluate pre-trained TitaNet, ECAPA-TDNN, and SpeakerNet models by enrolling and testing with speech-impaired patients speaking English, German, Danish, Spanish, and Arabic languages. Our results demonstrate that tested models can effectively generalize to clinical speakers, with less than 2.7% EER for European Languages and 8.26% EER for Arabic. This represents a significant step in developing more versatile and efficient speaker verification systems for cognitive and mental health clinical trials that can be used across a wide range of languages and dialects, substantially reducing the effort required to develop speaker verification systems for multiple languages. We also evaluate how speech tasks and number of speakers involved in the trial influence the performance and show that the type of speech tasks impacts the model performance.","sentences":["Due to the substantial number of clinicians, patients, and data collection environments involved in clinical trials, gathering data of superior quality poses a significant challenge.","In clinical trials, patients are assessed based on their speech data to detect and monitor cognitive and mental health disorders.","We propose using these speech recordings to verify the identities of enrolled patients and identify and exclude the individuals who try to enroll multiple times in the same trial.","Since clinical studies are often conducted across different countries, creating a system that can perform speaker verification in diverse languages without additional development effort is imperative.","We evaluate pre-trained TitaNet, ECAPA-TDNN, and SpeakerNet models by enrolling and testing with speech-impaired patients speaking English, German, Danish, Spanish, and Arabic languages.","Our results demonstrate that tested models can effectively generalize to clinical speakers, with less than 2.7% EER for European Languages and 8.26% EER for Arabic.","This represents a significant step in developing more versatile and efficient speaker verification systems for cognitive and mental health clinical trials that can be used across a wide range of languages and dialects, substantially reducing the effort required to develop speaker verification systems for multiple languages.","We also evaluate how speech tasks and number of speakers involved in the trial influence the performance and show that the type of speech tasks impacts the model performance."],"url":"http://arxiv.org/abs/2404.01981v1","category":"cs.LG"}
{"created":"2024-04-02 14:16:59","title":"Joint-Task Regularization for Partially Labeled Multi-Task Learning","abstract":"Multi-task learning has become increasingly popular in the machine learning field, but its practicality is hindered by the need for large, labeled datasets. Most multi-task learning methods depend on fully labeled datasets wherein each input example is accompanied by ground-truth labels for all target tasks. Unfortunately, curating such datasets can be prohibitively expensive and impractical, especially for dense prediction tasks which require per-pixel labels for each image. With this in mind, we propose Joint-Task Regularization (JTR), an intuitive technique which leverages cross-task relations to simultaneously regularize all tasks in a single joint-task latent space to improve learning when data is not fully labeled for all tasks. JTR stands out from existing approaches in that it regularizes all tasks jointly rather than separately in pairs -- therefore, it achieves linear complexity relative to the number of tasks while previous methods scale quadratically. To demonstrate the validity of our approach, we extensively benchmark our method across a wide variety of partially labeled scenarios based on NYU-v2, Cityscapes, and Taskonomy.","sentences":["Multi-task learning has become increasingly popular in the machine learning field, but its practicality is hindered by the need for large, labeled datasets.","Most multi-task learning methods depend on fully labeled datasets wherein each input example is accompanied by ground-truth labels for all target tasks.","Unfortunately, curating such datasets can be prohibitively expensive and impractical, especially for dense prediction tasks which require per-pixel labels for each image.","With this in mind, we propose Joint-Task Regularization (JTR), an intuitive technique which leverages cross-task relations to simultaneously regularize all tasks in a single joint-task latent space to improve learning when data is not fully labeled for all tasks.","JTR stands out from existing approaches in that it regularizes all tasks jointly rather than separately in pairs -- therefore, it achieves linear complexity relative to the number of tasks while previous methods scale quadratically.","To demonstrate the validity of our approach, we extensively benchmark our method across a wide variety of partially labeled scenarios based on NYU-v2, Cityscapes, and Taskonomy."],"url":"http://arxiv.org/abs/2404.01976v1","category":"cs.CV"}
{"created":"2024-04-02 14:16:56","title":"Gaia23bab : a new EXor","abstract":"On March 6 2023, the Gaia telescope has alerted a 2-magnitude burst from Gaia23bab, a Young Stellar Object in the Galactic plane. We observed Gaia23bab with the Large Binocular Telescope obtaining optical and near-infrared spectra close in time to the peak of the burst, and collected all public multi-band photometry to reconstruct the historical light curve. This latter shows three bursts in ten years (2013, 2017 and 2023), whose duration and amplitude are typical of EXor variables.   We estimate that, due to the bursts, the mass accumulated on the star is about twice greater than if the source had remained quiescent for the same period of time. Photometric analysis indicates that Gaia23bab is a Class,II source with age < 1 Myr, spectral type G3-K0, stellar luminosity 4.0 L_sun, and mass 1.6 M_sun. The optical/near infrared spectrum is rich in emission lines. From the analysis of these lines we measured the accretion luminosity and the mass accretion rate L_acc(burst)=3.7 L_sun, M_acc(burst) 2.0 10 $^(-7) M_sun/yr, consistent with those of EXors. More generally, we derive the relationships between accretion and stellar parameters in a sample of EXors. We find that, when in burst, the accretion parameters become almost independent of the stellar parameters and that EXors, even in quiescence, are more efficient than classical T Tauri stars in assembling mass.","sentences":["On March 6 2023, the Gaia telescope has alerted a 2-magnitude burst from Gaia23bab, a Young Stellar Object in the Galactic plane.","We observed Gaia23bab with the Large Binocular Telescope obtaining optical and near-infrared spectra close in time to the peak of the burst, and collected all public multi-band photometry to reconstruct the historical light curve.","This latter shows three bursts in ten years (2013, 2017 and 2023), whose duration and amplitude are typical of EXor variables.   ","We estimate that, due to the bursts, the mass accumulated on the star is about twice greater than if the source had remained quiescent for the same period of time.","Photometric analysis indicates that Gaia23bab is a Class,II source with age <","1 Myr, spectral type G3-K0, stellar luminosity 4.0 L_sun, and mass 1.6 M_sun.","The optical/near infrared spectrum is rich in emission lines.","From the analysis of these lines we measured the accretion luminosity and the mass accretion rate L_acc(burst)=3.7 L_sun, M_acc(burst) 2.0 10 $^(-7) M_sun/yr, consistent with those of EXors.","More generally, we derive the relationships between accretion and stellar parameters in a sample of EXors.","We find that, when in burst, the accretion parameters become almost independent of the stellar parameters and that EXors, even in quiescence, are more efficient than classical T Tauri stars in assembling mass."],"url":"http://arxiv.org/abs/2404.01974v1","category":"astro-ph.SR"}
{"created":"2024-04-02 14:03:37","title":"Towards Leveraging AutoML for Sustainable Deep Learning: A Multi-Objective HPO Approach on Deep Shift Neural Networks","abstract":"Deep Learning (DL) has advanced various fields by extracting complex patterns from large datasets. However, the computational demands of DL models pose environmental and resource challenges. Deep shift neural networks (DSNNs) offer a solution by leveraging shift operations to reduce computational complexity at inference. Following the insights from standard DNNs, we are interested in leveraging the full potential of DSNNs by means of AutoML techniques. We study the impact of hyperparameter optimization (HPO) to maximize DSNN performance while minimizing resource consumption. Since this combines multi-objective (MO) optimization with accuracy and energy consumption as potentially complementary objectives, we propose to combine state-of-the-art multi-fidelity (MF) HPO with multi-objective optimization. Experimental results demonstrate the effectiveness of our approach, resulting in models with over 80\\% in accuracy and low computational cost. Overall, our method accelerates efficient model development while enabling sustainable AI applications.","sentences":["Deep Learning (DL) has advanced various fields by extracting complex patterns from large datasets.","However, the computational demands of DL models pose environmental and resource challenges.","Deep shift neural networks (DSNNs) offer a solution by leveraging shift operations to reduce computational complexity at inference.","Following the insights from standard DNNs, we are interested in leveraging the full potential of DSNNs by means of AutoML techniques.","We study the impact of hyperparameter optimization (HPO) to maximize DSNN performance while minimizing resource consumption.","Since this combines multi-objective (MO) optimization with accuracy and energy consumption as potentially complementary objectives, we propose to combine state-of-the-art multi-fidelity (MF) HPO with multi-objective optimization.","Experimental results demonstrate the effectiveness of our approach, resulting in models with over 80\\% in accuracy and low computational cost.","Overall, our method accelerates efficient model development while enabling sustainable AI applications."],"url":"http://arxiv.org/abs/2404.01965v1","category":"cs.LG"}
{"created":"2024-04-02 13:48:49","title":"HyperCLOVA X Technical Report","abstract":"We introduce HyperCLOVA X, a family of large language models (LLMs) tailored to the Korean language and culture, along with competitive capabilities in English, math, and coding. HyperCLOVA X was trained on a balanced mix of Korean, English, and code data, followed by instruction-tuning with high-quality human-annotated datasets while abiding by strict safety guidelines reflecting our commitment to responsible AI. The model is evaluated across various benchmarks, including comprehensive reasoning, knowledge, commonsense, factuality, coding, math, chatting, instruction-following, and harmlessness, in both Korean and English. HyperCLOVA X exhibits strong reasoning capabilities in Korean backed by a deep understanding of the language and cultural nuances. Further analysis of the inherent bilingual nature and its extension to multilingualism highlights the model's cross-lingual proficiency and strong generalization ability to untargeted languages, including machine translation between several language pairs and cross-lingual inference tasks. We believe that HyperCLOVA X can provide helpful guidance for regions or countries in developing their sovereign LLMs.","sentences":["We introduce HyperCLOVA X, a family of large language models (LLMs) tailored to the Korean language and culture, along with competitive capabilities in English, math, and coding.","HyperCLOVA X was trained on a balanced mix of Korean, English, and code data, followed by instruction-tuning with high-quality human-annotated datasets while abiding by strict safety guidelines reflecting our commitment to responsible AI.","The model is evaluated across various benchmarks, including comprehensive reasoning, knowledge, commonsense, factuality, coding, math, chatting, instruction-following, and harmlessness, in both Korean and English.","HyperCLOVA","X exhibits strong reasoning capabilities in Korean backed by a deep understanding of the language and cultural nuances.","Further analysis of the inherent bilingual nature and its extension to multilingualism highlights the model's cross-lingual proficiency and strong generalization ability to untargeted languages, including machine translation between several language pairs and cross-lingual inference tasks.","We believe that HyperCLOVA X can provide helpful guidance for regions or countries in developing their sovereign LLMs."],"url":"http://arxiv.org/abs/2404.01954v1","category":"cs.CL"}
{"created":"2024-04-02 13:38:08","title":"Simulation and time series analysis of responsive active Brownian particles (rABPs) with memory","abstract":"To realise the goals of active matter at the micro- and nano-scale, the next generation of microrobots must be capable of autonomously sensing and responding to their environment to carry out pre-programmed tasks. Memory effects are proposed to have a significant effect on the dynamics of responsive robotic systems, drawing parallels to strategies used in nature across all length-scales. Inspired by the integral feedback control mechanism by which E.coli are proposed to sense their environment, we develop a numerical responsive active Brownian particle (rABP) model in which the rABPs continuously react to changes in the physical parameters dictated by their local environment. The resulting generated time series are then used to classify and characterise their response, leading to the identification of conditional heteroscedasticity in their physics. We then train recurrent neural networks (RNNs) capable of quantitatively describing the responsiveness of rABPs using their 2-D trajectories. We believe that our proposed strategy to determine the parameters governing the dynamics of rABPs can be applied to guide the design of microrobots with physical intelligence encoded during their fabrication.","sentences":["To realise the goals of active matter at the micro- and nano-scale, the next generation of microrobots must be capable of autonomously sensing and responding to their environment to carry out pre-programmed tasks.","Memory effects are proposed to have a significant effect on the dynamics of responsive robotic systems, drawing parallels to strategies used in nature across all length-scales.","Inspired by the integral feedback control mechanism by which E.coli are proposed to sense their environment, we develop a numerical responsive active Brownian particle (rABP) model in which the rABPs continuously react to changes in the physical parameters dictated by their local environment.","The resulting generated time series are then used to classify and characterise their response, leading to the identification of conditional heteroscedasticity in their physics.","We then train recurrent neural networks (RNNs) capable of quantitatively describing the responsiveness of rABPs using their 2-D trajectories.","We believe that our proposed strategy to determine the parameters governing the dynamics of rABPs can be applied to guide the design of microrobots with physical intelligence encoded during their fabrication."],"url":"http://arxiv.org/abs/2404.01944v1","category":"cond-mat.soft"}
{"created":"2024-04-02 13:33:23","title":"Towards Better Understanding of Cybercrime: The Role of Fine-Tuned LLMs in Translation","abstract":"Understanding cybercrime communications is paramount for cybersecurity defence. This often involves translating communications into English for processing, interpreting, and generating timely intelligence. The problem is that translation is hard. Human translation is slow, expensive, and scarce. Machine translation is inaccurate and biased. We propose using fine-tuned Large Language Models (LLM) to generate translations that can accurately capture the nuances of cybercrime language. We apply our technique to public chats from the NoName057(16) Russian-speaking hacktivist group. Our results show that our fine-tuned LLM model is better, faster, more accurate, and able to capture nuances of the language. Our method shows it is possible to achieve high-fidelity translations and significantly reduce costs by a factor ranging from 430 to 23,000 compared to a human translator.","sentences":["Understanding cybercrime communications is paramount for cybersecurity defence.","This often involves translating communications into English for processing, interpreting, and generating timely intelligence.","The problem is that translation is hard.","Human translation is slow, expensive, and scarce.","Machine translation is inaccurate and biased.","We propose using fine-tuned Large Language Models (LLM) to generate translations that can accurately capture the nuances of cybercrime language.","We apply our technique to public chats from the NoName057(16) Russian-speaking hacktivist group.","Our results show that our fine-tuned LLM model is better, faster, more accurate, and able to capture nuances of the language.","Our method shows it is possible to achieve high-fidelity translations and significantly reduce costs by a factor ranging from 430 to 23,000 compared to a human translator."],"url":"http://arxiv.org/abs/2404.01940v1","category":"cs.CL"}
{"created":"2024-04-02 13:29:38","title":"Towards a Completeness Argumentation for Scenario Concepts","abstract":"Scenario-based testing has become a promising approach to overcome the complexity of real-world traffic for safety assurance of automated vehicles. Within scenario-based testing, a system under test is confronted with a set of predefined scenarios. This set shall ensure more efficient testing of an automated vehicle operating in an open context compared to real-world testing. However, the question arises if a scenario catalog can cover the open context sufficiently to allow an argumentation for sufficiently safe driving functions and how this can be proven. Within this paper, a methodology is proposed to argue a sufficient completeness of a scenario concept using a goal structured notation. Thereby, the distinction between completeness and coverage is discussed. For both, methods are proposed for a streamlined argumentation and regarding evidence. These methods are applied to a scenario concept and the inD dataset to prove the usability.","sentences":["Scenario-based testing has become a promising approach to overcome the complexity of real-world traffic for safety assurance of automated vehicles.","Within scenario-based testing, a system under test is confronted with a set of predefined scenarios.","This set shall ensure more efficient testing of an automated vehicle operating in an open context compared to real-world testing.","However, the question arises if a scenario catalog can cover the open context sufficiently to allow an argumentation for sufficiently safe driving functions and how this can be proven.","Within this paper, a methodology is proposed to argue a sufficient completeness of a scenario concept using a goal structured notation.","Thereby, the distinction between completeness and coverage is discussed.","For both, methods are proposed for a streamlined argumentation and regarding evidence.","These methods are applied to a scenario concept and the inD dataset to prove the usability."],"url":"http://arxiv.org/abs/2404.01934v1","category":"cs.SE"}
{"created":"2024-04-02 13:22:19","title":"First Light Curve Analysis of NSVS 8294044, V1023 Her, and V1397 Her Contact Binary Systems","abstract":"The first photometric light curve investigation of the NSVS 8294044, V1023 Her, and V1397 Her binary systems is presented. We used ground-based observations for the NSVS 8294044 system and Transiting Exoplanet Survey Satellite (TESS) data for V1023 Her and V1397 Her. The primary and secondary times of minima were extracted from all the data, and by collecting the literature, a new ephemeris was computed for each system. Linear fits for the O-C diagrams were conducted using the Markov chain Monte Carlo (MCMC) method. Light curve solutions were performed using the PHysics Of Eclipsing BinariEs (PHOEBE) Python code and the MCMC approach. The systems were found to be contact binary stars based on the fillout factor and mass ratio. V1023 Her showed the O'Connell effect, and a cold starspot on the secondary component was required for the light curve solution. The absolute parameters of the system were estimated based on an empirical relationship between orbital period and mass. We presented a new T-M equation based on a sample of 428 contact binary systems and found that our three target systems were in good agreement with the fit. The positions of the systems were also depicted on the M-L, M-R, q-L_{ratio}, and M_{tot}-J_0 diagrams in the logarithmic scales.","sentences":["The first photometric light curve investigation of the NSVS 8294044, V1023 Her, and V1397 Her binary systems is presented.","We used ground-based observations for the NSVS 8294044 system and Transiting Exoplanet Survey Satellite (TESS) data for V1023 Her and V1397 Her.","The primary and secondary times of minima were extracted from all the data, and by collecting the literature, a new ephemeris was computed for each system.","Linear fits for the O-C diagrams were conducted using the Markov chain Monte Carlo (MCMC) method.","Light curve solutions were performed using the PHysics Of Eclipsing BinariEs (PHOEBE)","Python code and the MCMC approach.","The systems were found to be contact binary stars based on the fillout factor and mass ratio.","V1023","Her showed the O'Connell effect, and a cold starspot on the secondary component was required for the light curve solution.","The absolute parameters of the system were estimated based on an empirical relationship between orbital period and mass.","We presented a new T-M equation based on a sample of 428 contact binary systems and found that our three target systems were in good agreement with the fit.","The positions of the systems were also depicted on the M-L, M-R, q-L_{ratio}, and M_{tot}-J_0 diagrams in the logarithmic scales."],"url":"http://arxiv.org/abs/2404.01928v1","category":"astro-ph.SR"}
{"created":"2024-04-02 13:19:45","title":"Improving Bird's Eye View Semantic Segmentation by Task Decomposition","abstract":"Semantic segmentation in bird's eye view (BEV) plays a crucial role in autonomous driving. Previous methods usually follow an end-to-end pipeline, directly predicting the BEV segmentation map from monocular RGB inputs. However, the challenge arises when the RGB inputs and BEV targets from distinct perspectives, making the direct point-to-point predicting hard to optimize. In this paper, we decompose the original BEV segmentation task into two stages, namely BEV map reconstruction and RGB-BEV feature alignment. In the first stage, we train a BEV autoencoder to reconstruct the BEV segmentation maps given corrupted noisy latent representation, which urges the decoder to learn fundamental knowledge of typical BEV patterns. The second stage involves mapping RGB input images into the BEV latent space of the first stage, directly optimizing the correlations between the two views at the feature level. Our approach simplifies the complexity of combining perception and generation into distinct steps, equipping the model to handle intricate and challenging scenes effectively. Besides, we propose to transform the BEV segmentation map from the Cartesian to the polar coordinate system to establish the column-wise correspondence between RGB images and BEV maps. Moreover, our method requires neither multi-scale features nor camera intrinsic parameters for depth estimation and saves computational overhead. Extensive experiments on nuScenes and Argoverse show the effectiveness and efficiency of our method. Code is available at https://github.com/happytianhao/TaDe.","sentences":["Semantic segmentation in bird's eye view (BEV) plays a crucial role in autonomous driving.","Previous methods usually follow an end-to-end pipeline, directly predicting the BEV segmentation map from monocular RGB inputs.","However, the challenge arises when the RGB inputs and BEV targets from distinct perspectives, making the direct point-to-point predicting hard to optimize.","In this paper, we decompose the original BEV segmentation task into two stages, namely BEV map reconstruction and RGB-BEV feature alignment.","In the first stage, we train a BEV autoencoder to reconstruct the BEV segmentation maps given corrupted noisy latent representation, which urges the decoder to learn fundamental knowledge of typical BEV patterns.","The second stage involves mapping RGB input images into the BEV latent space of the first stage, directly optimizing the correlations between the two views at the feature level.","Our approach simplifies the complexity of combining perception and generation into distinct steps, equipping the model to handle intricate and challenging scenes effectively.","Besides, we propose to transform the BEV segmentation map from the Cartesian to the polar coordinate system to establish the column-wise correspondence between RGB images and BEV maps.","Moreover, our method requires neither multi-scale features nor camera intrinsic parameters for depth estimation and saves computational overhead.","Extensive experiments on nuScenes and Argoverse show the effectiveness and efficiency of our method.","Code is available at https://github.com/happytianhao/TaDe."],"url":"http://arxiv.org/abs/2404.01925v1","category":"cs.CV"}
{"created":"2024-04-02 13:19:06","title":"Toward Efficient Visual Gyroscopes: Spherical Moments, Harmonics Filtering, and Masking Techniques for Spherical Camera Applications","abstract":"Unlike a traditional gyroscope, a visual gyroscope estimates camera rotation through images. The integration of omnidirectional cameras, offering a larger field of view compared to traditional RGB cameras, has proven to yield more accurate and robust results. However, challenges arise in situations that lack features, have substantial noise causing significant errors, and where certain features in the images lack sufficient strength, leading to less precise prediction results.   Here, we address these challenges by introducing a novel visual gyroscope, which combines an analytical method with a neural network approach to provide a more efficient and accurate rotation estimation from spherical images. The presented method relies on three key contributions: an adapted analytical approach to compute the spherical moments coefficients, introduction of masks for better global feature representation, and the use of a multilayer perceptron to adaptively choose the best combination of masks and filters. Experimental results demonstrate superior performance of the proposed approach in terms of accuracy. The paper emphasizes the advantages of integrating machine learning to optimize analytical solutions, discusses limitations, and suggests directions for future research.","sentences":["Unlike a traditional gyroscope, a visual gyroscope estimates camera rotation through images.","The integration of omnidirectional cameras, offering a larger field of view compared to traditional RGB cameras, has proven to yield more accurate and robust results.","However, challenges arise in situations that lack features, have substantial noise causing significant errors, and where certain features in the images lack sufficient strength, leading to less precise prediction results.   ","Here, we address these challenges by introducing a novel visual gyroscope, which combines an analytical method with a neural network approach to provide a more efficient and accurate rotation estimation from spherical images.","The presented method relies on three key contributions: an adapted analytical approach to compute the spherical moments coefficients, introduction of masks for better global feature representation, and the use of a multilayer perceptron to adaptively choose the best combination of masks and filters.","Experimental results demonstrate superior performance of the proposed approach in terms of accuracy.","The paper emphasizes the advantages of integrating machine learning to optimize analytical solutions, discusses limitations, and suggests directions for future research."],"url":"http://arxiv.org/abs/2404.01924v1","category":"cs.CV"}
{"created":"2024-04-02 13:17:36","title":"SGSH: Stimulate Large Language Models with Skeleton Heuristics for Knowledge Base Question Generation","abstract":"Knowledge base question generation (KBQG) aims to generate natural language questions from a set of triplet facts extracted from KB. Existing methods have significantly boosted the performance of KBQG via pre-trained language models (PLMs) thanks to the richly endowed semantic knowledge. With the advance of pre-training techniques, large language models (LLMs) (e.g., GPT-3.5) undoubtedly possess much more semantic knowledge. Therefore, how to effectively organize and exploit the abundant knowledge for KBQG becomes the focus of our study. In this work, we propose SGSH--a simple and effective framework to Stimulate GPT-3.5 with Skeleton Heuristics to enhance KBQG. The framework incorporates \"skeleton heuristics\", which provides more fine-grained guidance associated with each input to stimulate LLMs to generate optimal questions, encompassing essential elements like the question phrase and the auxiliary verb.More specifically, we devise an automatic data construction strategy leveraging ChatGPT to construct a skeleton training dataset, based on which we employ a soft prompting approach to train a BART model dedicated to generating the skeleton associated with each input. Subsequently, skeleton heuristics are encoded into the prompt to incentivize GPT-3.5 to generate desired questions. Extensive experiments demonstrate that SGSH derives the new state-of-the-art performance on the KBQG tasks.","sentences":["Knowledge base question generation (KBQG) aims to generate natural language questions from a set of triplet facts extracted from KB.","Existing methods have significantly boosted the performance of KBQG via pre-trained language models (PLMs) thanks to the richly endowed semantic knowledge.","With the advance of pre-training techniques, large language models (LLMs) (e.g., GPT-3.5) undoubtedly possess much more semantic knowledge.","Therefore, how to effectively organize and exploit the abundant knowledge for KBQG becomes the focus of our study.","In this work, we propose SGSH--a simple and effective framework to Stimulate GPT-3.5 with Skeleton Heuristics to enhance KBQG.","The framework incorporates \"skeleton heuristics\", which provides more fine-grained guidance associated with each input to stimulate LLMs to generate optimal questions, encompassing essential elements like the question phrase and the auxiliary verb.","More specifically, we devise an automatic data construction strategy leveraging ChatGPT to construct a skeleton training dataset, based on which we employ a soft prompting approach to train a BART model dedicated to generating the skeleton associated with each input.","Subsequently, skeleton heuristics are encoded into the prompt to incentivize GPT-3.5 to generate desired questions.","Extensive experiments demonstrate that SGSH derives the new state-of-the-art performance on the KBQG tasks."],"url":"http://arxiv.org/abs/2404.01923v1","category":"cs.CL"}
{"created":"2024-04-02 13:05:41","title":"SCANNER: Knowledge-Enhanced Approach for Robust Multi-modal Named Entity Recognition of Unseen Entities","abstract":"Recent advances in named entity recognition (NER) have pushed the boundary of the task to incorporate visual signals, leading to many variants, including multi-modal NER (MNER) or grounded MNER (GMNER). A key challenge to these tasks is that the model should be able to generalize to the entities unseen during the training, and should be able to handle the training samples with noisy annotations. To address this obstacle, we propose SCANNER (Span CANdidate detection and recognition for NER), a model capable of effectively handling all three NER variants. SCANNER is a two-stage structure; we extract entity candidates in the first stage and use it as a query to get knowledge, effectively pulling knowledge from various sources. We can boost our performance by utilizing this entity-centric extracted knowledge to address unseen entities. Furthermore, to tackle the challenges arising from noisy annotations in NER datasets, we introduce a novel self-distillation method, enhancing the robustness and accuracy of our model in processing training data with inherent uncertainties. Our approach demonstrates competitive performance on the NER benchmark and surpasses existing methods on both MNER and GMNER benchmarks. Further analysis shows that the proposed distillation and knowledge utilization methods improve the performance of our model on various benchmarks.","sentences":["Recent advances in named entity recognition (NER) have pushed the boundary of the task to incorporate visual signals, leading to many variants, including multi-modal NER (MNER) or grounded MNER (GMNER).","A key challenge to these tasks is that the model should be able to generalize to the entities unseen during the training, and should be able to handle the training samples with noisy annotations.","To address this obstacle, we propose SCANNER (Span CANdidate detection and recognition for NER), a model capable of effectively handling all three NER variants.","SCANNER is a two-stage structure; we extract entity candidates in the first stage and use it as a query to get knowledge, effectively pulling knowledge from various sources.","We can boost our performance by utilizing this entity-centric extracted knowledge to address unseen entities.","Furthermore, to tackle the challenges arising from noisy annotations in NER datasets, we introduce a novel self-distillation method, enhancing the robustness and accuracy of our model in processing training data with inherent uncertainties.","Our approach demonstrates competitive performance on the NER benchmark and surpasses existing methods on both MNER and GMNER benchmarks.","Further analysis shows that the proposed distillation and knowledge utilization methods improve the performance of our model on various benchmarks."],"url":"http://arxiv.org/abs/2404.01914v1","category":"cs.CL"}
{"created":"2024-04-02 12:55:56","title":"A Temporal Graph Model to Study the Dynamics of Collective Behavior and Performance in Team Sports: An Application to Basketball","abstract":"In this study, a temporal graph model is designed to model the behavior of collective sports teams based on the networks of player interactions. The main motivation for the model is to integrate the temporal dimension into the analysis of players' passing networks in order to gain deeper insights into the dynamics of system behavior, particularly how a system exploits the degeneracy property to self-regulate. First, the temporal graph model and the entropy measures used to assess the complexity of the dynamics of the network structure are introduced and illustrated. Second, an experiment using basketball data is conducted to investigate the relationship between the complexity level and team performance. This is accomplished by examining the correlations between the entropy measures in a team's behavior and the team's final performance, as well as the link between the relative score compared to that of the opponent and the entropy in the team's behavior. Results indicate positive correlations between entropy measures and final team performance, and threshold values of relative score associated with changes in team behavior -- thereby revealing common and unique team signatures. From a complexity science perspective, the model proves useful for identifying key performance factors in team sports and for studying the effects of given constraints on the exploitation of degeneracy to organize team behavior through various network structures. Future research can easily extend the model and apply it to other types of social networks.","sentences":["In this study, a temporal graph model is designed to model the behavior of collective sports teams based on the networks of player interactions.","The main motivation for the model is to integrate the temporal dimension into the analysis of players' passing networks in order to gain deeper insights into the dynamics of system behavior, particularly how a system exploits the degeneracy property to self-regulate.","First, the temporal graph model and the entropy measures used to assess the complexity of the dynamics of the network structure are introduced and illustrated.","Second, an experiment using basketball data is conducted to investigate the relationship between the complexity level and team performance.","This is accomplished by examining the correlations between the entropy measures in a team's behavior and the team's final performance, as well as the link between the relative score compared to that of the opponent and the entropy in the team's behavior.","Results indicate positive correlations between entropy measures and final team performance, and threshold values of relative score associated with changes in team behavior -- thereby revealing common and unique team signatures.","From a complexity science perspective, the model proves useful for identifying key performance factors in team sports and for studying the effects of given constraints on the exploitation of degeneracy to organize team behavior through various network structures.","Future research can easily extend the model and apply it to other types of social networks."],"url":"http://arxiv.org/abs/2404.01909v1","category":"cs.DM"}
{"created":"2024-04-02 12:36:40","title":"Continuous Spiking Graph Neural Networks","abstract":"Continuous graph neural networks (CGNNs) have garnered significant attention due to their ability to generalize existing discrete graph neural networks (GNNs) by introducing continuous dynamics. They typically draw inspiration from diffusion-based methods to introduce a novel propagation scheme, which is analyzed using ordinary differential equations (ODE). However, the implementation of CGNNs requires significant computational power, making them challenging to deploy on battery-powered devices. Inspired by recent spiking neural networks (SNNs), which emulate a biological inference process and provide an energy-efficient neural architecture, we incorporate the SNNs with CGNNs in a unified framework, named Continuous Spiking Graph Neural Networks (COS-GNN). We employ SNNs for graph node representation at each time step, which are further integrated into the ODE process along with time. To enhance information preservation and mitigate information loss in SNNs, we introduce the high-order structure of COS-GNN, which utilizes the second-order ODE for spiking representation and continuous propagation. Moreover, we provide the theoretical proof that COS-GNN effectively mitigates the issues of exploding and vanishing gradients, enabling us to capture long-range dependencies between nodes. Experimental results on graph-based learning tasks demonstrate the effectiveness of the proposed COS-GNN over competitive baselines.","sentences":["Continuous graph neural networks (CGNNs) have garnered significant attention due to their ability to generalize existing discrete graph neural networks (GNNs) by introducing continuous dynamics.","They typically draw inspiration from diffusion-based methods to introduce a novel propagation scheme, which is analyzed using ordinary differential equations (ODE).","However, the implementation of CGNNs requires significant computational power, making them challenging to deploy on battery-powered devices.","Inspired by recent spiking neural networks (SNNs), which emulate a biological inference process and provide an energy-efficient neural architecture, we incorporate the SNNs with CGNNs in a unified framework, named Continuous Spiking Graph Neural Networks (COS-GNN).","We employ SNNs for graph node representation at each time step, which are further integrated into the ODE process along with time.","To enhance information preservation and mitigate information loss in SNNs, we introduce the high-order structure of COS-GNN, which utilizes the second-order ODE for spiking representation and continuous propagation.","Moreover, we provide the theoretical proof that COS-GNN effectively mitigates the issues of exploding and vanishing gradients, enabling us to capture long-range dependencies between nodes.","Experimental results on graph-based learning tasks demonstrate the effectiveness of the proposed COS-GNN over competitive baselines."],"url":"http://arxiv.org/abs/2404.01897v1","category":"cs.NE"}
{"created":"2024-04-02 12:28:40","title":"RAVE: Residual Vector Embedding for CLIP-Guided Backlit Image Enhancement","abstract":"In this paper we propose a novel modification of Contrastive Language-Image Pre-Training (CLIP) guidance for the task of unsupervised backlit image enhancement. Our work builds on the state-of-the-art CLIP-LIT approach, which learns a prompt pair by constraining the text-image similarity between a prompt (negative/positive sample) and a corresponding image (backlit image/well-lit image) in the CLIP embedding space. Learned prompts then guide an image enhancement network. Based on the CLIP-LIT framework, we propose two novel methods for CLIP guidance. First, we show that instead of tuning prompts in the space of text embeddings, it is possible to directly tune their embeddings in the latent space without any loss in quality. This accelerates training and potentially enables the use of additional encoders that do not have a text encoder. Second, we propose a novel approach that does not require any prompt tuning. Instead, based on CLIP embeddings of backlit and well-lit images from training data, we compute the residual vector in the embedding space as a simple difference between the mean embeddings of the well-lit and backlit images. This vector then guides the enhancement network during training, pushing a backlit image towards the space of well-lit images. This approach further dramatically reduces training time, stabilizes training and produces high quality enhanced images without artifacts, both in supervised and unsupervised training regimes. Additionally, we show that residual vectors can be interpreted, revealing biases in training data, and thereby enabling potential bias correction.","sentences":["In this paper we propose a novel modification of Contrastive Language-Image Pre-Training (CLIP) guidance for the task of unsupervised backlit image enhancement.","Our work builds on the state-of-the-art CLIP-LIT approach, which learns a prompt pair by constraining the text-image similarity between a prompt (negative/positive sample) and a corresponding image (backlit image/well-lit image) in the CLIP embedding space.","Learned prompts then guide an image enhancement network.","Based on the CLIP-LIT framework, we propose two novel methods for CLIP guidance.","First, we show that instead of tuning prompts in the space of text embeddings, it is possible to directly tune their embeddings in the latent space without any loss in quality.","This accelerates training and potentially enables the use of additional encoders that do not have a text encoder.","Second, we propose a novel approach that does not require any prompt tuning.","Instead, based on CLIP embeddings of backlit and well-lit images from training data, we compute the residual vector in the embedding space as a simple difference between the mean embeddings of the well-lit and backlit images.","This vector then guides the enhancement network during training, pushing a backlit image towards the space of well-lit images.","This approach further dramatically reduces training time, stabilizes training and produces high quality enhanced images without artifacts, both in supervised and unsupervised training regimes.","Additionally, we show that residual vectors can be interpreted, revealing biases in training data, and thereby enabling potential bias correction."],"url":"http://arxiv.org/abs/2404.01889v2","category":"cs.CV"}
{"created":"2024-04-02 12:05:02","title":"Procedural Fairness in Machine Learning","abstract":"Fairness in machine learning (ML) has received much attention. However, existing studies have mainly focused on the distributive fairness of ML models. The other dimension of fairness, i.e., procedural fairness, has been neglected. In this paper, we first define the procedural fairness of ML models, and then give formal definitions of individual and group procedural fairness. We propose a novel metric to evaluate the group procedural fairness of ML models, called $GPF_{FAE}$, which utilizes a widely used explainable artificial intelligence technique, namely feature attribution explanation (FAE), to capture the decision process of the ML models. We validate the effectiveness of $GPF_{FAE}$ on a synthetic dataset and eight real-world datasets. Our experiments reveal the relationship between procedural and distributive fairness of the ML model. Based on our analysis, we propose a method for identifying the features that lead to the procedural unfairness of the model and propose two methods to improve procedural fairness after identifying unfair features. Our experimental results demonstrate that we can accurately identify the features that lead to procedural unfairness in the ML model, and both of our proposed methods can significantly improve procedural fairness with a slight impact on model performance, while also improving distributive fairness.","sentences":["Fairness in machine learning (ML) has received much attention.","However, existing studies have mainly focused on the distributive fairness of ML models.","The other dimension of fairness, i.e., procedural fairness, has been neglected.","In this paper, we first define the procedural fairness of ML models, and then give formal definitions of individual and group procedural fairness.","We propose a novel metric to evaluate the group procedural fairness of ML models, called $GPF_{FAE}$, which utilizes a widely used explainable artificial intelligence technique, namely feature attribution explanation (FAE), to capture the decision process of the ML models.","We validate the effectiveness of $GPF_{FAE}$ on a synthetic dataset and eight real-world datasets.","Our experiments reveal the relationship between procedural and distributive fairness of the ML model.","Based on our analysis, we propose a method for identifying the features that lead to the procedural unfairness of the model and propose two methods to improve procedural fairness after identifying unfair features.","Our experimental results demonstrate that we can accurately identify the features that lead to procedural unfairness in the ML model, and both of our proposed methods can significantly improve procedural fairness with a slight impact on model performance, while also improving distributive fairness."],"url":"http://arxiv.org/abs/2404.01877v1","category":"cs.LG"}
{"created":"2024-04-02 11:46:31","title":"Beyond Accuracy: Evaluating the Reasoning Behavior of Large Language Models -- A Survey","abstract":"Large language models (LLMs) have recently shown impressive performance on tasks involving reasoning, leading to a lively debate on whether these models possess reasoning capabilities similar to humans. However, despite these successes, the depth of LLMs' reasoning abilities remains uncertain. This uncertainty partly stems from the predominant focus on task performance, measured through shallow accuracy metrics, rather than a thorough investigation of the models' reasoning behavior. This paper seeks to address this gap by providing a comprehensive review of studies that go beyond task accuracy, offering deeper insights into the models' reasoning processes. Furthermore, we survey prevalent methodologies to evaluate the reasoning behavior of LLMs, emphasizing current trends and efforts towards more nuanced reasoning analyses. Our review suggests that LLMs tend to rely on surface-level patterns and correlations in their training data, rather than on genuine reasoning abilities. Additionally, we identify the need for further research that delineates the key differences between human and LLM-based reasoning. Through this survey, we aim to shed light on the complex reasoning processes within LLMs.","sentences":["Large language models (LLMs) have recently shown impressive performance on tasks involving reasoning, leading to a lively debate on whether these models possess reasoning capabilities similar to humans.","However, despite these successes, the depth of LLMs' reasoning abilities remains uncertain.","This uncertainty partly stems from the predominant focus on task performance, measured through shallow accuracy metrics, rather than a thorough investigation of the models' reasoning behavior.","This paper seeks to address this gap by providing a comprehensive review of studies that go beyond task accuracy, offering deeper insights into the models' reasoning processes.","Furthermore, we survey prevalent methodologies to evaluate the reasoning behavior of LLMs, emphasizing current trends and efforts towards more nuanced reasoning analyses.","Our review suggests that LLMs tend to rely on surface-level patterns and correlations in their training data, rather than on genuine reasoning abilities.","Additionally, we identify the need for further research that delineates the key differences between human and LLM-based reasoning.","Through this survey, we aim to shed light on the complex reasoning processes within LLMs."],"url":"http://arxiv.org/abs/2404.01869v1","category":"cs.CL"}
{"created":"2024-04-02 11:40:38","title":"Confidence-aware Reward Optimization for Fine-tuning Text-to-Image Models","abstract":"Fine-tuning text-to-image models with reward functions trained on human feedback data has proven effective for aligning model behavior with human intent. However, excessive optimization with such reward models, which serve as mere proxy objectives, can compromise the performance of fine-tuned models, a phenomenon known as reward overoptimization. To investigate this issue in depth, we introduce the Text-Image Alignment Assessment (TIA2) benchmark, which comprises a diverse collection of text prompts, images, and human annotations. Our evaluation of several state-of-the-art reward models on this benchmark reveals their frequent misalignment with human assessment. We empirically demonstrate that overoptimization occurs notably when a poorly aligned reward model is used as the fine-tuning objective. To address this, we propose TextNorm, a simple method that enhances alignment based on a measure of reward model confidence estimated across a set of semantically contrastive text prompts. We demonstrate that incorporating the confidence-calibrated rewards in fine-tuning effectively reduces overoptimization, resulting in twice as many wins in human evaluation for text-image alignment compared against the baseline reward models.","sentences":["Fine-tuning text-to-image models with reward functions trained on human feedback data has proven effective for aligning model behavior with human intent.","However, excessive optimization with such reward models, which serve as mere proxy objectives, can compromise the performance of fine-tuned models, a phenomenon known as reward overoptimization.","To investigate this issue in depth, we introduce the Text-Image Alignment Assessment (TIA2) benchmark, which comprises a diverse collection of text prompts, images, and human annotations.","Our evaluation of several state-of-the-art reward models on this benchmark reveals their frequent misalignment with human assessment.","We empirically demonstrate that overoptimization occurs notably when a poorly aligned reward model is used as the fine-tuning objective.","To address this, we propose TextNorm, a simple method that enhances alignment based on a measure of reward model confidence estimated across a set of semantically contrastive text prompts.","We demonstrate that incorporating the confidence-calibrated rewards in fine-tuning effectively reduces overoptimization, resulting in twice as many wins in human evaluation for text-image alignment compared against the baseline reward models."],"url":"http://arxiv.org/abs/2404.01863v1","category":"cs.LG"}
{"created":"2024-04-02 11:33:04","title":"Where to Move Next: Zero-shot Generalization of LLMs for Next POI Recommendation","abstract":"Next Point-of-interest (POI) recommendation provides valuable suggestions for users to explore their surrounding environment. Existing studies rely on building recommendation models from large-scale users' check-in data, which is task-specific and needs extensive computational resources. Recently, the pretrained large language models (LLMs) have achieved significant advancements in various NLP tasks and have also been investigated for recommendation scenarios. However, the generalization abilities of LLMs still are unexplored to address the next POI recommendations, where users' geographical movement patterns should be extracted. Although there are studies that leverage LLMs for next-item recommendations, they fail to consider the geographical influence and sequential transitions. Hence, they cannot effectively solve the next POI recommendation task. To this end, we design novel prompting strategies and conduct empirical studies to assess the capability of LLMs, e.g., ChatGPT, for predicting a user's next check-in. Specifically, we consider several essential factors in human movement behaviors, including user geographical preference, spatial distance, and sequential transitions, and formulate the recommendation task as a ranking problem. Through extensive experiments on two widely used real-world datasets, we derive several key findings. Empirical evaluations demonstrate that LLMs have promising zero-shot recommendation abilities and can provide accurate and reasonable predictions. We also reveal that LLMs cannot accurately comprehend geographical context information and are sensitive to the order of presentation of candidate POIs, which shows the limitations of LLMs and necessitates further research on robust human mobility reasoning mechanisms.","sentences":["Next Point-of-interest (POI) recommendation provides valuable suggestions for users to explore their surrounding environment.","Existing studies rely on building recommendation models from large-scale users' check-in data, which is task-specific and needs extensive computational resources.","Recently, the pretrained large language models (LLMs) have achieved significant advancements in various NLP tasks and have also been investigated for recommendation scenarios.","However, the generalization abilities of LLMs still are unexplored to address the next POI recommendations, where users' geographical movement patterns should be extracted.","Although there are studies that leverage LLMs for next-item recommendations, they fail to consider the geographical influence and sequential transitions.","Hence, they cannot effectively solve the next POI recommendation task.","To this end, we design novel prompting strategies and conduct empirical studies to assess the capability of LLMs, e.g., ChatGPT, for predicting a user's next check-in.","Specifically, we consider several essential factors in human movement behaviors, including user geographical preference, spatial distance, and sequential transitions, and formulate the recommendation task as a ranking problem.","Through extensive experiments on two widely used real-world datasets, we derive several key findings.","Empirical evaluations demonstrate that LLMs have promising zero-shot recommendation abilities and can provide accurate and reasonable predictions.","We also reveal that LLMs cannot accurately comprehend geographical context information and are sensitive to the order of presentation of candidate POIs, which shows the limitations of LLMs and necessitates further research on robust human mobility reasoning mechanisms."],"url":"http://arxiv.org/abs/2404.01855v1","category":"cs.IR"}
{"created":"2024-04-02 11:27:54","title":"The orbital parameters of the del Cep inner binary system determined using 2019 HARPS-N spectroscopic data","abstract":"An inner companion has recently been discovered orbiting the prototype of classical Cepheids, delta Cep, whose orbital parameters are still not fully constrained. We collected new precise radial velocity measurements of delta Cep in 2019 using the HARPS-N spectrograph mounted at the Telescopio Nazionale Galileo. Using these radial velocity measurements, we aimed to improve the orbital parameters of the system. We considered a template available in the literature as a reference for the radial velocity curve of the pulsation of the star. We then calculated the residuals between our global dataset (composed of the new 2019 observations plus data from the literature) and the template as a function of the pulsation phase and the barycentric Julian date. This provides the orbital velocity of the Cepheid component. Using a Bayesian tool, we derived the orbital parameters of the system. Considering priors based on already published Gaia constraints, we find for the orbital period a maximum a posteriori probability of Porb=9.32+/-0.03 years (uncertainties correspond to the 95% highest density probability interval), and we obtain an eccentricity e=0.71+/-0.02, a semimajor axis a=0.029 +/-0.003 arcsecond, and a center-of-mass velocity V0=-17.28+/-0.08 km/s, among other parameters. In this short analysis we derive the orbital parameters of the delta Cep inner binary system and provide a cleaned radial velocity curve of the pulsation of the star, which will be used to study its Baade-Wesselink projection factor in a future publication.","sentences":["An inner companion has recently been discovered orbiting the prototype of classical Cepheids, delta Cep, whose orbital parameters are still not fully constrained.","We collected new precise radial velocity measurements of delta Cep in 2019 using the HARPS-N spectrograph mounted at the Telescopio Nazionale Galileo.","Using these radial velocity measurements, we aimed to improve the orbital parameters of the system.","We considered a template available in the literature as a reference for the radial velocity curve of the pulsation of the star.","We then calculated the residuals between our global dataset (composed of the new 2019 observations plus data from the literature) and the template as a function of the pulsation phase and the barycentric Julian date.","This provides the orbital velocity of the Cepheid component.","Using a Bayesian tool, we derived the orbital parameters of the system.","Considering priors based on already published Gaia constraints, we find for the orbital period a maximum a posteriori probability of Porb=9.32+/-0.03 years (uncertainties correspond to the 95% highest density probability interval), and we obtain an eccentricity e=0.71+/-0.02, a semimajor axis a=0.029 +/-0.003 arcsecond, and a center-of-mass velocity V0=-17.28+/-0.08 km/s, among other parameters.","In this short analysis we derive the orbital parameters of the delta Cep inner binary system and provide a cleaned radial velocity curve of the pulsation of the star, which will be used to study its Baade-Wesselink projection factor in a future publication."],"url":"http://arxiv.org/abs/2404.01851v1","category":"astro-ph.SR"}
{"created":"2024-04-02 11:27:30","title":"Intelligent Reflecting Surfaces assisted Laser-based Optical Wireless Communication Networks","abstract":"The increasing demand for wireless networks of higher capacity requires key-enabling technologies. Optical wireless communication (OWC) arises as a complementary technology to radio frequency (RF) systems that can support high aggregate data rates. However, OWC systems face some challenges including beam-blockage. Intelligent reflecting surfaces (IRSs) can offer alternative pathways for the optical signal, ensuring continuous connectivity. In this work, we investigate the potential of using IRS in an indoor OWC network. In particular, we define a system model of indoor OWC that employs IRS in conjunction with angle diversity transmitters (ADT) using vertical-cavity surface-emitting laser (VCSEL) arrays. The VCSEL beam is narrow, directed, and easy to block, however, it can deliver high data rates under eye safety regulations. Simulation results show that the deployment of IRS can significantly improve the achievable data rates of Laser-based OWC systems.","sentences":["The increasing demand for wireless networks of higher capacity requires key-enabling technologies.","Optical wireless communication (OWC) arises as a complementary technology to radio frequency (RF) systems that can support high aggregate data rates.","However, OWC systems face some challenges including beam-blockage.","Intelligent reflecting surfaces (IRSs) can offer alternative pathways for the optical signal, ensuring continuous connectivity.","In this work, we investigate the potential of using IRS in an indoor OWC network.","In particular, we define a system model of indoor OWC that employs IRS in conjunction with angle diversity transmitters (ADT) using vertical-cavity surface-emitting laser (VCSEL) arrays.","The VCSEL beam is narrow, directed, and easy to block, however, it can deliver high data rates under eye safety regulations.","Simulation results show that the deployment of IRS can significantly improve the achievable data rates of Laser-based OWC systems."],"url":"http://arxiv.org/abs/2404.01850v1","category":"eess.SP"}
{"created":"2024-04-02 11:22:53","title":"EV2Gym: A Flexible V2G Simulator for EV Smart Charging Research and Benchmarking","abstract":"As electric vehicle (EV) numbers rise, concerns about the capacity of current charging and power grid infrastructure grow, necessitating the development of smart charging solutions. While many smart charging simulators have been developed in recent years, only a few support the development of Reinforcement Learning (RL) algorithms in the form of a Gym environment, and those that do usually lack depth in modeling Vehicle-to-Grid (V2G) scenarios. To address the aforementioned issues, this paper introduces the EV2Gym, a realistic simulator platform for the development and assessment of small and large-scale smart charging algorithms within a standardized platform. The proposed simulator is populated with comprehensive EV, charging station, power transformer, and EV behavior models validated using real data. EV2Gym has a highly customizable interface empowering users to choose from pre-designed case studies or craft their own customized scenarios to suit their specific requirements. Moreover, it incorporates a diverse array of RL, mathematical programming, and heuristic algorithms to speed up the development and benchmarking of new solutions. By offering a unified and standardized platform, EV2Gym aims to provide researchers and practitioners with a robust environment for advancing and assessing smart charging algorithms.","sentences":["As electric vehicle (EV) numbers rise, concerns about the capacity of current charging and power grid infrastructure grow, necessitating the development of smart charging solutions.","While many smart charging simulators have been developed in recent years, only a few support the development of Reinforcement Learning (RL) algorithms in the form of a Gym environment, and those that do usually lack depth in modeling Vehicle-to-Grid (V2G) scenarios.","To address the aforementioned issues, this paper introduces the EV2Gym, a realistic simulator platform for the development and assessment of small and large-scale smart charging algorithms within a standardized platform.","The proposed simulator is populated with comprehensive EV, charging station, power transformer, and EV behavior models validated using real data.","EV2Gym has a highly customizable interface empowering users to choose from pre-designed case studies or craft their own customized scenarios to suit their specific requirements.","Moreover, it incorporates a diverse array of RL, mathematical programming, and heuristic algorithms to speed up the development and benchmarking of new solutions.","By offering a unified and standardized platform, EV2Gym aims to provide researchers and practitioners with a robust environment for advancing and assessing smart charging algorithms."],"url":"http://arxiv.org/abs/2404.01849v1","category":"cs.SE"}
{"created":"2024-04-02 10:48:36","title":"CARLOS: An Open, Modular, and Scalable Simulation Framework for the Development and Testing of Software for C-ITS","abstract":"Future mobility systems and their components are increasingly defined by their software. The complexity of these cooperative intelligent transport systems (C-ITS) and the everchanging requirements posed at the software require continual software updates. The dynamic nature of the system and the practically innumerable scenarios in which different software components work together necessitate efficient and automated development and testing procedures that use simulations as one core methodology. The availability of such simulation architectures is a common interest among many stakeholders, especially in the field of automated driving. That is why we propose CARLOS - an open, modular, and scalable simulation framework for the development and testing of software in C-ITS that leverages the rich CARLA and ROS ecosystems. We provide core building blocks for this framework and explain how it can be used and extended by the community. Its architecture builds upon modern microservice and DevOps principles such as containerization and continuous integration. In our paper, we motivate the architecture by describing important design principles and showcasing three major use cases - software prototyping, data-driven development, and automated testing. We make CARLOS and example implementations of the three use cases publicly available at github.com/ika-rwthaachen/carlos","sentences":["Future mobility systems and their components are increasingly defined by their software.","The complexity of these cooperative intelligent transport systems (C-ITS) and the everchanging requirements posed at the software require continual software updates.","The dynamic nature of the system and the practically innumerable scenarios in which different software components work together necessitate efficient and automated development and testing procedures that use simulations as one core methodology.","The availability of such simulation architectures is a common interest among many stakeholders, especially in the field of automated driving.","That is why we propose CARLOS - an open, modular, and scalable simulation framework for the development and testing of software in C-ITS that leverages the rich CARLA and ROS ecosystems.","We provide core building blocks for this framework and explain how it can be used and extended by the community.","Its architecture builds upon modern microservice and DevOps principles such as containerization and continuous integration.","In our paper, we motivate the architecture by describing important design principles and showcasing three major use cases - software prototyping, data-driven development, and automated testing.","We make CARLOS and example implementations of the three use cases publicly available at github.com/ika-rwthaachen/carlos"],"url":"http://arxiv.org/abs/2404.01836v1","category":"cs.RO"}
{"created":"2024-04-02 10:45:49","title":"Great, Now Write an Article About That: The Crescendo Multi-Turn LLM Jailbreak Attack","abstract":"Large Language Models (LLMs) have risen significantly in popularity and are increasingly being adopted across multiple applications. These LLMs are heavily aligned to resist engaging in illegal or unethical topics as a means to avoid contributing to responsible AI harms. However, a recent line of attacks, known as \"jailbreaks\", seek to overcome this alignment. Intuitively, jailbreak attacks aim to narrow the gap between what the model can do and what it is willing to do. In this paper, we introduce a novel jailbreak attack called Crescendo. Unlike existing jailbreak methods, Crescendo is a multi-turn jailbreak that interacts with the model in a seemingly benign manner. It begins with a general prompt or question about the task at hand and then gradually escalates the dialogue by referencing the model's replies, progressively leading to a successful jailbreak. We evaluate Crescendo on various public systems, including ChatGPT, Gemini Pro, Gemini-Ultra, LlaMA-2 70b Chat, and Anthropic Chat. Our results demonstrate the strong efficacy of Crescendo, with it achieving high attack success rates across all evaluated models and tasks. Furthermore, we introduce Crescendomation, a tool that automates the Crescendo attack, and our evaluation showcases its effectiveness against state-of-the-art models.","sentences":["Large Language Models (LLMs) have risen significantly in popularity and are increasingly being adopted across multiple applications.","These LLMs are heavily aligned to resist engaging in illegal or unethical topics as a means to avoid contributing to responsible AI harms.","However, a recent line of attacks, known as \"jailbreaks\", seek to overcome this alignment.","Intuitively, jailbreak attacks aim to narrow the gap between what the model can do and what it is willing to do.","In this paper, we introduce a novel jailbreak attack called Crescendo.","Unlike existing jailbreak methods, Crescendo is a multi-turn jailbreak that interacts with the model in a seemingly benign manner.","It begins with a general prompt or question about the task at hand and then gradually escalates the dialogue by referencing the model's replies, progressively leading to a successful jailbreak.","We evaluate Crescendo on various public systems, including ChatGPT, Gemini Pro, Gemini-Ultra, LlaMA-2 70b Chat, and Anthropic Chat.","Our results demonstrate the strong efficacy of Crescendo, with it achieving high attack success rates across all evaluated models and tasks.","Furthermore, we introduce Crescendomation, a tool that automates the Crescendo attack, and our evaluation showcases its effectiveness against state-of-the-art models."],"url":"http://arxiv.org/abs/2404.01833v1","category":"cs.CR"}
{"created":"2024-04-02 10:41:51","title":"Defense without Forgetting: Continual Adversarial Defense with Anisotropic & Isotropic Pseudo Replay","abstract":"Deep neural networks have demonstrated susceptibility to adversarial attacks. Adversarial defense techniques often focus on one-shot setting to maintain robustness against attack. However, new attacks can emerge in sequences in real-world deployment scenarios. As a result, it is crucial for a defense model to constantly adapt to new attacks, but the adaptation process can lead to catastrophic forgetting of previously defended against attacks. In this paper, we discuss for the first time the concept of continual adversarial defense under a sequence of attacks, and propose a lifelong defense baseline called Anisotropic \\& Isotropic Replay (AIR), which offers three advantages: (1) Isotropic replay ensures model consistency in the neighborhood distribution of new data, indirectly aligning the output preference between old and new tasks. (2) Anisotropic replay enables the model to learn a compromise data manifold with fresh mixed semantics for further replay constraints and potential future attacks. (3) A straightforward regularizer mitigates the 'plasticity-stability' trade-off by aligning model output between new and old tasks. Experiment results demonstrate that AIR can approximate or even exceed the empirical performance upper bounds achieved by Joint Training.","sentences":["Deep neural networks have demonstrated susceptibility to adversarial attacks.","Adversarial defense techniques often focus on one-shot setting to maintain robustness against attack.","However, new attacks can emerge in sequences in real-world deployment scenarios.","As a result, it is crucial for a defense model to constantly adapt to new attacks, but the adaptation process can lead to catastrophic forgetting of previously defended against attacks.","In this paper, we discuss for the first time the concept of continual adversarial defense under a sequence of attacks, and propose a lifelong defense baseline called Anisotropic \\& Isotropic Replay (AIR), which offers three advantages: (1) Isotropic replay ensures model consistency in the neighborhood distribution of new data, indirectly aligning the output preference between old and new tasks.","(2) Anisotropic replay enables the model to learn a compromise data manifold with fresh mixed semantics for further replay constraints and potential future attacks.","(3) A straightforward regularizer mitigates the 'plasticity-stability' trade-off by aligning model output between new and old tasks.","Experiment results demonstrate that AIR can approximate or even exceed the empirical performance upper bounds achieved by Joint Training."],"url":"http://arxiv.org/abs/2404.01828v1","category":"cs.LG"}
{"created":"2024-04-02 10:15:06","title":"Uncertainty-aware Active Learning of NeRF-based Object Models for Robot Manipulators using Visual and Re-orientation Actions","abstract":"Manipulating unseen objects is challenging without a 3D representation, as objects generally have occluded surfaces. This requires physical interaction with objects to build their internal representations. This paper presents an approach that enables a robot to rapidly learn the complete 3D model of a given object for manipulation in unfamiliar orientations. We use an ensemble of partially constructed NeRF models to quantify model uncertainty to determine the next action (a visual or re-orientation action) by optimizing informativeness and feasibility. Further, our approach determines when and how to grasp and re-orient an object given its partial NeRF model and re-estimates the object pose to rectify misalignments introduced during the interaction. Experiments with a simulated Franka Emika Robot Manipulator operating in a tabletop environment with benchmark objects demonstrate an improvement of (i) 14% in visual reconstruction quality (PSNR), (ii) 20% in the geometric/depth reconstruction of the object surface (F-score) and (iii) 71% in the task success rate of manipulating objects a-priori unseen orientations/stable configurations in the scene; over current methods. The project page can be found here: https://actnerf.github.io.","sentences":["Manipulating unseen objects is challenging without a 3D representation, as objects generally have occluded surfaces.","This requires physical interaction with objects to build their internal representations.","This paper presents an approach that enables a robot to rapidly learn the complete 3D model of a given object for manipulation in unfamiliar orientations.","We use an ensemble of partially constructed NeRF models to quantify model uncertainty to determine the next action (a visual or re-orientation action) by optimizing informativeness and feasibility.","Further, our approach determines when and how to grasp and re-orient an object given its partial NeRF model and re-estimates the object pose to rectify misalignments introduced during the interaction.","Experiments with a simulated Franka Emika Robot Manipulator operating in a tabletop environment with benchmark objects demonstrate an improvement of (i) 14% in visual reconstruction quality (PSNR), (ii) 20% in the geometric/depth reconstruction of the object surface (F-score) and (iii) 71% in the task success rate of manipulating objects a-priori unseen orientations/stable configurations in the scene; over current methods.","The project page can be found here: https://actnerf.github.io."],"url":"http://arxiv.org/abs/2404.01812v1","category":"cs.RO"}
{"created":"2024-04-02 10:12:37","title":"Spectral Map: Embedding Slow Kinetics in Collective Variables","abstract":"The dynamics of physical systems that require high-dimensional representation can often be captured in a few meaningful degrees of freedom called collective variables (CVs). However, identifying CVs is challenging and constitutes a fundamental problem in physical chemistry. This problem is even more pronounced when CVs information about slow kinetics related to rare transitions between long-lived metastable states. To address this issue, we propose an unsupervised deep-learning method called spectral map. Our method constructs slow CVs by maximizing the spectral gap between slow and fast eigenvalues of a transition matrix estimated by an anisotropic diffusion kernel. We demonstrate our method in several high-dimensional reversible folding processes.","sentences":["The dynamics of physical systems that require high-dimensional representation can often be captured in a few meaningful degrees of freedom called collective variables (CVs).","However, identifying CVs is challenging and constitutes a fundamental problem in physical chemistry.","This problem is even more pronounced when CVs information about slow kinetics related to rare transitions between long-lived metastable states.","To address this issue, we propose an unsupervised deep-learning method called spectral map.","Our method constructs slow CVs by maximizing the spectral gap between slow and fast eigenvalues of a transition matrix estimated by an anisotropic diffusion kernel.","We demonstrate our method in several high-dimensional reversible folding processes."],"url":"http://arxiv.org/abs/2404.01809v1","category":"physics.chem-ph"}
{"created":"2024-04-02 10:06:21","title":"Neuromorphic Wireless Device-Edge Co-Inference via the Directed Information Bottleneck","abstract":"An important use case of next-generation wireless systems is device-edge co-inference, where a semantic task is partitioned between a device and an edge server. The device carries out data collection and partial processing of the data, while the remote server completes the given task based on information received from the device. It is often required that processing and communication be run as efficiently as possible at the device, while more computing resources are available at the edge. To address such scenarios, we introduce a new system solution, termed neuromorphic wireless device-edge co-inference. According to it, the device runs sensing, processing, and communication units using neuromorphic hardware, while the server employs conventional radio and computing technologies. The proposed system is designed using a transmitter-centric information-theoretic criterion that targets a reduction of the communication overhead, while retaining the most relevant information for the end-to-end semantic task of interest. Numerical results on standard data sets validate the proposed architecture, and a preliminary testbed realization is reported.","sentences":["An important use case of next-generation wireless systems is device-edge co-inference, where a semantic task is partitioned between a device and an edge server.","The device carries out data collection and partial processing of the data, while the remote server completes the given task based on information received from the device.","It is often required that processing and communication be run as efficiently as possible at the device, while more computing resources are available at the edge.","To address such scenarios, we introduce a new system solution, termed neuromorphic wireless device-edge co-inference.","According to it, the device runs sensing, processing, and communication units using neuromorphic hardware, while the server employs conventional radio and computing technologies.","The proposed system is designed using a transmitter-centric information-theoretic criterion that targets a reduction of the communication overhead, while retaining the most relevant information for the end-to-end semantic task of interest.","Numerical results on standard data sets validate the proposed architecture, and a preliminary testbed realization is reported."],"url":"http://arxiv.org/abs/2404.01804v1","category":"cs.LG"}
{"created":"2024-04-02 09:59:49","title":"Sentiment Analysis of Citations in Scientific Articles Using ChatGPT: Identifying Potential Biases and Conflicts of Interest","abstract":"Scientific articles play a crucial role in advancing knowledge and informing research directions. One key aspect of evaluating scientific articles is the analysis of citations, which provides insights into the impact and reception of the cited works. This article introduces the innovative use of large language models, particularly ChatGPT, for comprehensive sentiment analysis of citations within scientific articles. By leveraging advanced natural language processing (NLP) techniques, ChatGPT can discern the nuanced positivity or negativity of citations, offering insights into the reception and impact of cited works. Furthermore, ChatGPT's capabilities extend to detecting potential biases and conflicts of interest in citations, enhancing the objectivity and reliability of scientific literature evaluation. This study showcases the transformative potential of artificial intelligence (AI)-powered tools in enhancing citation analysis and promoting integrity in scholarly research.","sentences":["Scientific articles play a crucial role in advancing knowledge and informing research directions.","One key aspect of evaluating scientific articles is the analysis of citations, which provides insights into the impact and reception of the cited works.","This article introduces the innovative use of large language models, particularly ChatGPT, for comprehensive sentiment analysis of citations within scientific articles.","By leveraging advanced natural language processing (NLP) techniques, ChatGPT can discern the nuanced positivity or negativity of citations, offering insights into the reception and impact of cited works.","Furthermore, ChatGPT's capabilities extend to detecting potential biases and conflicts of interest in citations, enhancing the objectivity and reliability of scientific literature evaluation.","This study showcases the transformative potential of artificial intelligence (AI)-powered tools in enhancing citation analysis and promoting integrity in scholarly research."],"url":"http://arxiv.org/abs/2404.01800v1","category":"cs.DL"}
