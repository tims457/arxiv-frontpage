{"created":"2024-03-27 17:59:54","title":"MetaCap: Meta-learning Priors from Multi-View Imagery for Sparse-view Human Performance Capture and Rendering","abstract":"Faithful human performance capture and free-view rendering from sparse RGB observations is a long-standing problem in Vision and Graphics. The main challenges are the lack of observations and the inherent ambiguities of the setting, e.g. occlusions and depth ambiguity. As a result, radiance fields, which have shown great promise in capturing high-frequency appearance and geometry details in dense setups, perform poorly when na\\\"ively supervising them on sparse camera views, as the field simply overfits to the sparse-view inputs. To address this, we propose MetaCap, a method for efficient and high-quality geometry recovery and novel view synthesis given very sparse or even a single view of the human. Our key idea is to meta-learn the radiance field weights solely from potentially sparse multi-view videos, which can serve as a prior when fine-tuning them on sparse imagery depicting the human. This prior provides a good network weight initialization, thereby effectively addressing ambiguities in sparse-view capture. Due to the articulated structure of the human body and motion-induced surface deformations, learning such a prior is non-trivial. Therefore, we propose to meta-learn the field weights in a pose-canonicalized space, which reduces the spatial feature range and makes feature learning more effective. Consequently, one can fine-tune our field parameters to quickly generalize to unseen poses, novel illumination conditions as well as novel and sparse (even monocular) camera views. For evaluating our method under different scenarios, we collect a new dataset, WildDynaCap, which contains subjects captured in, both, a dense camera dome and in-the-wild sparse camera rigs, and demonstrate superior results compared to recent state-of-the-art methods on both public and WildDynaCap dataset.","sentences":["Faithful human performance capture and free-view rendering from sparse RGB observations is a long-standing problem in Vision and Graphics.","The main challenges are the lack of observations and the inherent ambiguities of the setting, e.g. occlusions and depth ambiguity.","As a result, radiance fields, which have shown great promise in capturing high-frequency appearance and geometry details in dense setups, perform poorly when na\\\"ively supervising them on sparse camera views, as the field simply overfits to the sparse-view inputs.","To address this, we propose MetaCap, a method for efficient and high-quality geometry recovery and novel view synthesis given very sparse or even a single view of the human.","Our key idea is to meta-learn the radiance field weights solely from potentially sparse multi-view videos, which can serve as a prior when fine-tuning them on sparse imagery depicting the human.","This prior provides a good network weight initialization, thereby effectively addressing ambiguities in sparse-view capture.","Due to the articulated structure of the human body and motion-induced surface deformations, learning such a prior is non-trivial.","Therefore, we propose to meta-learn the field weights in a pose-canonicalized space, which reduces the spatial feature range and makes feature learning more effective.","Consequently, one can fine-tune our field parameters to quickly generalize to unseen poses, novel illumination conditions as well as novel and sparse (even monocular) camera views.","For evaluating our method under different scenarios, we collect a new dataset, WildDynaCap, which contains subjects captured in, both, a dense camera dome and in-the-wild sparse camera rigs, and demonstrate superior results compared to recent state-of-the-art methods on both public and WildDynaCap dataset."],"url":"http://arxiv.org/abs/2403.18820v1","category":"cs.CV"}
{"created":"2024-03-27 17:59:04","title":"Mini-Gemini: Mining the Potential of Multi-modality Vision Language Models","abstract":"In this work, we introduce Mini-Gemini, a simple and effective framework enhancing multi-modality Vision Language Models (VLMs). Despite the advancements in VLMs facilitating basic visual dialog and reasoning, a performance gap persists compared to advanced models like GPT-4 and Gemini. We try to narrow the gap by mining the potential of VLMs for better performance and any-to-any workflow from three aspects, i.e., high-resolution visual tokens, high-quality data, and VLM-guided generation. To enhance visual tokens, we propose to utilize an additional visual encoder for high-resolution refinement without increasing the visual token count. We further construct a high-quality dataset that promotes precise image comprehension and reasoning-based generation, expanding the operational scope of current VLMs. In general, Mini-Gemini further mines the potential of VLMs and empowers current frameworks with image understanding, reasoning, and generation simultaneously. Mini-Gemini supports a series of dense and MoE Large Language Models (LLMs) from 2B to 34B. It is demonstrated to achieve leading performance in several zero-shot benchmarks and even surpasses the developed private models. Code and models are available at https://github.com/dvlab-research/MiniGemini.","sentences":["In this work, we introduce Mini-Gemini, a simple and effective framework enhancing multi-modality Vision Language Models (VLMs).","Despite the advancements in VLMs facilitating basic visual dialog and reasoning, a performance gap persists compared to advanced models like GPT-4 and Gemini.","We try to narrow the gap by mining the potential of VLMs for better performance and any-to-any workflow from three aspects, i.e., high-resolution visual tokens, high-quality data, and VLM-guided generation.","To enhance visual tokens, we propose to utilize an additional visual encoder for high-resolution refinement without increasing the visual token count.","We further construct a high-quality dataset that promotes precise image comprehension and reasoning-based generation, expanding the operational scope of current VLMs.","In general, Mini-Gemini further mines the potential of VLMs and empowers current frameworks with image understanding, reasoning, and generation simultaneously.","Mini-Gemini supports a series of dense and MoE Large Language Models (LLMs) from 2B to 34B. It is demonstrated to achieve leading performance in several zero-shot benchmarks and even surpasses the developed private models.","Code and models are available at https://github.com/dvlab-research/MiniGemini."],"url":"http://arxiv.org/abs/2403.18814v1","category":"cs.CV"}
{"created":"2024-03-27 17:57:02","title":"Duolando: Follower GPT with Off-Policy Reinforcement Learning for Dance Accompaniment","abstract":"We introduce a novel task within the field of 3D dance generation, termed dance accompaniment, which necessitates the generation of responsive movements from a dance partner, the \"follower\", synchronized with the lead dancer's movements and the underlying musical rhythm. Unlike existing solo or group dance generation tasks, a duet dance scenario entails a heightened degree of interaction between the two participants, requiring delicate coordination in both pose and position. To support this task, we first build a large-scale and diverse duet interactive dance dataset, DD100, by recording about 117 minutes of professional dancers' performances. To address the challenges inherent in this task, we propose a GPT-based model, Duolando, which autoregressively predicts the subsequent tokenized motion conditioned on the coordinated information of the music, the leader's and the follower's movements. To further enhance the GPT's capabilities of generating stable results on unseen conditions (music and leader motions), we devise an off-policy reinforcement learning strategy that allows the model to explore viable trajectories from out-of-distribution samplings, guided by human-defined rewards. Based on the collected dataset and proposed method, we establish a benchmark with several carefully designed metrics.","sentences":["We introduce a novel task within the field of 3D dance generation, termed dance accompaniment, which necessitates the generation of responsive movements from a dance partner, the \"follower\", synchronized with the lead dancer's movements and the underlying musical rhythm.","Unlike existing solo or group dance generation tasks, a duet dance scenario entails a heightened degree of interaction between the two participants, requiring delicate coordination in both pose and position.","To support this task, we first build a large-scale and diverse duet interactive dance dataset, DD100, by recording about 117 minutes of professional dancers' performances.","To address the challenges inherent in this task, we propose a GPT-based model, Duolando, which autoregressively predicts the subsequent tokenized motion conditioned on the coordinated information of the music, the leader's and the follower's movements.","To further enhance the GPT's capabilities of generating stable results on unseen conditions (music and leader motions), we devise an off-policy reinforcement learning strategy that allows the model to explore viable trajectories from out-of-distribution samplings, guided by human-defined rewards.","Based on the collected dataset and proposed method, we establish a benchmark with several carefully designed metrics."],"url":"http://arxiv.org/abs/2403.18811v1","category":"cs.CV"}
{"created":"2024-03-27 17:53:30","title":"ECoDepth: Effective Conditioning of Diffusion Models for Monocular Depth Estimation","abstract":"In the absence of parallax cues, a learning-based single image depth estimation (SIDE) model relies heavily on shading and contextual cues in the image. While this simplicity is attractive, it is necessary to train such models on large and varied datasets, which are difficult to capture. It has been shown that using embeddings from pre-trained foundational models, such as CLIP, improves zero shot transfer in several applications. Taking inspiration from this, in our paper we explore the use of global image priors generated from a pre-trained ViT model to provide more detailed contextual information. We argue that the embedding vector from a ViT model, pre-trained on a large dataset, captures greater relevant information for SIDE than the usual route of generating pseudo image captions, followed by CLIP based text embeddings. Based on this idea, we propose a new SIDE model using a diffusion backbone which is conditioned on ViT embeddings. Our proposed design establishes a new state-of-the-art (SOTA) for SIDE on NYUv2 dataset, achieving Abs Rel error of 0.059(14% improvement) compared to 0.069 by the current SOTA (VPD). And on KITTI dataset, achieving Sq Rel error of 0.139 (2% improvement) compared to 0.142 by the current SOTA (GEDepth). For zero-shot transfer with a model trained on NYUv2, we report mean relative improvement of (20%, 23%, 81%, 25%) over NeWCRFs on (Sun-RGBD, iBims1, DIODE, HyperSim) datasets, compared to (16%, 18%, 45%, 9%) by ZoeDepth. The code is available at https://ecodepth-iitd.github.io","sentences":["In the absence of parallax cues, a learning-based single image depth estimation (SIDE) model relies heavily on shading and contextual cues in the image.","While this simplicity is attractive, it is necessary to train such models on large and varied datasets, which are difficult to capture.","It has been shown that using embeddings from pre-trained foundational models, such as CLIP, improves zero shot transfer in several applications.","Taking inspiration from this, in our paper we explore the use of global image priors generated from a pre-trained ViT model to provide more detailed contextual information.","We argue that the embedding vector from a ViT model, pre-trained on a large dataset, captures greater relevant information for SIDE than the usual route of generating pseudo image captions, followed by CLIP based text embeddings.","Based on this idea, we propose a new SIDE model using a diffusion backbone which is conditioned on ViT embeddings.","Our proposed design establishes a new state-of-the-art (SOTA) for SIDE on NYUv2 dataset, achieving Abs Rel error of 0.059(14% improvement) compared to 0.069 by the current SOTA (VPD).","And on KITTI dataset, achieving Sq Rel error of 0.139 (2% improvement) compared to 0.142 by the current SOTA (GEDepth).","For zero-shot transfer with a model trained on NYUv2, we report mean relative improvement of (20%, 23%, 81%, 25%) over NeWCRFs on (Sun-RGBD, iBims1, DIODE, HyperSim) datasets, compared to (16%, 18%, 45%, 9%) by ZoeDepth.","The code is available at https://ecodepth-iitd.github.io"],"url":"http://arxiv.org/abs/2403.18807v2","category":"cs.CV"}
{"created":"2024-03-27 17:48:55","title":"Long-form factuality in large language models","abstract":"Large language models (LLMs) often generate content that contains factual errors when responding to fact-seeking prompts on open-ended topics. To benchmark a model's long-form factuality in open domains, we first use GPT-4 to generate LongFact, a prompt set comprising thousands of questions spanning 38 topics. We then propose that LLM agents can be used as automated evaluators for long-form factuality through a method which we call Search-Augmented Factuality Evaluator (SAFE). SAFE utilizes an LLM to break down a long-form response into a set of individual facts and to evaluate the accuracy of each fact using a multi-step reasoning process comprising sending search queries to Google Search and determining whether a fact is supported by the search results. Furthermore, we propose extending F1 score as an aggregated metric for long-form factuality. To do so, we balance the percentage of supported facts in a response (precision) with the percentage of provided facts relative to a hyperparameter representing a user's preferred response length (recall).   Empirically, we demonstrate that LLM agents can achieve superhuman rating performance - on a set of ~16k individual facts, SAFE agrees with crowdsourced human annotators 72% of the time, and on a random subset of 100 disagreement cases, SAFE wins 76% of the time. At the same time, SAFE is more than 20 times cheaper than human annotators. We also benchmark thirteen language models on LongFact across four model families (Gemini, GPT, Claude, and PaLM-2), finding that larger language models generally achieve better long-form factuality. LongFact, SAFE, and all experimental code are available at https://github.com/google-deepmind/long-form-factuality.","sentences":["Large language models (LLMs) often generate content that contains factual errors when responding to fact-seeking prompts on open-ended topics.","To benchmark a model's long-form factuality in open domains, we first use GPT-4 to generate LongFact, a prompt set comprising thousands of questions spanning 38 topics.","We then propose that LLM agents can be used as automated evaluators for long-form factuality through a method which we call Search-Augmented Factuality Evaluator (SAFE).","SAFE utilizes an LLM to break down a long-form response into a set of individual facts and to evaluate the accuracy of each fact using a multi-step reasoning process comprising sending search queries to Google Search and determining whether a fact is supported by the search results.","Furthermore, we propose extending F1 score as an aggregated metric for long-form factuality.","To do so, we balance the percentage of supported facts in a response (precision) with the percentage of provided facts relative to a hyperparameter representing a user's preferred response length (recall).   ","Empirically, we demonstrate that LLM agents can achieve superhuman rating performance - on a set of ~16k individual facts, SAFE agrees with crowdsourced human annotators 72% of the time, and on a random subset of 100 disagreement cases, SAFE wins 76% of the time.","At the same time, SAFE is more than 20 times cheaper than human annotators.","We also benchmark thirteen language models on LongFact across four model families (Gemini, GPT, Claude, and PaLM-2), finding that larger language models generally achieve better long-form factuality.","LongFact, SAFE, and all experimental code are available at https://github.com/google-deepmind/long-form-factuality."],"url":"http://arxiv.org/abs/2403.18802v1","category":"cs.CL"}
{"created":"2024-03-27 17:44:29","title":"SolderlessPCB: Reusing Electronic Components in PCB Prototyping through Detachable 3D Printed Housings","abstract":"The iterative prototyping process for printed circuit boards (PCBs) frequently employs surface-mounted device (SMD) components, which are often discarded rather than reused due to the challenges associated with desoldering, leading to unnecessary electronic waste. This paper introduces SolderlessPCB, a collection of techniques for solder-free PCB prototyping, specifically designed to promote the recycling and reuse of electronic components. Central to this approach are custom 3D-printable housings that allow SMD components to be mounted onto PCBs without soldering. We detail the design of SolderlessPCB and the experiments conducted to evaluate its design parameters, electrical performance, and durability. To illustrate the potential for reusing SMD components with SolderlessPCB, we discuss two scenarios: the reuse of components from earlier design iterations and from obsolete prototypes. We also provide examples demonstrating that SolderlessPCB can handle high-current applications and is suitable for high-speed data transmission. The paper concludes by discussing the limitations of our approach and suggesting future directions to overcome these challenges.","sentences":["The iterative prototyping process for printed circuit boards (PCBs) frequently employs surface-mounted device (SMD) components, which are often discarded rather than reused due to the challenges associated with desoldering, leading to unnecessary electronic waste.","This paper introduces SolderlessPCB, a collection of techniques for solder-free PCB prototyping, specifically designed to promote the recycling and reuse of electronic components.","Central to this approach are custom 3D-printable housings that allow SMD components to be mounted onto PCBs without soldering.","We detail the design of SolderlessPCB and the experiments conducted to evaluate its design parameters, electrical performance, and durability.","To illustrate the potential for reusing SMD components with SolderlessPCB, we discuss two scenarios: the reuse of components from earlier design iterations and from obsolete prototypes.","We also provide examples demonstrating that SolderlessPCB can handle high-current applications and is suitable for high-speed data transmission.","The paper concludes by discussing the limitations of our approach and suggesting future directions to overcome these challenges."],"url":"http://arxiv.org/abs/2403.18797v1","category":"cs.HC"}
{"created":"2024-03-27 17:40:14","title":"Gamba: Marry Gaussian Splatting with Mamba for single view 3D reconstruction","abstract":"We tackle the challenge of efficiently reconstructing a 3D asset from a single image with growing demands for automated 3D content creation pipelines. Previous methods primarily rely on Score Distillation Sampling (SDS) and Neural Radiance Fields (NeRF). Despite their significant success, these approaches encounter practical limitations due to lengthy optimization and considerable memory usage. In this report, we introduce Gamba, an end-to-end amortized 3D reconstruction model from single-view images, emphasizing two main insights: (1) 3D representation: leveraging a large number of 3D Gaussians for an efficient 3D Gaussian splatting process; (2) Backbone design: introducing a Mamba-based sequential network that facilitates context-dependent reasoning and linear scalability with the sequence (token) length, accommodating a substantial number of Gaussians. Gamba incorporates significant advancements in data preprocessing, regularization design, and training methodologies. We assessed Gamba against existing optimization-based and feed-forward 3D generation approaches using the real-world scanned OmniObject3D dataset. Here, Gamba demonstrates competitive generation capabilities, both qualitatively and quantitatively, while achieving remarkable speed, approximately 0.6 second on a single NVIDIA A100 GPU.","sentences":["We tackle the challenge of efficiently reconstructing a 3D asset from a single image with growing demands for automated 3D content creation pipelines.","Previous methods primarily rely on Score Distillation Sampling (SDS) and Neural Radiance Fields (NeRF).","Despite their significant success, these approaches encounter practical limitations due to lengthy optimization and considerable memory usage.","In this report, we introduce Gamba, an end-to-end amortized 3D reconstruction model from single-view images, emphasizing two main insights: (1) 3D representation: leveraging a large number of 3D Gaussians for an efficient 3D Gaussian splatting process; (2) Backbone design: introducing a Mamba-based sequential network that facilitates context-dependent reasoning and linear scalability with the sequence (token) length, accommodating a substantial number of Gaussians.","Gamba incorporates significant advancements in data preprocessing, regularization design, and training methodologies.","We assessed Gamba against existing optimization-based and feed-forward 3D generation approaches using the real-world scanned OmniObject3D dataset.","Here, Gamba demonstrates competitive generation capabilities, both qualitatively and quantitatively, while achieving remarkable speed, approximately 0.6 second on a single NVIDIA A100 GPU."],"url":"http://arxiv.org/abs/2403.18795v1","category":"cs.CV"}
{"created":"2024-03-27 17:23:39","title":"ImageNet-D: Benchmarking Neural Network Robustness on Diffusion Synthetic Object","abstract":"We establish rigorous benchmarks for visual perception robustness. Synthetic images such as ImageNet-C, ImageNet-9, and Stylized ImageNet provide specific type of evaluation over synthetic corruptions, backgrounds, and textures, yet those robustness benchmarks are restricted in specified variations and have low synthetic quality. In this work, we introduce generative model as a data source for synthesizing hard images that benchmark deep models' robustness. Leveraging diffusion models, we are able to generate images with more diversified backgrounds, textures, and materials than any prior work, where we term this benchmark as ImageNet-D. Experimental results show that ImageNet-D results in a significant accuracy drop to a range of vision models, from the standard ResNet visual classifier to the latest foundation models like CLIP and MiniGPT-4, significantly reducing their accuracy by up to 60\\%. Our work suggests that diffusion models can be an effective source to test vision models. The code and dataset are available at https://github.com/chenshuang-zhang/imagenet_d.","sentences":["We establish rigorous benchmarks for visual perception robustness.","Synthetic images such as ImageNet-C, ImageNet-9, and Stylized ImageNet provide specific type of evaluation over synthetic corruptions, backgrounds, and textures, yet those robustness benchmarks are restricted in specified variations and have low synthetic quality.","In this work, we introduce generative model as a data source for synthesizing hard images that benchmark deep models' robustness.","Leveraging diffusion models, we are able to generate images with more diversified backgrounds, textures, and materials than any prior work, where we term this benchmark as ImageNet-D. Experimental results show that ImageNet-D results in a significant accuracy drop to a range of vision models, from the standard ResNet visual classifier to the latest foundation models like CLIP and MiniGPT-4, significantly reducing their accuracy by up to 60\\%.","Our work suggests that diffusion models can be an effective source to test vision models.","The code and dataset are available at https://github.com/chenshuang-zhang/imagenet_d."],"url":"http://arxiv.org/abs/2403.18775v1","category":"cs.CV"}
{"created":"2024-03-27 17:05:03","title":"Superior Parallel Big Data Clustering through Competitive Stochastic Sample Size Optimization in Big-means","abstract":"This paper introduces a novel K-means clustering algorithm, an advancement on the conventional Big-means methodology. The proposed method efficiently integrates parallel processing, stochastic sampling, and competitive optimization to create a scalable variant designed for big data applications. It addresses scalability and computation time challenges typically faced with traditional techniques. The algorithm adjusts sample sizes dynamically for each worker during execution, optimizing performance. Data from these sample sizes are continually analyzed, facilitating the identification of the most efficient configuration. By incorporating a competitive element among workers using different sample sizes, efficiency within the Big-means algorithm is further stimulated. In essence, the algorithm balances computational time and clustering quality by employing a stochastic, competitive sampling strategy in a parallel computing setting.","sentences":["This paper introduces a novel K-means clustering algorithm, an advancement on the conventional Big-means methodology.","The proposed method efficiently integrates parallel processing, stochastic sampling, and competitive optimization to create a scalable variant designed for big data applications.","It addresses scalability and computation time challenges typically faced with traditional techniques.","The algorithm adjusts sample sizes dynamically for each worker during execution, optimizing performance.","Data from these sample sizes are continually analyzed, facilitating the identification of the most efficient configuration.","By incorporating a competitive element among workers using different sample sizes, efficiency within the Big-means algorithm is further stimulated.","In essence, the algorithm balances computational time and clustering quality by employing a stochastic, competitive sampling strategy in a parallel computing setting."],"url":"http://arxiv.org/abs/2403.18766v1","category":"cs.LG"}
{"created":"2024-03-27 17:01:10","title":"ModaLink: Unifying Modalities for Efficient Image-to-PointCloud Place Recognition","abstract":"Place recognition is an important task for robots and autonomous cars to localize themselves and close loops in pre-built maps. While single-modal sensor-based methods have shown satisfactory performance, cross-modal place recognition that retrieving images from a point-cloud database remains a challenging problem. Current cross-modal methods transform images into 3D points using depth estimation for modality conversion, which are usually computationally intensive and need expensive labeled data for depth supervision. In this work, we introduce a fast and lightweight framework to encode images and point clouds into place-distinctive descriptors. We propose an effective Field of View (FoV) transformation module to convert point clouds into an analogous modality as images. This module eliminates the necessity for depth estimation and helps subsequent modules achieve real-time performance. We further design a non-negative factorization-based encoder to extract mutually consistent semantic features between point clouds and images. This encoder yields more distinctive global descriptors for retrieval. Experimental results on the KITTI dataset show that our proposed methods achieve state-of-the-art performance while running in real time. Additional evaluation on the HAOMO dataset covering a 17 km trajectory further shows the practical generalization capabilities. We have released the implementation of our methods as open source at: https://github.com/haomo-ai/ModaLink.git.","sentences":["Place recognition is an important task for robots and autonomous cars to localize themselves and close loops in pre-built maps.","While single-modal sensor-based methods have shown satisfactory performance, cross-modal place recognition that retrieving images from a point-cloud database remains a challenging problem.","Current cross-modal methods transform images into 3D points using depth estimation for modality conversion, which are usually computationally intensive and need expensive labeled data for depth supervision.","In this work, we introduce a fast and lightweight framework to encode images and point clouds into place-distinctive descriptors.","We propose an effective Field of View (FoV) transformation module to convert point clouds into an analogous modality as images.","This module eliminates the necessity for depth estimation and helps subsequent modules achieve real-time performance.","We further design a non-negative factorization-based encoder to extract mutually consistent semantic features between point clouds and images.","This encoder yields more distinctive global descriptors for retrieval.","Experimental results on the KITTI dataset show that our proposed methods achieve state-of-the-art performance while running in real time.","Additional evaluation on the HAOMO dataset covering a 17 km trajectory further shows the practical generalization capabilities.","We have released the implementation of our methods as open source at: https://github.com/haomo-ai/ModaLink.git."],"url":"http://arxiv.org/abs/2403.18762v1","category":"cs.CV"}
{"created":"2024-03-27 16:56:14","title":"Detection of subclinical atherosclerosis by image-based deep learning on chest x-ray","abstract":"Aims. To develop a deep-learning based system for recognition of subclinical atherosclerosis on a plain frontal chest x-ray. Methods and Results. A deep-learning algorithm to predict coronary artery calcium (CAC) score (the AI-CAC model) was developed on 460 chest x-ray (80% training cohort, 20% internal validation cohort) of primary prevention patients (58.4% male, median age 63 [51-74] years) with available paired chest x-ray and chest computed tomography (CT) indicated for any clinical reason and performed within 3 months. The CAC score calculated on chest CT was used as ground truth. The model was validated on an temporally-independent cohort of 90 patients from the same institution (external validation). The diagnostic accuracy of the AI-CAC model assessed by the area under the curve (AUC) was the primary outcome. Overall, median AI-CAC score was 35 (0-388) and 28.9% patients had no AI-CAC. AUC of the AI-CAC model to identify a CAC>0 was 0.90 in the internal validation cohort and 0.77 in the external validation cohort. Sensitivity was consistently above 92% in both cohorts. In the overall cohort (n=540), among patients with AI-CAC=0, a single ASCVD event occurred, after 4.3 years. Patients with AI-CAC>0 had significantly higher Kaplan Meier estimates for ASCVD events (13.5% vs. 3.4%, log-rank=0.013). Conclusion. The AI-CAC model seems to accurately detect subclinical atherosclerosis on chest x-ray with elevated sensitivity, and to predict ASCVD events with elevated negative predictive value. Adoption of the AI-CAC model to refine CV risk stratification or as an opportunistic screening tool requires prospective evaluation.","sentences":["Aims.","To develop a deep-learning based system for recognition of subclinical atherosclerosis on a plain frontal chest x-ray.","Methods and Results.","A deep-learning algorithm to predict coronary artery calcium (CAC) score (the AI-CAC model) was developed on 460 chest x-ray (80% training cohort, 20% internal validation cohort) of primary prevention patients (58.4% male, median age 63","[51-74] years) with available paired chest x-ray and chest computed tomography (CT) indicated for any clinical reason and performed within 3 months.","The CAC score calculated on chest CT was used as ground truth.","The model was validated on an temporally-independent cohort of 90 patients from the same institution (external validation).","The diagnostic accuracy of the AI-CAC model assessed by the area under the curve (AUC) was the primary outcome.","Overall, median AI-CAC score was 35 (0-388) and 28.9% patients had no AI-CAC.","AUC of the AI-CAC model to identify a CAC>0 was 0.90 in the internal validation cohort and 0.77 in the external validation cohort.","Sensitivity was consistently above 92% in both cohorts.","In the overall cohort (n=540), among patients with AI-CAC=0, a single ASCVD event occurred, after 4.3 years.","Patients with AI-CAC>0 had significantly higher Kaplan Meier estimates for ASCVD events (13.5% vs. 3.4%, log-rank=0.013).","Conclusion.","The AI-CAC model seems to accurately detect subclinical atherosclerosis on chest x-ray with elevated sensitivity, and to predict ASCVD events with elevated negative predictive value.","Adoption of the AI-CAC model to refine CV risk stratification or as an opportunistic screening tool requires prospective evaluation."],"url":"http://arxiv.org/abs/2403.18756v1","category":"cs.CV"}
{"created":"2024-03-27 16:54:45","title":"Many-Objective Evolutionary Influence Maximization: Balancing Spread, Budget, Fairness, and Time","abstract":"The Influence Maximization (IM) problem seeks to discover the set of nodes in a graph that can spread the information propagation at most. This problem is known to be NP-hard, and it is usually studied by maximizing the influence (spread) and, optionally, optimizing a second objective, such as minimizing the seed set size or maximizing the influence fairness. However, in many practical scenarios multiple aspects of the IM problem must be optimized at the same time. In this work, we propose a first case study where several IM-specific objective functions, namely budget, fairness, communities, and time, are optimized on top of the maximization of influence and minimization of the seed set size. To this aim, we introduce MOEIM (Many-Objective Evolutionary Algorithm for Influence Maximization) a Multi-Objective Evolutionary Algorithm (MOEA) based on NSGA-II incorporating graph-aware operators and a smart initialization. We compare MOEIM in two experimental settings, including a total of nine graph datasets, two heuristic methods, a related MOEA, and a state-of-the-art Deep Learning approach. The experiments show that MOEIM overall outperforms the competitors in most of the tested many-objective settings. To conclude, we also investigate the correlation between the objectives, leading to novel insights into the topic. The codebase is available at https://github.com/eliacunegatti/MOEIM.","sentences":["The Influence Maximization (IM) problem seeks to discover the set of nodes in a graph that can spread the information propagation at most.","This problem is known to be NP-hard, and it is usually studied by maximizing the influence (spread) and, optionally, optimizing a second objective, such as minimizing the seed set size or maximizing the influence fairness.","However, in many practical scenarios multiple aspects of the IM problem must be optimized at the same time.","In this work, we propose a first case study where several IM-specific objective functions, namely budget, fairness, communities, and time, are optimized on top of the maximization of influence and minimization of the seed set size.","To this aim, we introduce MOEIM (Many-Objective Evolutionary Algorithm for Influence Maximization) a Multi-Objective Evolutionary Algorithm (MOEA) based on NSGA-II incorporating graph-aware operators and a smart initialization.","We compare MOEIM in two experimental settings, including a total of nine graph datasets, two heuristic methods, a related MOEA, and a state-of-the-art Deep Learning approach.","The experiments show that MOEIM overall outperforms the competitors in most of the tested many-objective settings.","To conclude, we also investigate the correlation between the objectives, leading to novel insights into the topic.","The codebase is available at https://github.com/eliacunegatti/MOEIM."],"url":"http://arxiv.org/abs/2403.18755v2","category":"cs.NE"}
{"created":"2024-03-27 16:39:28","title":"Understanding the Learning Dynamics of Alignment with Human Feedback","abstract":"Aligning large language models (LLMs) with human intentions has become a critical task for safely deploying models in real-world systems. While existing alignment approaches have seen empirical success, theoretically understanding how these methods affect model behavior remains an open question. Our work provides an initial attempt to theoretically analyze the learning dynamics of human preference alignment. We formally show how the distribution of preference datasets influences the rate of model updates and provide rigorous guarantees on the training accuracy. Our theory also reveals an intricate phenomenon where the optimization is prone to prioritizing certain behaviors with higher preference distinguishability. We empirically validate our findings on contemporary LLMs and alignment tasks, reinforcing our theoretical insights and shedding light on considerations for future alignment approaches. Disclaimer: This paper contains potentially offensive text; reader discretion is advised.","sentences":["Aligning large language models (LLMs) with human intentions has become a critical task for safely deploying models in real-world systems.","While existing alignment approaches have seen empirical success, theoretically understanding how these methods affect model behavior remains an open question.","Our work provides an initial attempt to theoretically analyze the learning dynamics of human preference alignment.","We formally show how the distribution of preference datasets influences the rate of model updates and provide rigorous guarantees on the training accuracy.","Our theory also reveals an intricate phenomenon where the optimization is prone to prioritizing certain behaviors with higher preference distinguishability.","We empirically validate our findings on contemporary LLMs and alignment tasks, reinforcing our theoretical insights and shedding light on considerations for future alignment approaches.","Disclaimer:","This paper contains potentially offensive text; reader discretion is advised."],"url":"http://arxiv.org/abs/2403.18742v1","category":"cs.LG"}
{"created":"2024-03-27 16:22:45","title":"A vascular synthetic model for improved aneurysm segmentation and detection via Deep Neural Networks","abstract":"We hereby present a full synthetic model, able to mimic the various constituents of the cerebral vascular tree: the cerebral arteries, the bifurcations and the intracranial aneurysms. By building this model, our goal was to provide a substantial dataset of brain arteries which could be used by a 3D Convolutional Neural Network (CNN) to either segment or detect/recognize various vascular diseases (such as artery dissection/thrombosis) or even some portions of the cerebral vasculature, such as the bifurcations or aneurysms. In this study, we will particularly focus on Intra-Cranial Aneurysm (ICA) detection and segmentation. The cerebral aneurysms most often occur on a particular structure of the vascular tree named the Circle of Willis. Various studies have been conducted to detect and monitor the ICAs and those based on Deep Learning (DL) achieve the best performances. Specifically, in this work, we propose a full synthetic 3D model able to mimic the brain vasculature as acquired by Magnetic Resonance Angiography (MRA), and more particularly the Time Of Flight (TOF) principle. Among the various MRI modalities, the MRA-TOF allows to have a relatively good rendering of the blood vessels and is non-invasive (no contrast liquid injection). Our model has been designed to simultaneously mimic the arteries geometry, the ICA shape and the background noise. The geometry of the vascular tree is modeled thanks to an interpolation with 3D Spline functions, and the statistical properties of the background MRI noise is collected from MRA acquisitions and reproduced within the model. In this work, we thoroughly describe the synthetic vasculature model, we build up a neural network designed for ICA segmentation and detection, and finally, we carry out an in-depth evaluation of the performance gap gained thanks to the synthetic model data augmentation.","sentences":["We hereby present a full synthetic model, able to mimic the various constituents of the cerebral vascular tree: the cerebral arteries, the bifurcations and the intracranial aneurysms.","By building this model, our goal was to provide a substantial dataset of brain arteries which could be used by a 3D Convolutional Neural Network (CNN) to either segment or detect/recognize various vascular diseases (such as artery dissection/thrombosis) or even some portions of the cerebral vasculature, such as the bifurcations or aneurysms.","In this study, we will particularly focus on Intra-Cranial Aneurysm (ICA) detection and segmentation.","The cerebral aneurysms most often occur on a particular structure of the vascular tree named the Circle of Willis.","Various studies have been conducted to detect and monitor the ICAs and those based on Deep Learning (DL) achieve the best performances.","Specifically, in this work, we propose a full synthetic 3D model able to mimic the brain vasculature as acquired by Magnetic Resonance Angiography (MRA), and more particularly the Time Of Flight (TOF) principle.","Among the various MRI modalities, the MRA-TOF allows to have a relatively good rendering of the blood vessels and is non-invasive (no contrast liquid injection).","Our model has been designed to simultaneously mimic the arteries geometry, the ICA shape and the background noise.","The geometry of the vascular tree is modeled thanks to an interpolation with 3D Spline functions, and the statistical properties of the background MRI noise is collected from MRA acquisitions and reproduced within the model.","In this work, we thoroughly describe the synthetic vasculature model, we build up a neural network designed for ICA segmentation and detection, and finally, we carry out an in-depth evaluation of the performance gap gained thanks to the synthetic model data augmentation."],"url":"http://arxiv.org/abs/2403.18734v1","category":"eess.IV"}
{"created":"2024-03-27 16:21:24","title":"Enhancing Manufacturing Quality Prediction Models through the Integration of Explainability Methods","abstract":"This research presents a method that utilizes explainability techniques to amplify the performance of machine learning (ML) models in forecasting the quality of milling processes, as demonstrated in this paper through a manufacturing use case. The methodology entails the initial training of ML models, followed by a fine-tuning phase where irrelevant features identified through explainability methods are eliminated. This procedural refinement results in performance enhancements, paving the way for potential reductions in manufacturing costs and a better understanding of the trained ML models. This study highlights the usefulness of explainability techniques in both explaining and optimizing predictive models in the manufacturing realm.","sentences":["This research presents a method that utilizes explainability techniques to amplify the performance of machine learning (ML) models in forecasting the quality of milling processes, as demonstrated in this paper through a manufacturing use case.","The methodology entails the initial training of ML models, followed by a fine-tuning phase where irrelevant features identified through explainability methods are eliminated.","This procedural refinement results in performance enhancements, paving the way for potential reductions in manufacturing costs and a better understanding of the trained ML models.","This study highlights the usefulness of explainability techniques in both explaining and optimizing predictive models in the manufacturing realm."],"url":"http://arxiv.org/abs/2403.18731v1","category":"cs.AI"}
{"created":"2024-03-27 16:15:21","title":"Probabilistic Model Checking of Stochastic Reinforcement Learning Policies","abstract":"We introduce a method to verify stochastic reinforcement learning (RL) policies. This approach is compatible with any RL algorithm as long as the algorithm and its corresponding environment collectively adhere to the Markov property. In this setting, the future state of the environment should depend solely on its current state and the action executed, independent of any previous states or actions. Our method integrates a verification technique, referred to as model checking, with RL, leveraging a Markov decision process, a trained RL policy, and a probabilistic computation tree logic (PCTL) formula to build a formal model that can be subsequently verified via the model checker Storm. We demonstrate our method's applicability across multiple benchmarks, comparing it to baseline methods called deterministic safety estimates and naive monolithic model checking. Our results show that our method is suited to verify stochastic RL policies.","sentences":["We introduce a method to verify stochastic reinforcement learning (RL) policies.","This approach is compatible with any RL algorithm as long as the algorithm and its corresponding environment collectively adhere to the Markov property.","In this setting, the future state of the environment should depend solely on its current state and the action executed, independent of any previous states or actions.","Our method integrates a verification technique, referred to as model checking, with RL, leveraging a Markov decision process, a trained RL policy, and a probabilistic computation tree logic (PCTL) formula to build a formal model that can be subsequently verified via the model checker Storm.","We demonstrate our method's applicability across multiple benchmarks, comparing it to baseline methods called deterministic safety estimates and naive monolithic model checking.","Our results show that our method is suited to verify stochastic RL policies."],"url":"http://arxiv.org/abs/2403.18725v1","category":"cs.AI"}
{"created":"2024-03-27 16:06:37","title":"Semi-Supervised Learning for Deep Causal Generative Models","abstract":"Developing models that can answer questions of the form \"How would $x$ change if $y$ had been $z$?\" is fundamental for advancing medical image analysis. Training causal generative models that address such counterfactual questions, though, currently requires that all relevant variables have been observed and that corresponding labels are available in training data. However, clinical data may not have complete records for all patients and state of the art causal generative models are unable to take full advantage of this. We thus develop, for the first time, a semi-supervised deep causal generative model that exploits the causal relationships between variables to maximise the use of all available data. We explore this in the setting where each sample is either fully labelled or fully unlabelled, as well as the more clinically realistic case of having different labels missing for each sample. We leverage techniques from causal inference to infer missing values and subsequently generate realistic counterfactuals, even for samples with incomplete labels.","sentences":["Developing models that can answer questions of the form \"How would $x$ change if $y$ had been $z$?\" is fundamental for advancing medical image analysis.","Training causal generative models that address such counterfactual questions, though, currently requires that all relevant variables have been observed and that corresponding labels are available in training data.","However, clinical data may not have complete records for all patients and state of the art causal generative models are unable to take full advantage of this.","We thus develop, for the first time, a semi-supervised deep causal generative model that exploits the causal relationships between variables to maximise the use of all available data.","We explore this in the setting where each sample is either fully labelled or fully unlabelled, as well as the more clinically realistic case of having different labels missing for each sample.","We leverage techniques from causal inference to infer missing values and subsequently generate realistic counterfactuals, even for samples with incomplete labels."],"url":"http://arxiv.org/abs/2403.18717v1","category":"cs.LG"}
{"created":"2024-03-27 16:04:47","title":"Mitigating Hallucinations in Large Vision-Language Models with Instruction Contrastive Decoding","abstract":"Large Vision-Language Models (LVLMs) are increasingly adept at generating contextually detailed and coherent responses from visual inputs. However, their application in multimodal decision-making and open-ended generation is hindered by a notable rate of hallucinations, where generated text inaccurately represents the visual contents. To address this issue, this paper introduces the Instruction Contrastive Decoding (ICD) method, a novel approach designed to reduce hallucinations during LVLM inference. Our method is inspired by our observation that what we call disturbance instructions significantly exacerbate hallucinations in multimodal fusion modules. ICD contrasts distributions from standard and instruction disturbance, thereby increasing alignment uncertainty and effectively subtracting hallucinated concepts from the original distribution. Through comprehensive experiments on discriminative benchmarks (POPE and MME) and a generative benchmark (LLaVa-Bench), we demonstrate that ICD significantly mitigates both object-level and attribute-level hallucinations. Moreover, our method not only addresses hallucinations but also significantly enhances the general perception and recognition capabilities of LVLMs.","sentences":["Large Vision-Language Models (LVLMs) are increasingly adept at generating contextually detailed and coherent responses from visual inputs.","However, their application in multimodal decision-making and open-ended generation is hindered by a notable rate of hallucinations, where generated text inaccurately represents the visual contents.","To address this issue, this paper introduces the Instruction Contrastive Decoding (ICD) method, a novel approach designed to reduce hallucinations during LVLM inference.","Our method is inspired by our observation that what we call disturbance instructions significantly exacerbate hallucinations in multimodal fusion modules.","ICD contrasts distributions from standard and instruction disturbance, thereby increasing alignment uncertainty and effectively subtracting hallucinated concepts from the original distribution.","Through comprehensive experiments on discriminative benchmarks (POPE and MME) and a generative benchmark (LLaVa-Bench), we demonstrate that ICD significantly mitigates both object-level and attribute-level hallucinations.","Moreover, our method not only addresses hallucinations but also significantly enhances the general perception and recognition capabilities of LVLMs."],"url":"http://arxiv.org/abs/2403.18715v1","category":"cs.CV"}
{"created":"2024-03-27 15:58:25","title":"SAT-NGP : Unleashing Neural Graphics Primitives for Fast Relightable Transient-Free 3D reconstruction from Satellite Imagery","abstract":"Current stereo-vision pipelines produce high accuracy 3D reconstruction when using multiple pairs or triplets of satellite images. However, these pipelines are sensitive to the changes between images that can occur as a result of multi-date acquisitions. Such variations are mainly due to variable shadows, reflexions and transient objects (cars, vegetation). To take such changes into account, Neural Radiance Fields (NeRF) have recently been applied to multi-date satellite imagery. However, Neural methods are very compute-intensive, taking dozens of hours to learn, compared with minutes for standard stereo-vision pipelines. Following the ideas of Instant Neural Graphics Primitives we propose to use an efficient sampling strategy and multi-resolution hash encoding to accelerate the learning. Our model, Satellite Neural Graphics Primitives (SAT-NGP) decreases the learning time to 15 minutes while maintaining the quality of the 3D reconstruction.","sentences":["Current stereo-vision pipelines produce high accuracy 3D reconstruction when using multiple pairs or triplets of satellite images.","However, these pipelines are sensitive to the changes between images that can occur as a result of multi-date acquisitions.","Such variations are mainly due to variable shadows, reflexions and transient objects (cars, vegetation).","To take such changes into account, Neural Radiance Fields (NeRF) have recently been applied to multi-date satellite imagery.","However, Neural methods are very compute-intensive, taking dozens of hours to learn, compared with minutes for standard stereo-vision pipelines.","Following the ideas of Instant Neural Graphics Primitives we propose to use an efficient sampling strategy and multi-resolution hash encoding to accelerate the learning.","Our model, Satellite Neural Graphics Primitives (SAT-NGP) decreases the learning time to 15 minutes while maintaining the quality of the 3D reconstruction."],"url":"http://arxiv.org/abs/2403.18711v1","category":"cs.CV"}
{"created":"2024-03-27 15:48:35","title":"Collective excitations in competing phases in two and three dimensions","abstract":"We investigate the superconducting (SC), charge-density wave (CDW), and antiferromagnetic (AFM) phases in the extended Hubbard model at zero temperature and half-filling. We employ the iterated equations of motion approach to compute the two-particle Green's functions and their spectral densities. This renders a comprehensive analysis of the behavior of collective excitations possible as the model's parameters are tuned across phase transitions. We identify the well-known amplitude (Higgs) and phase (Anderson-Bogoliubov) modes within the superconducting phase and observe a similar excitation (cooperon) in the CDW phase which shifts towards zero energy as the system approaches the phase transition to the SC phase. In the CDW phase, close to the phase transition to the AFM phase, we find a collective mode, an exciton, that does not change significantly and another mode, a longitudinal magnon, that emerges from the two-particle continuum as the system approaches the phase transition to the AFM phase. It becomes identical with the former at the transition. In the AFM phase, their roles are reversed. Additionally, we find a transversal Goldstone magnon located at zero energy.","sentences":["We investigate the superconducting (SC), charge-density wave (CDW), and antiferromagnetic (AFM) phases in the extended Hubbard model at zero temperature and half-filling.","We employ the iterated equations of motion approach to compute the two-particle Green's functions and their spectral densities.","This renders a comprehensive analysis of the behavior of collective excitations possible as the model's parameters are tuned across phase transitions.","We identify the well-known amplitude (Higgs) and phase (Anderson-Bogoliubov) modes within the superconducting phase and observe a similar excitation (cooperon) in the CDW phase which shifts towards zero energy as the system approaches the phase transition to the SC phase.","In the CDW phase, close to the phase transition to the AFM phase, we find a collective mode, an exciton, that does not change significantly and another mode, a longitudinal magnon, that emerges from the two-particle continuum as the system approaches the phase transition to the AFM phase.","It becomes identical with the former at the transition.","In the AFM phase, their roles are reversed.","Additionally, we find a transversal Goldstone magnon located at zero energy."],"url":"http://arxiv.org/abs/2403.18701v1","category":"cond-mat.str-el"}
{"created":"2024-03-27 15:48:16","title":"Contrastive Learning with Orthonormal Anchors (CLOA)","abstract":"This study focuses on addressing the instability issues prevalent in contrastive learning, specifically examining the InfoNCE loss function and its derivatives. We reveal a critical observation that these loss functions exhibit a restrictive behavior, leading to a convergence phenomenon where embeddings tend to merge into a singular point. This \"over-fusion\" effect detrimentally affects classification accuracy in subsequent supervised-learning tasks. Through theoretical analysis, we demonstrate that embeddings, when equalized or confined to a rank-1 linear subspace, represent a local minimum for InfoNCE. In response to this challenge, our research introduces an innovative strategy that leverages the same or fewer labeled data than typically used in the fine-tuning phase. The loss we proposed, Orthonormal Anchor Regression Loss, is designed to disentangle embedding clusters, significantly enhancing the distinctiveness of each embedding while simultaneously ensuring their aggregation into dense, well-defined clusters. Our method demonstrates remarkable improvements with just a fraction of the conventional label requirements, as evidenced by our results on CIFAR10 and CIFAR100 datasets.","sentences":["This study focuses on addressing the instability issues prevalent in contrastive learning, specifically examining the InfoNCE loss function and its derivatives.","We reveal a critical observation that these loss functions exhibit a restrictive behavior, leading to a convergence phenomenon where embeddings tend to merge into a singular point.","This \"over-fusion\" effect detrimentally affects classification accuracy in subsequent supervised-learning tasks.","Through theoretical analysis, we demonstrate that embeddings, when equalized or confined to a rank-1 linear subspace, represent a local minimum for InfoNCE.","In response to this challenge, our research introduces an innovative strategy that leverages the same or fewer labeled data than typically used in the fine-tuning phase.","The loss we proposed, Orthonormal Anchor Regression Loss, is designed to disentangle embedding clusters, significantly enhancing the distinctiveness of each embedding while simultaneously ensuring their aggregation into dense, well-defined clusters.","Our method demonstrates remarkable improvements with just a fraction of the conventional label requirements, as evidenced by our results on CIFAR10 and CIFAR100 datasets."],"url":"http://arxiv.org/abs/2403.18699v1","category":"cs.LG"}
{"created":"2024-03-27 15:41:23","title":"Annolid: Annotate, Segment, and Track Anything You Need","abstract":"Annolid is a deep learning-based software package designed for the segmentation, labeling, and tracking of research targets within video files, focusing primarily on animal behavior analysis. Based on state-of-the-art instance segmentation methods, Annolid now harnesses the Cutie video object segmentation model to achieve resilient, markerless tracking of multiple animals from single annotated frames, even in environments in which they may be partially or entirely concealed by environmental features or by one another. Our integration of Segment Anything and Grounding-DINO strategies additionally enables the automatic masking and segmentation of recognizable animals and objects by text command, removing the need for manual annotation. Annolid's comprehensive approach to object segmentation flexibly accommodates a broad spectrum of behavior analysis applications, enabling the classification of diverse behavioral states such as freezing, digging, pup huddling, and social interactions in addition to the tracking of animals and their body parts.","sentences":["Annolid is a deep learning-based software package designed for the segmentation, labeling, and tracking of research targets within video files, focusing primarily on animal behavior analysis.","Based on state-of-the-art instance segmentation methods, Annolid now harnesses the Cutie video object segmentation model to achieve resilient, markerless tracking of multiple animals from single annotated frames, even in environments in which they may be partially or entirely concealed by environmental features or by one another.","Our integration of Segment Anything and Grounding-DINO strategies additionally enables the automatic masking and segmentation of recognizable animals and objects by text command, removing the need for manual annotation.","Annolid's comprehensive approach to object segmentation flexibly accommodates a broad spectrum of behavior analysis applications, enabling the classification of diverse behavioral states such as freezing, digging, pup huddling, and social interactions in addition to the tracking of animals and their body parts."],"url":"http://arxiv.org/abs/2403.18690v1","category":"cs.CV"}
{"created":"2024-03-27 15:24:54","title":"TransFusion: Contrastive Learning with Transformers","abstract":"This paper proposes a novel framework, TransFusion, designed to make the process of contrastive learning more analytical and explainable. TransFusion consists of attention blocks whose softmax being replaced by ReLU, and its final block's weighted-sum operation is truncated to leave the adjacency matrix as the output. The model is trained by minimizing the Jensen-Shannon Divergence between its output and the target affinity matrix, which indicates whether each pair of samples belongs to the same or different classes. The main contribution of TransFusion lies in defining a theoretical limit for answering two fundamental questions in the field: the maximum level of data augmentation and the minimum batch size required for effective contrastive learning. Furthermore, experimental results indicate that TransFusion successfully extracts features that isolate clusters from complex real-world data, leading to improved classification accuracy in downstream tasks.","sentences":["This paper proposes a novel framework, TransFusion, designed to make the process of contrastive learning more analytical and explainable.","TransFusion consists of attention blocks whose softmax being replaced by ReLU, and its final block's weighted-sum operation is truncated to leave the adjacency matrix as the output.","The model is trained by minimizing the Jensen-Shannon Divergence between its output and the target affinity matrix, which indicates whether each pair of samples belongs to the same or different classes.","The main contribution of TransFusion lies in defining a theoretical limit for answering two fundamental questions in the field: the maximum level of data augmentation and the minimum batch size required for effective contrastive learning.","Furthermore, experimental results indicate that TransFusion successfully extracts features that isolate clusters from complex real-world data, leading to improved classification accuracy in downstream tasks."],"url":"http://arxiv.org/abs/2403.18681v1","category":"cs.LG"}
{"created":"2024-03-27 15:21:58","title":"An Exploratory Study on Upper-Level Computing Students' Use of Large Language Models as Tools in a Semester-Long Project","abstract":"Background: Large Language Models (LLMs) such as ChatGPT and CoPilot are influencing software engineering practice. Software engineering educators must teach future software engineers how to use such tools well. As of yet, there have been few studies that report on the use of LLMs in the classroom. It is, therefore, important to evaluate students' perception of LLMs and possible ways of adapting the computing curriculum to these shifting paradigms.   Purpose: The purpose of this study is to explore computing students' experiences and approaches to using LLMs during a semester-long software engineering project.   Design/Method: We collected data from a senior-level software engineering course at Purdue University. This course uses a project-based learning (PBL) design. The students used LLMs such as ChatGPT and Copilot in their projects. A sample of these student teams were interviewed to understand (1) how they used LLMs in their projects; and (2) whether and how their perspectives on LLMs changed over the course of the semester. We analyzed the data to identify themes related to students' usage patterns and learning outcomes.   Results/Discussion: When computing students utilize LLMs within a project, their use cases cover both technical and professional applications. In addition, these students perceive LLMs to be efficient tools in obtaining information and completion of tasks. However, there were concerns about the responsible use of LLMs without being detrimental to their own learning outcomes. Based on our findings, we recommend future research to investigate the usage of LLM's in lower-level computer engineering courses to understand whether and how LLMs can be integrated as a learning aid without hurting the learning outcomes.","sentences":["Background: Large Language Models (LLMs) such as ChatGPT and CoPilot are influencing software engineering practice.","Software engineering educators must teach future software engineers how to use such tools well.","As of yet, there have been few studies that report on the use of LLMs in the classroom.","It is, therefore, important to evaluate students' perception of LLMs and possible ways of adapting the computing curriculum to these shifting paradigms.   ","Purpose: The purpose of this study is to explore computing students' experiences and approaches to using LLMs during a semester-long software engineering project.   ","Design/Method: We collected data from a senior-level software engineering course at Purdue University.","This course uses a project-based learning (PBL) design.","The students used LLMs such as ChatGPT and Copilot in their projects.","A sample of these student teams were interviewed to understand (1) how they used LLMs in their projects; and (2) whether and how their perspectives on LLMs changed over the course of the semester.","We analyzed the data to identify themes related to students' usage patterns and learning outcomes.   ","Results/Discussion: When computing students utilize LLMs within a project, their use cases cover both technical and professional applications.","In addition, these students perceive LLMs to be efficient tools in obtaining information and completion of tasks.","However, there were concerns about the responsible use of LLMs without being detrimental to their own learning outcomes.","Based on our findings, we recommend future research to investigate the usage of LLM's in lower-level computer engineering courses to understand whether and how LLMs can be integrated as a learning aid without hurting the learning outcomes."],"url":"http://arxiv.org/abs/2403.18679v1","category":"cs.SE"}
{"created":"2024-03-27 15:17:10","title":"Deep Learning for Robust and Explainable Models in Computer Vision","abstract":"Recent breakthroughs in machine and deep learning (ML and DL) research have provided excellent tools for leveraging enormous amounts of data and optimizing huge models with millions of parameters to obtain accurate networks for image processing. These developments open up tremendous opportunities for using artificial intelligence (AI) in the automation and human assisted AI industry. However, as more and more models are deployed and used in practice, many challenges have emerged. This thesis presents various approaches that address robustness and explainability challenges for using ML and DL in practice.   Robustness and reliability are the critical components of any model before certification and deployment in practice. Deep convolutional neural networks (CNNs) exhibit vulnerability to transformations of their inputs, such as rotation and scaling, or intentional manipulations as described in the adversarial attack literature. In addition, building trust in AI-based models requires a better understanding of current models and developing methods that are more explainable and interpretable a priori.   This thesis presents developments in computer vision models' robustness and explainability. Furthermore, this thesis offers an example of using vision models' feature response visualization (models' interpretations) to improve robustness despite interpretability and robustness being seemingly unrelated in the related research. Besides methodological developments for robust and explainable vision models, a key message of this thesis is introducing model interpretation techniques as a tool for understanding vision models and improving their design and robustness. In addition to the theoretical developments, this thesis demonstrates several applications of ML and DL in different contexts, such as medical imaging and affective computing.","sentences":["Recent breakthroughs in machine and deep learning (ML and DL) research have provided excellent tools for leveraging enormous amounts of data and optimizing huge models with millions of parameters to obtain accurate networks for image processing.","These developments open up tremendous opportunities for using artificial intelligence (AI) in the automation and human assisted AI industry.","However, as more and more models are deployed and used in practice, many challenges have emerged.","This thesis presents various approaches that address robustness and explainability challenges for using ML and DL in practice.   ","Robustness and reliability are the critical components of any model before certification and deployment in practice.","Deep convolutional neural networks (CNNs) exhibit vulnerability to transformations of their inputs, such as rotation and scaling, or intentional manipulations as described in the adversarial attack literature.","In addition, building trust in AI-based models requires a better understanding of current models and developing methods that are more explainable and interpretable a priori.   ","This thesis presents developments in computer vision models' robustness and explainability.","Furthermore, this thesis offers an example of using vision models' feature response visualization (models' interpretations) to improve robustness despite interpretability and robustness being seemingly unrelated in the related research.","Besides methodological developments for robust and explainable vision models, a key message of this thesis is introducing model interpretation techniques as a tool for understanding vision models and improving their design and robustness.","In addition to the theoretical developments, this thesis demonstrates several applications of ML and DL in different contexts, such as medical imaging and affective computing."],"url":"http://arxiv.org/abs/2403.18674v1","category":"cs.CV"}
{"created":"2024-03-27 15:11:07","title":"Aiming for Relevance","abstract":"Vital signs are crucial in intensive care units (ICUs). They are used to track the patient's state and to identify clinically significant changes. Predicting vital sign trajectories is valuable for early detection of adverse events. However, conventional machine learning metrics like RMSE often fail to capture the true clinical relevance of such predictions. We introduce novel vital sign prediction performance metrics that align with clinical contexts, focusing on deviations from clinical norms, overall trends, and trend deviations. These metrics are derived from empirical utility curves obtained in a previous study through interviews with ICU clinicians. We validate the metrics' usefulness using simulated and real clinical datasets (MIMIC and eICU). Furthermore, we employ these metrics as loss functions for neural networks, resulting in models that excel in predicting clinically significant events. This research paves the way for clinically relevant machine learning model evaluation and optimization, promising to improve ICU patient care. 10 pages, 9 figures.","sentences":["Vital signs are crucial in intensive care units (ICUs).","They are used to track the patient's state and to identify clinically significant changes.","Predicting vital sign trajectories is valuable for early detection of adverse events.","However, conventional machine learning metrics like RMSE often fail to capture the true clinical relevance of such predictions.","We introduce novel vital sign prediction performance metrics that align with clinical contexts, focusing on deviations from clinical norms, overall trends, and trend deviations.","These metrics are derived from empirical utility curves obtained in a previous study through interviews with ICU clinicians.","We validate the metrics' usefulness using simulated and real clinical datasets (MIMIC and eICU).","Furthermore, we employ these metrics as loss functions for neural networks, resulting in models that excel in predicting clinically significant events.","This research paves the way for clinically relevant machine learning model evaluation and optimization, promising to improve ICU patient care.","10 pages, 9 figures."],"url":"http://arxiv.org/abs/2403.18668v1","category":"cs.LG"}
{"created":"2024-03-27 15:03:33","title":"INEXA: Interactive and Explainable Process Model Abstraction Through Object-Centric Process Mining","abstract":"Process events are recorded by multiple information systems at different granularity levels. Based on the resulting event logs, process models are discovered at different granularity levels, as well. Events stored at a fine-grained granularity level, for example, may hinder the discovered process model to be displayed due the high number of resulting model elements. The discovered process model of a real-world manufacturing process, for example, consists of 1,489 model elements and over 2,000 arcs. Existing process model abstraction techniques could help reducing the size of the model, but would disconnect it from the underlying event log. Existing event abstraction techniques do neither support the analysis of mixed granularity levels, nor interactive exploration of a suitable granularity level. To enable the exploration of discovered process models at different granularity levels, we propose INEXA, an interactive, explainable process model abstraction method that keeps the link to the event log. As a starting point, INEXA aggregates large process models to a \"displayable\" size, e.g., for the manufacturing use case to a process model with 58 model elements. Then, the process analyst can explore granularity levels interactively, while applied abstractions are automatically traced in the event log for explainability.","sentences":["Process events are recorded by multiple information systems at different granularity levels.","Based on the resulting event logs, process models are discovered at different granularity levels, as well.","Events stored at a fine-grained granularity level, for example, may hinder the discovered process model to be displayed due the high number of resulting model elements.","The discovered process model of a real-world manufacturing process, for example, consists of 1,489 model elements and over 2,000 arcs.","Existing process model abstraction techniques could help reducing the size of the model, but would disconnect it from the underlying event log.","Existing event abstraction techniques do neither support the analysis of mixed granularity levels, nor interactive exploration of a suitable granularity level.","To enable the exploration of discovered process models at different granularity levels, we propose INEXA, an interactive, explainable process model abstraction method that keeps the link to the event log.","As a starting point, INEXA aggregates large process models to a \"displayable\" size, e.g., for the manufacturing use case to a process model with 58 model elements.","Then, the process analyst can explore granularity levels interactively, while applied abstractions are automatically traced in the event log for explainability."],"url":"http://arxiv.org/abs/2403.18659v1","category":"cs.AI"}
{"created":"2024-03-27 14:56:44","title":"Addressing Data Annotation Challenges in Multiple Sensors: A Solution for Scania Collected Datasets","abstract":"Data annotation in autonomous vehicles is a critical step in the development of Deep Neural Network (DNN) based models or the performance evaluation of the perception system. This often takes the form of adding 3D bounding boxes on time-sequential and registered series of point-sets captured from active sensors like Light Detection and Ranging (LiDAR) and Radio Detection and Ranging (RADAR). When annotating multiple active sensors, there is a need to motion compensate and translate the points to a consistent coordinate frame and timestamp respectively. However, highly dynamic objects pose a unique challenge, as they can appear at different timestamps in each sensor's data. Without knowing the speed of the objects, their position appears to be different in different sensor outputs. Thus, even after motion compensation, highly dynamic objects are not matched from multiple sensors in the same frame, and human annotators struggle to add unique bounding boxes that capture all objects. This article focuses on addressing this challenge, primarily within the context of Scania collected datasets. The proposed solution takes a track of an annotated object as input and uses the Moving Horizon Estimation (MHE) to robustly estimate its speed. The estimated speed profile is utilized to correct the position of the annotated box and add boxes to object clusters missed by the original annotation.","sentences":["Data annotation in autonomous vehicles is a critical step in the development of Deep Neural Network (DNN) based models or the performance evaluation of the perception system.","This often takes the form of adding 3D bounding boxes on time-sequential and registered series of point-sets captured from active sensors like Light Detection and Ranging (LiDAR) and Radio Detection and Ranging (RADAR).","When annotating multiple active sensors, there is a need to motion compensate and translate the points to a consistent coordinate frame and timestamp respectively.","However, highly dynamic objects pose a unique challenge, as they can appear at different timestamps in each sensor's data.","Without knowing the speed of the objects, their position appears to be different in different sensor outputs.","Thus, even after motion compensation, highly dynamic objects are not matched from multiple sensors in the same frame, and human annotators struggle to add unique bounding boxes that capture all objects.","This article focuses on addressing this challenge, primarily within the context of Scania collected datasets.","The proposed solution takes a track of an annotated object as input and uses the Moving Horizon Estimation (MHE) to robustly estimate its speed.","The estimated speed profile is utilized to correct the position of the annotated box and add boxes to object clusters missed by the original annotation."],"url":"http://arxiv.org/abs/2403.18649v1","category":"cs.CV"}
{"created":"2024-03-27 14:46:54","title":"Sampling-Based Motion Planning with Online Racing Line Generation for Autonomous Driving on Three-Dimensional Race Tracks","abstract":"Existing approaches to trajectory planning for autonomous racing employ sampling-based methods, generating numerous jerk-optimal trajectories and selecting the most favorable feasible trajectory based on a cost function penalizing deviations from an offline-calculated racing line. While successful on oval tracks, these methods face limitations on complex circuits due to the simplistic geometry of jerk-optimal edges failing to capture the complexity of the racing line. Additionally, they only consider two-dimensional tracks, potentially neglecting or surpassing the actual dynamic potential. In this paper, we present a sampling-based local trajectory planning approach for autonomous racing that can maintain the lap time of the racing line even on complex race tracks and consider the race track's three-dimensional effects. In simulative experiments, we demonstrate that our approach achieves lower lap times and improved utilization of dynamic limits compared to existing approaches. We also investigate the impact of online racing line generation, in which the time-optimal solution is planned from the current vehicle state for a limited spatial horizon, in contrast to a closed racing line calculated offline. We show that combining the sampling-based planner with the online racing line generation can significantly reduce lap times in multi-vehicle scenarios.","sentences":["Existing approaches to trajectory planning for autonomous racing employ sampling-based methods, generating numerous jerk-optimal trajectories and selecting the most favorable feasible trajectory based on a cost function penalizing deviations from an offline-calculated racing line.","While successful on oval tracks, these methods face limitations on complex circuits due to the simplistic geometry of jerk-optimal edges failing to capture the complexity of the racing line.","Additionally, they only consider two-dimensional tracks, potentially neglecting or surpassing the actual dynamic potential.","In this paper, we present a sampling-based local trajectory planning approach for autonomous racing that can maintain the lap time of the racing line even on complex race tracks and consider the race track's three-dimensional effects.","In simulative experiments, we demonstrate that our approach achieves lower lap times and improved utilization of dynamic limits compared to existing approaches.","We also investigate the impact of online racing line generation, in which the time-optimal solution is planned from the current vehicle state for a limited spatial horizon, in contrast to a closed racing line calculated offline.","We show that combining the sampling-based planner with the online racing line generation can significantly reduce lap times in multi-vehicle scenarios."],"url":"http://arxiv.org/abs/2403.18643v1","category":"cs.RO"}
{"created":"2024-03-27 14:45:43","title":"Collective schedules: axioms and algorithms","abstract":"The collective schedules problem consists in computing a schedule of tasks shared between individuals. Tasks may have different duration, and individuals have preferences over the order of the shared tasks. This problem has numerous applications since tasks may model public infrastructure projects, events taking place in a shared room, or work done by co-workers. Our aim is, given the preferred schedules of individuals (voters), to return a consensus schedule. We propose an axiomatic study of the collective schedule problem, by using classic axioms in computational social choice and new axioms that take into account the duration of the tasks. We show that some axioms are incompatible, and we study the axioms fulfilled by three rules: one which has been studied in the seminal paper on collective schedules (Pascual et al. 2018), one which generalizes the Kemeny rule, and one which generalizes Spearman's footrule. From an algorithmic point of view, we show that these rules solve NP-hard problems, but that it is possible to solve optimally these problems for small but realistic size instances, and we give an efficient heuristic for large instances. We conclude this paper with experiments.","sentences":["The collective schedules problem consists in computing a schedule of tasks shared between individuals.","Tasks may have different duration, and individuals have preferences over the order of the shared tasks.","This problem has numerous applications since tasks may model public infrastructure projects, events taking place in a shared room, or work done by co-workers.","Our aim is, given the preferred schedules of individuals (voters), to return a consensus schedule.","We propose an axiomatic study of the collective schedule problem, by using classic axioms in computational social choice and new axioms that take into account the duration of the tasks.","We show that some axioms are incompatible, and we study the axioms fulfilled by three rules: one which has been studied in the seminal paper on collective schedules (Pascual et al. 2018), one which generalizes the Kemeny rule, and one which generalizes Spearman's footrule.","From an algorithmic point of view, we show that these rules solve NP-hard problems, but that it is possible to solve optimally these problems for small but realistic size instances, and we give an efficient heuristic for large instances.","We conclude this paper with experiments."],"url":"http://arxiv.org/abs/2403.18642v1","category":"cs.GT"}
{"created":"2024-03-27 14:28:44","title":"Scalable Lipschitz Estimation for CNNs","abstract":"Estimating the Lipschitz constant of deep neural networks is of growing interest as it is useful for informing on generalisability and adversarial robustness. Convolutional neural networks (CNNs) in particular, underpin much of the recent success in computer vision related applications. However, although existing methods for estimating the Lipschitz constant can be tight, they have limited scalability when applied to CNNs. To tackle this, we propose a novel method to accelerate Lipschitz constant estimation for CNNs. The core idea is to divide a large convolutional block via a joint layer and width-wise partition, into a collection of smaller blocks. We prove an upper-bound on the Lipschitz constant of the larger block in terms of the Lipschitz constants of the smaller blocks. Through varying the partition factor, the resulting method can be adjusted to prioritise either accuracy or scalability and permits parallelisation. We demonstrate an enhanced scalability and comparable accuracy to existing baselines through a range of experiments.","sentences":["Estimating the Lipschitz constant of deep neural networks is of growing interest as it is useful for informing on generalisability and adversarial robustness.","Convolutional neural networks (CNNs) in particular, underpin much of the recent success in computer vision related applications.","However, although existing methods for estimating the Lipschitz constant can be tight, they have limited scalability when applied to CNNs.","To tackle this, we propose a novel method to accelerate Lipschitz constant estimation for CNNs.","The core idea is to divide a large convolutional block via a joint layer and width-wise partition, into a collection of smaller blocks.","We prove an upper-bound on the Lipschitz constant of the larger block in terms of the Lipschitz constants of the smaller blocks.","Through varying the partition factor, the resulting method can be adjusted to prioritise either accuracy or scalability and permits parallelisation.","We demonstrate an enhanced scalability and comparable accuracy to existing baselines through a range of experiments."],"url":"http://arxiv.org/abs/2403.18613v1","category":"cs.LG"}
{"created":"2024-03-27 14:26:44","title":"Cavity Detection of Gravitational Waves: Where Do We Stand?","abstract":"High frequency gravitational waves (HFGWs) are predicted in various exotic scenarios involving both cosmological and astrophysical sources. These elusive signals have recently sparked the interest of a diverse community of researchers, due to the possibility of HFGW detection in the laboratory through graviton-photon conversion in strong magnetic fields. Notable examples include the redesign of the resonant cavities currently under development to detect the cosmic axion. In this work, we derive the sensitivities of some existing and planned resonant cavities to detect a HFGW background. As a concrete scenario, we consider the collective signals that originate from the merging of compact objects, such as two primordial black holes (PBHs) in the asteroid mass window. Our findings improve over existing work by explicitly discussing and quantifying the loss in the experimental reach due to the actual coherence of the source. We elucidate on the approach we adopt in relation with recent literature on the topic. Most notably, we give a recipe for the estimate of the stochastic background that focuses on the presence of the signal in the cavity at all times and showing that, in the relevant PBH mass region, the signal is dominated by coherent binary mergers.","sentences":["High frequency gravitational waves (HFGWs) are predicted in various exotic scenarios involving both cosmological and astrophysical sources.","These elusive signals have recently sparked the interest of a diverse community of researchers, due to the possibility of HFGW detection in the laboratory through graviton-photon conversion in strong magnetic fields.","Notable examples include the redesign of the resonant cavities currently under development to detect the cosmic axion.","In this work, we derive the sensitivities of some existing and planned resonant cavities to detect a HFGW background.","As a concrete scenario, we consider the collective signals that originate from the merging of compact objects, such as two primordial black holes (PBHs) in the asteroid mass window.","Our findings improve over existing work by explicitly discussing and quantifying the loss in the experimental reach due to the actual coherence of the source.","We elucidate on the approach we adopt in relation with recent literature on the topic.","Most notably, we give a recipe for the estimate of the stochastic background that focuses on the presence of the signal in the cavity at all times and showing that, in the relevant PBH mass region, the signal is dominated by coherent binary mergers."],"url":"http://arxiv.org/abs/2403.18610v1","category":"gr-qc"}
{"created":"2024-03-27 14:25:02","title":"Spikewhisper: Temporal Spike Backdoor Attacks on Federated Neuromorphic Learning over Low-power Devices","abstract":"Federated neuromorphic learning (FedNL) leverages event-driven spiking neural networks and federated learning frameworks to effectively execute intelligent analysis tasks over amounts of distributed low-power devices but also perform vulnerability to poisoning attacks. The threat of backdoor attacks on traditional deep neural networks typically comes from time-invariant data. However, in FedNL, unknown threats may be hidden in time-varying spike signals. In this paper, we start to explore a novel vulnerability of FedNL-based systems with the concept of time division multiplexing, termed Spikewhisper, which allows attackers to evade detection as much as possible, as multiple malicious clients can imperceptibly poison with different triggers at different timeslices. In particular, the stealthiness of Spikewhisper is derived from the time-domain divisibility of global triggers, in which each malicious client pastes only one local trigger to a certain timeslice in the neuromorphic sample, and also the polarity and motion of each local trigger can be configured by attackers. Extensive experiments based on two different neuromorphic datasets demonstrate that the attack success rate of Spikewispher is higher than the temporally centralized attacks. Besides, it is validated that the effect of Spikewispher is sensitive to the trigger duration.","sentences":["Federated neuromorphic learning (FedNL) leverages event-driven spiking neural networks and federated learning frameworks to effectively execute intelligent analysis tasks over amounts of distributed low-power devices but also perform vulnerability to poisoning attacks.","The threat of backdoor attacks on traditional deep neural networks typically comes from time-invariant data.","However, in FedNL, unknown threats may be hidden in time-varying spike signals.","In this paper, we start to explore a novel vulnerability of FedNL-based systems with the concept of time division multiplexing, termed Spikewhisper, which allows attackers to evade detection as much as possible, as multiple malicious clients can imperceptibly poison with different triggers at different timeslices.","In particular, the stealthiness of Spikewhisper is derived from the time-domain divisibility of global triggers, in which each malicious client pastes only one local trigger to a certain timeslice in the neuromorphic sample, and also the polarity and motion of each local trigger can be configured by attackers.","Extensive experiments based on two different neuromorphic datasets demonstrate that the attack success rate of Spikewispher is higher than the temporally centralized attacks.","Besides, it is validated that the effect of Spikewispher is sensitive to the trigger duration."],"url":"http://arxiv.org/abs/2403.18607v1","category":"cs.CR"}
{"created":"2024-03-27 14:22:40","title":"RAP: Retrieval-Augmented Planner for Adaptive Procedure Planning in Instructional Videos","abstract":"Procedure Planning in instructional videos entails generating a sequence of action steps based on visual observations of the initial and target states. Despite the rapid progress in this task, there remain several critical challenges to be solved: (1) Adaptive procedures: Prior works hold an unrealistic assumption that the number of action steps is known and fixed, leading to non-generalizable models in real-world scenarios where the sequence length varies. (2) Temporal relation: Understanding the step temporal relation knowledge is essential in producing reasonable and executable plans. (3) Annotation cost: Annotating instructional videos with step-level labels (i.e., timestamp) or sequence-level labels (i.e., action category) is demanding and labor-intensive, limiting its generalizability to large-scale datasets.In this work, we propose a new and practical setting, called adaptive procedure planning in instructional videos, where the procedure length is not fixed or pre-determined. To address these challenges we introduce Retrieval-Augmented Planner (RAP) model. Specifically, for adaptive procedures, RAP adaptively determines the conclusion of actions using an auto-regressive model architecture. For temporal relation, RAP establishes an external memory module to explicitly retrieve the most relevant state-action pairs from the training videos and revises the generated procedures. To tackle high annotation cost, RAP utilizes a weakly-supervised learning manner to expand the training dataset to other task-relevant, unannotated videos by generating pseudo labels for action steps. Experiments on CrossTask and COIN benchmarks show the superiority of RAP over traditional fixed-length models, establishing it as a strong baseline solution for adaptive procedure planning.","sentences":["Procedure Planning in instructional videos entails generating a sequence of action steps based on visual observations of the initial and target states.","Despite the rapid progress in this task, there remain several critical challenges to be solved: (1) Adaptive procedures: Prior works hold an unrealistic assumption that the number of action steps is known and fixed, leading to non-generalizable models in real-world scenarios where the sequence length varies.","(2) Temporal relation: Understanding the step temporal relation knowledge is essential in producing reasonable and executable plans.","(3) Annotation cost: Annotating instructional videos with step-level labels (i.e., timestamp) or sequence-level labels (i.e., action category) is demanding and labor-intensive, limiting its generalizability to large-scale datasets.","In this work, we propose a new and practical setting, called adaptive procedure planning in instructional videos, where the procedure length is not fixed or pre-determined.","To address these challenges we introduce Retrieval-Augmented Planner (RAP) model.","Specifically, for adaptive procedures, RAP adaptively determines the conclusion of actions using an auto-regressive model architecture.","For temporal relation, RAP establishes an external memory module to explicitly retrieve the most relevant state-action pairs from the training videos and revises the generated procedures.","To tackle high annotation cost, RAP utilizes a weakly-supervised learning manner to expand the training dataset to other task-relevant, unannotated videos by generating pseudo labels for action steps.","Experiments on CrossTask and COIN benchmarks show the superiority of RAP over traditional fixed-length models, establishing it as a strong baseline solution for adaptive procedure planning."],"url":"http://arxiv.org/abs/2403.18600v1","category":"cs.CV"}
{"created":"2024-03-27 14:18:09","title":"Homogeneous Tokenizer Matters: Homogeneous Visual Tokenizer for Remote Sensing Image Understanding","abstract":"The tokenizer, as one of the fundamental components of large models, has long been overlooked or even misunderstood in visual tasks. One key factor of the great comprehension power of the large language model is that natural language tokenizers utilize meaningful words or subwords as the basic elements of language. In contrast, mainstream visual tokenizers, represented by patch-based methods such as Patch Embed, rely on meaningless rectangular patches as basic elements of vision, which cannot serve as effectively as words or subwords in language. Starting from the essence of the tokenizer, we defined semantically independent regions (SIRs) for vision. We designed a simple HOmogeneous visual tOKenizer: HOOK. HOOK mainly consists of two modules: the Object Perception Module (OPM) and the Object Vectorization Module (OVM). To achieve homogeneity, the OPM splits the image into 4*4 pixel seeds and then utilizes the attention mechanism to perceive SIRs. The OVM employs cross-attention to merge seeds within the same SIR. To achieve adaptability, the OVM defines a variable number of learnable vectors as cross-attention queries, allowing for the adjustment of token quantity. We conducted experiments on the NWPU-RESISC45, WHU-RS19 classification dataset, and GID5 segmentation dataset for sparse and dense tasks. The results demonstrate that the visual tokens obtained by HOOK correspond to individual objects, which demonstrates homogeneity. HOOK outperformed Patch Embed by 6\\% and 10\\% in the two tasks and achieved state-of-the-art performance compared to the baselines used for comparison. Compared to Patch Embed, which requires more than one hundred tokens for one image, HOOK requires only 6 and 8 tokens for sparse and dense tasks, respectively, resulting in efficiency improvements of 1.5 to 2.8 times. The code is available at https://github.com/GeoX-Lab/Hook.","sentences":["The tokenizer, as one of the fundamental components of large models, has long been overlooked or even misunderstood in visual tasks.","One key factor of the great comprehension power of the large language model is that natural language tokenizers utilize meaningful words or subwords as the basic elements of language.","In contrast, mainstream visual tokenizers, represented by patch-based methods such as Patch Embed, rely on meaningless rectangular patches as basic elements of vision, which cannot serve as effectively as words or subwords in language.","Starting from the essence of the tokenizer, we defined semantically independent regions (SIRs) for vision.","We designed a simple HOmogeneous visual tOKenizer: HOOK.","HOOK mainly consists of two modules: the Object Perception Module (OPM) and the Object Vectorization Module (OVM).","To achieve homogeneity, the OPM splits the image into 4*4 pixel seeds and then utilizes the attention mechanism to perceive SIRs.","The OVM employs cross-attention to merge seeds within the same SIR.","To achieve adaptability, the OVM defines a variable number of learnable vectors as cross-attention queries, allowing for the adjustment of token quantity.","We conducted experiments on the NWPU-RESISC45, WHU-RS19 classification dataset, and GID5 segmentation dataset for sparse and dense tasks.","The results demonstrate that the visual tokens obtained by HOOK correspond to individual objects, which demonstrates homogeneity.","HOOK outperformed Patch Embed by 6\\% and 10\\% in the two tasks and achieved state-of-the-art performance compared to the baselines used for comparison.","Compared to Patch Embed, which requires more than one hundred tokens for one image, HOOK requires only 6 and 8 tokens for sparse and dense tasks, respectively, resulting in efficiency improvements of 1.5 to 2.8 times.","The code is available at https://github.com/GeoX-Lab/Hook."],"url":"http://arxiv.org/abs/2403.18593v1","category":"cs.CV"}
{"created":"2024-03-27 13:59:09","title":"On Optimizing Hyperparameters for Quantum Neural Networks","abstract":"The increasing capabilities of Machine Learning (ML) models go hand in hand with an immense amount of data and computational power required for training. Therefore, training is usually outsourced into HPC facilities, where we have started to experience limits in scaling conventional HPC hardware, as theorized by Moore's law. Despite heavy parallelization and optimization efforts, current state-of-the-art ML models require weeks for training, which is associated with an enormous $CO_2$ footprint. Quantum Computing, and specifically Quantum Machine Learning (QML), can offer significant theoretical speed-ups and enhanced expressive power. However, training QML models requires tuning various hyperparameters, which is a nontrivial task and suboptimal choices can highly affect the trainability and performance of the models. In this study, we identify the most impactful hyperparameters and collect data about the performance of QML models. We compare different configurations and provide researchers with performance data and concrete suggestions for hyperparameter selection.","sentences":["The increasing capabilities of Machine Learning (ML) models go hand in hand with an immense amount of data and computational power required for training.","Therefore, training is usually outsourced into HPC facilities, where we have started to experience limits in scaling conventional HPC hardware, as theorized by Moore's law.","Despite heavy parallelization and optimization efforts, current state-of-the-art ML models require weeks for training, which is associated with an enormous $CO_2$ footprint.","Quantum Computing, and specifically Quantum Machine Learning (QML), can offer significant theoretical speed-ups and enhanced expressive power.","However, training QML models requires tuning various hyperparameters, which is a nontrivial task and suboptimal choices can highly affect the trainability and performance of the models.","In this study, we identify the most impactful hyperparameters and collect data about the performance of QML models.","We compare different configurations and provide researchers with performance data and concrete suggestions for hyperparameter selection."],"url":"http://arxiv.org/abs/2403.18579v1","category":"cs.LG"}
{"created":"2024-03-27 13:51:26","title":"Physics-Informed Graph Neural Networks for Water Distribution Systems","abstract":"Water distribution systems (WDS) are an integral part of critical infrastructure which is pivotal to urban development. As 70% of the world's population will likely live in urban environments in 2050, efficient simulation and planning tools for WDS play a crucial role in reaching UN's sustainable developmental goal (SDG) 6 - \"Clean water and sanitation for all\". In this realm, we propose a novel and efficient machine learning emulator, more precisely, a physics-informed deep learning (DL) model, for hydraulic state estimation in WDS. Using a recursive approach, our model only needs a few graph convolutional neural network (GCN) layers and employs an innovative algorithm based on message passing. Unlike conventional machine learning tasks, the model uses hydraulic principles to infer two additional hydraulic state features in the process of reconstructing the available ground truth feature in an unsupervised manner. To the best of our knowledge, this is the first DL approach to emulate the popular hydraulic simulator EPANET, utilizing no additional information. Like most DL models and unlike the hydraulic simulator, our model demonstrates vastly faster emulation times that do not increase drastically with the size of the WDS. Moreover, we achieve high accuracy on the ground truth and very similar results compared to the hydraulic simulator as demonstrated through experiments on five real-world WDS datasets.","sentences":["Water distribution systems (WDS) are an integral part of critical infrastructure which is pivotal to urban development.","As 70% of the world's population will likely live in urban environments in 2050, efficient simulation and planning tools for WDS play a crucial role in reaching UN's sustainable developmental goal (SDG) 6 - \"Clean water and sanitation for all\".","In this realm, we propose a novel and efficient machine learning emulator, more precisely, a physics-informed deep learning (DL) model, for hydraulic state estimation in WDS.","Using a recursive approach, our model only needs a few graph convolutional neural network (GCN) layers and employs an innovative algorithm based on message passing.","Unlike conventional machine learning tasks, the model uses hydraulic principles to infer two additional hydraulic state features in the process of reconstructing the available ground truth feature in an unsupervised manner.","To the best of our knowledge, this is the first DL approach to emulate the popular hydraulic simulator EPANET, utilizing no additional information.","Like most DL models and unlike the hydraulic simulator, our model demonstrates vastly faster emulation times that do not increase drastically with the size of the WDS.","Moreover, we achieve high accuracy on the ground truth and very similar results compared to the hydraulic simulator as demonstrated through experiments on five real-world WDS datasets."],"url":"http://arxiv.org/abs/2403.18570v1","category":"cs.LG"}
{"created":"2024-03-27 13:50:13","title":"PDNNet: PDN-Aware GNN-CNN Heterogeneous Network for Dynamic IR Drop Prediction","abstract":"IR drop on the power delivery network (PDN) is closely related to PDN's configuration and cell current consumption. As the integrated circuit (IC) design is growing larger, dynamic IR drop simulation becomes computationally unaffordable and machine learning based IR drop prediction has been explored as a promising solution. Although CNN-based methods have been adapted to IR drop prediction task in several works, the shortcomings of overlooking PDN configuration is non-negligible. In this paper, we consider not only how to properly represent cell-PDN relation, but also how to model IR drop following its physical nature in the feature aggregation procedure. Thus, we propose a novel graph structure, PDNGraph, to unify the representations of the PDN structure and the fine-grained cell-PDN relation. We further propose a dual-branch heterogeneous network, PDNNet, incorporating two parallel GNN-CNN branches to favorably capture the above features during the learning process. Several key designs are presented to make the dynamic IR drop prediction highly effective and interpretable. We are the first work to apply graph structure to deep-learning based dynamic IR drop prediction method. Experiments show that PDNNet outperforms the state-of-the-art CNN-based methods by up to 39.3% reduction in prediction error and achieves 545x speedup compared to the commercial tool, which demonstrates the superiority of our method.","sentences":["IR drop on the power delivery network (PDN) is closely related to PDN's configuration and cell current consumption.","As the integrated circuit (IC) design is growing larger, dynamic IR drop simulation becomes computationally unaffordable and machine learning based IR drop prediction has been explored as a promising solution.","Although CNN-based methods have been adapted to IR drop prediction task in several works, the shortcomings of overlooking PDN configuration is non-negligible.","In this paper, we consider not only how to properly represent cell-PDN relation, but also how to model IR drop following its physical nature in the feature aggregation procedure.","Thus, we propose a novel graph structure, PDNGraph, to unify the representations of the PDN structure and the fine-grained cell-PDN relation.","We further propose a dual-branch heterogeneous network, PDNNet, incorporating two parallel GNN-CNN branches to favorably capture the above features during the learning process.","Several key designs are presented to make the dynamic IR drop prediction highly effective and interpretable.","We are the first work to apply graph structure to deep-learning based dynamic IR drop prediction method.","Experiments show that PDNNet outperforms the state-of-the-art CNN-based methods by up to 39.3% reduction in prediction error and achieves 545x speedup compared to the commercial tool, which demonstrates the superiority of our method."],"url":"http://arxiv.org/abs/2403.18569v1","category":"cs.LG"}
{"created":"2024-03-27 13:42:19","title":"A Dynamic Programming Approach for Road Traffic Estimation","abstract":"We consider a road network represented by a directed graph. We assume to collect many measurements of traffic flows on all the network arcs, or on a subset of them. We assume that the users are divided into different groups. Each group follows a different path. The flows of all user groups are modeled as a set of independent Poisson processes. Our focus is estimating the paths followed by each user group, and the means of the associated Poisson processes. We present a possible solution based on a Dynamic Programming algorithm. The method relies on the knowledge of high order cumulants. We discuss the theoretical properties of the introduced method. Finally, we present some numerical tests on well-known benchmark networks, using synthetic data.","sentences":["We consider a road network represented by a directed graph.","We assume to collect many measurements of traffic flows on all the network arcs, or on a subset of them.","We assume that the users are divided into different groups.","Each group follows a different path.","The flows of all user groups are modeled as a set of independent Poisson processes.","Our focus is estimating the paths followed by each user group, and the means of the associated Poisson processes.","We present a possible solution based on a Dynamic Programming algorithm.","The method relies on the knowledge of high order cumulants.","We discuss the theoretical properties of the introduced method.","Finally, we present some numerical tests on well-known benchmark networks, using synthetic data."],"url":"http://arxiv.org/abs/2403.18561v1","category":"eess.SY"}
{"created":"2024-03-27 13:25:43","title":"Neural Architecture Search for Sentence Classification with BERT","abstract":"Pre training of language models on large text corpora is common practice in Natural Language Processing. Following, fine tuning of these models is performed to achieve the best results on a variety of tasks. In this paper we question the common practice of only adding a single output layer as a classification head on top of the network. We perform an AutoML search to find architectures that outperform the current single layer at only a small compute cost. We validate our classification architecture on a variety of NLP benchmarks from the GLUE dataset.","sentences":["Pre training of language models on large text corpora is common practice in Natural Language Processing.","Following, fine tuning of these models is performed to achieve the best results on a variety of tasks.","In this paper we question the common practice of only adding a single output layer as a classification head on top of the network.","We perform an AutoML search to find architectures that outperform the current single layer at only a small compute cost.","We validate our classification architecture on a variety of NLP benchmarks from the GLUE dataset."],"url":"http://arxiv.org/abs/2403.18547v1","category":"cs.AI"}
{"created":"2024-03-27 13:24:58","title":"Efficient Heatmap-Guided 6-Dof Grasp Detection in Cluttered Scenes","abstract":"Fast and robust object grasping in clutter is a crucial component of robotics. Most current works resort to the whole observed point cloud for 6-Dof grasp generation, ignoring the guidance information excavated from global semantics, thus limiting high-quality grasp generation and real-time performance. In this work, we show that the widely used heatmaps are underestimated in the efficiency of 6-Dof grasp generation. Therefore, we propose an effective local grasp generator combined with grasp heatmaps as guidance, which infers in a global-to-local semantic-to-point way. Specifically, Gaussian encoding and the grid-based strategy are applied to predict grasp heatmaps as guidance to aggregate local points into graspable regions and provide global semantic information. Further, a novel non-uniform anchor sampling mechanism is designed to improve grasp accuracy and diversity. Benefiting from the high-efficiency encoding in the image space and focusing on points in local graspable regions, our framework can perform high-quality grasp detection in real-time and achieve state-of-the-art results. In addition, real robot experiments demonstrate the effectiveness of our method with a success rate of 94% and a clutter completion rate of 100%. Our code is available at https://github.com/THU-VCLab/HGGD.","sentences":["Fast and robust object grasping in clutter is a crucial component of robotics.","Most current works resort to the whole observed point cloud for 6-Dof grasp generation, ignoring the guidance information excavated from global semantics, thus limiting high-quality grasp generation and real-time performance.","In this work, we show that the widely used heatmaps are underestimated in the efficiency of 6-Dof grasp generation.","Therefore, we propose an effective local grasp generator combined with grasp heatmaps as guidance, which infers in a global-to-local semantic-to-point way.","Specifically, Gaussian encoding and the grid-based strategy are applied to predict grasp heatmaps as guidance to aggregate local points into graspable regions and provide global semantic information.","Further, a novel non-uniform anchor sampling mechanism is designed to improve grasp accuracy and diversity.","Benefiting from the high-efficiency encoding in the image space and focusing on points in local graspable regions, our framework can perform high-quality grasp detection in real-time and achieve state-of-the-art results.","In addition, real robot experiments demonstrate the effectiveness of our method with a success rate of 94% and a clutter completion rate of 100%.","Our code is available at https://github.com/THU-VCLab/HGGD."],"url":"http://arxiv.org/abs/2403.18546v1","category":"cs.RO"}
{"created":"2024-03-27 13:12:57","title":"A Path Towards Legal Autonomy: An interoperable and explainable approach to extracting, transforming, loading and computing legal information using large language models, expert systems and Bayesian networks","abstract":"Legal autonomy - the lawful activity of artificial intelligence agents - can be achieved in one of two ways. It can be achieved either by imposing constraints on AI actors such as developers, deployers and users, and on AI resources such as data, or by imposing constraints on the range and scope of the impact that AI agents can have on the environment. The latter approach involves encoding extant rules concerning AI driven devices into the software of AI agents controlling those devices (e.g., encoding rules about limitations on zones of operations into the agent software of an autonomous drone device). This is a challenge since the effectivity of such an approach requires a method of extracting, loading, transforming and computing legal information that would be both explainable and legally interoperable, and that would enable AI agents to reason about the law. In this paper, we sketch a proof of principle for such a method using large language models (LLMs), expert legal systems known as legal decision paths, and Bayesian networks. We then show how the proposed method could be applied to extant regulation in matters of autonomous cars, such as the California Vehicle Code.","sentences":["Legal autonomy - the lawful activity of artificial intelligence agents - can be achieved in one of two ways.","It can be achieved either by imposing constraints on AI actors such as developers, deployers and users, and on AI resources such as data, or by imposing constraints on the range and scope of the impact that AI agents can have on the environment.","The latter approach involves encoding extant rules concerning AI driven devices into the software of AI agents controlling those devices (e.g., encoding rules about limitations on zones of operations into the agent software of an autonomous drone device).","This is a challenge since the effectivity of such an approach requires a method of extracting, loading, transforming and computing legal information that would be both explainable and legally interoperable, and that would enable AI agents to reason about the law.","In this paper, we sketch a proof of principle for such a method using large language models (LLMs), expert legal systems known as legal decision paths, and Bayesian networks.","We then show how the proposed method could be applied to extant regulation in matters of autonomous cars, such as the California Vehicle Code."],"url":"http://arxiv.org/abs/2403.18537v1","category":"cs.AI"}
{"created":"2024-03-27 13:12:41","title":"A Novel Behavior-Based Recommendation System for E-commerce","abstract":"The majority of existing recommender systems rely on user ratings, which are limited by the lack of user collaboration and the sparsity problem. To address these issues, this study proposes a behavior-based recommender system that leverages customers' natural behaviors, such as browsing and clicking, on e-commerce platforms. The proposed recommendation system involves clustering active customers, determining neighborhoods, collecting similar users, calculating product reputation based on similar users, and recommending high-reputation products. To overcome the complexity of customer behaviors and traditional clustering methods, an unsupervised clustering approach based on product categories is developed to enhance the recommendation methodology. This study makes notable contributions in several aspects. Firstly, a groundbreaking behavior-based recommendation methodology is developed, incorporating customer behavior to generate accurate and tailored recommendations leading to improved customer satisfaction and engagement. Secondly, an original unsupervised clustering method, focusing on product categories, enables more precise clustering and facilitates accurate recommendations. Finally, an approach to determine neighborhoods for active customers within clusters is established, ensuring grouping of customers with similar behavioral patterns to enhance recommendation accuracy and relevance. The proposed recommendation methodology and clustering method contribute to improved recommendation performance, offering valuable insights for researchers and practitioners in the field of e-commerce recommendation systems. Additionally, the proposed method outperforms benchmark methods in experiments conducted using a behavior dataset from the well-known e-commerce site Alibaba.","sentences":["The majority of existing recommender systems rely on user ratings, which are limited by the lack of user collaboration and the sparsity problem.","To address these issues, this study proposes a behavior-based recommender system that leverages customers' natural behaviors, such as browsing and clicking, on e-commerce platforms.","The proposed recommendation system involves clustering active customers, determining neighborhoods, collecting similar users, calculating product reputation based on similar users, and recommending high-reputation products.","To overcome the complexity of customer behaviors and traditional clustering methods, an unsupervised clustering approach based on product categories is developed to enhance the recommendation methodology.","This study makes notable contributions in several aspects.","Firstly, a groundbreaking behavior-based recommendation methodology is developed, incorporating customer behavior to generate accurate and tailored recommendations leading to improved customer satisfaction and engagement.","Secondly, an original unsupervised clustering method, focusing on product categories, enables more precise clustering and facilitates accurate recommendations.","Finally, an approach to determine neighborhoods for active customers within clusters is established, ensuring grouping of customers with similar behavioral patterns to enhance recommendation accuracy and relevance.","The proposed recommendation methodology and clustering method contribute to improved recommendation performance, offering valuable insights for researchers and practitioners in the field of e-commerce recommendation systems.","Additionally, the proposed method outperforms benchmark methods in experiments conducted using a behavior dataset from the well-known e-commerce site Alibaba."],"url":"http://arxiv.org/abs/2403.18536v1","category":"cs.IR"}
{"created":"2024-03-27 12:50:27","title":"Improving Line Search Methods for Large Scale Neural Network Training","abstract":"In recent studies, line search methods have shown significant improvements in the performance of traditional stochastic gradient descent techniques, eliminating the need for a specific learning rate schedule. In this paper, we identify existing issues in state-of-the-art line search methods, propose enhancements, and rigorously evaluate their effectiveness. We test these methods on larger datasets and more complex data domains than before. Specifically, we improve the Armijo line search by integrating the momentum term from ADAM in its search direction, enabling efficient large-scale training, a task that was previously prone to failure using Armijo line search methods. Our optimization approach outperforms both the previous Armijo implementation and tuned learning rate schedules for Adam. Our evaluation focuses on Transformers and CNNs in the domains of NLP and image data. Our work is publicly available as a Python package, which provides a hyperparameter free Pytorch optimizer.","sentences":["In recent studies, line search methods have shown significant improvements in the performance of traditional stochastic gradient descent techniques, eliminating the need for a specific learning rate schedule.","In this paper, we identify existing issues in state-of-the-art line search methods, propose enhancements, and rigorously evaluate their effectiveness.","We test these methods on larger datasets and more complex data domains than before.","Specifically, we improve the Armijo line search by integrating the momentum term from ADAM in its search direction, enabling efficient large-scale training, a task that was previously prone to failure using Armijo line search methods.","Our optimization approach outperforms both the previous Armijo implementation and tuned learning rate schedules for Adam.","Our evaluation focuses on Transformers and CNNs in the domains of NLP and image data.","Our work is publicly available as a Python package, which provides a hyperparameter free Pytorch optimizer."],"url":"http://arxiv.org/abs/2403.18519v1","category":"cs.LG"}
{"created":"2024-03-27 12:40:00","title":"Bolzano's Conjecture: Measuring the Numerosity of Infinite Sets","abstract":"Bolzano and Cantor were the first mathematicians to make significant attempts to measure the size (numerosity) of different infinite collections. They differed in their methodological approaches, with Cantor's prevailing. This led to the foundation of the theory of sets as well as Cantor's transfinite arithmetic. This paper argues that Bolzano's conjecture is correct and that Euclid's principle, 'that the whole is greater than a part', should be considered as a necessary condition for the quantification of infinite sets (rather than bijection). Cantor had concluded that the rational and the algebraic numbers were of the same size as the natural numbers, whilst, in contrast, the real numbers were a larger set. Using Cantor's methods it is shown in this paper that the rational numbers are of larger size than the natural numbers, thus showing that bijection is not a reliable measure of the size of infinite sets. It is also concluded, using mathematical induction, that different 'countably' infinite sets can have various different sizes. The implications for theorems using bijection as a measure of size is then briefly discussed. There already exist new methods of measuring numerosity, based on Euclid's principle, which may develop a consistent system of infinite arithmetic.","sentences":["Bolzano and Cantor were the first mathematicians to make significant attempts to measure the size (numerosity) of different infinite collections.","They differed in their methodological approaches, with Cantor's prevailing.","This led to the foundation of the theory of sets as well as Cantor's transfinite arithmetic.","This paper argues that Bolzano's conjecture is correct and that Euclid's principle, 'that the whole is greater than a part', should be considered as a necessary condition for the quantification of infinite sets (rather than bijection).","Cantor had concluded that the rational and the algebraic numbers were of the same size as the natural numbers, whilst, in contrast, the real numbers were a larger set.","Using Cantor's methods it is shown in this paper that the rational numbers are of larger size than the natural numbers, thus showing that bijection is not a reliable measure of the size of infinite sets.","It is also concluded, using mathematical induction, that different 'countably' infinite sets can have various different sizes.","The implications for theorems using bijection as a measure of size is then briefly discussed.","There already exist new methods of measuring numerosity, based on Euclid's principle, which may develop a consistent system of infinite arithmetic."],"url":"http://arxiv.org/abs/2403.18511v1","category":"math.GM"}
{"created":"2024-03-27 12:35:23","title":"Faster Convergence for Transformer Fine-tuning with Line Search Methods","abstract":"Recent works have shown that line search methods greatly increase performance of traditional stochastic gradient descent methods on a variety of datasets and architectures [1], [2]. In this work we succeed in extending line search methods to the novel and highly popular Transformer architecture and dataset domains in natural language processing. More specifically, we combine the Armijo line search with the Adam optimizer and extend it by subdividing the networks architecture into sensible units and perform the line search separately on these local units. Our optimization method outperforms the traditional Adam optimizer and achieves significant performance improvements for small data sets or small training budgets, while performing equal or better for other tested cases. Our work is publicly available as a python package, which provides a hyperparameter-free pytorch optimizer that is compatible with arbitrary network architectures.","sentences":["Recent works have shown that line search methods greatly increase performance of traditional stochastic gradient descent methods on a variety of datasets and architectures","[1], [2].","In this work we succeed in extending line search methods to the novel and highly popular Transformer architecture and dataset domains in natural language processing.","More specifically, we combine the Armijo line search with the Adam optimizer and extend it by subdividing the networks architecture into sensible units and perform the line search separately on these local units.","Our optimization method outperforms the traditional Adam optimizer and achieves significant performance improvements for small data sets or small training budgets, while performing equal or better for other tested cases.","Our work is publicly available as a python package, which provides a hyperparameter-free pytorch optimizer that is compatible with arbitrary network architectures."],"url":"http://arxiv.org/abs/2403.18506v1","category":"cs.LG"}
{"created":"2024-03-27 12:01:51","title":"Impact of Employing Weather Forecast Data as Input to the Estimation of Evapotranspiration by Deep Neural Network Models","abstract":"Reference Evapotranspiration (ET0) is a key parameter for designing smart irrigation scheduling, since it is related by a coefficient to the water needs of a crop. The United Nations Food and Agriculture Organization, proposed a standard method for ET0 computation (FAO56PM), based on the parameterization of the Penman-Monteith equation, that is widely adopted in the literature. To compute ET0 using the FAO56-PM method, four main weather parameters are needed: temperature, humidity, wind, and solar radiation (SR). One way to make daily ET0 estimations for future days is to use freely available weather forecast services (WFSs), where many meteorological parameters are estimated up to the next 15 days. A problem with this method is that currently, SR is not provided as a free forecast parameter on most of those online services or, normally, such forecasts present a financial cost penalty. For this reason, several ET0 estimation models using machine and deep learning were developed and presented in the literature, that use as input features a reduced set of carefully selected weather parameters, that are compatible with common freely available WFSs. However, most studies on this topic have only evaluated model performance using data from weather stations (WSs), without considering the effect of using weather forecast data. In this study, the performance of authors' previous models is evaluated when using weather forecast data from two online WFSs, in the following scenarios: (i) direct ET0 estimation by an ANN model, and (ii) estimate SR by ANN model, and then use that estimation for ET0 computation, using the FAO56-PM method. Employing data collected from two WFSs and a WS located in Vale do Lobo, Portugal, the latter approach achieved the best result, with a coefficient of determination (R2) ranging between 0.893 and 0.667, when considering forecasts up to 15 days.","sentences":["Reference Evapotranspiration (ET0) is a key parameter for designing smart irrigation scheduling, since it is related by a coefficient to the water needs of a crop.","The United Nations Food and Agriculture Organization, proposed a standard method for ET0 computation (FAO56PM), based on the parameterization of the Penman-Monteith equation, that is widely adopted in the literature.","To compute ET0 using the FAO56-PM method, four main weather parameters are needed: temperature, humidity, wind, and solar radiation (SR).","One way to make daily ET0 estimations for future days is to use freely available weather forecast services (WFSs), where many meteorological parameters are estimated up to the next 15 days.","A problem with this method is that currently, SR is not provided as a free forecast parameter on most of those online services or, normally, such forecasts present a financial cost penalty.","For this reason, several ET0 estimation models using machine and deep learning were developed and presented in the literature, that use as input features a reduced set of carefully selected weather parameters, that are compatible with common freely available WFSs.","However, most studies on this topic have only evaluated model performance using data from weather stations (WSs), without considering the effect of using weather forecast data.","In this study, the performance of authors' previous models is evaluated when using weather forecast data from two online WFSs, in the following scenarios: (i) direct ET0 estimation by an ANN model, and (ii) estimate SR by ANN model, and then use that estimation for ET0 computation, using the FAO56-PM method.","Employing data collected from two WFSs and a WS located in Vale do Lobo, Portugal, the latter approach achieved the best result, with a coefficient of determination (R2) ranging between 0.893 and 0.667, when considering forecasts up to 15 days."],"url":"http://arxiv.org/abs/2403.18489v1","category":"cs.AI"}
{"created":"2024-03-27 11:58:45","title":"Synthesizing EEG Signals from Event-Related Potential Paradigms with Conditional Diffusion Models","abstract":"Data scarcity in the brain-computer interface field can be alleviated through the use of generative models, specifically diffusion models. While diffusion models have previously been successfully applied to electroencephalogram (EEG) data, existing models lack flexibility w.r.t.~sampling or require alternative representations of the EEG data. To overcome these limitations, we introduce a novel approach to conditional diffusion models that utilizes classifier-free guidance to directly generate subject-, session-, and class-specific EEG data. In addition to commonly used metrics, domain-specific metrics are employed to evaluate the specificity of the generated samples. The results indicate that the proposed model can generate EEG data that resembles real data for each subject, session, and class.","sentences":["Data scarcity in the brain-computer interface field can be alleviated through the use of generative models, specifically diffusion models.","While diffusion models have previously been successfully applied to electroencephalogram (EEG) data, existing models lack flexibility w.r.t.~sampling or require alternative representations of the EEG data.","To overcome these limitations, we introduce a novel approach to conditional diffusion models that utilizes classifier-free guidance to directly generate subject-, session-, and class-specific EEG data.","In addition to commonly used metrics, domain-specific metrics are employed to evaluate the specificity of the generated samples.","The results indicate that the proposed model can generate EEG data that resembles real data for each subject, session, and class."],"url":"http://arxiv.org/abs/2403.18486v1","category":"cs.LG"}
{"created":"2024-03-27 11:49:58","title":"Enhanced Generative Recommendation via Content and Collaboration Integration","abstract":"Generative recommendation has emerged as a promising paradigm aimed at augmenting recommender systems with recent advancements in generative artificial intelligence. This task has been formulated as a sequence-to-sequence generation process, wherein the input sequence encompasses data pertaining to the user's previously interacted items, and the output sequence denotes the generative identifier for the suggested item. However, existing generative recommendation approaches still encounter challenges in (i) effectively integrating user-item collaborative signals and item content information within a unified generative framework, and (ii) executing an efficient alignment between content information and collaborative signals.   In this paper, we introduce content-based collaborative generation for recommender systems, denoted as ColaRec. To capture collaborative signals, the generative item identifiers are derived from a pretrained collaborative filtering model, while the user is represented through the aggregation of interacted items' content. Subsequently, the aggregated textual description of items is fed into a language model to encapsulate content information. This integration enables ColaRec to amalgamate collaborative signals and content information within an end-to-end framework. Regarding the alignment, we propose an item indexing task to facilitate the mapping between the content-based semantic space and the interaction-based collaborative space. Additionally, a contrastive loss is introduced to ensure that items with similar collaborative GIDs possess comparable content representations, thereby enhancing alignment. To validate the efficacy of ColaRec, we conduct experiments on three benchmark datasets. Empirical results substantiate the superior performance of ColaRec.","sentences":["Generative recommendation has emerged as a promising paradigm aimed at augmenting recommender systems with recent advancements in generative artificial intelligence.","This task has been formulated as a sequence-to-sequence generation process, wherein the input sequence encompasses data pertaining to the user's previously interacted items, and the output sequence denotes the generative identifier for the suggested item.","However, existing generative recommendation approaches still encounter challenges in (i) effectively integrating user-item collaborative signals and item content information within a unified generative framework, and (ii) executing an efficient alignment between content information and collaborative signals.   ","In this paper, we introduce content-based collaborative generation for recommender systems, denoted as ColaRec.","To capture collaborative signals, the generative item identifiers are derived from a pretrained collaborative filtering model, while the user is represented through the aggregation of interacted items' content.","Subsequently, the aggregated textual description of items is fed into a language model to encapsulate content information.","This integration enables ColaRec to amalgamate collaborative signals and content information within an end-to-end framework.","Regarding the alignment, we propose an item indexing task to facilitate the mapping between the content-based semantic space and the interaction-based collaborative space.","Additionally, a contrastive loss is introduced to ensure that items with similar collaborative GIDs possess comparable content representations, thereby enhancing alignment.","To validate the efficacy of ColaRec, we conduct experiments on three benchmark datasets.","Empirical results substantiate the superior performance of ColaRec."],"url":"http://arxiv.org/abs/2403.18480v1","category":"cs.IR"}
{"created":"2024-03-27 11:32:44","title":"DiffusionFace: Towards a Comprehensive Dataset for Diffusion-Based Face Forgery Analysis","abstract":"The rapid progress in deep learning has given rise to hyper-realistic facial forgery methods, leading to concerns related to misinformation and security risks. Existing face forgery datasets have limitations in generating high-quality facial images and addressing the challenges posed by evolving generative techniques. To combat this, we present DiffusionFace, the first diffusion-based face forgery dataset, covering various forgery categories, including unconditional and Text Guide facial image generation, Img2Img, Inpaint, and Diffusion-based facial exchange algorithms. Our DiffusionFace dataset stands out with its extensive collection of 11 diffusion models and the high-quality of the generated images, providing essential metadata and a real-world internet-sourced forgery facial image dataset for evaluation. Additionally, we provide an in-depth analysis of the data and introduce practical evaluation protocols to rigorously assess discriminative models' effectiveness in detecting counterfeit facial images, aiming to enhance security in facial image authentication processes. The dataset is available for download at \\url{https://github.com/Rapisurazurite/DiffFace}.","sentences":["The rapid progress in deep learning has given rise to hyper-realistic facial forgery methods, leading to concerns related to misinformation and security risks.","Existing face forgery datasets have limitations in generating high-quality facial images and addressing the challenges posed by evolving generative techniques.","To combat this, we present DiffusionFace, the first diffusion-based face forgery dataset, covering various forgery categories, including unconditional and Text Guide facial image generation, Img2Img, Inpaint, and Diffusion-based facial exchange algorithms.","Our DiffusionFace dataset stands out with its extensive collection of 11 diffusion models and the high-quality of the generated images, providing essential metadata and a real-world internet-sourced forgery facial image dataset for evaluation.","Additionally, we provide an in-depth analysis of the data and introduce practical evaluation protocols to rigorously assess discriminative models' effectiveness in detecting counterfeit facial images, aiming to enhance security in facial image authentication processes.","The dataset is available for download at \\url{https://github.com/Rapisurazurite/DiffFace}."],"url":"http://arxiv.org/abs/2403.18471v1","category":"cs.CV"}
{"created":"2024-03-27 11:28:57","title":"Density-guided Translator Boosts Synthetic-to-Real Unsupervised Domain Adaptive Segmentation of 3D Point Clouds","abstract":"3D synthetic-to-real unsupervised domain adaptive segmentation is crucial to annotating new domains. Self-training is a competitive approach for this task, but its performance is limited by different sensor sampling patterns (i.e., variations in point density) and incomplete training strategies. In this work, we propose a density-guided translator (DGT), which translates point density between domains, and integrates it into a two-stage self-training pipeline named DGT-ST. First, in contrast to existing works that simultaneously conduct data generation and feature/output alignment within unstable adversarial training, we employ the non-learnable DGT to bridge the domain gap at the input level. Second, to provide a well-initialized model for self-training, we propose a category-level adversarial network in stage one that utilizes the prototype to prevent negative transfer. Finally, by leveraging the designs above, a domain-mixed self-training method with source-aware consistency loss is proposed in stage two to narrow the domain gap further. Experiments on two synthetic-to-real segmentation tasks (SynLiDAR $\\rightarrow$ semanticKITTI and SynLiDAR $\\rightarrow$ semanticPOSS) demonstrate that DGT-ST outperforms state-of-the-art methods, achieving 9.4$\\%$ and 4.3$\\%$ mIoU improvements, respectively. Code is available at \\url{https://github.com/yuan-zm/DGT-ST}.","sentences":["3D synthetic-to-real unsupervised domain adaptive segmentation is crucial to annotating new domains.","Self-training is a competitive approach for this task, but its performance is limited by different sensor sampling patterns (i.e., variations in point density) and incomplete training strategies.","In this work, we propose a density-guided translator (DGT), which translates point density between domains, and integrates it into a two-stage self-training pipeline named DGT-ST.","First, in contrast to existing works that simultaneously conduct data generation and feature/output alignment within unstable adversarial training, we employ the non-learnable DGT to bridge the domain gap at the input level.","Second, to provide a well-initialized model for self-training, we propose a category-level adversarial network in stage one that utilizes the prototype to prevent negative transfer.","Finally, by leveraging the designs above, a domain-mixed self-training method with source-aware consistency loss is proposed in stage two to narrow the domain gap further.","Experiments on two synthetic-to-real segmentation tasks (SynLiDAR $\\rightarrow$ semanticKITTI and SynLiDAR $\\rightarrow$ semanticPOSS) demonstrate that DGT-ST outperforms state-of-the-art methods, achieving 9.4$\\%$ and 4.3$\\%$ mIoU improvements, respectively.","Code is available at \\url{https://github.com/yuan-zm/DGT-ST}."],"url":"http://arxiv.org/abs/2403.18469v1","category":"cs.CV"}
{"created":"2024-03-27 11:28:32","title":"Deep Learning Segmentation and Classification of Red Blood Cells Using a Large Multi-Scanner Dataset","abstract":"Digital pathology has recently been revolutionized by advancements in artificial intelligence, deep learning, and high-performance computing. With its advanced tools, digital pathology can help improve and speed up the diagnostic process, reduce human errors, and streamline the reporting step. In this paper, we report a new large red blood cell (RBC) image dataset and propose a two-stage deep learning framework for RBC image segmentation and classification. The dataset is a highly diverse dataset of more than 100K RBCs containing eight different classes. The dataset, which is considerably larger than any publicly available hematopathology dataset, was labeled independently by two hematopathologists who also manually created masks for RBC cell segmentation. Subsequently, in the proposed framework, first, a U-Net model was trained to achieve automatic RBC image segmentation. Second, an EfficientNetB0 model was trained to classify RBC images into one of the eight classes using a transfer learning approach with a 5X2 cross-validation scheme. An IoU of 98.03% and an average classification accuracy of 96.5% were attained on the test set. Moreover, we have performed experimental comparisons against several prominent CNN models. These comparisons show the superiority of the proposed model with a good balance between performance and computational cost.","sentences":["Digital pathology has recently been revolutionized by advancements in artificial intelligence, deep learning, and high-performance computing.","With its advanced tools, digital pathology can help improve and speed up the diagnostic process, reduce human errors, and streamline the reporting step.","In this paper, we report a new large red blood cell (RBC) image dataset and propose a two-stage deep learning framework for RBC image segmentation and classification.","The dataset is a highly diverse dataset of more than 100K RBCs containing eight different classes.","The dataset, which is considerably larger than any publicly available hematopathology dataset, was labeled independently by two hematopathologists who also manually created masks for RBC cell segmentation.","Subsequently, in the proposed framework, first, a U-Net model was trained to achieve automatic RBC image segmentation.","Second, an EfficientNetB0 model was trained to classify RBC images into one of the eight classes using a transfer learning approach with a 5X2 cross-validation scheme.","An IoU of 98.03% and an average classification accuracy of 96.5% were attained on the test set.","Moreover, we have performed experimental comparisons against several prominent CNN models.","These comparisons show the superiority of the proposed model with a good balance between performance and computational cost."],"url":"http://arxiv.org/abs/2403.18468v1","category":"eess.IV"}
{"created":"2024-03-27 11:22:00","title":"Cumulative Incidence Function Estimation Based on Population-Based Biobank Data","abstract":"Many countries have established population-based biobanks, which are being used increasingly in epidemiolgical and clinical research. These biobanks offer opportunities for large-scale studies addressing questions beyond the scope of traditional clinical trials or cohort studies. However, using biobank data poses new challenges. Typically, biobank data is collected from a study cohort recruited over a defined calendar period, with subjects entering the study at various ages falling between $c_L$ and $c_U$. This work focuses on biobank data with individuals reporting disease-onset age upon recruitment, termed prevalent data, along with individuals initially recruited as healthy, and their disease onset observed during the follow-up period. We propose a novel cumulative incidence function (CIF) estimator that efficiently incorporates prevalent cases, in contrast to existing methods, providing two advantages: (1) increased efficiency, and (2) CIF estimation for ages before the lower limit, $c_L$.","sentences":["Many countries have established population-based biobanks, which are being used increasingly in epidemiolgical and clinical research.","These biobanks offer opportunities for large-scale studies addressing questions beyond the scope of traditional clinical trials or cohort studies.","However, using biobank data poses new challenges.","Typically, biobank data is collected from a study cohort recruited over a defined calendar period, with subjects entering the study at various ages falling between $c_L$ and $c_U$. This work focuses on biobank data with individuals reporting disease-onset age upon recruitment, termed prevalent data, along with individuals initially recruited as healthy, and their disease onset observed during the follow-up period.","We propose a novel cumulative incidence function (CIF) estimator that efficiently incorporates prevalent cases, in contrast to existing methods, providing two advantages: (1) increased efficiency, and (2) CIF estimation for ages before the lower limit, $c_L$."],"url":"http://arxiv.org/abs/2403.18464v1","category":"stat.ME"}
{"created":"2024-03-27 11:18:01","title":"CoBOS: Constraint-Based Online Scheduler for Human-Robot Collaboration","abstract":"Assembly processes involving humans and robots are challenging scenarios because the individual activities and access to shared workspace have to be coordinated. Fixed robot programs leave no room to diverge from a fixed protocol. Working on such a process can be stressful for the user and lead to ineffective behavior or failure. We propose a novel approach of online constraint-based scheduling in a reactive execution control framework facilitating behavior trees called CoBOS. This allows the robot to adapt to uncertain events such as delayed activity completions and activity selection (by the human). The user will experience less stress as the robotic coworkers adapt their behavior to best complement the human-selected activities to complete the common task. In addition to the improved working conditions, our algorithm leads to increased efficiency, even in highly uncertain scenarios. We evaluate our algorithm using a probabilistic simulation study with 56000 experiments. We outperform all baselines by a margin of 4-10%. Initial real robot experiments using a Franka Emika Panda robot and human tracking based on HTC Vive VR gloves look promising.","sentences":["Assembly processes involving humans and robots are challenging scenarios because the individual activities and access to shared workspace have to be coordinated.","Fixed robot programs leave no room to diverge from a fixed protocol.","Working on such a process can be stressful for the user and lead to ineffective behavior or failure.","We propose a novel approach of online constraint-based scheduling in a reactive execution control framework facilitating behavior trees called CoBOS.","This allows the robot to adapt to uncertain events such as delayed activity completions and activity selection (by the human).","The user will experience less stress as the robotic coworkers adapt their behavior to best complement the human-selected activities to complete the common task.","In addition to the improved working conditions, our algorithm leads to increased efficiency, even in highly uncertain scenarios.","We evaluate our algorithm using a probabilistic simulation study with 56000 experiments.","We outperform all baselines by a margin of 4-10%.","Initial real robot experiments using a Franka Emika Panda robot and human tracking based on HTC Vive VR gloves look promising."],"url":"http://arxiv.org/abs/2403.18459v1","category":"cs.RO"}
{"created":"2024-03-27 11:13:20","title":"Scaling Vision-and-Language Navigation With Offline RL","abstract":"The study of vision-and-language navigation (VLN) has typically relied on expert trajectories, which may not always be available in real-world situations due to the significant effort required to collect them. On the other hand, existing approaches to training VLN agents that go beyond available expert data involve data augmentations or online exploration which can be tedious and risky. In contrast, it is easy to access large repositories of suboptimal offline trajectories. Inspired by research in offline reinforcement learning (ORL), we introduce a new problem setup of VLN-ORL which studies VLN using suboptimal demonstration data. We introduce a simple and effective reward-conditioned approach that can account for dataset suboptimality for training VLN agents, as well as benchmarks to evaluate progress and promote research in this area. We empirically study various noise models for characterizing dataset suboptimality among other unique challenges in VLN-ORL and instantiate it for the VLN$\\circlearrowright$BERT and MTVM architectures in the R2R and RxR environments. Our experiments demonstrate that the proposed reward-conditioned approach leads to significant performance improvements, even in complex and intricate environments.","sentences":["The study of vision-and-language navigation (VLN) has typically relied on expert trajectories, which may not always be available in real-world situations due to the significant effort required to collect them.","On the other hand, existing approaches to training VLN agents that go beyond available expert data involve data augmentations or online exploration which can be tedious and risky.","In contrast, it is easy to access large repositories of suboptimal offline trajectories.","Inspired by research in offline reinforcement learning (ORL), we introduce a new problem setup of VLN-ORL which studies VLN using suboptimal demonstration data.","We introduce a simple and effective reward-conditioned approach that can account for dataset suboptimality for training VLN agents, as well as benchmarks to evaluate progress and promote research in this area.","We empirically study various noise models for characterizing dataset suboptimality among other unique challenges in VLN-ORL and instantiate it for the VLN$\\circlearrowright$BERT and MTVM architectures in the R2R and RxR environments.","Our experiments demonstrate that the proposed reward-conditioned approach leads to significant performance improvements, even in complex and intricate environments."],"url":"http://arxiv.org/abs/2403.18454v1","category":"cs.CV"}
{"created":"2024-03-27 11:11:06","title":"CoRAST: Towards Foundation Model-Powered Correlated Data Analysis in Resource-Constrained CPS and IoT","abstract":"Foundation models (FMs) emerge as a promising solution to harness distributed and diverse environmental data by leveraging prior knowledge to understand the complicated temporal and spatial correlations within heterogeneous datasets. Unlike distributed learning frameworks such as federated learning, which often struggle with multimodal data, FMs can transform diverse inputs into embeddings. This process facilitates the integration of information from various modalities and the application of prior learning to new domains. However, deploying FMs in resource-constrained edge systems poses significant challenges. To this end, we introduce CoRAST, a novel learning framework that utilizes FMs for enhanced analysis of distributed, correlated heterogeneous data. Utilizing a server-based FM, CoRAST can exploit existing environment information to extract temporal, spatial, and cross-modal correlations among sensor data. This enables CoRAST to offer context-aware insights for localized client tasks through FM-powered global representation learning. Our evaluation on real-world weather dataset demonstrates CoRAST's ability to exploit correlated heterogeneous data through environmental representation learning to reduce the forecast errors by up to 50.3% compared to the baselines.","sentences":["Foundation models (FMs) emerge as a promising solution to harness distributed and diverse environmental data by leveraging prior knowledge to understand the complicated temporal and spatial correlations within heterogeneous datasets.","Unlike distributed learning frameworks such as federated learning, which often struggle with multimodal data, FMs can transform diverse inputs into embeddings.","This process facilitates the integration of information from various modalities and the application of prior learning to new domains.","However, deploying FMs in resource-constrained edge systems poses significant challenges.","To this end, we introduce CoRAST, a novel learning framework that utilizes FMs for enhanced analysis of distributed, correlated heterogeneous data.","Utilizing a server-based FM, CoRAST can exploit existing environment information to extract temporal, spatial, and cross-modal correlations among sensor data.","This enables CoRAST to offer context-aware insights for localized client tasks through FM-powered global representation learning.","Our evaluation on real-world weather dataset demonstrates CoRAST's ability to exploit correlated heterogeneous data through environmental representation learning to reduce the forecast errors by up to 50.3% compared to the baselines."],"url":"http://arxiv.org/abs/2403.18451v1","category":"cs.LG"}
{"created":"2024-03-27 11:00:33","title":"$\\mathrm{F^2Depth}$: Self-supervised Indoor Monocular Depth Estimation via Optical Flow Consistency and Feature Map Synthesis","abstract":"Self-supervised monocular depth estimation methods have been increasingly given much attention due to the benefit of not requiring large, labelled datasets. Such self-supervised methods require high-quality salient features and consequently suffer from severe performance drop for indoor scenes, where low-textured regions dominant in the scenes are almost indiscriminative. To address the issue, we propose a self-supervised indoor monocular depth estimation framework called $\\mathrm{F^2Depth}$. A self-supervised optical flow estimation network is introduced to supervise depth learning. To improve optical flow estimation performance in low-textured areas, only some patches of points with more discriminative features are adopted for finetuning based on our well-designed patch-based photometric loss. The finetuned optical flow estimation network generates high-accuracy optical flow as a supervisory signal for depth estimation. Correspondingly, an optical flow consistency loss is designed. Multi-scale feature maps produced by finetuned optical flow estimation network perform warping to compute feature map synthesis loss as another supervisory signal for depth learning. Experimental results on the NYU Depth V2 dataset demonstrate the effectiveness of the framework and our proposed losses. To evaluate the generalization ability of our $\\mathrm{F^2Depth}$, we collect a Campus Indoor depth dataset composed of approximately 1500 points selected from 99 images in 18 scenes. Zero-shot generalization experiments on 7-Scenes dataset and Campus Indoor achieve $\\delta_1$ accuracy of 75.8% and 76.0% respectively. The accuracy results show that our model can generalize well to monocular images captured in unknown indoor scenes.","sentences":["Self-supervised monocular depth estimation methods have been increasingly given much attention due to the benefit of not requiring large, labelled datasets.","Such self-supervised methods require high-quality salient features and consequently suffer from severe performance drop for indoor scenes, where low-textured regions dominant in the scenes are almost indiscriminative.","To address the issue, we propose a self-supervised indoor monocular depth estimation framework called $\\mathrm{F^2Depth}$. A self-supervised optical flow estimation network is introduced to supervise depth learning.","To improve optical flow estimation performance in low-textured areas, only some patches of points with more discriminative features are adopted for finetuning based on our well-designed patch-based photometric loss.","The finetuned optical flow estimation network generates high-accuracy optical flow as a supervisory signal for depth estimation.","Correspondingly, an optical flow consistency loss is designed.","Multi-scale feature maps produced by finetuned optical flow estimation network perform warping to compute feature map synthesis loss as another supervisory signal for depth learning.","Experimental results on the NYU Depth V2 dataset demonstrate the effectiveness of the framework and our proposed losses.","To evaluate the generalization ability of our $\\mathrm{F^2Depth}$, we collect a Campus Indoor depth dataset composed of approximately 1500 points selected from 99 images in 18 scenes.","Zero-shot generalization experiments on 7-Scenes dataset and Campus Indoor achieve $\\delta_1$ accuracy of 75.8% and 76.0% respectively.","The accuracy results show that our model can generalize well to monocular images captured in unknown indoor scenes."],"url":"http://arxiv.org/abs/2403.18443v1","category":"cs.CV"}
{"created":"2024-03-27 10:47:09","title":"Connections between metric differentiability and rectifiability","abstract":"We combine Kirchheim's metric differentials with Cheeger charts in order to establish a non-embeddability principle for any collection $\\mathcal C$ of Banach (or metric) spaces: if a metric measure space $X$ bi-Lipschitz embeds in some element in $\\mathcal C$, and if every Lipschitz map $X\\to Y\\in \\mathcal C$ is differentiable, then $X$ is rectifiable. This gives a simple proof of the rectifiability of Lipschitz differentiability spaces that are bi-Lipschitz embeddable in Euclidean space, due to Kell--Mondino. Our principle also implies a converse to Kirchheim's theorem: if all Lipschitz maps from a domain space to arbitrary targets are metrically differentiable, the domain is rectifiable. We moreover establish the compatibility of metric and w$^*$-differentials of maps from metric spaces in the spirit of Ambrosio--Kirchheim.","sentences":["We combine Kirchheim's metric differentials with Cheeger charts in order to establish a non-embeddability principle for any collection $\\mathcal C$ of Banach (or metric) spaces: if a metric measure space $X$ bi-Lipschitz embeds in some element in $\\mathcal C$, and if every Lipschitz map $X\\to Y\\in \\mathcal C$ is differentiable, then $X$ is rectifiable.","This gives a simple proof of the rectifiability of Lipschitz differentiability spaces that are bi-Lipschitz embeddable in Euclidean space, due to Kell--Mondino.","Our principle also implies a converse to Kirchheim's theorem: if all Lipschitz maps from a domain space to arbitrary targets are metrically differentiable, the domain is rectifiable.","We moreover establish the compatibility of metric and w$^*$-differentials of maps from metric spaces in the spirit of Ambrosio--Kirchheim."],"url":"http://arxiv.org/abs/2403.18440v1","category":"math.MG"}
{"created":"2024-03-27 10:43:12","title":"Coherent Collections of Rules Describing Exceptional Materials Identified with a Multi-Objective Optimization of Subgroups","abstract":"Using a modest amount of data from a large population, subgroup discovery (SGD) identifies outstanding subsets of data with respect to a certain property of interest of that population. The SGs are described by \"rules\". These are constraints on key descriptive parameters that characterize the material or the environment. These parameters and constraints are obtained by maximizing a quality function that establishes a tradeoff between SG size and utility, i.e., between generality and exceptionality. The utility function measures how outstanding a SG is. However, this approach does not give a unique solution, but typically many SGs have similar quality-function values. Here, we identify coherent collections of SGs of a \"Pareto region\" presenting various size-utility tradeoffs and define a SG similarity measure based on the Jaccard index, which allows us to hierarchically cluster these optimal SGs. These concepts are demonstrated by learning rules that describe perovskites with high bulk modulus. We show that SGs focusing on exceptional materials exhibit a high quality-function value but do not necessarily maximize it. We compare the mean shift with the cumulative Jensen-Shannon divergence ($D_{sJS}$) as utility functions and show that the SG rules obtained with $D_{cJS}$ are more focused than those obtained with the mean shift.","sentences":["Using a modest amount of data from a large population, subgroup discovery (SGD) identifies outstanding subsets of data with respect to a certain property of interest of that population.","The SGs are described by \"rules\".","These are constraints on key descriptive parameters that characterize the material or the environment.","These parameters and constraints are obtained by maximizing a quality function that establishes a tradeoff between SG size and utility, i.e., between generality and exceptionality.","The utility function measures how outstanding a SG is.","However, this approach does not give a unique solution, but typically many SGs have similar quality-function values.","Here, we identify coherent collections of SGs of a \"Pareto region\" presenting various size-utility tradeoffs and define a SG similarity measure based on the Jaccard index, which allows us to hierarchically cluster these optimal SGs.","These concepts are demonstrated by learning rules that describe perovskites with high bulk modulus.","We show that SGs focusing on exceptional materials exhibit a high quality-function value but do not necessarily maximize it.","We compare the mean shift with the cumulative Jensen-Shannon divergence ($D_{sJS}$) as utility functions and show that the SG rules obtained with $D_{cJS}$ are more focused than those obtained with the mean shift."],"url":"http://arxiv.org/abs/2403.18437v1","category":"cond-mat.mtrl-sci"}
{"created":"2024-03-27 10:40:27","title":"Collaborative Active Learning in Conditional Trust Environment","abstract":"In this paper, we investigate collaborative active learning, a paradigm in which multiple collaborators explore a new domain by leveraging their combined machine learning capabilities without disclosing their existing data and models. Instead, the collaborators share prediction results from the new domain and newly acquired labels. This collaboration offers several advantages: (a) it addresses privacy and security concerns by eliminating the need for direct model and data disclosure; (b) it enables the use of different data sources and insights without direct data exchange; and (c) it promotes cost-effectiveness and resource efficiency through shared labeling costs. To realize these benefits, we introduce a collaborative active learning framework designed to fulfill the aforementioned objectives. We validate the effectiveness of the proposed framework through simulations. The results demonstrate that collaboration leads to higher AUC scores compared to independent efforts, highlighting the framework's ability to overcome the limitations of individual models. These findings support the use of collaborative approaches in active learning, emphasizing their potential to enhance outcomes through collective expertise and shared resources. Our work provides a foundation for further research on collaborative active learning and its practical applications in various domains where data privacy, cost efficiency, and model performance are critical considerations.","sentences":["In this paper, we investigate collaborative active learning, a paradigm in which multiple collaborators explore a new domain by leveraging their combined machine learning capabilities without disclosing their existing data and models.","Instead, the collaborators share prediction results from the new domain and newly acquired labels.","This collaboration offers several advantages: (a) it addresses privacy and security concerns by eliminating the need for direct model and data disclosure; (b) it enables the use of different data sources and insights without direct data exchange; and (c) it promotes cost-effectiveness and resource efficiency through shared labeling costs.","To realize these benefits, we introduce a collaborative active learning framework designed to fulfill the aforementioned objectives.","We validate the effectiveness of the proposed framework through simulations.","The results demonstrate that collaboration leads to higher AUC scores compared to independent efforts, highlighting the framework's ability to overcome the limitations of individual models.","These findings support the use of collaborative approaches in active learning, emphasizing their potential to enhance outcomes through collective expertise and shared resources.","Our work provides a foundation for further research on collaborative active learning and its practical applications in various domains where data privacy, cost efficiency, and model performance are critical considerations."],"url":"http://arxiv.org/abs/2403.18436v1","category":"cs.LG"}
{"created":"2024-03-27 17:59:56","title":"Real Acoustic Fields: An Audio-Visual Room Acoustics Dataset and Benchmark","abstract":"We present a new dataset called Real Acoustic Fields (RAF) that captures real acoustic room data from multiple modalities. The dataset includes high-quality and densely captured room impulse response data paired with multi-view images, and precise 6DoF pose tracking data for sound emitters and listeners in the rooms. We used this dataset to evaluate existing methods for novel-view acoustic synthesis and impulse response generation which previously relied on synthetic data. In our evaluation, we thoroughly assessed existing audio and audio-visual models against multiple criteria and proposed settings to enhance their performance on real-world data. We also conducted experiments to investigate the impact of incorporating visual data (i.e., images and depth) into neural acoustic field models. Additionally, we demonstrated the effectiveness of a simple sim2real approach, where a model is pre-trained with simulated data and fine-tuned with sparse real-world data, resulting in significant improvements in the few-shot learning approach. RAF is the first dataset to provide densely captured room acoustic data, making it an ideal resource for researchers working on audio and audio-visual neural acoustic field modeling techniques. Demos and datasets are available on our project page: https://facebookresearch.github.io/real-acoustic-fields/","sentences":["We present a new dataset called Real Acoustic Fields (RAF) that captures real acoustic room data from multiple modalities.","The dataset includes high-quality and densely captured room impulse response data paired with multi-view images, and precise 6DoF pose tracking data for sound emitters and listeners in the rooms.","We used this dataset to evaluate existing methods for novel-view acoustic synthesis and impulse response generation which previously relied on synthetic data.","In our evaluation, we thoroughly assessed existing audio and audio-visual models against multiple criteria and proposed settings to enhance their performance on real-world data.","We also conducted experiments to investigate the impact of incorporating visual data (i.e., images and depth) into neural acoustic field models.","Additionally, we demonstrated the effectiveness of a simple sim2real approach, where a model is pre-trained with simulated data and fine-tuned with sparse real-world data, resulting in significant improvements in the few-shot learning approach.","RAF is the first dataset to provide densely captured room acoustic data, making it an ideal resource for researchers working on audio and audio-visual neural acoustic field modeling techniques.","Demos and datasets are available on our project page: https://facebookresearch.github.io/real-acoustic-fields/"],"url":"http://arxiv.org/abs/2403.18821v1","category":"cs.SD"}
{"created":"2024-03-27 17:59:35","title":"Signatures of electronic ordering in transport in graphene flat bands","abstract":"Recently, a wide family of electronic orders was unveiled in graphene flat bands, such as spin- and valley-polarized phases as well as nematic momentum-polarized phases, stabilized by exchange interactions via a generalized Stoner mechanism. Momentum polarization involves orbital degrees of freedom and is therefore expected to impact resistivity in a way which is uniquely sensitive to the ordering type. Under pocket polarization, carrier distribution shifts in k space and samples the band mass in regions defined by the displaced momentum distribution. This makes transport coefficients sensitive to pocket polarization, resulting in the ohmic resistivity decreasing with temperature. In addition, it leads to current switching and hysteresis under strong E field. This behavior remains robust in the presence of electron-phonon scattering and is therefore expected to be generic.","sentences":["Recently, a wide family of electronic orders was unveiled in graphene flat bands, such as spin- and valley-polarized phases as well as nematic momentum-polarized phases, stabilized by exchange interactions via a generalized Stoner mechanism.","Momentum polarization involves orbital degrees of freedom and is therefore expected to impact resistivity in a way which is uniquely sensitive to the ordering type.","Under pocket polarization, carrier distribution shifts in k space and samples the band mass in regions defined by the displaced momentum distribution.","This makes transport coefficients sensitive to pocket polarization, resulting in the ohmic resistivity decreasing with temperature.","In addition, it leads to current switching and hysteresis under strong E field.","This behavior remains robust in the presence of electron-phonon scattering and is therefore expected to be generic."],"url":"http://arxiv.org/abs/2403.18817v1","category":"cond-mat.str-el"}
{"created":"2024-03-27 17:58:20","title":"Equivalence Checking of Quantum Circuits by Model Counting","abstract":"Verifying equivalence between two quantum circuits is a hard problem, that is nonetheless crucial in compiling and optimizing quantum algorithms for real-world devices. This paper gives a Turing reduction of the (universal) quantum circuits equivalence problem to weighted model counting (WMC). Our starting point is a folklore theorem showing that equivalence checking of quantum circuits can be done in the so-called Pauli-basis. We combine this insight with a WMC encoding of quantum circuit simulation, which we extend with support for the Toffoli gate. Finally, we prove that the weights computed by the model counter indeed realize the reduction. With an open-source implementation, we demonstrate that this novel approach can outperform a state-of-the-art equivalence-checking tool based on ZX calculus and decision diagrams.","sentences":["Verifying equivalence between two quantum circuits is a hard problem, that is nonetheless crucial in compiling and optimizing quantum algorithms for real-world devices.","This paper gives a Turing reduction of the (universal) quantum circuits equivalence problem to weighted model counting (WMC).","Our starting point is a folklore theorem showing that equivalence checking of quantum circuits can be done in the so-called Pauli-basis.","We combine this insight with a WMC encoding of quantum circuit simulation, which we extend with support for the Toffoli gate.","Finally, we prove that the weights computed by the model counter indeed realize the reduction.","With an open-source implementation, we demonstrate that this novel approach can outperform a state-of-the-art equivalence-checking tool based on ZX calculus and decision diagrams."],"url":"http://arxiv.org/abs/2403.18813v1","category":"quant-ph"}
{"created":"2024-03-27 17:57:16","title":"On the Communication Complexity of Approximate Pattern Matching","abstract":"The decades-old Pattern Matching with Edits problem, given a length-$n$ string $T$ (the text), a length-$m$ string $P$ (the pattern), and a positive integer $k$ (the threshold), asks to list all fragments of $T$ that are at edit distance at most $k$ from $P$. The one-way communication complexity of this problem is the minimum amount of space needed to encode the answer so that it can be retrieved without accessing the input strings $P$ and $T$.   The closely related Pattern Matching with Mismatches problem (defined in terms of the Hamming distance instead of the edit distance) is already well understood from the communication complexity perspective: Clifford, Kociumaka, and Porat [SODA 2019] proved that $\\Omega(n/m \\cdot k \\log(m/k))$ bits are necessary and $O(n/m \\cdot k\\log (m|\\Sigma|/k))$ bits are sufficient; the upper bound allows encoding not only the occurrences of $P$ in $T$ with at most $k$ mismatches but also the substitutions needed to make each $k$-mismatch occurrence exact.   Despite recent improvements in the running time [Charalampopoulos, Kociumaka, and Wellnitz; FOCS 2020 and 2022], the communication complexity of Pattern Matching with Edits remained unexplored, with a lower bound of $\\Omega(n/m \\cdot k\\log(m/k))$ bits and an upper bound of $O(n/m \\cdot k^3\\log m)$ bits stemming from previous research. In this work, we prove an upper bound of $O(n/m \\cdot k \\log^2 m)$ bits, thus establishing the optimal communication complexity up to logarithmic factors. We also show that $O(n/m \\cdot k \\log m \\log (m|\\Sigma|))$ bits allow encoding, for each $k$-error occurrence of $P$ in $T$, the shortest sequence of edits needed to make the occurrence exact.   We leverage the techniques behind our new result on the communication complexity to obtain quantum algorithms for Pattern Matching with Edits.","sentences":["The decades-old Pattern Matching with Edits problem, given a length-$n$ string $T$ (the text), a length-$m$ string $P$ (the pattern), and a positive integer $k$ (the threshold), asks to list all fragments of $T$ that are at edit distance at most $k$ from $P$. The one-way communication complexity of this problem is the minimum amount of space needed to encode the answer so that it can be retrieved without accessing the input strings $P$ and $T$.   The closely related Pattern Matching with Mismatches problem (defined in terms of the Hamming distance instead of the edit distance) is already well understood from the communication complexity perspective: Clifford, Kociumaka, and","Porat [SODA 2019] proved that $\\Omega(n/m \\cdot k \\log(m/k))$ bits are necessary and $O(n/m \\cdot k\\log (m|\\Sigma|/k))$ bits are sufficient; the upper bound allows encoding not only the occurrences of $P$ in $T$ with at most $k$ mismatches but also the substitutions needed to make each $k$-mismatch occurrence exact.   ","Despite recent improvements in the running time [Charalampopoulos, Kociumaka, and Wellnitz; FOCS 2020 and 2022], the communication complexity of Pattern Matching with Edits remained unexplored, with a lower bound of $\\Omega(n/m \\cdot k\\log(m/k))$ bits and an upper bound of $O(n/m \\cdot k^3\\log m)$ bits stemming from previous research.","In this work, we prove an upper bound of $O(n/m \\cdot k \\log^2 m)$ bits, thus establishing the optimal communication complexity up to logarithmic factors.","We also show that $O(n/m \\cdot k \\log m \\log (m|\\Sigma|))$ bits allow encoding, for each $k$-error occurrence of $P$ in $T$, the shortest sequence of edits needed to make the occurrence exact.   ","We leverage the techniques behind our new result on the communication complexity to obtain quantum algorithms for Pattern Matching with Edits."],"url":"http://arxiv.org/abs/2403.18812v1","category":"cs.DS"}
{"created":"2024-03-27 17:55:32","title":"$L^\\infty$-error bounds for approximations of the Koopman operator by kernel extended dynamic mode decomposition","abstract":"Extended dynamic mode decomposition (EDMD) is a well-established method to generate a data-driven approximation of the Koopman operator for analysis and prediction of nonlinear dynamical systems. Recently, kernel EDMD (kEDMD) has gained popularity due to its ability to resolve the challenging task of choosing a suitable dictionary by defining data-based observables. In this paper, we provide the first pointwise bounds on the approximation error of kEDMD. The main idea consists of two steps. First, we show that the reproducing kernel Hilbert spaces of Wendland functions are invariant under the Koopman operator. Second, exploiting that the learning problem given by regression in the native norm can be recast as an interpolation problem, we prove our novel error bounds by using interpolation estimates. Finally, we validate our findings with numerical experiments.","sentences":["Extended dynamic mode decomposition (EDMD) is a well-established method to generate a data-driven approximation of the Koopman operator for analysis and prediction of nonlinear dynamical systems.","Recently, kernel EDMD (kEDMD) has gained popularity due to its ability to resolve the challenging task of choosing a suitable dictionary by defining data-based observables.","In this paper, we provide the first pointwise bounds on the approximation error of kEDMD.","The main idea consists of two steps.","First, we show that the reproducing kernel Hilbert spaces of Wendland functions are invariant under the Koopman operator.","Second, exploiting that the learning problem given by regression in the native norm can be recast as an interpolation problem, we prove our novel error bounds by using interpolation estimates.","Finally, we validate our findings with numerical experiments."],"url":"http://arxiv.org/abs/2403.18809v1","category":"math.DS"}
{"created":"2024-03-27 17:49:31","title":"Projective Methods for Mitigating Gender Bias in Pre-trained Language Models","abstract":"Mitigation of gender bias in NLP has a long history tied to debiasing static word embeddings. More recently, attention has shifted to debiasing pre-trained language models. We study to what extent the simplest projective debiasing methods, developed for word embeddings, can help when applied to BERT's internal representations. Projective methods are fast to implement, use a small number of saved parameters, and make no updates to the existing model parameters. We evaluate the efficacy of the methods in reducing both intrinsic bias, as measured by BERT's next sentence prediction task, and in mitigating observed bias in a downstream setting when fine-tuned. To this end, we also provide a critical analysis of a popular gender-bias assessment test for quantifying intrinsic bias, resulting in an enhanced test set and new bias measures. We find that projective methods can be effective at both intrinsic bias and downstream bias mitigation, but that the two outcomes are not necessarily correlated. This finding serves as a warning that intrinsic bias test sets, based either on language modeling tasks or next sentence prediction, should not be the only benchmark in developing a debiased language model.","sentences":["Mitigation of gender bias in NLP has a long history tied to debiasing static word embeddings.","More recently, attention has shifted to debiasing pre-trained language models.","We study to what extent the simplest projective debiasing methods, developed for word embeddings, can help when applied to BERT's internal representations.","Projective methods are fast to implement, use a small number of saved parameters, and make no updates to the existing model parameters.","We evaluate the efficacy of the methods in reducing both intrinsic bias, as measured by BERT's next sentence prediction task, and in mitigating observed bias in a downstream setting when fine-tuned.","To this end, we also provide a critical analysis of a popular gender-bias assessment test for quantifying intrinsic bias, resulting in an enhanced test set and new bias measures.","We find that projective methods can be effective at both intrinsic bias and downstream bias mitigation, but that the two outcomes are not necessarily correlated.","This finding serves as a warning that intrinsic bias test sets, based either on language modeling tasks or next sentence prediction, should not be the only benchmark in developing a debiased language model."],"url":"http://arxiv.org/abs/2403.18803v1","category":"cs.CL"}
{"created":"2024-03-27 17:45:29","title":"Dimension-independent functional inequalities by tensorization and projection arguments","abstract":"We study stability under tensorization and projection-type operations of gradient-type estimates and other functional inequalities for Markov semigroups on metric spaces. Using transportation-type inequalities obtained by F. Baudoin and N. Eldredge in 2021, we prove that constants in the gradient estimates can be chosen to be independent of the dimension. Our results are applicable to hypoelliptic diffusions on sub-Riemannian manifolds and some hypocoercive diffusions. As a byproduct, we obtain dimension-independent reverse Poincar\\'{e}, reverse logarithmic Sobolev, and gradient bounds for Lie groups with a transverse symmetry and for non-isotropic Heisenberg groups.","sentences":["We study stability under tensorization and projection-type operations of gradient-type estimates and other functional inequalities for Markov semigroups on metric spaces.","Using transportation-type inequalities obtained by F. Baudoin and N. Eldredge in 2021, we prove that constants in the gradient estimates can be chosen to be independent of the dimension.","Our results are applicable to hypoelliptic diffusions on sub-Riemannian manifolds and some hypocoercive diffusions.","As a byproduct, we obtain dimension-independent reverse Poincar\\'{e}, reverse logarithmic Sobolev, and gradient bounds for Lie groups with a transverse symmetry and for non-isotropic Heisenberg groups."],"url":"http://arxiv.org/abs/2403.18799v1","category":"math.PR"}
{"created":"2024-03-27 17:37:24","title":"Evaluation of transition rates from nonequilibrium instantons","abstract":"Equilibrium rate theories play a crucial role in understanding rare, reactive events. However, they are inapplicable to a range of irreversible processes in systems driven far from thermodynamic equilibrium like active and biological matter. Here, we develop a general, computationally efficient nonequilibrium rate theory in the weak-noise limit based on an instanton approximation to the stochastic path integral and illustrate its wide range of application in the study of rare nonequilibrium events. We demonstrate excellent agreement of the instanton rates with numerically exact results for a particle under a non-conservative force. We also study phase transitions in an active field theory. We elucidate how activity alters the stability of the two phases and their rates of interconversion in a manner that can be well-described by modifying classical nucleation theory","sentences":["Equilibrium rate theories play a crucial role in understanding rare, reactive events.","However, they are inapplicable to a range of irreversible processes in systems driven far from thermodynamic equilibrium like active and biological matter.","Here, we develop a general, computationally efficient nonequilibrium rate theory in the weak-noise limit based on an instanton approximation to the stochastic path integral and illustrate its wide range of application in the study of rare nonequilibrium events.","We demonstrate excellent agreement of the instanton rates with numerically exact results for a particle under a non-conservative force.","We also study phase transitions in an active field theory.","We elucidate how activity alters the stability of the two phases and their rates of interconversion in a manner that can be well-described by modifying classical nucleation theory"],"url":"http://arxiv.org/abs/2403.18794v1","category":"cond-mat.stat-mech"}
{"created":"2024-03-27 17:34:50","title":"Squeezing below the ground state of motion of a continuously monitored levitating nanoparticle","abstract":"Squeezing is a crucial resource for quantum information processing and quantum sensing. In levitated nanomechanics, squeezed states of motion can be generated via temporal control of the trapping frequency of a massive particle. However, the amount of achievable squeezing typically suffers from detrimental environmental effects. We analyze the performance of a scheme that, by embedding careful time-control of trapping potentials and fully accounting for the most relevant sources of noise -- including measurement backaction -- achieves significant levels of mechanical squeezing. The feasibility of our proposal, which is close to experimental state-of-the-art, makes it a valuable tool for quantum state engineering.","sentences":["Squeezing is a crucial resource for quantum information processing and quantum sensing.","In levitated nanomechanics, squeezed states of motion can be generated via temporal control of the trapping frequency of a massive particle.","However, the amount of achievable squeezing typically suffers from detrimental environmental effects.","We analyze the performance of a scheme that, by embedding careful time-control of trapping potentials and fully accounting for the most relevant sources of noise -- including measurement backaction -- achieves significant levels of mechanical squeezing.","The feasibility of our proposal, which is close to experimental state-of-the-art, makes it a valuable tool for quantum state engineering."],"url":"http://arxiv.org/abs/2403.18790v1","category":"quant-ph"}
{"created":"2024-03-27 17:32:04","title":"SplatFace: Gaussian Splat Face Reconstruction Leveraging an Optimizable Surface","abstract":"We present SplatFace, a novel Gaussian splatting framework designed for 3D human face reconstruction without reliance on accurate pre-determined geometry. Our method is designed to simultaneously deliver both high-quality novel view rendering and accurate 3D mesh reconstructions. We incorporate a generic 3D Morphable Model (3DMM) to provide a surface geometric structure, making it possible to reconstruct faces with a limited set of input images. We introduce a joint optimization strategy that refines both the Gaussians and the morphable surface through a synergistic non-rigid alignment process. A novel distance metric, splat-to-surface, is proposed to improve alignment by considering both the Gaussian position and covariance. The surface information is also utilized to incorporate a world-space densification process, resulting in superior reconstruction quality. Our experimental analysis demonstrates that the proposed method is competitive with both other Gaussian splatting techniques in novel view synthesis and other 3D reconstruction methods in producing 3D face meshes with high geometric precision.","sentences":["We present SplatFace, a novel Gaussian splatting framework designed for 3D human face reconstruction without reliance on accurate pre-determined geometry.","Our method is designed to simultaneously deliver both high-quality novel view rendering and accurate 3D mesh reconstructions.","We incorporate a generic 3D Morphable Model (3DMM) to provide a surface geometric structure, making it possible to reconstruct faces with a limited set of input images.","We introduce a joint optimization strategy that refines both the Gaussians and the morphable surface through a synergistic non-rigid alignment process.","A novel distance metric, splat-to-surface, is proposed to improve alignment by considering both the Gaussian position and covariance.","The surface information is also utilized to incorporate a world-space densification process, resulting in superior reconstruction quality.","Our experimental analysis demonstrates that the proposed method is competitive with both other Gaussian splatting techniques in novel view synthesis and other 3D reconstruction methods in producing 3D face meshes with high geometric precision."],"url":"http://arxiv.org/abs/2403.18784v1","category":"cs.CV"}
{"created":"2024-03-27 17:26:42","title":"3P-LLM: Probabilistic Path Planning using Large Language Model for Autonomous Robot Navigation","abstract":"Much worldly semantic knowledge can be encoded in large language models (LLMs). Such information could be of great use to robots that want to carry out high-level, temporally extended commands stated in natural language. However, the lack of real-world experience that language models have is a key limitation that makes it challenging to use them for decision-making inside a particular embodiment. This research assesses the feasibility of using LLM (GPT-3.5-turbo chatbot by OpenAI) for robotic path planning. The shortcomings of conventional approaches to managing complex environments and developing trustworthy plans for shifting environmental conditions serve as the driving force behind the research. Due to the sophisticated natural language processing abilities of LLM, the capacity to provide effective and adaptive path-planning algorithms in real-time, great accuracy, and few-shot learning capabilities, GPT-3.5-turbo is well suited for path planning in robotics. In numerous simulated scenarios, the research compares the performance of GPT-3.5-turbo with that of state-of-the-art path planners like Rapidly Exploring Random Tree (RRT) and A*. We observed that GPT-3.5-turbo is able to provide real-time path planning feedback to the robot and outperforms its counterparts. This paper establishes the foundation for LLM-powered path planning for robotic systems.","sentences":["Much worldly semantic knowledge can be encoded in large language models (LLMs).","Such information could be of great use to robots that want to carry out high-level, temporally extended commands stated in natural language.","However, the lack of real-world experience that language models have is a key limitation that makes it challenging to use them for decision-making inside a particular embodiment.","This research assesses the feasibility of using LLM (GPT-3.5-turbo chatbot by OpenAI) for robotic path planning.","The shortcomings of conventional approaches to managing complex environments and developing trustworthy plans for shifting environmental conditions serve as the driving force behind the research.","Due to the sophisticated natural language processing abilities of LLM, the capacity to provide effective and adaptive path-planning algorithms in real-time, great accuracy, and few-shot learning capabilities, GPT-3.5-turbo is well suited for path planning in robotics.","In numerous simulated scenarios, the research compares the performance of GPT-3.5-turbo with that of state-of-the-art path planners like Rapidly Exploring Random Tree (RRT) and A*.","We observed that GPT-3.5-turbo is able to provide real-time path planning feedback to the robot and outperforms its counterparts.","This paper establishes the foundation for LLM-powered path planning for robotic systems."],"url":"http://arxiv.org/abs/2403.18778v1","category":"cs.RO"}
{"created":"2024-03-27 17:22:07","title":"On the equivalence of all notions of generalized derivations whose domain is a C$^{\\ast}$-algebra","abstract":"Let $\\mathcal{M}$ be a Banach bimodule over an associative Banach algebra $\\mathcal{A}$, and let $F: \\mathcal{A}\\to \\mathcal{M}$ be a linear mapping. Three main uses of the term \\emph{generalized derivation} are identified in the available literature, namely,   ($\\checkmark$) $F$ is a generalized derivation of the first type if there exists a derivation $ d : \\mathcal{A}\\to \\mathcal{M}$ satisfying $F(a b ) = F(a) b + a d(b)$ for all $a,b\\in \\mathcal{A}$.   ($\\checkmark$) $F$ is a generalized derivation of the second type if there exists an element $\\xi\\in \\mathcal{M}^{**}$ satisfying $F(a b ) = F(a) b + a F(b) - a \\xi b$ for all $a,b\\in \\mathcal{A}$.   ($\\checkmark$) $F$ is a generalized derivation of the third type if there exist two (non-necessarily linear) mappings $G,H : \\mathcal{A}\\to \\mathcal{M}$ satisfying $F(a b ) = G(a) b + a H(b)$ for all $a,b\\in \\mathcal{A}$.   There are examples showing that these three definitions are not, in general, equivalent. Despite that the first two notions are well studied when $\\mathcal{A}$ is a C$^*$-algebra, it is not known if the three notions are equivalent under these special assumptions. In this note we prove that every generalized derivation of the third type whose domain is a C$^*$-algebra is automatically continuous. We also prove that every (continuous) generalized derivation of the third type from a C$^*$-algebra $\\mathcal{A}$ into a general Banach $\\mathcal{A}$-bimodule is a generalized derivation of the first and second type. In particular, the three notions coincide in this case. We also explore the possible notions of generalized Jordan derivations on a C$^*$-algebra and establish some continuity properties for them.","sentences":["Let $\\mathcal{M}$ be a Banach bimodule over an associative Banach algebra $\\mathcal{A}$, and let $F: \\mathcal{A}\\to \\mathcal{M}$ be a linear mapping.","Three main uses of the term \\emph{generalized derivation} are identified in the available literature, namely,   ($\\checkmark$) $F$ is a generalized derivation of the first type if there exists a derivation $ d :","\\mathcal{A}\\to \\mathcal{M}$ satisfying $F(a b ) = F(a) b + a d(b)$ for all $a,b\\in \\mathcal{A}$.   ($\\checkmark$) $F$ is a generalized derivation of the second type if there exists an element $\\xi\\in \\mathcal{M}^{**}$ satisfying $F(a b ) = F(a) b + a F(b) - a \\xi b$ for all $a,b\\in \\mathcal{A}$.   ($\\checkmark$) $F$ is a generalized derivation of the third type if there exist two (non-necessarily linear) mappings $G,H :","\\mathcal{A}\\to \\mathcal{M}$ satisfying $F(a b ) = G(a) b + a H(b)$ for all $a,b\\in \\mathcal{A}$.   There are examples showing that these three definitions are not, in general, equivalent.","Despite that the first two notions are well studied when $\\mathcal{A}$ is a C$^*$-algebra, it is not known if the three notions are equivalent under these special assumptions.","In this note we prove that every generalized derivation of the third type whose domain is a C$^*$-algebra is automatically continuous.","We also prove that every (continuous) generalized derivation of the third type from a C$^*$-algebra $\\mathcal{A}$ into a general Banach $\\mathcal{A}$-bimodule is a generalized derivation of the first and second type.","In particular, the three notions coincide in this case.","We also explore the possible notions of generalized Jordan derivations on a C$^*$-algebra and establish some continuity properties for them."],"url":"http://arxiv.org/abs/2403.18773v1","category":"math.OA"}
{"created":"2024-03-27 17:01:32","title":"Duality for Hodge-Witt cohomology with modulus","abstract":"Given an effective Cartier divisor D with simple normal crossing support on a smooth and proper scheme X over a perfect field of positive characteristic p, there is a natural notion of de Rham-Witt sheaves on X with zeros along D. We show that these sheaves correspond under Grothendieck duality for coherent sheaves to de Rham-Witt sheaves on X with modulus (X,D), as defined in the theory of cube invariant modulus sheaves with transfers developed by Kahn-Miyazaki-Saito-Yamazaki. From this we deduce refined versions of Ekedahl - and Poincar\\'e duality for crystalline cohomology generalizing results of Mokrane and Nakkajima for reduced D, and a modulus version of Milne-Kato duality for \\'etale motivic cohomology with p-primary torsion coefficients, which refines a result of Jannsen-Saito-Zhao. We furthermore get new integral models for rigid cohomology with compact supports on the complement of D and a modulus version of Milne's perfect Brauer group pairing for smooth projective surfaces over finite fields.","sentences":["Given an effective Cartier divisor D with simple normal crossing support on a smooth and proper scheme X over a perfect field of positive characteristic p, there is a natural notion of de Rham-Witt sheaves on X with zeros along D. We show that these sheaves correspond under Grothendieck duality for coherent sheaves to de Rham-Witt sheaves on X with modulus (X,D), as defined in the theory of cube invariant modulus sheaves with transfers developed by Kahn-Miyazaki-Saito-Yamazaki.","From this we deduce refined versions of Ekedahl - and Poincar\\'e duality for crystalline cohomology generalizing results of Mokrane and Nakkajima for reduced D, and a modulus version of Milne-Kato duality for \\'etale motivic cohomology with p-primary torsion coefficients, which refines a result of Jannsen-Saito-Zhao.","We furthermore get new integral models for rigid cohomology with compact supports on the complement of D and a modulus version of Milne's perfect Brauer group pairing for smooth projective surfaces over finite fields."],"url":"http://arxiv.org/abs/2403.18763v1","category":"math.AG"}
{"created":"2024-03-27 16:57:48","title":"On the cohomological dimension of kernels of maps to $\\mathbb Z$","abstract":"We prove that if $G$ is a finitely generated RFRS group of cohomological dimension $2$, then $G$ is virtually free-by-cyclic if and only if $b_2^{(2)}(G) = 0$. This answers a question of Wise and generalises and gives a new proof of a recent theorem of Kielak and Linton, where the same result is obtained under the additional hypotheses that $G$ is virtually compact special and hyperbolic. More generally, we show that if $G$ is a RFRS group of cohomological dimension $n$ and of type $\\mathrm{FP}_{n-1}$, then $G$ admits a virtual map to $\\mathbb Z$ with kernel of rational cohomological dimension $n-1$ if and only if $b_n^{(2)}(G) = 0$.","sentences":["We prove that if $G$ is a finitely generated RFRS group of cohomological dimension $2$, then $G$ is virtually free-by-cyclic if and only if $b_2^{(2)}(G) = 0$.","This answers a question of Wise and generalises and gives a new proof of a recent theorem of Kielak and Linton, where the same result is obtained under the additional hypotheses that $G$ is virtually compact special and hyperbolic.","More generally, we show that if $G$ is a RFRS group of cohomological dimension $n$ and of type $\\mathrm{FP}_{n-1}$, then $G$ admits a virtual map to $\\mathbb Z$ with kernel of rational cohomological dimension $n-1$ if and only if $b_n^{(2)}(G) = 0$."],"url":"http://arxiv.org/abs/2403.18758v1","category":"math.GR"}
{"created":"2024-03-27 17:50:00","title":"Is Modularity Transferable? A Case Study through the Lens of Knowledge Distillation","abstract":"The rise of Modular Deep Learning showcases its potential in various Natural Language Processing applications. Parameter-efficient fine-tuning (PEFT) modularity has been shown to work for various use cases, from domain adaptation to multilingual setups. However, all this work covers the case where the modular components are trained and deployed within one single Pre-trained Language Model (PLM). This model-specific setup is a substantial limitation on the very modularity that modular architectures are trying to achieve. We ask whether current modular approaches are transferable between models and whether we can transfer the modules from more robust and larger PLMs to smaller ones. In this work, we aim to fill this gap via a lens of Knowledge Distillation, commonly used for model compression, and present an extremely straightforward approach to transferring pre-trained, task-specific PEFT modules between same-family PLMs. Moreover, we propose a method that allows the transfer of modules between incompatible PLMs without any change in the inference complexity. The experiments on Named Entity Recognition, Natural Language Inference, and Paraphrase Identification tasks over multiple languages and PEFT methods showcase the initial potential of transferable modularity.","sentences":["The rise of Modular Deep Learning showcases its potential in various Natural Language Processing applications.","Parameter-efficient fine-tuning (PEFT) modularity has been shown to work for various use cases, from domain adaptation to multilingual setups.","However, all this work covers the case where the modular components are trained and deployed within one single Pre-trained Language Model (PLM).","This model-specific setup is a substantial limitation on the very modularity that modular architectures are trying to achieve.","We ask whether current modular approaches are transferable between models and whether we can transfer the modules from more robust and larger PLMs to smaller ones.","In this work, we aim to fill this gap via a lens of Knowledge Distillation, commonly used for model compression, and present an extremely straightforward approach to transferring pre-trained, task-specific PEFT modules between same-family PLMs.","Moreover, we propose a method that allows the transfer of modules between incompatible PLMs without any change in the inference complexity.","The experiments on Named Entity Recognition, Natural Language Inference, and Paraphrase Identification tasks over multiple languages and PEFT methods showcase the initial potential of transferable modularity."],"url":"http://arxiv.org/abs/2403.18804v1","category":"cs.CL"}
{"created":"2024-03-27 17:31:39","title":"Towards a World-English Language Model for On-Device Virtual Assistants","abstract":"Neural Network Language Models (NNLMs) for Virtual Assistants (VAs) are generally language-, region-, and in some cases, device-dependent, which increases the effort to scale and maintain them. Combining NNLMs for one or more of the categories is one way to improve scalability. In this work, we combine regional variants of English to build a ``World English'' NNLM for on-device VAs. In particular, we investigate the application of adapter bottlenecks to model dialect-specific characteristics in our existing production NNLMs {and enhance the multi-dialect baselines}. We find that adapter modules are more effective in modeling dialects than specializing entire sub-networks. Based on this insight and leveraging the design of our production models, we introduce a new architecture for World English NNLM that meets the accuracy, latency, and memory constraints of our single-dialect models.","sentences":["Neural Network Language Models (NNLMs) for Virtual Assistants (VAs) are generally language-, region-, and in some cases, device-dependent, which increases the effort to scale and maintain them.","Combining NNLMs for one or more of the categories is one way to improve scalability.","In this work, we combine regional variants of English to build a ``World English'' NNLM for on-device VAs.","In particular, we investigate the application of adapter bottlenecks to model dialect-specific characteristics in our existing production NNLMs {and enhance the multi-dialect baselines}.","We find that adapter modules are more effective in modeling dialects than specializing entire sub-networks.","Based on this insight and leveraging the design of our production models, we introduce a new architecture for World English NNLM that meets the accuracy, latency, and memory constraints of our single-dialect models."],"url":"http://arxiv.org/abs/2403.18783v1","category":"cs.CL"}
{"created":"2024-03-27 17:23:45","title":"Breaking the Limitations with Sparse Inputs by Variational Frameworks (BLIss) in Terahertz Super-Resolution 3D Reconstruction","abstract":"Data acquisition, image processing, and image quality are the long-lasting issues for terahertz (THz) 3D reconstructed imaging. Existing methods are primarily designed for 2D scenarios, given the challenges associated with obtaining super-resolution (SR) data and the absence of an efficient SR 3D reconstruction framework in conventional computed tomography (CT). Here, we demonstrate BLIss, a new approach for THz SR 3D reconstruction with sparse 2D data input. BLIss seamlessly integrates conventional CT techniques and variational framework with the core of the adapted Euler-Elastica-based model. The quantitative 3D image evaluation metrics, including the standard deviation of Gaussian, mean curvatures, and the multi-scale structural similarity index measure (MS-SSIM), validate the superior smoothness and fidelity achieved with our variational framework approach compared with conventional THz CT modal. Beyond its contributions to advancing THz SR 3D reconstruction, BLIss demonstrates potential applicability in other imaging modalities, such as X-ray and MRI. This suggests extensive impacts on the broader field of imaging applications.","sentences":["Data acquisition, image processing, and image quality are the long-lasting issues for terahertz (THz) 3D reconstructed imaging.","Existing methods are primarily designed for 2D scenarios, given the challenges associated with obtaining super-resolution (SR) data and the absence of an efficient SR 3D reconstruction framework in conventional computed tomography (CT).","Here, we demonstrate BLIss, a new approach for THz SR 3D reconstruction with sparse 2D data input.","BLIss seamlessly integrates conventional CT techniques and variational framework with the core of the adapted Euler-Elastica-based model.","The quantitative 3D image evaluation metrics, including the standard deviation of Gaussian, mean curvatures, and the multi-scale structural similarity index measure (MS-SSIM), validate the superior smoothness and fidelity achieved with our variational framework approach compared with conventional THz CT modal.","Beyond its contributions to advancing THz SR 3D reconstruction, BLIss demonstrates potential applicability in other imaging modalities, such as X-ray and MRI.","This suggests extensive impacts on the broader field of imaging applications."],"url":"http://arxiv.org/abs/2403.18776v1","category":"physics.optics"}
{"created":"2024-03-27 16:59:21","title":"MATTopo: Topology-preserving Medial Axis Transform with Restricted Power Diagram","abstract":"We present a novel volumetric RPD (restricted power diagram) based framework for approximating the medial axes of 3D CAD shapes adaptively, while preserving topological equivalence, medial features, and geometric convergence. To solve the topology preservation problem, we propose a volumetric RPD based strategy, which discretizes the input volume into sub-regions given a set of medial spheres. With this intermediate structure, we convert the homotopy equivalence between the generated medial mesh and the input 3D shape into a localized problem between each primitive of the medial mesh (vertex, edge, face) and its dual restricted elements (power cell, power face, power edge), by checking their connected components and Euler characteristics. We further proposed a fractional Euler characteristic strategy for efficient GPU-based computation of Euler characteristic for each restricted element on the fly while computing the volumetric RPD. Compared with existing voxel-based or sampling-based methods, our method is the first that can adaptively and directly revise the medial mesh without modifying the dependent structure globally, such as voxel size or sampling density. Compared with the feature preservation method MATFP, our method offers geometrically comparable results with fewer number of spheres, while more robustly captures the topology of the input shape.","sentences":["We present a novel volumetric RPD (restricted power diagram) based framework for approximating the medial axes of 3D CAD shapes adaptively, while preserving topological equivalence, medial features, and geometric convergence.","To solve the topology preservation problem, we propose a volumetric RPD based strategy, which discretizes the input volume into sub-regions given a set of medial spheres.","With this intermediate structure, we convert the homotopy equivalence between the generated medial mesh and the input 3D shape into a localized problem between each primitive of the medial mesh (vertex, edge, face) and its dual restricted elements (power cell, power face, power edge), by checking their connected components and Euler characteristics.","We further proposed a fractional Euler characteristic strategy for efficient GPU-based computation of Euler characteristic for each restricted element on the fly while computing the volumetric RPD.","Compared with existing voxel-based or sampling-based methods, our method is the first that can adaptively and directly revise the medial mesh without modifying the dependent structure globally, such as voxel size or sampling density.","Compared with the feature preservation method MATFP, our method offers geometrically comparable results with fewer number of spheres, while more robustly captures the topology of the input shape."],"url":"http://arxiv.org/abs/2403.18761v1","category":"cs.GR"}
{"created":"2024-03-27 16:58:09","title":"Symmetries of the Large Scale Structures of the Universe as a Phenomenology of a Fractal Turbulence: The Role of the Plasma Component","abstract":"We present a new perspective on the symmetries that govern the formation of large-scale structures across the Universe, particularly focusing on the transition from the seeds of galaxy clusters to the seeds of galaxies themselves. We address two main features of cosmological fluid dynamics pertaining to both the linear and non-linear regimes. The linear dynamics of cosmological perturbations within the Hubble horizon is characterized by the Jeans length, which separates stable configurations from unstable fluctuations due to the gravitational effect on sufficiently large (and therefore, massive enough) overdensities. On the other hand, the non-linear dynamics of the cosmological fluid is associated with a turbulent behavior once the Reynolds numbers reach a sufficiently high level. This turbulent regime leads to energy dissipation across smaller and smaller scales, resulting in a fractal distribution of eddies throughout physical space. The proposed scenario suggests that the spatial scale of eddy formation is associated with the Jeans length of various levels of fragmentation from an original large-scale structure. By focusing on the fragmentation of galaxy cluster seeds versus galaxy seeds, we arrived at a phenomenological law that links the ratio of the two structure densities to the number of galaxies in each cluster and to the Hausdorff number of the Universe matter distribution. Finally, we introduced a primordial magnetic field and studied its influence on the Jeans length dynamics. The resulting anisotropic behavior of the density contrast led us to infer that the main features of the turbulence could be reduced to a 2D Euler equation. Numerical simulations showed that the two lowest wavenumbers contained the major energy contribution of the spectrum.","sentences":["We present a new perspective on the symmetries that govern the formation of large-scale structures across the Universe, particularly focusing on the transition from the seeds of galaxy clusters to the seeds of galaxies themselves.","We address two main features of cosmological fluid dynamics pertaining to both the linear and non-linear regimes.","The linear dynamics of cosmological perturbations within the Hubble horizon is characterized by the Jeans length, which separates stable configurations from unstable fluctuations due to the gravitational effect on sufficiently large (and therefore, massive enough) overdensities.","On the other hand, the non-linear dynamics of the cosmological fluid is associated with a turbulent behavior once the Reynolds numbers reach a sufficiently high level.","This turbulent regime leads to energy dissipation across smaller and smaller scales, resulting in a fractal distribution of eddies throughout physical space.","The proposed scenario suggests that the spatial scale of eddy formation is associated with the Jeans length of various levels of fragmentation from an original large-scale structure.","By focusing on the fragmentation of galaxy cluster seeds versus galaxy seeds, we arrived at a phenomenological law that links the ratio of the two structure densities to the number of galaxies in each cluster and to the Hausdorff number of the Universe matter distribution.","Finally, we introduced a primordial magnetic field and studied its influence on the Jeans length dynamics.","The resulting anisotropic behavior of the density contrast led us to infer that the main features of the turbulence could be reduced to a 2D Euler equation.","Numerical simulations showed that the two lowest wavenumbers contained the major energy contribution of the spectrum."],"url":"http://arxiv.org/abs/2403.18759v1","category":"astro-ph.CO"}
{"created":"2024-03-27 16:53:33","title":"Long gamma-ray burst light curves as the result of a common stochastic pulse-avalanche process","abstract":"Context. The complexity and variety exhibited by the light curves of long gamma-ray bursts (GRBs) enclose a wealth of information that still awaits being fully deciphered. Despite the tremendous advance in the knowledge of the energetics, structure, and composition of the relativistic jet that results from the core collapse of the progenitor star, the nature of the inner engine, how it powers the relativistic outflow, and the dissipation mechanisms remain open issues. Aims. A promising way to gain insights is describing GRB light curves as the result of a common stochastic process. In the Burst And Transient Source Experiment (BATSE) era, a stochastic pulse avalanche model was proposed and tested through the comparison of ensemble-average properties of simulated and real light curves. Here we aim to revive and further test this model. Methods. We apply it to two independent data sets, BATSE and Swift/BAT, through a machine learning approach: the model parameters are optimised using a genetic algorithm. Results. The average properties are successfully reproduced. Notwithstanding the different populations and passbands of both data sets, the corresponding optimal parameters are interestingly similar. In particular, for both sets the dynamics appears to be close to a critical state, which is key to reproduce the observed variety of time profiles. Conclusions. Our results propel the avalanche character in a critical regime as a key trait of the energy release in GRB engines, which underpins some kind of instability.","sentences":["Context.","The complexity and variety exhibited by the light curves of long gamma-ray bursts (GRBs) enclose a wealth of information that still awaits being fully deciphered.","Despite the tremendous advance in the knowledge of the energetics, structure, and composition of the relativistic jet that results from the core collapse of the progenitor star, the nature of the inner engine, how it powers the relativistic outflow, and the dissipation mechanisms remain open issues.","Aims.","A promising way to gain insights is describing GRB light curves as the result of a common stochastic process.","In the Burst And Transient Source Experiment (BATSE) era, a stochastic pulse avalanche model was proposed and tested through the comparison of ensemble-average properties of simulated and real light curves.","Here we aim to revive and further test this model.","Methods.","We apply it to two independent data sets, BATSE and Swift/BAT, through a machine learning approach: the model parameters are optimised using a genetic algorithm.","Results.","The average properties are successfully reproduced.","Notwithstanding the different populations and passbands of both data sets, the corresponding optimal parameters are interestingly similar.","In particular, for both sets the dynamics appears to be close to a critical state, which is key to reproduce the observed variety of time profiles.","Conclusions.","Our results propel the avalanche character in a critical regime as a key trait of the energy release in GRB engines, which underpins some kind of instability."],"url":"http://arxiv.org/abs/2403.18754v1","category":"astro-ph.HE"}
{"created":"2024-03-27 16:50:12","title":"Full counting statistics of 1d short-range Riesz gases in confinement","abstract":"We investigate the full counting statistics (FCS) of a harmonically confined 1d short-range Riesz gas consisting of $N$ particles in equilibrium at finite temperature. The particles interact with each other through a repulsive power-law interaction with an exponent $k>1$ which includes the Calogero-Moser model for $k=2$. We examine the probability distribution of the number of particles in a finite domain $[-W, W]$ called number distribution, denoted by $\\mathcal{N}(W, N)$. We analyze the probability distribution of $\\mathcal{N}(W, N)$ and show that it exhibits a large deviation form for large $N$ characterised by a speed $N^{\\frac{3k+2}{k+2}}$ and by a large deviation function of the fraction $c = \\mathcal{N}(W, N)/N$ of the particles inside the domain and $W$. We show that the density profiles that create the large deviations display interesting shape transitions as one varies $c$ and $W$. This is manifested by a third-order phase transition exhibited by the large deviation function that has discontinuous third derivatives. Monte-Carlo (MC) simulations show good agreement with our analytical expressions for the corresponding density profiles. We find that the typical fluctuations of $\\mathcal{N}(W, N)$, obtained from our field theoretic calculations are Gaussian distributed with a variance that scales as $N^{\\nu_k}$, with $\\nu_k = (2-k)/(2+k)$. We also present some numerical findings on the mean and the variance. Furthermore, we adapt our formalism to study the index distribution (where the domain is semi-infinite $(-\\infty, W])$, linear statistics (the variance), thermodynamic pressure and bulk modulus.","sentences":["We investigate the full counting statistics (FCS) of a harmonically confined 1d short-range Riesz gas consisting of $N$ particles in equilibrium at finite temperature.","The particles interact with each other through a repulsive power-law interaction with an exponent $k>1$ which includes the Calogero-Moser model for $k=2$. We examine the probability distribution of the number of particles in a finite domain $[-W, W]$ called number distribution, denoted by $\\mathcal{N}(W, N)$. We analyze the probability distribution of $\\mathcal{N}(W, N)$ and show that it exhibits a large deviation form for large $N$ characterised by a speed $N^{\\frac{3k+2}{k+2}}$ and by a large deviation function of the fraction $c = \\mathcal{N}(W, N)/N$ of the particles inside the domain and $W$. We show that the density profiles that create the large deviations display interesting shape transitions as one varies $c$ and $W$. This is manifested by a third-order phase transition exhibited by the large deviation function that has discontinuous third derivatives.","Monte-Carlo (MC) simulations show good agreement with our analytical expressions for the corresponding density profiles.","We find that the typical fluctuations of $\\mathcal{N}(W, N)$, obtained from our field theoretic calculations are Gaussian distributed with a variance that scales as $N^{\\nu_k}$, with $\\nu_k = (2-k)/(2+k)$.","We also present some numerical findings on the mean and the variance.","Furthermore, we adapt our formalism to study the index distribution (where the domain is semi-infinite $(-\\infty, W])$, linear statistics (the variance), thermodynamic pressure and bulk modulus."],"url":"http://arxiv.org/abs/2403.18750v1","category":"cond-mat.stat-mech"}
{"created":"2024-03-27 15:42:36","title":"Anomalous friction of supercooled glycerol on mica","abstract":"The fundamental understanding of friction of liquids on solid surfaces remains one of the key knowledge gaps in the transport of fluids. While the standard perspective emphasizes the role of wettability and commensurability, recent works have unveiled the crucial role of the solid's internal excitations, whether electronic or phononic, on liquid-solid dissipation. In this work, we take advantage of the considerable variation of the molecular timescales of supercooled glycerol under mild change of temperature, in order to explore how friction depends on the liquid's molecular dynamics. Using a dedicated tuning-fork-based AFM to measure the hydrodynamic slippage of glycerol on mica, we report a 2-order of magnitude increase of the slip length with decreasing temperature by only 30{\\deg}C. However the solid-liquid friction coefficient is found to be a non monotonous function of the fluid molecular relaxation rate, f{\\alpha}, at odd with an expected Arrhenius behavior. In particular, the linear increase of friction with the liquid molecular rate measured at high temperature cannot be accounted for by existing modelling. We show that this unconventional and non-arrhenian friction is consistent with a contribution of the solid's phonons to the liquid-solid friction. This dynamical friction opens new perspectives to control hydrodynamic flows by properly engineering phononic and electronic excitation spectra in channel walls.","sentences":["The fundamental understanding of friction of liquids on solid surfaces remains one of the key knowledge gaps in the transport of fluids.","While the standard perspective emphasizes the role of wettability and commensurability, recent works have unveiled the crucial role of the solid's internal excitations, whether electronic or phononic, on liquid-solid dissipation.","In this work, we take advantage of the considerable variation of the molecular timescales of supercooled glycerol under mild change of temperature, in order to explore how friction depends on the liquid's molecular dynamics.","Using a dedicated tuning-fork-based AFM to measure the hydrodynamic slippage of glycerol on mica, we report a 2-order of magnitude increase of the slip length with decreasing temperature by only 30{\\deg}C.","However the solid-liquid friction coefficient is found to be a non monotonous function of the fluid molecular relaxation rate, f{\\alpha}, at odd with an expected Arrhenius behavior.","In particular, the linear increase of friction with the liquid molecular rate measured at high temperature cannot be accounted for by existing modelling.","We show that this unconventional and non-arrhenian friction is consistent with a contribution of the solid's phonons to the liquid-solid friction.","This dynamical friction opens new perspectives to control hydrodynamic flows by properly engineering phononic and electronic excitation spectra in channel walls."],"url":"http://arxiv.org/abs/2403.18693v1","category":"cond-mat.soft"}
{"created":"2024-03-27 15:15:14","title":"Fact Checking Beyond Training Set","abstract":"Evaluating the veracity of everyday claims is time consuming and in some cases requires domain expertise. We empirically demonstrate that the commonly used fact checking pipeline, known as the retriever-reader, suffers from performance deterioration when it is trained on the labeled data from one domain and used in another domain. Afterwards, we delve into each component of the pipeline and propose novel algorithms to address this problem. We propose an adversarial algorithm to make the retriever component robust against distribution shift. Our core idea is to initially train a bi-encoder on the labeled source data, and then, to adversarially train two separate document and claim encoders using unlabeled target data. We then focus on the reader component and propose to train it such that it is insensitive towards the order of claims and evidence documents. Our empirical evaluations support the hypothesis that such a reader shows a higher robustness against distribution shift. To our knowledge, there is no publicly available multi-topic fact checking dataset. Thus, we propose a simple automatic method to re-purpose two well-known fact checking datasets. We then construct eight fact checking scenarios from these datasets, and compare our model to a set of strong baseline models, including recent domain adaptation models that use GPT4 for generating synthetic data.","sentences":["Evaluating the veracity of everyday claims is time consuming and in some cases requires domain expertise.","We empirically demonstrate that the commonly used fact checking pipeline, known as the retriever-reader, suffers from performance deterioration when it is trained on the labeled data from one domain and used in another domain.","Afterwards, we delve into each component of the pipeline and propose novel algorithms to address this problem.","We propose an adversarial algorithm to make the retriever component robust against distribution shift.","Our core idea is to initially train a bi-encoder on the labeled source data, and then, to adversarially train two separate document and claim encoders using unlabeled target data.","We then focus on the reader component and propose to train it such that it is insensitive towards the order of claims and evidence documents.","Our empirical evaluations support the hypothesis that such a reader shows a higher robustness against distribution shift.","To our knowledge, there is no publicly available multi-topic fact checking dataset.","Thus, we propose a simple automatic method to re-purpose two well-known fact checking datasets.","We then construct eight fact checking scenarios from these datasets, and compare our model to a set of strong baseline models, including recent domain adaptation models that use GPT4 for generating synthetic data."],"url":"http://arxiv.org/abs/2403.18671v1","category":"cs.CL"}
{"created":"2024-03-27 14:58:11","title":"MPC-CBF with Adaptive Safety Margins for Safety-critical Teleoperation over Imperfect Network Connections","abstract":"The paper focuses on the design of a control strategy for safety-critical remote teleoperation. The main goal is to make the controlled system track the desired velocity specified by an operator while avoiding obstacles despite communication delays. Control Barrier Functions (CBFs) are used to define the safety constraints that the system has to respect to avoid obstacles, while Model Predictive Control (MPC) provides the framework for adjusting the desired input, taking the constraints into account. The resulting input is sent to the remote system, where appropriate low-level velocity controllers translate it into system-specific commands. The main novelty of the paper is a method to make the CBFs robust against the uncertainties caused by the network delays affecting the system's state and do so in a less conservative manner. The results show how the proposed method successfully solves the safety-critical teleoperation problem, making the controlled systems avoid obstacles with different types of network delay. The controller has also been tested in simulation and on a real manipulator, demonstrating its general applicability when reliable low-level velocity controllers are available.","sentences":["The paper focuses on the design of a control strategy for safety-critical remote teleoperation.","The main goal is to make the controlled system track the desired velocity specified by an operator while avoiding obstacles despite communication delays.","Control Barrier Functions (CBFs) are used to define the safety constraints that the system has to respect to avoid obstacles, while Model Predictive Control (MPC) provides the framework for adjusting the desired input, taking the constraints into account.","The resulting input is sent to the remote system, where appropriate low-level velocity controllers translate it into system-specific commands.","The main novelty of the paper is a method to make the CBFs robust against the uncertainties caused by the network delays affecting the system's state and do so in a less conservative manner.","The results show how the proposed method successfully solves the safety-critical teleoperation problem, making the controlled systems avoid obstacles with different types of network delay.","The controller has also been tested in simulation and on a real manipulator, demonstrating its general applicability when reliable low-level velocity controllers are available."],"url":"http://arxiv.org/abs/2403.18650v1","category":"cs.SY"}
{"created":"2024-03-27 14:54:27","title":"SDSAT: Accelerating LLM Inference through Speculative Decoding with Semantic Adaptive Tokens","abstract":"We propose an acceleration scheme for large language models (LLMs) through Speculative Decoding with Semantic Adaptive Tokens (SDSAT). The primary objective of this design is to enhance the LLM model's ability to generate draft tokens more accurately without compromising the model's accuracy. The core strategies involve: 1) Fine-tune the model by incorporating semantic adaptive tokens that possess flexible decoding capabilities without changing its structure, allowing them to generate high-quality draft tokens. 2) By employing a training method that does not affect the standard tokens, the model can acquire parallel decoding abilities atop its original framework with minimal training overhead. 3) We have designed the \"two-step-draft-then-verify\" generation strategies using both greedy search and nucleus sampling. Experiments conducted on the CodeLlama-13B and 7B models have yielded speed increases of over 3.5X and 3.0X, respectively. Please refer to https://github.com/hasuoshenyun/SDSAT.","sentences":["We propose an acceleration scheme for large language models (LLMs) through Speculative Decoding with Semantic Adaptive Tokens (SDSAT).","The primary objective of this design is to enhance the LLM model's ability to generate draft tokens more accurately without compromising the model's accuracy.","The core strategies involve: 1) Fine-tune the model by incorporating semantic adaptive tokens that possess flexible decoding capabilities without changing its structure, allowing them to generate high-quality draft tokens.","2) By employing a training method that does not affect the standard tokens, the model can acquire parallel decoding abilities atop its original framework with minimal training overhead.","3) We have designed the \"two-step-draft-then-verify\" generation strategies using both greedy search and nucleus sampling.","Experiments conducted on the CodeLlama-13B and 7B models have yielded speed increases of over 3.5X and 3.0X, respectively.","Please refer to https://github.com/hasuoshenyun/SDSAT."],"url":"http://arxiv.org/abs/2403.18647v1","category":"cs.CL"}
{"created":"2024-03-27 14:44:24","title":"Mind the Domain Gap: a Systematic Analysis on Bioacoustic Sound Event Detection","abstract":"Detecting the presence of animal vocalisations in nature is essential to study animal populations and their behaviors. A recent development in the field is the introduction of the task known as few-shot bioacoustic sound event detection, which aims to train a versatile animal sound detector using only a small set of audio samples. Previous efforts in this area have utilized different architectures and data augmentation techniques to enhance model performance. However, these approaches have not fully bridged the domain gap between source and target distributions, limiting their applicability in real-world scenarios. In this work, we introduce an new dataset designed to augment the diversity and breadth of classes available for few-shot bioacoustic event detection, building on the foundations of our previous datasets. To establish a robust baseline system tailored for the DCASE 2024 Task 5 challenge, we delve into an array of acoustic features and adopt negative hard sampling as our primary domain adaptation strategy. This approach, chosen in alignment with the challenge's guidelines that necessitate the independent treatment of each audio file, sidesteps the use of transductive learning to ensure compliance while aiming to enhance the system's adaptability to domain shifts. Our experiments show that the proposed baseline system achieves a better performance compared with the vanilla prototypical network. The findings also confirm the effectiveness of each domain adaptation method by ablating different components within the networks. This highlights the potential to improve few-shot bioacoustic sound event detection by further reducing the impact of domain shift.","sentences":["Detecting the presence of animal vocalisations in nature is essential to study animal populations and their behaviors.","A recent development in the field is the introduction of the task known as few-shot bioacoustic sound event detection, which aims to train a versatile animal sound detector using only a small set of audio samples.","Previous efforts in this area have utilized different architectures and data augmentation techniques to enhance model performance.","However, these approaches have not fully bridged the domain gap between source and target distributions, limiting their applicability in real-world scenarios.","In this work, we introduce an new dataset designed to augment the diversity and breadth of classes available for few-shot bioacoustic event detection, building on the foundations of our previous datasets.","To establish a robust baseline system tailored for the DCASE 2024 Task 5 challenge, we delve into an array of acoustic features and adopt negative hard sampling as our primary domain adaptation strategy.","This approach, chosen in alignment with the challenge's guidelines that necessitate the independent treatment of each audio file, sidesteps the use of transductive learning to ensure compliance while aiming to enhance the system's adaptability to domain shifts.","Our experiments show that the proposed baseline system achieves a better performance compared with the vanilla prototypical network.","The findings also confirm the effectiveness of each domain adaptation method by ablating different components within the networks.","This highlights the potential to improve few-shot bioacoustic sound event detection by further reducing the impact of domain shift."],"url":"http://arxiv.org/abs/2403.18638v1","category":"eess.AS"}
{"created":"2024-03-27 14:32:56","title":"Enhanced OpenMP Algorithm to Compute All-Pairs Shortest Path on x86 Architectures","abstract":"Graphs have become a key tool when modeling and solving problems in different areas. The Floyd-Warshall (FW) algorithm computes the shortest path between all pairs of vertices in a graph and is employed in areas like communication networking, traffic routing, bioinformatics, among others. However, FW is computationally and spatially expensive since it requires O(n^3) operations and O(n^2) memory space. As the graph gets larger, parallel computing becomes necessary to provide a solution in an acceptable time range. In this paper, we studied a FW code developed for Xeon Phi KNL processors and adapted it to run on any Intel x86 processors, losing the specificity of the former. To do so, we verified one by one the optimizations proposed by the original code, making adjustments to the base code where necessary, and analyzing its performance on two Intel servers under different test scenarios. In addition, a new optimization was proposed to increase the concurrency degree of the parallel algorithm, which was implemented using two different synchronization mechanisms. The experimental results show that all optimizations were beneficial on the two x86 platforms selected. Last, the new optimization proposal improved performance by up to 23%.","sentences":["Graphs have become a key tool when modeling and solving problems in different areas.","The Floyd-Warshall (FW) algorithm computes the shortest path between all pairs of vertices in a graph and is employed in areas like communication networking, traffic routing, bioinformatics, among others.","However, FW is computationally and spatially expensive since it requires O(n^3) operations and O(n^2) memory space.","As the graph gets larger, parallel computing becomes necessary to provide a solution in an acceptable time range.","In this paper, we studied a FW code developed for Xeon Phi KNL processors and adapted it to run on any Intel x86 processors, losing the specificity of the former.","To do so, we verified one by one the optimizations proposed by the original code, making adjustments to the base code where necessary, and analyzing its performance on two Intel servers under different test scenarios.","In addition, a new optimization was proposed to increase the concurrency degree of the parallel algorithm, which was implemented using two different synchronization mechanisms.","The experimental results show that all optimizations were beneficial on the two x86 platforms selected.","Last, the new optimization proposal improved performance by up to 23%."],"url":"http://arxiv.org/abs/2403.18619v1","category":"cs.DC"}
{"created":"2024-03-27 14:24:30","title":"FlexEdit: Flexible and Controllable Diffusion-based Object-centric Image Editing","abstract":"Our work addresses limitations seen in previous approaches for object-centric editing problems, such as unrealistic results due to shape discrepancies and limited control in object replacement or insertion. To this end, we introduce FlexEdit, a flexible and controllable editing framework for objects where we iteratively adjust latents at each denoising step using our FlexEdit block. Initially, we optimize latents at test time to align with specified object constraints. Then, our framework employs an adaptive mask, automatically extracted during denoising, to protect the background while seamlessly blending new content into the target image. We demonstrate the versatility of FlexEdit in various object editing tasks and curate an evaluation test suite with samples from both real and synthetic images, along with novel evaluation metrics designed for object-centric editing. We conduct extensive experiments on different editing scenarios, demonstrating the superiority of our editing framework over recent advanced text-guided image editing methods. Our project page is published at https://flex-edit.github.io/.","sentences":["Our work addresses limitations seen in previous approaches for object-centric editing problems, such as unrealistic results due to shape discrepancies and limited control in object replacement or insertion.","To this end, we introduce FlexEdit, a flexible and controllable editing framework for objects where we iteratively adjust latents at each denoising step using our FlexEdit block.","Initially, we optimize latents at test time to align with specified object constraints.","Then, our framework employs an adaptive mask, automatically extracted during denoising, to protect the background while seamlessly blending new content into the target image.","We demonstrate the versatility of FlexEdit in various object editing tasks and curate an evaluation test suite with samples from both real and synthetic images, along with novel evaluation metrics designed for object-centric editing.","We conduct extensive experiments on different editing scenarios, demonstrating the superiority of our editing framework over recent advanced text-guided image editing methods.","Our project page is published at https://flex-edit.github.io/."],"url":"http://arxiv.org/abs/2403.18605v2","category":"cs.CV"}
{"created":"2024-03-27 13:44:20","title":"Natural convection in a vertical channel. Part 2. Oblique solutions and global bifurcations in a spanwise-extended domain","abstract":"Vertical thermal convection is a non-equilibrium system in which both buoyancy and shear forces play a role in driving the convective flow. Beyond the onset of convection, the driven dissipative system exhibits chaotic dynamics and turbulence. In a three-dimensional domain extended in both the vertical and the transverse dimensions, Gao et al. (2018) have observed a variety of convection patterns which are not described by linear stability analysis. We investigate the fully non-linear dynamics of vertical convection using a dynamical-systems approach based on the Oberbeck-Boussinesq equations. We compute the invariant solutions of these equations and the bifurcations that are responsible for the creation and termination of various branches. We map out a sequence of local bifurcations from the laminar base state, including simultaneous bifurcations involving patterned steady states with different symmetries. This atypical phenomenon of multiple branches simultaneously bifurcating from a single parent branch is explained by the role of D4 symmetry. In addition, two global bifurcations are identified: first, a homoclinic cycle from modulated transverse rolls and second, a robust heteroclinic cycle linking two symmetry-related diamond-roll patterns. These are confirmed by phase space projections as well as the functional form of the divergence of the period close to the bifurcation points. The intricacy of this bifurcation diagram highlights the essential role played by dynamical systems theory and computation in hydrodynamic configurations.","sentences":["Vertical thermal convection is a non-equilibrium system in which both buoyancy and shear forces play a role in driving the convective flow.","Beyond the onset of convection, the driven dissipative system exhibits chaotic dynamics and turbulence.","In a three-dimensional domain extended in both the vertical and the transverse dimensions, Gao et al. (2018) have observed a variety of convection patterns which are not described by linear stability analysis.","We investigate the fully non-linear dynamics of vertical convection using a dynamical-systems approach based on the Oberbeck-Boussinesq equations.","We compute the invariant solutions of these equations and the bifurcations that are responsible for the creation and termination of various branches.","We map out a sequence of local bifurcations from the laminar base state, including simultaneous bifurcations involving patterned steady states with different symmetries.","This atypical phenomenon of multiple branches simultaneously bifurcating from a single parent branch is explained by the role of D4 symmetry.","In addition, two global bifurcations are identified: first, a homoclinic cycle from modulated transverse rolls and second, a robust heteroclinic cycle linking two symmetry-related diamond-roll patterns.","These are confirmed by phase space projections as well as the functional form of the divergence of the period close to the bifurcation points.","The intricacy of this bifurcation diagram highlights the essential role played by dynamical systems theory and computation in hydrodynamic configurations."],"url":"http://arxiv.org/abs/2403.18563v1","category":"physics.flu-dyn"}
{"created":"2024-03-27 13:14:29","title":"Safe and Robust Reinforcement-Learning: Principles and Practice","abstract":"Reinforcement Learning (RL) has shown remarkable success in solving relatively complex tasks, yet the deployment of RL systems in real-world scenarios poses significant challenges related to safety and robustness. This paper aims to identify and further understand those challenges thorough the exploration of the main dimensions of the safe and robust RL landscape, encompassing algorithmic, ethical, and practical considerations. We conduct a comprehensive review of methodologies and open problems that summarizes the efforts in recent years to address the inherent risks associated with RL applications.   After discussing and proposing definitions for both safe and robust RL, the paper categorizes existing research works into different algorithmic approaches that enhance the safety and robustness of RL agents. We examine techniques such as uncertainty estimation, optimisation methodologies, exploration-exploitation trade-offs, and adversarial training. Environmental factors, including sim-to-real transfer and domain adaptation, are also scrutinized to understand how RL systems can adapt to diverse and dynamic surroundings. Moreover, human involvement is an integral ingredient of the analysis, acknowledging the broad set of roles that humans can take in this context.   Importantly, to aid practitioners in navigating the complexities of safe and robust RL implementation, this paper introduces a practical checklist derived from the synthesized literature. The checklist encompasses critical aspects of algorithm design, training environment considerations, and ethical guidelines. It will serve as a resource for developers and policymakers alike to ensure the responsible deployment of RL systems in many application domains.","sentences":["Reinforcement Learning (RL) has shown remarkable success in solving relatively complex tasks, yet the deployment of RL systems in real-world scenarios poses significant challenges related to safety and robustness.","This paper aims to identify and further understand those challenges thorough the exploration of the main dimensions of the safe and robust RL landscape, encompassing algorithmic, ethical, and practical considerations.","We conduct a comprehensive review of methodologies and open problems that summarizes the efforts in recent years to address the inherent risks associated with RL applications.   ","After discussing and proposing definitions for both safe and robust RL, the paper categorizes existing research works into different algorithmic approaches that enhance the safety and robustness of RL agents.","We examine techniques such as uncertainty estimation, optimisation methodologies, exploration-exploitation trade-offs, and adversarial training.","Environmental factors, including sim-to-real transfer and domain adaptation, are also scrutinized to understand how RL systems can adapt to diverse and dynamic surroundings.","Moreover, human involvement is an integral ingredient of the analysis, acknowledging the broad set of roles that humans can take in this context.   ","Importantly, to aid practitioners in navigating the complexities of safe and robust RL implementation, this paper introduces a practical checklist derived from the synthesized literature.","The checklist encompasses critical aspects of algorithm design, training environment considerations, and ethical guidelines.","It will serve as a resource for developers and policymakers alike to ensure the responsible deployment of RL systems in many application domains."],"url":"http://arxiv.org/abs/2403.18539v1","category":"cs.LG"}
{"created":"2024-03-27 13:00:06","title":"Wirtinger gradient descent methods for low-dose Poisson phase retrieval","abstract":"The problem of phase retrieval has many applications in the field of optical imaging. Motivated by imaging experiments with biological specimens, we primarily consider the setting of low-dose illumination where Poisson noise plays the dominant role. In this paper, we discuss gradient descent algorithms based on different loss functions adapted to data affected by Poisson noise, in particular in the low-dose regime. Starting from the maximum log-likelihood function for the Poisson distribution, we investigate different regularizations and approximations of the problem to design an algorithm that meets the requirements that are faced in applications. In the course of this, we focus on low-count measurements. For all suggested loss functions, we study the convergence of the respective gradient descent algorithms to stationary points and find constant step sizes that guarantee descent of the loss in each iteration. Numerical experiments in the low-dose regime are performed to corroborate the theoretical observations.","sentences":["The problem of phase retrieval has many applications in the field of optical imaging.","Motivated by imaging experiments with biological specimens, we primarily consider the setting of low-dose illumination where Poisson noise plays the dominant role.","In this paper, we discuss gradient descent algorithms based on different loss functions adapted to data affected by Poisson noise, in particular in the low-dose regime.","Starting from the maximum log-likelihood function for the Poisson distribution, we investigate different regularizations and approximations of the problem to design an algorithm that meets the requirements that are faced in applications.","In the course of this, we focus on low-count measurements.","For all suggested loss functions, we study the convergence of the respective gradient descent algorithms to stationary points and find constant step sizes that guarantee descent of the loss in each iteration.","Numerical experiments in the low-dose regime are performed to corroborate the theoretical observations."],"url":"http://arxiv.org/abs/2403.18527v1","category":"math.NA"}
{"created":"2024-03-27 12:50:58","title":"Global convergence of iterative solvers for problems of nonlinear magnetostatics","abstract":"We consider the convergence of iterative solvers for problems of nonlinear magnetostatics. Using the equivalence to an underlying minimization problem, we can establish global linear convergence of a large class of methods, including the damped Newton-method, fixed-point iteration, and the Kacanov iteration, which can all be interpreted as generalized gradient descent methods. Armijo backtracking isconsidered for an adaptive choice of the stepsize. The general assumptions required for our analysis cover inhomogeneous, nonlinear, and anisotropic materials, as well as permanent magnets. The main results are proven on the continuous level, but they carry over almost verbatim to various approximation schemes, including finite elements and isogeometric analysis, leading to bounds on the iteration numbers, which are independent of the particular discretization. The theoretical results are illustrated by numerical tests for a typical benchmark problem.","sentences":["We consider the convergence of iterative solvers for problems of nonlinear magnetostatics.","Using the equivalence to an underlying minimization problem, we can establish global linear convergence of a large class of methods, including the damped Newton-method, fixed-point iteration, and the Kacanov iteration, which can all be interpreted as generalized gradient descent methods.","Armijo backtracking isconsidered for an adaptive choice of the stepsize.","The general assumptions required for our analysis cover inhomogeneous, nonlinear, and anisotropic materials, as well as permanent magnets.","The main results are proven on the continuous level, but they carry over almost verbatim to various approximation schemes, including finite elements and isogeometric analysis, leading to bounds on the iteration numbers, which are independent of the particular discretization.","The theoretical results are illustrated by numerical tests for a typical benchmark problem."],"url":"http://arxiv.org/abs/2403.18520v1","category":"math.NA"}
{"created":"2024-03-27 12:08:41","title":"VersaT2I: Improving Text-to-Image Models with Versatile Reward","abstract":"Recent text-to-image (T2I) models have benefited from large-scale and high-quality data, demonstrating impressive performance. However, these T2I models still struggle to produce images that are aesthetically pleasing, geometrically accurate, faithful to text, and of good low-level quality. We present VersaT2I, a versatile training framework that can boost the performance with multiple rewards of any T2I model. We decompose the quality of the image into several aspects such as aesthetics, text-image alignment, geometry, low-level quality, etc. Then, for every quality aspect, we select high-quality images in this aspect generated by the model as the training set to finetune the T2I model using the Low-Rank Adaptation (LoRA). Furthermore, we introduce a gating function to combine multiple quality aspects, which can avoid conflicts between different quality aspects. Our method is easy to extend and does not require any manual annotation, reinforcement learning, or model architecture changes. Extensive experiments demonstrate that VersaT2I outperforms the baseline methods across various quality criteria.","sentences":["Recent text-to-image (T2I) models have benefited from large-scale and high-quality data, demonstrating impressive performance.","However, these T2I models still struggle to produce images that are aesthetically pleasing, geometrically accurate, faithful to text, and of good low-level quality.","We present VersaT2I, a versatile training framework that can boost the performance with multiple rewards of any T2I model.","We decompose the quality of the image into several aspects such as aesthetics, text-image alignment, geometry, low-level quality, etc.","Then, for every quality aspect, we select high-quality images in this aspect generated by the model as the training set to finetune the T2I model using the Low-Rank Adaptation (LoRA).","Furthermore, we introduce a gating function to combine multiple quality aspects, which can avoid conflicts between different quality aspects.","Our method is easy to extend and does not require any manual annotation, reinforcement learning, or model architecture changes.","Extensive experiments demonstrate that VersaT2I outperforms the baseline methods across various quality criteria."],"url":"http://arxiv.org/abs/2403.18493v1","category":"cs.CV"}
{"created":"2024-03-27 11:56:08","title":"UVL Sentinel: a tool for parsing and syntactic correction of UVL datasets","abstract":"Feature models have become a de facto standard for representing variability in software product lines. UVL (Universal Variability Language) is a language which expresses the features, dependencies, and constraints between them. This language is written in plain text and follows a syntactic structure that needs to be processed by a parser. This parser is software with specific syntactic rules that the language must comply with to be processed correctly. Researchers have datasets with numerous feature models. The language description form of these feature models is tied to a version of the parser language. When the parser is updated to support new features or correct previous ones, these feature models are often no longer compatible, generating incompatibilities and inconsistency within the dataset. In this paper, we present UVL Sentinel. This tool analyzes a dataset of feature models in UVL format, generating error analysis reports, describing those errors and, eventually, a syntactic processing that applies the most common solutions. This tool can detect the incompatibilities of the feature models of a dataset when the parser is updated and tries to correct the most common syntactic errors, facilitating the management of the dataset and the adaptation of their models to the new version of the parser. Our tool was evaluated using a dataset of 1,479 UVL models from different sources and helped semi-automatically fix 185 warnings and syntax errors.","sentences":["Feature models have become a de facto standard for representing variability in software product lines.","UVL (Universal Variability Language) is a language which expresses the features, dependencies, and constraints between them.","This language is written in plain text and follows a syntactic structure that needs to be processed by a parser.","This parser is software with specific syntactic rules that the language must comply with to be processed correctly.","Researchers have datasets with numerous feature models.","The language description form of these feature models is tied to a version of the parser language.","When the parser is updated to support new features or correct previous ones, these feature models are often no longer compatible, generating incompatibilities and inconsistency within the dataset.","In this paper, we present UVL Sentinel.","This tool analyzes a dataset of feature models in UVL format, generating error analysis reports, describing those errors and, eventually, a syntactic processing that applies the most common solutions.","This tool can detect the incompatibilities of the feature models of a dataset when the parser is updated and tries to correct the most common syntactic errors, facilitating the management of the dataset and the adaptation of their models to the new version of the parser.","Our tool was evaluated using a dataset of 1,479 UVL models from different sources and helped semi-automatically fix 185 warnings and syntax errors."],"url":"http://arxiv.org/abs/2403.18482v1","category":"cs.SE"}
{"created":"2024-03-27 11:48:45","title":"Thermalization condition for non-Hermitian quantum systems","abstract":"The application of the eigenstate thermalization hypothesis to non-Hermitian quantum systems has become one of the most important topics in dissipative quantum chaos, recently giving rise to intense debates. The process of thermalization is intricate, involving many time-evolution trajectories in the reduced Hilbert space of the system. By considering two different expansion forms of the density matrices adopted in the biorthogonal and right-state time evolutions, we have derived two versions of the Gorini-Kossakowski-Sudarshan-Lindblad master equations describing the non-Hermitian systems coupled to a bosonic heat bath in thermal equilibrium. By solving the equations, we have identified a sufficient condition for thermalization under both time evolutions, resulting in Boltzmann biorthogonal and right-eigenstate statistics, respectively. This finding implies that the recently proposed biorthogonal random matrix theory needs an appropriate revision. Moreover, we have exemplified the precise dynamics of thermalization and thermodynamic properties with test models.","sentences":["The application of the eigenstate thermalization hypothesis to non-Hermitian quantum systems has become one of the most important topics in dissipative quantum chaos, recently giving rise to intense debates.","The process of thermalization is intricate, involving many time-evolution trajectories in the reduced Hilbert space of the system.","By considering two different expansion forms of the density matrices adopted in the biorthogonal and right-state time evolutions, we have derived two versions of the Gorini-Kossakowski-Sudarshan-Lindblad master equations describing the non-Hermitian systems coupled to a bosonic heat bath in thermal equilibrium.","By solving the equations, we have identified a sufficient condition for thermalization under both time evolutions, resulting in Boltzmann biorthogonal and right-eigenstate statistics, respectively.","This finding implies that the recently proposed biorthogonal random matrix theory needs an appropriate revision.","Moreover, we have exemplified the precise dynamics of thermalization and thermodynamic properties with test models."],"url":"http://arxiv.org/abs/2403.18477v1","category":"quant-ph"}
{"created":"2024-03-27 11:22:26","title":"Kinetic data-driven approach to turbulence subgrid modeling","abstract":"Numerical simulations of turbulent flows are well known to pose extreme computational challenges due to the huge number of dynamical degrees of freedom required to correctly describe the complex multi-scale statistical correlations of the velocity. On the other hand, kinetic mesoscale approaches based on the Boltzmann equation, have the potential to describe a broad range of flows, stretching well beyond the special case of gases close to equilibrium, which results in the ordinary Navier-Stokes dynamics. Here we demonstrate that, by properly tuning, a kinetic approach can statistically reproduce the quantitative dynamics of the larger scales in turbulence, thereby providing an alternative, computationally efficient and physically rooted approach towards subgrid scale (SGS) modeling in turbulence. More specifically we show that by leveraging on data from fully resolved Direct Numerical Simulation (DNS) data we can learn a collision operator for the discretized Boltzmann equation solver (the lattice Boltzmann method), which effectively implies a turbulence subgrid closure model. The mesoscopic nature of our formulation makes the learning problem fully local in both space and time, leading to reduced computational costs and enhanced generalization capabilities. We show that the model offers superior performance compared to traditional methods, such as the Smagorinsky model, being less dissipative and, therefore, being able to more closely capture the intermittency of higher-order velocity correlations.","sentences":["Numerical simulations of turbulent flows are well known to pose extreme computational challenges due to the huge number of dynamical degrees of freedom required to correctly describe the complex multi-scale statistical correlations of the velocity.","On the other hand, kinetic mesoscale approaches based on the Boltzmann equation, have the potential to describe a broad range of flows, stretching well beyond the special case of gases close to equilibrium, which results in the ordinary Navier-Stokes dynamics.","Here we demonstrate that, by properly tuning, a kinetic approach can statistically reproduce the quantitative dynamics of the larger scales in turbulence, thereby providing an alternative, computationally efficient and physically rooted approach towards subgrid scale (SGS) modeling in turbulence.","More specifically we show that by leveraging on data from fully resolved Direct Numerical Simulation (DNS) data we can learn a collision operator for the discretized Boltzmann equation solver (the lattice Boltzmann method), which effectively implies a turbulence subgrid closure model.","The mesoscopic nature of our formulation makes the learning problem fully local in both space and time, leading to reduced computational costs and enhanced generalization capabilities.","We show that the model offers superior performance compared to traditional methods, such as the Smagorinsky model, being less dissipative and, therefore, being able to more closely capture the intermittency of higher-order velocity correlations."],"url":"http://arxiv.org/abs/2403.18466v1","category":"physics.flu-dyn"}
{"created":"2024-03-27 11:16:04","title":"Inverse kinematics learning of a continuum manipulator using limited real time data","abstract":"Data driven control of a continuum manipulator requires a lot of data for training but generating sufficient amount of real time data is not cost efficient. Random actuation of the manipulator can also be unsafe sometimes. Meta learning has been used successfully to adapt to a new environment. Hence, this paper tries to solve the above mentioned problem using meta learning. We consider two cases for that. First, this paper proposes a method to use simulation data for training the model using MAML(Model-Agnostic Meta-Learning). Then, it adapts to the real world using gradient steps. Secondly,if the simulation model is not available or difficult to formulate, then we propose a CGAN(Conditional Generative adversial network)-MAML based method for it. The model is trained using a small amount of real time data and augmented data for different loading conditions. Then, adaptation is done in the real environment. It has been found out from the experiments that the relative positioning error for both the cases are below 3%. The proposed models are experimentally verified on a real continuum manipulator.","sentences":["Data driven control of a continuum manipulator requires a lot of data for training but generating sufficient amount of real time data is not cost efficient.","Random actuation of the manipulator can also be unsafe sometimes.","Meta learning has been used successfully to adapt to a new environment.","Hence, this paper tries to solve the above mentioned problem using meta learning.","We consider two cases for that.","First, this paper proposes a method to use simulation data for training the model using MAML(Model-Agnostic Meta-Learning).","Then, it adapts to the real world using gradient steps.","Secondly,if the simulation model is not available or difficult to formulate, then we propose a CGAN(Conditional Generative adversial network)-MAML based method for it.","The model is trained using a small amount of real time data and augmented data for different loading conditions.","Then, adaptation is done in the real environment.","It has been found out from the experiments that the relative positioning error for both the cases are below 3%.","The proposed models are experimentally verified on a real continuum manipulator."],"url":"http://arxiv.org/abs/2403.18456v1","category":"cs.RO"}
{"created":"2024-03-27 11:11:08","title":"SingularTrajectory: Universal Trajectory Predictor Using Diffusion Model","abstract":"There are five types of trajectory prediction tasks: deterministic, stochastic, domain adaptation, momentary observation, and few-shot. These associated tasks are defined by various factors, such as the length of input paths, data split and pre-processing methods. Interestingly, even though they commonly take sequential coordinates of observations as input and infer future paths in the same coordinates as output, designing specialized architectures for each task is still necessary. For the other task, generality issues can lead to sub-optimal performances. In this paper, we propose SingularTrajectory, a diffusion-based universal trajectory prediction framework to reduce the performance gap across the five tasks. The core of SingularTrajectory is to unify a variety of human dynamics representations on the associated tasks. To do this, we first build a Singular space to project all types of motion patterns from each task into one embedding space. We next propose an adaptive anchor working in the Singular space. Unlike traditional fixed anchor methods that sometimes yield unacceptable paths, our adaptive anchor enables correct anchors, which are put into a wrong location, based on a traversability map. Finally, we adopt a diffusion-based predictor to further enhance the prototype paths using a cascaded denoising process. Our unified framework ensures the generality across various benchmark settings such as input modality, and trajectory lengths. Extensive experiments on five public benchmarks demonstrate that SingularTrajectory substantially outperforms existing models, highlighting its effectiveness in estimating general dynamics of human movements. Code is publicly available at https://github.com/inhwanbae/SingularTrajectory .","sentences":["There are five types of trajectory prediction tasks: deterministic, stochastic, domain adaptation, momentary observation, and few-shot.","These associated tasks are defined by various factors, such as the length of input paths, data split and pre-processing methods.","Interestingly, even though they commonly take sequential coordinates of observations as input and infer future paths in the same coordinates as output, designing specialized architectures for each task is still necessary.","For the other task, generality issues can lead to sub-optimal performances.","In this paper, we propose SingularTrajectory, a diffusion-based universal trajectory prediction framework to reduce the performance gap across the five tasks.","The core of SingularTrajectory is to unify a variety of human dynamics representations on the associated tasks.","To do this, we first build a Singular space to project all types of motion patterns from each task into one embedding space.","We next propose an adaptive anchor working in the Singular space.","Unlike traditional fixed anchor methods that sometimes yield unacceptable paths, our adaptive anchor enables correct anchors, which are put into a wrong location, based on a traversability map.","Finally, we adopt a diffusion-based predictor to further enhance the prototype paths using a cascaded denoising process.","Our unified framework ensures the generality across various benchmark settings such as input modality, and trajectory lengths.","Extensive experiments on five public benchmarks demonstrate that SingularTrajectory substantially outperforms existing models, highlighting its effectiveness in estimating general dynamics of human movements.","Code is publicly available at https://github.com/inhwanbae/SingularTrajectory ."],"url":"http://arxiv.org/abs/2403.18452v1","category":"cs.CV"}
{"created":"2024-03-27 10:50:24","title":"Backpropagation-free Network for 3D Test-time Adaptation","abstract":"Real-world systems often encounter new data over time, which leads to experiencing target domain shifts. Existing Test-Time Adaptation (TTA) methods tend to apply computationally heavy and memory-intensive backpropagation-based approaches to handle this. Here, we propose a novel method that uses a backpropagation-free approach for TTA for the specific case of 3D data. Our model uses a two-stream architecture to maintain knowledge about the source domain as well as complementary target-domain-specific information. The backpropagation-free property of our model helps address the well-known forgetting problem and mitigates the error accumulation issue. The proposed method also eliminates the need for the usually noisy process of pseudo-labeling and reliance on costly self-supervised training. Moreover, our method leverages subspace learning, effectively reducing the distribution variance between the two domains. Furthermore, the source-domain-specific and the target-domain-specific streams are aligned using a novel entropy-based adaptive fusion strategy. Extensive experiments on popular benchmarks demonstrate the effectiveness of our method. The code will be available at https://github.com/abie-e/BFTT3D.","sentences":["Real-world systems often encounter new data over time, which leads to experiencing target domain shifts.","Existing Test-Time Adaptation (TTA) methods tend to apply computationally heavy and memory-intensive backpropagation-based approaches to handle this.","Here, we propose a novel method that uses a backpropagation-free approach for TTA for the specific case of 3D data.","Our model uses a two-stream architecture to maintain knowledge about the source domain as well as complementary target-domain-specific information.","The backpropagation-free property of our model helps address the well-known forgetting problem and mitigates the error accumulation issue.","The proposed method also eliminates the need for the usually noisy process of pseudo-labeling and reliance on costly self-supervised training.","Moreover, our method leverages subspace learning, effectively reducing the distribution variance between the two domains.","Furthermore, the source-domain-specific and the target-domain-specific streams are aligned using a novel entropy-based adaptive fusion strategy.","Extensive experiments on popular benchmarks demonstrate the effectiveness of our method.","The code will be available at https://github.com/abie-e/BFTT3D."],"url":"http://arxiv.org/abs/2403.18442v1","category":"cs.CV"}
{"created":"2024-03-27 10:45:16","title":"Global Vegetation Modeling with Pre-Trained Weather Transformers","abstract":"Accurate vegetation models can produce further insights into the complex interaction between vegetation activity and ecosystem processes. Previous research has established that long-term trends and short-term variability of temperature and precipitation affect vegetation activity. Motivated by the recent success of Transformer-based Deep Learning models for medium-range weather forecasting, we adapt the publicly available pre-trained FourCastNet to model vegetation activity while accounting for the short-term dynamics of climate variability. We investigate how the learned global representation of the atmosphere's state can be transferred to model the normalized difference vegetation index (NDVI). Our model globally estimates vegetation activity at a resolution of \\SI{0.25}{\\degree} while relying only on meteorological data. We demonstrate that leveraging pre-trained weather models improves the NDVI estimates compared to learning an NDVI model from scratch. Additionally, we compare our results to other recent data-driven NDVI modeling approaches from machine learning and ecology literature. We further provide experimental evidence on how much data and training time is necessary to turn FourCastNet into an effective vegetation model. Code and models will be made available upon publication.","sentences":["Accurate vegetation models can produce further insights into the complex interaction between vegetation activity and ecosystem processes.","Previous research has established that long-term trends and short-term variability of temperature and precipitation affect vegetation activity.","Motivated by the recent success of Transformer-based Deep Learning models for medium-range weather forecasting, we adapt the publicly available pre-trained FourCastNet to model vegetation activity while accounting for the short-term dynamics of climate variability.","We investigate how the learned global representation of the atmosphere's state can be transferred to model the normalized difference vegetation index (NDVI).","Our model globally estimates vegetation activity at a resolution of \\SI{0.25}{\\degree} while relying only on meteorological data.","We demonstrate that leveraging pre-trained weather models improves the NDVI estimates compared to learning an NDVI model from scratch.","Additionally, we compare our results to other recent data-driven NDVI modeling approaches from machine learning and ecology literature.","We further provide experimental evidence on how much data and training time is necessary to turn FourCastNet into an effective vegetation model.","Code and models will be made available upon publication."],"url":"http://arxiv.org/abs/2403.18438v1","category":"cs.LG"}
{"created":"2024-03-27 10:08:48","title":"A Delaunay Refinement Algorithm for the Particle Finite Element Method applied to Free Surface Flows","abstract":"This paper proposes two contributions to the calculation of free surface flows using the particle finite element method (PFEM). The PFEM is based on a Lagrangian approach: a set of particles defines the fluid. Then, unlike a pure Lagrangian method, all the particles are connected by a triangular mesh. The difficulty lies in locating the free surface from this mesh. It is a matter of deciding which of the elements in the mesh are part of the fluid domain, and to define a boundary - the free surface. Then, the incompressible Navier-Stokes equations are solved on the fluid domain and the particles' position is updated using the resulting velocity vector. Our first contribution is to propose an approach to adapt the mesh with theoretical guarantees of quality: the mesh generation community has acquired a lot of experience and understanding about mesh adaptation approaches with guarantees of quality on the final mesh. We use here a Delaunay refinement strategy, allowing to insert and remove nodes while gradually improving mesh quality. We show that this allows to create stable and smooth free surface geometries. Our PFEM approach models the topological evolution of one fluid. It is nevertheless necessary to apply conditions on the domain boundaries. When a boundary is a free surface, the flow on the other side is not modelled, it is represented by an external pressure. On the external free surface boundary, atmospheric pressure can be imposed. Nevertheless, there may be internal free surfaces: the fluid can fully encapsulate cavities to form bubbles. The pressure required to maintain the volume of those bubbles is a priori unknown. We propose a multi-point constraint approach to enforce global incompressibility of those empty bubbles. This approach allows to accurately model bubbly flows that involve two fluids with large density differences, while only modelling the heavier fluid.","sentences":["This paper proposes two contributions to the calculation of free surface flows using the particle finite element method (PFEM).","The PFEM is based on a Lagrangian approach: a set of particles defines the fluid.","Then, unlike a pure Lagrangian method, all the particles are connected by a triangular mesh.","The difficulty lies in locating the free surface from this mesh.","It is a matter of deciding which of the elements in the mesh are part of the fluid domain, and to define a boundary - the free surface.","Then, the incompressible Navier-Stokes equations are solved on the fluid domain and the particles' position is updated using the resulting velocity vector.","Our first contribution is to propose an approach to adapt the mesh with theoretical guarantees of quality: the mesh generation community has acquired a lot of experience and understanding about mesh adaptation approaches with guarantees of quality on the final mesh.","We use here a Delaunay refinement strategy, allowing to insert and remove nodes while gradually improving mesh quality.","We show that this allows to create stable and smooth free surface geometries.","Our PFEM approach models the topological evolution of one fluid.","It is nevertheless necessary to apply conditions on the domain boundaries.","When a boundary is a free surface, the flow on the other side is not modelled, it is represented by an external pressure.","On the external free surface boundary, atmospheric pressure can be imposed.","Nevertheless, there may be internal free surfaces: the fluid can fully encapsulate cavities to form bubbles.","The pressure required to maintain the volume of those bubbles is a priori unknown.","We propose a multi-point constraint approach to enforce global incompressibility of those empty bubbles.","This approach allows to accurately model bubbly flows that involve two fluids with large density differences, while only modelling the heavier fluid."],"url":"http://arxiv.org/abs/2403.18416v1","category":"cs.CE"}
{"created":"2024-03-27 09:37:12","title":"Adaptive Economic Model Predictive Control for linear systems with performance guarantees","abstract":"We present a model predictive control (MPC) formulation to directly optimize economic criteria for linear constrained systems subject to disturbances and uncertain model parameters. The proposed formulation combines a certainty equivalent economic MPC with a simple least-squares parameter adaptation. For the resulting adaptive economic MPC scheme, we derive strong asymptotic and transient performance guarantees. We provide a numerical example involving building temperature control and demonstrate performance benefits of online parameter adaptation.","sentences":["We present a model predictive control (MPC) formulation to directly optimize economic criteria for linear constrained systems subject to disturbances and uncertain model parameters.","The proposed formulation combines a certainty equivalent economic MPC with a simple least-squares parameter adaptation.","For the resulting adaptive economic MPC scheme, we derive strong asymptotic and transient performance guarantees.","We provide a numerical example involving building temperature control and demonstrate performance benefits of online parameter adaptation."],"url":"http://arxiv.org/abs/2403.18398v1","category":"eess.SY"}
{"created":"2024-03-27 09:30:50","title":"Tensor-based Graph Learning with Consistency and Specificity for Multi-view Clustering","abstract":"Graph learning is widely recognized as a crucial technique in multi-view clustering. Existing graph learning methods typically involve constructing an adaptive neighbor graph based on probabilistic neighbors and then learning a consensus graph to for clustering, however, they are confronted with two limitations. Firstly, they often rely on Euclidean distance to measure similarity when constructing the adaptive neighbor graph, which proves inadequate in capturing the intrinsic structure among data points in many real-world scenarios. Secondly, most of these methods focus solely on consensus graph, ignoring view-specific graph information. In response to the aforementioned drawbacks, we in this paper propose a novel tensor-based graph learning framework that simultaneously considers consistency and specificity for multi-view clustering. Specifically, we calculate the similarity distance on the Stiefel manifold to preserve the intrinsic structure among data points. By making an assumption that the learned neighbor graph of each view comprises both a consistent graph and a view-specific graph, we formulate a new tensor-based target graph learning paradigm. Owing to the benefits of tensor singular value decomposition (t-SVD) in uncovering high-order correlations, this model is capable of achieving a complete understanding of the target graph. Furthermore, we develop an iterative algorithm to solve the proposed objective optimization problem. Experiments conducted on real-world datasets have demonstrated the superior performance of the proposed method over some state-of-the-art multi-view clustering methods. The source code has been released on https://github.com/lshi91/CSTGL-Code.","sentences":["Graph learning is widely recognized as a crucial technique in multi-view clustering.","Existing graph learning methods typically involve constructing an adaptive neighbor graph based on probabilistic neighbors and then learning a consensus graph to for clustering, however, they are confronted with two limitations.","Firstly, they often rely on Euclidean distance to measure similarity when constructing the adaptive neighbor graph, which proves inadequate in capturing the intrinsic structure among data points in many real-world scenarios.","Secondly, most of these methods focus solely on consensus graph, ignoring view-specific graph information.","In response to the aforementioned drawbacks, we in this paper propose a novel tensor-based graph learning framework that simultaneously considers consistency and specificity for multi-view clustering.","Specifically, we calculate the similarity distance on the Stiefel manifold to preserve the intrinsic structure among data points.","By making an assumption that the learned neighbor graph of each view comprises both a consistent graph and a view-specific graph, we formulate a new tensor-based target graph learning paradigm.","Owing to the benefits of tensor singular value decomposition (t-SVD) in uncovering high-order correlations, this model is capable of achieving a complete understanding of the target graph.","Furthermore, we develop an iterative algorithm to solve the proposed objective optimization problem.","Experiments conducted on real-world datasets have demonstrated the superior performance of the proposed method over some state-of-the-art multi-view clustering methods.","The source code has been released on https://github.com/lshi91/CSTGL-Code."],"url":"http://arxiv.org/abs/2403.18393v1","category":"cs.LG"}
{"created":"2024-03-27 09:24:38","title":"Morrey-Lorentz estimates for Hodge-type systems","abstract":"We prove up to the boundary regularity estimates in Morrey-Lorentz spaces for weak solutions of the linear system of differential forms with regular anisotropic coefficients   \\begin{equation*}   d^{\\ast} \\left( A d\\omega \\right) + B^{\\intercal}d d^{\\ast} \\left( B\\omega \\right) = \\lambda B\\omega + f \\text{ in } \\Omega,   \\end{equation*}   with either $ \\nu\\wedge \\omega$ and $\\nu\\wedge d^{\\ast} \\left( B\\omega \\right)$ or $\\nu\\lrcorner B\\omega$ and   $\\nu\\lrcorner \\left( A d\\omega \\right)$ prescribed on $\\partial\\Omega.$ We derive these estimates from the $L^{p}$ estimates obtained in \\cite{Sil_linearregularity} in the spirit of Campanato's method. Unlike Lorentz spaces, Morrey spaces are neither interpolation spaces nor rearrangement invariant. So Morrey estimates can not be obtained directly from the $L^{p}$ estimates using interpolation. We instead adapt an idea of Lieberman \\cite{Lieberman_morrey_from_Lp} to our setting to derive the estimates. Applications to Hodge decomposition in Morrey-Lorentz spaces, Gaffney type inequalities and estimates for related systems such as Hodge-Maxwell systems and `div-curl' systems are discussed.","sentences":["We prove up to the boundary regularity estimates in Morrey-Lorentz spaces for weak solutions of the linear system of differential forms with regular anisotropic coefficients   \\begin{equation*}   d^{\\ast} \\left( A d\\omega \\right) + B^{\\intercal}d d^{\\ast} \\left( B\\omega \\right) = \\lambda B\\omega +","f \\text{ in } \\Omega,   \\end{equation*}   with either $ \\nu\\wedge \\omega$ and $\\nu\\wedge d^{\\ast} \\left( B\\omega \\right)$ or $\\nu\\lrcorner B\\omega$ and   ","$\\nu\\lrcorner \\left( A d\\omega \\right)$ prescribed on $\\partial\\Omega.$ We derive these estimates from the $L^{p}$ estimates obtained in \\cite{Sil_linearregularity} in the spirit of Campanato's method.","Unlike Lorentz spaces, Morrey spaces are neither interpolation spaces nor rearrangement invariant.","So Morrey estimates can not be obtained directly from the $L^{p}$ estimates using interpolation.","We instead adapt an idea of Lieberman \\cite{Lieberman_morrey_from_Lp} to our setting to derive the estimates.","Applications to Hodge decomposition in Morrey-Lorentz spaces, Gaffney type inequalities and estimates for related systems such as Hodge-Maxwell systems and `div-curl' systems are discussed."],"url":"http://arxiv.org/abs/2403.18387v1","category":"math.AP"}
{"created":"2024-03-27 09:21:07","title":"Generative Multi-modal Models are Good Class-Incremental Learners","abstract":"In class-incremental learning (CIL) scenarios, the phenomenon of catastrophic forgetting caused by the classifier's bias towards the current task has long posed a significant challenge. It is mainly caused by the characteristic of discriminative models. With the growing popularity of the generative multi-modal models, we would explore replacing discriminative models with generative ones for CIL. However, transitioning from discriminative to generative models requires addressing two key challenges. The primary challenge lies in transferring the generated textual information into the classification of distinct categories. Additionally, it requires formulating the task of CIL within a generative framework. To this end, we propose a novel generative multi-modal model (GMM) framework for class-incremental learning. Our approach directly generates labels for images using an adapted generative model. After obtaining the detailed text, we use a text encoder to extract text features and employ feature matching to determine the most similar label as the classification prediction. In the conventional CIL settings, we achieve significantly better results in long-sequence task scenarios. Under the Few-shot CIL setting, we have improved by at least 14\\% accuracy over all the current state-of-the-art methods with significantly less forgetting. Our code is available at \\url{https://github.com/DoubleClass/GMM}.","sentences":["In class-incremental learning (CIL) scenarios, the phenomenon of catastrophic forgetting caused by the classifier's bias towards the current task has long posed a significant challenge.","It is mainly caused by the characteristic of discriminative models.","With the growing popularity of the generative multi-modal models, we would explore replacing discriminative models with generative ones for CIL.","However, transitioning from discriminative to generative models requires addressing two key challenges.","The primary challenge lies in transferring the generated textual information into the classification of distinct categories.","Additionally, it requires formulating the task of CIL within a generative framework.","To this end, we propose a novel generative multi-modal model (GMM) framework for class-incremental learning.","Our approach directly generates labels for images using an adapted generative model.","After obtaining the detailed text, we use a text encoder to extract text features and employ feature matching to determine the most similar label as the classification prediction.","In the conventional CIL settings, we achieve significantly better results in long-sequence task scenarios.","Under the Few-shot CIL setting, we have improved by at least 14\\% accuracy over all the current state-of-the-art methods with significantly less forgetting.","Our code is available at \\url{https://github.com/DoubleClass/GMM}."],"url":"http://arxiv.org/abs/2403.18383v1","category":"cs.CV"}
{"created":"2024-03-27 09:20:30","title":"Joint distribution of $L$-values and orders of Sha groups of quadratic twists of elliptic curves","abstract":"We study the joint distribution of central $L$-values and orders of Tate-Shafarevich groups of quadratic twists of elliptic curves. In particular, adapting Radziwill and Soundararajan's principles of establishing upper and lower bounds for the distribution of central values in families of $L$-functions, we obtain conditional upper and lower bounds for such a joint distribution for rank zero twists. These lead us to a conjecture on the full asymptotic for the joint distribution.","sentences":["We study the joint distribution of central $L$-values and orders of Tate-Shafarevich groups of quadratic twists of elliptic curves.","In particular, adapting Radziwill and Soundararajan's principles of establishing upper and lower bounds for the distribution of central values in families of $L$-functions, we obtain conditional upper and lower bounds for such a joint distribution for rank zero twists.","These lead us to a conjecture on the full asymptotic for the joint distribution."],"url":"http://arxiv.org/abs/2403.18382v1","category":"math.NT"}
{"created":"2024-03-27 08:57:21","title":"BLADE: Enhancing Black-box Large Language Models with Small Domain-Specific Models","abstract":"Large Language Models (LLMs) like ChatGPT and GPT-4 are versatile and capable of addressing a diverse range of tasks. However, general LLMs, which are developed on open-domain data, may lack the domain-specific knowledge essential for tasks in vertical domains, such as legal, medical, etc. To address this issue, previous approaches either conduct continuous pre-training with domain-specific data or employ retrieval augmentation to support general LLMs. Unfortunately, these strategies are either cost-intensive or unreliable in practical applications. To this end, we present a novel framework named BLADE, which enhances Black-box LArge language models with small Domain-spEcific models. BLADE consists of a black-box LLM and a small domain-specific LM. The small LM preserves domain-specific knowledge and offers specialized insights, while the general LLM contributes robust language comprehension and reasoning capabilities. Specifically, our method involves three steps: 1) pre-training the small LM with domain-specific data, 2) fine-tuning this model using knowledge instruction data, and 3) joint Bayesian optimization of the general LLM and the small LM. Extensive experiments conducted on public legal and medical benchmarks reveal that BLADE significantly outperforms existing approaches. This shows the potential of BLADE as an effective and cost-efficient solution in adapting general LLMs for vertical domains.","sentences":["Large Language Models (LLMs) like ChatGPT and GPT-4 are versatile and capable of addressing a diverse range of tasks.","However, general LLMs, which are developed on open-domain data, may lack the domain-specific knowledge essential for tasks in vertical domains, such as legal, medical, etc.","To address this issue, previous approaches either conduct continuous pre-training with domain-specific data or employ retrieval augmentation to support general LLMs.","Unfortunately, these strategies are either cost-intensive or unreliable in practical applications.","To this end, we present a novel framework named BLADE, which enhances Black-box LArge language models with small Domain-spEcific models.","BLADE consists of a black-box LLM and a small domain-specific LM.","The small LM preserves domain-specific knowledge and offers specialized insights, while the general LLM contributes robust language comprehension and reasoning capabilities.","Specifically, our method involves three steps: 1) pre-training the small LM with domain-specific data, 2) fine-tuning this model using knowledge instruction data, and 3) joint Bayesian optimization of the general LLM and the small LM.","Extensive experiments conducted on public legal and medical benchmarks reveal that BLADE significantly outperforms existing approaches.","This shows the potential of BLADE as an effective and cost-efficient solution in adapting general LLMs for vertical domains."],"url":"http://arxiv.org/abs/2403.18365v1","category":"cs.CL"}
{"created":"2024-03-27 08:57:15","title":"Intent-Aware DRL-Based Uplink Dynamic Scheduler for 5G-NR","abstract":"We investigate the problem of supporting Industrial Internet of Things user equipment (IIoT UEs) with intent (i.e., requested quality of service (QoS)) and random traffic arrival. A deep reinforcement learning (DRL) based centralized dynamic scheduler for time-frequency resources is proposed to learn how to schedule the available communication resources among the IIoT UEs. The proposed scheduler leverages an RL framework to adapt to the dynamic changes in the wireless communication system and traffic arrivals. Moreover, a graph-based reduction scheme is proposed to reduce the state and action space of the RL framework to allow fast convergence and a better learning strategy. Simulation results demonstrate the effectiveness of the proposed intelligent scheduler in guaranteeing the expressed intent of IIoT UEs compared to several traditional scheduling schemes, such as round-robin, semi-static, and heuristic approaches. The proposed scheduler also outperforms the contention-free and contention-based schemes in maximizing the number of successfully computed tasks.","sentences":["We investigate the problem of supporting Industrial Internet of Things user equipment (IIoT UEs) with intent (i.e., requested quality of service (QoS)) and random traffic arrival.","A deep reinforcement learning (DRL) based centralized dynamic scheduler for time-frequency resources is proposed to learn how to schedule the available communication resources among the IIoT UEs.","The proposed scheduler leverages an RL framework to adapt to the dynamic changes in the wireless communication system and traffic arrivals.","Moreover, a graph-based reduction scheme is proposed to reduce the state and action space of the RL framework to allow fast convergence and a better learning strategy.","Simulation results demonstrate the effectiveness of the proposed intelligent scheduler in guaranteeing the expressed intent of IIoT UEs compared to several traditional scheduling schemes, such as round-robin, semi-static, and heuristic approaches.","The proposed scheduler also outperforms the contention-free and contention-based schemes in maximizing the number of successfully computed tasks."],"url":"http://arxiv.org/abs/2403.18364v1","category":"cs.IT"}
{"created":"2024-03-27 08:55:08","title":"Fractional variational integrators based on convolution quadrature","abstract":"Fractional dissipation is a powerful tool to study non-local physical phenomena such as damping models. The design of geometric, in particular, variational integrators for the numerical simulation of such systems relies on a variational formulation of the model. In [19], a new approach is proposed to deal with dissipative systems including fractionally damped systems in a variational way for both, the continuous and discrete setting. It is based on the doubling of variables and their fractional derivatives. The aim of this work is to derive higher-order fractional variational integrators by means of convolution quadrature (CQ) based on backward difference formulas. We then provide numerical methods that are of order 2 improving a previous result in [19]. The convergence properties of the fractional variational integrators and saturation effects due to the approximation of the fractional derivatives by CQ are studied numerically.","sentences":["Fractional dissipation is a powerful tool to study non-local physical phenomena such as damping models.","The design of geometric, in particular, variational integrators for the numerical simulation of such systems relies on a variational formulation of the model.","In [19], a new approach is proposed to deal with dissipative systems including fractionally damped systems in a variational way for both, the continuous and discrete setting.","It is based on the doubling of variables and their fractional derivatives.","The aim of this work is to derive higher-order fractional variational integrators by means of convolution quadrature (CQ) based on backward difference formulas.","We then provide numerical methods that are of order 2 improving a previous result in [19].","The convergence properties of the fractional variational integrators and saturation effects due to the approximation of the fractional derivatives by CQ are studied numerically."],"url":"http://arxiv.org/abs/2403.18362v1","category":"math.NA"}
{"created":"2024-03-27 08:53:13","title":"ViTAR: Vision Transformer with Any Resolution","abstract":"This paper tackles a significant challenge faced by Vision Transformers (ViTs): their constrained scalability across different image resolutions. Typically, ViTs experience a performance decline when processing resolutions different from those seen during training. Our work introduces two key innovations to address this issue. Firstly, we propose a novel module for dynamic resolution adjustment, designed with a single Transformer block, specifically to achieve highly efficient incremental token integration. Secondly, we introduce fuzzy positional encoding in the Vision Transformer to provide consistent positional awareness across multiple resolutions, thereby preventing overfitting to any single training resolution. Our resulting model, ViTAR (Vision Transformer with Any Resolution), demonstrates impressive adaptability, achieving 83.3\\% top-1 accuracy at a 1120x1120 resolution and 80.4\\% accuracy at a 4032x4032 resolution, all while reducing computational costs. ViTAR also shows strong performance in downstream tasks such as instance and semantic segmentation and can easily combined with self-supervised learning techniques like Masked AutoEncoder. Our work provides a cost-effective solution for enhancing the resolution scalability of ViTs, paving the way for more versatile and efficient high-resolution image processing.","sentences":["This paper tackles a significant challenge faced by Vision Transformers (ViTs): their constrained scalability across different image resolutions.","Typically, ViTs experience a performance decline when processing resolutions different from those seen during training.","Our work introduces two key innovations to address this issue.","Firstly, we propose a novel module for dynamic resolution adjustment, designed with a single Transformer block, specifically to achieve highly efficient incremental token integration.","Secondly, we introduce fuzzy positional encoding in the Vision Transformer to provide consistent positional awareness across multiple resolutions, thereby preventing overfitting to any single training resolution.","Our resulting model, ViTAR (Vision Transformer with Any Resolution), demonstrates impressive adaptability, achieving 83.3\\% top-1 accuracy at a 1120x1120 resolution and 80.4\\% accuracy at a 4032x4032 resolution, all while reducing computational costs.","ViTAR also shows strong performance in downstream tasks such as instance and semantic segmentation and can easily combined with self-supervised learning techniques like Masked AutoEncoder.","Our work provides a cost-effective solution for enhancing the resolution scalability of ViTs, paving the way for more versatile and efficient high-resolution image processing."],"url":"http://arxiv.org/abs/2403.18361v2","category":"cs.CV"}
{"created":"2024-03-27 08:52:44","title":"Learning CNN on ViT: A Hybrid Model to Explicitly Class-specific Boundaries for Domain Adaptation","abstract":"Most domain adaptation (DA) methods are based on either a convolutional neural networks (CNNs) or a vision transformers (ViTs). They align the distribution differences between domains as encoders without considering their unique characteristics. For instance, ViT excels in accuracy due to its superior ability to capture global representations, while CNN has an advantage in capturing local representations. This fact has led us to design a hybrid method to fully take advantage of both ViT and CNN, called Explicitly Class-specific Boundaries (ECB). ECB learns CNN on ViT to combine their distinct strengths. In particular, we leverage ViT's properties to explicitly find class-specific decision boundaries by maximizing the discrepancy between the outputs of the two classifiers to detect target samples far from the source support. In contrast, the CNN encoder clusters target features based on the previously defined class-specific boundaries by minimizing the discrepancy between the probabilities of the two classifiers. Finally, ViT and CNN mutually exchange knowledge to improve the quality of pseudo labels and reduce the knowledge discrepancies of these models. Compared to conventional DA methods, our ECB achieves superior performance, which verifies its effectiveness in this hybrid model. The project website can be found https://dotrannhattuong.github.io/ECB/website/.","sentences":["Most domain adaptation (DA) methods are based on either a convolutional neural networks (CNNs) or a vision transformers (ViTs).","They align the distribution differences between domains as encoders without considering their unique characteristics.","For instance, ViT excels in accuracy due to its superior ability to capture global representations, while CNN has an advantage in capturing local representations.","This fact has led us to design a hybrid method to fully take advantage of both ViT and CNN, called Explicitly Class-specific Boundaries (ECB).","ECB learns CNN on ViT to combine their distinct strengths.","In particular, we leverage ViT's properties to explicitly find class-specific decision boundaries by maximizing the discrepancy between the outputs of the two classifiers to detect target samples far from the source support.","In contrast, the CNN encoder clusters target features based on the previously defined class-specific boundaries by minimizing the discrepancy between the probabilities of the two classifiers.","Finally, ViT and CNN mutually exchange knowledge to improve the quality of pseudo labels and reduce the knowledge discrepancies of these models.","Compared to conventional DA methods, our ECB achieves superior performance, which verifies its effectiveness in this hybrid model.","The project website can be found https://dotrannhattuong.github.io/ECB/website/."],"url":"http://arxiv.org/abs/2403.18360v1","category":"cs.CV"}
{"created":"2024-03-27 08:44:40","title":"Early Stopping for Ensemble Kalman-Bucy Inversion","abstract":"Bayesian linear inverse problems aim to recover an unknown signal from noisy observations, incorporating prior knowledge. This paper analyses a data dependent method to choose the scale parameter of a Gaussian prior. The method we study arises from early stopping methods, which have been successfully applied to a range of problems for statistical inverse problems in the frequentist setting. These results are extended to the Bayesian setting. We study the use of a discrepancy based stopping rule in the setting of random noise. Our proposed stopping rule results in optimal rates under certain conditions on the prior covariance operator. We furthermore derive for which class of signals this method is adaptive. It is also shown that the associated posterior contracts at the optimal rate and provides a conservative measure of uncertainty. We implement the proposed stopping rule using the continuous-time ensemble Kalman--Bucy filter (EnKBF). The fictitious time parameter replaces the scale parameter, and the ensemble size is appropriately adjusted in order to not lose statistical optimality of the computed estimator. The EnKBF, then, gives a continuous process from the prior distribution to the posterior which is terminated using the proposed stopping rule.","sentences":["Bayesian linear inverse problems aim to recover an unknown signal from noisy observations, incorporating prior knowledge.","This paper analyses a data dependent method to choose the scale parameter of a Gaussian prior.","The method we study arises from early stopping methods, which have been successfully applied to a range of problems for statistical inverse problems in the frequentist setting.","These results are extended to the Bayesian setting.","We study the use of a discrepancy based stopping rule in the setting of random noise.","Our proposed stopping rule results in optimal rates under certain conditions on the prior covariance operator.","We furthermore derive for which class of signals this method is adaptive.","It is also shown that the associated posterior contracts at the optimal rate and provides a conservative measure of uncertainty.","We implement the proposed stopping rule using the continuous-time ensemble Kalman--Bucy filter (EnKBF).","The fictitious time parameter replaces the scale parameter, and the ensemble size is appropriately adjusted in order to not lose statistical optimality of the computed estimator.","The EnKBF, then, gives a continuous process from the prior distribution to the posterior which is terminated using the proposed stopping rule."],"url":"http://arxiv.org/abs/2403.18353v1","category":"math.ST"}
{"created":"2024-03-27 08:28:14","title":"H2ASeg: Hierarchical Adaptive Interaction and Weighting Network for Tumor Segmentation in PET/CT Images","abstract":"Positron emission tomography (PET) combined with computed tomography (CT) imaging is routinely used in cancer diagnosis and prognosis by providing complementary information. Automatically segmenting tumors in PET/CT images can significantly improve examination efficiency. Traditional multi-modal segmentation solutions mainly rely on concatenation operations for modality fusion, which fail to effectively model the non-linear dependencies between PET and CT modalities. Recent studies have investigated various approaches to optimize the fusion of modality-specific features for enhancing joint representations. However, modality-specific encoders used in these methods operate independently, inadequately leveraging the synergistic relationships inherent in PET and CT modalities, for example, the complementarity between semantics and structure. To address these issues, we propose a Hierarchical Adaptive Interaction and Weighting Network termed H2ASeg to explore the intrinsic cross-modal correlations and transfer potential complementary information. Specifically, we design a Modality-Cooperative Spatial Attention (MCSA) module that performs intra- and inter-modal interactions globally and locally. Additionally, a Target-Aware Modality Weighting (TAMW) module is developed to highlight tumor-related features within multi-modal features, thereby refining tumor segmentation. By embedding these modules across different layers, H2ASeg can hierarchically model cross-modal correlations, enabling a nuanced understanding of both semantic and structural tumor features. Extensive experiments demonstrate the superiority of H2ASeg, outperforming state-of-the-art methods on AutoPet-II and Hecktor2022 benchmarks. The code is released at https://github.com/JinPLu/H2ASeg.","sentences":["Positron emission tomography (PET) combined with computed tomography (CT) imaging is routinely used in cancer diagnosis and prognosis by providing complementary information.","Automatically segmenting tumors in PET/CT images can significantly improve examination efficiency.","Traditional multi-modal segmentation solutions mainly rely on concatenation operations for modality fusion, which fail to effectively model the non-linear dependencies between PET and CT modalities.","Recent studies have investigated various approaches to optimize the fusion of modality-specific features for enhancing joint representations.","However, modality-specific encoders used in these methods operate independently, inadequately leveraging the synergistic relationships inherent in PET and CT modalities, for example, the complementarity between semantics and structure.","To address these issues, we propose a Hierarchical Adaptive Interaction and Weighting Network termed H2ASeg to explore the intrinsic cross-modal correlations and transfer potential complementary information.","Specifically, we design a Modality-Cooperative Spatial Attention (MCSA) module that performs intra- and inter-modal interactions globally and locally.","Additionally, a Target-Aware Modality Weighting (TAMW) module is developed to highlight tumor-related features within multi-modal features, thereby refining tumor segmentation.","By embedding these modules across different layers, H2ASeg can hierarchically model cross-modal correlations, enabling a nuanced understanding of both semantic and structural tumor features.","Extensive experiments demonstrate the superiority of H2ASeg, outperforming state-of-the-art methods on AutoPet-II and Hecktor2022 benchmarks.","The code is released at https://github.com/JinPLu/H2ASeg."],"url":"http://arxiv.org/abs/2403.18339v2","category":"eess.IV"}
{"created":"2024-03-27 08:16:33","title":"DODA: Diffusion for Object-detection Domain Adaptation in Agriculture","abstract":"The diverse and high-quality content generated by recent generative models demonstrates the great potential of using synthetic data to train downstream models. However, in vision, especially in objection detection, related areas are not fully explored, the synthetic images are merely used to balance the long tails of existing datasets, and the accuracy of the generated labels is low, the full potential of generative models has not been exploited. In this paper, we propose DODA, a data synthesizer that can generate high-quality object detection data for new domains in agriculture. Specifically, we improve the controllability of layout-to-image through encoding layout as an image, thereby improving the quality of labels, and use a visual encoder to provide visual clues for the diffusion model to decouple visual features from the diffusion model, and empowering the model the ability to generate data in new domains. On the Global Wheat Head Detection (GWHD) Dataset, which is the largest dataset in agriculture and contains diverse domains, using the data synthesized by DODA improves the performance of the object detector by 12.74-17.76 AP$_{50}$ in the domain that was significantly shifted from the training data.","sentences":["The diverse and high-quality content generated by recent generative models demonstrates the great potential of using synthetic data to train downstream models.","However, in vision, especially in objection detection, related areas are not fully explored, the synthetic images are merely used to balance the long tails of existing datasets, and the accuracy of the generated labels is low, the full potential of generative models has not been exploited.","In this paper, we propose DODA, a data synthesizer that can generate high-quality object detection data for new domains in agriculture.","Specifically, we improve the controllability of layout-to-image through encoding layout as an image, thereby improving the quality of labels, and use a visual encoder to provide visual clues for the diffusion model to decouple visual features from the diffusion model, and empowering the model the ability to generate data in new domains.","On the Global Wheat Head Detection (GWHD) Dataset, which is the largest dataset in agriculture and contains diverse domains, using the data synthesized by DODA improves the performance of the object detector by 12.74-17.76 AP$_{50}$ in the domain that was significantly shifted from the training data."],"url":"http://arxiv.org/abs/2403.18334v1","category":"cs.CV"}
{"created":"2024-03-27 07:52:51","title":"How to Cache Important Contents for Multi-modal Service in Dynamic Networks: A DRL-based Caching Scheme","abstract":"With the continuous evolution of networking technologies, multi-modal services that involve video, audio, and haptic contents are expected to become the dominant multimedia service in the near future. Edge caching is a key technology that can significantly reduce network load and content transmission latency, which is critical for the delivery of multi-modal contents. However, existing caching approaches only rely on a limited number of factors, e.g., popularity, to evaluate their importance for caching, which is inefficient for caching multi-modal contents, especially in dynamic network environments. To overcome this issue, we propose a content importance-based caching scheme which consists of a content importance evaluation model and a caching model. By leveraging dueling double deep Q networks (D3QN) model, the content importance evaluation model can adaptively evaluate contents' importance in dynamic networks. Based on the evaluated contents' importance, the caching model can easily cache and evict proper contents to improve caching efficiency. The simulation results show that the proposed content importance-based caching scheme outperforms existing caching schemes in terms of caching hit ratio (at least 15% higher), reduced network load (up to 22% reduction), average number of hops (up to 27% lower), and unsatisfied requests ratio (more than 47% reduction).","sentences":["With the continuous evolution of networking technologies, multi-modal services that involve video, audio, and haptic contents are expected to become the dominant multimedia service in the near future.","Edge caching is a key technology that can significantly reduce network load and content transmission latency, which is critical for the delivery of multi-modal contents.","However, existing caching approaches only rely on a limited number of factors, e.g., popularity, to evaluate their importance for caching, which is inefficient for caching multi-modal contents, especially in dynamic network environments.","To overcome this issue, we propose a content importance-based caching scheme which consists of a content importance evaluation model and a caching model.","By leveraging dueling double deep Q networks (D3QN) model, the content importance evaluation model can adaptively evaluate contents' importance in dynamic networks.","Based on the evaluated contents' importance, the caching model can easily cache and evict proper contents to improve caching efficiency.","The simulation results show that the proposed content importance-based caching scheme outperforms existing caching schemes in terms of caching hit ratio (at least 15% higher), reduced network load (up to 22% reduction), average number of hops (up to 27% lower), and unsatisfied requests ratio (more than 47% reduction)."],"url":"http://arxiv.org/abs/2403.18323v1","category":"cs.NI"}
{"created":"2024-03-27 07:46:57","title":"Online Prediction for Streaming Tensor Time Series","abstract":"Real-time prediction plays a vital role in various control systems, such as traffic congestion control and wireless channel resource allocation. In these scenarios, the predictor usually needs to track the evolution of the latent statistical patterns in the modern high-dimensional streaming time series continuously and quickly, which presents new challenges for traditional prediction methods. This paper proposes a novel algorithm based on tensor factorization to predict streaming tensor time series online. The proposed algorithm updates the predictor in a low-complexity online manner to adapt to the time-evolving data. Additionally, an automatically adaptive version of the algorithm is presented to mitigate the negative impact of stale data. Simulation results demonstrate that our proposed methods achieve prediction accuracy similar to that of conventional offline tensor prediction methods, while being much faster than them during long-term online prediction. Therefore, our proposed algorithm provides an effective and efficient solution for the online prediction of streaming tensor time series.","sentences":["Real-time prediction plays a vital role in various control systems, such as traffic congestion control and wireless channel resource allocation.","In these scenarios, the predictor usually needs to track the evolution of the latent statistical patterns in the modern high-dimensional streaming time series continuously and quickly, which presents new challenges for traditional prediction methods.","This paper proposes a novel algorithm based on tensor factorization to predict streaming tensor time series online.","The proposed algorithm updates the predictor in a low-complexity online manner to adapt to the time-evolving data.","Additionally, an automatically adaptive version of the algorithm is presented to mitigate the negative impact of stale data.","Simulation results demonstrate that our proposed methods achieve prediction accuracy similar to that of conventional offline tensor prediction methods, while being much faster than them during long-term online prediction.","Therefore, our proposed algorithm provides an effective and efficient solution for the online prediction of streaming tensor time series."],"url":"http://arxiv.org/abs/2403.18320v1","category":"math.OC"}
{"created":"2024-03-27 07:22:32","title":"A thermodynamically consistent physics-informed deep learning material model for short fiber/polymer nanocomposites","abstract":"This work proposes a physics-informed deep learning (PIDL)-based constitutive model for investigating the viscoelastic-viscoplastic behavior of short fiber-reinforced nanoparticle-filled epoxies under various ambient conditions. The deep-learning model is trained to enforce thermodynamic principles, leading to a thermodynamically consistent constitutive model. To accomplish this, a long short-term memory network is combined with a feed-forward neural network to predict internal variables required for characterizing the internal dissipation of the nanocomposite materials. In addition, another feed-forward neural network is used to indicate the free-energy function, which enables defining the thermodynamic state of the entire system. The PIDL model is initially developed for the three-dimensional case by generating synthetic data from a classical constitutive model. The model is then trained by extracting the data directly from cyclic loading-unloading experimental tests. Numerical examples show that the PIDL model can accurately predict the mechanical behavior of epoxy-based nanocomposites for different volume fractions of fibers and nanoparticles under various hygrothermal conditions.","sentences":["This work proposes a physics-informed deep learning (PIDL)-based constitutive model for investigating the viscoelastic-viscoplastic behavior of short fiber-reinforced nanoparticle-filled epoxies under various ambient conditions.","The deep-learning model is trained to enforce thermodynamic principles, leading to a thermodynamically consistent constitutive model.","To accomplish this, a long short-term memory network is combined with a feed-forward neural network to predict internal variables required for characterizing the internal dissipation of the nanocomposite materials.","In addition, another feed-forward neural network is used to indicate the free-energy function, which enables defining the thermodynamic state of the entire system.","The PIDL model is initially developed for the three-dimensional case by generating synthetic data from a classical constitutive model.","The model is then trained by extracting the data directly from cyclic loading-unloading experimental tests.","Numerical examples show that the PIDL model can accurately predict the mechanical behavior of epoxy-based nanocomposites for different volume fractions of fibers and nanoparticles under various hygrothermal conditions."],"url":"http://arxiv.org/abs/2403.18310v1","category":"cs.LG"}
{"created":"2024-03-27 06:37:51","title":"Efficient Test-Time Adaptation of Vision-Language Models","abstract":"Test-time adaptation with pre-trained vision-language models has attracted increasing attention for tackling distribution shifts during the test time. Though prior studies have achieved very promising performance, they involve intensive computation which is severely unaligned with test-time adaptation. We design TDA, a training-free dynamic adapter that enables effective and efficient test-time adaptation with vision-language models. TDA works with a lightweight key-value cache that maintains a dynamic queue with few-shot pseudo labels as values and the corresponding test-sample features as keys. Leveraging the key-value cache, TDA allows adapting to test data gradually via progressive pseudo label refinement which is super-efficient without incurring any backpropagation. In addition, we introduce negative pseudo labeling that alleviates the adverse impact of pseudo label noises by assigning pseudo labels to certain negative classes when the model is uncertain about its pseudo label predictions. Extensive experiments over two benchmarks demonstrate TDA's superior effectiveness and efficiency as compared with the state-of-the-art. The code has been released in \\url{https://kdiaaa.github.io/tda/}.","sentences":["Test-time adaptation with pre-trained vision-language models has attracted increasing attention for tackling distribution shifts during the test time.","Though prior studies have achieved very promising performance, they involve intensive computation which is severely unaligned with test-time adaptation.","We design TDA, a training-free dynamic adapter that enables effective and efficient test-time adaptation with vision-language models.","TDA works with a lightweight key-value cache that maintains a dynamic queue with few-shot pseudo labels as values and the corresponding test-sample features as keys.","Leveraging the key-value cache, TDA allows adapting to test data gradually via progressive pseudo label refinement which is super-efficient without incurring any backpropagation.","In addition, we introduce negative pseudo labeling that alleviates the adverse impact of pseudo label noises by assigning pseudo labels to certain negative classes when the model is uncertain about its pseudo label predictions.","Extensive experiments over two benchmarks demonstrate TDA's superior effectiveness and efficiency as compared with the state-of-the-art.","The code has been released in \\url{https://kdiaaa.github.io/tda/}."],"url":"http://arxiv.org/abs/2403.18293v1","category":"cs.CV"}
{"created":"2024-03-27 06:28:19","title":"Towards Non-Exemplar Semi-Supervised Class-Incremental Learning","abstract":"Deep neural networks perform remarkably well in close-world scenarios. However, novel classes emerged continually in real applications, making it necessary to learn incrementally. Class-incremental learning (CIL) aims to gradually recognize new classes while maintaining the discriminability of old ones. Existing CIL methods have two limitations: a heavy reliance on preserving old data for forgetting mitigation and the need for vast labeled data for knowledge adaptation. To overcome these issues, we propose a non-exemplar semi-supervised CIL framework with contrastive learning and semi-supervised incremental prototype classifier (Semi-IPC). On the one hand, contrastive learning helps the model learn rich representations, easing the trade-off between learning representations of new classes and forgetting that of old classes. On the other hand, Semi-IPC learns a prototype for each class with unsupervised regularization, enabling the model to incrementally learn from partially labeled new data while maintaining the knowledge of old classes. Experiments on benchmark datasets demonstrate the strong performance of our method: without storing any old samples and only using less than 1% of labels, Semi-IPC outperforms advanced exemplar-based methods. We hope our work offers new insights for future CIL research. The code will be made publicly available.","sentences":["Deep neural networks perform remarkably well in close-world scenarios.","However, novel classes emerged continually in real applications, making it necessary to learn incrementally.","Class-incremental learning (CIL) aims to gradually recognize new classes while maintaining the discriminability of old ones.","Existing CIL methods have two limitations: a heavy reliance on preserving old data for forgetting mitigation and the need for vast labeled data for knowledge adaptation.","To overcome these issues, we propose a non-exemplar semi-supervised CIL framework with contrastive learning and semi-supervised incremental prototype classifier (Semi-IPC).","On the one hand, contrastive learning helps the model learn rich representations, easing the trade-off between learning representations of new classes and forgetting that of old classes.","On the other hand, Semi-IPC learns a prototype for each class with unsupervised regularization, enabling the model to incrementally learn from partially labeled new data while maintaining the knowledge of old classes.","Experiments on benchmark datasets demonstrate the strong performance of our method: without storing any old samples and only using less than 1% of labels, Semi-IPC outperforms advanced exemplar-based methods.","We hope our work offers new insights for future CIL research.","The code will be made publicly available."],"url":"http://arxiv.org/abs/2403.18291v1","category":"cs.CV"}
{"created":"2024-03-27 06:18:40","title":"SGDM: Static-Guided Dynamic Module Make Stronger Visual Models","abstract":"The spatial attention mechanism has been widely used to improve object detection performance. However, its operation is currently limited to static convolutions lacking content-adaptive features. This paper innovatively approaches from the perspective of dynamic convolution. We propose Razor Dynamic Convolution (RDConv) to address thetwo flaws in dynamic weight convolution, making it hard to implement in spatial mechanism: 1) it is computation-heavy; 2) when generating weights, spatial information is disregarded. Firstly, by using Razor Operation to generate certain features, we vastly reduce the parameters of the entire dynamic convolution operation. Secondly, we added a spatial branch inside RDConv to generate convolutional kernel parameters with richer spatial information. Embedding dynamic convolution will also bring the problem of sensitivity to high-frequency noise. We propose the Static-Guided Dynamic Module (SGDM) to address this limitation. By using SGDM, we utilize a set of asymmetric static convolution kernel parameters to guide the construction of dynamic convolution. We introduce the mechanism of shared weights in static convolution to solve the problem of dynamic convolution being sensitive to high-frequency noise. Extensive experiments illustrate that multiple different object detection backbones equipped with SGDM achieve a highly competitive boost in performance(e.g., +4% mAP with YOLOv5n on VOC and +1.7% mAP with YOLOv8n on COCO) with negligible parameter increase(i.e., +0.33M on YOLOv5n and +0.19M on YOLOv8n).","sentences":["The spatial attention mechanism has been widely used to improve object detection performance.","However, its operation is currently limited to static convolutions lacking content-adaptive features.","This paper innovatively approaches from the perspective of dynamic convolution.","We propose Razor Dynamic Convolution (RDConv) to address thetwo flaws in dynamic weight convolution, making it hard to implement in spatial mechanism: 1) it is computation-heavy; 2) when generating weights, spatial information is disregarded.","Firstly, by using Razor Operation to generate certain features, we vastly reduce the parameters of the entire dynamic convolution operation.","Secondly, we added a spatial branch inside RDConv to generate convolutional kernel parameters with richer spatial information.","Embedding dynamic convolution will also bring the problem of sensitivity to high-frequency noise.","We propose the Static-Guided Dynamic Module (SGDM) to address this limitation.","By using SGDM, we utilize a set of asymmetric static convolution kernel parameters to guide the construction of dynamic convolution.","We introduce the mechanism of shared weights in static convolution to solve the problem of dynamic convolution being sensitive to high-frequency noise.","Extensive experiments illustrate that multiple different object detection backbones equipped with SGDM achieve a highly competitive boost in performance(e.g., +4% mAP with YOLOv5n on VOC and","+1.7% mAP with YOLOv8n on COCO) with negligible parameter increase(i.e., +0.33M on YOLOv5n and +0.19M on YOLOv8n)."],"url":"http://arxiv.org/abs/2403.18282v1","category":"cs.CV"}
{"created":"2024-03-27 06:17:21","title":"AIR-HLoc: Adaptive Image Retrieval for Efficient Visual Localisation","abstract":"State-of-the-art (SOTA) hierarchical localisation pipelines (HLoc) rely on image retrieval (IR) techniques to establish 2D-3D correspondences by selecting the $k$ most similar images from a reference image database for a given query image. Although higher values of $k$ enhance localisation robustness, the computational cost for feature matching increases linearly with $k$. In this paper, we observe that queries that are the most similar to images in the database result in a higher proportion of feature matches and, thus, more accurate positioning. Thus, a small number of images is sufficient for queries very similar to images in the reference database. We then propose a novel approach, AIR-HLoc, which divides query images into different localisation difficulty levels based on their similarity to the reference image database. We consider an image with high similarity to the reference image as an easy query and an image with low similarity as a hard query. Easy queries show a limited improvement in accuracy when increasing $k$. Conversely, higher values of $k$ significantly improve accuracy for hard queries. Given the limited improvement in accuracy when increasing $k$ for easy queries and the significant improvement for hard queries, we adapt the value of $k$ to the query's difficulty level. Therefore, AIR-HLoc optimizes processing time by adaptively assigning different values of $k$ based on the similarity between the query and reference images without losing accuracy. Our extensive experiments on the Cambridge Landmarks, 7Scenes, and Aachen Day-Night-v1.1 datasets demonstrate our algorithm's efficacy, reducing 30\\%, 26\\%, and 11\\% in computational overhead while maintaining SOTA accuracy compared to HLoc with fixed image retrieval.","sentences":["State-of-the-art (SOTA) hierarchical localisation pipelines (HLoc) rely on image retrieval (IR) techniques to establish 2D-3D correspondences by selecting the $k$ most similar images from a reference image database for a given query image.","Although higher values of $k$ enhance localisation robustness, the computational cost for feature matching increases linearly with $k$. In this paper, we observe that queries that are the most similar to images in the database result in a higher proportion of feature matches and, thus, more accurate positioning.","Thus, a small number of images is sufficient for queries very similar to images in the reference database.","We then propose a novel approach, AIR-HLoc, which divides query images into different localisation difficulty levels based on their similarity to the reference image database.","We consider an image with high similarity to the reference image as an easy query and an image with low similarity as a hard query.","Easy queries show a limited improvement in accuracy when increasing $k$. Conversely, higher values of $k$ significantly improve accuracy for hard queries.","Given the limited improvement in accuracy when increasing $k$ for easy queries and the significant improvement for hard queries, we adapt the value of $k$ to the query's difficulty level.","Therefore, AIR-HLoc optimizes processing time by adaptively assigning different values of $k$ based on the similarity between the query and reference images without losing accuracy.","Our extensive experiments on the Cambridge Landmarks, 7Scenes, and Aachen Day-Night-v1.1 datasets demonstrate our algorithm's efficacy, reducing 30\\%, 26\\%, and 11\\% in computational overhead while maintaining SOTA accuracy compared to HLoc with fixed image retrieval."],"url":"http://arxiv.org/abs/2403.18281v1","category":"cs.CV"}
{"created":"2024-03-27 05:57:45","title":"DVLO: Deep Visual-LiDAR Odometry with Local-to-Global Feature Fusion and Bi-Directional Structure Alignment","abstract":"Information inside visual and LiDAR data is well complementary derived from the fine-grained texture of images and massive geometric information in point clouds. However, it remains challenging to explore effective visual-LiDAR fusion, mainly due to the intrinsic data structure inconsistency between two modalities: Images are regular and dense, but LiDAR points are unordered and sparse. To address the problem, we propose a local-to-global fusion network with bi-directional structure alignment. To obtain locally fused features, we project points onto image plane as cluster centers and cluster image pixels around each center. Image pixels are pre-organized as pseudo points for image-to-point structure alignment. Then, we convert points to pseudo images by cylindrical projection (point-to-image structure alignment) and perform adaptive global feature fusion between point features with local fused features. Our method achieves state-of-the-art performance on KITTI odometry and FlyingThings3D scene flow datasets compared to both single-modal and multi-modal methods. Codes will be released later.","sentences":["Information inside visual and LiDAR data is well complementary derived from the fine-grained texture of images and massive geometric information in point clouds.","However, it remains challenging to explore effective visual-LiDAR fusion, mainly due to the intrinsic data structure inconsistency between two modalities: Images are regular and dense, but LiDAR points are unordered and sparse.","To address the problem, we propose a local-to-global fusion network with bi-directional structure alignment.","To obtain locally fused features, we project points onto image plane as cluster centers and cluster image pixels around each center.","Image pixels are pre-organized as pseudo points for image-to-point structure alignment.","Then, we convert points to pseudo images by cylindrical projection (point-to-image structure alignment) and perform adaptive global feature fusion between point features with local fused features.","Our method achieves state-of-the-art performance on KITTI odometry and FlyingThings3D scene flow datasets compared to both single-modal and multi-modal methods.","Codes will be released later."],"url":"http://arxiv.org/abs/2403.18274v1","category":"cs.CV"}
{"created":"2024-03-27 05:55:16","title":"Unleashing the Potential of SAM for Medical Adaptation via Hierarchical Decoding","abstract":"The Segment Anything Model (SAM) has garnered significant attention for its versatile segmentation abilities and intuitive prompt-based interface. However, its application in medical imaging presents challenges, requiring either substantial training costs and extensive medical datasets for full model fine-tuning or high-quality prompts for optimal performance. This paper introduces H-SAM: a prompt-free adaptation of SAM tailored for efficient fine-tuning of medical images via a two-stage hierarchical decoding procedure. In the initial stage, H-SAM employs SAM's original decoder to generate a prior probabilistic mask, guiding a more intricate decoding process in the second stage. Specifically, we propose two key designs: 1) A class-balanced, mask-guided self-attention mechanism addressing the unbalanced label distribution, enhancing image embedding; 2) A learnable mask cross-attention mechanism spatially modulating the interplay among different image regions based on the prior mask. Moreover, the inclusion of a hierarchical pixel decoder in H-SAM enhances its proficiency in capturing fine-grained and localized details. This approach enables SAM to effectively integrate learned medical priors, facilitating enhanced adaptation for medical image segmentation with limited samples. Our H-SAM demonstrates a 4.78% improvement in average Dice compared to existing prompt-free SAM variants for multi-organ segmentation using only 10% of 2D slices. Notably, without using any unlabeled data, H-SAM even outperforms state-of-the-art semi-supervised models relying on extensive unlabeled training data across various medical datasets. Our code is available at https://github.com/Cccccczh404/H-SAM.","sentences":["The Segment Anything Model (SAM) has garnered significant attention for its versatile segmentation abilities and intuitive prompt-based interface.","However, its application in medical imaging presents challenges, requiring either substantial training costs and extensive medical datasets for full model fine-tuning or high-quality prompts for optimal performance.","This paper introduces H-SAM: a prompt-free adaptation of SAM tailored for efficient fine-tuning of medical images via a two-stage hierarchical decoding procedure.","In the initial stage, H-SAM employs SAM's original decoder to generate a prior probabilistic mask, guiding a more intricate decoding process in the second stage.","Specifically, we propose two key designs: 1) A class-balanced, mask-guided self-attention mechanism addressing the unbalanced label distribution, enhancing image embedding; 2) A learnable mask cross-attention mechanism spatially modulating the interplay among different image regions based on the prior mask.","Moreover, the inclusion of a hierarchical pixel decoder in H-SAM enhances its proficiency in capturing fine-grained and localized details.","This approach enables SAM to effectively integrate learned medical priors, facilitating enhanced adaptation for medical image segmentation with limited samples.","Our H-SAM demonstrates a 4.78% improvement in average Dice compared to existing prompt-free SAM variants for multi-organ segmentation using only 10% of 2D slices.","Notably, without using any unlabeled data, H-SAM even outperforms state-of-the-art semi-supervised models relying on extensive unlabeled training data across various medical datasets.","Our code is available at https://github.com/Cccccczh404/H-SAM."],"url":"http://arxiv.org/abs/2403.18271v1","category":"cs.CV"}
{"created":"2024-03-27 05:38:48","title":"Branch-Tuning: Balancing Stability and Plasticity for Continual Self-Supervised Learning","abstract":"Self-supervised learning (SSL) has emerged as an effective paradigm for deriving general representations from vast amounts of unlabeled data. However, as real-world applications continually integrate new content, the high computational and resource demands of SSL necessitate continual learning rather than complete retraining. This poses a challenge in striking a balance between stability and plasticity when adapting to new information. In this paper, we employ Centered Kernel Alignment for quantitatively analyzing model stability and plasticity, revealing the critical roles of batch normalization layers for stability and convolutional layers for plasticity. Motivated by this, we propose Branch-tuning, an efficient and straightforward method that achieves a balance between stability and plasticity in continual SSL. Branch-tuning consists of branch expansion and compression, and can be easily applied to various SSL methods without the need of modifying the original methods, retaining old data or models. We validate our method through incremental experiments on various benchmark datasets, demonstrating its effectiveness and practical value in real-world scenarios. We hope our work offers new insights for future continual self-supervised learning research. The code will be made publicly available.","sentences":["Self-supervised learning (SSL) has emerged as an effective paradigm for deriving general representations from vast amounts of unlabeled data.","However, as real-world applications continually integrate new content, the high computational and resource demands of SSL necessitate continual learning rather than complete retraining.","This poses a challenge in striking a balance between stability and plasticity when adapting to new information.","In this paper, we employ Centered Kernel Alignment for quantitatively analyzing model stability and plasticity, revealing the critical roles of batch normalization layers for stability and convolutional layers for plasticity.","Motivated by this, we propose Branch-tuning, an efficient and straightforward method that achieves a balance between stability and plasticity in continual SSL.","Branch-tuning consists of branch expansion and compression, and can be easily applied to various SSL methods without the need of modifying the original methods, retaining old data or models.","We validate our method through incremental experiments on various benchmark datasets, demonstrating its effectiveness and practical value in real-world scenarios.","We hope our work offers new insights for future continual self-supervised learning research.","The code will be made publicly available."],"url":"http://arxiv.org/abs/2403.18266v1","category":"cs.LG"}
{"created":"2024-03-27 05:15:48","title":"RoboKeyGen: Robot Pose and Joint Angles Estimation via Diffusion-based 3D Keypoint Generation","abstract":"Estimating robot pose and joint angles is significant in advanced robotics, enabling applications like robot collaboration and online hand-eye calibration.However, the introduction of unknown joint angles makes prediction more complex than simple robot pose estimation, due to its higher dimensionality.Previous methods either regress 3D keypoints directly or utilise a render&compare strategy. These approaches often falter in terms of performance or efficiency and grapple with the cross-camera gap problem.This paper presents a novel framework that bifurcates the high-dimensional prediction task into two manageable subtasks: 2D keypoints detection and lifting 2D keypoints to 3D. This separation promises enhanced performance without sacrificing the efficiency innate to keypoint-based techniques.A vital component of our method is the lifting of 2D keypoints to 3D keypoints. Common deterministic regression methods may falter when faced with uncertainties from 2D detection errors or self-occlusions.Leveraging the robust modeling potential of diffusion models, we reframe this issue as a conditional 3D keypoints generation task. To bolster cross-camera adaptability, we introduce theNormalised Camera Coordinate Space (NCCS), ensuring alignment of estimated 2D keypoints across varying camera intrinsics.Experimental results demonstrate that the proposed method outperforms the state-of-the-art render\\&compare method and achieves higher inference speed.Furthermore, the tests accentuate our method's robust cross-camera generalisation capabilities.We intend to release both the dataset and code in https://nimolty.github.io/Robokeygen/","sentences":["Estimating robot pose and joint angles is significant in advanced robotics, enabling applications like robot collaboration and online hand-eye calibration.","However, the introduction of unknown joint angles makes prediction more complex than simple robot pose estimation, due to its higher dimensionality.","Previous methods either regress 3D keypoints directly or utilise a render&compare strategy.","These approaches often falter in terms of performance or efficiency and grapple with the cross-camera gap problem.","This paper presents a novel framework that bifurcates the high-dimensional prediction task into two manageable subtasks: 2D keypoints detection and lifting 2D keypoints to 3D.","This separation promises enhanced performance without sacrificing the efficiency innate to keypoint-based techniques.","A vital component of our method is the lifting of 2D keypoints to 3D keypoints.","Common deterministic regression methods may falter when faced with uncertainties from 2D detection errors or self-occlusions.","Leveraging the robust modeling potential of diffusion models, we reframe this issue as a conditional 3D keypoints generation task.","To bolster cross-camera adaptability, we introduce theNormalised Camera Coordinate Space (NCCS), ensuring alignment of estimated 2D keypoints across varying camera intrinsics.","Experimental results demonstrate that the proposed method outperforms the state-of-the-art render\\&compare method and achieves higher inference speed.","Furthermore, the tests accentuate our method's robust cross-camera generalisation capabilities.","We intend to release both the dataset and code in https://nimolty.github.io/Robokeygen/"],"url":"http://arxiv.org/abs/2403.18259v1","category":"cs.RO"}
{"created":"2024-03-27 05:10:38","title":"Enhancing Generative Class Incremental Learning Performance with Model Forgetting Approach","abstract":"This study presents a novel approach to Generative Class Incremental Learning (GCIL) by introducing the forgetting mechanism, aimed at dynamically managing class information for better adaptation to streaming data. GCIL is one of the hot topics in the field of computer vision, and this is considered one of the crucial tasks in society, specifically the continual learning of generative models. The ability to forget is a crucial brain function that facilitates continual learning by selectively discarding less relevant information for humans. However, in the field of machine learning models, the concept of intentionally forgetting has not been extensively investigated. In this study we aim to bridge this gap by incorporating the forgetting mechanisms into GCIL, thereby examining their impact on the models' ability to learn in continual learning. Through our experiments, we have found that integrating the forgetting mechanisms significantly enhances the models' performance in acquiring new knowledge, underscoring the positive role that strategic forgetting plays in the process of continual learning.","sentences":["This study presents a novel approach to Generative Class Incremental Learning (GCIL) by introducing the forgetting mechanism, aimed at dynamically managing class information for better adaptation to streaming data.","GCIL is one of the hot topics in the field of computer vision, and this is considered one of the crucial tasks in society, specifically the continual learning of generative models.","The ability to forget is a crucial brain function that facilitates continual learning by selectively discarding less relevant information for humans.","However, in the field of machine learning models, the concept of intentionally forgetting has not been extensively investigated.","In this study we aim to bridge this gap by incorporating the forgetting mechanisms into GCIL, thereby examining their impact on the models' ability to learn in continual learning.","Through our experiments, we have found that integrating the forgetting mechanisms significantly enhances the models' performance in acquiring new knowledge, underscoring the positive role that strategic forgetting plays in the process of continual learning."],"url":"http://arxiv.org/abs/2403.18258v1","category":"cs.CV"}
{"created":"2024-03-27 04:20:18","title":"Boosting Conversational Question Answering with Fine-Grained Retrieval-Augmentation and Self-Check","abstract":"Retrieval-Augmented Generation (RAG) aims to generate more reliable and accurate responses, by augmenting large language models (LLMs) with the external vast and dynamic knowledge. Most previous work focuses on using RAG for single-round question answering, while how to adapt RAG to the complex conversational setting wherein the question is interdependent on the preceding context is not well studied. In this paper, we propose a conversation-level RAG approach, which incorporates fine-grained retrieval augmentation and self-check for conversational question answering (CQA). In particular, our approach consists of three components, namely conversational question refiner, fine-grained retriever and self-check based response generator, which work collaboratively for question understanding and relevant information acquisition in conversational settings. Extensive experiments demonstrate the great advantages of our approach over the state-of-the-art baselines. Moreover, we also release a Chinese CQA dataset with new features including reformulated question, extracted keyword, retrieved paragraphs and their helpfulness, which facilitates further researches in RAG enhanced CQA.","sentences":["Retrieval-Augmented Generation (RAG) aims to generate more reliable and accurate responses, by augmenting large language models (LLMs) with the external vast and dynamic knowledge.","Most previous work focuses on using RAG for single-round question answering, while how to adapt RAG to the complex conversational setting wherein the question is interdependent on the preceding context is not well studied.","In this paper, we propose a conversation-level RAG approach, which incorporates fine-grained retrieval augmentation and self-check for conversational question answering (CQA).","In particular, our approach consists of three components, namely conversational question refiner, fine-grained retriever and self-check based response generator, which work collaboratively for question understanding and relevant information acquisition in conversational settings.","Extensive experiments demonstrate the great advantages of our approach over the state-of-the-art baselines.","Moreover, we also release a Chinese CQA dataset with new features including reformulated question, extracted keyword, retrieved paragraphs and their helpfulness, which facilitates further researches in RAG enhanced CQA."],"url":"http://arxiv.org/abs/2403.18243v1","category":"cs.AI"}
{"created":"2024-03-27 04:03:55","title":"TAFormer: A Unified Target-Aware Transformer for Video and Motion Joint Prediction in Aerial Scenes","abstract":"As drone technology advances, using unmanned aerial vehicles for aerial surveys has become the dominant trend in modern low-altitude remote sensing. The surge in aerial video data necessitates accurate prediction for future scenarios and motion states of the interested target, particularly in applications like traffic management and disaster response. Existing video prediction methods focus solely on predicting future scenes (video frames), suffering from the neglect of explicitly modeling target's motion states, which is crucial for aerial video interpretation. To address this issue, we introduce a novel task called Target-Aware Aerial Video Prediction, aiming to simultaneously predict future scenes and motion states of the target. Further, we design a model specifically for this task, named TAFormer, which provides a unified modeling approach for both video and target motion states. Specifically, we introduce Spatiotemporal Attention (STA), which decouples the learning of video dynamics into spatial static attention and temporal dynamic attention, effectively modeling the scene appearance and motion. Additionally, we design an Information Sharing Mechanism (ISM), which elegantly unifies the modeling of video and target motion by facilitating information interaction through two sets of messenger tokens. Moreover, to alleviate the difficulty of distinguishing targets in blurry predictions, we introduce Target-Sensitive Gaussian Loss (TSGL), enhancing the model's sensitivity to both target's position and content. Extensive experiments on UAV123VP and VisDroneVP (derived from single-object tracking datasets) demonstrate the exceptional performance of TAFormer in target-aware video prediction, showcasing its adaptability to the additional requirements of aerial video interpretation for target awareness.","sentences":["As drone technology advances, using unmanned aerial vehicles for aerial surveys has become the dominant trend in modern low-altitude remote sensing.","The surge in aerial video data necessitates accurate prediction for future scenarios and motion states of the interested target, particularly in applications like traffic management and disaster response.","Existing video prediction methods focus solely on predicting future scenes (video frames), suffering from the neglect of explicitly modeling target's motion states, which is crucial for aerial video interpretation.","To address this issue, we introduce a novel task called Target-Aware Aerial Video Prediction, aiming to simultaneously predict future scenes and motion states of the target.","Further, we design a model specifically for this task, named TAFormer, which provides a unified modeling approach for both video and target motion states.","Specifically, we introduce Spatiotemporal Attention (STA), which decouples the learning of video dynamics into spatial static attention and temporal dynamic attention, effectively modeling the scene appearance and motion.","Additionally, we design an Information Sharing Mechanism (ISM), which elegantly unifies the modeling of video and target motion by facilitating information interaction through two sets of messenger tokens.","Moreover, to alleviate the difficulty of distinguishing targets in blurry predictions, we introduce Target-Sensitive Gaussian Loss (TSGL), enhancing the model's sensitivity to both target's position and content.","Extensive experiments on UAV123VP and VisDroneVP (derived from single-object tracking datasets) demonstrate the exceptional performance of TAFormer in target-aware video prediction, showcasing its adaptability to the additional requirements of aerial video interpretation for target awareness."],"url":"http://arxiv.org/abs/2403.18238v1","category":"cs.CV"}
{"created":"2024-03-27 03:25:45","title":"A Transformer-Based Framework for Payload Malware Detection and Classification","abstract":"As malicious cyber threats become more sophisticated in breaching computer networks, the need for effective intrusion detection systems (IDSs) becomes crucial. Techniques such as Deep Packet Inspection (DPI) have been introduced to allow IDSs analyze the content of network packets, providing more context for identifying potential threats. IDSs traditionally rely on using anomaly-based and signature-based detection techniques to detect unrecognized and suspicious activity. Deep learning techniques have shown great potential in DPI for IDSs due to their efficiency in learning intricate patterns from the packet content being transmitted through the network. In this paper, we propose a revolutionary DPI algorithm based on transformers adapted for the purpose of detecting malicious traffic with a classifier head. Transformers learn the complex content of sequence data and generalize them well to similar scenarios thanks to their self-attention mechanism. Our proposed method uses the raw payload bytes that represent the packet contents and is deployed as man-in-the-middle. The payload bytes are used to detect malicious packets and classify their types. Experimental results on the UNSW-NB15 and CIC-IOT23 datasets demonstrate that our transformer-based model is effective in distinguishing malicious from benign traffic in the test dataset, attaining an average accuracy of 79\\% using binary classification and 72\\% on the multi-classification experiment, both using solely payload bytes.","sentences":["As malicious cyber threats become more sophisticated in breaching computer networks, the need for effective intrusion detection systems (IDSs) becomes crucial.","Techniques such as Deep Packet Inspection (DPI) have been introduced to allow IDSs analyze the content of network packets, providing more context for identifying potential threats.","IDSs traditionally rely on using anomaly-based and signature-based detection techniques to detect unrecognized and suspicious activity.","Deep learning techniques have shown great potential in DPI for IDSs due to their efficiency in learning intricate patterns from the packet content being transmitted through the network.","In this paper, we propose a revolutionary DPI algorithm based on transformers adapted for the purpose of detecting malicious traffic with a classifier head.","Transformers learn the complex content of sequence data and generalize them well to similar scenarios thanks to their self-attention mechanism.","Our proposed method uses the raw payload bytes that represent the packet contents and is deployed as man-in-the-middle.","The payload bytes are used to detect malicious packets and classify their types.","Experimental results on the UNSW-NB15 and CIC-IOT23 datasets demonstrate that our transformer-based model is effective in distinguishing malicious from benign traffic in the test dataset, attaining an average accuracy of 79\\% using binary classification and 72\\% on the multi-classification experiment, both using solely payload bytes."],"url":"http://arxiv.org/abs/2403.18223v1","category":"cs.CR"}
{"created":"2024-03-27 03:07:18","title":"From Two-Dimensional to Three-Dimensional Environment with Q-Learning: Modeling Autonomous Navigation with Reinforcement Learning and no Libraries","abstract":"Reinforcement learning (RL) algorithms have become indispensable tools in artificial intelligence, empowering agents to acquire optimal decision-making policies through interactions with their environment and feedback mechanisms. This study explores the performance of RL agents in both two-dimensional (2D) and three-dimensional (3D) environments, aiming to research the dynamics of learning across different spatial dimensions. A key aspect of this investigation is the absence of pre-made libraries for learning, with the algorithm developed exclusively through computational mathematics. The methodological framework centers on RL principles, employing a Q-learning agent class and distinct environment classes tailored to each spatial dimension. The research aims to address the question: How do reinforcement learning agents adapt and perform in environments of varying spatial dimensions, particularly in 2D and 3D settings? Through empirical analysis, the study evaluates agents' learning trajectories and adaptation processes, revealing insights into the efficacy of RL algorithms in navigating complex, multi-dimensional spaces. Reflections on the findings prompt considerations for future research, particularly in understanding the dynamics of learning in higher-dimensional environments.","sentences":["Reinforcement learning (RL) algorithms have become indispensable tools in artificial intelligence, empowering agents to acquire optimal decision-making policies through interactions with their environment and feedback mechanisms.","This study explores the performance of RL agents in both two-dimensional (2D) and three-dimensional (3D) environments, aiming to research the dynamics of learning across different spatial dimensions.","A key aspect of this investigation is the absence of pre-made libraries for learning, with the algorithm developed exclusively through computational mathematics.","The methodological framework centers on RL principles, employing a Q-learning agent class and distinct environment classes tailored to each spatial dimension.","The research aims to address the question: How do reinforcement learning agents adapt and perform in environments of varying spatial dimensions, particularly in 2D and 3D settings?","Through empirical analysis, the study evaluates agents' learning trajectories and adaptation processes, revealing insights into the efficacy of RL algorithms in navigating complex, multi-dimensional spaces.","Reflections on the findings prompt considerations for future research, particularly in understanding the dynamics of learning in higher-dimensional environments."],"url":"http://arxiv.org/abs/2403.18219v1","category":"cs.LG"}
{"created":"2024-03-27 02:42:52","title":"NeuroPictor: Refining fMRI-to-Image Reconstruction via Multi-individual Pretraining and Multi-level Modulation","abstract":"Recent fMRI-to-image approaches mainly focused on associating fMRI signals with specific conditions of pre-trained diffusion models. These approaches, while producing high-quality images, capture only a limited aspect of the complex information in fMRI signals and offer little detailed control over image creation. In contrast, this paper proposes to directly modulate the generation process of diffusion models using fMRI signals. Our approach, NeuroPictor, divides the fMRI-to-image process into three steps: i) fMRI calibrated-encoding, to tackle multi-individual pre-training for a shared latent space to minimize individual difference and enable the subsequent cross-subject training; ii) fMRI-to-image cross-subject pre-training, perceptually learning to guide diffusion model with high- and low-level conditions across different individuals; iii) fMRI-to-image single-subject refining, similar with step ii but focus on adapting to particular individual. NeuroPictor extracts high-level semantic features from fMRI signals that characterizing the visual stimulus and incrementally fine-tunes the diffusion model with a low-level manipulation network to provide precise structural instructions. By training with over 60,000 fMRI-image pairs from various individuals, our model enjoys superior fMRI-to-image decoding capacity, particularly in the within-subject setting, as evidenced in benchmark datasets. Project page: https://jingyanghuo.github.io/neuropictor/.","sentences":["Recent fMRI-to-image approaches mainly focused on associating fMRI signals with specific conditions of pre-trained diffusion models.","These approaches, while producing high-quality images, capture only a limited aspect of the complex information in fMRI signals and offer little detailed control over image creation.","In contrast, this paper proposes to directly modulate the generation process of diffusion models using fMRI signals.","Our approach, NeuroPictor, divides the fMRI-to-image process into three steps: i) fMRI calibrated-encoding, to tackle multi-individual pre-training for a shared latent space to minimize individual difference and enable the subsequent cross-subject training; ii) fMRI-to-image cross-subject pre-training, perceptually learning to guide diffusion model with high- and low-level conditions across different individuals; iii) fMRI-to-image single-subject refining, similar with step ii but focus on adapting to particular individual.","NeuroPictor extracts high-level semantic features from fMRI signals that characterizing the visual stimulus and incrementally fine-tunes the diffusion model with a low-level manipulation network to provide precise structural instructions.","By training with over 60,000 fMRI-image pairs from various individuals, our model enjoys superior fMRI-to-image decoding capacity, particularly in the within-subject setting, as evidenced in benchmark datasets.","Project page: https://jingyanghuo.github.io/neuropictor/."],"url":"http://arxiv.org/abs/2403.18211v1","category":"cs.CV"}
{"created":"2024-03-27 02:39:23","title":"An Evolutionary Network Architecture Search Framework with Adaptive Multimodal Fusion for Hand Gesture Recognition","abstract":"Hand gesture recognition (HGR) based on multimodal data has attracted considerable attention owing to its great potential in applications. Various manually designed multimodal deep networks have performed well in multimodal HGR (MHGR), but most of existing algorithms require a lot of expert experience and time-consuming manual trials. To address these issues, we propose an evolutionary network architecture search framework with the adaptive multimodel fusion (AMF-ENAS). Specifically, we design an encoding space that simultaneously considers fusion positions and ratios of the multimodal data, allowing for the automatic construction of multimodal networks with different architectures through decoding. Additionally, we consider three input streams corresponding to intra-modal surface electromyography (sEMG), intra-modal accelerometer (ACC), and inter-modal sEMG-ACC. To automatically adapt to various datasets, the ENAS framework is designed to automatically search a MHGR network with appropriate fusion positions and ratios. To the best of our knowledge, this is the first time that ENAS has been utilized in MHGR to tackle issues related to the fusion position and ratio of multimodal data. Experimental results demonstrate that AMF-ENAS achieves state-of-the-art performance on the Ninapro DB2, DB3, and DB7 datasets.","sentences":["Hand gesture recognition (HGR) based on multimodal data has attracted considerable attention owing to its great potential in applications.","Various manually designed multimodal deep networks have performed well in multimodal HGR (MHGR), but most of existing algorithms require a lot of expert experience and time-consuming manual trials.","To address these issues, we propose an evolutionary network architecture search framework with the adaptive multimodel fusion (AMF-ENAS).","Specifically, we design an encoding space that simultaneously considers fusion positions and ratios of the multimodal data, allowing for the automatic construction of multimodal networks with different architectures through decoding.","Additionally, we consider three input streams corresponding to intra-modal surface electromyography (sEMG), intra-modal accelerometer (ACC), and inter-modal sEMG-ACC.","To automatically adapt to various datasets, the ENAS framework is designed to automatically search a MHGR network with appropriate fusion positions and ratios.","To the best of our knowledge, this is the first time that ENAS has been utilized in MHGR to tackle issues related to the fusion position and ratio of multimodal data.","Experimental results demonstrate that AMF-ENAS achieves state-of-the-art performance on the Ninapro DB2, DB3, and DB7 datasets."],"url":"http://arxiv.org/abs/2403.18208v1","category":"cs.CV"}
{"created":"2024-03-27 02:24:00","title":"Few-shot Online Anomaly Detection and Segmentation","abstract":"Detecting anomaly patterns from images is a crucial artificial intelligence technique in industrial applications. Recent research in this domain has emphasized the necessity of a large volume of training data, overlooking the practical scenario where, post-deployment of the model, unlabeled data containing both normal and abnormal samples can be utilized to enhance the model's performance. Consequently, this paper focuses on addressing the challenging yet practical few-shot online anomaly detection and segmentation (FOADS) task. Under the FOADS framework, models are trained on a few-shot normal dataset, followed by inspection and improvement of their capabilities by leveraging unlabeled streaming data containing both normal and abnormal samples simultaneously.   To tackle this issue, we propose modeling the feature distribution of normal images using a Neural Gas network, which offers the flexibility to adapt the topology structure to identify outliers in the data flow. In order to achieve improved performance with limited training samples, we employ multi-scale feature embedding extracted from a CNN pre-trained on ImageNet to obtain a robust representation. Furthermore, we introduce an algorithm that can incrementally update parameters without the need to store previous samples. Comprehensive experimental results demonstrate that our method can achieve substantial performance under the FOADS setting, while ensuring that the time complexity remains within an acceptable range on MVTec AD and BTAD datasets.","sentences":["Detecting anomaly patterns from images is a crucial artificial intelligence technique in industrial applications.","Recent research in this domain has emphasized the necessity of a large volume of training data, overlooking the practical scenario where, post-deployment of the model, unlabeled data containing both normal and abnormal samples can be utilized to enhance the model's performance.","Consequently, this paper focuses on addressing the challenging yet practical few-shot online anomaly detection and segmentation (FOADS) task.","Under the FOADS framework, models are trained on a few-shot normal dataset, followed by inspection and improvement of their capabilities by leveraging unlabeled streaming data containing both normal and abnormal samples simultaneously.   ","To tackle this issue, we propose modeling the feature distribution of normal images using a Neural Gas network, which offers the flexibility to adapt the topology structure to identify outliers in the data flow.","In order to achieve improved performance with limited training samples, we employ multi-scale feature embedding extracted from a CNN pre-trained on ImageNet to obtain a robust representation.","Furthermore, we introduce an algorithm that can incrementally update parameters without the need to store previous samples.","Comprehensive experimental results demonstrate that our method can achieve substantial performance under the FOADS setting, while ensuring that the time complexity remains within an acceptable range on MVTec AD and BTAD datasets."],"url":"http://arxiv.org/abs/2403.18201v1","category":"cs.CV"}
{"created":"2024-03-27 02:13:24","title":"LocoMan: Advancing Versatile Quadrupedal Dexterity with Lightweight Loco-Manipulators","abstract":"Quadrupedal robots have emerged as versatile agents capable of locomoting and manipulating in complex environments. Traditional designs typically rely on the robot's inherent body parts or incorporate top-mounted arms for manipulation tasks. However, these configurations may limit the robot's operational dexterity, efficiency and adaptability, particularly in cluttered or constrained spaces. In this work, we present LocoMan, a dexterous quadrupedal robot with a novel morphology to perform versatile manipulation in diverse constrained environments. By equipping a Unitree Go1 robot with two low-cost and lightweight modular 3-DoF loco-manipulators on its front calves, LocoMan leverages the combined mobility and functionality of the legs and grippers for complex manipulation tasks that require precise 6D positioning of the end effector in a wide workspace. To harness the loco-manipulation capabilities of LocoMan, we introduce a unified control framework that extends the whole-body controller (WBC) to integrate the dynamics of loco-manipulators. Through experiments, we validate that the proposed whole-body controller can accurately and stably follow desired 6D trajectories of the end effector and torso, which, when combined with the large workspace from our design, facilitates a diverse set of challenging dexterous loco-manipulation tasks in confined spaces, such as opening doors, plugging into sockets, picking objects in narrow and low-lying spaces, and bimanual manipulation.","sentences":["Quadrupedal robots have emerged as versatile agents capable of locomoting and manipulating in complex environments.","Traditional designs typically rely on the robot's inherent body parts or incorporate top-mounted arms for manipulation tasks.","However, these configurations may limit the robot's operational dexterity, efficiency and adaptability, particularly in cluttered or constrained spaces.","In this work, we present LocoMan, a dexterous quadrupedal robot with a novel morphology to perform versatile manipulation in diverse constrained environments.","By equipping a Unitree Go1 robot with two low-cost and lightweight modular 3-DoF loco-manipulators on its front calves, LocoMan leverages the combined mobility and functionality of the legs and grippers for complex manipulation tasks that require precise 6D positioning of the end effector in a wide workspace.","To harness the loco-manipulation capabilities of LocoMan, we introduce a unified control framework that extends the whole-body controller (WBC) to integrate the dynamics of loco-manipulators.","Through experiments, we validate that the proposed whole-body controller can accurately and stably follow desired 6D trajectories of the end effector and torso, which, when combined with the large workspace from our design, facilitates a diverse set of challenging dexterous loco-manipulation tasks in confined spaces, such as opening doors, plugging into sockets, picking objects in narrow and low-lying spaces, and bimanual manipulation."],"url":"http://arxiv.org/abs/2403.18197v1","category":"cs.RO"}
{"created":"2024-03-27 02:06:25","title":"Middle Fusion and Multi-Stage, Multi-Form Prompts for Robust RGB-T Tracking","abstract":"RGB-T tracking, a vital downstream task of object tracking, has made remarkable progress in recent years. Yet, it remains hindered by two major challenges: 1) the trade-off between performance and efficiency; 2) the scarcity of training data. To address the latter challenge, some recent methods employ prompts to fine-tune pre-trained RGB tracking models and leverage upstream knowledge in a parameter-efficient manner. However, these methods inadequately explore modality-independent patterns and disregard the dynamic reliability of different modalities in open scenarios. We propose M3PT, a novel RGB-T prompt tracking method that leverages middle fusion and multi-modal and multi-stage visual prompts to overcome these challenges. We pioneer the use of the middle fusion framework for RGB-T tracking, which achieves a balance between performance and efficiency. Furthermore, we incorporate the pre-trained RGB tracking model into the framework and utilize multiple flexible prompt strategies to adapt the pre-trained model to the comprehensive exploration of uni-modal patterns and the improved modeling of fusion-modal features, harnessing the potential of prompt learning in RGB-T tracking. Our method outperforms the state-of-the-art methods on four challenging benchmarks, while attaining 46.1 fps inference speed.","sentences":["RGB-T tracking, a vital downstream task of object tracking, has made remarkable progress in recent years.","Yet, it remains hindered by two major challenges: 1) the trade-off between performance and efficiency; 2) the scarcity of training data.","To address the latter challenge, some recent methods employ prompts to fine-tune pre-trained RGB tracking models and leverage upstream knowledge in a parameter-efficient manner.","However, these methods inadequately explore modality-independent patterns and disregard the dynamic reliability of different modalities in open scenarios.","We propose M3PT, a novel RGB-T prompt tracking method that leverages middle fusion and multi-modal and multi-stage visual prompts to overcome these challenges.","We pioneer the use of the middle fusion framework for RGB-T tracking, which achieves a balance between performance and efficiency.","Furthermore, we incorporate the pre-trained RGB tracking model into the framework and utilize multiple flexible prompt strategies to adapt the pre-trained model to the comprehensive exploration of uni-modal patterns and the improved modeling of fusion-modal features, harnessing the potential of prompt learning in RGB-T tracking.","Our method outperforms the state-of-the-art methods on four challenging benchmarks, while attaining 46.1 fps inference speed."],"url":"http://arxiv.org/abs/2403.18193v1","category":"cs.CV"}
{"created":"2024-03-27 02:00:18","title":"Multi-Label Adaptive Batch Selection by Highlighting Hard and Imbalanced Samples","abstract":"Deep neural network models have demonstrated their effectiveness in classifying multi-label data from various domains. Typically, they employ a training mode that combines mini-batches with optimizers, where each sample is randomly selected with equal probability when constructing mini-batches. However, the intrinsic class imbalance in multi-label data may bias the model towards majority labels, since samples relevant to minority labels may be underrepresented in each mini-batch. Meanwhile, during the training process, we observe that instances associated with minority labels tend to induce greater losses. Existing heuristic batch selection methods, such as priority selection of samples with high contribution to the objective function, i.e., samples with high loss, have been proven to accelerate convergence while reducing the loss and test error in single-label data. However, batch selection methods have not yet been applied and validated in multi-label data. In this study, we introduce a simple yet effective adaptive batch selection algorithm tailored to multi-label deep learning models. It adaptively selects each batch by prioritizing hard samples related to minority labels. A variant of our method also takes informative label correlations into consideration. Comprehensive experiments combining five multi-label deep learning models on thirteen benchmark datasets show that our method converges faster and performs better than random batch selection.","sentences":["Deep neural network models have demonstrated their effectiveness in classifying multi-label data from various domains.","Typically, they employ a training mode that combines mini-batches with optimizers, where each sample is randomly selected with equal probability when constructing mini-batches.","However, the intrinsic class imbalance in multi-label data may bias the model towards majority labels, since samples relevant to minority labels may be underrepresented in each mini-batch.","Meanwhile, during the training process, we observe that instances associated with minority labels tend to induce greater losses.","Existing heuristic batch selection methods, such as priority selection of samples with high contribution to the objective function, i.e., samples with high loss, have been proven to accelerate convergence while reducing the loss and test error in single-label data.","However, batch selection methods have not yet been applied and validated in multi-label data.","In this study, we introduce a simple yet effective adaptive batch selection algorithm tailored to multi-label deep learning models.","It adaptively selects each batch by prioritizing hard samples related to minority labels.","A variant of our method also takes informative label correlations into consideration.","Comprehensive experiments combining five multi-label deep learning models on thirteen benchmark datasets show that our method converges faster and performs better than random batch selection."],"url":"http://arxiv.org/abs/2403.18192v1","category":"cs.LG"}
{"created":"2024-03-27 01:44:39","title":"Integrating urban digital twins with cloud-based geospatial dashboards for coastal resilience planning: A case study in Florida","abstract":"Coastal communities are confronted with a growing incidence of climate-induced flooding, necessitating adaptation measures for resilience. In this paper, we introduce a framework that integrates an urban digital twin with a geospatial dashboard to allow visualization of the vulnerabilities within critical infrastructure across a range of spatial and temporal scales. The synergy between these two technologies fosters heightened community awareness about increased flood risks to establish a unified understanding, the foundation for collective decision-making in adaptation plans. The paper also elucidates ethical considerations while developing the platform, including ensuring accessibility, promoting transparency and equity, and safeguarding individual privacy.","sentences":["Coastal communities are confronted with a growing incidence of climate-induced flooding, necessitating adaptation measures for resilience.","In this paper, we introduce a framework that integrates an urban digital twin with a geospatial dashboard to allow visualization of the vulnerabilities within critical infrastructure across a range of spatial and temporal scales.","The synergy between these two technologies fosters heightened community awareness about increased flood risks to establish a unified understanding, the foundation for collective decision-making in adaptation plans.","The paper also elucidates ethical considerations while developing the platform, including ensuring accessibility, promoting transparency and equity, and safeguarding individual privacy."],"url":"http://arxiv.org/abs/2403.18188v1","category":"cs.CY"}
{"created":"2024-03-27 01:15:05","title":"Multi-Layer Dense Attention Decoder for Polyp Segmentation","abstract":"Detecting and segmenting polyps is crucial for expediting the diagnosis of colon cancer. This is a challenging task due to the large variations of polyps in color, texture, and lighting conditions, along with subtle differences between the polyp and its surrounding area. Recently, vision Transformers have shown robust abilities in modeling global context for polyp segmentation. However, they face two major limitations: the inability to learn local relations among multi-level layers and inadequate feature aggregation in the decoder. To address these issues, we propose a novel decoder architecture aimed at hierarchically aggregating locally enhanced multi-level dense features. Specifically, we introduce a novel module named Dense Attention Gate (DAG), which adaptively fuses all previous layers' features to establish local feature relations among all layers. Furthermore, we propose a novel nested decoder architecture that hierarchically aggregates decoder features, thereby enhancing semantic features. We incorporate our novel dense decoder with the PVT backbone network and conduct evaluations on five polyp segmentation datasets: Kvasir, CVC-300, CVC-ColonDB, CVC-ClinicDB, and ETIS. Our experiments and comparisons with nine competing segmentation models demonstrate that the proposed architecture achieves state-of-the-art performance and outperforms the previous models on four datasets. The source code is available at: https://github.com/krushi1992/Dense-Decoder.","sentences":["Detecting and segmenting polyps is crucial for expediting the diagnosis of colon cancer.","This is a challenging task due to the large variations of polyps in color, texture, and lighting conditions, along with subtle differences between the polyp and its surrounding area.","Recently, vision Transformers have shown robust abilities in modeling global context for polyp segmentation.","However, they face two major limitations: the inability to learn local relations among multi-level layers and inadequate feature aggregation in the decoder.","To address these issues, we propose a novel decoder architecture aimed at hierarchically aggregating locally enhanced multi-level dense features.","Specifically, we introduce a novel module named Dense Attention Gate (DAG), which adaptively fuses all previous layers' features to establish local feature relations among all layers.","Furthermore, we propose a novel nested decoder architecture that hierarchically aggregates decoder features, thereby enhancing semantic features.","We incorporate our novel dense decoder with the PVT backbone network and conduct evaluations on five polyp segmentation datasets: Kvasir, CVC-300, CVC-ColonDB, CVC-ClinicDB, and ETIS.","Our experiments and comparisons with nine competing segmentation models demonstrate that the proposed architecture achieves state-of-the-art performance and outperforms the previous models on four datasets.","The source code is available at: https://github.com/krushi1992/Dense-Decoder."],"url":"http://arxiv.org/abs/2403.18180v1","category":"cs.CV"}
{"created":"2024-03-27 01:02:27","title":"Local (coarse) correlated equilibria in non-concave games","abstract":"We investigate local notions of correlated equilibria, distributions of actions for smooth games such that players do not incur any regret against modifications of their strategies along a set of continuous vector fields. Our analysis shows that such equilibria are intrinsically linked to the projected gradient dynamics of the game. We identify the equivalent of coarse equilibria in this setting when no regret is incurred against any gradient field of a differentiable function. As a result, such equilibria are approximable when all players employ online (projected) gradient ascent with equal step-sizes as learning algorithms, and when their compact and convex action sets either (1) possess a smooth boundary, or (2) are polyhedra over which linear optimisation is ``trivial''. As a consequence, primal-dual proofs of performance guarantees for local coarse equilibria take the form of a generalised Lyapunov function for the gradient dynamics of the game. Adapting the regret matching framework to our setting, we also show that general local correlated equilibria are approximable when the set of vector fields is finite, given access to a fixed-point oracle for linear or conical combinations. For the class of affine-linear vector fields, which subsumes correlated equilibria of normal form games as a special case, such a fixed-point turns out to be the solution of a convex quadratic minimisation problem. Our results are independent of concavity assumptions on players' utilities.","sentences":["We investigate local notions of correlated equilibria, distributions of actions for smooth games such that players do not incur any regret against modifications of their strategies along a set of continuous vector fields.","Our analysis shows that such equilibria are intrinsically linked to the projected gradient dynamics of the game.","We identify the equivalent of coarse equilibria in this setting when no regret is incurred against any gradient field of a differentiable function.","As a result, such equilibria are approximable when all players employ online (projected) gradient ascent with equal step-sizes as learning algorithms, and when their compact and convex action sets either (1) possess a smooth boundary, or (2) are polyhedra over which linear optimisation is ``trivial''.","As a consequence, primal-dual proofs of performance guarantees for local coarse equilibria take the form of a generalised Lyapunov function for the gradient dynamics of the game.","Adapting the regret matching framework to our setting, we also show that general local correlated equilibria are approximable when the set of vector fields is finite, given access to a fixed-point oracle for linear or conical combinations.","For the class of affine-linear vector fields, which subsumes correlated equilibria of normal form games as a special case, such a fixed-point turns out to be the solution of a convex quadratic minimisation problem.","Our results are independent of concavity assumptions on players' utilities."],"url":"http://arxiv.org/abs/2403.18174v1","category":"cs.GT"}
{"created":"2024-03-26 23:12:12","title":"Adaptive TTD Configurations for Near-Field Communications: An Unsupervised Transformer Approach","abstract":"True-time delayers (TTDs) are popular analog devices for facilitating near-field wideband beamforming subject to the spatial-wideband effect. In this paper, an adaptive TTD configuration is proposed for short-range TTDs. Compared to the existing TTD configurations, the proposed one can effectively combat the spatial-widebandd effect for arbitrary user locations and array shapes with the aid of a switch network. A novel end-to-end deep neural network is proposed to optimize the hybrid beamforming with adaptive TTDs for maximizing spectral efficiency. 1) First, based on the U-Net architecture, a near-field channel learning module (NFC-LM) is proposed for adaptive beamformer design through extracting the latent channel response features of various users across different frequencies. In the NFC-LM, an improved cross attention (CA) is introduced to further optimize beamformer design by enhancing the latent feature connection between near-field channel and different beamformers. 2) Second, a switch multi-user transformer (S-MT) is proposed to adaptively control the connection between TTDs and phase shifters (PSs). In the S-MT, an improved multi-head attention, namely multi-user attention (MSA), is introduced to optimize the switch network through exploring the latent channel relations among various users. 3) Third, a multi feature cross attention (MCA) is introduced to simultaneously optimize the NFC-LM and S-MT by enhancing the latent feature correlation between beamformers and switch network. Numerical simulation results show that 1) the proposed adaptive TTD configuration effectively eliminates the spatial-wideband effect under uniform linear array (ULA) and uniform circular array (UCA) architectures, and 2) the proposed deep neural network can provide near optimal spectral efficiency, and solve the multi-user bemformer design and dynamical connection problem in real-time.","sentences":["True-time delayers (TTDs) are popular analog devices for facilitating near-field wideband beamforming subject to the spatial-wideband effect.","In this paper, an adaptive TTD configuration is proposed for short-range TTDs.","Compared to the existing TTD configurations, the proposed one can effectively combat the spatial-widebandd effect for arbitrary user locations and array shapes with the aid of a switch network.","A novel end-to-end deep neural network is proposed to optimize the hybrid beamforming with adaptive TTDs for maximizing spectral efficiency.","1) First, based on the U-Net architecture, a near-field channel learning module (NFC-LM) is proposed for adaptive beamformer design through extracting the latent channel response features of various users across different frequencies.","In the NFC-LM, an improved cross attention (CA) is introduced to further optimize beamformer design by enhancing the latent feature connection between near-field channel and different beamformers.","2) Second, a switch multi-user transformer (S-MT) is proposed to adaptively control the connection between TTDs and phase shifters (PSs).","In the S-MT, an improved multi-head attention, namely multi-user attention (MSA), is introduced to optimize the switch network through exploring the latent channel relations among various users.","3) Third, a multi feature cross attention (MCA) is introduced to simultaneously optimize the NFC-LM and S-MT by enhancing the latent feature correlation between beamformers and switch network.","Numerical simulation results show that 1) the proposed adaptive TTD configuration effectively eliminates the spatial-wideband effect under uniform linear array (ULA) and uniform circular array (UCA) architectures, and 2) the proposed deep neural network can provide near optimal spectral efficiency, and solve the multi-user bemformer design and dynamical connection problem in real-time."],"url":"http://arxiv.org/abs/2403.18146v1","category":"cs.IT"}
{"created":"2024-03-26 23:03:06","title":"HERTA: A High-Efficiency and Rigorous Training Algorithm for Unfolded Graph Neural Networks","abstract":"As a variant of Graph Neural Networks (GNNs), Unfolded GNNs offer enhanced interpretability and flexibility over traditional designs. Nevertheless, they still suffer from scalability challenges when it comes to the training cost. Although many methods have been proposed to address the scalability issues, they mostly focus on per-iteration efficiency, without worst-case convergence guarantees. Moreover, those methods typically add components to or modify the original model, thus possibly breaking the interpretability of Unfolded GNNs. In this paper, we propose HERTA: a High-Efficiency and Rigorous Training Algorithm for Unfolded GNNs that accelerates the whole training process, achieving a nearly-linear time worst-case training guarantee. Crucially, HERTA converges to the optimum of the original model, thus preserving the interpretability of Unfolded GNNs. Additionally, as a byproduct of HERTA, we propose a new spectral sparsification method applicable to normalized and regularized graph Laplacians that ensures tighter bounds for our algorithm than existing spectral sparsifiers do. Experiments on real-world datasets verify the superiority of HERTA as well as its adaptability to various loss functions and optimizers.","sentences":["As a variant of Graph Neural Networks (GNNs), Unfolded GNNs offer enhanced interpretability and flexibility over traditional designs.","Nevertheless, they still suffer from scalability challenges when it comes to the training cost.","Although many methods have been proposed to address the scalability issues, they mostly focus on per-iteration efficiency, without worst-case convergence guarantees.","Moreover, those methods typically add components to or modify the original model, thus possibly breaking the interpretability of Unfolded GNNs.","In this paper, we propose HERTA: a High-Efficiency and Rigorous Training Algorithm for Unfolded GNNs that accelerates the whole training process, achieving a nearly-linear time worst-case training guarantee.","Crucially, HERTA converges to the optimum of the original model, thus preserving the interpretability of Unfolded GNNs.","Additionally, as a byproduct of HERTA, we propose a new spectral sparsification method applicable to normalized and regularized graph Laplacians that ensures tighter bounds for our algorithm than existing spectral sparsifiers do.","Experiments on real-world datasets verify the superiority of HERTA as well as its adaptability to various loss functions and optimizers."],"url":"http://arxiv.org/abs/2403.18142v1","category":"cs.LG"}
{"created":"2024-03-26 22:41:41","title":"Securing GNNs: Explanation-Based Identification of Backdoored Training Graphs","abstract":"Graph Neural Networks (GNNs) have gained popularity in numerous domains, yet they are vulnerable to backdoor attacks that can compromise their performance and ethical application. The detection of these attacks is crucial for maintaining the reliability and security of GNN classification tasks, but effective detection techniques are lacking. Following an initial investigation, we observed that while graph-level explanations can offer limited insights, their effectiveness in detecting backdoor triggers is inconsistent and incomplete. To bridge this gap, we extract and transform secondary outputs of GNN explanation mechanisms, designing seven novel metrics that more effectively detect backdoor attacks. Additionally, we develop an adaptive attack to rigorously evaluate our approach. We test our method on multiple benchmark datasets and examine its efficacy against various attack models. Our results show that our method can achieve high detection performance, marking a significant advancement in safeguarding GNNs against backdoor attacks.","sentences":["Graph Neural Networks (GNNs) have gained popularity in numerous domains, yet they are vulnerable to backdoor attacks that can compromise their performance and ethical application.","The detection of these attacks is crucial for maintaining the reliability and security of GNN classification tasks, but effective detection techniques are lacking.","Following an initial investigation, we observed that while graph-level explanations can offer limited insights, their effectiveness in detecting backdoor triggers is inconsistent and incomplete.","To bridge this gap, we extract and transform secondary outputs of GNN explanation mechanisms, designing seven novel metrics that more effectively detect backdoor attacks.","Additionally, we develop an adaptive attack to rigorously evaluate our approach.","We test our method on multiple benchmark datasets and examine its efficacy against various attack models.","Our results show that our method can achieve high detection performance, marking a significant advancement in safeguarding GNNs against backdoor attacks."],"url":"http://arxiv.org/abs/2403.18136v1","category":"cs.LG"}
{"created":"2024-03-26 22:01:14","title":"Adaptive Loss Weighting for Machine Learning Interatomic Potentials","abstract":"Training machine learning interatomic potentials often requires optimizing a loss function composed of three variables: potential energies, forces, and stress. The contribution of each variable to the total loss is typically weighted using fixed coefficients. Identifying these coefficients usually relies on iterative or heuristic methods, which may yield sub-optimal   results. To address this issue, we propose an adaptive loss weighting algorithm that automatically adjusts the loss weights of these variables during the training of potentials, dynamically adapting to the characteristics of the training dataset. The comparative analysis of models trained with fixed and adaptive loss weights demonstrates that the adaptive method not only achieves a more balanced predictions across the three variables but also improves overall prediction accuracy.","sentences":["Training machine learning interatomic potentials often requires optimizing a loss function composed of three variables: potential energies, forces, and stress.","The contribution of each variable to the total loss is typically weighted using fixed coefficients.","Identifying these coefficients usually relies on iterative or heuristic methods, which may yield sub-optimal   results.","To address this issue, we propose an adaptive loss weighting algorithm that automatically adjusts the loss weights of these variables during the training of potentials, dynamically adapting to the characteristics of the training dataset.","The comparative analysis of models trained with fixed and adaptive loss weights demonstrates that the adaptive method not only achieves a more balanced predictions across the three variables but also improves overall prediction accuracy."],"url":"http://arxiv.org/abs/2403.18122v1","category":"physics.comp-ph"}
{"created":"2024-03-26 21:50:09","title":"Multiple Model Reference Adaptive Control with Blending for Non-Square Multivariable Systems","abstract":"In this paper we develop a multiple model reference adaptive controller (MMRAC) with blending. The systems under consideration are non-square, i.e., the number of inputs is not equal to the number of states; multi-input, linear, time-invariant with uncertain parameters that lie inside of a known, compact, and convex set. Moreover, the full state of the plant is available for feedback. A multiple model online identification scheme for the plant's state and input matrices is developed that guarantees the estimated parameters converge to the underlying plant model under the assumption of persistence of excitation. Using an exact matching condition, the parameter estimates are used in a control law such that the plant's states asymptotically track the reference signal generated by a state-space model reference. The control architecture is proven to provide boundedness of all closed-loop signals and to asymptotically drive the state tracking error to zero. Numerical simulations illustrate the stability and efficacy of the proposed MMRAC scheme.","sentences":["In this paper we develop a multiple model reference adaptive controller (MMRAC) with blending.","The systems under consideration are non-square, i.e., the number of inputs is not equal to the number of states; multi-input, linear, time-invariant with uncertain parameters that lie inside of a known, compact, and convex set.","Moreover, the full state of the plant is available for feedback.","A multiple model online identification scheme for the plant's state and input matrices is developed that guarantees the estimated parameters converge to the underlying plant model under the assumption of persistence of excitation.","Using an exact matching condition, the parameter estimates are used in a control law such that the plant's states asymptotically track the reference signal generated by a state-space model reference.","The control architecture is proven to provide boundedness of all closed-loop signals and to asymptotically drive the state tracking error to zero.","Numerical simulations illustrate the stability and efficacy of the proposed MMRAC scheme."],"url":"http://arxiv.org/abs/2403.18119v1","category":"eess.SY"}
{"created":"2024-03-26 21:04:29","title":"Large Language Models for Education: A Survey and Outlook","abstract":"The advent of Large Language Models (LLMs) has brought in a new era of possibilities in the realm of education. This survey paper summarizes the various technologies of LLMs in educational settings from multifaceted perspectives, encompassing student and teacher assistance, adaptive learning, and commercial tools. We systematically review the technological advancements in each perspective, organize related datasets and benchmarks, and identify the risks and challenges associated with deploying LLMs in education. Furthermore, we outline future research opportunities, highlighting the potential promising directions. Our survey aims to provide a comprehensive technological picture for educators, researchers, and policymakers to harness the power of LLMs to revolutionize educational practices and foster a more effective personalized learning environment.","sentences":["The advent of Large Language Models (LLMs) has brought in a new era of possibilities in the realm of education.","This survey paper summarizes the various technologies of LLMs in educational settings from multifaceted perspectives, encompassing student and teacher assistance, adaptive learning, and commercial tools.","We systematically review the technological advancements in each perspective, organize related datasets and benchmarks, and identify the risks and challenges associated with deploying LLMs in education.","Furthermore, we outline future research opportunities, highlighting the potential promising directions.","Our survey aims to provide a comprehensive technological picture for educators, researchers, and policymakers to harness the power of LLMs to revolutionize educational practices and foster a more effective personalized learning environment."],"url":"http://arxiv.org/abs/2403.18105v1","category":"cs.CL"}
{"created":"2024-03-26 20:20:19","title":"Diffuse radio emission from merger shocks in simulated galaxy clusters","abstract":"Galaxy clusters are the largest gravitationally-bound structures in the Universe. As such, during merger events with similar systems, they release an enormous amount of energy that is dissipated through the formation of shock waves and turbulence in the intracluster medium (ICM), the hot ionised plasma permeating the cluster volume. These shock waves are believed to be ideal sites for electron acceleration that, in the presence of ubiquitous magnetic fields in the ICM, are capable of producing elongated non-thermal radio features typically observed in the outskirts of dynamically disturbed clusters, also known as radio relics. In this work, we analyse a hydrodynamical re-simulation of merging galaxy clusters, extracted from a large set of zoom-in cosmological simulations of The Three Hundred Project, to study the evolution and diversity of merger shocks and their associated diffuse radio emission within the framework of the diffusive shock acceleration scenario.","sentences":["Galaxy clusters are the largest gravitationally-bound structures in the Universe.","As such, during merger events with similar systems, they release an enormous amount of energy that is dissipated through the formation of shock waves and turbulence in the intracluster medium (ICM), the hot ionised plasma permeating the cluster volume.","These shock waves are believed to be ideal sites for electron acceleration that, in the presence of ubiquitous magnetic fields in the ICM, are capable of producing elongated non-thermal radio features typically observed in the outskirts of dynamically disturbed clusters, also known as radio relics.","In this work, we analyse a hydrodynamical re-simulation of merging galaxy clusters, extracted from a large set of zoom-in cosmological simulations of The Three Hundred Project, to study the evolution and diversity of merger shocks and their associated diffuse radio emission within the framework of the diffusive shock acceleration scenario."],"url":"http://arxiv.org/abs/2403.18089v1","category":"astro-ph.CO"}
{"created":"2024-03-26 19:24:40","title":"Online Submodular Welfare Maximization Meets Post-Allocation Stochasticity and Reusability","abstract":"We generalize the problem of online submodular welfare maximization to incorporate a variety of new elements arising from reusability, stochastic rewards, combinatorial actions and similar features that have received significant attention in recent years. For our general formulation, we show that a non-adaptive Greedy algorithm achieves the highest possible competitive ratio against an adaptive offline benchmark in the adversarial arrival model and in the unknown IID stochastic arrival model. In addition to generalizing several previous results, this shows that, in general, adaptivity to stochastic rewards (and similar features) offers no theoretical (worst-case) benefits.","sentences":["We generalize the problem of online submodular welfare maximization to incorporate a variety of new elements arising from reusability, stochastic rewards, combinatorial actions and similar features that have received significant attention in recent years.","For our general formulation, we show that a non-adaptive Greedy algorithm achieves the highest possible competitive ratio against an adaptive offline benchmark in the adversarial arrival model and in the unknown IID stochastic arrival model.","In addition to generalizing several previous results, this shows that, in general, adaptivity to stochastic rewards (and similar features) offers no theoretical (worst-case) benefits."],"url":"http://arxiv.org/abs/2403.18059v1","category":"cs.DS"}
{"created":"2024-03-26 19:17:03","title":"Adaptive Boundary Control of the Kuramoto-Sivashinsky Equation Under Intermittent Sensing","abstract":"We study in this paper boundary stabilization, in the L2 sense, of the one-dimensional Kuramoto-Sivashinsky equation subject to intermittent sensing. We assume that we measure the state of this spatio-temporal equation on a given spatial subdomain during certain intervals of time, while we measure the state on the remaining spatial subdomain during the remaining intervals of time. As a result, we assign a feedback law at the boundary of the spatial domain and force to zero the value of the state at the junction of the two subdomains. Throughout the study, the destabilizing coefficient is assumed to be space-dependent and bounded but unknown. Adaptive boundary controllers are designed under different assumptions on the forcing term. In particular, when the forcing term is null, we guarantee global exponential stability of the origin. Furthermore, when the forcing term is bounded and admits a known upper bound, we guarantee input-to-state stability, and only global uniform ultimate boundedness is guaranteed when the upper bound is unknown. Numerical simulations are performed to illustrate our results","sentences":["We study in this paper boundary stabilization, in the L2 sense, of the one-dimensional Kuramoto-Sivashinsky equation subject to intermittent sensing.","We assume that we measure the state of this spatio-temporal equation on a given spatial subdomain during certain intervals of time, while we measure the state on the remaining spatial subdomain during the remaining intervals of time.","As a result, we assign a feedback law at the boundary of the spatial domain and force to zero the value of the state at the junction of the two subdomains.","Throughout the study, the destabilizing coefficient is assumed to be space-dependent and bounded but unknown.","Adaptive boundary controllers are designed under different assumptions on the forcing term.","In particular, when the forcing term is null, we guarantee global exponential stability of the origin.","Furthermore, when the forcing term is bounded and admits a known upper bound, we guarantee input-to-state stability, and only global uniform ultimate boundedness is guaranteed when the upper bound is unknown.","Numerical simulations are performed to illustrate our results"],"url":"http://arxiv.org/abs/2403.18055v1","category":"eess.SY"}
{"created":"2024-03-26 18:52:50","title":"Learning Piecewise Residuals of Control Barrier Functions for Safety of Switching Systems using Multi-Output Gaussian Processes","abstract":"Control barrier functions (CBFs) have recently been introduced as a systematic tool to ensure safety by establishing set invariance. When combined with a control Lyapunov function (CLF), they form a safety-critical control mechanism. However, the effectiveness of CBFs and CLFs is closely tied to the system model. In practice, model uncertainty can jeopardize safety and stability guarantees and may lead to undesirable performance. In this paper, we develop a safe learning-based control strategy for switching systems in the face of uncertainty. We focus on the case that a nominal model is available for a true underlying switching system. This uncertainty results in piecewise residuals for each switching surface, impacting the CLF and CBF constraints. We introduce a batch multi-output Gaussian process (MOGP) framework to approximate these piecewise residuals, thereby mitigating the adverse effects of uncertainty. A particular structure of the covariance function enables us to convert the MOGP-based chance constraints CLF and CBF into second-order cone constraints, which leads to a convex optimization. We analyze the feasibility of the resulting optimization and provide the necessary and sufficient conditions for feasibility. The effectiveness of the proposed strategy is validated through a simulation of a switching adaptive cruise control system.","sentences":["Control barrier functions (CBFs) have recently been introduced as a systematic tool to ensure safety by establishing set invariance.","When combined with a control Lyapunov function (CLF), they form a safety-critical control mechanism.","However, the effectiveness of CBFs and CLFs is closely tied to the system model.","In practice, model uncertainty can jeopardize safety and stability guarantees and may lead to undesirable performance.","In this paper, we develop a safe learning-based control strategy for switching systems in the face of uncertainty.","We focus on the case that a nominal model is available for a true underlying switching system.","This uncertainty results in piecewise residuals for each switching surface, impacting the CLF and CBF constraints.","We introduce a batch multi-output Gaussian process (MOGP) framework to approximate these piecewise residuals, thereby mitigating the adverse effects of uncertainty.","A particular structure of the covariance function enables us to convert the MOGP-based chance constraints CLF and CBF into second-order cone constraints, which leads to a convex optimization.","We analyze the feasibility of the resulting optimization and provide the necessary and sufficient conditions for feasibility.","The effectiveness of the proposed strategy is validated through a simulation of a switching adaptive cruise control system."],"url":"http://arxiv.org/abs/2403.18041v1","category":"eess.SY"}
{"created":"2024-03-26 18:23:16","title":"Improving Pre-trained Language Model Sensitivity via Mask Specific losses: A case study on Biomedical NER","abstract":"Adapting language models (LMs) to novel domains is often achieved through fine-tuning a pre-trained LM (PLM) on domain-specific data. Fine-tuning introduces new knowledge into an LM, enabling it to comprehend and efficiently perform a target domain task. Fine-tuning can however be inadvertently insensitive if it ignores the wide array of disparities (e.g in word meaning) between source and target domains. For instance, words such as chronic and pressure may be treated lightly in social conversations, however, clinically, these words are usually an expression of concern. To address insensitive fine-tuning, we propose Mask Specific Language Modeling (MSLM), an approach that efficiently acquires target domain knowledge by appropriately weighting the importance of domain-specific terms (DS-terms) during fine-tuning. MSLM jointly masks DS-terms and generic words, then learns mask-specific losses by ensuring LMs incur larger penalties for inaccurately predicting DS-terms compared to generic words. Results of our analysis show that MSLM improves LMs sensitivity and detection of DS-terms. We empirically show that an optimal masking rate not only depends on the LM, but also on the dataset and the length of sequences. Our proposed masking strategy outperforms advanced masking strategies such as span- and PMI-based masking.","sentences":["Adapting language models (LMs) to novel domains is often achieved through fine-tuning a pre-trained LM (PLM) on domain-specific data.","Fine-tuning introduces new knowledge into an LM, enabling it to comprehend and efficiently perform a target domain task.","Fine-tuning can however be inadvertently insensitive if it ignores the wide array of disparities (e.g in word meaning) between source and target domains.","For instance, words such as chronic and pressure may be treated lightly in social conversations, however, clinically, these words are usually an expression of concern.","To address insensitive fine-tuning, we propose Mask Specific Language Modeling (MSLM), an approach that efficiently acquires target domain knowledge by appropriately weighting the importance of domain-specific terms (DS-terms) during fine-tuning.","MSLM jointly masks DS-terms and generic words, then learns mask-specific losses by ensuring LMs incur larger penalties for inaccurately predicting DS-terms compared to generic words.","Results of our analysis show that MSLM improves LMs sensitivity and detection of DS-terms.","We empirically show that an optimal masking rate not only depends on the LM, but also on the dataset and the length of sequences.","Our proposed masking strategy outperforms advanced masking strategies such as span- and PMI-based masking."],"url":"http://arxiv.org/abs/2403.18025v2","category":"cs.CL"}
{"created":"2024-03-26 17:59:52","title":"Text Is MASS: Modeling as Stochastic Embedding for Text-Video Retrieval","abstract":"The increasing prevalence of video clips has sparked growing interest in text-video retrieval. Recent advances focus on establishing a joint embedding space for text and video, relying on consistent embedding representations to compute similarity. However, the text content in existing datasets is generally short and concise, making it hard to fully describe the redundant semantics of a video. Correspondingly, a single text embedding may be less expressive to capture the video embedding and empower the retrieval. In this study, we propose a new stochastic text modeling method T-MASS, i.e., text is modeled as a stochastic embedding, to enrich text embedding with a flexible and resilient semantic range, yielding a text mass. To be specific, we introduce a similarity-aware radius module to adapt the scale of the text mass upon the given text-video pairs. Plus, we design and develop a support text regularization to further control the text mass during the training. The inference pipeline is also tailored to fully exploit the text mass for accurate retrieval. Empirical evidence suggests that T-MASS not only effectively attracts relevant text-video pairs while distancing irrelevant ones, but also enables the determination of precise text embeddings for relevant pairs. Our experimental results show a substantial improvement of T-MASS over baseline (3% to 6.3% by R@1). Also, T-MASS achieves state-of-the-art performance on five benchmark datasets, including MSRVTT, LSMDC, DiDeMo, VATEX, and Charades.","sentences":["The increasing prevalence of video clips has sparked growing interest in text-video retrieval.","Recent advances focus on establishing a joint embedding space for text and video, relying on consistent embedding representations to compute similarity.","However, the text content in existing datasets is generally short and concise, making it hard to fully describe the redundant semantics of a video.","Correspondingly, a single text embedding may be less expressive to capture the video embedding and empower the retrieval.","In this study, we propose a new stochastic text modeling method T-MASS, i.e., text is modeled as a stochastic embedding, to enrich text embedding with a flexible and resilient semantic range, yielding a text mass.","To be specific, we introduce a similarity-aware radius module to adapt the scale of the text mass upon the given text-video pairs.","Plus, we design and develop a support text regularization to further control the text mass during the training.","The inference pipeline is also tailored to fully exploit the text mass for accurate retrieval.","Empirical evidence suggests that T-MASS not only effectively attracts relevant text-video pairs while distancing irrelevant ones, but also enables the determination of precise text embeddings for relevant pairs.","Our experimental results show a substantial improvement of T-MASS over baseline (3% to 6.3% by R@1).","Also, T-MASS achieves state-of-the-art performance on five benchmark datasets, including MSRVTT, LSMDC, DiDeMo, VATEX, and Charades."],"url":"http://arxiv.org/abs/2403.17998v1","category":"cs.CV"}
{"created":"2024-03-27 17:32:22","title":"Measuring the Lense-Thirring precession and the neutron star moment of inertia with pulsars","abstract":"Neutron stars (NSs) are compact objects that host the densest forms of matter in the observable universe, providing unique opportunities to study the behaviour of matter at extreme densities. While precision measurements of NS masses through pulsar timing have imposed effective constraints on the equation of state (EoS) of dense matter, accurately determining the radius or moment of inertia (MoI) of a NS remains a major challenge. This article presents a detailed review on measuring the Lense-Thirring (LT) precession effect in the orbit of binary pulsars, which would give access to the MoI of NSs and offer further constraints on the EoS. We discuss the suitability of certain classes of binary pulsars for measuring the LT precession from the perspective of binary star evolution, and highlight five pulsars that exhibit properties promising to realise these goals in the near future. Finally, discoveries of compact binaries with shorter orbital periods hold the potential to greatly enhance measurements of the MoI of NSs. The MoI measurements of binary pulsars are pivotal to advancing our understanding of matter at supranuclear densities as well as improving the precision of gravity tests, such as the orbital decay due to gravitational wave emission and of tests of alternative gravity theories.","sentences":["Neutron stars (NSs) are compact objects that host the densest forms of matter in the observable universe, providing unique opportunities to study the behaviour of matter at extreme densities.","While precision measurements of NS masses through pulsar timing have imposed effective constraints on the equation of state (EoS) of dense matter, accurately determining the radius or moment of inertia (MoI) of a NS remains a major challenge.","This article presents a detailed review on measuring the Lense-Thirring (LT) precession effect in the orbit of binary pulsars, which would give access to the MoI of NSs and offer further constraints on the EoS. We discuss the suitability of certain classes of binary pulsars for measuring the LT precession from the perspective of binary star evolution, and highlight five pulsars that exhibit properties promising to realise these goals in the near future.","Finally, discoveries of compact binaries with shorter orbital periods hold the potential to greatly enhance measurements of the MoI of NSs.","The MoI measurements of binary pulsars are pivotal to advancing our understanding of matter at supranuclear densities as well as improving the precision of gravity tests, such as the orbital decay due to gravitational wave emission and of tests of alternative gravity theories."],"url":"http://arxiv.org/abs/2403.18785v1","category":"gr-qc"}
{"created":"2024-03-27 17:21:46","title":"Non-local quantum field theory from doubly special relativity","abstract":"Non-local quantum field theories could be a solution to the inconsistencies arising when quantizing gravity. Doubly special relativity is regarded as a low-energy limit of a quantum gravity theory with testable predictions. We present a new formulation of quantum field theories in doubly special relativity with non-local behavior. Our construction restricts the models to those showing linear Lorentz invariance. The deformed Klein--Gordon, Dirac, and electromagnetic Lagrangians are derived. The deformed Maxwell equations and the electric potential of a point charge are discussed.","sentences":["Non-local quantum field theories could be a solution to the inconsistencies arising when quantizing gravity.","Doubly special relativity is regarded as a low-energy limit of a quantum gravity theory with testable predictions.","We present a new formulation of quantum field theories in doubly special relativity with non-local behavior.","Our construction restricts the models to those showing linear Lorentz invariance.","The deformed Klein--Gordon, Dirac, and electromagnetic Lagrangians are derived.","The deformed Maxwell equations and the electric potential of a point charge are discussed."],"url":"http://arxiv.org/abs/2403.18772v1","category":"hep-th"}
{"created":"2024-03-27 17:18:17","title":"Rogue curves in the Davey-Stewartson I equation","abstract":"We report new rogue wave patterns whose wave crests form closed or open curves in the spatial plane, which we call rogue curves, in the Davey-Stewartson I equation. These rogue curves come in various striking shapes, such as rings, double rings, and many others. They emerge from a uniform background (possibly with a few lumps on it), reach high amplitude in such striking shapes, and then disappear into the same background again. We reveal that these rogue curves would arise when an internal parameter in bilinear expressions of the rogue waves is real and large. Analytically, we show that these rogue curves are predicted by root curves of certain types of double-real-variable polynomials. We compare analytical predictions of rogue curves to true solutions and demonstrate good agreement between them.","sentences":["We report new rogue wave patterns whose wave crests form closed or open curves in the spatial plane, which we call rogue curves, in the Davey-Stewartson","I equation.","These rogue curves come in various striking shapes, such as rings, double rings, and many others.","They emerge from a uniform background (possibly with a few lumps on it), reach high amplitude in such striking shapes, and then disappear into the same background again.","We reveal that these rogue curves would arise when an internal parameter in bilinear expressions of the rogue waves is real and large.","Analytically, we show that these rogue curves are predicted by root curves of certain types of double-real-variable polynomials.","We compare analytical predictions of rogue curves to true solutions and demonstrate good agreement between them."],"url":"http://arxiv.org/abs/2403.18770v1","category":"nlin.SI"}
{"created":"2024-03-27 17:13:38","title":"Improved Neural Protoform Reconstruction via Reflex Prediction","abstract":"Protolanguage reconstruction is central to historical linguistics. The comparative method, one of the most influential theoretical and methodological frameworks in the history of the language sciences, allows linguists to infer protoforms (reconstructed ancestral words) from their reflexes (related modern words) based on the assumption of regular sound change. Not surprisingly, numerous computational linguists have attempted to operationalize comparative reconstruction through various computational models, the most successful of which have been supervised encoder-decoder models, which treat the problem of predicting protoforms given sets of reflexes as a sequence-to-sequence problem. We argue that this framework ignores one of the most important aspects of the comparative method: not only should protoforms be inferable from cognate sets (sets of related reflexes) but the reflexes should also be inferable from the protoforms. Leveraging another line of research -- reflex prediction -- we propose a system in which candidate protoforms from a reconstruction model are reranked by a reflex prediction model. We show that this more complete implementation of the comparative method allows us to surpass state-of-the-art protoform reconstruction methods on three of four Chinese and Romance datasets.","sentences":["Protolanguage reconstruction is central to historical linguistics.","The comparative method, one of the most influential theoretical and methodological frameworks in the history of the language sciences, allows linguists to infer protoforms (reconstructed ancestral words) from their reflexes (related modern words) based on the assumption of regular sound change.","Not surprisingly, numerous computational linguists have attempted to operationalize comparative reconstruction through various computational models, the most successful of which have been supervised encoder-decoder models, which treat the problem of predicting protoforms given sets of reflexes as a sequence-to-sequence problem.","We argue that this framework ignores one of the most important aspects of the comparative method: not only should protoforms be inferable from cognate sets (sets of related reflexes) but the reflexes should also be inferable from the protoforms.","Leveraging another line of research -- reflex prediction -- we propose a system in which candidate protoforms from a reconstruction model are reranked by a reflex prediction model.","We show that this more complete implementation of the comparative method allows us to surpass state-of-the-art protoform reconstruction methods on three of four Chinese and Romance datasets."],"url":"http://arxiv.org/abs/2403.18769v1","category":"cs.CL"}
{"created":"2024-03-27 16:57:40","title":"The Fubini--Study metric on an `odd' Grassmannian is rigid","abstract":"Following the ideas of Gasqui and Goldschmidt, we give an explicit description of the infinitesimal Einstein deformations admitted by the Fubini--Study metric on complex Grassmannians $G_{m}(\\mathbb{C}^{n+m})$ with $m,n\\geq 2$. The deformations were first shown to exist by Koiso in the 1980s but it has remained an open question as to whether they can be integrated to give genuine deformations of the Fubini--Study metric. We show that when $n+m$ is odd, the answer is no.","sentences":["Following the ideas of Gasqui and Goldschmidt, we give an explicit description of the infinitesimal Einstein deformations admitted by the Fubini--Study metric on complex Grassmannians $G_{m}(\\mathbb{C}^{n+m})$ with $m,n\\geq 2$.","The deformations were first shown to exist by Koiso in the 1980s but it has remained an open question as to whether they can be integrated to give genuine deformations of the Fubini--Study metric.","We show that when $n+m$ is odd, the answer is no."],"url":"http://arxiv.org/abs/2403.18757v1","category":"math.DG"}
{"created":"2024-03-27 16:52:53","title":"Neutron Stars Mass-Radius relations analysis in the Quintessence scenario","abstract":"In this paper, we explore the effects of General Relativity modification on the Mass-Radius relations of Neutron Stars induced by the presence of the Quintessence field. We consider, in particular, the Kiselev model, according to which the Quintessence field, being present in the entire Universe, might also be present around massive objects. Considering the Equation of State (EoS) for Baryonic matter BSk22 derived by A. Y. Potekhin et al., we infer the upper limit for NS masses in the presence of Quintessence. The presence of Quintessence generates a peculiar effect for which the Mass-Radius relation is unvaried and therefore the presence of Quintessence is indistinguishable from ordinary matter, at least for the Kiselev model studied in this paper.","sentences":["In this paper, we explore the effects of General Relativity modification on the Mass-Radius relations of Neutron Stars induced by the presence of the Quintessence field.","We consider, in particular, the Kiselev model, according to which the Quintessence field, being present in the entire Universe, might also be present around massive objects.","Considering the Equation of State (EoS) for Baryonic matter BSk22 derived by A. Y. Potekhin et al., we infer the upper limit for NS masses in the presence of Quintessence.","The presence of Quintessence generates a peculiar effect for which the Mass-Radius relation is unvaried and therefore the presence of Quintessence is indistinguishable from ordinary matter, at least for the Kiselev model studied in this paper."],"url":"http://arxiv.org/abs/2403.18752v1","category":"gr-qc"}
{"created":"2024-03-27 16:49:37","title":"Robust Numerical Algebraic Geometry","abstract":"The field of numerical algebraic geometry consists of algorithms for numerically solving systems of polynomial equations. When the system is exact, such as having rational coefficients, the solution set is well-defined. However, for a member of a parameterized family of polynomial systems where the parameter values may be measured with imprecision or arise from prior numerical computations, uncertainty may arise in the structure of the solution set, including the number of isolated solutions, the existence of higher dimensional solution components, and the number of irreducible components along with their multiplicities. The loci where these structures change form a stratification of exceptional algebraic sets in the space of parameters. We describe methodologies for making the interpretation of numerical results more robust by searching for nearby parameter values on an exceptional set. We demonstrate these techniques on several illustrative examples and then treat several more substantial problems arising from the kinematics of mechanisms and robots.","sentences":["The field of numerical algebraic geometry consists of algorithms for numerically solving systems of polynomial equations.","When the system is exact, such as having rational coefficients, the solution set is well-defined.","However, for a member of a parameterized family of polynomial systems where the parameter values may be measured with imprecision or arise from prior numerical computations, uncertainty may arise in the structure of the solution set, including the number of isolated solutions, the existence of higher dimensional solution components, and the number of irreducible components along with their multiplicities.","The loci where these structures change form a stratification of exceptional algebraic sets in the space of parameters.","We describe methodologies for making the interpretation of numerical results more robust by searching for nearby parameter values on an exceptional set.","We demonstrate these techniques on several illustrative examples and then treat several more substantial problems arising from the kinematics of mechanisms and robots."],"url":"http://arxiv.org/abs/2403.18749v1","category":"math.NA"}
{"created":"2024-03-27 16:32:32","title":"Usage-Specific Survival Modeling Based on Operational Data and Neural Networks","abstract":"Accurate predictions of when a component will fail are crucial when planning maintenance, and by modeling the distribution of these failure times, survival models have shown to be particularly useful in this context. The presented methodology is based on conventional neural network-based survival models that are trained using data that is continuously gathered and stored at specific times, called snapshots. An important property of this type of training data is that it can contain more than one snapshot from a specific individual which results in that standard maximum likelihood training can not be directly applied since the data is not independent. However, the papers show that if the data is in a specific format where all snapshot times are the same for all individuals, called homogeneously sampled, maximum likelihood training can be applied and produce desirable results. In many cases, the data is not homogeneously sampled and in this case, it is proposed to resample the data to make it homogeneously sampled. How densely the dataset is sampled turns out to be an important parameter; it should be chosen large enough to produce good results, but this also increases the size of the dataset which makes training slow. To reduce the number of samples needed during training, the paper also proposes a technique to, instead of resampling the dataset once before the training starts, randomly resample the dataset at the start of each epoch during the training. The proposed methodology is evaluated on both a simulated dataset and an experimental dataset of starter battery failures. The results show that if the data is homogeneously sampled the methodology works as intended and produces accurate survival models. The results also show that randomly resampling the dataset on each epoch is an effective way to reduce the size of the training data.","sentences":["Accurate predictions of when a component will fail are crucial when planning maintenance, and by modeling the distribution of these failure times, survival models have shown to be particularly useful in this context.","The presented methodology is based on conventional neural network-based survival models that are trained using data that is continuously gathered and stored at specific times, called snapshots.","An important property of this type of training data is that it can contain more than one snapshot from a specific individual which results in that standard maximum likelihood training can not be directly applied since the data is not independent.","However, the papers show that if the data is in a specific format where all snapshot times are the same for all individuals, called homogeneously sampled, maximum likelihood training can be applied and produce desirable results.","In many cases, the data is not homogeneously sampled and in this case, it is proposed to resample the data to make it homogeneously sampled.","How densely the dataset is sampled turns out to be an important parameter; it should be chosen large enough to produce good results, but this also increases the size of the dataset which makes training slow.","To reduce the number of samples needed during training, the paper also proposes a technique to, instead of resampling the dataset once before the training starts, randomly resample the dataset at the start of each epoch during the training.","The proposed methodology is evaluated on both a simulated dataset and an experimental dataset of starter battery failures.","The results show that if the data is homogeneously sampled the methodology works as intended and produces accurate survival models.","The results also show that randomly resampling the dataset on each epoch is an effective way to reduce the size of the training data."],"url":"http://arxiv.org/abs/2403.18739v1","category":"cs.LG"}
{"created":"2024-03-27 16:24:26","title":"Nonlinear model reduction for operator learning","abstract":"Operator learning provides methods to approximate mappings between infinite-dimensional function spaces. Deep operator networks (DeepONets) are a notable architecture in this field. Recently, an extension of DeepONet based on model reduction and neural networks, proper orthogonal decomposition (POD)-DeepONet, has been able to outperform other architectures in terms of accuracy for several benchmark tests. We extend this idea towards nonlinear model order reduction by proposing an efficient framework that combines neural networks with kernel principal component analysis (KPCA) for operator learning. Our results demonstrate the superior performance of KPCA-DeepONet over POD-DeepONet.","sentences":["Operator learning provides methods to approximate mappings between infinite-dimensional function spaces.","Deep operator networks (DeepONets) are a notable architecture in this field.","Recently, an extension of DeepONet based on model reduction and neural networks, proper orthogonal decomposition (POD)-DeepONet, has been able to outperform other architectures in terms of accuracy for several benchmark tests.","We extend this idea towards nonlinear model order reduction by proposing an efficient framework that combines neural networks with kernel principal component analysis (KPCA) for operator learning.","Our results demonstrate the superior performance of KPCA-DeepONet over POD-DeepONet."],"url":"http://arxiv.org/abs/2403.18735v1","category":"cs.LG"}
{"created":"2024-03-27 16:22:27","title":"Identifying CP Basis Invariants in SMEFT","abstract":"Building on our automated framework that uses ring diagrams for classifying CP basis invariants [1], this paper broadens the application of the methodology with more extensive examples and a wider scope of theoretical frameworks. Here, we showcase its versatility through detailed analyses in the Standard Model Effective Field Theory (SMEFT) up to dim-2n, and SMEFT with sterile neutrinos ({\\nu}SMEFT) up to dimension-7. By integrating the ring-diagram technique with the Cayley-Hamilton theorem, we have developed a system that not only simplifies the process of identifying basic and joint invariants but also enables the automatic differentiation between CP-even and CP-odd invariants from the lowest orders. Additionally, this work presents a comparison of our results with those derived using the traditional Hilbert-Poincar\\'e series and its Plethystic logarithm. While these conventional approaches primarily yield the numerical count of invariants, our framework provides a complete structure of invariants, thereby surpassing the limitations of these traditional methods.","sentences":["Building on our automated framework that uses ring diagrams for classifying CP basis invariants [1], this paper broadens the application of the methodology with more extensive examples and a wider scope of theoretical frameworks.","Here, we showcase its versatility through detailed analyses in the Standard Model Effective Field Theory (SMEFT) up to dim-2n, and SMEFT with sterile neutrinos ({\\nu}SMEFT) up to dimension-7.","By integrating the ring-diagram technique with the Cayley-Hamilton theorem, we have developed a system that not only simplifies the process of identifying basic and joint invariants but also enables the automatic differentiation between CP-even and CP-odd invariants from the lowest orders.","Additionally, this work presents a comparison of our results with those derived using the traditional Hilbert-Poincar\\'e series and its Plethystic logarithm.","While these conventional approaches primarily yield the numerical count of invariants, our framework provides a complete structure of invariants, thereby surpassing the limitations of these traditional methods."],"url":"http://arxiv.org/abs/2403.18732v1","category":"hep-ph"}
{"created":"2024-03-27 16:20:08","title":"ConstraintFlow: A DSL for Specification and Verification of Neural Network Analyses","abstract":"The uninterpretability of DNNs hinders their deployment to safety-critical applications. Recent works have shown that Abstract-Interpretation-based formal certification techniques provide promising avenues for building trust in DNNs to some extent. The intricate mathematical background of Abstract Interpretation poses two challenges: (i) easily designing the algorithms that capture the intricate DNN behavior by balancing cost vs. precision tradeoff, and (ii) maintaining the over-approximation-based soundness of these certifiers.   General-purpose programming languages like C++ provide extensive functionality, however, verifying the soundness of the algorithms written in them can be impractical. The most commonly used DNN certification libraries like auto_LiRPA and ERAN prove the correctness of their analyses. However, they consist of only a few hard-coded abstract domains and abstract transformers (or transfer functions) and do not allow the user to define new analyses. Further, these libraries can handle only specific DNN architectures.   To address these issues, we develop a declarative DSL -- ConstraintFlow -- that can be used to specify Abstract Interpretation-based DNN certifiers. In ConstraintFlow, programmers can easily define various existing and new abstract domains and transformers, all within just a few 10s of Lines of Code as opposed to 1000s of LOCs of existing libraries. We also provide lightweight automatic verification, which can be used to ensure the over-approximation-based soundness of the certifier code written in ConstraintFlow for arbitrary (but bounded) DNN architectures. Using this automated verification procedure, for the first time, we can verify the soundness of state-of-the-art DNN certifiers for arbitrary DNN architectures, all within a few minutes. We prove the soundness of our verification procedure and the completeness of a subset of ConstraintFlow.","sentences":["The uninterpretability of DNNs hinders their deployment to safety-critical applications.","Recent works have shown that Abstract-Interpretation-based formal certification techniques provide promising avenues for building trust in DNNs to some extent.","The intricate mathematical background of Abstract Interpretation poses two challenges: (i) easily designing the algorithms that capture the intricate DNN behavior by balancing cost vs. precision tradeoff, and (ii) maintaining the over-approximation-based soundness of these certifiers.   ","General-purpose programming languages like C++ provide extensive functionality, however, verifying the soundness of the algorithms written in them can be impractical.","The most commonly used DNN certification libraries like auto_LiRPA and ERAN prove the correctness of their analyses.","However, they consist of only a few hard-coded abstract domains and abstract transformers (or transfer functions) and do not allow the user to define new analyses.","Further, these libraries can handle only specific DNN architectures.   ","To address these issues, we develop a declarative DSL -- ConstraintFlow -- that can be used to specify Abstract Interpretation-based DNN certifiers.","In ConstraintFlow, programmers can easily define various existing and new abstract domains and transformers, all within just a few 10s of Lines of Code as opposed to 1000s of LOCs of existing libraries.","We also provide lightweight automatic verification, which can be used to ensure the over-approximation-based soundness of the certifier code written in ConstraintFlow for arbitrary (but bounded) DNN architectures.","Using this automated verification procedure, for the first time, we can verify the soundness of state-of-the-art DNN certifiers for arbitrary DNN architectures, all within a few minutes.","We prove the soundness of our verification procedure and the completeness of a subset of ConstraintFlow."],"url":"http://arxiv.org/abs/2403.18729v1","category":"cs.PL"}
{"created":"2024-03-27 16:14:52","title":"An exactly curl-free finite-volume scheme for a hyperbolic compressible barotropic two-phase model","abstract":"We present a new second order accurate structure-preserving finite volume scheme for the solution of the compressible barotropic two-phase model of Romenski et. al in multiple space dimensions. The governing equations fall into the wider class of symmetric hyperbolic and thermodynamically compatible (SHTC) systems and consist of a set of first-order hyperbolic partial differential equations (PDE). In the absence of algebraic source terms, the model is subject to a curl-free constraint for the relative velocity between the two phases. The main objective of this paper is, therefore, to preserve this structural property exactly also at the discrete level. The new numerical method is based on a staggered grid arrangement where the relative velocity field is stored in the cell vertexes while all the remaining variables are stored in the cell centers. This allows the definition of discretely compatible gradient and curl operators, which ensure that the discrete curl errors of the relative velocity field remain zero up to machine precision. A set of numerical results confirms this property also experimentally.","sentences":["We present a new second order accurate structure-preserving finite volume scheme for the solution of the compressible barotropic two-phase model of Romenski et.","al in multiple space dimensions.","The governing equations fall into the wider class of symmetric hyperbolic and thermodynamically compatible (SHTC) systems and consist of a set of first-order hyperbolic partial differential equations (PDE).","In the absence of algebraic source terms, the model is subject to a curl-free constraint for the relative velocity between the two phases.","The main objective of this paper is, therefore, to preserve this structural property exactly also at the discrete level.","The new numerical method is based on a staggered grid arrangement where the relative velocity field is stored in the cell vertexes while all the remaining variables are stored in the cell centers.","This allows the definition of discretely compatible gradient and curl operators, which ensure that the discrete curl errors of the relative velocity field remain zero up to machine precision.","A set of numerical results confirms this property also experimentally."],"url":"http://arxiv.org/abs/2403.18724v1","category":"math.NA"}
{"created":"2024-03-27 16:08:41","title":"On the scaling of random Tamari intervals and Schnyder woods of random triangulations (with an asymptotic D-finite trick)","abstract":"We consider a Tamari interval of size $n$ (i.e., a pair of Dyck paths which are comparable for the Tamari relation) chosen uniformly at random. We show that the height of a uniformly chosen vertex on the upper or lower path scales as $n^{3/4}$, and has an explicit limit law. By the Bernardi-Bonichon bijection, this result also describes the height of points in the canonical Schnyder trees of a uniform random plane triangulation of size $n$.   The exact solution of the model is based on polynomial equations with one and two catalytic variables. To prove the convergence from the exact solution, we use a version of moment pumping based on D-finiteness, which is essentially automatic and should apply to many other models. We are not sure to have seen this simple trick used before.   It would be interesting to study the universality of this convergence for decomposition trees associated to positive Bousquet-M\\'elou--Jehanne equations.","sentences":["We consider a Tamari interval of size $n$ (i.e., a pair of Dyck paths which are comparable for the Tamari relation) chosen uniformly at random.","We show that the height of a uniformly chosen vertex on the upper or lower path scales as $n^{3/4}$, and has an explicit limit law.","By the Bernardi-Bonichon bijection, this result also describes the height of points in the canonical Schnyder trees of a uniform random plane triangulation of size $n$.   The exact solution of the model is based on polynomial equations with one and two catalytic variables.","To prove the convergence from the exact solution, we use a version of moment pumping based on D-finiteness, which is essentially automatic and should apply to many other models.","We are not sure to have seen this simple trick used before.   ","It would be interesting to study the universality of this convergence for decomposition trees associated to positive Bousquet-M\\'elou--Jehanne equations."],"url":"http://arxiv.org/abs/2403.18719v1","category":"math.CO"}
{"created":"2024-03-27 16:08:12","title":"Constructive proofs of existence and stability of solitary waves in the capillary-gravity Whitham equation","abstract":"In this manuscript, we present a method to prove constructively the existence and spectral stability of solitary waves (solitons) in the capillary-gravity Whitham equation. By employing Fourier series analysis and computer-aided techniques, we successfully approximate the Fourier multiplier operator in this equation, allowing the construction of an approximate inverse for the linearization around an approximate solution $u_0$. Then, using a Newton-Kantorovich approach, we provide a sufficient condition under which the existence of a unique solitary wave $\\tilde{u}$ in a ball centered at $u_0$ is obtained. The verification of such a condition is established combining analytic techniques and rigorous numerical computations. Moreover, we derive a methodology to control the spectrum of the linearization around $\\tilde{u}$, enabling the study of spectral stability of the solution. As an illustration, we provide a (constructive) computer-assisted proof of existence of a stable soliton in both the case with capillary effects ($T>0$) and without capillary effects ($T=0$). The methodology presented in this paper can be generalized and provides a new approach for addressing the existence and spectral stability of solitary waves in nonlocal nonlinear equations. All computer-assisted proofs, including the requisite codes, are accessible on GitHub at \\cite{julia_cadiot}.","sentences":["In this manuscript, we present a method to prove constructively the existence and spectral stability of solitary waves (solitons) in the capillary-gravity Whitham equation.","By employing Fourier series analysis and computer-aided techniques, we successfully approximate the Fourier multiplier operator in this equation, allowing the construction of an approximate inverse for the linearization around an approximate solution $u_0$. Then, using a Newton-Kantorovich approach, we provide a sufficient condition under which the existence of a unique solitary wave $\\tilde{u}$ in a ball centered at $u_0$ is obtained.","The verification of such a condition is established combining analytic techniques and rigorous numerical computations.","Moreover, we derive a methodology to control the spectrum of the linearization around $\\tilde{u}$, enabling the study of spectral stability of the solution.","As an illustration, we provide a (constructive) computer-assisted proof of existence of a stable soliton in both the case with capillary effects ($T>0$) and without capillary effects ($T=0$).","The methodology presented in this paper can be generalized and provides a new approach for addressing the existence and spectral stability of solitary waves in nonlocal nonlinear equations.","All computer-assisted proofs, including the requisite codes, are accessible on GitHub at \\cite{julia_cadiot}."],"url":"http://arxiv.org/abs/2403.18718v1","category":"math.AP"}
{"created":"2024-03-27 15:58:33","title":"Phasing segmented telescopes via deep learning methods: application to a deployable CubeSat","abstract":"Capturing high resolution imagery of the Earth's surface often calls for a telescope of considerable size, even from Low Earth Orbits (LEO). A large aperture often requires large and expensive platforms. For instance, achieving a resolution of 1m at visible wavelengths from LEO typically requires an aperture diameter of at least 30cm. Additionally, ensuring high revisit times often prompts the use of multiple satellites. In light of these challenges, a small, segmented, deployable CubeSat telescope was recently proposed creating the additional need of phasing the telescope's mirrors. Phasing methods on compact platforms are constrained by the limited volume and power available, excluding solutions that rely on dedicated hardware or demand substantial computational resources. Neural Network (NN) are known for their computationally efficient inference and reduced on board requirements. Therefore we developed a NN based method to measure co phasing errors inherent to a deployable telescope. The proposed technique demonstrates its ability to detect phasing error at the targeted performance level (typically a wavefront error (WFE) below 15 nm RMS for a visible imager operating at the diffraction limit) using a point source. The robustness of the NN method is verified in presence of high order aberrations or noise and the results are compared against existing state of the art techniques. The developed NN model ensures its feasibility and provides a realistic pathway towards achieving diffraction limited images.","sentences":["Capturing high resolution imagery of the Earth's surface often calls for a telescope of considerable size, even from Low Earth Orbits (LEO).","A large aperture often requires large and expensive platforms.","For instance, achieving a resolution of 1m at visible wavelengths from LEO typically requires an aperture diameter of at least 30cm.","Additionally, ensuring high revisit times often prompts the use of multiple satellites.","In light of these challenges, a small, segmented, deployable CubeSat telescope was recently proposed creating the additional need of phasing the telescope's mirrors.","Phasing methods on compact platforms are constrained by the limited volume and power available, excluding solutions that rely on dedicated hardware or demand substantial computational resources.","Neural Network (NN) are known for their computationally efficient inference and reduced on board requirements.","Therefore we developed a NN based method to measure co phasing errors inherent to a deployable telescope.","The proposed technique demonstrates its ability to detect phasing error at the targeted performance level (typically a wavefront error (WFE) below 15 nm RMS for a visible imager operating at the diffraction limit) using a point source.","The robustness of the NN method is verified in presence of high order aberrations or noise and the results are compared against existing state of the art techniques.","The developed NN model ensures its feasibility and provides a realistic pathway towards achieving diffraction limited images."],"url":"http://arxiv.org/abs/2403.18712v1","category":"astro-ph.IM"}
{"created":"2024-03-27 15:57:42","title":"Deep Learning for Traffic Flow Prediction using Cellular Automata-based Model and CNN-LSTM architecture","abstract":"Recent works have attempted to use deep learning to predict future states of traffic flow, but have met with mixed results. These approaches face two key challenges. First, training deep learning neural networks requires large amounts of training data which are not yet easily available for traffic flow systems. Second, even when data is available, the neural networks require access to historical data that covers most possible traffic flow dynamics to successfully predict future traffic states. Specifically, these deep learning approaches do not fully leverage domain-knowledge about traffic flow dynamics, despite a significant existing knowledge-base. In this work, we propose to solve both issues using a Convolutional Neural Network (CNNs) with Long Short Term Memory (LSTM) deep learning architecture to successfully predict traffic flow, while leveraging a cellular automata-based statistical mechanics model of traffic flow to generate training and test data. Another major contribution of this paper is the insight that training data for a large traffic system can actually be sampled from the simulations of a much smaller traffic system. This is achieved through observing that the normalized energy distribution of the statistical mechanics model is scale invariant, which significantly eases the burden of data generation for large scale traffic systems. The resulting simulations indicate good agreement between the predicted and the true traffic flow dynamics.","sentences":["Recent works have attempted to use deep learning to predict future states of traffic flow, but have met with mixed results.","These approaches face two key challenges.","First, training deep learning neural networks requires large amounts of training data which are not yet easily available for traffic flow systems.","Second, even when data is available, the neural networks require access to historical data that covers most possible traffic flow dynamics to successfully predict future traffic states.","Specifically, these deep learning approaches do not fully leverage domain-knowledge about traffic flow dynamics, despite a significant existing knowledge-base.","In this work, we propose to solve both issues using a Convolutional Neural Network (CNNs) with Long Short Term Memory (LSTM) deep learning architecture to successfully predict traffic flow, while leveraging a cellular automata-based statistical mechanics model of traffic flow to generate training and test data.","Another major contribution of this paper is the insight that training data for a large traffic system can actually be sampled from the simulations of a much smaller traffic system.","This is achieved through observing that the normalized energy distribution of the statistical mechanics model is scale invariant, which significantly eases the burden of data generation for large scale traffic systems.","The resulting simulations indicate good agreement between the predicted and the true traffic flow dynamics."],"url":"http://arxiv.org/abs/2403.18710v1","category":"cs.LG"}
{"created":"2024-03-27 15:53:42","title":"Convergence rates under a range invariance condition with application to electrical impedance tomography","abstract":"This paper is devoted to proving convergence rates of variational and iterative regularization methods under variational source conditions VSCs for inverse problems whose linearization satisfies a range invariance condition. In order to achieve this, often an appropriate relaxation of the problem needs to be found that is usually based on an augmentation of the set of unknowns and leads to a particularly structured reformulation of the inverse problem. We analyze three approaches that make use of this structure, namely a variational and a Newton type scheme, whose convergence without rates has already been established in \\cite{rangeinvar}; additionally we propose a split minimization approach that can be show to satisfy the same rates results. \\\\ The range invariance condition has been verified for several coefficient identification problems for partial differential equations from boundary observations as relevant in a variety of tomographic imaging modalities. Our motivation particularly comes from the by now classical inverse problem of electrical impedance tomography EIT and we study both the original formulation by a diffusion type equation and its reformulation as a Schr\\\"odinger equation. For both of them we find relaxations that can be proven to satisfy the range invariance condition. Combining results on VSCs from \\cite{Diss-Weidling} with the abstract framework for the three approaches mentioned above, we arrive at convergence rates results for the variational, split minimization and Newton type method in EIT.","sentences":["This paper is devoted to proving convergence rates of variational and iterative regularization methods under variational source conditions VSCs for inverse problems whose linearization satisfies a range invariance condition.","In order to achieve this, often an appropriate relaxation of the problem needs to be found that is usually based on an augmentation of the set of unknowns and leads to a particularly structured reformulation of the inverse problem.","We analyze three approaches that make use of this structure, namely a variational and a Newton type scheme, whose convergence without rates has already been established in \\cite{rangeinvar}; additionally we propose a split minimization approach that can be show to satisfy the same rates results.","\\\\","The range invariance condition has been verified for several coefficient identification problems for partial differential equations from boundary observations as relevant in a variety of tomographic imaging modalities.","Our motivation particularly comes from the by now classical inverse problem of electrical impedance tomography EIT and we study both the original formulation by a diffusion type equation and its reformulation as a Schr\\\"odinger equation.","For both of them we find relaxations that can be proven to satisfy the range invariance condition.","Combining results on VSCs from \\cite{Diss-Weidling} with the abstract framework for the three approaches mentioned above, we arrive at convergence rates results for the variational, split minimization and Newton type method in EIT."],"url":"http://arxiv.org/abs/2403.18704v1","category":"math.NA"}
{"created":"2024-03-27 15:34:46","title":"The Gross--Kohnen--Zagier theorem via $p$-adic uniformization","abstract":"This article gives a new proof of the Gross--Kohnen--Zagier theorem for Shimura curves which exploits the $p$-adic uniformization of Cerednik--Drinfeld. The explicit description of CM points via this uniformization leads to an expression relating the Gross--Kohnen--Zagier generating series to the ordinary projection of the first derivative, with respect to a weight variable, of a $p$-adic family of positive definite ternary theta series.","sentences":["This article gives a new proof of the Gross--Kohnen--Zagier theorem for Shimura curves which exploits the $p$-adic uniformization of Cerednik--Drinfeld.","The explicit description of CM points via this uniformization leads to an expression relating the Gross--Kohnen--Zagier generating series to the ordinary projection of the first derivative, with respect to a weight variable, of a $p$-adic family of positive definite ternary theta series."],"url":"http://arxiv.org/abs/2403.18688v1","category":"math.NT"}
{"created":"2024-03-27 15:34:27","title":"InceptionTime vs. Wavelet -- A comparison for time series classification","abstract":"Neural networks were used to classify infrasound data. Two different approaches were compared. One based on the direct classification of time series data, using a custom implementation of the InceptionTime network. For the other approach, we generated 2D images of the wavelet transformation of the signals, which were subsequently classified using a ResNet implementation. Choosing appropriate hyperparameter settings, both achieve a classification accuracy of above 90 %, with the direct approach reaching 95.2 %.","sentences":["Neural networks were used to classify infrasound data.","Two different approaches were compared.","One based on the direct classification of time series data, using a custom implementation of the InceptionTime network.","For the other approach, we generated 2D images of the wavelet transformation of the signals, which were subsequently classified using a ResNet implementation.","Choosing appropriate hyperparameter settings, both achieve a classification accuracy of above 90 %, with the direct approach reaching 95.2 %."],"url":"http://arxiv.org/abs/2403.18687v1","category":"cs.LG"}
{"created":"2024-03-27 15:27:36","title":"Scaling Laws For Dense Retrieval","abstract":"Scaling up neural models has yielded significant advancements in a wide array of tasks, particularly in language generation. Previous studies have found that the performance of neural models frequently adheres to predictable scaling laws, correlated with factors such as training set size and model size. This insight is invaluable, especially as large-scale experiments grow increasingly resource-intensive. Yet, such scaling law has not been fully explored in dense retrieval due to the discrete nature of retrieval metrics and complex relationships between training data and model sizes in retrieval tasks. In this study, we investigate whether the performance of dense retrieval models follows the scaling law as other neural models. We propose to use contrastive log-likelihood as the evaluation metric and conduct extensive experiments with dense retrieval models implemented with different numbers of parameters and trained with different amounts of annotated data. Results indicate that, under our settings, the performance of dense retrieval models follows a precise power-law scaling related to the model size and the number of annotations. Additionally, we examine scaling with prevalent data augmentation methods to assess the impact of annotation quality, and apply the scaling law to find the best resource allocation strategy under a budget constraint. We believe that these insights will significantly contribute to understanding the scaling effect of dense retrieval models and offer meaningful guidance for future research endeavors.","sentences":["Scaling up neural models has yielded significant advancements in a wide array of tasks, particularly in language generation.","Previous studies have found that the performance of neural models frequently adheres to predictable scaling laws, correlated with factors such as training set size and model size.","This insight is invaluable, especially as large-scale experiments grow increasingly resource-intensive.","Yet, such scaling law has not been fully explored in dense retrieval due to the discrete nature of retrieval metrics and complex relationships between training data and model sizes in retrieval tasks.","In this study, we investigate whether the performance of dense retrieval models follows the scaling law as other neural models.","We propose to use contrastive log-likelihood as the evaluation metric and conduct extensive experiments with dense retrieval models implemented with different numbers of parameters and trained with different amounts of annotated data.","Results indicate that, under our settings, the performance of dense retrieval models follows a precise power-law scaling related to the model size and the number of annotations.","Additionally, we examine scaling with prevalent data augmentation methods to assess the impact of annotation quality, and apply the scaling law to find the best resource allocation strategy under a budget constraint.","We believe that these insights will significantly contribute to understanding the scaling effect of dense retrieval models and offer meaningful guidance for future research endeavors."],"url":"http://arxiv.org/abs/2403.18684v1","category":"cs.IR"}
{"created":"2024-03-27 15:27:04","title":"Exploring the Berezinskii-Kosterlitz-Thouless Transition in a Two-dimensional Dipolar Bose Gas","abstract":"Long-range and anisotropic dipolar interactions induce complex order in quantum systems. It becomes particularly interesting in two-dimension (2D), where the superfluidity with quasi-long-range order emerges via Berezinskii-Kosterlitz-Thouless (BKT) mechanism, which still remains elusive with dipolar interactions. Here, we observe the BKT transition from a normal gas to the superfluid phase in a quasi-2D dipolar Bose gas of erbium atoms. Controlling the orientation of dipoles, we characterize the transition point by monitoring extended coherence and measuring the equation of state. This allows us to gain a systematic understanding of the BKT transition based on an effective short-range description of dipolar interaction in 2D. Additionally, we observe anisotropic density fluctuations and non-local effects in the superfluid regime, which establishes the dipolar nature of the 2D superfluid. Our results lay the ground for understanding the behavior of dipolar bosons in 2D and open up opportunities for examining complex orders in a dipolar superfluid.","sentences":["Long-range and anisotropic dipolar interactions induce complex order in quantum systems.","It becomes particularly interesting in two-dimension (2D), where the superfluidity with quasi-long-range order emerges via Berezinskii-Kosterlitz-Thouless (BKT) mechanism, which still remains elusive with dipolar interactions.","Here, we observe the BKT transition from a normal gas to the superfluid phase in a quasi-2D dipolar Bose gas of erbium atoms.","Controlling the orientation of dipoles, we characterize the transition point by monitoring extended coherence and measuring the equation of state.","This allows us to gain a systematic understanding of the BKT transition based on an effective short-range description of dipolar interaction in 2D. Additionally, we observe anisotropic density fluctuations and non-local effects in the superfluid regime, which establishes the dipolar nature of the 2D superfluid.","Our results lay the ground for understanding the behavior of dipolar bosons in 2D and open up opportunities for examining complex orders in a dipolar superfluid."],"url":"http://arxiv.org/abs/2403.18683v1","category":"cond-mat.quant-gas"}
{"created":"2024-03-27 15:17:59","title":"Submanifolds with boundary and Stokes' Theorem in Heisenberg groups","abstract":"We introduce and study the notion of $C^1_\\mathbb{H}$-regular submanifold with boundary in sub-Riemannian Heisenberg groups. As an application, we prove a version of Stokes' Theorem for $C^1_\\mathbb{H}$-regular submanifolds with boundary that takes into account Rumin's complex of differential forms in Heisenberg groups.","sentences":["We introduce and study the notion of $C^1_\\mathbb{H}$-regular submanifold with boundary in sub-Riemannian Heisenberg groups.","As an application, we prove a version of Stokes' Theorem for $C^1_\\mathbb{H}$-regular submanifolds with boundary that takes into account Rumin's complex of differential forms in Heisenberg groups."],"url":"http://arxiv.org/abs/2403.18675v1","category":"math.DG"}
{"created":"2024-03-27 15:13:26","title":"Orthogonal Polynomials with a Singularly Perturbed Airy Weight","abstract":"We study the monic orthogonal polynomials with respect to a singularly perturbed Airy weight. By using Chen and Ismail's ladder operator approach, we derive a discrete system satisfied by the recurrence coefficients for the orthogonal polynomials. We find that the orthogonal polynomials satisfy a second-order linear ordinary differential equation, whose coefficients are all expressed in terms of the recurrence coefficients. By considering the time evolution, we obtain a system of differential-difference equations satisfied by the recurrence coefficients. Finally, we study the asymptotics of the recurrence coefficients when the degrees of the orthogonal polynomials tend to infinity.","sentences":["We study the monic orthogonal polynomials with respect to a singularly perturbed Airy weight.","By using Chen and Ismail's ladder operator approach, we derive a discrete system satisfied by the recurrence coefficients for the orthogonal polynomials.","We find that the orthogonal polynomials satisfy a second-order linear ordinary differential equation, whose coefficients are all expressed in terms of the recurrence coefficients.","By considering the time evolution, we obtain a system of differential-difference equations satisfied by the recurrence coefficients.","Finally, we study the asymptotics of the recurrence coefficients when the degrees of the orthogonal polynomials tend to infinity."],"url":"http://arxiv.org/abs/2403.18669v1","category":"math.CA"}
{"created":"2024-03-27 15:09:46","title":"FluxGAT: Integrating Flux Sampling with Graph Neural Networks for Unbiased Gene Essentiality Classification","abstract":"Gene essentiality, the necessity of a specific gene for the survival of an organism, is crucial to our understanding of cellular processes and identifying drug targets. Experimental determination of gene essentiality requires large growth screens that are time-consuming and expensive, motivating the development of in-silico approaches. Existing methods predominantly utilise flux balance analysis (FBA), a constraint-based optimisation algorithm; however, they are fundamentally limited by the necessity of a predefined cellular objective function. This requirement introduces an element of observer bias, as the objective function often reflects the researcher's assumptions rather than the cell's biological goals. Here, we present FluxGAT, a graph neural network (GNN) model capable of predicting gene essentiality directly from graphical representations of flux sampling data. Flux sampling removes the need for objective functions, thereby eliminating observer bias. FluxGAT leverages the unique strengths of GNNs in learning representations of complex relationships within metabolic reaction networks. The success of our approach in predicting experimentally determined gene essentiality, with almost double the sensitivity of FBA, explores the possibility of predicting cellular phenotypes in cases when objectives are less understood. Thus, we demonstrate a method for more general gene essentiality predictions across a broader spectrum of biological systems and environments.","sentences":["Gene essentiality, the necessity of a specific gene for the survival of an organism, is crucial to our understanding of cellular processes and identifying drug targets.","Experimental determination of gene essentiality requires large growth screens that are time-consuming and expensive, motivating the development of in-silico approaches.","Existing methods predominantly utilise flux balance analysis (FBA), a constraint-based optimisation algorithm; however, they are fundamentally limited by the necessity of a predefined cellular objective function.","This requirement introduces an element of observer bias, as the objective function often reflects the researcher's assumptions rather than the cell's biological goals.","Here, we present FluxGAT, a graph neural network (GNN) model capable of predicting gene essentiality directly from graphical representations of flux sampling data.","Flux sampling removes the need for objective functions, thereby eliminating observer bias.","FluxGAT leverages the unique strengths of GNNs in learning representations of complex relationships within metabolic reaction networks.","The success of our approach in predicting experimentally determined gene essentiality, with almost double the sensitivity of FBA, explores the possibility of predicting cellular phenotypes in cases when objectives are less understood.","Thus, we demonstrate a method for more general gene essentiality predictions across a broader spectrum of biological systems and environments."],"url":"http://arxiv.org/abs/2403.18666v2","category":"q-bio.QM"}
{"created":"2024-03-27 15:08:00","title":"Neural Network-Based Piecewise Survival Models","abstract":"In this paper, a family of neural network-based survival models is presented. The models are specified based on piecewise definitions of the hazard function and the density function on a partitioning of the time; both constant and linear piecewise definitions are presented, resulting in a family of four models. The models can be seen as an extension of the commonly used discrete-time and piecewise exponential models and thereby add flexibility to this set of standard models. Using a simulated dataset the models are shown to perform well compared to the highly expressive, state-of-the-art energy-based model, while only requiring a fraction of the computation time.","sentences":["In this paper, a family of neural network-based survival models is presented.","The models are specified based on piecewise definitions of the hazard function and the density function on a partitioning of the time; both constant and linear piecewise definitions are presented, resulting in a family of four models.","The models can be seen as an extension of the commonly used discrete-time and piecewise exponential models and thereby add flexibility to this set of standard models.","Using a simulated dataset the models are shown to perform well compared to the highly expressive, state-of-the-art energy-based model, while only requiring a fraction of the computation time."],"url":"http://arxiv.org/abs/2403.18664v1","category":"stat.ML"}
{"created":"2024-03-27 15:04:15","title":"A machine-learning pipeline for real-time detection of gravitational waves from compact binary coalescences","abstract":"The promise of multi-messenger astronomy relies on the rapid detection of gravitational waves at very low latencies ($\\mathcal{O}$(1\\,s)) in order to maximize the amount of time available for follow-up observations. In recent years, neural-networks have demonstrated robust non-linear modeling capabilities and millisecond-scale inference at a comparatively small computational footprint, making them an attractive family of algorithms in this context. However, integration of these algorithms into the gravitational-wave astrophysics research ecosystem has proven non-trivial. Here, we present the first fully machine learning-based pipeline for the detection of gravitational waves from compact binary coalescences (CBCs) running in low-latency. We demonstrate this pipeline to have a fraction of the latency of traditional matched filtering search pipelines while achieving state-of-the-art sensitivity to higher-mass stellar binary black holes.","sentences":["The promise of multi-messenger astronomy relies on the rapid detection of gravitational waves at very low latencies ($\\mathcal{O}$(1\\,s)) in order to maximize the amount of time available for follow-up observations.","In recent years, neural-networks have demonstrated robust non-linear modeling capabilities and millisecond-scale inference at a comparatively small computational footprint, making them an attractive family of algorithms in this context.","However, integration of these algorithms into the gravitational-wave astrophysics research ecosystem has proven non-trivial.","Here, we present the first fully machine learning-based pipeline for the detection of gravitational waves from compact binary coalescences (CBCs) running in low-latency.","We demonstrate this pipeline to have a fraction of the latency of traditional matched filtering search pipelines while achieving state-of-the-art sensitivity to higher-mass stellar binary black holes."],"url":"http://arxiv.org/abs/2403.18661v1","category":"gr-qc"}
{"created":"2024-03-27 15:01:51","title":"A Dimca-Greuel type inequality for foliations","abstract":"Let $\\mathcal{F}$ be a holomorphic foliation at $p\\in \\mathbb{C}^2$, and $B$ be a separatrix of $\\mathcal{F}$. We prove the following Dimca-Greuel type inequality $\\frac{\\mu_p(\\mathcal{F},B)}{\\tau_p(\\mathcal{F},B)}<4/3$, where $\\mu_p(\\mathcal{F},B)$ is the multiplicity of $\\mathcal{F}$ along $B$ and $\\tau_p(\\mathcal{F},B)$ is the dimension of the quotient of $\\mathbb{C}[[x,y]]$ by the ideal generated by the components of any $1$-form defining $\\mathcal{F}$ and any equation of $B$. As a consequence, we provide a new proof of the $\\frac{4}{3}$-Dimca-Greuel's conjecture for singularities of irreducible plane curve germs, with foliations ingredients, that differs from those given by Alberich-Carrami\\~nana, Almir\\'on, Blanco, Melle-Hern\\'andez and Genzmer-Hernandes but it is in line with the idea developed by Wang.","sentences":["Let $\\mathcal{F}$ be a holomorphic foliation at $p\\in \\mathbb{C}^2$, and $B$ be a separatrix of $\\mathcal{F}$. We prove the following Dimca-Greuel type inequality $\\frac{\\mu_p(\\mathcal{F},B)}{\\tau_p(\\mathcal{F},B)}<4/3$, where $\\mu_p(\\mathcal{F},B)$ is the multiplicity of $\\mathcal{F}$ along $B$ and $\\tau_p(\\mathcal{F},B)$ is the dimension of the quotient of $\\mathbb{C}[[x,y]]$ by the ideal generated by the components of any $1$-form defining $\\mathcal{F}$ and any equation of $B$. As a consequence, we provide a new proof of the $\\frac{4}{3}$-Dimca-Greuel's conjecture for singularities of irreducible plane curve germs, with foliations ingredients, that differs from those given by Alberich-Carrami\\~nana, Almir\\'on, Blanco, Melle-Hern\\'andez and Genzmer-Hernandes but it is in line with the idea developed by Wang."],"url":"http://arxiv.org/abs/2403.18654v1","category":"math.CV"}
{"created":"2024-03-27 15:00:46","title":"Indecomposable set-theoretical solutions to the Yang-Baxter equation of size $p^2$","abstract":"The quantum Yang-Baxter equation is a braiding condition on complex vector spaces which is of high relevance in several fields of mathematics, such as knot theory and quantum group theory. A combinatorial approach is the investigation of set-theoretic solutions to the Yang--Baxter equation and their associated algebraic structures. In this article, we focus on indecomposable set-theoretic solutions to the Yang--Baxter equation. More specifically, we give a full classification of those which are of size $p^2$.","sentences":["The quantum Yang-Baxter equation is a braiding condition on complex vector spaces which is of high relevance in several fields of mathematics, such as knot theory and quantum group theory.","A combinatorial approach is the investigation of set-theoretic solutions to the Yang--Baxter equation and their associated algebraic structures.","In this article, we focus on indecomposable set-theoretic solutions to the Yang--Baxter equation.","More specifically, we give a full classification of those which are of size $p^2$."],"url":"http://arxiv.org/abs/2403.18653v1","category":"math.QA"}
{"created":"2024-03-27 17:33:55","title":"Peregrine: ML-based Malicious Traffic Detection for Terabit Networks","abstract":"Malicious traffic detectors leveraging machine learning (ML), namely those incorporating deep learning techniques, exhibit impressive detection capabilities across multiple attacks. However, their effectiveness becomes compromised when deployed in networks handling Terabit-speed traffic. In practice, these systems require substantial traffic sampling to reconcile the high data plane packet rates with the comparatively slower processing speeds of ML detection. As sampling significantly reduces traffic observability, it fundamentally undermines their detection capability.   We present Peregrine, an ML-based malicious traffic detector for Terabit networks. The key idea is to run the detection process partially in the network data plane. Specifically, we offload the detector's ML feature computation to a commodity switch. The Peregrine switch processes a diversity of features per-packet, at Tbps line rates - three orders of magnitude higher than the fastest detector - to feed the ML-based component in the control plane. Our offloading approach presents a distinct advantage. While, in practice, current systems sample raw traffic, in Peregrine sampling occurs after feature computation. This essential trait enables computing features over all traffic, significantly enhancing detection performance. The Peregrine detector is not only effective for Terabit networks, but it is also energy- and cost-efficient. Further, by shifting a compute-heavy component to the switch, it saves precious CPU cycles and improves detection throughput.","sentences":["Malicious traffic detectors leveraging machine learning (ML), namely those incorporating deep learning techniques, exhibit impressive detection capabilities across multiple attacks.","However, their effectiveness becomes compromised when deployed in networks handling Terabit-speed traffic.","In practice, these systems require substantial traffic sampling to reconcile the high data plane packet rates with the comparatively slower processing speeds of ML detection.","As sampling significantly reduces traffic observability, it fundamentally undermines their detection capability.   ","We present Peregrine, an ML-based malicious traffic detector for Terabit networks.","The key idea is to run the detection process partially in the network data plane.","Specifically, we offload the detector's ML feature computation to a commodity switch.","The Peregrine switch processes a diversity of features per-packet, at Tbps line rates - three orders of magnitude higher than the fastest detector - to feed the ML-based component in the control plane.","Our offloading approach presents a distinct advantage.","While, in practice, current systems sample raw traffic, in Peregrine sampling occurs after feature computation.","This essential trait enables computing features over all traffic, significantly enhancing detection performance.","The Peregrine detector is not only effective for Terabit networks, but it is also energy- and cost-efficient.","Further, by shifting a compute-heavy component to the switch, it saves precious CPU cycles and improves detection throughput."],"url":"http://arxiv.org/abs/2403.18788v1","category":"cs.NI"}
{"created":"2024-03-27 17:28:05","title":"IR Spectroscopy of Carboxylate-Passivated Semiconducting Nanocrystals: Simulation and Experiment","abstract":"Surfaces of colloidal nanocrystals are frequently passivated with carboxylate ligands which exert significant effects on their optoelectronic properties and chemical stability. Experimentally, binding geometries of such ligands are typically investigated using vibrational spectroscopy, but the interpretation of the IR signal is usually not trivial. Here, using machine-learning (ML) algorithms trained on DFT data, we simulate an IR spectrum of a lead-rich PbS nanocrystal passivated with butyrate ligands. We obtain a good agreement with the experimental signal and demonstrate that the observed line shape stems from a very wide range of `tilted-bridge'-type geometries and does not indicate a coexistence of `bridging' and `chelating' binding modes as has been previously assumed. This work illustrates limitations of empirical spectrum assignment and demonstrates the effectiveness of ML-driven molecular dynamics simulations in reproducing IR spectra of nanoscopic systems.","sentences":["Surfaces of colloidal nanocrystals are frequently passivated with carboxylate ligands which exert significant effects on their optoelectronic properties and chemical stability.","Experimentally, binding geometries of such ligands are typically investigated using vibrational spectroscopy, but the interpretation of the IR signal is usually not trivial.","Here, using machine-learning (ML) algorithms trained on DFT data, we simulate an IR spectrum of a lead-rich PbS nanocrystal passivated with butyrate ligands.","We obtain a good agreement with the experimental signal and demonstrate that the observed line shape stems from a very wide range of `tilted-bridge'-type geometries and does not indicate a coexistence of `bridging' and `chelating' binding modes as has been previously assumed.","This work illustrates limitations of empirical spectrum assignment and demonstrates the effectiveness of ML-driven molecular dynamics simulations in reproducing IR spectra of nanoscopic systems."],"url":"http://arxiv.org/abs/2403.18779v1","category":"physics.chem-ph"}
{"created":"2024-03-27 17:03:31","title":"CaT: Constraints as Terminations for Legged Locomotion Reinforcement Learning","abstract":"Deep Reinforcement Learning (RL) has demonstrated impressive results in solving complex robotic tasks such as quadruped locomotion. Yet, current solvers fail to produce efficient policies respecting hard constraints. In this work, we advocate for integrating constraints into robot learning and present Constraints as Terminations (CaT), a novel constrained RL algorithm. Departing from classical constrained RL formulations, we reformulate constraints through stochastic terminations during policy learning: any violation of a constraint triggers a probability of terminating potential future rewards the RL agent could attain. We propose an algorithmic approach to this formulation, by minimally modifying widely used off-the-shelf RL algorithms in robot learning (such as Proximal Policy Optimization). Our approach leads to excellent constraint adherence without introducing undue complexity and computational overhead, thus mitigating barriers to broader adoption. Through empirical evaluation on the real quadruped robot Solo crossing challenging obstacles, we demonstrate that CaT provides a compelling solution for incorporating constraints into RL frameworks. Videos and code are available at https://constraints-as-terminations.github.io.","sentences":["Deep Reinforcement Learning (RL) has demonstrated impressive results in solving complex robotic tasks such as quadruped locomotion.","Yet, current solvers fail to produce efficient policies respecting hard constraints.","In this work, we advocate for integrating constraints into robot learning and present Constraints as Terminations (CaT), a novel constrained RL algorithm.","Departing from classical constrained RL formulations, we reformulate constraints through stochastic terminations during policy learning: any violation of a constraint triggers a probability of terminating potential future rewards the RL agent could attain.","We propose an algorithmic approach to this formulation, by minimally modifying widely used off-the-shelf RL algorithms in robot learning (such as Proximal Policy Optimization).","Our approach leads to excellent constraint adherence without introducing undue complexity and computational overhead, thus mitigating barriers to broader adoption.","Through empirical evaluation on the real quadruped robot Solo crossing challenging obstacles, we demonstrate that CaT provides a compelling solution for incorporating constraints into RL frameworks.","Videos and code are available at https://constraints-as-terminations.github.io."],"url":"http://arxiv.org/abs/2403.18765v1","category":"cs.RO"}
{"created":"2024-03-27 17:59:33","title":"Garment3DGen: 3D Garment Stylization and Texture Generation","abstract":"We introduce Garment3DGen a new method to synthesize 3D garment assets from a base mesh given a single input image as guidance. Our proposed approach allows users to generate 3D textured clothes based on both real and synthetic images, such as those generated by text prompts. The generated assets can be directly draped and simulated on human bodies. First, we leverage the recent progress of image to 3D diffusion methods to generate 3D garment geometries. However, since these geometries cannot be utilized directly for downstream tasks, we propose to use them as pseudo ground-truth and set up a mesh deformation optimization procedure that deforms a base template mesh to match the generated 3D target. Second, we introduce carefully designed losses that allow the input base mesh to freely deform towards the desired target, yet preserve mesh quality and topology such that they can be simulated. Finally, a texture estimation module generates high-fidelity texture maps that are globally and locally consistent and faithfully capture the input guidance, allowing us to render the generated 3D assets. With Garment3DGen users can generate the textured 3D garment of their choice without the need of artist intervention. One can provide a textual prompt describing the garment they desire to generate a simulation-ready 3D asset. We present a plethora of quantitative and qualitative comparisons on various assets both real and generated and provide use-cases of how one can generate simulation-ready 3D garments.","sentences":["We introduce Garment3DGen a new method to synthesize 3D garment assets from a base mesh given a single input image as guidance.","Our proposed approach allows users to generate 3D textured clothes based on both real and synthetic images, such as those generated by text prompts.","The generated assets can be directly draped and simulated on human bodies.","First, we leverage the recent progress of image to 3D diffusion methods to generate 3D garment geometries.","However, since these geometries cannot be utilized directly for downstream tasks, we propose to use them as pseudo ground-truth and set up a mesh deformation optimization procedure that deforms a base template mesh to match the generated 3D target.","Second, we introduce carefully designed losses that allow the input base mesh to freely deform towards the desired target, yet preserve mesh quality and topology such that they can be simulated.","Finally, a texture estimation module generates high-fidelity texture maps that are globally and locally consistent and faithfully capture the input guidance, allowing us to render the generated 3D assets.","With Garment3DGen users can generate the textured 3D garment of their choice without the need of artist intervention.","One can provide a textual prompt describing the garment they desire to generate a simulation-ready 3D asset.","We present a plethora of quantitative and qualitative comparisons on various assets both real and generated and provide use-cases of how one can generate simulation-ready 3D garments."],"url":"http://arxiv.org/abs/2403.18816v1","category":"cs.CV"}
{"created":"2024-03-27 17:51:00","title":"Using an invariant knot of a flow to find additional invariant structure","abstract":"Consider a continuous flow in $\\mathbb{R}^3$ or any orientable $3$-manifold. Let $(Q_1, Q_0)$ be an index pair in the sense of Conley and consider the region $N := \\overline{Q_1 - Q_0}$. (An example of this is a compact $3$-manifold $N$ such that trajectories of the flow cross $\\partial N$ inwards or outwards transversally, or bounce off it from the outside). Suppose we know there is an invariant knot or link $K$ in the interior of $N$. We prove the following: if $K$ is contractible and nontrivial (in the sense of knot theory) in $N$, then every neighbourhood $U$ of $K$ contains a point $p \\in N - K$ such that the whole trajectory of $p$ is contained in $N$. In other words, the presence of $K$ forces the existence of additional invariant structure in $N$ (besides $K$), and the latter can actually be found arbitrarily close to $K$.   To prove this result we develop a ``coloured'' handle theory which may be of independent interest to study flows in $3$-manifolds.","sentences":["Consider a continuous flow in $\\mathbb{R}^3$ or any orientable $3$-manifold.","Let $(Q_1, Q_0)$ be an index pair in the sense of Conley and consider the region $N := \\overline{Q_1 - Q_0}$. (An example of this is a compact $3$-manifold $N$ such that trajectories of the flow cross $\\partial N$ inwards or outwards transversally, or bounce off it from the outside).","Suppose we know there is an invariant knot or link $K$ in the interior of $N$. We prove the following: if $K$ is contractible and nontrivial (in the sense of knot theory) in $N$, then every neighbourhood $U$ of $K$ contains a point $p \\in N - K$ such that the whole trajectory of $p$ is contained in $N$. In other words, the presence of $K$ forces the existence of additional invariant structure in $N$ (besides $K$), and the latter can actually be found arbitrarily close to $K$.   To prove this result we develop a ``coloured'' handle theory which may be of independent interest to study flows in $3$-manifolds."],"url":"http://arxiv.org/abs/2403.18805v1","category":"math.DS"}
{"created":"2024-03-27 17:23:52","title":"New Graph and Hypergraph Container Lemmas with Applications in Property Testing","abstract":"The graph and hypergraph container methods are powerful tools with a wide range of applications across combinatorics. Recently, Blais and Seth (FOCS 2023) showed that the graph container method is particularly well-suited for the analysis of the natural canonical tester for two fundamental graph properties: having a large independent set and $k$-colorability. In this work, we show that the connection between the container method and property testing extends further along two different directions.   First, we show that the container method can be used to analyze the canonical tester for many other properties of graphs and hypergraphs. We introduce a new hypergraph container lemma and use it to give an upper bound of $\\widetilde{O}(kq^3/\\epsilon)$ on the sample complexity of $\\epsilon$-testing satisfiability, where $q$ is the number of variables per constraint and $k$ is the size of the alphabet. This is the first upper bound for the problem that is polynomial in all of $k$, $q$ and $1/\\epsilon$. As a corollary, we get new upper bounds on the sample complexity of the canonical testers for hypergraph colorability and for every semi-homogeneous graph partition property.   Second, we show that the container method can also be used to study the query complexity of (non-canonical) graph property testers. This result is obtained by introducing a new container lemma for the class of all independent set stars, a strict superset of the class of all independent sets. We use this container lemma to give a new upper bound of $\\widetilde{O}(\\rho^5/\\epsilon^{7/2})$ on the query complexity of $\\epsilon$-testing the $\\rho$-independent set property. This establishes for the first time the non-optimality of the canonical tester for a non-homogeneous graph partition property.","sentences":["The graph and hypergraph container methods are powerful tools with a wide range of applications across combinatorics.","Recently, Blais and Seth (FOCS 2023) showed that the graph container method is particularly well-suited for the analysis of the natural canonical tester for two fundamental graph properties: having a large independent set and $k$-colorability.","In this work, we show that the connection between the container method and property testing extends further along two different directions.   ","First, we show that the container method can be used to analyze the canonical tester for many other properties of graphs and hypergraphs.","We introduce a new hypergraph container lemma and use it to give an upper bound of $\\widetilde{O}(kq^3/\\epsilon)$ on the sample complexity of $\\epsilon$-testing satisfiability, where $q$ is the number of variables per constraint and $k$ is the size of the alphabet.","This is the first upper bound for the problem that is polynomial in all of $k$, $q$ and $1/\\epsilon$. As a corollary, we get new upper bounds on the sample complexity of the canonical testers for hypergraph colorability and for every semi-homogeneous graph partition property.   ","Second, we show that the container method can also be used to study the query complexity of (non-canonical) graph property testers.","This result is obtained by introducing a new container lemma for the class of all independent set stars, a strict superset of the class of all independent sets.","We use this container lemma to give a new upper bound of $\\widetilde{O}(\\rho^5/\\epsilon^{7/2})$ on the query complexity of $\\epsilon$-testing the $\\rho$-independent set property.","This establishes for the first time the non-optimality of the canonical tester for a non-homogeneous graph partition property."],"url":"http://arxiv.org/abs/2403.18777v1","category":"cs.DS"}
{"created":"2024-03-27 17:05:06","title":"The best approximation pair problem relative to two subsets in a normed space","abstract":"In the classical best approximation pair (BAP) problem, one is given two nonempty, closed, convex and disjoint subsets in a finite- or an infinite-dimensional Hilbert space, and the goal is to find a pair of points, each from each subset, which realizes the distance between the subsets. This problem, which has a long history, has found applications in science and technology. We discuss the problem in more general normed spaces and with possibly non-convex subsets, and focus our attention on the issues of uniqueness and existence of the solution to the problem. To the best of our knowledge these fundamental issues have not received much attention. In particular, we present several sufficient geometric conditions for the (at most) uniqueness of a BAP relative to these subsets. These conditions are related to the structure of the boundaries of the subsets, their relative orientation, and the structure of the unit sphere of the space. In addition, we present many sufficient conditions for the existence of a BAP, possibly without convexity . Our results allow us to significantly extend the horizon of the recent alternating simultaneous Halpern-Lions-Wittmann-Bauschke (A-S-HLWB) algorithm [Censor, Mansour and Reem, The alternating simultaneous Halpern-Lions-Wittmann-Bauschke algorithm for finding the best approximation pair for two disjoint intersections of convex sets, arXiv:2304.09600 (2023)] for solving the BAP problem.","sentences":["In the classical best approximation pair (BAP) problem, one is given two nonempty, closed, convex and disjoint subsets in a finite- or an infinite-dimensional Hilbert space, and the goal is to find a pair of points, each from each subset, which realizes the distance between the subsets.","This problem, which has a long history, has found applications in science and technology.","We discuss the problem in more general normed spaces and with possibly non-convex subsets, and focus our attention on the issues of uniqueness and existence of the solution to the problem.","To the best of our knowledge these fundamental issues have not received much attention.","In particular, we present several sufficient geometric conditions for the (at most) uniqueness of a BAP relative to these subsets.","These conditions are related to the structure of the boundaries of the subsets, their relative orientation, and the structure of the unit sphere of the space.","In addition, we present many sufficient conditions for the existence of a BAP, possibly without convexity .","Our results allow us to significantly extend the horizon of the recent alternating simultaneous Halpern-Lions-Wittmann-Bauschke (A-S-HLWB)","algorithm","[Censor, Mansour and Reem, The alternating simultaneous Halpern-Lions-Wittmann-Bauschke algorithm for finding the best approximation pair for two disjoint intersections of convex sets, arXiv:2304.09600 (2023)] for solving the BAP problem."],"url":"http://arxiv.org/abs/2403.18767v1","category":"math.OC"}
{"created":"2024-03-27 16:44:39","title":"Fast Decision Algorithms for Efficient Access Point Assignment in SDN-Controlled Wireless Access Networks","abstract":"Global optimization of access point (AP) assignment to user terminals requires efficient monitoring of user behavior, fast decision algorithms, efficient control signaling, and fast AP reassignment mechanisms. In this scenario, software defined networking (SDN) technology may be suitable for network monitoring, signaling, and control. We recently proposed embedding virtual switches in user terminals for direct management by an SDN controller, further contributing to SDN-oriented access network optimization. However, since users may restrict terminal-side traffic monitoring for privacy reasons (a common assumption by previous authors), we infer user traffic classes at the APs. On the other hand, since handovers will be more frequent in dense small-cell networks (e.g., mmWave-based 5G deployments will require dense network topologies with inter-site distances of ~150-200 m), the delay to take assignment decisions should be minimal. To this end, we propose taking fast decisions based exclusively on extremely simple network-side application flow-type predictions based on past user behavior. Using real data we show that a centralized allocation algorithm based on those predictions achieves network utilization levels that approximate those of optimal allocations. We also test a distributed version of this algorithm. Finally, we quantify the elapsed time since a user traffic event takes place until its terminal is assigned an AP, when needed.","sentences":["Global optimization of access point (AP) assignment to user terminals requires efficient monitoring of user behavior, fast decision algorithms, efficient control signaling, and fast AP reassignment mechanisms.","In this scenario, software defined networking (SDN) technology may be suitable for network monitoring, signaling, and control.","We recently proposed embedding virtual switches in user terminals for direct management by an SDN controller, further contributing to SDN-oriented access network optimization.","However, since users may restrict terminal-side traffic monitoring for privacy reasons (a common assumption by previous authors), we infer user traffic classes at the APs.","On the other hand, since handovers will be more frequent in dense small-cell networks (e.g., mmWave-based 5G deployments will require dense network topologies with inter-site distances of ~150-200 m), the delay to take assignment decisions should be minimal.","To this end, we propose taking fast decisions based exclusively on extremely simple network-side application flow-type predictions based on past user behavior.","Using real data we show that a centralized allocation algorithm based on those predictions achieves network utilization levels that approximate those of optimal allocations.","We also test a distributed version of this algorithm.","Finally, we quantify the elapsed time since a user traffic event takes place until its terminal is assigned an AP, when needed."],"url":"http://arxiv.org/abs/2403.18745v1","category":"cs.NI"}
{"created":"2024-03-27 16:43:08","title":"A nonsmooth Frank-Wolfe algorithm through a dual cutting-plane approach","abstract":"An extension of the Frank-Wolfe Algorithm (FWA), also known as Conditional Gradient algorithm, is proposed. In its standard form, the FWA allows to solve constrained optimization problems involving $\\beta$-smooth cost functions, calling at each iteration a Linear Minimization Oracle. More specifically, the oracle solves a problem obtained by linearization of the original cost function. The algorithm designed and investigated in this article, named Dualized Level-Set (DLS) algorithm, extends the FWA and allows to address a class of nonsmooth costs, involving in particular support functions. The key idea behind the construction of the DLS method is a general interpretation of the FWA as a cutting-plane algorithm, from the dual point of view. The DLS algorithm essentially results from a dualization of a specific cutting-plane algorithm, based on projections on some level sets. The DLS algorithm generates a sequence of primal-dual candidates, and we prove that the corresponding primal-dual gap converges with a rate of $O(1/\\sqrt{t})$.","sentences":["An extension of the Frank-Wolfe Algorithm (FWA), also known as Conditional Gradient algorithm, is proposed.","In its standard form, the FWA allows to solve constrained optimization problems involving $\\beta$-smooth cost functions, calling at each iteration a Linear Minimization Oracle.","More specifically, the oracle solves a problem obtained by linearization of the original cost function.","The algorithm designed and investigated in this article, named Dualized Level-Set (DLS) algorithm, extends the FWA and allows to address a class of nonsmooth costs, involving in particular support functions.","The key idea behind the construction of the DLS method is a general interpretation of the FWA as a cutting-plane algorithm, from the dual point of view.","The DLS algorithm essentially results from a dualization of a specific cutting-plane algorithm, based on projections on some level sets.","The DLS algorithm generates a sequence of primal-dual candidates, and we prove that the corresponding primal-dual gap converges with a rate of $O(1/\\sqrt{t})$."],"url":"http://arxiv.org/abs/2403.18744v1","category":"math.OC"}
{"created":"2024-03-27 16:25:57","title":"Optimal Rebalancing in Dynamic AMMs","abstract":"Dynamic AMM pools, as found in Temporal Function Market Making, rebalance their holdings to a new desired ratio (e.g. moving from being 50-50 between two assets to being 90-10 in favour of one of them) by introducing an arbitrage opportunity that disappears when their holdings are in line with their target. Structuring this arbitrage opportunity reduces to the problem of choosing the sequence of portfolio weights the pool exposes to the market via its trading function. Linear interpolation from start weights to end weights has been used to reduce the cost paid by pools to arbitrageurs to rebalance. Here we obtain the $\\textit{optimal}$ interpolation in the limit of small weight changes (which has the downside of requiring a call to a transcendental function) and then obtain a cheap-to-compute approximation to that optimal approach that gives almost the same performance improvement. We then demonstrate this method on a range of market backtests, including simulating pool performance when trading fees are present, finding that the new approximately-optimal method of changing weights gives robust increases in pool performance. For a BTC-ETH-DAI pool from July 2022 to June 2023, the increases of pool P\\&L from approximately-optimal weight changes is $\\sim25\\%$ for a range of different strategies and trading fees.","sentences":["Dynamic AMM pools, as found in Temporal Function Market Making, rebalance their holdings to a new desired ratio (e.g. moving from being 50-50 between two assets to being 90-10 in favour of one of them) by introducing an arbitrage opportunity that disappears when their holdings are in line with their target.","Structuring this arbitrage opportunity reduces to the problem of choosing the sequence of portfolio weights the pool exposes to the market via its trading function.","Linear interpolation from start weights to end weights has been used to reduce the cost paid by pools to arbitrageurs to rebalance.","Here we obtain the $\\textit{optimal}$ interpolation in the limit of small weight changes (which has the downside of requiring a call to a transcendental function) and then obtain a cheap-to-compute approximation to that optimal approach that gives almost the same performance improvement.","We then demonstrate this method on a range of market backtests, including simulating pool performance when trading fees are present, finding that the new approximately-optimal method of changing weights gives robust increases in pool performance.","For a BTC-ETH-DAI pool from July 2022 to June 2023, the increases of pool P\\&L from approximately-optimal weight changes is $\\sim25\\%$ for a range of different strategies and trading fees."],"url":"http://arxiv.org/abs/2403.18737v1","category":"q-fin.TR"}
{"created":"2024-03-27 16:00:48","title":"Characterization of Spatial-Temporal Channel Statistics from Indoor Measurement Data at D Band","abstract":"Millimeter-wave (mmWave) and D Band (110--170~GHz) frequencies are poised to play a pivotal role in the advancement of sixth-generation (6G) systems and beyond, owing to their ability to enhance performance metrics such as capacity, ultra-low latency, and spectral efficiency. This paper concentrates on deriving statistical insights into power, delay, and the number of paths based on measurements conducted across four distinct locations at a center frequency of 143.1 GHz. The findings underscore the suitability of various distributions in characterizing power behavior in line-of-sight (LOS) scenarios, including lognormal, Nakagami, gamma, and beta distributions, whereas the loglogistic distribution gives the optimal fit for power distribution in non-line-of-sight (NLOS) scenarios. Moreover, the exponential distribution shows to be the most appropriate model for the delay distribution in both LOS and NLOS scenarios. In terms of the number of paths, observations indicate a tendency for the highest concentration within the 10 m to 30 m distance range between the transmitter (Tx) and receiver (Rx). These insights shed light on the statistical nature of D band propagation characteristics, which are vital for informing the design and optimization of future 6G communication systems","sentences":["Millimeter-wave (mmWave) and D Band (110--170~GHz) frequencies are poised to play a pivotal role in the advancement of sixth-generation (6G) systems and beyond, owing to their ability to enhance performance metrics such as capacity, ultra-low latency, and spectral efficiency.","This paper concentrates on deriving statistical insights into power, delay, and the number of paths based on measurements conducted across four distinct locations at a center frequency of 143.1 GHz.","The findings underscore the suitability of various distributions in characterizing power behavior in line-of-sight (LOS) scenarios, including lognormal, Nakagami, gamma, and beta distributions, whereas the loglogistic distribution gives the optimal fit for power distribution in non-line-of-sight (NLOS) scenarios.","Moreover, the exponential distribution shows to be the most appropriate model for the delay distribution in both LOS and NLOS scenarios.","In terms of the number of paths, observations indicate a tendency for the highest concentration within the 10 m to 30 m distance range between the transmitter (Tx) and receiver (Rx).","These insights shed light on the statistical nature of D band propagation characteristics, which are vital for informing the design and optimization of future 6G communication systems"],"url":"http://arxiv.org/abs/2403.18713v1","category":"cs.IT"}
{"created":"2024-03-27 15:56:35","title":"Connections between Reachability and Time Optimality","abstract":"This paper presents the concept of an equivalence relation between the set of optimal control problems. By leveraging this concept, we show that the boundary of the reachability set can be constructed by the solutions of time optimal problems. Alongside, a more generalized equivalence theorem is presented together. The findings facilitate the use of solution structures from a certain class of optimal control problems to address problems in corresponding equivalent classes. As a byproduct, we state and prove the construction methods of the reachability sets of three-dimensional curves with prescribed curvature bound. The findings are twofold: Firstly, we prove that any boundary point of the reachability set, with the terminal direction taken into account, can be accessed via curves of H, CSC, CCC, or their respective subsegments, where H denotes a helicoidal arc, C a circular arc with maximum curvature, and S a straight segment. Secondly, we show that any boundary point of the reachability set, without considering the terminal direction, can be accessed by curves of CC, CS, or their respective subsegments. These findings extend the developments presented in literature regarding planar curves, or Dubins car dynamics, into spatial curves in $\\mathbb{R}^3$. For higher dimensions, we confirm that the problem of identifying the reachability set of curvature bounded paths subsumes the well-known Markov-Dubins problem. These advancements in understanding the reachability of curvature bounded paths in $\\mathbb{R}^3$ hold significant practical implications, particularly in the contexts of mission planning problems and time optimal guidance.","sentences":["This paper presents the concept of an equivalence relation between the set of optimal control problems.","By leveraging this concept, we show that the boundary of the reachability set can be constructed by the solutions of time optimal problems.","Alongside, a more generalized equivalence theorem is presented together.","The findings facilitate the use of solution structures from a certain class of optimal control problems to address problems in corresponding equivalent classes.","As a byproduct, we state and prove the construction methods of the reachability sets of three-dimensional curves with prescribed curvature bound.","The findings are twofold: Firstly, we prove that any boundary point of the reachability set, with the terminal direction taken into account, can be accessed via curves of H, CSC, CCC, or their respective subsegments, where H denotes a helicoidal arc, C a circular arc with maximum curvature, and S a straight segment.","Secondly, we show that any boundary point of the reachability set, without considering the terminal direction, can be accessed by curves of CC, CS, or their respective subsegments.","These findings extend the developments presented in literature regarding planar curves, or Dubins car dynamics, into spatial curves in $\\mathbb{R}^3$. For higher dimensions, we confirm that the problem of identifying the reachability set of curvature bounded paths subsumes the well-known Markov-Dubins problem.","These advancements in understanding the reachability of curvature bounded paths in $\\mathbb{R}^3$ hold significant practical implications, particularly in the contexts of mission planning problems and time optimal guidance."],"url":"http://arxiv.org/abs/2403.18707v1","category":"math.OC"}
{"created":"2024-03-27 15:54:55","title":"Conditional Wasserstein Distances with Applications in Bayesian OT Flow Matching","abstract":"In inverse problems, many conditional generative models approximate the posterior measure by minimizing a distance between the joint measure and its learned approximation. While this approach also controls the distance between the posterior measures in the case of the Kullback--Leibler divergence, this is in general not hold true for the Wasserstein distance. In this paper, we introduce a conditional Wasserstein distance via a set of restricted couplings that equals the expected Wasserstein distance of the posteriors. Interestingly, the dual formulation of the conditional Wasserstein-1 flow resembles losses in the conditional Wasserstein GAN literature in a quite natural way. We derive theoretical properties of the conditional Wasserstein distance, characterize the corresponding geodesics and velocity fields as well as the flow ODEs. Subsequently, we propose to approximate the velocity fields by relaxing the conditional Wasserstein distance. Based on this, we propose an extension of OT Flow Matching for solving Bayesian inverse problems and demonstrate its numerical advantages on an inverse problem and class-conditional image generation.","sentences":["In inverse problems, many conditional generative models approximate the posterior measure by minimizing a distance between the joint measure and its learned approximation.","While this approach also controls the distance between the posterior measures in the case of the Kullback--Leibler divergence, this is in general not hold true for the Wasserstein distance.","In this paper, we introduce a conditional Wasserstein distance via a set of restricted couplings that equals the expected Wasserstein distance of the posteriors.","Interestingly, the dual formulation of the conditional Wasserstein-1 flow resembles losses in the conditional Wasserstein GAN literature in a quite natural way.","We derive theoretical properties of the conditional Wasserstein distance, characterize the corresponding geodesics and velocity fields as well as the flow ODEs.","Subsequently, we propose to approximate the velocity fields by relaxing the conditional Wasserstein distance.","Based on this, we propose an extension of OT Flow Matching for solving Bayesian inverse problems and demonstrate its numerical advantages on an inverse problem and class-conditional image generation."],"url":"http://arxiv.org/abs/2403.18705v1","category":"cs.LG"}
{"created":"2024-03-27 15:44:25","title":"An Efficient Risk-aware Branch MPC for Automated Driving that is Robust to Uncertain Vehicle Behaviors","abstract":"One of the critical challenges in automated driving is ensuring safety of automated vehicles despite the unknown behavior of the other vehicles. Although motion prediction modules are able to generate a probability distribution associated with various behavior modes, their probabilistic estimates are often inaccurate, thus leading to a possibly unsafe trajectory. To overcome this challenge, we propose a risk-aware motion planning framework that appropriately accounts for the ambiguity in the estimated probability distribution. We formulate the risk-aware motion planning problem as a min-max optimization problem and develop an efficient iterative method by incorporating a regularization term in the probability update step. Via extensive numerical studies, we validate the convergence of our method and demonstrate its advantages compared to the state-of-the-art approaches.","sentences":["One of the critical challenges in automated driving is ensuring safety of automated vehicles despite the unknown behavior of the other vehicles.","Although motion prediction modules are able to generate a probability distribution associated with various behavior modes, their probabilistic estimates are often inaccurate, thus leading to a possibly unsafe trajectory.","To overcome this challenge, we propose a risk-aware motion planning framework that appropriately accounts for the ambiguity in the estimated probability distribution.","We formulate the risk-aware motion planning problem as a min-max optimization problem and develop an efficient iterative method by incorporating a regularization term in the probability update step.","Via extensive numerical studies, we validate the convergence of our method and demonstrate its advantages compared to the state-of-the-art approaches."],"url":"http://arxiv.org/abs/2403.18695v1","category":"eess.SY"}
{"created":"2024-03-27 15:22:16","title":"NL-ITI: Optimizing Probing and Intervention for Improvement of ITI Method","abstract":"Large Language Models (LLM) are prone to returning false information. It constitutes one of major challenges in the AI field. In our work, we explore paradigm introduced by Inference-Time-Intervention (ITI). In first stage, it identifies attention heads, which contain the highest amount of desired type of knowledge (e.g., truthful). Afterwards, during inference, LLM activations are shifted for chosen subset of attention heads. We further improved the ITI framework by introducing a nonlinear probing and multi-token intervention - Non-Linear ITI (NL-ITI). NL-ITI is tested on diverse multiple-choice benchmarks, including TruthfulQA, on which we report around 14% MC1 metric improvement with respect to the baseline ITI results. NL-ITI achieves also encouraging results on other testsets - on Business Ethics subdomain of MMLU, around 18% MC1 improvement over baseline LLaMA2-7B. Additionally, NL-ITI performs better while being less invasive in the behavior of LLM at the same time (as measured by Kullback-Leibler divergence).","sentences":["Large Language Models (LLM) are prone to returning false information.","It constitutes one of major challenges in the AI field.","In our work, we explore paradigm introduced by Inference-Time-Intervention (ITI).","In first stage, it identifies attention heads, which contain the highest amount of desired type of knowledge (e.g., truthful).","Afterwards, during inference, LLM activations are shifted for chosen subset of attention heads.","We further improved the ITI framework by introducing a nonlinear probing and multi-token intervention - Non-Linear ITI (NL-ITI).","NL-ITI is tested on diverse multiple-choice benchmarks, including TruthfulQA, on which we report around 14% MC1 metric improvement with respect to the baseline ITI results.","NL-ITI achieves also encouraging results on other testsets - on Business Ethics subdomain of MMLU, around 18% MC1 improvement over baseline LLaMA2-7B.","Additionally, NL-ITI performs better while being less invasive in the behavior of LLM at the same time (as measured by Kullback-Leibler divergence)."],"url":"http://arxiv.org/abs/2403.18680v1","category":"cs.CL"}
{"created":"2024-03-27 15:03:38","title":"InstructBrush: Learning Attention-based Instruction Optimization for Image Editing","abstract":"In recent years, instruction-based image editing methods have garnered significant attention in image editing. However, despite encompassing a wide range of editing priors, these methods are helpless when handling editing tasks that are challenging to accurately describe through language. We propose InstructBrush, an inversion method for instruction-based image editing methods to bridge this gap. It extracts editing effects from exemplar image pairs as editing instructions, which are further applied for image editing. Two key techniques are introduced into InstructBrush, Attention-based Instruction Optimization and Transformation-oriented Instruction Initialization, to address the limitations of the previous method in terms of inversion effects and instruction generalization. To explore the ability of instruction inversion methods to guide image editing in open scenarios, we establish a TransformationOriented Paired Benchmark (TOP-Bench), which contains a rich set of scenes and editing types. The creation of this benchmark paves the way for further exploration of instruction inversion. Quantitatively and qualitatively, our approach achieves superior performance in editing and is more semantically consistent with the target editing effects.","sentences":["In recent years, instruction-based image editing methods have garnered significant attention in image editing.","However, despite encompassing a wide range of editing priors, these methods are helpless when handling editing tasks that are challenging to accurately describe through language.","We propose InstructBrush, an inversion method for instruction-based image editing methods to bridge this gap.","It extracts editing effects from exemplar image pairs as editing instructions, which are further applied for image editing.","Two key techniques are introduced into InstructBrush, Attention-based Instruction Optimization and Transformation-oriented Instruction Initialization, to address the limitations of the previous method in terms of inversion effects and instruction generalization.","To explore the ability of instruction inversion methods to guide image editing in open scenarios, we establish a TransformationOriented Paired Benchmark (TOP-Bench), which contains a rich set of scenes and editing types.","The creation of this benchmark paves the way for further exploration of instruction inversion.","Quantitatively and qualitatively, our approach achieves superior performance in editing and is more semantically consistent with the target editing effects."],"url":"http://arxiv.org/abs/2403.18660v1","category":"cs.GR"}
{"created":"2024-03-27 14:45:41","title":"Improving Efficiency of Parallel Across the Method Spectral Deferred Corrections","abstract":"Parallel-across-the method time integration can provide small scale parallelism when solving initial value problems. Spectral deferred corrections (SDC) with a diagonal sweeper, which is closely related to iterated Runge-Kutta methods proposed by Van der Houwen and Sommeijer, can use a number of threads equal to the number of quadrature nodes in the underlying collocation method. However, convergence speed, efficiency and stability depends critically on the used coefficients. Previous approaches have used numerical optimization to find good parameters. Instead, we propose an ansatz that allows to find optimal parameters analytically. We show that the resulting parallel SDC methods provide stability domains and convergence order very similar to those of well established serial SDC variants. Using a model for computational cost that assumes 80% efficiency of an implementation of parallel SDC we show that our variants are competitive with serial SDC, previously published parallel SDC coefficients as well as Picard iteration, explicit RKM-4 and an implicit fourth-order diagonally implicit Runge-Kutta method.","sentences":["Parallel-across-the method time integration can provide small scale parallelism when solving initial value problems.","Spectral deferred corrections (SDC) with a diagonal sweeper, which is closely related to iterated Runge-Kutta methods proposed by Van der Houwen and Sommeijer, can use a number of threads equal to the number of quadrature nodes in the underlying collocation method.","However, convergence speed, efficiency and stability depends critically on the used coefficients.","Previous approaches have used numerical optimization to find good parameters.","Instead, we propose an ansatz that allows to find optimal parameters analytically.","We show that the resulting parallel SDC methods provide stability domains and convergence order very similar to those of well established serial SDC variants.","Using a model for computational cost that assumes 80% efficiency of an implementation of parallel SDC we show that our variants are competitive with serial SDC, previously published parallel SDC coefficients as well as Picard iteration, explicit RKM-4 and an implicit fourth-order diagonally implicit Runge-Kutta method."],"url":"http://arxiv.org/abs/2403.18641v1","category":"math.NA"}
{"created":"2024-03-27 14:41:39","title":"A Diffusion-Based Generative Equalizer for Music Restoration","abstract":"This paper presents a novel approach to audio restoration, focusing on the enhancement of low-quality music recordings, and in particular historical ones. Building upon a previous algorithm called BABE, or Blind Audio Bandwidth Extension, we introduce BABE-2, which presents a series of significant improvements. This research broadens the concept of bandwidth extension to \\emph{generative equalization}, a novel task that, to the best of our knowledge, has not been explicitly addressed in previous studies. BABE-2 is built around an optimization algorithm utilizing priors from diffusion models, which are trained or fine-tuned using a curated set of high-quality music tracks. The algorithm simultaneously performs two critical tasks: estimation of the filter degradation magnitude response and hallucination of the restored audio. The proposed method is objectively evaluated on historical piano recordings, showing a marked enhancement over the prior version. The method yields similarly impressive results in rejuvenating the works of renowned vocalists Enrico Caruso and Nellie Melba. This research represents an advancement in the practical restoration of historical music.","sentences":["This paper presents a novel approach to audio restoration, focusing on the enhancement of low-quality music recordings, and in particular historical ones.","Building upon a previous algorithm called BABE, or Blind Audio Bandwidth Extension, we introduce BABE-2, which presents a series of significant improvements.","This research broadens the concept of bandwidth extension to \\emph{generative equalization}, a novel task that, to the best of our knowledge, has not been explicitly addressed in previous studies.","BABE-2 is built around an optimization algorithm utilizing priors from diffusion models, which are trained or fine-tuned using a curated set of high-quality music tracks.","The algorithm simultaneously performs two critical tasks: estimation of the filter degradation magnitude response and hallucination of the restored audio.","The proposed method is objectively evaluated on historical piano recordings, showing a marked enhancement over the prior version.","The method yields similarly impressive results in rejuvenating the works of renowned vocalists Enrico Caruso and Nellie Melba.","This research represents an advancement in the practical restoration of historical music."],"url":"http://arxiv.org/abs/2403.18636v1","category":"eess.AS"}
{"created":"2024-03-27 14:38:22","title":"Optimal Control Synthesis of Markov Decision Processes for Efficiency with Surveillance Tasks","abstract":"We investigate the problem of optimal control synthesis for Markov Decision Processes (MDPs), addressing both qualitative and quantitative objectives. Specifically, we require the system to fulfill a qualitative surveillance task in the sense that a specific region of interest can be visited infinitely often with probability one. Furthermore, to quantify the performance of the system, we consider the concept of efficiency, which is defined as the ratio between rewards and costs. This measure is more general than the standard long-run average reward metric as it aims to maximize the reward obtained per unit cost. Our objective is to synthesize a control policy that ensures the surveillance task while maximizes the efficiency. We provide an effective approach to synthesize a stationary control policy achieving $\\epsilon$-optimality by integrating state classifications of MDPs and perturbation analysis in a novel manner. Our results generalize existing works on efficiency-optimal control synthesis for MDP by incorporating qualitative surveillance tasks. A robot motion planning case study is provided to illustrate the proposed algorithm.","sentences":["We investigate the problem of optimal control synthesis for Markov Decision Processes (MDPs), addressing both qualitative and quantitative objectives.","Specifically, we require the system to fulfill a qualitative surveillance task in the sense that a specific region of interest can be visited infinitely often with probability one.","Furthermore, to quantify the performance of the system, we consider the concept of efficiency, which is defined as the ratio between rewards and costs.","This measure is more general than the standard long-run average reward metric as it aims to maximize the reward obtained per unit cost.","Our objective is to synthesize a control policy that ensures the surveillance task while maximizes the efficiency.","We provide an effective approach to synthesize a stationary control policy achieving $\\epsilon$-optimality by integrating state classifications of MDPs and perturbation analysis in a novel manner.","Our results generalize existing works on efficiency-optimal control synthesis for MDP by incorporating qualitative surveillance tasks.","A robot motion planning case study is provided to illustrate the proposed algorithm."],"url":"http://arxiv.org/abs/2403.18632v1","category":"eess.SY"}
{"created":"2024-03-27 14:32:30","title":"Accelerating preconditioned ADMM via degenerate proximal point mappings","abstract":"In this paper, we aim to accelerate a preconditioned alternating direction method of multipliers (pADMM), whose proximal terms are convex quadratic functions, for solving linearly constrained convex optimization problems. To achieve this, we first reformulate the pADMM into a form of proximal point method (PPM) with a positive semidefinite preconditioner which can be degenerate due to the lack of strong convexity of the proximal terms in the pADMM. Then we accelerate the pADMM by accelerating the reformulated degenerate PPM (dPPM). Specifically, we first propose an accelerated dPPM by integrating the Halpern iteration and the fast Krasnosel'ski\\u{i}-Mann iteration into it, achieving asymptotic $o(1/k)$ and non-asymptotic $O(1/k)$ convergence rates. Subsequently, building upon the accelerated dPPM, we develop an accelerated pADMM algorithm that exhibits both asymptotic $o(1/k)$ and non-asymptotic $O(1/k)$ nonergodic convergence rates concerning the Karush-Kuhn-Tucker residual and the primal objective function value gap. Preliminary numerical experiments validate the theoretical findings, demonstrating that the accelerated pADMM outperforms the pADMM in solving convex quadratic programming problems.","sentences":["In this paper, we aim to accelerate a preconditioned alternating direction method of multipliers (pADMM), whose proximal terms are convex quadratic functions, for solving linearly constrained convex optimization problems.","To achieve this, we first reformulate the pADMM into a form of proximal point method (PPM) with a positive semidefinite preconditioner which can be degenerate due to the lack of strong convexity of the proximal terms in the pADMM.","Then we accelerate the pADMM by accelerating the reformulated degenerate PPM (dPPM).","Specifically, we first propose an accelerated dPPM by integrating the Halpern iteration and the fast Krasnosel'ski\\u{i}-Mann iteration into it, achieving asymptotic $o(1/k)$ and non-asymptotic $O(1/k)$ convergence rates.","Subsequently, building upon the accelerated dPPM, we develop an accelerated pADMM algorithm that exhibits both asymptotic $o(1/k)$ and non-asymptotic $O(1/k)$ nonergodic convergence rates concerning the Karush-Kuhn-Tucker residual and the primal objective function value gap.","Preliminary numerical experiments validate the theoretical findings, demonstrating that the accelerated pADMM outperforms the pADMM in solving convex quadratic programming problems."],"url":"http://arxiv.org/abs/2403.18618v1","category":"math.OC"}
{"created":"2024-03-27 14:32:03","title":"Quantum concentration inequalities and equivalence of the thermodynamical ensembles: an optimal mass transport approach","abstract":"We prove new concentration inequalities for quantum spin systems which apply to any local observable measured on any product state or on any state with exponentially decaying correlations. Our results do not require the spins to be arranged in a regular lattice, and cover the case of observables that contain terms acting on spins at arbitrary distance. Moreover, we introduce a local W1 distance, which quantifies the distinguishability of two states with respect to local observables. We prove a transportation-cost inequality stating that the local W1 distance between a generic state and a state with exponentially decaying correlations is upper bounded by a function of their relative entropy. Finally, we apply such inequality to prove the equivalence between the canonical and microcanonical ensembles of quantum statistical mechanics and the weak eigenstate thermalization hypothesis for the Hamiltonians whose Gibbs states have exponentially decaying correlations.","sentences":["We prove new concentration inequalities for quantum spin systems which apply to any local observable measured on any product state or on any state with exponentially decaying correlations.","Our results do not require the spins to be arranged in a regular lattice, and cover the case of observables that contain terms acting on spins at arbitrary distance.","Moreover, we introduce a local W1 distance, which quantifies the distinguishability of two states with respect to local observables.","We prove a transportation-cost inequality stating that the local W1 distance between a generic state and a state with exponentially decaying correlations is upper bounded by a function of their relative entropy.","Finally, we apply such inequality to prove the equivalence between the canonical and microcanonical ensembles of quantum statistical mechanics and the weak eigenstate thermalization hypothesis for the Hamiltonians whose Gibbs states have exponentially decaying correlations."],"url":"http://arxiv.org/abs/2403.18617v1","category":"math-ph"}
{"created":"2024-03-27 14:10:01","title":"Quantum backflow current in a ring: Optimal bounds and fractality","abstract":"The probability density of a quantum particle moving freely within a circular ring can exhibit local flow patterns inconsistent with its angular momentum, a phenomenon known as quantum backflow. In this study, we examine a quantum particle confined to a ring and prepared in a state composed of a fixed (yet arbitrary) number of lowest energy eigenstates with non-negative angular momentum. We investigate the time-dependent behavior of the probability current at a specified point along the ring's circumference. We establish precise lower and upper bounds for this probability current, thereby delineating the exact scope of the quantum backflow effect. We also present an analytical expression for a quantum state that yields a record-high backflow probability transfer, reaching over 95% of the theoretical bound. Furthermore, our investigation yields compelling numerical and analytical evidence supporting the conjecture that the current-versus-time function associated with states maximizing backflow probability transfer forms a fractal curve with a dimension of 7/4. The observed fractality may provide a characteristic, experimentally-relevant signature of quantum backflow near the probability-transfer bound.","sentences":["The probability density of a quantum particle moving freely within a circular ring can exhibit local flow patterns inconsistent with its angular momentum, a phenomenon known as quantum backflow.","In this study, we examine a quantum particle confined to a ring and prepared in a state composed of a fixed (yet arbitrary) number of lowest energy eigenstates with non-negative angular momentum.","We investigate the time-dependent behavior of the probability current at a specified point along the ring's circumference.","We establish precise lower and upper bounds for this probability current, thereby delineating the exact scope of the quantum backflow effect.","We also present an analytical expression for a quantum state that yields a record-high backflow probability transfer, reaching over 95% of the theoretical bound.","Furthermore, our investigation yields compelling numerical and analytical evidence supporting the conjecture that the current-versus-time function associated with states maximizing backflow probability transfer forms a fractal curve with a dimension of 7/4.","The observed fractality may provide a characteristic, experimentally-relevant signature of quantum backflow near the probability-transfer bound."],"url":"http://arxiv.org/abs/2403.18586v1","category":"quant-ph"}
{"created":"2024-03-27 13:52:41","title":"Bootstrapping Guarantees: Stability and Performance Analysis for Dynamic Encrypted Control","abstract":"Encrypted dynamic controllers that operate for an unlimited time have been a challenging subject of research. The fundamental difficulty is the accumulation of errors and scaling factors in the internal state during operation. Bootstrapping, a technique commonly employed in fully homomorphic cryptosystems, can be used to avoid overflows in the controller state but can potentially introduce significant numerical errors. In this paper, we analyze dynamic encrypted control with explicit consideration of bootstrapping. By recognizing the bootstrapping errors occurring in the controller's state as an uncertainty in the robust control framework, we can provide stability and performance guarantees for the whole encrypted control system. Further, the conservatism of the stability and performance test is reduced by using a lifted version of the control system.","sentences":["Encrypted dynamic controllers that operate for an unlimited time have been a challenging subject of research.","The fundamental difficulty is the accumulation of errors and scaling factors in the internal state during operation.","Bootstrapping, a technique commonly employed in fully homomorphic cryptosystems, can be used to avoid overflows in the controller state but can potentially introduce significant numerical errors.","In this paper, we analyze dynamic encrypted control with explicit consideration of bootstrapping.","By recognizing the bootstrapping errors occurring in the controller's state as an uncertainty in the robust control framework, we can provide stability and performance guarantees for the whole encrypted control system.","Further, the conservatism of the stability and performance test is reduced by using a lifted version of the control system."],"url":"http://arxiv.org/abs/2403.18571v1","category":"eess.SY"}
{"created":"2024-03-27 13:46:01","title":"Artifact Reduction in 3D and 4D Cone-beam Computed Tomography Images with Deep Learning -- A Review","abstract":"Deep learning based approaches have been used to improve image quality in cone-beam computed tomography (CBCT), a medical imaging technique often used in applications such as image-guided radiation therapy, implant dentistry or orthopaedics. In particular, while deep learning methods have been applied to reduce various types of CBCT image artifacts arising from motion, metal objects, or low-dose acquisition, a comprehensive review summarizing the successes and shortcomings of these approaches, with a primary focus on the type of artifacts rather than the architecture of neural networks, is lacking in the literature. In this review, the data generation and simulation pipelines, and artifact reduction techniques are specifically investigated for each type of artifact. We provide an overview of deep learning techniques that have successfully been shown to reduce artifacts in 3D, as well as in time-resolved (4D) CBCT through the use of projection- and/or volume-domain optimizations, or by introducing neural networks directly within the CBCT reconstruction algorithms. Research gaps are identified to suggest avenues for future exploration. One of the key findings of this work is an observed trend towards the use of generative models including GANs and score-based or diffusion models, accompanied with the need for more diverse and open training datasets and simulations.","sentences":["Deep learning based approaches have been used to improve image quality in cone-beam computed tomography (CBCT), a medical imaging technique often used in applications such as image-guided radiation therapy, implant dentistry or orthopaedics.","In particular, while deep learning methods have been applied to reduce various types of CBCT image artifacts arising from motion, metal objects, or low-dose acquisition, a comprehensive review summarizing the successes and shortcomings of these approaches, with a primary focus on the type of artifacts rather than the architecture of neural networks, is lacking in the literature.","In this review, the data generation and simulation pipelines, and artifact reduction techniques are specifically investigated for each type of artifact.","We provide an overview of deep learning techniques that have successfully been shown to reduce artifacts in 3D, as well as in time-resolved (4D) CBCT through the use of projection- and/or volume-domain optimizations, or by introducing neural networks directly within the CBCT reconstruction algorithms.","Research gaps are identified to suggest avenues for future exploration.","One of the key findings of this work is an observed trend towards the use of generative models including GANs and score-based or diffusion models, accompanied with the need for more diverse and open training datasets and simulations."],"url":"http://arxiv.org/abs/2403.18565v1","category":"cs.CV"}
{"created":"2024-03-27 13:39:06","title":"Stability Properties of the Impulsive Goodwin's Oscillator in 1-cycle","abstract":"The Impulsive Goodwin's Oscillator (IGO) is a mathematical model of a hybrid closed-loop system. It arises by closing a special kind of continuous linear positive time-invariant system with impulsive feedback, which employs both amplitude and frequency pulse modulation. The structure of IGO precludes the existence of equilibria, and all its solutions are oscillatory. With its origin in mathematical biology, the IGO also presents a control paradigm useful in a wide range of applications, in particular dosing of chemicals and medicines. Since the pulse modulation feedback mechanism introduces significant nonlinearity and non-smoothness in the closedloop dynamics, conventional controller design methods fail to apply. However, the hybrid dynamics of IGO reduce to a nonlinear, time-invariant discrete-time system, exhibiting a one-to-one correspondence between periodic solutions of the original IGO and those of the discrete-time system. The paper proposes a design approach that leverages the linearization of the equivalent discrete-time dynamics in the vicinity of a fixed point. A simple and efficient local stability condition of the 1-cycle in terms of the characteristics of the amplitude and frequency modulation functions is obtained.","sentences":["The Impulsive Goodwin's Oscillator (IGO) is a mathematical model of a hybrid closed-loop system.","It arises by closing a special kind of continuous linear positive time-invariant system with impulsive feedback, which employs both amplitude and frequency pulse modulation.","The structure of IGO precludes the existence of equilibria, and all its solutions are oscillatory.","With its origin in mathematical biology, the IGO also presents a control paradigm useful in a wide range of applications, in particular dosing of chemicals and medicines.","Since the pulse modulation feedback mechanism introduces significant nonlinearity and non-smoothness in the closedloop dynamics, conventional controller design methods fail to apply.","However, the hybrid dynamics of IGO reduce to a nonlinear, time-invariant discrete-time system, exhibiting a one-to-one correspondence between periodic solutions of the original IGO and those of the discrete-time system.","The paper proposes a design approach that leverages the linearization of the equivalent discrete-time dynamics in the vicinity of a fixed point.","A simple and efficient local stability condition of the 1-cycle in terms of the characteristics of the amplitude and frequency modulation functions is obtained."],"url":"http://arxiv.org/abs/2403.18557v1","category":"math.OC"}
{"created":"2024-03-27 13:37:12","title":"Numerical optimisation of Dirac eigenvalues","abstract":"Motivated by relativistic materials, we develop a numerical scheme to support existing or state new conjectures in the spectral optimisation of eigenvalues of the Dirac operator, subject to infinite-mass boundary conditions. We study the optimality of the regular polygon (respectively, disk) among all polygons of a given number of sides (respectively, arbitrary sets), subject to area or perimeter constraints. We consider the three lowest positive eigenvalues and their ratios. Roughly, we find results analogous to known or expected for the Dirichlet Laplacian, except for the third eigenvalue which does not need to be minimised by the regular polygon (respectively, the disk) for all masses. In addition to the numerical results, a new, mass-dependent upper bound to the lowest eigenvalue in rectangles is proved and its extension to arbitrary quadrilaterals is conjectured.","sentences":["Motivated by relativistic materials, we develop a numerical scheme to support existing or state new conjectures in the spectral optimisation of eigenvalues of the Dirac operator, subject to infinite-mass boundary conditions.","We study the optimality of the regular polygon (respectively, disk) among all polygons of a given number of sides (respectively, arbitrary sets), subject to area or perimeter constraints.","We consider the three lowest positive eigenvalues and their ratios.","Roughly, we find results analogous to known or expected for the Dirichlet Laplacian, except for the third eigenvalue which does not need to be minimised by the regular polygon (respectively, the disk) for all masses.","In addition to the numerical results, a new, mass-dependent upper bound to the lowest eigenvalue in rectangles is proved and its extension to arbitrary quadrilaterals is conjectured."],"url":"http://arxiv.org/abs/2403.18556v1","category":"math.OC"}
{"created":"2024-03-27 13:32:12","title":"Generalized convergence of the deep BSDE method: a step towards fully-coupled FBSDEs and applications in stochastic control","abstract":"We are concerned with high-dimensional coupled FBSDE systems approximated by the deep BSDE method of Han et al. (2018). It was shown by Han and Long (2020) that the errors induced by the deep BSDE method admit a posteriori estimate depending on the loss function, whenever the backward equation only couples into the forward diffusion through the Y process. We generalize this result to fully-coupled drift coefficients, and give sufficient conditions for convergence under standard assumptions. The resulting conditions are directly verifiable for any equation. Consequently, unlike in earlier theory, our convergence analysis enables the treatment of FBSDEs stemming from stochastic optimal control problems. In particular, we provide a theoretical justification for the non-convergence of the deep BSDE method observed in recent literature, and present direct guidelines for when convergence can be guaranteed in practice. Our theoretical findings are supported by several numerical experiments in high-dimensional settings.","sentences":["We are concerned with high-dimensional coupled FBSDE systems approximated by the deep BSDE method of Han et al.","(2018).","It was shown by Han and Long (2020) that the errors induced by the deep BSDE method admit a posteriori estimate depending on the loss function, whenever the backward equation only couples into the forward diffusion through the Y process.","We generalize this result to fully-coupled drift coefficients, and give sufficient conditions for convergence under standard assumptions.","The resulting conditions are directly verifiable for any equation.","Consequently, unlike in earlier theory, our convergence analysis enables the treatment of FBSDEs stemming from stochastic optimal control problems.","In particular, we provide a theoretical justification for the non-convergence of the deep BSDE method observed in recent literature, and present direct guidelines for when convergence can be guaranteed in practice.","Our theoretical findings are supported by several numerical experiments in high-dimensional settings."],"url":"http://arxiv.org/abs/2403.18552v1","category":"math.NA"}
{"created":"2024-03-27 13:24:56","title":"Optimal Resource Efficiency with Fairness in Heterogeneous GPU Clusters","abstract":"Ensuring the highest training throughput to maximize resource efficiency, while maintaining fairness among users, is critical for deep learning (DL) training in heterogeneous GPU clusters. However, current DL schedulers provide only limited fairness properties and suboptimal training throughput, impeding tenants from effectively leveraging heterogeneous resources. The underlying design challenge stems from inherent conflicts between efficiency and fairness properties.   In this paper, we introduce OEF, a new resource allocation framework specifically developed for achieving optimal resource efficiency and ensuring diverse fairness properties in heterogeneous GPU clusters. By integrating resource efficiency and fairness within a global optimization framework, OEF is capable of providing users with maximized overall efficiency, as well as various guarantees of fairness, in both cooperative and non-cooperative environments. We have implemented OEF in a cluster resource manager and conducted large-scale experiments, showing that OEF can improve the overall training throughput by up to 32% while improving fairness compared to state-of-the-art heterogeneity-aware schedulers.","sentences":["Ensuring the highest training throughput to maximize resource efficiency, while maintaining fairness among users, is critical for deep learning (DL) training in heterogeneous GPU clusters.","However, current DL schedulers provide only limited fairness properties and suboptimal training throughput, impeding tenants from effectively leveraging heterogeneous resources.","The underlying design challenge stems from inherent conflicts between efficiency and fairness properties.   ","In this paper, we introduce OEF, a new resource allocation framework specifically developed for achieving optimal resource efficiency and ensuring diverse fairness properties in heterogeneous GPU clusters.","By integrating resource efficiency and fairness within a global optimization framework, OEF is capable of providing users with maximized overall efficiency, as well as various guarantees of fairness, in both cooperative and non-cooperative environments.","We have implemented OEF in a cluster resource manager and conducted large-scale experiments, showing that OEF can improve the overall training throughput by up to 32% while improving fairness compared to state-of-the-art heterogeneity-aware schedulers."],"url":"http://arxiv.org/abs/2403.18545v1","category":"cs.DC"}
{"created":"2024-03-27 13:17:15","title":"skscope: Fast Sparsity-Constrained Optimization in Python","abstract":"Applying iterative solvers on sparsity-constrained optimization (SCO) requires tedious mathematical deduction and careful programming/debugging that hinders these solvers' broad impact. In the paper, the library skscope is introduced to overcome such an obstacle. With skscope, users can solve the SCO by just programming the objective function. The convenience of skscope is demonstrated through two examples in the paper, where sparse linear regression and trend filtering are addressed with just four lines of code. More importantly, skscope's efficient implementation allows state-of-the-art solvers to quickly attain the sparse solution regardless of the high dimensionality of parameter space. Numerical experiments reveal the available solvers in skscope can achieve up to 80x speedup on the competing relaxation solutions obtained via the benchmarked convex solver. skscope is published on the Python Package Index (PyPI) and Conda, and its source code is available at: https://github.com/abess-team/skscope.","sentences":["Applying iterative solvers on sparsity-constrained optimization (SCO) requires tedious mathematical deduction and careful programming/debugging that hinders these solvers' broad impact.","In the paper, the library skscope is introduced to overcome such an obstacle.","With skscope, users can solve the SCO by just programming the objective function.","The convenience of skscope is demonstrated through two examples in the paper, where sparse linear regression and trend filtering are addressed with just four lines of code.","More importantly, skscope's efficient implementation allows state-of-the-art solvers to quickly attain the sparse solution regardless of the high dimensionality of parameter space.","Numerical experiments reveal the available solvers in skscope can achieve up to 80x speedup on the competing relaxation solutions obtained via the benchmarked convex solver.","skscope is published on the Python Package Index (PyPI) and Conda, and its source code is available at: https://github.com/abess-team/skscope."],"url":"http://arxiv.org/abs/2403.18540v1","category":"stat.ML"}
{"created":"2024-03-27 13:00:10","title":"Limited Attention Allocation in a Stochastic Linear Quadratic System with Multiplicative Noise","abstract":"This study addresses limited attention allocation in a stochastic linear quadratic system with multiplicative noise. Our approach enables strategic resource allocation to enhance noise estimation and improve control decisions. We provide analytical optimal control and propose a numerical method for optimal attention allocation. Additionally, we apply our ffndings to dynamic mean-variance portfolio selection, showing effective resource allocation across time periods and factors, providing valuable insights for investors.","sentences":["This study addresses limited attention allocation in a stochastic linear quadratic system with multiplicative noise.","Our approach enables strategic resource allocation to enhance noise estimation and improve control decisions.","We provide analytical optimal control and propose a numerical method for optimal attention allocation.","Additionally, we apply our ffndings to dynamic mean-variance portfolio selection, showing effective resource allocation across time periods and factors, providing valuable insights for investors."],"url":"http://arxiv.org/abs/2403.18528v1","category":"math.OC"}
{"created":"2024-03-27 12:49:53","title":"Non-empirical prediction of the length-dependent ionization potential in molecular chains","abstract":"The ionization potential of molecular chains is well-known to be a tunable nano-scale property that exhibits clear quantum confinement effects. State-of-the-art methods can accurately predict the ionization potential in the small molecule limit and in the solid-state limit, but for intermediate, nano-sized systems prediction of the evolution of the electronic structure between the two limits is more difficult. Recently, optimal tuning of range-separated hybrid functionals has emerged as a highly accurate method for predicting ionization potentials. This was first achieved for molecules using the ionization potential theorem (IPT) and more recently extended to solid-state systems, based on an \\textit{ansatz} that generalizes the IPT to the removal of charge from a localized Wannier function. Here, we study one-dimensional molecular chains of increasing size, from the monomer limit to the infinite polymer limit using this approach. By comparing our results with other localization-based methods and where available with experiment, we demonstrate that Wannier-localization-based optimal tuning is highly accurate in predicting ionization potentials for any chain length, including the nano-scale regime.","sentences":["The ionization potential of molecular chains is well-known to be a tunable nano-scale property that exhibits clear quantum confinement effects.","State-of-the-art methods can accurately predict the ionization potential in the small molecule limit and in the solid-state limit, but for intermediate, nano-sized systems prediction of the evolution of the electronic structure between the two limits is more difficult.","Recently, optimal tuning of range-separated hybrid functionals has emerged as a highly accurate method for predicting ionization potentials.","This was first achieved for molecules using the ionization potential theorem (IPT) and more recently extended to solid-state systems, based on an \\textit{ansatz} that generalizes the IPT to the removal of charge from a localized Wannier function.","Here, we study one-dimensional molecular chains of increasing size, from the monomer limit to the infinite polymer limit using this approach.","By comparing our results with other localization-based methods and where available with experiment, we demonstrate that Wannier-localization-based optimal tuning is highly accurate in predicting ionization potentials for any chain length, including the nano-scale regime."],"url":"http://arxiv.org/abs/2403.18518v1","category":"physics.chem-ph"}
{"created":"2024-03-27 12:49:14","title":"Efficient Algorithms for Regularized Nonnegative Scale-invariant Low-rank Approximation Models","abstract":"Regularized nonnegative low-rank approximations such as sparse Nonnegative Matrix Factorization or sparse Nonnegative Tucker Decomposition are an important branch of dimensionality reduction models with enhanced interpretability. However, from a practical perspective, the choice of regularizers and regularization coefficients, as well as the design of efficient algorithms, is challenging because of the multifactor nature of these models and the lack of theory to back these choices. This paper aims at improving upon these issues. By studying a more general model called the Homogeneous Regularized Scale-Invariant, we prove that the scale-invariance inherent to low-rank approximation models causes an implicit regularization with both unexpected beneficial and detrimental effects. This observation allows to better understand the effect of regularization functions in low-rank approximation models, to guide the choice of the regularization hyperparameters, and to design balancing strategies to enhance the convergence speed of dedicated optimization algorithms. Some of these results were already known but restricted to specific instances of regularized low-rank approximations. We also derive a generic Majorization Minimization algorithm that handles many regularized nonnegative low-rank approximations, with convergence guarantees. We showcase our contributions on sparse Nonnegative Matrix Factorization, ridge-regularized Canonical Polyadic decomposition and sparse Nonnegative Tucker Decomposition.","sentences":["Regularized nonnegative low-rank approximations such as sparse Nonnegative Matrix Factorization or sparse Nonnegative Tucker Decomposition are an important branch of dimensionality reduction models with enhanced interpretability.","However, from a practical perspective, the choice of regularizers and regularization coefficients, as well as the design of efficient algorithms, is challenging because of the multifactor nature of these models and the lack of theory to back these choices.","This paper aims at improving upon these issues.","By studying a more general model called the Homogeneous Regularized Scale-Invariant, we prove that the scale-invariance inherent to low-rank approximation models causes an implicit regularization with both unexpected beneficial and detrimental effects.","This observation allows to better understand the effect of regularization functions in low-rank approximation models, to guide the choice of the regularization hyperparameters, and to design balancing strategies to enhance the convergence speed of dedicated optimization algorithms.","Some of these results were already known but restricted to specific instances of regularized low-rank approximations.","We also derive a generic Majorization Minimization algorithm that handles many regularized nonnegative low-rank approximations, with convergence guarantees.","We showcase our contributions on sparse Nonnegative Matrix Factorization, ridge-regularized Canonical Polyadic decomposition and sparse Nonnegative Tucker Decomposition."],"url":"http://arxiv.org/abs/2403.18517v1","category":"cs.LG"}
{"created":"2024-03-27 12:39:16","title":"Distributed Maximum Consensus over Noisy Links","abstract":"We introduce a distributed algorithm, termed noise-robust distributed maximum consensus (RD-MC), for estimating the maximum value within a multi-agent network in the presence of noisy communication links. Our approach entails redefining the maximum consensus problem as a distributed optimization problem, allowing a solution using the alternating direction method of multipliers. Unlike existing algorithms that rely on multiple sets of noise-corrupted estimates, RD-MC employs a single set, enhancing both robustness and efficiency. To further mitigate the effects of link noise and improve robustness, we apply moving averaging to the local estimates. Through extensive simulations, we demonstrate that RD-MC is significantly more robust to communication link noise compared to existing maximum-consensus algorithms.","sentences":["We introduce a distributed algorithm, termed noise-robust distributed maximum consensus (RD-MC), for estimating the maximum value within a multi-agent network in the presence of noisy communication links.","Our approach entails redefining the maximum consensus problem as a distributed optimization problem, allowing a solution using the alternating direction method of multipliers.","Unlike existing algorithms that rely on multiple sets of noise-corrupted estimates, RD-MC employs a single set, enhancing both robustness and efficiency.","To further mitigate the effects of link noise and improve robustness, we apply moving averaging to the local estimates.","Through extensive simulations, we demonstrate that RD-MC is significantly more robust to communication link noise compared to existing maximum-consensus algorithms."],"url":"http://arxiv.org/abs/2403.18509v1","category":"cs.DC"}
{"created":"2024-03-27 12:10:30","title":"Learning in PINNs: Phase transition, total diffusion, and generalization","abstract":"We investigate the learning dynamics of fully-connected neural networks through the lens of gradient signal-to-noise ratio (SNR), examining the behavior of first-order optimizers like Adam in non-convex objectives. By interpreting the drift/diffusion phases in the information bottleneck theory, focusing on gradient homogeneity, we identify a third phase termed ``total diffusion\", characterized by equilibrium in the learning rates and homogeneous gradients. This phase is marked by an abrupt SNR increase, uniform residuals across the sample space and the most rapid training convergence. We propose a residual-based re-weighting scheme to accelerate this diffusion in quadratic loss functions, enhancing generalization. We also explore the information compression phenomenon, pinpointing a significant saturation-induced compression of activations at the total diffusion phase, with deeper layers experiencing negligible information loss. Supported by experimental data on physics-informed neural networks (PINNs), which underscore the importance of gradient homogeneity due to their PDE-based sample inter-dependence, our findings suggest that recognizing phase transitions could refine ML optimization strategies for improved generalization.","sentences":["We investigate the learning dynamics of fully-connected neural networks through the lens of gradient signal-to-noise ratio (SNR), examining the behavior of first-order optimizers like Adam in non-convex objectives.","By interpreting the drift/diffusion phases in the information bottleneck theory, focusing on gradient homogeneity, we identify a third phase termed ``total diffusion\", characterized by equilibrium in the learning rates and homogeneous gradients.","This phase is marked by an abrupt SNR increase, uniform residuals across the sample space and the most rapid training convergence.","We propose a residual-based re-weighting scheme to accelerate this diffusion in quadratic loss functions, enhancing generalization.","We also explore the information compression phenomenon, pinpointing a significant saturation-induced compression of activations at the total diffusion phase, with deeper layers experiencing negligible information loss.","Supported by experimental data on physics-informed neural networks (PINNs), which underscore the importance of gradient homogeneity due to their PDE-based sample inter-dependence, our findings suggest that recognizing phase transitions could refine ML optimization strategies for improved generalization."],"url":"http://arxiv.org/abs/2403.18494v1","category":"cs.LG"}
{"created":"2024-03-27 11:56:17","title":"Existence and role of low energy charge-paramagnon modes in the strange metal phase of Bi$_2$Sr$_2$CaCu$_2$O$_{8+y}$","abstract":"The strange metal phase is characteristic for the $T$-linear dc resistivity behaviour over a large $T$-range. The effect of the strength of the charge-paramagnon interactions on the charge fluctuations in optimally doped and underdoped regions of Bi$_2$Sr$_2$CaCu$_2$O$_{8+y}$ (Bi-2212) may shine light on the anomalous behaviour of the optical conductivity response in the energy range 50 - 500 meV. We present a preliminary analysis of a single initial run of electron energy loss spectroscopy (EELS) measurements done in a scanning transmission electron microscope (STEM) which exhibit linear dispersive modes separated by 50 meV energy gaps up to 250 meV in optimally doped Bi-2212. Our observations show similarities with the fluctuating stripes as predicted by Zaanen.","sentences":["The strange metal phase is characteristic for the $T$-linear dc resistivity behaviour over a large $T$-range.","The effect of the strength of the charge-paramagnon interactions on the charge fluctuations in optimally doped and underdoped regions of Bi$_2$Sr$_2$CaCu$_2$O$_{8+y}$ (Bi-2212) may shine light on the anomalous behaviour of the optical conductivity response in the energy range 50 - 500 meV.","We present a preliminary analysis of a single initial run of electron energy loss spectroscopy (EELS) measurements done in a scanning transmission electron microscope (STEM) which exhibit linear dispersive modes separated by 50 meV energy gaps up to 250 meV in optimally doped Bi-2212.","Our observations show similarities with the fluctuating stripes as predicted by Zaanen."],"url":"http://arxiv.org/abs/2403.18483v1","category":"cond-mat.str-el"}
{"created":"2024-03-27 11:49:55","title":"Lightweight Embeddings for Graph Collaborative Filtering","abstract":"Graph neural networks (GNNs) are currently one of the most performant collaborative filtering methods. Meanwhile, owing to the use of an embedding table to represent each user/item as a distinct vector, GNN-based recommenders have inherited the long-standing defect of parameter inefficiency. As a common practice for scalable embeddings, parameter sharing enables the use of fewer embedding vectors (i.e., meta-embeddings). When assigning meta-embeddings, most existing methods are a heuristically designed, predefined mapping from each user's/item's ID to the corresponding meta-embedding indexes, thus simplifying the optimization problem into learning only the meta-embeddings. However, in the context of GNN-based collaborative filtering, such a fixed mapping omits the semantic correlations between entities that are evident in the user-item interaction graph, leading to suboptimal recommendation performance. To this end, we propose Lightweight Embeddings for Graph Collaborative Filtering (LEGCF), a parameter-efficient embedding framework dedicated to GNN-based recommenders. LEGCF innovatively introduces an assignment matrix as an extra learnable component on top of meta-embeddings. To jointly optimize these two heavily entangled components, aside from learning the meta-embeddings by minimizing the recommendation loss, LEGCF further performs efficient assignment update by enforcing a novel semantic similarity constraint and finding its closed-form solution based on matrix pseudo-inverse. The meta-embeddings and assignment matrix are alternately updated, where the latter is sparsified on the fly to ensure negligible storage overhead. Extensive experiments on three benchmark datasets have verified LEGCF's smallest trade-off between size and performance, with consistent accuracy gain over state-of-the-art baselines. The codebase of LEGCF is available in https://github.com/xurong-liang/LEGCF.","sentences":["Graph neural networks (GNNs) are currently one of the most performant collaborative filtering methods.","Meanwhile, owing to the use of an embedding table to represent each user/item as a distinct vector, GNN-based recommenders have inherited the long-standing defect of parameter inefficiency.","As a common practice for scalable embeddings, parameter sharing enables the use of fewer embedding vectors (i.e., meta-embeddings).","When assigning meta-embeddings, most existing methods are a heuristically designed, predefined mapping from each user's/item's ID to the corresponding meta-embedding indexes, thus simplifying the optimization problem into learning only the meta-embeddings.","However, in the context of GNN-based collaborative filtering, such a fixed mapping omits the semantic correlations between entities that are evident in the user-item interaction graph, leading to suboptimal recommendation performance.","To this end, we propose Lightweight Embeddings for Graph Collaborative Filtering (LEGCF), a parameter-efficient embedding framework dedicated to GNN-based recommenders.","LEGCF innovatively introduces an assignment matrix as an extra learnable component on top of meta-embeddings.","To jointly optimize these two heavily entangled components, aside from learning the meta-embeddings by minimizing the recommendation loss, LEGCF further performs efficient assignment update by enforcing a novel semantic similarity constraint and finding its closed-form solution based on matrix pseudo-inverse.","The meta-embeddings and assignment matrix are alternately updated, where the latter is sparsified on the fly to ensure negligible storage overhead.","Extensive experiments on three benchmark datasets have verified LEGCF's smallest trade-off between size and performance, with consistent accuracy gain over state-of-the-art baselines.","The codebase of LEGCF is available in https://github.com/xurong-liang/LEGCF."],"url":"http://arxiv.org/abs/2403.18479v2","category":"cs.IR"}
{"created":"2024-03-27 11:45:08","title":"Modeling uncertainty for Gaussian Splatting","abstract":"We present Stochastic Gaussian Splatting (SGS): the first framework for uncertainty estimation using Gaussian Splatting (GS). GS recently advanced the novel-view synthesis field by achieving impressive reconstruction quality at a fraction of the computational cost of Neural Radiance Fields (NeRF). However, contrary to the latter, it still lacks the ability to provide information about the confidence associated with their outputs. To address this limitation, in this paper, we introduce a Variational Inference-based approach that seamlessly integrates uncertainty prediction into the common rendering pipeline of GS. Additionally, we introduce the Area Under Sparsification Error (AUSE) as a new term in the loss function, enabling optimization of uncertainty estimation alongside image reconstruction. Experimental results on the LLFF dataset demonstrate that our method outperforms existing approaches in terms of both image rendering quality and uncertainty estimation accuracy. Overall, our framework equips practitioners with valuable insights into the reliability of synthesized views, facilitating safer decision-making in real-world applications.","sentences":["We present Stochastic Gaussian Splatting (SGS): the first framework for uncertainty estimation using Gaussian Splatting (GS).","GS recently advanced the novel-view synthesis field by achieving impressive reconstruction quality at a fraction of the computational cost of Neural Radiance Fields (NeRF).","However, contrary to the latter, it still lacks the ability to provide information about the confidence associated with their outputs.","To address this limitation, in this paper, we introduce a Variational Inference-based approach that seamlessly integrates uncertainty prediction into the common rendering pipeline of GS.","Additionally, we introduce the Area Under Sparsification Error (AUSE) as a new term in the loss function, enabling optimization of uncertainty estimation alongside image reconstruction.","Experimental results on the LLFF dataset demonstrate that our method outperforms existing approaches in terms of both image rendering quality and uncertainty estimation accuracy.","Overall, our framework equips practitioners with valuable insights into the reliability of synthesized views, facilitating safer decision-making in real-world applications."],"url":"http://arxiv.org/abs/2403.18476v1","category":"cs.CV"}
{"created":"2024-03-27 11:16:27","title":"Specificity of $\u03c4$ -- approximation for chaotic electron trajectories on complex Fermi surfaces","abstract":"The work examines a special behavior of the magnetic conductivity of metals that arises when chaotic electron trajectories appear on the Fermi surface. This behavior is due to the scattering of electrons at singular points of the dynamic system describing the dynamics of electrons in $\\, {\\bf p}$-space, and caused by small-angle scattering of electrons on phonons. In this situation, the electronic system is described by a \"non-standard\" relaxation time, which plays the main role in a certain range of temperature and magnetic field values.","sentences":["The work examines a special behavior of the magnetic conductivity of metals that arises when chaotic electron trajectories appear on the Fermi surface.","This behavior is due to the scattering of electrons at singular points of the dynamic system describing the dynamics of electrons in $\\, {\\bf p}$-space, and caused by small-angle scattering of electrons on phonons.","In this situation, the electronic system is described by a \"non-standard\" relaxation time, which plays the main role in a certain range of temperature and magnetic field values."],"url":"http://arxiv.org/abs/2403.18457v1","category":"cond-mat.stat-mech"}
{"created":"2024-03-27 11:11:37","title":"Annotating Slack Directly on Your Verilog: Fine-Grained RTL Timing Evaluation for Early Optimization","abstract":"In digital IC design, compared with post-synthesis netlists or layouts, the early register-transfer level (RTL) stage offers greater optimization flexibility for both designers and EDA tools. However, timing information is typically unavailable at this early stage. Some recent machine learning (ML) solutions propose to predict the total negative slack (TNS) and worst negative slack (WNS) of an entire design at the RTL stage, but the fine-grained timing information of individual registers remains unavailable. In this work, we address the unique challenges of RTL timing prediction and introduce our solution named RTL-Timer. To the best of our knowledge, this is the first fine-grained general timing estimator applicable to any given design. RTL-Timer explores multiple promising RTL representations and proposes customized loss functions to capture the maximum arrival time at register endpoints. RTL-Timer's fine-grained predictions are further applied to guide optimization in a standard synthesis flow. The average results on unknown test designs demonstrate a correlation above 0.89, contributing around 3% WNS and 10% TNS improvement after optimization.","sentences":["In digital IC design, compared with post-synthesis netlists or layouts, the early register-transfer level (RTL) stage offers greater optimization flexibility for both designers and EDA tools.","However, timing information is typically unavailable at this early stage.","Some recent machine learning (ML) solutions propose to predict the total negative slack (TNS) and worst negative slack (WNS) of an entire design at the RTL stage, but the fine-grained timing information of individual registers remains unavailable.","In this work, we address the unique challenges of RTL timing prediction and introduce our solution named RTL-Timer.","To the best of our knowledge, this is the first fine-grained general timing estimator applicable to any given design.","RTL-Timer explores multiple promising RTL representations and proposes customized loss functions to capture the maximum arrival time at register endpoints.","RTL-Timer's fine-grained predictions are further applied to guide optimization in a standard synthesis flow.","The average results on unknown test designs demonstrate a correlation above 0.89, contributing around 3% WNS and 10% TNS improvement after optimization."],"url":"http://arxiv.org/abs/2403.18453v1","category":"cs.AR"}
{"created":"2024-03-27 11:06:44","title":"Can Language Beat Numerical Regression? Language-Based Multimodal Trajectory Prediction","abstract":"Language models have demonstrated impressive ability in context understanding and generative performance. Inspired by the recent success of language foundation models, in this paper, we propose LMTraj (Language-based Multimodal Trajectory predictor), which recasts the trajectory prediction task into a sort of question-answering problem. Departing from traditional numerical regression models, which treat the trajectory coordinate sequence as continuous signals, we consider them as discrete signals like text prompts. Specially, we first transform an input space for the trajectory coordinate into the natural language space. Here, the entire time-series trajectories of pedestrians are converted into a text prompt, and scene images are described as text information through image captioning. The transformed numerical and image data are then wrapped into the question-answering template for use in a language model. Next, to guide the language model in understanding and reasoning high-level knowledge, such as scene context and social relationships between pedestrians, we introduce an auxiliary multi-task question and answering. We then train a numerical tokenizer with the prompt data. We encourage the tokenizer to separate the integer and decimal parts well, and leverage it to capture correlations between the consecutive numbers in the language model. Lastly, we train the language model using the numerical tokenizer and all of the question-answer prompts. Here, we propose a beam-search-based most-likely prediction and a temperature-based multimodal prediction to implement both deterministic and stochastic inferences. Applying our LMTraj, we show that the language-based model can be a powerful pedestrian trajectory predictor, and outperforms existing numerical-based predictor methods. Code is publicly available at https://github.com/inhwanbae/LMTrajectory .","sentences":["Language models have demonstrated impressive ability in context understanding and generative performance.","Inspired by the recent success of language foundation models, in this paper, we propose LMTraj (Language-based Multimodal Trajectory predictor), which recasts the trajectory prediction task into a sort of question-answering problem.","Departing from traditional numerical regression models, which treat the trajectory coordinate sequence as continuous signals, we consider them as discrete signals like text prompts.","Specially, we first transform an input space for the trajectory coordinate into the natural language space.","Here, the entire time-series trajectories of pedestrians are converted into a text prompt, and scene images are described as text information through image captioning.","The transformed numerical and image data are then wrapped into the question-answering template for use in a language model.","Next, to guide the language model in understanding and reasoning high-level knowledge, such as scene context and social relationships between pedestrians, we introduce an auxiliary multi-task question and answering.","We then train a numerical tokenizer with the prompt data.","We encourage the tokenizer to separate the integer and decimal parts well, and leverage it to capture correlations between the consecutive numbers in the language model.","Lastly, we train the language model using the numerical tokenizer and all of the question-answer prompts.","Here, we propose a beam-search-based most-likely prediction and a temperature-based multimodal prediction to implement both deterministic and stochastic inferences.","Applying our LMTraj, we show that the language-based model can be a powerful pedestrian trajectory predictor, and outperforms existing numerical-based predictor methods.","Code is publicly available at https://github.com/inhwanbae/LMTrajectory ."],"url":"http://arxiv.org/abs/2403.18447v1","category":"cs.CL"}
{"created":"2024-03-27 11:01:15","title":"Asymptotic Analysis of Synchronous Signal Processing","abstract":"This paper extends various theoretical results from stationary data processing to cyclostationary (CS) processes under a unified framework. We first derive their asymptotic eigenbasis, which provides a link between their Fourier and Karhunen-Lo\\`eve (KL) expansions, through a unitary transformation dictated by the cyclic spectrum. By exploiting this connection and the optimalities offered by the KL representation, we study the asymptotic performance of smoothing, filtering and prediction of CS processes, without the need for deriving explicit implementations. We obtain minimum mean squared error expressions that depend on the cyclic spectrum and include classical limits based on the power spectral density as particular cases. We conclude this work by applying the results to a practical scenario, in order to quantify the achievable gains of synchronous signal processing.","sentences":["This paper extends various theoretical results from stationary data processing to cyclostationary (CS) processes under a unified framework.","We first derive their asymptotic eigenbasis, which provides a link between their Fourier and Karhunen-Lo\\`eve (KL) expansions, through a unitary transformation dictated by the cyclic spectrum.","By exploiting this connection and the optimalities offered by the KL representation, we study the asymptotic performance of smoothing, filtering and prediction of CS processes, without the need for deriving explicit implementations.","We obtain minimum mean squared error expressions that depend on the cyclic spectrum and include classical limits based on the power spectral density as particular cases.","We conclude this work by applying the results to a practical scenario, in order to quantify the achievable gains of synchronous signal processing."],"url":"http://arxiv.org/abs/2403.18445v1","category":"eess.SP"}
{"created":"2024-03-27 11:00:53","title":"FRESCO: Federated Reinforcement Energy System for Cooperative Optimization","abstract":"The rise in renewable energy is creating new dynamics in the energy grid that promise to create a cleaner and more participative energy grid, where technology plays a crucial part in making the required flexibility to achieve the vision of the next-generation grid. This work presents FRESCO, a framework that aims to ease the implementation of energy markets using a hierarchical control architecture of reinforcement learning agents trained using federated learning. The core concept we are proving is that having greedy agents subject to changing conditions from a higher level agent creates a cooperative setup that will allow for fulfilling all the individual objectives. This paper presents a general overview of the framework, the current progress, and some insights we obtained from the recent results.","sentences":["The rise in renewable energy is creating new dynamics in the energy grid that promise to create a cleaner and more participative energy grid, where technology plays a crucial part in making the required flexibility to achieve the vision of the next-generation grid.","This work presents FRESCO, a framework that aims to ease the implementation of energy markets using a hierarchical control architecture of reinforcement learning agents trained using federated learning.","The core concept we are proving is that having greedy agents subject to changing conditions from a higher level agent creates a cooperative setup that will allow for fulfilling all the individual objectives.","This paper presents a general overview of the framework, the current progress, and some insights we obtained from the recent results."],"url":"http://arxiv.org/abs/2403.18444v1","category":"cs.LG"}
{"created":"2024-03-27 10:47:53","title":"Physics and data driven model for prediction of residual stresses in machining","abstract":"Predicting residual stresses has always been a topic of significance due to its implications in the development of enhanced materials and better processing conditions. In this work, an analytical model for prediction of residual stresses is developed for orthogonal machining. It consists of three component models for force, temperature and stress computation. The Oxley force model and Waldorf's slip-line model are employed for obtaining cutting force, thrust force, and temperatures at the shear zone and tool-chip interface for the given parameters. The Komanduri-Hou two heat source model is used for obtaining the temperature distribution in the workpiece. The effect of coolant with differing mass flow rates has also been incorporated. The residual stresses are obtained by combining the mechanical and thermal components, followed by the loading and relaxation of the stresses. Optimal values for unknown parameters are predicted by leveraging a cost function. The residual stress distributions obtained give a tensile region near the surface for Inconel 718, and a compressive region for Ti6Al4V, which are in line with experimental results found in literature.","sentences":["Predicting residual stresses has always been a topic of significance due to its implications in the development of enhanced materials and better processing conditions.","In this work, an analytical model for prediction of residual stresses is developed for orthogonal machining.","It consists of three component models for force, temperature and stress computation.","The Oxley force model and Waldorf's slip-line model are employed for obtaining cutting force, thrust force, and temperatures at the shear zone and tool-chip interface for the given parameters.","The Komanduri-Hou two heat source model is used for obtaining the temperature distribution in the workpiece.","The effect of coolant with differing mass flow rates has also been incorporated.","The residual stresses are obtained by combining the mechanical and thermal components, followed by the loading and relaxation of the stresses.","Optimal values for unknown parameters are predicted by leveraging a cost function.","The residual stress distributions obtained give a tensile region near the surface for Inconel 718, and a compressive region for Ti6Al4V, which are in line with experimental results found in literature."],"url":"http://arxiv.org/abs/2403.18441v1","category":"cond-mat.mtrl-sci"}
{"created":"2024-03-27 10:47:06","title":"Generalized Policy Learning for Smart Grids: FL TRPO Approach","abstract":"The smart grid domain requires bolstering the capabilities of existing energy management systems; Federated Learning (FL) aligns with this goal as it demonstrates a remarkable ability to train models on heterogeneous datasets while maintaining data privacy, making it suitable for smart grid applications, which often involve disparate data distributions and interdependencies among features that hinder the suitability of linear models. This paper introduces a framework that combines FL with a Trust Region Policy Optimization (FL TRPO) aiming to reduce energy-associated emissions and costs. Our approach reveals latent interconnections and employs personalized encoding methods to capture unique insights, understanding the relationships between features and optimal strategies, allowing our model to generalize to previously unseen data. Experimental results validate the robustness of our approach, affirming its proficiency in effectively learning policy models for smart grid challenges.","sentences":["The smart grid domain requires bolstering the capabilities of existing energy management systems; Federated Learning (FL) aligns with this goal as it demonstrates a remarkable ability to train models on heterogeneous datasets while maintaining data privacy, making it suitable for smart grid applications, which often involve disparate data distributions and interdependencies among features that hinder the suitability of linear models.","This paper introduces a framework that combines FL with a Trust Region Policy Optimization (FL TRPO) aiming to reduce energy-associated emissions and costs.","Our approach reveals latent interconnections and employs personalized encoding methods to capture unique insights, understanding the relationships between features and optimal strategies, allowing our model to generalize to previously unseen data.","Experimental results validate the robustness of our approach, affirming its proficiency in effectively learning policy models for smart grid challenges."],"url":"http://arxiv.org/abs/2403.18439v1","category":"cs.LG"}
