{"created":"2024-05-28 17:59:33","title":"DiG: Scalable and Efficient Diffusion Models with Gated Linear Attention","abstract":"Diffusion models with large-scale pre-training have achieved significant success in the field of visual content generation, particularly exemplified by Diffusion Transformers (DiT). However, DiT models have faced challenges with scalability and quadratic complexity efficiency. In this paper, we aim to leverage the long sequence modeling capability of Gated Linear Attention (GLA) Transformers, expanding its applicability to diffusion models. We introduce Diffusion Gated Linear Attention Transformers (DiG), a simple, adoptable solution with minimal parameter overhead, following the DiT design, but offering superior efficiency and effectiveness. In addition to better performance than DiT, DiG-S/2 exhibits $2.5\\times$ higher training speed than DiT-S/2 and saves $75.7\\%$ GPU memory at a resolution of $1792 \\times 1792$. Moreover, we analyze the scalability of DiG across a variety of computational complexity. DiG models, with increased depth/width or augmentation of input tokens, consistently exhibit decreasing FID. We further compare DiG with other subquadratic-time diffusion models. With the same model size, DiG-XL/2 is $4.2\\times$ faster than the recent Mamba-based diffusion model at a $1024$ resolution, and is $1.8\\times$ faster than DiT with CUDA-optimized FlashAttention-2 under the $2048$ resolution. All these results demonstrate its superior efficiency among the latest diffusion models. Code is released at https://github.com/hustvl/DiG.","sentences":["Diffusion models with large-scale pre-training have achieved significant success in the field of visual content generation, particularly exemplified by Diffusion Transformers (DiT).","However, DiT models have faced challenges with scalability and quadratic complexity efficiency.","In this paper, we aim to leverage the long sequence modeling capability of Gated Linear Attention (GLA) Transformers, expanding its applicability to diffusion models.","We introduce Diffusion Gated Linear Attention Transformers (DiG), a simple, adoptable solution with minimal parameter overhead, following the DiT design, but offering superior efficiency and effectiveness.","In addition to better performance than DiT, DiG-S/2 exhibits $2.5\\times$ higher training speed than DiT-S/2 and saves $75.7\\%$ GPU memory at a resolution of $1792 \\times 1792$.","Moreover, we analyze the scalability of DiG across a variety of computational complexity.","DiG models, with increased depth/width or augmentation of input tokens, consistently exhibit decreasing FID.","We further compare DiG with other subquadratic-time diffusion models.","With the same model size, DiG-XL/2 is $4.2\\times$ faster than the recent Mamba-based diffusion model at a $1024$ resolution, and is $1.8\\times$ faster than DiT with CUDA-optimized FlashAttention-2 under the $2048$ resolution.","All these results demonstrate its superior efficiency among the latest diffusion models.","Code is released at https://github.com/hustvl/DiG."],"url":"http://arxiv.org/abs/2405.18428v1","category":"cs.CV"}
{"created":"2024-05-28 17:59:31","title":"Classifying Overlapping Gaussian Mixtures in High Dimensions: From Optimal Classifiers to Neural Nets","abstract":"We derive closed-form expressions for the Bayes optimal decision boundaries in binary classification of high dimensional overlapping Gaussian mixture model (GMM) data, and show how they depend on the eigenstructure of the class covariances, for particularly interesting structured data. We empirically demonstrate, through experiments on synthetic GMMs inspired by real-world data, that deep neural networks trained for classification, learn predictors which approximate the derived optimal classifiers. We further extend our study to networks trained on authentic data, observing that decision thresholds correlate with the covariance eigenvectors rather than the eigenvalues, mirroring our GMM analysis. This provides theoretical insights regarding neural networks' ability to perform probabilistic inference and distill statistical patterns from intricate distributions.","sentences":["We derive closed-form expressions for the Bayes optimal decision boundaries in binary classification of high dimensional overlapping Gaussian mixture model (GMM) data, and show how they depend on the eigenstructure of the class covariances, for particularly interesting structured data.","We empirically demonstrate, through experiments on synthetic GMMs inspired by real-world data, that deep neural networks trained for classification, learn predictors which approximate the derived optimal classifiers.","We further extend our study to networks trained on authentic data, observing that decision thresholds correlate with the covariance eigenvectors rather than the eigenvalues, mirroring our GMM analysis.","This provides theoretical insights regarding neural networks' ability to perform probabilistic inference and distill statistical patterns from intricate distributions."],"url":"http://arxiv.org/abs/2405.18427v1","category":"stat.ML"}
{"created":"2024-05-28 17:59:22","title":"GFlow: Recovering 4D World from Monocular Video","abstract":"Reconstructing 4D scenes from video inputs is a crucial yet challenging task. Conventional methods usually rely on the assumptions of multi-view video inputs, known camera parameters, or static scenes, all of which are typically absent under in-the-wild scenarios. In this paper, we relax all these constraints and tackle a highly ambitious but practical task, which we termed as AnyV4D: we assume only one monocular video is available without any camera parameters as input, and we aim to recover the dynamic 4D world alongside the camera poses. To this end, we introduce GFlow, a new framework that utilizes only 2D priors (depth and optical flow) to lift a video (3D) to a 4D explicit representation, entailing a flow of Gaussian splatting through space and time. GFlow first clusters the scene into still and moving parts, then applies a sequential optimization process that optimizes camera poses and the dynamics of 3D Gaussian points based on 2D priors and scene clustering, ensuring fidelity among neighboring points and smooth movement across frames. Since dynamic scenes always introduce new content, we also propose a new pixel-wise densification strategy for Gaussian points to integrate new visual content. Moreover, GFlow transcends the boundaries of mere 4D reconstruction; it also enables tracking of any points across frames without the need for prior training and segments moving objects from the scene in an unsupervised way. Additionally, the camera poses of each frame can be derived from GFlow, allowing for rendering novel views of a video scene through changing camera pose. By employing the explicit representation, we may readily conduct scene-level or object-level editing as desired, underscoring its versatility and power. Visit our project website at: https://littlepure2333.github.io/GFlow","sentences":["Reconstructing 4D scenes from video inputs is a crucial yet challenging task.","Conventional methods usually rely on the assumptions of multi-view video inputs, known camera parameters, or static scenes, all of which are typically absent under in-the-wild scenarios.","In this paper, we relax all these constraints and tackle a highly ambitious but practical task, which we termed as AnyV4D: we assume only one monocular video is available without any camera parameters as input, and we aim to recover the dynamic 4D world alongside the camera poses.","To this end, we introduce GFlow, a new framework that utilizes only 2D priors (depth and optical flow) to lift a video (3D) to a 4D explicit representation, entailing a flow of Gaussian splatting through space and time.","GFlow first clusters the scene into still and moving parts, then applies a sequential optimization process that optimizes camera poses and the dynamics of 3D Gaussian points based on 2D priors and scene clustering, ensuring fidelity among neighboring points and smooth movement across frames.","Since dynamic scenes always introduce new content, we also propose a new pixel-wise densification strategy for Gaussian points to integrate new visual content.","Moreover, GFlow transcends the boundaries of mere 4D reconstruction; it also enables tracking of any points across frames without the need for prior training and segments moving objects from the scene in an unsupervised way.","Additionally, the camera poses of each frame can be derived from GFlow, allowing for rendering novel views of a video scene through changing camera pose.","By employing the explicit representation, we may readily conduct scene-level or object-level editing as desired, underscoring its versatility and power.","Visit our project website at: https://littlepure2333.github.io/GFlow"],"url":"http://arxiv.org/abs/2405.18426v1","category":"cs.CV"}
{"created":"2024-05-28 17:59:21","title":"ViG: Linear-complexity Visual Sequence Learning with Gated Linear Attention","abstract":"Recently, linear complexity sequence modeling networks have achieved modeling capabilities similar to Vision Transformers on a variety of computer vision tasks, while using fewer FLOPs and less memory. However, their advantage in terms of actual runtime speed is not significant. To address this issue, we introduce Gated Linear Attention (GLA) for vision, leveraging its superior hardware-awareness and efficiency. We propose direction-wise gating to capture 1D global context through bidirectional modeling and a 2D gating locality injection to adaptively inject 2D local details into 1D global context. Our hardware-aware implementation further merges forward and backward scanning into a single kernel, enhancing parallelism and reducing memory cost and latency. The proposed model, ViG, offers a favorable trade-off in accuracy, parameters, and FLOPs on ImageNet and downstream tasks, outperforming popular Transformer and CNN-based models. Notably, ViG-S matches DeiT-B's accuracy while using only 27% of the parameters and 20% of the FLOPs, running 2$\\times$ faster on $224\\times224$ images. At $1024\\times1024$ resolution, ViG-T uses 5.2$\\times$ fewer FLOPs, saves 90% GPU memory, runs 4.8$\\times$ faster, and achieves 20.7% higher top-1 accuracy than DeiT-T. These results position ViG as an efficient and scalable solution for visual representation learning. Code is available at \\url{https://github.com/hustvl/ViG}.","sentences":["Recently, linear complexity sequence modeling networks have achieved modeling capabilities similar to Vision Transformers on a variety of computer vision tasks, while using fewer FLOPs and less memory.","However, their advantage in terms of actual runtime speed is not significant.","To address this issue, we introduce Gated Linear Attention (GLA) for vision, leveraging its superior hardware-awareness and efficiency.","We propose direction-wise gating to capture 1D global context through bidirectional modeling and a 2D gating locality injection to adaptively inject 2D local details into 1D global context.","Our hardware-aware implementation further merges forward and backward scanning into a single kernel, enhancing parallelism and reducing memory cost and latency.","The proposed model, ViG, offers a favorable trade-off in accuracy, parameters, and FLOPs on ImageNet and downstream tasks, outperforming popular Transformer and CNN-based models.","Notably, ViG-S matches DeiT-B's accuracy while using only 27% of the parameters and 20% of the FLOPs, running 2$\\times$ faster on $224\\times224$ images.","At $1024\\times1024$ resolution, ViG-T uses 5.2$\\times$ fewer FLOPs, saves 90% GPU memory, runs 4.8$\\times$ faster, and achieves 20.7% higher top-1 accuracy than DeiT-T. These results position ViG as an efficient and scalable solution for visual representation learning.","Code is available at \\url{https://github.com/hustvl/ViG}."],"url":"http://arxiv.org/abs/2405.18425v2","category":"cs.CV"}
{"created":"2024-05-28 17:57:40","title":"Exploring the Evolution of Altruistic Punishment with a PDE Model of Cultural Multilevel Selection","abstract":"Two mechanisms that have been used to study the evolution of cooperative behavior are altruistic punishment, in which cooperative individuals pay additional costs to punish defection, and multilevel selection, in which competition between groups can help to counteract individual-level incentives to cheat. Boyd, Gintis, Bowles, and Richerson have used simulation models of cultural evolution to suggest that altruistic punishment and pairwise group-level competition can work in concert to promote cooperation, even when neither mechanism can do so on its own. In this paper, we formulate a PDE model for multilevel selection motivated by the approach of Boyd and coauthors, modeling individual-level birth-death competition with a replicator equation based on individual payoffs and describing group-level competition with pairwise conflicts based on differences in the average payoffs of the competing groups. Building off of existing PDE models for multilevel selection with frequency-independent group-level competition, we use analytical and numerical techniques to understand how the forms of individual and average payoffs can impact the long-time ability to sustain altruistic punishment in group-structured populations. We find several interesting differences between the behavior of our new PDE model with pairwise group-level competition and existing multilevel PDE models, including the observation that our new model can feature a non-monotonic dependence of the long-time collective payoff on the strength of altruistic punishment. Going forward, our PDE framework can serve as a way to connect and compare disparate approaches for understanding multilevel selection across the literature in evolutionary biology and anthropology.","sentences":["Two mechanisms that have been used to study the evolution of cooperative behavior are altruistic punishment, in which cooperative individuals pay additional costs to punish defection, and multilevel selection, in which competition between groups can help to counteract individual-level incentives to cheat.","Boyd, Gintis, Bowles, and Richerson have used simulation models of cultural evolution to suggest that altruistic punishment and pairwise group-level competition can work in concert to promote cooperation, even when neither mechanism can do so on its own.","In this paper, we formulate a PDE model for multilevel selection motivated by the approach of Boyd and coauthors, modeling individual-level birth-death competition with a replicator equation based on individual payoffs and describing group-level competition with pairwise conflicts based on differences in the average payoffs of the competing groups.","Building off of existing PDE models for multilevel selection with frequency-independent group-level competition, we use analytical and numerical techniques to understand how the forms of individual and average payoffs can impact the long-time ability to sustain altruistic punishment in group-structured populations.","We find several interesting differences between the behavior of our new PDE model with pairwise group-level competition and existing multilevel PDE models, including the observation that our new model can feature a non-monotonic dependence of the long-time collective payoff on the strength of altruistic punishment.","Going forward, our PDE framework can serve as a way to connect and compare disparate approaches for understanding multilevel selection across the literature in evolutionary biology and anthropology."],"url":"http://arxiv.org/abs/2405.18419v1","category":"q-bio.PE"}
{"created":"2024-05-28 17:57:06","title":"Why are Visually-Grounded Language Models Bad at Image Classification?","abstract":"Image classification is one of the most fundamental capabilities of machine vision intelligence. In this work, we revisit the image classification task using visually-grounded language models (VLMs) such as GPT-4V and LLaVA. We find that existing proprietary and public VLMs, despite often using CLIP as a vision encoder and having many more parameters, significantly underperform CLIP on standard image classification benchmarks like ImageNet. To understand the reason, we explore several hypotheses concerning the inference algorithms, training objectives, and data processing in VLMs. Our analysis reveals that the primary cause is data-related: critical information for image classification is encoded in the VLM's latent space but can only be effectively decoded with enough training data. Specifically, there is a strong correlation between the frequency of class exposure during VLM training and instruction-tuning and the VLM's performance in those classes; when trained with sufficient data, VLMs can match the accuracy of state-of-the-art classification models. Based on these findings, we enhance a VLM by integrating classification-focused datasets into its training, and demonstrate that the enhanced classification performance of the VLM transfers to its general capabilities, resulting in an improvement of 11.8% on the newly collected ImageWikiQA dataset.","sentences":["Image classification is one of the most fundamental capabilities of machine vision intelligence.","In this work, we revisit the image classification task using visually-grounded language models (VLMs) such as GPT-4V and LLaVA.","We find that existing proprietary and public VLMs, despite often using CLIP as a vision encoder and having many more parameters, significantly underperform CLIP on standard image classification benchmarks like ImageNet.","To understand the reason, we explore several hypotheses concerning the inference algorithms, training objectives, and data processing in VLMs.","Our analysis reveals that the primary cause is data-related: critical information for image classification is encoded in the VLM's latent space but can only be effectively decoded with enough training data.","Specifically, there is a strong correlation between the frequency of class exposure during VLM training and instruction-tuning and the VLM's performance in those classes; when trained with sufficient data, VLMs can match the accuracy of state-of-the-art classification models.","Based on these findings, we enhance a VLM by integrating classification-focused datasets into its training, and demonstrate that the enhanced classification performance of the VLM transfers to its general capabilities, resulting in an improvement of 11.8% on the newly collected ImageWikiQA dataset."],"url":"http://arxiv.org/abs/2405.18415v1","category":"cs.CV"}
{"created":"2024-05-28 17:46:36","title":"RACCooN: Remove, Add, and Change Video Content with Auto-Generated Narratives","abstract":"Recent video generative models primarily rely on carefully written text prompts for specific tasks, like inpainting or style editing. They require labor-intensive textual descriptions for input videos, hindering their flexibility to adapt personal/raw videos to user specifications. This paper proposes RACCooN, a versatile and user-friendly video-to-paragraph-to-video generative framework that supports multiple video editing capabilities such as removal, addition, and modification, through a unified pipeline. RACCooN consists of two principal stages: Video-to-Paragraph (V2P) and Paragraph-to-Video (P2V). In the V2P stage, we automatically describe video scenes in well-structured natural language, capturing both the holistic context and focused object details. Subsequently, in the P2V stage, users can optionally refine these descriptions to guide the video diffusion model, enabling various modifications to the input video, such as removing, changing subjects, and/or adding new objects. The proposed approach stands out from other methods through several significant contributions: (1) RACCooN suggests a multi-granular spatiotemporal pooling strategy to generate well-structured video descriptions, capturing both the broad context and object details without requiring complex human annotations, simplifying precise video content editing based on text for users. (2) Our video generative model incorporates auto-generated narratives or instructions to enhance the quality and accuracy of the generated content. It supports the addition of video objects, inpainting, and attribute modification within a unified framework, surpassing existing video editing and inpainting benchmarks. The proposed framework demonstrates impressive versatile capabilities in video-to-paragraph generation, video content editing, and can be incorporated into other SoTA video generative models for further enhancement.","sentences":["Recent video generative models primarily rely on carefully written text prompts for specific tasks, like inpainting or style editing.","They require labor-intensive textual descriptions for input videos, hindering their flexibility to adapt personal/raw videos to user specifications.","This paper proposes RACCooN, a versatile and user-friendly video-to-paragraph-to-video generative framework that supports multiple video editing capabilities such as removal, addition, and modification, through a unified pipeline.","RACCooN consists of two principal stages: Video-to-Paragraph (V2P) and Paragraph-to-Video (P2V).","In the V2P stage, we automatically describe video scenes in well-structured natural language, capturing both the holistic context and focused object details.","Subsequently, in the P2V stage, users can optionally refine these descriptions to guide the video diffusion model, enabling various modifications to the input video, such as removing, changing subjects, and/or adding new objects.","The proposed approach stands out from other methods through several significant contributions: (1) RACCooN suggests a multi-granular spatiotemporal pooling strategy to generate well-structured video descriptions, capturing both the broad context and object details without requiring complex human annotations, simplifying precise video content editing based on text for users.","(2) Our video generative model incorporates auto-generated narratives or instructions to enhance the quality and accuracy of the generated content.","It supports the addition of video objects, inpainting, and attribute modification within a unified framework, surpassing existing video editing and inpainting benchmarks.","The proposed framework demonstrates impressive versatile capabilities in video-to-paragraph generation, video content editing, and can be incorporated into other SoTA video generative models for further enhancement."],"url":"http://arxiv.org/abs/2405.18406v1","category":"cs.CV"}
{"created":"2024-05-28 17:46:27","title":"WIDIn: Wording Image for Domain-Invariant Representation in Single-Source Domain Generalization","abstract":"Language has been useful in extending the vision encoder to data from diverse distributions without empirical discovery in training domains. However, as the image description is mostly at coarse-grained level and ignores visual details, the resulted embeddings are still ineffective in overcoming complexity of domains at inference time. We present a self-supervision framework WIDIn, Wording Images for Domain-Invariant representation, to disentangle discriminative visual representation, by only leveraging data in a single domain and without any test prior. Specifically, for each image, we first estimate the language embedding with fine-grained alignment, which can be consequently used to adaptively identify and then remove domain-specific counterpart from the raw visual embedding. WIDIn can be applied to both pretrained vision-language models like CLIP, and separately trained uni-modal models like MoCo and BERT. Experimental studies on three domain generalization datasets demonstrate the effectiveness of our approach.","sentences":["Language has been useful in extending the vision encoder to data from diverse distributions without empirical discovery in training domains.","However, as the image description is mostly at coarse-grained level and ignores visual details, the resulted embeddings are still ineffective in overcoming complexity of domains at inference time.","We present a self-supervision framework WIDIn, Wording Images for Domain-Invariant representation, to disentangle discriminative visual representation, by only leveraging data in a single domain and without any test prior.","Specifically, for each image, we first estimate the language embedding with fine-grained alignment, which can be consequently used to adaptively identify and then remove domain-specific counterpart from the raw visual embedding.","WIDIn can be applied to both pretrained vision-language models like CLIP, and separately trained uni-modal models like MoCo and BERT.","Experimental studies on three domain generalization datasets demonstrate the effectiveness of our approach."],"url":"http://arxiv.org/abs/2405.18405v1","category":"cs.CV"}
{"created":"2024-05-28 17:22:22","title":"OwLore: Outlier-weighed Layerwise Sampled Low-Rank Projection for Memory-Efficient LLM Fine-tuning","abstract":"The rapid advancements in Large Language Models (LLMs) have revolutionized various natural language processing tasks. However, the substantial size of LLMs presents significant challenges in training or fine-tuning. While parameter-efficient approaches such as low-rank adaptation (LoRA) have gained popularity, they often compromise performance compared to full-rank fine-tuning. In this paper, we propose Outlier-weighed Layerwise Sampled Low-Rank Projection (OwLore), a new memory-efficient fine-tuning approach, inspired by the layerwise outlier distribution of LLMs, which dynamically samples pre-trained layers to fine-tune instead of adding additional adaptors. We first interpret the outlier phenomenon through the lens of Heavy-Tailed Self-Regularization theory (HT-SR), discovering that layers with more outliers tend to be more heavy-tailed and consequently better trained. Inspired by this finding, OwLore strategically assigns higher sampling probabilities to layers with more outliers to better leverage the knowledge stored in pre-trained LLMs. To further mitigate the memory demands of fine-tuning, we integrate gradient low-rank projection into our approach, which facilitates each layer to be efficiently trained in a low-rank manner. By incorporating the efficient characteristics of low-rank and optimal layerwise sampling, OwLore significantly improves the memory-performance trade-off in LLM pruning. Our extensive experiments across various architectures, including LLaMa2, LLaMa3, and Mistral, demonstrate that OwLore consistently outperforms baseline approaches, including full fine-tuning. Specifically, it achieves up to a 1.1% average accuracy gain on the Commonsense Reasoning benchmark, a 3.0% improvement on MMLU, and a notable 10% boost on MT-Bench, while being more memory efficient. OwLore allows us to fine-tune LLaMa2-7B with only 21GB of memory.","sentences":["The rapid advancements in Large Language Models (LLMs) have revolutionized various natural language processing tasks.","However, the substantial size of LLMs presents significant challenges in training or fine-tuning.","While parameter-efficient approaches such as low-rank adaptation (LoRA) have gained popularity, they often compromise performance compared to full-rank fine-tuning.","In this paper, we propose Outlier-weighed Layerwise Sampled Low-Rank Projection (OwLore), a new memory-efficient fine-tuning approach, inspired by the layerwise outlier distribution of LLMs, which dynamically samples pre-trained layers to fine-tune instead of adding additional adaptors.","We first interpret the outlier phenomenon through the lens of Heavy-Tailed Self-Regularization theory (HT-SR), discovering that layers with more outliers tend to be more heavy-tailed and consequently better trained.","Inspired by this finding, OwLore strategically assigns higher sampling probabilities to layers with more outliers to better leverage the knowledge stored in pre-trained LLMs.","To further mitigate the memory demands of fine-tuning, we integrate gradient low-rank projection into our approach, which facilitates each layer to be efficiently trained in a low-rank manner.","By incorporating the efficient characteristics of low-rank and optimal layerwise sampling, OwLore significantly improves the memory-performance trade-off in LLM pruning.","Our extensive experiments across various architectures, including LLaMa2, LLaMa3, and Mistral, demonstrate that OwLore consistently outperforms baseline approaches, including full fine-tuning.","Specifically, it achieves up to a 1.1% average accuracy gain on the Commonsense Reasoning benchmark, a 3.0% improvement on MMLU, and a notable 10% boost on MT-Bench, while being more memory efficient.","OwLore allows us to fine-tune LLaMa2-7B with only 21GB of memory."],"url":"http://arxiv.org/abs/2405.18380v1","category":"cs.LG"}
{"created":"2024-05-28 17:18:17","title":"Empowering Source-Free Domain Adaptation with MLLM-driven Curriculum Learning","abstract":"Source-Free Domain Adaptation (SFDA) aims to adapt a pre-trained source model to a target domain using only unlabeled target data. Current SFDA methods face challenges in effectively leveraging pre-trained knowledge and exploiting target domain data. Multimodal Large Language Models (MLLMs) offer remarkable capabilities in understanding visual and textual information, but their applicability to SFDA poses challenges such as instruction-following failures, intensive computational demands, and difficulties in performance measurement prior to adaptation. To alleviate these issues, we propose Reliability-based Curriculum Learning (RCL), a novel framework that integrates multiple MLLMs for knowledge exploitation via pseudo-labeling in SFDA. Our framework incorporates proposed Reliable Knowledge Transfer, Self-correcting and MLLM-guided Knowledge Expansion, and Multi-hot Masking Refinement to progressively exploit unlabeled data in the target domain. RCL achieves state-of-the-art (SOTA) performance on multiple SFDA benchmarks, e.g., $\\textbf{+9.4%}$ on DomainNet, demonstrating its effectiveness in enhancing adaptability and robustness without requiring access to source data. Code: https://github.com/Dong-Jie-Chen/RCL.","sentences":["Source-Free Domain Adaptation (SFDA) aims to adapt a pre-trained source model to a target domain using only unlabeled target data.","Current SFDA methods face challenges in effectively leveraging pre-trained knowledge and exploiting target domain data.","Multimodal Large Language Models (MLLMs) offer remarkable capabilities in understanding visual and textual information, but their applicability to SFDA poses challenges such as instruction-following failures, intensive computational demands, and difficulties in performance measurement prior to adaptation.","To alleviate these issues, we propose Reliability-based Curriculum Learning (RCL), a novel framework that integrates multiple MLLMs for knowledge exploitation via pseudo-labeling in SFDA.","Our framework incorporates proposed Reliable Knowledge Transfer, Self-correcting and MLLM-guided Knowledge Expansion, and Multi-hot Masking Refinement to progressively exploit unlabeled data in the target domain.","RCL achieves state-of-the-art (SOTA) performance on multiple SFDA benchmarks, e.g., $\\textbf{+9.4%}$ on DomainNet, demonstrating its effectiveness in enhancing adaptability and robustness without requiring access to source data.","Code: https://github.com/Dong-Jie-Chen/RCL."],"url":"http://arxiv.org/abs/2405.18376v1","category":"cs.LG"}
{"created":"2024-05-28 17:08:31","title":"PromptWizard: Task-Aware Agent-driven Prompt Optimization Framework","abstract":"Large language models (LLMs) have revolutionized AI across diverse domains, showcasing remarkable capabilities. Central to their success is the concept of prompting, which guides model output generation. However, manual prompt engineering is labor-intensive and domain-specific, necessitating automated solutions. This paper introduces PromptWizard, a novel framework leveraging LLMs to iteratively synthesize and refine prompts tailored to specific tasks. Unlike existing approaches, PromptWizard optimizes both prompt instructions and in-context examples, maximizing model performance. The framework iteratively refines prompts by mutating instructions and incorporating negative examples to deepen understanding and ensure diversity. It further enhances both instructions and examples with the aid of a critic, synthesizing new instructions and examples enriched with detailed reasoning steps for optimal performance. PromptWizard offers several key features and capabilities, including computational efficiency compared to state-of-the-art approaches, adaptability to scenarios with varying amounts of training data, and effectiveness with smaller LLMs. Rigorous evaluation across 35 tasks on 8 datasets demonstrates PromptWizard's superiority over existing prompt strategies, showcasing its efficacy and scalability in prompt optimization.","sentences":["Large language models (LLMs) have revolutionized AI across diverse domains, showcasing remarkable capabilities.","Central to their success is the concept of prompting, which guides model output generation.","However, manual prompt engineering is labor-intensive and domain-specific, necessitating automated solutions.","This paper introduces PromptWizard, a novel framework leveraging LLMs to iteratively synthesize and refine prompts tailored to specific tasks.","Unlike existing approaches, PromptWizard optimizes both prompt instructions and in-context examples, maximizing model performance.","The framework iteratively refines prompts by mutating instructions and incorporating negative examples to deepen understanding and ensure diversity.","It further enhances both instructions and examples with the aid of a critic, synthesizing new instructions and examples enriched with detailed reasoning steps for optimal performance.","PromptWizard offers several key features and capabilities, including computational efficiency compared to state-of-the-art approaches, adaptability to scenarios with varying amounts of training data, and effectiveness with smaller LLMs.","Rigorous evaluation across 35 tasks on 8 datasets demonstrates PromptWizard's superiority over existing prompt strategies, showcasing its efficacy and scalability in prompt optimization."],"url":"http://arxiv.org/abs/2405.18369v1","category":"cs.CL"}
{"created":"2024-05-28 16:56:42","title":"Bridging the Gap: Dynamic Learning Strategies for Improving Multilingual Performance in LLMs","abstract":"Large language models (LLMs) are at the forefront of transforming numerous domains globally. However, their inclusivity and effectiveness remain limited for non-Latin scripts and low-resource languages. This paper tackles the imperative challenge of enhancing the multilingual performance of LLMs without extensive training or fine-tuning. Through systematic investigation and evaluation of diverse languages using popular question-answering (QA) datasets, we present novel techniques that unlock the true potential of LLMs in a polyglot landscape. Our approach encompasses three key strategies that yield significant improvements in multilingual proficiency. First, by meticulously optimizing prompts tailored for polyglot LLMs, we unlock their latent capabilities, resulting in substantial performance boosts across languages. Second, we introduce a new hybrid approach that synergizes LLM Retrieval Augmented Generation (RAG) with multilingual embeddings and achieves improved multilingual task performance. Finally, we introduce a novel learning approach that dynamically selects the optimal prompt strategy, LLM model, and embedding model per query at run-time. This dynamic adaptation maximizes the efficacy of LLMs across languages, outperforming best static and random strategies. Additionally, our approach adapts configurations in both offline and online settings, and can seamlessly adapt to new languages and datasets, leading to substantial advancements in multilingual understanding and generation across diverse languages.","sentences":["Large language models (LLMs) are at the forefront of transforming numerous domains globally.","However, their inclusivity and effectiveness remain limited for non-Latin scripts and low-resource languages.","This paper tackles the imperative challenge of enhancing the multilingual performance of LLMs without extensive training or fine-tuning.","Through systematic investigation and evaluation of diverse languages using popular question-answering (QA) datasets, we present novel techniques that unlock the true potential of LLMs in a polyglot landscape.","Our approach encompasses three key strategies that yield significant improvements in multilingual proficiency.","First, by meticulously optimizing prompts tailored for polyglot LLMs, we unlock their latent capabilities, resulting in substantial performance boosts across languages.","Second, we introduce a new hybrid approach that synergizes LLM Retrieval Augmented Generation (RAG) with multilingual embeddings and achieves improved multilingual task performance.","Finally, we introduce a novel learning approach that dynamically selects the optimal prompt strategy, LLM model, and embedding model per query at run-time.","This dynamic adaptation maximizes the efficacy of LLMs across languages, outperforming best static and random strategies.","Additionally, our approach adapts configurations in both offline and online settings, and can seamlessly adapt to new languages and datasets, leading to substantial advancements in multilingual understanding and generation across diverse languages."],"url":"http://arxiv.org/abs/2405.18359v1","category":"cs.CL"}
{"created":"2024-05-28 16:55:15","title":"Universal and Extensible Language-Vision Models for Organ Segmentation and Tumor Detection from Abdominal Computed Tomography","abstract":"The advancement of artificial intelligence (AI) for organ segmentation and tumor detection is propelled by the growing availability of computed tomography (CT) datasets with detailed, per-voxel annotations. However, these AI models often struggle with flexibility for partially annotated datasets and extensibility for new classes due to limitations in the one-hot encoding, architectural design, and learning scheme. To overcome these limitations, we propose a universal, extensible framework enabling a single model, termed Universal Model, to deal with multiple public datasets and adapt to new classes (e.g., organs/tumors). Firstly, we introduce a novel language-driven parameter generator that leverages language embeddings from large language models, enriching semantic encoding compared with one-hot encoding. Secondly, the conventional output layers are replaced with lightweight, class-specific heads, allowing Universal Model to simultaneously segment 25 organs and six types of tumors and ease the addition of new classes. We train our Universal Model on 3,410 CT volumes assembled from 14 publicly available datasets and then test it on 6,173 CT volumes from four external datasets. Universal Model achieves first place on six CT tasks in the Medical Segmentation Decathlon (MSD) public leaderboard and leading performance on the Beyond The Cranial Vault (BTCV) dataset. In summary, Universal Model exhibits remarkable computational efficiency (6x faster than other dataset-specific models), demonstrates strong generalization across different hospitals, transfers well to numerous downstream tasks, and more importantly, facilitates the extensibility to new classes while alleviating the catastrophic forgetting of previously learned classes. Codes, models, and datasets are available at https://github.com/ljwztc/CLIP-Driven-Universal-Model","sentences":["The advancement of artificial intelligence (AI) for organ segmentation and tumor detection is propelled by the growing availability of computed tomography (CT) datasets with detailed, per-voxel annotations.","However, these AI models often struggle with flexibility for partially annotated datasets and extensibility for new classes due to limitations in the one-hot encoding, architectural design, and learning scheme.","To overcome these limitations, we propose a universal, extensible framework enabling a single model, termed Universal Model, to deal with multiple public datasets and adapt to new classes (e.g., organs/tumors).","Firstly, we introduce a novel language-driven parameter generator that leverages language embeddings from large language models, enriching semantic encoding compared with one-hot encoding.","Secondly, the conventional output layers are replaced with lightweight, class-specific heads, allowing Universal Model to simultaneously segment 25 organs and six types of tumors and ease the addition of new classes.","We train our Universal Model on 3,410 CT volumes assembled from 14 publicly available datasets and then test it on 6,173 CT volumes from four external datasets.","Universal Model achieves first place on six CT tasks in the Medical Segmentation Decathlon (MSD) public leaderboard and leading performance on the Beyond The Cranial Vault (BTCV) dataset.","In summary, Universal Model exhibits remarkable computational efficiency (6x faster than other dataset-specific models), demonstrates strong generalization across different hospitals, transfers well to numerous downstream tasks, and more importantly, facilitates the extensibility to new classes while alleviating the catastrophic forgetting of previously learned classes.","Codes, models, and datasets are available at https://github.com/ljwztc/CLIP-Driven-Universal-Model"],"url":"http://arxiv.org/abs/2405.18356v1","category":"eess.IV"}
{"created":"2024-05-28 16:52:52","title":"Simulating infinite-dimensional nonlinear diffusion bridges","abstract":"The diffusion bridge is a type of diffusion process that conditions on hitting a specific state within a finite time period. It has broad applications in fields such as Bayesian inference, financial mathematics, control theory, and shape analysis. However, simulating the diffusion bridge for natural data can be challenging due to both the intractability of the drift term and continuous representations of the data. Although several methods are available to simulate finite-dimensional diffusion bridges, infinite-dimensional cases remain unresolved. In the paper, we present a solution to this problem by merging score-matching techniques with operator learning, enabling a direct approach to score-matching for the infinite-dimensional bridge. We construct the score to be discretization invariant, which is natural given the underlying spatially continuous process. We conduct a series of experiments, ranging from synthetic examples with closed-form solutions to the stochastic nonlinear evolution of real-world biological shape data, and our method demonstrates high efficacy, particularly due to its ability to adapt to any resolution without extra training.","sentences":["The diffusion bridge is a type of diffusion process that conditions on hitting a specific state within a finite time period.","It has broad applications in fields such as Bayesian inference, financial mathematics, control theory, and shape analysis.","However, simulating the diffusion bridge for natural data can be challenging due to both the intractability of the drift term and continuous representations of the data.","Although several methods are available to simulate finite-dimensional diffusion bridges, infinite-dimensional cases remain unresolved.","In the paper, we present a solution to this problem by merging score-matching techniques with operator learning, enabling a direct approach to score-matching for the infinite-dimensional bridge.","We construct the score to be discretization invariant, which is natural given the underlying spatially continuous process.","We conduct a series of experiments, ranging from synthetic examples with closed-form solutions to the stochastic nonlinear evolution of real-world biological shape data, and our method demonstrates high efficacy, particularly due to its ability to adapt to any resolution without extra training."],"url":"http://arxiv.org/abs/2405.18353v1","category":"cs.LG"}
{"created":"2024-05-28 16:48:05","title":"A System for Automatic English Text Expansion","abstract":"We present an automatic text expansion system to generate English sentences, which performs automatic Natural Language Generation (NLG) by combining linguistic rules with statistical approaches. Here, \"automatic\" means that the system can generate coherent and correct sentences from a minimum set of words. From its inception, the design is modular and adaptable to other languages. This adaptability is one of its greatest advantages. For English, we have created the highly precise aLexiE lexicon with wide coverage, which represents a contribution on its own. We have evaluated the resulting NLG library in an Augmentative and Alternative Communication (AAC) proof of concept, both directly (by regenerating corpus sentences) and manually (from annotations) using a popular corpus in the NLG field. We performed a second analysis by comparing the quality of text expansion in English to Spanish, using an ad-hoc Spanish-English parallel corpus. The system might also be applied to other domains such as report and news generation.","sentences":["We present an automatic text expansion system to generate English sentences, which performs automatic Natural Language Generation (NLG) by combining linguistic rules with statistical approaches.","Here, \"automatic\" means that the system can generate coherent and correct sentences from a minimum set of words.","From its inception, the design is modular and adaptable to other languages.","This adaptability is one of its greatest advantages.","For English, we have created the highly precise aLexiE lexicon with wide coverage, which represents a contribution on its own.","We have evaluated the resulting NLG library in an Augmentative and Alternative Communication (AAC) proof of concept, both directly (by regenerating corpus sentences) and manually (from annotations) using a popular corpus in the NLG field.","We performed a second analysis by comparing the quality of text expansion in English to Spanish, using an ad-hoc Spanish-English parallel corpus.","The system might also be applied to other domains such as report and news generation."],"url":"http://arxiv.org/abs/2405.18350v1","category":"cs.CL"}
{"created":"2024-05-28 16:25:43","title":"Lattice ultrasensitivity produces large gain in E. coli chemosensing","abstract":"E. coli use a regular lattice of receptors and attached kinases to detect and amplify faint chemical signals. Kinase output is characterized by precise adaptation to a wide range of background ligand levels and large gain in response to small relative changes in ligand concentration. These characteristics are well described by models which achieve their gain through equilibrium cooperativity. But these models are challenged by two experimental results. First, neither adaptation nor large gain are present in receptor binding assays. Second, in cells lacking adaptation machinery, fluctuations can sometimes be enormous, with essentially all kinases transitioning together. Here we introduce a far-from equilibrium model in which receptors gate the spread of activity between neighboring kinases. This model achieves large gain through a mechanism we term lattice ultrasensitivity (LU). In our LU model, kinase and receptor states are separate degrees of freedom, and kinase kinetics are dominated by chemical rates far-from-equilibrium rather than by equilibrium allostery. The model recapitulates the successes of past models, but also matches the challenging experimental findings. Importantly, unlike past lattice critical models, our LU model does not require parameters to be fine tuned for function.","sentences":["E. coli use a regular lattice of receptors and attached kinases to detect and amplify faint chemical signals.","Kinase output is characterized by precise adaptation to a wide range of background ligand levels and large gain in response to small relative changes in ligand concentration.","These characteristics are well described by models which achieve their gain through equilibrium cooperativity.","But these models are challenged by two experimental results.","First, neither adaptation nor large gain are present in receptor binding assays.","Second, in cells lacking adaptation machinery, fluctuations can sometimes be enormous, with essentially all kinases transitioning together.","Here we introduce a far-from equilibrium model in which receptors gate the spread of activity between neighboring kinases.","This model achieves large gain through a mechanism we term lattice ultrasensitivity (LU).","In our LU model, kinase and receptor states are separate degrees of freedom, and kinase kinetics are dominated by chemical rates far-from-equilibrium rather than by equilibrium allostery.","The model recapitulates the successes of past models, but also matches the challenging experimental findings.","Importantly, unlike past lattice critical models, our LU model does not require parameters to be fine tuned for function."],"url":"http://arxiv.org/abs/2405.18331v1","category":"physics.bio-ph"}
{"created":"2024-05-28 16:24:47","title":"Frustratingly Easy Test-Time Adaptation of Vision-Language Models","abstract":"Vision-Language Models seamlessly discriminate among arbitrary semantic categories, yet they still suffer from poor generalization when presented with challenging examples. For this reason, Episodic Test-Time Adaptation (TTA) strategies have recently emerged as powerful techniques to adapt VLMs in the presence of a single unlabeled image. The recent literature on TTA is dominated by the paradigm of prompt tuning by Marginal Entropy Minimization, which, relying on online backpropagation, inevitably slows down inference while increasing memory. In this work, we theoretically investigate the properties of this approach and unveil that a surprisingly strong TTA method lies dormant and hidden within it. We term this approach ZERO (TTA with \"zero\" temperature), whose design is both incredibly effective and frustratingly simple: augment N times, predict, retain the most confident predictions, and marginalize after setting the Softmax temperature to zero. Remarkably, ZERO requires a single batched forward pass through the vision encoder only and no backward passes. We thoroughly evaluate our approach following the experimental protocol established in the literature and show that ZERO largely surpasses or compares favorably w.r.t. the state-of-the-art while being almost 10x faster and 13x more memory-friendly than standard Test-Time Prompt Tuning. Thanks to its simplicity and comparatively negligible computation, ZERO can serve as a strong baseline for future work in this field. The code is available at https://github.com/FarinaMatteo/zero.","sentences":["Vision-Language Models seamlessly discriminate among arbitrary semantic categories, yet they still suffer from poor generalization when presented with challenging examples.","For this reason, Episodic Test-Time Adaptation (TTA) strategies have recently emerged as powerful techniques to adapt VLMs in the presence of a single unlabeled image.","The recent literature on TTA is dominated by the paradigm of prompt tuning by Marginal Entropy Minimization, which, relying on online backpropagation, inevitably slows down inference while increasing memory.","In this work, we theoretically investigate the properties of this approach and unveil that a surprisingly strong TTA method lies dormant and hidden within it.","We term this approach ZERO (TTA with \"zero\" temperature), whose design is both incredibly effective and frustratingly simple: augment N times, predict, retain the most confident predictions, and marginalize after setting the Softmax temperature to zero.","Remarkably, ZERO requires a single batched forward pass through the vision encoder only and no backward passes.","We thoroughly evaluate our approach following the experimental protocol established in the literature and show that ZERO largely surpasses or compares favorably w.r.t.","the state-of-the-art while being almost 10x faster and 13x more memory-friendly than standard Test-Time Prompt Tuning.","Thanks to its simplicity and comparatively negligible computation, ZERO can serve as a strong baseline for future work in this field.","The code is available at https://github.com/FarinaMatteo/zero."],"url":"http://arxiv.org/abs/2405.18330v1","category":"cs.CV"}
{"created":"2024-05-28 16:20:33","title":"Value Alignment and Trust in Human-Robot Interaction: Insights from Simulation and User Study","abstract":"With the advent of AI technologies, humans and robots are increasingly teaming up to perform collaborative tasks. To enable smooth and effective collaboration, the topic of value alignment (operationalized herein as the degree of dynamic goal alignment within a task) between the robot and the human is gaining increasing research attention. Prior literature on value alignment makes an inherent assumption that aligning the values of the robot with that of the human benefits the team. This assumption, however, has not been empirically verified. Moreover, prior literature does not account for human's trust in the robot when analyzing human-robot value alignment. Thus, a research gap needs to be bridged by answering two questions: How does alignment of values affect trust? Is it always beneficial to align the robot's values with that of the human? We present a simulation study and a human-subject study to answer these questions. Results from the simulation study show that alignment of values is important for trust when the overall risk level of the task is high. We also present an adaptive strategy for the robot that uses Inverse Reinforcement Learning (IRL) to match the values of the robot with those of the human during interaction. Our simulations suggest that such an adaptive strategy is able to maintain trust across the full spectrum of human values. We also present results from an empirical study that validate these findings from simulation. Results indicate that real-time personalized value alignment is beneficial to trust and perceived performance by the human when the robot does not have a good prior on the human's values.","sentences":["With the advent of AI technologies, humans and robots are increasingly teaming up to perform collaborative tasks.","To enable smooth and effective collaboration, the topic of value alignment (operationalized herein as the degree of dynamic goal alignment within a task) between the robot and the human is gaining increasing research attention.","Prior literature on value alignment makes an inherent assumption that aligning the values of the robot with that of the human benefits the team.","This assumption, however, has not been empirically verified.","Moreover, prior literature does not account for human's trust in the robot when analyzing human-robot value alignment.","Thus, a research gap needs to be bridged by answering two questions: How does alignment of values affect trust?","Is it always beneficial to align the robot's values with that of the human?","We present a simulation study and a human-subject study to answer these questions.","Results from the simulation study show that alignment of values is important for trust when the overall risk level of the task is high.","We also present an adaptive strategy for the robot that uses Inverse Reinforcement Learning (IRL) to match the values of the robot with those of the human during interaction.","Our simulations suggest that such an adaptive strategy is able to maintain trust across the full spectrum of human values.","We also present results from an empirical study that validate these findings from simulation.","Results indicate that real-time personalized value alignment is beneficial to trust and perceived performance by the human when the robot does not have a good prior on the human's values."],"url":"http://arxiv.org/abs/2405.18324v1","category":"cs.RO"}
{"created":"2024-05-28 15:53:02","title":"CompetEvo: Towards Morphological Evolution from Competition","abstract":"Training an agent to adapt to specific tasks through co-optimization of morphology and control has widely attracted attention. However, whether there exists an optimal configuration and tactics for agents in a multiagent competition scenario is still an issue that is challenging to definitively conclude. In this context, we propose competitive evolution (CompetEvo), which co-evolves agents' designs and tactics in confrontation. We build arenas consisting of three animals and their evolved derivatives, placing agents with different morphologies in direct competition with each other. The results reveal that our method enables agents to evolve a more suitable design and strategy for fighting compared to fixed-morph agents, allowing them to obtain advantages in combat scenarios. Moreover, we demonstrate the amazing and impressive behaviors that emerge when confrontations are conducted under asymmetrical morphs.","sentences":["Training an agent to adapt to specific tasks through co-optimization of morphology and control has widely attracted attention.","However, whether there exists an optimal configuration and tactics for agents in a multiagent competition scenario is still an issue that is challenging to definitively conclude.","In this context, we propose competitive evolution (CompetEvo), which co-evolves agents' designs and tactics in confrontation.","We build arenas consisting of three animals and their evolved derivatives, placing agents with different morphologies in direct competition with each other.","The results reveal that our method enables agents to evolve a more suitable design and strategy for fighting compared to fixed-morph agents, allowing them to obtain advantages in combat scenarios.","Moreover, we demonstrate the amazing and impressive behaviors that emerge when confrontations are conducted under asymmetrical morphs."],"url":"http://arxiv.org/abs/2405.18300v1","category":"cs.AI"}
{"created":"2024-05-28 15:48:39","title":"Intent3D: 3D Object Detection in RGB-D Scans Based on Human Intention","abstract":"In real-life scenarios, humans seek out objects in the 3D world to fulfill their daily needs or intentions. This inspires us to introduce 3D intention grounding, a new task in 3D object detection employing RGB-D, based on human intention, such as \"I want something to support my back\". Closely related, 3D visual grounding focuses on understanding human reference. To achieve detection based on human intention, it relies on humans to observe the scene, reason out the target that aligns with their intention (\"pillow\" in this case), and finally provide a reference to the AI system, such as \"A pillow on the couch\". Instead, 3D intention grounding challenges AI agents to automatically observe, reason and detect the desired target solely based on human intention. To tackle this challenge, we introduce the new Intent3D dataset, consisting of 44,990 intention texts associated with 209 fine-grained classes from 1,042 scenes of the ScanNet dataset. We also establish several baselines based on different language-based 3D object detection models on our benchmark. Finally, we propose IntentNet, our unique approach, designed to tackle this intention-based detection problem. It focuses on three key aspects: intention understanding, reasoning to identify object candidates, and cascaded adaptive learning that leverages the intrinsic priority logic of different losses for multiple objective optimization.","sentences":["In real-life scenarios, humans seek out objects in the 3D world to fulfill their daily needs or intentions.","This inspires us to introduce 3D intention grounding, a new task in 3D object detection employing RGB-D, based on human intention, such as \"I want something to support my back\".","Closely related, 3D visual grounding focuses on understanding human reference.","To achieve detection based on human intention, it relies on humans to observe the scene, reason out the target that aligns with their intention (\"pillow\" in this case), and finally provide a reference to the AI system, such as \"A pillow on the couch\".","Instead, 3D intention grounding challenges AI agents to automatically observe, reason and detect the desired target solely based on human intention.","To tackle this challenge, we introduce the new Intent3D dataset, consisting of 44,990 intention texts associated with 209 fine-grained classes from 1,042 scenes of the ScanNet dataset.","We also establish several baselines based on different language-based 3D object detection models on our benchmark.","Finally, we propose IntentNet, our unique approach, designed to tackle this intention-based detection problem.","It focuses on three key aspects: intention understanding, reasoning to identify object candidates, and cascaded adaptive learning that leverages the intrinsic priority logic of different losses for multiple objective optimization."],"url":"http://arxiv.org/abs/2405.18295v1","category":"cs.CV"}
{"created":"2024-05-28 15:47:11","title":"Semantic are Beacons: A Semantic Perspective for Unveiling Parameter-Efficient Fine-Tuning in Knowledge Learning","abstract":"Parameter-Efficient Fine-Tuning (PEFT) methods enable efficient adaptation of Large Language Models (LLMs) to various downstream applications. However, the effectiveness of the PEFT diminishes notably when downstream tasks require accurate learning of factual knowledge. In this paper, we adopt a semantic perspective to investigate this phenomenon, uncovering the reasons behind PEFT's limitations in knowledge learning task. Our findings reveal that: (1) PEFT presents a notable risk of pushing the model away from the intended knowledge target; (2) multiple knowledge interfere with each other, and such interference suppresses the learning and expression of knowledge features. Based on these insights, we introduce a data filtering strategy to exclude data that is detrimental to knowledge learning and a re-weighted learning strategy to make the model attentive to semantic distance during knowledge learning. Experimental results demonstrate the effectiveness of the proposed method on open-source large language model, further validate the semantic challenge in PEFT, thus paving the way for future research.","sentences":["Parameter-Efficient Fine-Tuning (PEFT) methods enable efficient adaptation of Large Language Models (LLMs) to various downstream applications.","However, the effectiveness of the PEFT diminishes notably when downstream tasks require accurate learning of factual knowledge.","In this paper, we adopt a semantic perspective to investigate this phenomenon, uncovering the reasons behind PEFT's limitations in knowledge learning task.","Our findings reveal that: (1) PEFT presents a notable risk of pushing the model away from the intended knowledge target; (2) multiple knowledge interfere with each other, and such interference suppresses the learning and expression of knowledge features.","Based on these insights, we introduce a data filtering strategy to exclude data that is detrimental to knowledge learning and a re-weighted learning strategy to make the model attentive to semantic distance during knowledge learning.","Experimental results demonstrate the effectiveness of the proposed method on open-source large language model, further validate the semantic challenge in PEFT, thus paving the way for future research."],"url":"http://arxiv.org/abs/2405.18292v1","category":"cs.CL"}
{"created":"2024-05-28 15:43:29","title":"FedSAC: Dynamic Submodel Allocation for Collaborative Fairness in Federated Learning","abstract":"Collaborative fairness stands as an essential element in federated learning to encourage client participation by equitably distributing rewards based on individual contributions. Existing methods primarily focus on adjusting gradient allocations among clients to achieve collaborative fairness. However, they frequently overlook crucial factors such as maintaining consistency across local models and catering to the diverse requirements of high-contributing clients. This oversight inevitably decreases both fairness and model accuracy in practice. To address these issues, we propose FedSAC, a novel Federated learning framework with dynamic Submodel Allocation for Collaborative fairness, backed by a theoretical convergence guarantee. First, we present the concept of \"bounded collaborative fairness (BCF)\", which ensures fairness by tailoring rewards to individual clients based on their contributions. Second, to implement the BCF, we design a submodel allocation module with a theoretical guarantee of fairness. This module incentivizes high-contributing clients with high-performance submodels containing a diverse range of crucial neurons, thereby preserving consistency across local models. Third, we further develop a dynamic aggregation module to adaptively aggregate submodels, ensuring the equitable treatment of low-frequency neurons and consequently enhancing overall model accuracy. Extensive experiments conducted on three public benchmarks demonstrate that FedSAC outperforms all baseline methods in both fairness and model accuracy. We see this work as a significant step towards incentivizing broader client participation in federated learning. The source code is available at https://github.com/wangzihuixmu/FedSAC.","sentences":["Collaborative fairness stands as an essential element in federated learning to encourage client participation by equitably distributing rewards based on individual contributions.","Existing methods primarily focus on adjusting gradient allocations among clients to achieve collaborative fairness.","However, they frequently overlook crucial factors such as maintaining consistency across local models and catering to the diverse requirements of high-contributing clients.","This oversight inevitably decreases both fairness and model accuracy in practice.","To address these issues, we propose FedSAC, a novel Federated learning framework with dynamic Submodel Allocation for Collaborative fairness, backed by a theoretical convergence guarantee.","First, we present the concept of \"bounded collaborative fairness (BCF)\", which ensures fairness by tailoring rewards to individual clients based on their contributions.","Second, to implement the BCF, we design a submodel allocation module with a theoretical guarantee of fairness.","This module incentivizes high-contributing clients with high-performance submodels containing a diverse range of crucial neurons, thereby preserving consistency across local models.","Third, we further develop a dynamic aggregation module to adaptively aggregate submodels, ensuring the equitable treatment of low-frequency neurons and consequently enhancing overall model accuracy.","Extensive experiments conducted on three public benchmarks demonstrate that FedSAC outperforms all baseline methods in both fairness and model accuracy.","We see this work as a significant step towards incentivizing broader client participation in federated learning.","The source code is available at https://github.com/wangzihuixmu/FedSAC."],"url":"http://arxiv.org/abs/2405.18291v1","category":"cs.LG"}
{"created":"2024-05-28 15:36:48","title":"Adaptive debiased SGD in high-dimensional GLMs with steaming data","abstract":"Online statistical inference facilitates real-time analysis of sequentially collected data, making it different from traditional methods that rely on static datasets. This paper introduces a novel approach to online inference in high-dimensional generalized linear models, where we update regression coefficient estimates and their standard errors upon each new data arrival. In contrast to existing methods that either require full dataset access or large-dimensional summary statistics storage, our method operates in a single-pass mode, significantly reducing both time and space complexity. The core of our methodological innovation lies in an adaptive stochastic gradient descent algorithm tailored for dynamic objective functions, coupled with a novel online debiasing procedure. This allows us to maintain low-dimensional summary statistics while effectively controlling optimization errors introduced by the dynamically changing loss functions. We demonstrate that our method, termed the Approximated Debiased Lasso (ADL), not only mitigates the need for the bounded individual probability condition but also significantly improves numerical performance. Numerical experiments demonstrate that the proposed ADL method consistently exhibits robust performance across various covariance matrix structures.","sentences":["Online statistical inference facilitates real-time analysis of sequentially collected data, making it different from traditional methods that rely on static datasets.","This paper introduces a novel approach to online inference in high-dimensional generalized linear models, where we update regression coefficient estimates and their standard errors upon each new data arrival.","In contrast to existing methods that either require full dataset access or large-dimensional summary statistics storage, our method operates in a single-pass mode, significantly reducing both time and space complexity.","The core of our methodological innovation lies in an adaptive stochastic gradient descent algorithm tailored for dynamic objective functions, coupled with a novel online debiasing procedure.","This allows us to maintain low-dimensional summary statistics while effectively controlling optimization errors introduced by the dynamically changing loss functions.","We demonstrate that our method, termed the Approximated Debiased Lasso (ADL), not only mitigates the need for the bounded individual probability condition but also significantly improves numerical performance.","Numerical experiments demonstrate that the proposed ADL method consistently exhibits robust performance across various covariance matrix structures."],"url":"http://arxiv.org/abs/2405.18284v1","category":"stat.ML"}
{"created":"2024-05-28 15:17:58","title":"CT-based brain ventricle segmentation via diffusion Schr\u00f6dinger Bridge without target domain ground truths","abstract":"Efficient and accurate brain ventricle segmentation from clinical CT scans is critical for emergency surgeries like ventriculostomy. With the challenges in poor soft tissue contrast and a scarcity of well-annotated databases for clinical brain CTs, we introduce a novel uncertainty-aware ventricle segmentation technique without the need of CT segmentation ground truths by leveraging diffusion-model-based domain adaptation. Specifically, our method employs the diffusion Schr\\\"odinger Bridge and an attention recurrent residual U-Net to capitalize on unpaired CT and MRI scans to derive automatic CT segmentation from those of the MRIs, which are more accessible. Importantly, we propose an end-to-end, joint training framework of image translation and segmentation tasks, and demonstrate its benefit over training individual tasks separately. By comparing the proposed method against similar setups using two different GAN models for domain adaptation (CycleGAN and CUT), we also reveal the advantage of diffusion models towards improved segmentation and image translation quality. With a Dice score of 0.78$\\pm$0.27, our proposed method outperformed the compared methods, including SynSeg-Net, while providing intuitive uncertainty measures to further facilitate quality control of the automatic segmentation outcomes.","sentences":["Efficient and accurate brain ventricle segmentation from clinical CT scans is critical for emergency surgeries like ventriculostomy.","With the challenges in poor soft tissue contrast and a scarcity of well-annotated databases for clinical brain CTs, we introduce a novel uncertainty-aware ventricle segmentation technique without the need of CT segmentation ground truths by leveraging diffusion-model-based domain adaptation.","Specifically, our method employs the diffusion Schr\\\"odinger Bridge and an attention recurrent residual U-Net to capitalize on unpaired CT and MRI scans to derive automatic CT segmentation from those of the MRIs, which are more accessible.","Importantly, we propose an end-to-end, joint training framework of image translation and segmentation tasks, and demonstrate its benefit over training individual tasks separately.","By comparing the proposed method against similar setups using two different GAN models for domain adaptation (CycleGAN and CUT), we also reveal the advantage of diffusion models towards improved segmentation and image translation quality.","With a Dice score of 0.78$\\pm$0.27, our proposed method outperformed the compared methods, including SynSeg-Net, while providing intuitive uncertainty measures to further facilitate quality control of the automatic segmentation outcomes."],"url":"http://arxiv.org/abs/2405.18267v1","category":"eess.IV"}
{"created":"2024-05-28 15:17:03","title":"Population III star formation in the presence of turbulence, magnetic fields and ionizing radiation feedback","abstract":"Turbulence, magnetic fields and radiation feedback are key components that shape the formation of stars, especially in the metal-free environments at high redshifts where Population III stars form. Yet no 3D numerical simulations exist that simultaneously take all of these into account. We present the first suite of radiation-magnetohydrodynamics (RMHD) simulations of Population III star formation using the adaptive mesh refinement (AMR) code FLASH. We include both turbulent magnetic fields and ionizing radiation feedback coupled to primordial chemistry, and resolve the collapse of primordial clouds down to few au. We find that dynamically strong magnetic fields significantly slow down accretion onto protostars, while ionizing feedback is largely unable to regulate gas accretion because the partially ionized \\ion{H}{ii} region gets trapped near the star due to insufficient radiative outputs from the star. The maximum stellar mass in the HD and RHD simulations that only yield one star exceeds $100\\,\\rm{M_{\\odot}}$ within the first $5000\\,\\rm{yr}$. However, in the corresponding MHD and RMHD runs, the maximum mass of Population III star is only $60\\,\\rm{M_{\\odot}}$. In other realizations where we observe widespread fragmentation leading to the formation of Population III star clusters, the maximum stellar mass is further reduced by a factor of few due to fragmentation-induced starvation. We thus conclude that magnetic fields are more important than ionizing feedback in regulating the mass of the star, at least during the earliest stages of Population III star formation, in typical dark matter minihaloes at $z \\approx 30$.","sentences":["Turbulence, magnetic fields and radiation feedback are key components that shape the formation of stars, especially in the metal-free environments at high redshifts where Population III stars form.","Yet no 3D numerical simulations exist that simultaneously take all of these into account.","We present the first suite of radiation-magnetohydrodynamics (RMHD) simulations of Population III star formation using the adaptive mesh refinement (AMR) code FLASH.","We include both turbulent magnetic fields and ionizing radiation feedback coupled to primordial chemistry, and resolve the collapse of primordial clouds down to few au.","We find that dynamically strong magnetic fields significantly slow down accretion onto protostars, while ionizing feedback is largely unable to regulate gas accretion because the partially ionized \\ion{H}{ii} region gets trapped near the star due to insufficient radiative outputs from the star.","The maximum stellar mass in the HD and RHD simulations that only yield one star exceeds $100\\,\\rm{M_{\\odot}}$ within the first $5000\\,\\rm{yr}$. However, in the corresponding MHD and RMHD runs, the maximum mass of Population III star is only $60\\,\\rm{M_{\\odot}}$. In other realizations where we observe widespread fragmentation leading to the formation of Population III star clusters, the maximum stellar mass is further reduced by a factor of few due to fragmentation-induced starvation.","We thus conclude that magnetic fields are more important than ionizing feedback in regulating the mass of the star, at least during the earliest stages of Population III star formation, in typical dark matter minihaloes at $z \\approx 30$."],"url":"http://arxiv.org/abs/2405.18265v1","category":"astro-ph.GA"}
{"created":"2024-05-28 15:13:29","title":"A Vlogger-augmented Graph Neural Network Model for Micro-video Recommendation","abstract":"Existing micro-video recommendation models exploit the interactions between users and micro-videos and/or multi-modal information of micro-videos to predict the next micro-video a user will watch, ignoring the information related to vloggers, i.e., the producers of micro-videos. However, in micro-video scenarios, vloggers play a significant role in user-video interactions, since vloggers generally focus on specific topics and users tend to follow the vloggers they are interested in. Therefore, in the paper, we propose a vlogger-augmented graph neural network model VA-GNN, which takes the effect of vloggers into consideration. Specifically, we construct a tripartite graph with users, micro-videos, and vloggers as nodes, capturing user preferences from different views, i.e., the video-view and the vlogger-view. Moreover, we conduct cross-view contrastive learning to keep the consistency between node embeddings from the two different views. Besides, when predicting the next user-video interaction, we adaptively combine the user preferences for a video itself and its vlogger. We conduct extensive experiments on two real-world datasets. The experimental results show that VA-GNN outperforms multiple existing GNN-based recommendation models.","sentences":["Existing micro-video recommendation models exploit the interactions between users and micro-videos and/or multi-modal information of micro-videos to predict the next micro-video a user will watch, ignoring the information related to vloggers, i.e., the producers of micro-videos.","However, in micro-video scenarios, vloggers play a significant role in user-video interactions, since vloggers generally focus on specific topics and users tend to follow the vloggers they are interested in.","Therefore, in the paper, we propose a vlogger-augmented graph neural network model VA-GNN, which takes the effect of vloggers into consideration.","Specifically, we construct a tripartite graph with users, micro-videos, and vloggers as nodes, capturing user preferences from different views, i.e., the video-view and the vlogger-view.","Moreover, we conduct cross-view contrastive learning to keep the consistency between node embeddings from the two different views.","Besides, when predicting the next user-video interaction, we adaptively combine the user preferences for a video itself and its vlogger.","We conduct extensive experiments on two real-world datasets.","The experimental results show that VA-GNN outperforms multiple existing GNN-based recommendation models."],"url":"http://arxiv.org/abs/2405.18260v1","category":"cs.IR"}
{"created":"2024-05-28 14:58:07","title":"Utilitarian Algorithm Configuration for Infinite Parameter Spaces","abstract":"Utilitarian algorithm configuration is a general-purpose technique for automatically searching the parameter space of a given algorithm to optimize its performance, as measured by a given utility function, on a given set of inputs. Recently introduced utilitarian configuration procedures offer optimality guarantees about the returned parameterization while provably adapting to the hardness of the underlying problem. However, the applicability of these approaches is severely limited by the fact that they only search a finite, relatively small set of parameters. They cannot effectively search the configuration space of algorithms with continuous or uncountable parameters. In this paper we introduce a new procedure, which we dub COUP (Continuous, Optimistic Utilitarian Procrastination). COUP is designed to search infinite parameter spaces efficiently to find good configurations quickly. Furthermore, COUP maintains the theoretical benefits of previous utilitarian configuration procedures when applied to finite parameter spaces but is significantly faster, both provably and experimentally.","sentences":["Utilitarian algorithm configuration is a general-purpose technique for automatically searching the parameter space of a given algorithm to optimize its performance, as measured by a given utility function, on a given set of inputs.","Recently introduced utilitarian configuration procedures offer optimality guarantees about the returned parameterization while provably adapting to the hardness of the underlying problem.","However, the applicability of these approaches is severely limited by the fact that they only search a finite, relatively small set of parameters.","They cannot effectively search the configuration space of algorithms with continuous or uncountable parameters.","In this paper we introduce a new procedure, which we dub COUP (Continuous, Optimistic Utilitarian Procrastination).","COUP is designed to search infinite parameter spaces efficiently to find good configurations quickly.","Furthermore, COUP maintains the theoretical benefits of previous utilitarian configuration procedures when applied to finite parameter spaces but is significantly faster, both provably and experimentally."],"url":"http://arxiv.org/abs/2405.18246v1","category":"cs.AI"}
{"created":"2024-05-28 14:50:12","title":"MSPE: Multi-Scale Patch Embedding Prompts Vision Transformers to Any Resolution","abstract":"Although Vision Transformers (ViTs) have recently advanced computer vision tasks significantly, an important real-world problem was overlooked: adapting to variable input resolutions. Typically, images are resized to a fixed resolution, such as 224x224, for efficiency during training and inference. However, uniform input size conflicts with real-world scenarios where images naturally vary in resolution. Modifying the preset resolution of a model may severely degrade the performance. In this work, we propose to enhance the model adaptability to resolution variation by optimizing the patch embedding. The proposed method, called Multi-Scale Patch Embedding (MSPE), substitutes the standard patch embedding with multiple variable-sized patch kernels and selects the best parameters for different resolutions, eliminating the need to resize the original image. Our method does not require high-cost training or modifications to other parts, making it easy to apply to most ViT models. Experiments in image classification, segmentation, and detection tasks demonstrate the effectiveness of MSPE, yielding superior performance on low-resolution inputs and performing comparably on high-resolution inputs with existing methods.","sentences":["Although Vision Transformers (ViTs) have recently advanced computer vision tasks significantly, an important real-world problem was overlooked: adapting to variable input resolutions.","Typically, images are resized to a fixed resolution, such as 224x224, for efficiency during training and inference.","However, uniform input size conflicts with real-world scenarios where images naturally vary in resolution.","Modifying the preset resolution of a model may severely degrade the performance.","In this work, we propose to enhance the model adaptability to resolution variation by optimizing the patch embedding.","The proposed method, called Multi-Scale Patch Embedding (MSPE), substitutes the standard patch embedding with multiple variable-sized patch kernels and selects the best parameters for different resolutions, eliminating the need to resize the original image.","Our method does not require high-cost training or modifications to other parts, making it easy to apply to most ViT models.","Experiments in image classification, segmentation, and detection tasks demonstrate the effectiveness of MSPE, yielding superior performance on low-resolution inputs and performing comparably on high-resolution inputs with existing methods."],"url":"http://arxiv.org/abs/2405.18240v1","category":"cs.CV"}
{"created":"2024-05-28 14:48:19","title":"The CoExplorer Technology Probe: A Generative AI-Powered Adaptive Interface to Support Intentionality in Planning and Running Video Meetings","abstract":"Effective meetings are effortful, but traditional videoconferencing systems offer little support for reducing this effort across the meeting lifecycle. Generative AI (GenAI) has the potential to radically redefine meetings by augmenting intentional meeting behaviors. CoExplorer, our novel adaptive meeting prototype, preemptively generates likely phases that meetings would undergo, tools that allow capturing attendees' thoughts before the meeting, and for each phase, window layouts, and appropriate applications and files. Using CoExplorer as a technology probe in a guided walkthrough, we studied its potential in a sample of participants from a global technology company. Our findings suggest that GenAI has the potential to help meetings stay on track and reduce workload, although concerns were raised about users' agency, trust, and possible disruption to traditional meeting norms. We discuss these concerns and their design implications for the development of GenAI meeting technology.","sentences":["Effective meetings are effortful, but traditional videoconferencing systems offer little support for reducing this effort across the meeting lifecycle.","Generative AI (GenAI) has the potential to radically redefine meetings by augmenting intentional meeting behaviors.","CoExplorer, our novel adaptive meeting prototype, preemptively generates likely phases that meetings would undergo, tools that allow capturing attendees' thoughts before the meeting, and for each phase, window layouts, and appropriate applications and files.","Using CoExplorer as a technology probe in a guided walkthrough, we studied its potential in a sample of participants from a global technology company.","Our findings suggest that GenAI has the potential to help meetings stay on track and reduce workload, although concerns were raised about users' agency, trust, and possible disruption to traditional meeting norms.","We discuss these concerns and their design implications for the development of GenAI meeting technology."],"url":"http://arxiv.org/abs/2405.18239v2","category":"cs.HC"}
{"created":"2024-05-28 14:34:51","title":"SSLChange: A Self-supervised Change Detection Framework Based on Domain Adaptation","abstract":"In conventional remote sensing change detection (RS CD) procedures, extensive manual labeling for bi-temporal images is first required to maintain the performance of subsequent fully supervised training. However, pixel-level labeling for CD tasks is very complex and time-consuming. In this paper, we explore a novel self-supervised contrastive framework applicable to the RS CD task, which promotes the model to accurately capture spatial, structural, and semantic information through domain adapter and hierarchical contrastive head. The proposed SSLChange framework accomplishes self-learning only by taking a single-temporal sample and can be flexibly transferred to main-stream CD baselines. With self-supervised contrastive learning, feature representation pre-training can be performed directly based on the original data even without labeling. After a certain amount of labels are subsequently obtained, the pre-trained features will be aligned with the labels for fully supervised fine-tuning. Without introducing any additional data or labels, the performance of downstream baselines will experience a significant enhancement. Experimental results on 2 entire datasets and 6 diluted datasets show that our proposed SSLChange improves the performance and stability of CD baseline in data-limited situations. The code of SSLChange will be released at \\url{https://github.com/MarsZhaoYT/SSLChange}","sentences":["In conventional remote sensing change detection (RS CD) procedures, extensive manual labeling for bi-temporal images is first required to maintain the performance of subsequent fully supervised training.","However, pixel-level labeling for CD tasks is very complex and time-consuming.","In this paper, we explore a novel self-supervised contrastive framework applicable to the RS CD task, which promotes the model to accurately capture spatial, structural, and semantic information through domain adapter and hierarchical contrastive head.","The proposed SSLChange framework accomplishes self-learning only by taking a single-temporal sample and can be flexibly transferred to main-stream CD baselines.","With self-supervised contrastive learning, feature representation pre-training can be performed directly based on the original data even without labeling.","After a certain amount of labels are subsequently obtained, the pre-trained features will be aligned with the labels for fully supervised fine-tuning.","Without introducing any additional data or labels, the performance of downstream baselines will experience a significant enhancement.","Experimental results on 2 entire datasets and 6 diluted datasets show that our proposed SSLChange improves the performance and stability of CD baseline in data-limited situations.","The code of SSLChange will be released at \\url{https://github.com/MarsZhaoYT/SSLChange}"],"url":"http://arxiv.org/abs/2405.18224v1","category":"cs.CV"}
{"created":"2024-05-28 14:30:07","title":"From Learning to Optimize to Learning Optimization Algorithms","abstract":"Towards designing learned optimization algorithms that are usable beyond their training setting, we identify key principles that classical algorithms obey, but have up to now, not been used for Learning to Optimize (L2O). Following these principles, we provide a general design pipeline, taking into account data, architecture and learning strategy, and thereby enabling a synergy between classical optimization and L2O, resulting in a philosophy of Learning Optimization Algorithms. As a consequence our learned algorithms perform well far beyond problems from the training distribution. We demonstrate the success of these novel principles by designing a new learning-enhanced BFGS algorithm and provide numerical experiments evidencing its adaptation to many settings at test time.","sentences":["Towards designing learned optimization algorithms that are usable beyond their training setting, we identify key principles that classical algorithms obey, but have up to now, not been used for Learning to Optimize (L2O).","Following these principles, we provide a general design pipeline, taking into account data, architecture and learning strategy, and thereby enabling a synergy between classical optimization and L2O, resulting in a philosophy of Learning Optimization Algorithms.","As a consequence our learned algorithms perform well far beyond problems from the training distribution.","We demonstrate the success of these novel principles by designing a new learning-enhanced BFGS algorithm and provide numerical experiments evidencing its adaptation to many settings at test time."],"url":"http://arxiv.org/abs/2405.18222v1","category":"cs.LG"}
{"created":"2024-05-28 14:28:28","title":"Non-negative Tensor Mixture Learning for Discrete Density Estimation","abstract":"We present an expectation-maximization (EM) based unified framework for non-negative tensor decomposition that optimizes the Kullback-Leibler divergence. To avoid iterations in each M-step and learning rate tuning, we establish a general relationship between low-rank decomposition and many-body approximation. Using this connection, we exploit that the closed-form solution of the many-body approximation can be used to update all parameters simultaneously in the M-step. Our framework not only offers a unified methodology for a variety of low-rank structures, including CP, Tucker, and Train decompositions, but also their combinations forming mixtures of tensors as well as robust adaptive noise modeling. Empirically, we demonstrate that our framework provides superior generalization for discrete density estimation compared to conventional tensor-based approaches.","sentences":["We present an expectation-maximization (EM) based unified framework for non-negative tensor decomposition that optimizes the Kullback-Leibler divergence.","To avoid iterations in each M-step and learning rate tuning, we establish a general relationship between low-rank decomposition and many-body approximation.","Using this connection, we exploit that the closed-form solution of the many-body approximation can be used to update all parameters simultaneously in the M-step.","Our framework not only offers a unified methodology for a variety of low-rank structures, including CP, Tucker, and Train decompositions, but also their combinations forming mixtures of tensors as well as robust adaptive noise modeling.","Empirically, we demonstrate that our framework provides superior generalization for discrete density estimation compared to conventional tensor-based approaches."],"url":"http://arxiv.org/abs/2405.18220v1","category":"stat.ML"}
{"created":"2024-05-28 14:11:01","title":"IAPT: Instruction-Aware Prompt Tuning for Large Language Models","abstract":"Soft prompt tuning is a widely studied parameter-efficient fine-tuning method. However, it has a clear drawback: many soft tokens must be inserted into the input sequences to guarantee downstream performance. As a result, soft prompt tuning is less considered than Low-rank adaptation (LoRA) in the large language modeling (LLM) era. In this work, we propose a novel prompt tuning method, Instruction-Aware Prompt Tuning (IAPT), that requires only four soft tokens. First, we install a parameter-efficient soft prompt generator at each Transformer layer to generate idiosyncratic soft prompts for each input instruction. The generated soft prompts can be seen as a semantic summary of the input instructions and can effectively guide the output generation. Second, the soft prompt generators are modules with a bottleneck architecture consisting of a self-attention pooling operation, two linear projections, and an activation function. Pilot experiments show that prompt generators at different Transformer layers require different activation functions. Thus, we propose to learn the idiosyncratic activation functions for prompt generators automatically with the help of rational functions. We have conducted experiments on various tasks, and the experimental results demonstrate that (a) our IAPT method can outperform the recent baselines with comparable tunable parameters. (b) Our IAPT method is more efficient than LoRA under the single-backbone multi-tenant setting.","sentences":["Soft prompt tuning is a widely studied parameter-efficient fine-tuning method.","However, it has a clear drawback: many soft tokens must be inserted into the input sequences to guarantee downstream performance.","As a result, soft prompt tuning is less considered than Low-rank adaptation (LoRA) in the large language modeling (LLM) era.","In this work, we propose a novel prompt tuning method, Instruction-Aware Prompt Tuning (IAPT), that requires only four soft tokens.","First, we install a parameter-efficient soft prompt generator at each Transformer layer to generate idiosyncratic soft prompts for each input instruction.","The generated soft prompts can be seen as a semantic summary of the input instructions and can effectively guide the output generation.","Second, the soft prompt generators are modules with a bottleneck architecture consisting of a self-attention pooling operation, two linear projections, and an activation function.","Pilot experiments show that prompt generators at different Transformer layers require different activation functions.","Thus, we propose to learn the idiosyncratic activation functions for prompt generators automatically with the help of rational functions.","We have conducted experiments on various tasks, and the experimental results demonstrate that (a) our IAPT method can outperform the recent baselines with comparable tunable parameters.","(b) Our IAPT method is more efficient than LoRA under the single-backbone multi-tenant setting."],"url":"http://arxiv.org/abs/2405.18203v1","category":"cs.CL"}
{"created":"2024-05-28 14:08:04","title":"Adam with model exponential moving average is effective for nonconvex optimization","abstract":"In this work, we offer a theoretical analysis of two modern optimization techniques for training large and complex models: (i) adaptive optimization algorithms, such as Adam, and (ii) the model exponential moving average (EMA). Specifically, we demonstrate that a clipped version of Adam with model EMA achieves the optimal convergence rates in various nonconvex optimization settings, both smooth and nonsmooth. Moreover, when the scale varies significantly across different coordinates, we demonstrate that the coordinate-wise adaptivity of Adam is provably advantageous. Notably, unlike previous analyses of Adam, our analysis crucially relies on its core elements -- momentum and discounting factors -- as well as model EMA, motivating their wide applications in practice.","sentences":["In this work, we offer a theoretical analysis of two modern optimization techniques for training large and complex models: (i) adaptive optimization algorithms, such as Adam, and (ii) the model exponential moving average (EMA).","Specifically, we demonstrate that a clipped version of Adam with model EMA achieves the optimal convergence rates in various nonconvex optimization settings, both smooth and nonsmooth.","Moreover, when the scale varies significantly across different coordinates, we demonstrate that the coordinate-wise adaptivity of Adam is provably advantageous.","Notably, unlike previous analyses of Adam, our analysis crucially relies on its core elements -- momentum and discounting factors -- as well as model EMA, motivating their wide applications in practice."],"url":"http://arxiv.org/abs/2405.18199v1","category":"cs.LG"}
{"created":"2024-05-28 14:03:52","title":"In-Context Symmetries: Self-Supervised Learning through Contextual World Models","abstract":"At the core of self-supervised learning for vision is the idea of learning invariant or equivariant representations with respect to a set of data transformations. This approach, however, introduces strong inductive biases, which can render the representations fragile in downstream tasks that do not conform to these symmetries. In this work, drawing insights from world models, we propose to instead learn a general representation that can adapt to be invariant or equivariant to different transformations by paying attention to context -- a memory module that tracks task-specific states, actions, and future states. Here, the action is the transformation, while the current and future states respectively represent the input's representation before and after the transformation. Our proposed algorithm, Contextual Self-Supervised Learning (ContextSSL), learns equivariance to all transformations (as opposed to invariance). In this way, the model can learn to encode all relevant features as general representations while having the versatility to tail down to task-wise symmetries when given a few examples as the context. Empirically, we demonstrate significant performance gains over existing methods on equivariance-related tasks, supported by both qualitative and quantitative evaluations.","sentences":["At the core of self-supervised learning for vision is the idea of learning invariant or equivariant representations with respect to a set of data transformations.","This approach, however, introduces strong inductive biases, which can render the representations fragile in downstream tasks that do not conform to these symmetries.","In this work, drawing insights from world models, we propose to instead learn a general representation that can adapt to be invariant or equivariant to different transformations by paying attention to context -- a memory module that tracks task-specific states, actions, and future states.","Here, the action is the transformation, while the current and future states respectively represent the input's representation before and after the transformation.","Our proposed algorithm, Contextual Self-Supervised Learning (ContextSSL), learns equivariance to all transformations (as opposed to invariance).","In this way, the model can learn to encode all relevant features as general representations while having the versatility to tail down to task-wise symmetries when given a few examples as the context.","Empirically, we demonstrate significant performance gains over existing methods on equivariance-related tasks, supported by both qualitative and quantitative evaluations."],"url":"http://arxiv.org/abs/2405.18193v1","category":"cs.LG"}
{"created":"2024-05-28 13:47:21","title":"Safe Reinforcement Learning in Black-Box Environments via Adaptive Shielding","abstract":"Empowering safe exploration of reinforcement learning (RL) agents during training is a critical impediment towards deploying RL agents in many real-world scenarios. Training RL agents in unknown, black-box environments poses an even greater safety risk when prior knowledge of the domain/task is unavailable. We introduce ADVICE (Adaptive Shielding with a Contrastive Autoencoder), a novel post-shielding technique that distinguishes safe and unsafe features of state-action pairs during training, thus protecting the RL agent from executing actions that yield potentially hazardous outcomes. Our comprehensive experimental evaluation against state-of-the-art safe RL exploration techniques demonstrates how ADVICE can significantly reduce safety violations during training while maintaining a competitive outcome reward.","sentences":["Empowering safe exploration of reinforcement learning (RL) agents during training is a critical impediment towards deploying RL agents in many real-world scenarios.","Training RL agents in unknown, black-box environments poses an even greater safety risk when prior knowledge of the domain/task is unavailable.","We introduce ADVICE (Adaptive Shielding with a Contrastive Autoencoder), a novel post-shielding technique that distinguishes safe and unsafe features of state-action pairs during training, thus protecting the RL agent from executing actions that yield potentially hazardous outcomes.","Our comprehensive experimental evaluation against state-of-the-art safe RL exploration techniques demonstrates how ADVICE can significantly reduce safety violations during training while maintaining a competitive outcome reward."],"url":"http://arxiv.org/abs/2405.18180v1","category":"cs.AI"}
{"created":"2024-05-28 13:29:31","title":"Efficient Adaptable Streaming Aggregation Engine","abstract":"Aggregation queries are a series of computationally-demanding analytics operations on grouped and/or time series (streaming) data. They include tasks such as summation or finding the mean among the items of a group (sharing a group ID) or within the last N observed tuples. They have a wide range of applications including in database analytics, operating systems, bank security and medical sensors. Existing challenges include the increased hardware utilisation and random memory access patterns that result from hash-based approaches or multi-tasking as a way to introduce parallelism. There are also challenges relating to the degree of which the function can be calculated incrementally for sliding windows, such as with overlapping windows. This paper presents a pipelined and reconfigurable approach for calculating a wide range of aggregation queries with minimal hardware overhead.","sentences":["Aggregation queries are a series of computationally-demanding analytics operations on grouped and/or time series (streaming) data.","They include tasks such as summation or finding the mean among the items of a group (sharing a group ID) or within the last N observed tuples.","They have a wide range of applications including in database analytics, operating systems, bank security and medical sensors.","Existing challenges include the increased hardware utilisation and random memory access patterns that result from hash-based approaches or multi-tasking as a way to introduce parallelism.","There are also challenges relating to the degree of which the function can be calculated incrementally for sliding windows, such as with overlapping windows.","This paper presents a pipelined and reconfigurable approach for calculating a wide range of aggregation queries with minimal hardware overhead."],"url":"http://arxiv.org/abs/2405.18168v1","category":"cs.AR"}
{"created":"2024-05-28 13:25:31","title":"Time Series Representation Models","abstract":"Time series analysis remains a major challenge due to its sparse characteristics, high dimensionality, and inconsistent data quality. Recent advancements in transformer-based techniques have enhanced capabilities in forecasting and imputation; however, these methods are still resource-heavy, lack adaptability, and face difficulties in integrating both local and global attributes of time series. To tackle these challenges, we propose a new architectural concept for time series analysis based on introspection. Central to this concept is the self-supervised pretraining of Time Series Representation Models (TSRMs), which once learned can be easily tailored and fine-tuned for specific tasks, such as forecasting and imputation, in an automated and resource-efficient manner. Our architecture is equipped with a flexible and hierarchical representation learning process, which is robust against missing data and outliers. It can capture and learn both local and global features of the structure, semantics, and crucial patterns of a given time series category, such as heart rate data. Our learned time series representation models can be efficiently adapted to a specific task, such as forecasting or imputation, without manual intervention. Furthermore, our architecture's design supports explainability by highlighting the significance of each input value for the task at hand. Our empirical study using four benchmark datasets shows that, compared to investigated state-of-the-art baseline methods, our architecture improves imputation and forecasting errors by up to 90.34% and 71.54%, respectively, while reducing the required trainable parameters by up to 92.43%. The source code is available at https://github.com/RobertLeppich/TSRM.","sentences":["Time series analysis remains a major challenge due to its sparse characteristics, high dimensionality, and inconsistent data quality.","Recent advancements in transformer-based techniques have enhanced capabilities in forecasting and imputation; however, these methods are still resource-heavy, lack adaptability, and face difficulties in integrating both local and global attributes of time series.","To tackle these challenges, we propose a new architectural concept for time series analysis based on introspection.","Central to this concept is the self-supervised pretraining of Time Series Representation Models (TSRMs), which once learned can be easily tailored and fine-tuned for specific tasks, such as forecasting and imputation, in an automated and resource-efficient manner.","Our architecture is equipped with a flexible and hierarchical representation learning process, which is robust against missing data and outliers.","It can capture and learn both local and global features of the structure, semantics, and crucial patterns of a given time series category, such as heart rate data.","Our learned time series representation models can be efficiently adapted to a specific task, such as forecasting or imputation, without manual intervention.","Furthermore, our architecture's design supports explainability by highlighting the significance of each input value for the task at hand.","Our empirical study using four benchmark datasets shows that, compared to investigated state-of-the-art baseline methods, our architecture improves imputation and forecasting errors by up to 90.34% and 71.54%, respectively, while reducing the required trainable parameters by up to 92.43%.","The source code is available at https://github.com/RobertLeppich/TSRM."],"url":"http://arxiv.org/abs/2405.18165v1","category":"cs.LG"}
{"created":"2024-05-28 13:24:48","title":"Imaging, counting, and positioning single interstitial atoms in solids","abstract":"Interstitial atoms are ubiquitous in solids and they are widely incorporated into materials to tune their lattice structure, electronic transportation, and mechanical properties. Because the distribution of interstitial atoms in matrix materials is usually disordered and most of them are light atoms with weak scattering ability, it remains a challenge to directly image single interstitial atoms and measure their geometrical positions. In this work, direct imaging and measuring of single interstitial atoms have been realized with adaptive-propagator ptychography. The measurement of their three-dimensional coordinates enables quantitative analysis of the pair distribution function of the interstitial atoms and reveals the anisotropic occupation of oxygen in the interstitial sites in titanium. The current work paves the way for the determination of interstitial atoms in materials, and for the correlation between the atomic-scale behavior of interstitial atoms and the physical properties of materials.","sentences":["Interstitial atoms are ubiquitous in solids and they are widely incorporated into materials to tune their lattice structure, electronic transportation, and mechanical properties.","Because the distribution of interstitial atoms in matrix materials is usually disordered and most of them are light atoms with weak scattering ability, it remains a challenge to directly image single interstitial atoms and measure their geometrical positions.","In this work, direct imaging and measuring of single interstitial atoms have been realized with adaptive-propagator ptychography.","The measurement of their three-dimensional coordinates enables quantitative analysis of the pair distribution function of the interstitial atoms and reveals the anisotropic occupation of oxygen in the interstitial sites in titanium.","The current work paves the way for the determination of interstitial atoms in materials, and for the correlation between the atomic-scale behavior of interstitial atoms and the physical properties of materials."],"url":"http://arxiv.org/abs/2405.18164v1","category":"cond-mat.mtrl-sci"}
{"created":"2024-05-28 13:14:26","title":"Practical aspects for the creation of an audio dataset from field recordings with optimized labeling budget with AI-assisted strategy","abstract":"Machine Listening focuses on developing technologies to extract relevant information from audio signals. A critical aspect of these projects is the acquisition and labeling of contextualized data, which is inherently complex and requires specific resources and strategies. Despite the availability of some audio datasets, many are unsuitable for commercial applications. The paper emphasizes the importance of Active Learning (AL) using expert labelers over crowdsourcing, which often lacks detailed insights into dataset structures. AL is an iterative process combining human labelers and AI models to optimize the labeling budget by intelligently selecting samples for human review. This approach addresses the challenge of handling large, constantly growing datasets that exceed available computational resources and memory. The paper presents a comprehensive data-centric framework for Machine Listening projects, detailing the configuration of recording nodes, database structure, and labeling budget optimization in resource-constrained scenarios. Applied to an industrial port in Valencia, Spain, the framework successfully labeled 6540 ten-second audio samples over five months with a small team, demonstrating its effectiveness and adaptability to various resource availability situations.","sentences":["Machine Listening focuses on developing technologies to extract relevant information from audio signals.","A critical aspect of these projects is the acquisition and labeling of contextualized data, which is inherently complex and requires specific resources and strategies.","Despite the availability of some audio datasets, many are unsuitable for commercial applications.","The paper emphasizes the importance of Active Learning (AL) using expert labelers over crowdsourcing, which often lacks detailed insights into dataset structures.","AL is an iterative process combining human labelers and AI models to optimize the labeling budget by intelligently selecting samples for human review.","This approach addresses the challenge of handling large, constantly growing datasets that exceed available computational resources and memory.","The paper presents a comprehensive data-centric framework for Machine Listening projects, detailing the configuration of recording nodes, database structure, and labeling budget optimization in resource-constrained scenarios.","Applied to an industrial port in Valencia, Spain, the framework successfully labeled 6540 ten-second audio samples over five months with a small team, demonstrating its effectiveness and adaptability to various resource availability situations."],"url":"http://arxiv.org/abs/2405.18153v1","category":"cs.SD"}
{"created":"2024-05-28 13:06:32","title":"Unified Low-rank Compression Framework for Click-through Rate Prediction","abstract":"Deep Click-Through Rate (CTR) prediction models play an important role in modern industrial recommendation scenarios. However, high memory overhead and computational costs limit their deployment in resource-constrained environments. Low-rank approximation is an effective method for computer vision and natural language processing models, but its application in compressing CTR prediction models has been less explored. Due to the limited memory and computing resources, compression of CTR prediction models often confronts three fundamental challenges, i.e., (1). How to reduce the model sizes to adapt to edge devices? (2). How to speed up CTR prediction model inference? (3). How to retain the capabilities of original models after compression? Previous low-rank compression research mostly uses tensor decomposition, which can achieve a high parameter compression ratio, but brings in AUC degradation and additional computing overhead. To address these challenges, we propose a unified low-rank decomposition framework for compressing CTR prediction models. We find that even with the most classic matrix decomposition SVD method, our framework can achieve better performance than the original model. To further improve the effectiveness of our framework, we locally compress the output features instead of compressing the model weights. Our unified low-rank compression framework can be applied to embedding tables and MLP layers in various CTR prediction models. Extensive experiments on two academic datasets and one real industrial benchmark demonstrate that, with 3-5x model size reduction, our compressed models can achieve both faster inference and higher AUC than the uncompressed original models. Our code is at https://github.com/yuhao318/Atomic_Feature_Mimicking.","sentences":["Deep Click-Through Rate (CTR) prediction models play an important role in modern industrial recommendation scenarios.","However, high memory overhead and computational costs limit their deployment in resource-constrained environments.","Low-rank approximation is an effective method for computer vision and natural language processing models, but its application in compressing CTR prediction models has been less explored.","Due to the limited memory and computing resources, compression of CTR prediction models often confronts three fundamental challenges, i.e., (1).","How to reduce the model sizes to adapt to edge devices?","(2).","How to speed up CTR prediction model inference?","(3).","How to retain the capabilities of original models after compression?","Previous low-rank compression research mostly uses tensor decomposition, which can achieve a high parameter compression ratio, but brings in AUC degradation and additional computing overhead.","To address these challenges, we propose a unified low-rank decomposition framework for compressing CTR prediction models.","We find that even with the most classic matrix decomposition SVD method, our framework can achieve better performance than the original model.","To further improve the effectiveness of our framework, we locally compress the output features instead of compressing the model weights.","Our unified low-rank compression framework can be applied to embedding tables and MLP layers in various CTR prediction models.","Extensive experiments on two academic datasets and one real industrial benchmark demonstrate that, with 3-5x model size reduction, our compressed models can achieve both faster inference and higher AUC than the uncompressed original models.","Our code is at https://github.com/yuhao318/Atomic_Feature_Mimicking."],"url":"http://arxiv.org/abs/2405.18146v1","category":"cs.IR"}
{"created":"2024-05-28 12:48:47","title":"Bringing Rust to Safety-Critical Systems in Space","abstract":"The development of safety-critical aerospace systems is traditionally dominated by the C language. Its language characteristics make it trivial to accidentally introduce memory safety issues resulting in undefined behavior or security vulnerabilities. The Rust language aims to drastically reduce the chance of introducing bugs and consequently produces overall more secure and safer code. However, due to its relatively short lifespan, industry adaption in safety-critical environments is still lacking. This work provides a set of recommendations for the development of safety-critical space systems in Rust. Our recommendations are based on insights from our multi-fold contributions towards safer and more secure aerospace systems: We provide a comprehensive overview of ongoing efforts to adapt Rust for safety-critical system programming, highlighting its potential to enhance system robustness. Next, we introduce a procedure for partially rewriting C-based systems in Rust, offering a pragmatic pathway to improving safety without necessitating a full system overhaul. During the execution of our rewriting case study, we identify and fix three previously undiscovered vulnerabilities in a popular open-source satellite communication protocol. Finally, we introduce a new Rust compiler target configuration for bare metal PowerPC. With this, we aim to broaden Rust's applicability in space-oriented projects, as the architecture is commonly encountered in the domain, e.g., in the James Webb Space Telescope.","sentences":["The development of safety-critical aerospace systems is traditionally dominated by the C language.","Its language characteristics make it trivial to accidentally introduce memory safety issues resulting in undefined behavior or security vulnerabilities.","The Rust language aims to drastically reduce the chance of introducing bugs and consequently produces overall more secure and safer code.","However, due to its relatively short lifespan, industry adaption in safety-critical environments is still lacking.","This work provides a set of recommendations for the development of safety-critical space systems in Rust.","Our recommendations are based on insights from our multi-fold contributions towards safer and more secure aerospace systems: We provide a comprehensive overview of ongoing efforts to adapt Rust for safety-critical system programming, highlighting its potential to enhance system robustness.","Next, we introduce a procedure for partially rewriting C-based systems in Rust, offering a pragmatic pathway to improving safety without necessitating a full system overhaul.","During the execution of our rewriting case study, we identify and fix three previously undiscovered vulnerabilities in a popular open-source satellite communication protocol.","Finally, we introduce a new Rust compiler target configuration for bare metal PowerPC.","With this, we aim to broaden Rust's applicability in space-oriented projects, as the architecture is commonly encountered in the domain, e.g., in the James Webb Space Telescope."],"url":"http://arxiv.org/abs/2405.18135v1","category":"cs.CR"}
{"created":"2024-05-28 12:26:02","title":"Emergent Inequalities in a Primitive Agent-Based Good-Exchange Model","abstract":"Rising inequalities around the globe bring into question our economic systems and the origin of such inequalities. Here we propose a toy agent-based model where each entity is simultaneously producing and consuming indivisible goods. We find that the system exhibits a non-trivial phase transition beyond which a market clearing equilibrium exists but becomes dynamically unreachable. When production capacity exceeds a threshold and adapts too slowly, some agents cannot sell all their goods. This leads to global price deflation and induces strong wealth inequalities, with the spontaneous separation of the population into a rich class and a poor class. We explore ways to alleviate poverty in this model and whether they have real life significance.","sentences":["Rising inequalities around the globe bring into question our economic systems and the origin of such inequalities.","Here we propose a toy agent-based model where each entity is simultaneously producing and consuming indivisible goods.","We find that the system exhibits a non-trivial phase transition beyond which a market clearing equilibrium exists but becomes dynamically unreachable.","When production capacity exceeds a threshold and adapts too slowly, some agents cannot sell all their goods.","This leads to global price deflation and induces strong wealth inequalities, with the spontaneous separation of the population into a rich class and a poor class.","We explore ways to alleviate poverty in this model and whether they have real life significance."],"url":"http://arxiv.org/abs/2405.18116v1","category":"cond-mat.dis-nn"}
{"created":"2024-05-28 12:11:24","title":"Quantum-Classical Autoencoder Architectures for End-to-End Radio Communication","abstract":"This paper presents a comprehensive study on the possible hybrid quantum-classical autoencoder architectures for end-to-end radio communication against noisy channel conditions using standard encoded radio signals. The hybrid scenarios include single-sided, i.e., quantum encoder (transmitter) or quantum decoder (receiver), as well as fully quantum channel autoencoder (transmitter-receiver) systems. We provide detailed formulas for each scenario and validate our model through an extensive set of simulations. Our results demonstrate model robustness and adaptability. Supporting experiments are conducted utilizing 4-QAM and 16-QAM schemes and we expect that the model is adaptable to more general encoding schemes. We explore model performance against both additive white Gaussian noise and Rayleigh fading models. Our findings highlight the importance of designing efficient quantum neural network architectures for meeting application performance constraints -- including data re-uploading methods, encoding schemes, and core layer structures. By offering a general framework, this work paves the way for further exploration and development of quantum machine learning applications in radio communication.","sentences":["This paper presents a comprehensive study on the possible hybrid quantum-classical autoencoder architectures for end-to-end radio communication against noisy channel conditions using standard encoded radio signals.","The hybrid scenarios include single-sided, i.e., quantum encoder (transmitter) or quantum decoder (receiver), as well as fully quantum channel autoencoder (transmitter-receiver) systems.","We provide detailed formulas for each scenario and validate our model through an extensive set of simulations.","Our results demonstrate model robustness and adaptability.","Supporting experiments are conducted utilizing 4-QAM and 16-QAM schemes and we expect that the model is adaptable to more general encoding schemes.","We explore model performance against both additive white Gaussian noise and Rayleigh fading models.","Our findings highlight the importance of designing efficient quantum neural network architectures for meeting application performance constraints -- including data re-uploading methods, encoding schemes, and core layer structures.","By offering a general framework, this work paves the way for further exploration and development of quantum machine learning applications in radio communication."],"url":"http://arxiv.org/abs/2405.18105v1","category":"quant-ph"}
{"created":"2024-05-28 11:57:29","title":"An adaptive transfer learning perspective on classification in non-stationary environments","abstract":"We consider a semi-supervised classification problem with non-stationary label-shift in which we observe a labelled data set followed by a sequence of unlabelled covariate vectors in which the marginal probabilities of the class labels may change over time. Our objective is to predict the corresponding class-label for each covariate vector, without ever observing the ground-truth labels, beyond the initial labelled data set. Previous work has demonstrated the potential of sophisticated variants of online gradient descent to perform competitively with the optimal dynamic strategy (Bai et al. 2022). In this work we explore an alternative approach grounded in statistical methods for adaptive transfer learning. We demonstrate the merits of this alternative methodology by establishing a high-probability regret bound on the test error at any given individual test-time, which adapt automatically to the unknown dynamics of the marginal label probabilities. Further more, we give bounds on the average dynamic regret which match the average guarantees of the online learning perspective for any given time interval.","sentences":["We consider a semi-supervised classification problem with non-stationary label-shift in which we observe a labelled data set followed by a sequence of unlabelled covariate vectors in which the marginal probabilities of the class labels may change over time.","Our objective is to predict the corresponding class-label for each covariate vector, without ever observing the ground-truth labels, beyond the initial labelled data set.","Previous work has demonstrated the potential of sophisticated variants of online gradient descent to perform competitively with the optimal dynamic strategy (Bai et al. 2022).","In this work we explore an alternative approach grounded in statistical methods for adaptive transfer learning.","We demonstrate the merits of this alternative methodology by establishing a high-probability regret bound on the test error at any given individual test-time, which adapt automatically to the unknown dynamics of the marginal label probabilities.","Further more, we give bounds on the average dynamic regret which match the average guarantees of the online learning perspective for any given time interval."],"url":"http://arxiv.org/abs/2405.18091v1","category":"math.ST"}
{"created":"2024-05-28 11:29:25","title":"An Empirical Analysis of Forgetting in Pre-trained Models with Incremental Low-Rank Updates","abstract":"Broad, open source availability of large pretrained foundation models on the internet through platforms such as HuggingFace has taken the world of practical deep learning by storm. A classical pipeline for neural network training now typically consists of finetuning these pretrained network on a small target dataset instead of training from scratch. In the case of large models this can be done even on modest hardware using a low rank training technique known as Low-Rank Adaptation (LoRA). While Low Rank training has already been studied in the continual learning setting, existing works often consider storing the learned adapter along with the existing model but rarely attempt to modify the weights of the pretrained model by merging the LoRA with the existing weights after finishing the training of each task. In this article we investigate this setting and study the impact of LoRA rank on the forgetting of the pretraining foundation task and on the plasticity and forgetting of subsequent ones. We observe that this rank has an important impact on forgetting of both the pretraining and downstream tasks. We also observe that vision transformers finetuned in that way exhibit a sort of ``contextual'' forgetting, a behaviour that we do not observe for residual networks and that we believe has not been observed yet in previous continual learning works.","sentences":["Broad, open source availability of large pretrained foundation models on the internet through platforms such as HuggingFace has taken the world of practical deep learning by storm.","A classical pipeline for neural network training now typically consists of finetuning these pretrained network on a small target dataset instead of training from scratch.","In the case of large models this can be done even on modest hardware using a low rank training technique known as Low-Rank Adaptation (LoRA).","While Low Rank training has already been studied in the continual learning setting, existing works often consider storing the learned adapter along with the existing model but rarely attempt to modify the weights of the pretrained model by merging the LoRA with the existing weights after finishing the training of each task.","In this article we investigate this setting and study the impact of LoRA rank on the forgetting of the pretraining foundation task and on the plasticity and forgetting of subsequent ones.","We observe that this rank has an important impact on forgetting of both the pretraining and downstream tasks.","We also observe that vision transformers finetuned in that way exhibit a sort of ``contextual'' forgetting, a behaviour that we do not observe for residual networks and that we believe has not been observed yet in previous continual learning works."],"url":"http://arxiv.org/abs/2405.18069v1","category":"cs.LG"}
{"created":"2024-05-28 11:05:41","title":"Learning-Based Link Anomaly Detection in Continuous-Time Dynamic Graphs","abstract":"Anomaly detection in continuous-time dynamic graphs is an emerging field yet under-explored in the context of learning-based approaches. In this paper, we pioneer structured analyses of link-level anomalies and graph representation learning for identifying anomalous links in these graphs. First, we introduce a fine-grain taxonomy for edge-level anomalies leveraging structural, temporal, and contextual graph properties. We present a method for generating and injecting such typed anomalies into graphs. Next, we introduce a novel method to generate continuous-time dynamic graphs with consistent patterns across time, structure, and context. To allow temporal graph methods to learn the link anomaly detection task, we extend the generic link prediction setting by: (1) conditioning link existence on contextual edge attributes; and (2) refining the training regime to accommodate diverse perturbations in the negative edge sampler. Building on this, we benchmark methods for anomaly detection. Comprehensive experiments on synthetic and real-world datasets -- featuring synthetic and labeled organic anomalies and employing six state-of-the-art learning methods -- validate our taxonomy and generation processes for anomalies and benign graphs, as well as our approach to adapting link prediction methods for anomaly detection. Our results further reveal that different learning methods excel in capturing different aspects of graph normality and detecting different types of anomalies. We conclude with a comprehensive list of findings highlighting opportunities for future research.","sentences":["Anomaly detection in continuous-time dynamic graphs is an emerging field yet under-explored in the context of learning-based approaches.","In this paper, we pioneer structured analyses of link-level anomalies and graph representation learning for identifying anomalous links in these graphs.","First, we introduce a fine-grain taxonomy for edge-level anomalies leveraging structural, temporal, and contextual graph properties.","We present a method for generating and injecting such typed anomalies into graphs.","Next, we introduce a novel method to generate continuous-time dynamic graphs with consistent patterns across time, structure, and context.","To allow temporal graph methods to learn the link anomaly detection task, we extend the generic link prediction setting by: (1) conditioning link existence on contextual edge attributes; and (2) refining the training regime to accommodate diverse perturbations in the negative edge sampler.","Building on this, we benchmark methods for anomaly detection.","Comprehensive experiments on synthetic and real-world datasets -- featuring synthetic and labeled organic anomalies and employing six state-of-the-art learning methods -- validate our taxonomy and generation processes for anomalies and benign graphs, as well as our approach to adapting link prediction methods for anomaly detection.","Our results further reveal that different learning methods excel in capturing different aspects of graph normality and detecting different types of anomalies.","We conclude with a comprehensive list of findings highlighting opportunities for future research."],"url":"http://arxiv.org/abs/2405.18050v1","category":"cs.LG"}
{"created":"2024-05-28 10:56:01","title":"Improving mid-infrared thermal background subtraction with Principal Component Analysis","abstract":"Ground-based large-aperture telescopes, interferometers, and future Extremely Large Telescopes equipped with adaptive-optics systems provide angular resolution and high-contrast performance that are superior to space-based telescopes at thermal-infrared wavelengths. Their sensitivity, however, is critically limited by the high thermal background inherent to ground-based observations in this wavelength regime. We aim to improve the subtraction quality of the thermal-infrared background from ground-based observations, using Principal Component Analysis (PCA). We use data obtained with the Nulling-Optimized Mid-Infrared Camera on the Large Binocular Telescope Interferometer as a proxy for general high-sensitivity, AO-assisted ground-based data. We apply both a classical background subtraction -- using the mean of dedicated background observations -- and a new background subtraction based on a PCA of the background observations. We compare the performances of these two methods in both high-contrast imaging and aperture photometry. Compared to the classical background subtraction approach, PCA background subtraction delivers up to two times better contrasts down to the diffraction limit of the LBT's primary aperture (i.e., 350 mas in N band), that is, in the case of high-contrast imaging. Improvement factor between two and three are obtained over the mean background retrieval within the diffraction limit in the case of aperture photometry. PCA background subtraction significantly improves the sensitivity of ground-based thermal-infrared imaging observations. When applied to LBTI's nulling interferometry data, we expect the method to improve the sensitivity by a similar factor 2-3. This study paves the way to maximising the potential of future infrared ground-based instruments and facilities, such as the future 30m-class telescopes.","sentences":["Ground-based large-aperture telescopes, interferometers, and future Extremely Large Telescopes equipped with adaptive-optics systems provide angular resolution and high-contrast performance that are superior to space-based telescopes at thermal-infrared wavelengths.","Their sensitivity, however, is critically limited by the high thermal background inherent to ground-based observations in this wavelength regime.","We aim to improve the subtraction quality of the thermal-infrared background from ground-based observations, using Principal Component Analysis (PCA).","We use data obtained with the Nulling-Optimized Mid-Infrared Camera on the Large Binocular Telescope Interferometer as a proxy for general high-sensitivity, AO-assisted ground-based data.","We apply both a classical background subtraction -- using the mean of dedicated background observations -- and a new background subtraction based on a PCA of the background observations.","We compare the performances of these two methods in both high-contrast imaging and aperture photometry.","Compared to the classical background subtraction approach, PCA background subtraction delivers up to two times better contrasts down to the diffraction limit of the LBT's primary aperture (i.e., 350 mas in N band), that is, in the case of high-contrast imaging.","Improvement factor between two and three are obtained over the mean background retrieval within the diffraction limit in the case of aperture photometry.","PCA background subtraction significantly improves the sensitivity of ground-based thermal-infrared imaging observations.","When applied to LBTI's nulling interferometry data, we expect the method to improve the sensitivity by a similar factor 2-3.","This study paves the way to maximising the potential of future infrared ground-based instruments and facilities, such as the future 30m-class telescopes."],"url":"http://arxiv.org/abs/2405.18043v1","category":"astro-ph.IM"}
{"created":"2024-05-28 10:40:20","title":"ForecastGrapher: Redefining Multivariate Time Series Forecasting with Graph Neural Networks","abstract":"The challenge of effectively learning inter-series correlations for multivariate time series forecasting remains a substantial and unresolved problem. Traditional deep learning models, which are largely dependent on the Transformer paradigm for modeling long sequences, often fail to integrate information from multiple time series into a coherent and universally applicable model. To bridge this gap, our paper presents ForecastGrapher, a framework reconceptualizes multivariate time series forecasting as a node regression task, providing a unique avenue for capturing the intricate temporal dynamics and inter-series correlations. Our approach is underpinned by three pivotal steps: firstly, generating custom node embeddings to reflect the temporal variations within each series; secondly, constructing an adaptive adjacency matrix to encode the inter-series correlations; and thirdly, augmenting the GNNs' expressive power by diversifying the node feature distribution. To enhance this expressive power, we introduce the Group Feature Convolution GNN (GFC-GNN). This model employs a learnable scaler to segment node features into multiple groups and applies one-dimensional convolutions with different kernel lengths to each group prior to the aggregation phase. Consequently, the GFC-GNN method enriches the diversity of node feature distribution in a fully end-to-end fashion. Through extensive experiments and ablation studies, we show that ForecastGrapher surpasses strong baselines and leading published techniques in the domain of multivariate time series forecasting.","sentences":["The challenge of effectively learning inter-series correlations for multivariate time series forecasting remains a substantial and unresolved problem.","Traditional deep learning models, which are largely dependent on the Transformer paradigm for modeling long sequences, often fail to integrate information from multiple time series into a coherent and universally applicable model.","To bridge this gap, our paper presents ForecastGrapher, a framework reconceptualizes multivariate time series forecasting as a node regression task, providing a unique avenue for capturing the intricate temporal dynamics and inter-series correlations.","Our approach is underpinned by three pivotal steps: firstly, generating custom node embeddings to reflect the temporal variations within each series; secondly, constructing an adaptive adjacency matrix to encode the inter-series correlations; and thirdly, augmenting the GNNs' expressive power by diversifying the node feature distribution.","To enhance this expressive power, we introduce the Group Feature Convolution GNN (GFC-GNN).","This model employs a learnable scaler to segment node features into multiple groups and applies one-dimensional convolutions with different kernel lengths to each group prior to the aggregation phase.","Consequently, the GFC-GNN method enriches the diversity of node feature distribution in a fully end-to-end fashion.","Through extensive experiments and ablation studies, we show that ForecastGrapher surpasses strong baselines and leading published techniques in the domain of multivariate time series forecasting."],"url":"http://arxiv.org/abs/2405.18036v1","category":"cs.LG"}
{"created":"2024-05-28 10:26:37","title":"Modeling and Controlling Many-Core HPC Processors: an Alternative to PID and Moving Average Algorithms","abstract":"The race towards performance increase and computing power has led to chips with heterogeneous and complex designs, integrating an ever-growing number of cores on the same monolithic chip or chiplet silicon die. Higher integration density, compounded with the slowdown of technology-driven power reduction, implies that power and thermal management become increasingly relevant. Unfortunately, existing research lacks a detailed analysis and modeling of thermal, power, and electrical coupling effects and how they have to be jointly considered to perform dynamic control of complex and heterogeneous Multi-Processor System on Chips (MPSoCs). To close the gap, in this work, we first provide a detailed thermal and power model targeting a modern High Performance Computing (HPC) MPSoC. We consider real-world coupling effects such as actuators' non-idealities and the exponential relation between the dissipated power, the temperature state, and the voltage level in a single processing element. We analyze how these factors affect the control algorithm behavior and the type of challenges that they pose. Based on the analysis, we propose a thermal capping strategy inspired by Fuzzy control theory to replace the state-of-the-art PID controller, as well as a root-finding iterative method to optimally choose the shared voltage value among cores grouped in the same voltage domain. We evaluate the proposed controller with model-in-the-loop and hardware-in-the-loop co-simulations. We show an improvement over state-of-the-art methods of up to 5x the maximum exceeded temperature while providing an average of 3.56% faster application execution runtime across all the evaluation scenarios.","sentences":["The race towards performance increase and computing power has led to chips with heterogeneous and complex designs, integrating an ever-growing number of cores on the same monolithic chip or chiplet silicon die.","Higher integration density, compounded with the slowdown of technology-driven power reduction, implies that power and thermal management become increasingly relevant.","Unfortunately, existing research lacks a detailed analysis and modeling of thermal, power, and electrical coupling effects and how they have to be jointly considered to perform dynamic control of complex and heterogeneous Multi-Processor System on Chips (MPSoCs).","To close the gap, in this work, we first provide a detailed thermal and power model targeting a modern High Performance Computing (HPC) MPSoC. We consider real-world coupling effects such as actuators' non-idealities and the exponential relation between the dissipated power, the temperature state, and the voltage level in a single processing element.","We analyze how these factors affect the control algorithm behavior and the type of challenges that they pose.","Based on the analysis, we propose a thermal capping strategy inspired by Fuzzy control theory to replace the state-of-the-art PID controller, as well as a root-finding iterative method to optimally choose the shared voltage value among cores grouped in the same voltage domain.","We evaluate the proposed controller with model-in-the-loop and hardware-in-the-loop co-simulations.","We show an improvement over state-of-the-art methods of up to 5x the maximum exceeded temperature while providing an average of 3.56% faster application execution runtime across all the evaluation scenarios."],"url":"http://arxiv.org/abs/2405.18030v1","category":"eess.SY"}
{"created":"2024-05-28 09:57:28","title":"MultiADE: A Multi-domain Benchmark for Adverse Drug Event Extraction","abstract":"Objective. Active adverse event surveillance monitors Adverse Drug Events (ADE) from different data sources, such as electronic health records, medical literature, social media and search engine logs. Over years, many datasets are created, and shared tasks are organised to facilitate active adverse event surveillance. However, most-if not all-datasets or shared tasks focus on extracting ADEs from a particular type of text. Domain generalisation-the ability of a machine learning model to perform well on new, unseen domains (text types)-is under-explored. Given the rapid advancements in natural language processing, one unanswered question is how far we are from having a single ADE extraction model that are effective on various types of text, such as scientific literature and social media posts}. Methods. We contribute to answering this question by building a multi-domain benchmark for adverse drug event extraction, which we named MultiADE. The new benchmark comprises several existing datasets sampled from different text types and our newly created dataset-CADECv2, which is an extension of CADEC (Karimi, et al., 2015), covering online posts regarding more diverse drugs than CADEC. Our new dataset is carefully annotated by human annotators following detailed annotation guidelines. Conclusion. Our benchmark results show that the generalisation of the trained models is far from perfect, making it infeasible to be deployed to process different types of text. In addition, although intermediate transfer learning is a promising approach to utilising existing resources, further investigation is needed on methods of domain adaptation, particularly cost-effective methods to select useful training instances.","sentences":["Objective.","Active adverse event surveillance monitors Adverse Drug Events (ADE) from different data sources, such as electronic health records, medical literature, social media and search engine logs.","Over years, many datasets are created, and shared tasks are organised to facilitate active adverse event surveillance.","However, most-if not all-datasets or shared tasks focus on extracting ADEs from a particular type of text.","Domain generalisation-the ability of a machine learning model to perform well on new, unseen domains (text types)-is under-explored.","Given the rapid advancements in natural language processing, one unanswered question is how far we are from having a single ADE extraction model that are effective on various types of text, such as scientific literature and social media posts}.","Methods.","We contribute to answering this question by building a multi-domain benchmark for adverse drug event extraction, which we named MultiADE.","The new benchmark comprises several existing datasets sampled from different text types and our newly created dataset-CADECv2, which is an extension of CADEC (Karimi, et al., 2015), covering online posts regarding more diverse drugs than CADEC.","Our new dataset is carefully annotated by human annotators following detailed annotation guidelines.","Conclusion.","Our benchmark results show that the generalisation of the trained models is far from perfect, making it infeasible to be deployed to process different types of text.","In addition, although intermediate transfer learning is a promising approach to utilising existing resources, further investigation is needed on methods of domain adaptation, particularly cost-effective methods to select useful training instances."],"url":"http://arxiv.org/abs/2405.18015v1","category":"cs.CL"}
{"created":"2024-05-28 09:30:44","title":"Local boundedness of cone multipliers","abstract":"We show that the cone multiplier satisfies local $L^p$-$L^q$ bounds only in the trivial range $1\\leq q\\leq 2\\leq p\\leq\\infty$. To do so, we suitably adapt to this setting the proof of Fefferman for the ball multiplier. As a consequence we answer negatively a question by B\\'ekoll\\'e and Bonami (Colloq. Math. 68, 1995, 81-100), regarding the continuity from $L^p\\to L^q$ of the Cauchy-Szeg\\\"o projections associated with a class of bounded symmetric domains in $\\mathbb{C}^n$ with rank $r\\geq2$.","sentences":["We show that the cone multiplier satisfies local $L^p$-$L^q$ bounds only in the trivial range $1\\leq q\\leq 2\\leq p\\leq\\infty$. To do so, we suitably adapt to this setting the proof of Fefferman for the ball multiplier.","As a consequence we answer negatively a question by B\\'ekoll\\'e and Bonami (Colloq.","Math. 68, 1995, 81-100), regarding the continuity from $L^p\\to L^q$ of the Cauchy-Szeg\\\"o projections associated with a class of bounded symmetric domains in $\\mathbb{C}^n$ with rank $r\\geq2$."],"url":"http://arxiv.org/abs/2405.17997v1","category":"math.AP"}
{"created":"2024-05-28 09:20:14","title":"Multi spacecraft study with the Icarus model: Modelling the propagation of CMEs to Mercury and Earth","abstract":"Coronal Mass Ejections (CMEs) are the main drivers of the disturbances in interplanetary space. Understanding the CME interior magnetic structure is crucial for advancing space weather studies. Assessing the capabilities of a numerical heliospheric model is crucial, as understanding the nature and extent of its limitations can be used for improving the model and the space weather predictions based on it.   The present paper aims to test the capabilities of the recently developed heliospheric model Icarus and the linear force-free spheromak model that has been implemented in it.   To validate the Icarus space weather modeling tool, two CME events were selected that were observed by two spacecraft located near Mercury and Earth, respectively. This enables testing the heliospheric model computed with Icarus at two distant locations. The source regions for the CMEs were identified, and the CME parameters were determined and later optimized. Different adaptive mesh refinement levels were applied in the simulations to assess its performance by comparing the simulation results to in-situ measurements.   The first CME event erupted on SOL2013-07-09T15:24. The modeled time series were in good agreement with the observations both at MESSENGER and ACE. The second CME event started on SOL2014-02-16T10:24 and was more complicated, as three CME interactions occurred in this event. It was impossible to recover the observed profiles without modeling the other two CMEs that were observed, one before the main CME and one afterward. For both CME studies, AMR level 3 was sufficient to reconstruct small-scale features near Mercury, while at Earth, AMR level 4 was necessary due to the radially stretched grid that was used.","sentences":["Coronal Mass Ejections (CMEs) are the main drivers of the disturbances in interplanetary space.","Understanding the CME interior magnetic structure is crucial for advancing space weather studies.","Assessing the capabilities of a numerical heliospheric model is crucial, as understanding the nature and extent of its limitations can be used for improving the model and the space weather predictions based on it.   ","The present paper aims to test the capabilities of the recently developed heliospheric model Icarus and the linear force-free spheromak model that has been implemented in it.   ","To validate the Icarus space weather modeling tool, two CME events were selected that were observed by two spacecraft located near Mercury and Earth, respectively.","This enables testing the heliospheric model computed with Icarus at two distant locations.","The source regions for the CMEs were identified, and the CME parameters were determined and later optimized.","Different adaptive mesh refinement levels were applied in the simulations to assess its performance by comparing the simulation results to in-situ measurements.   ","The first CME event erupted on SOL2013-07-09T15:24.","The modeled time series were in good agreement with the observations both at MESSENGER and ACE.","The second CME event started on SOL2014-02-16T10:24 and was more complicated, as three CME interactions occurred in this event.","It was impossible to recover the observed profiles without modeling the other two CMEs that were observed, one before the main CME and one afterward.","For both CME studies, AMR level 3 was sufficient to reconstruct small-scale features near Mercury, while at Earth, AMR level 4 was necessary due to the radially stretched grid that was used."],"url":"http://arxiv.org/abs/2405.17988v1","category":"astro-ph.SR"}
{"created":"2024-05-28 09:19:52","title":"BlueSWAT: A Lightweight State-Aware Security Framework for Bluetooth Low Energy","abstract":"Bluetooth Low Energy (BLE) is a short-range wireless communication technology for resource-constrained IoT devices. Unfortunately, BLE is vulnerable to session-based attacks, where previous packets construct exploitable conditions for subsequent packets to compromise connections. Defending against session-based attacks is challenging because each step in the attack sequence is legitimate when inspected individually. In this paper, we present BlueSWAT, a lightweight state-aware security framework for protecting BLE devices. To perform inspection on the session level rather than individual packets, BlueSWAT leverages a finite state machine (FSM) to monitor sequential actions of connections at runtime. Patterns of session-based attacks are modeled as malicious transition paths in the FSM. To overcome the heterogeneous IoT environment, we develop a lightweight eBPF framework to facilitate universal patch distribution across different BLE architectures and stacks, without requiring device reboot. We implement BlueSWAT on 5 real-world devices with different chips and stacks to demonstrate its cross-device adaptability. On our dataset with 101 real-world BLE vulnerabilities, BlueSWAT can mitigate 76.1% of session-based attacks, outperforming other defense frameworks. In our end-to-end application evaluation, BlueSWAT patches introduce an average of 0.073% memory overhead and negligible latency.","sentences":["Bluetooth Low Energy (BLE) is a short-range wireless communication technology for resource-constrained IoT devices.","Unfortunately, BLE is vulnerable to session-based attacks, where previous packets construct exploitable conditions for subsequent packets to compromise connections.","Defending against session-based attacks is challenging because each step in the attack sequence is legitimate when inspected individually.","In this paper, we present BlueSWAT, a lightweight state-aware security framework for protecting BLE devices.","To perform inspection on the session level rather than individual packets, BlueSWAT leverages a finite state machine (FSM) to monitor sequential actions of connections at runtime.","Patterns of session-based attacks are modeled as malicious transition paths in the FSM.","To overcome the heterogeneous IoT environment, we develop a lightweight eBPF framework to facilitate universal patch distribution across different BLE architectures and stacks, without requiring device reboot.","We implement BlueSWAT on 5 real-world devices with different chips and stacks to demonstrate its cross-device adaptability.","On our dataset with 101 real-world BLE vulnerabilities, BlueSWAT can mitigate 76.1% of session-based attacks, outperforming other defense frameworks.","In our end-to-end application evaluation, BlueSWAT patches introduce an average of 0.073% memory overhead and negligible latency."],"url":"http://arxiv.org/abs/2405.17987v1","category":"cs.CR"}
{"created":"2024-05-28 09:19:05","title":"Representing the dissipation of infinite-dimensional linear port-Hamiltonian systems","abstract":"It is well known that linear and non-linear dissipative port-Hamiltonian systems in finite dimensions admit an energy balance, relating the energy increase in the system with the supplied energy and the dissipated energy. The integrand in the dissipation term is then a function of the state variable. In this note, we answer the question of when this is possible for linear port-Hamiltonian systems in infinite dimensions.","sentences":["It is well known that linear and non-linear dissipative port-Hamiltonian systems in finite dimensions admit an energy balance, relating the energy increase in the system with the supplied energy and the dissipated energy.","The integrand in the dissipation term is then a function of the state variable.","In this note, we answer the question of when this is possible for linear port-Hamiltonian systems in infinite dimensions."],"url":"http://arxiv.org/abs/2405.17986v1","category":"math.AP"}
{"created":"2024-05-28 09:13:12","title":"Explicit formulae for the mean value of products of values of Dirichlet $L$-functions at positive integers","abstract":"Let $m\\ge 1$ be a rational integer. We give an explicit formula for the mean value $$\\frac{2}{\\phi(f)}\\sum_{\\chi (-1)=(-1)^m}\\vert L(m,\\chi )\\vert^2,$$ where $\\chi$ ranges over the $\\phi (f)/2$ Dirichlet characters modulo $f>2$ with the same parity as $m$. We then adapt our proof to obtain explicit means values for products of the form $L(m_1,\\chi_1)\\cdots L(m_{n-1},\\chi_{n-1})\\overline{L(m_n,\\chi_1\\cdots\\chi_{n-1})}$.","sentences":["Let $m\\ge 1$ be a rational integer.","We give an explicit formula for the mean value $$\\frac{2}{\\phi(f)}\\sum_{\\chi (-1)=(-1)^m}\\vert L(m,\\chi )\\vert^2,$$ where $\\chi$ ranges over the $\\phi (f)/2$ Dirichlet characters modulo $f>2$ with the same parity as $m$. We then adapt our proof to obtain explicit means values for products of the form $L(m_1,\\chi_1)\\cdots L(m_{n-1},\\chi_{n-1})\\overline{L(m_n,\\chi_1\\cdots\\chi_{n-1})}$."],"url":"http://arxiv.org/abs/2405.17981v1","category":"math.NT"}
{"created":"2024-05-28 09:06:38","title":"FASTopic: A Fast, Adaptive, Stable, and Transferable Topic Modeling Paradigm","abstract":"Topic models have been evolving rapidly over the years, from conventional to recent neural models. However, existing topic models generally struggle with either effectiveness, efficiency, or stability, highly impeding their practical applications. In this paper, we propose FASTopic, a fast, adaptive, stable, and transferable topic model. FASTopic follows a new paradigm: Dual Semantic-relation Reconstruction (DSR). Instead of previous conventional, neural VAE-based or clustering-based methods, DSR discovers latent topics by reconstruction through modeling the semantic relations among document, topic, and word embeddings. This brings about a neat and efficient topic modeling framework. We further propose a novel Embedding Transport Plan (ETP) method. Rather than early straightforward approaches, ETP explicitly regularizes the semantic relations as optimal transport plans. This addresses the relation bias issue and thus leads to effective topic modeling. Extensive experiments on benchmark datasets demonstrate that our FASTopic shows superior effectiveness, efficiency, adaptivity, stability, and transferability, compared to state-of-the-art baselines across various scenarios. Our code is available at https://github.com/bobxwu/FASTopic .","sentences":["Topic models have been evolving rapidly over the years, from conventional to recent neural models.","However, existing topic models generally struggle with either effectiveness, efficiency, or stability, highly impeding their practical applications.","In this paper, we propose FASTopic, a fast, adaptive, stable, and transferable topic model.","FASTopic follows a new paradigm: Dual Semantic-relation Reconstruction (DSR).","Instead of previous conventional, neural VAE-based or clustering-based methods, DSR discovers latent topics by reconstruction through modeling the semantic relations among document, topic, and word embeddings.","This brings about a neat and efficient topic modeling framework.","We further propose a novel Embedding Transport Plan (ETP) method.","Rather than early straightforward approaches, ETP explicitly regularizes the semantic relations as optimal transport plans.","This addresses the relation bias issue and thus leads to effective topic modeling.","Extensive experiments on benchmark datasets demonstrate that our FASTopic shows superior effectiveness, efficiency, adaptivity, stability, and transferability, compared to state-of-the-art baselines across various scenarios.","Our code is available at https://github.com/bobxwu/FASTopic ."],"url":"http://arxiv.org/abs/2405.17978v1","category":"cs.CL"}
{"created":"2024-05-28 08:40:14","title":"FreeSplat: Generalizable 3D Gaussian Splatting Towards Free-View Synthesis of Indoor Scenes","abstract":"Empowering 3D Gaussian Splatting with generalization ability is appealing. However, existing generalizable 3D Gaussian Splatting methods are largely confined to narrow-range interpolation between stereo images due to their heavy backbones, thus lacking the ability to accurately localize 3D Gaussian and support free-view synthesis across wide view range. In this paper, we present a novel framework FreeSplat that is capable of reconstructing geometrically consistent 3D scenes from long sequence input towards free-view synthesis.Specifically, we firstly introduce Low-cost Cross-View Aggregation achieved by constructing adaptive cost volumes among nearby views and aggregating features using a multi-scale structure. Subsequently, we present the Pixel-wise Triplet Fusion to eliminate redundancy of 3D Gaussians in overlapping view regions and to aggregate features observed across multiple views. Additionally, we propose a simple but effective free-view training strategy that ensures robust view synthesis across broader view range regardless of the number of views. Our empirical results demonstrate state-of-the-art novel view synthesis peformances in both novel view rendered color maps quality and depth maps accuracy across different numbers of input views. We also show that FreeSplat performs inference more efficiently and can effectively reduce redundant Gaussians, offering the possibility of feed-forward large scene reconstruction without depth priors.","sentences":["Empowering 3D Gaussian Splatting with generalization ability is appealing.","However, existing generalizable 3D Gaussian Splatting methods are largely confined to narrow-range interpolation between stereo images due to their heavy backbones, thus lacking the ability to accurately localize 3D Gaussian and support free-view synthesis across wide view range.","In this paper, we present a novel framework FreeSplat that is capable of reconstructing geometrically consistent 3D scenes from long sequence input towards free-view synthesis.","Specifically, we firstly introduce Low-cost Cross-View Aggregation achieved by constructing adaptive cost volumes among nearby views and aggregating features using a multi-scale structure.","Subsequently, we present the Pixel-wise Triplet Fusion to eliminate redundancy of 3D Gaussians in overlapping view regions and to aggregate features observed across multiple views.","Additionally, we propose a simple but effective free-view training strategy that ensures robust view synthesis across broader view range regardless of the number of views.","Our empirical results demonstrate state-of-the-art novel view synthesis peformances in both novel view rendered color maps quality and depth maps accuracy across different numbers of input views.","We also show that FreeSplat performs inference more efficiently and can effectively reduce redundant Gaussians, offering the possibility of feed-forward large scene reconstruction without depth priors."],"url":"http://arxiv.org/abs/2405.17958v1","category":"cs.CV"}
{"created":"2024-05-28 08:11:12","title":"World Models for General Surgical Grasping","abstract":"Intelligent vision control systems for surgical robots should adapt to unknown and diverse objects while being robust to system disturbances. Previous methods did not meet these requirements due to mainly relying on pose estimation and feature tracking. We propose a world-model-based deep reinforcement learning framework \"Grasp Anything for Surgery\" (GAS), that learns a pixel-level visuomotor policy for surgical grasping, enhancing both generality and robustness. In particular, a novel method is proposed to estimate the values and uncertainties of depth pixels for a rigid-link object's inaccurate region based on the empirical prior of the object's size; both depth and mask images of task objects are encoded to a single compact 3-channel image (size: 64x64x3) by dynamically zooming in the mask regions, minimizing the information loss. The learned controller's effectiveness is extensively evaluated in simulation and in a real robot. Our learned visuomotor policy handles: i) unseen objects, including 5 types of target grasping objects and a robot gripper, in unstructured real-world surgery environments, and ii) disturbances in perception and control. Note that we are the first work to achieve a unified surgical control system that grasps diverse surgical objects using different robot grippers on real robots in complex surgery scenes (average success rate: 69%). Our system also demonstrates significant robustness across 6 conditions including background variation, target disturbance, camera pose variation, kinematic control error, image noise, and re-grasping after the gripped target object drops from the gripper. Videos and codes can be found on our project page: https://linhongbin.github.io/gas/.","sentences":["Intelligent vision control systems for surgical robots should adapt to unknown and diverse objects while being robust to system disturbances.","Previous methods did not meet these requirements due to mainly relying on pose estimation and feature tracking.","We propose a world-model-based deep reinforcement learning framework \"Grasp Anything for Surgery\" (GAS), that learns a pixel-level visuomotor policy for surgical grasping, enhancing both generality and robustness.","In particular, a novel method is proposed to estimate the values and uncertainties of depth pixels for a rigid-link object's inaccurate region based on the empirical prior of the object's size; both depth and mask images of task objects are encoded to a single compact 3-channel image (size: 64x64x3) by dynamically zooming in the mask regions, minimizing the information loss.","The learned controller's effectiveness is extensively evaluated in simulation and in a real robot.","Our learned visuomotor policy handles: i) unseen objects, including 5 types of target grasping objects and a robot gripper, in unstructured real-world surgery environments, and ii) disturbances in perception and control.","Note that we are the first work to achieve a unified surgical control system that grasps diverse surgical objects using different robot grippers on real robots in complex surgery scenes (average success rate: 69%).","Our system also demonstrates significant robustness across 6 conditions including background variation, target disturbance, camera pose variation, kinematic control error, image noise, and re-grasping after the gripped target object drops from the gripper.","Videos and codes can be found on our project page: https://linhongbin.github.io/gas/."],"url":"http://arxiv.org/abs/2405.17940v1","category":"cs.RO"}
{"created":"2024-05-28 07:58:33","title":"ToonCrafter: Generative Cartoon Interpolation","abstract":"We introduce ToonCrafter, a novel approach that transcends traditional correspondence-based cartoon video interpolation, paving the way for generative interpolation. Traditional methods, that implicitly assume linear motion and the absence of complicated phenomena like dis-occlusion, often struggle with the exaggerated non-linear and large motions with occlusion commonly found in cartoons, resulting in implausible or even failed interpolation results. To overcome these limitations, we explore the potential of adapting live-action video priors to better suit cartoon interpolation within a generative framework. ToonCrafter effectively addresses the challenges faced when applying live-action video motion priors to generative cartoon interpolation. First, we design a toon rectification learning strategy that seamlessly adapts live-action video priors to the cartoon domain, resolving the domain gap and content leakage issues. Next, we introduce a dual-reference-based 3D decoder to compensate for lost details due to the highly compressed latent prior spaces, ensuring the preservation of fine details in interpolation results. Finally, we design a flexible sketch encoder that empowers users with interactive control over the interpolation results. Experimental results demonstrate that our proposed method not only produces visually convincing and more natural dynamics, but also effectively handles dis-occlusion. The comparative evaluation demonstrates the notable superiority of our approach over existing competitors.","sentences":["We introduce ToonCrafter, a novel approach that transcends traditional correspondence-based cartoon video interpolation, paving the way for generative interpolation.","Traditional methods, that implicitly assume linear motion and the absence of complicated phenomena like dis-occlusion, often struggle with the exaggerated non-linear and large motions with occlusion commonly found in cartoons, resulting in implausible or even failed interpolation results.","To overcome these limitations, we explore the potential of adapting live-action video priors to better suit cartoon interpolation within a generative framework.","ToonCrafter effectively addresses the challenges faced when applying live-action video motion priors to generative cartoon interpolation.","First, we design a toon rectification learning strategy that seamlessly adapts live-action video priors to the cartoon domain, resolving the domain gap and content leakage issues.","Next, we introduce a dual-reference-based 3D decoder to compensate for lost details due to the highly compressed latent prior spaces, ensuring the preservation of fine details in interpolation results.","Finally, we design a flexible sketch encoder that empowers users with interactive control over the interpolation results.","Experimental results demonstrate that our proposed method not only produces visually convincing and more natural dynamics, but also effectively handles dis-occlusion.","The comparative evaluation demonstrates the notable superiority of our approach over existing competitors."],"url":"http://arxiv.org/abs/2405.17933v1","category":"cs.CV"}
{"created":"2024-05-28 07:56:49","title":"Towards Communication-efficient Federated Learning via Sparse and Aligned Adaptive Optimization","abstract":"Adaptive moment estimation (Adam), as a Stochastic Gradient Descent (SGD) variant, has gained widespread popularity in federated learning (FL) due to its fast convergence. However, federated Adam (FedAdam) algorithms suffer from a threefold increase in uplink communication overhead compared to federated SGD (FedSGD) algorithms, which arises from the necessity to transmit both local model updates and first and second moment estimates from distributed devices to the centralized server for aggregation. Driven by this issue, we propose a novel sparse FedAdam algorithm called FedAdam-SSM, wherein distributed devices sparsify the updates of local model parameters and moment estimates and subsequently upload the sparse representations to the centralized server. To further reduce the communication overhead, the updates of local model parameters and moment estimates incorporate a shared sparse mask (SSM) into the sparsification process, eliminating the need for three separate sparse masks. Theoretically, we develop an upper bound on the divergence between the local model trained by FedAdam-SSM and the desired model trained by centralized Adam, which is related to sparsification error and imbalanced data distribution. By minimizing the divergence bound between the model trained by FedAdam-SSM and centralized Adam, we optimize the SSM to mitigate the learning performance degradation caused by sparsification error. Additionally, we provide convergence bounds for FedAdam-SSM in both convex and non-convex objective function settings, and investigate the impact of local epoch, learning rate and sparsification ratio on the convergence rate of FedAdam-SSM. Experimental results show that FedAdam-SSM outperforms baselines in terms of convergence rate (over 1.1$\\times$ faster than the sparse FedAdam baselines) and test accuracy (over 14.5\\% ahead of the quantized FedAdam baselines).","sentences":["Adaptive moment estimation (Adam), as a Stochastic Gradient Descent (SGD) variant, has gained widespread popularity in federated learning (FL) due to its fast convergence.","However, federated Adam (FedAdam) algorithms suffer from a threefold increase in uplink communication overhead compared to federated SGD (FedSGD) algorithms, which arises from the necessity to transmit both local model updates and first and second moment estimates from distributed devices to the centralized server for aggregation.","Driven by this issue, we propose a novel sparse FedAdam algorithm called FedAdam-SSM, wherein distributed devices sparsify the updates of local model parameters and moment estimates and subsequently upload the sparse representations to the centralized server.","To further reduce the communication overhead, the updates of local model parameters and moment estimates incorporate a shared sparse mask (SSM) into the sparsification process, eliminating the need for three separate sparse masks.","Theoretically, we develop an upper bound on the divergence between the local model trained by FedAdam-SSM and the desired model trained by centralized Adam, which is related to sparsification error and imbalanced data distribution.","By minimizing the divergence bound between the model trained by FedAdam-SSM and centralized Adam, we optimize the SSM to mitigate the learning performance degradation caused by sparsification error.","Additionally, we provide convergence bounds for FedAdam-SSM in both convex and non-convex objective function settings, and investigate the impact of local epoch, learning rate and sparsification ratio on the convergence rate of FedAdam-SSM.","Experimental results show that FedAdam-SSM outperforms baselines in terms of convergence rate (over 1.1$\\times$ faster than the sparse FedAdam baselines) and test accuracy (over 14.5\\% ahead of the quantized FedAdam baselines)."],"url":"http://arxiv.org/abs/2405.17932v1","category":"cs.LG"}
{"created":"2024-05-28 07:45:32","title":"Unraveling friction forces of droplets on non-wetting surface","abstract":"This paper explores the friction forces encountered by droplets on non-wetting surfaces, specifically focusing on superhydrophobic and superheated substrates. Employing a combination of experimental techniques, including inclined plane tests and cantilever force sensor measurements, we quantify friction forces across a broad range of velocities and surface types. Our results demonstrate that friction forces vary significantly with changes in droplet velocity and surface characteristics, transitioning from contact line pinning to viscous dissipation in the bulk of the droplet. We propose a universal scaling law that accounts for contact angle hysteresis, viscous dissipation, and aerodynamic drag, providing a comprehensive framework for understanding droplet dynamics on non-wetting surfaces. These findings offer valuable insights for optimizing surface designs in fluid transport and microfluidic applications, paving the way for enhanced efficiency and innovation in these technologies.","sentences":["This paper explores the friction forces encountered by droplets on non-wetting surfaces, specifically focusing on superhydrophobic and superheated substrates.","Employing a combination of experimental techniques, including inclined plane tests and cantilever force sensor measurements, we quantify friction forces across a broad range of velocities and surface types.","Our results demonstrate that friction forces vary significantly with changes in droplet velocity and surface characteristics, transitioning from contact line pinning to viscous dissipation in the bulk of the droplet.","We propose a universal scaling law that accounts for contact angle hysteresis, viscous dissipation, and aerodynamic drag, providing a comprehensive framework for understanding droplet dynamics on non-wetting surfaces.","These findings offer valuable insights for optimizing surface designs in fluid transport and microfluidic applications, paving the way for enhanced efficiency and innovation in these technologies."],"url":"http://arxiv.org/abs/2405.17923v1","category":"physics.flu-dyn"}
{"created":"2024-05-28 07:38:01","title":"Cascaded Group Testing","abstract":"In this paper, we introduce a variation of the group testing problem where each test is specified by an ordered subset of items, and returns the first defective item in the specified order. We refer to this as \\textit{cascaded group testing} and the goal is to identify a small set of $K$ defective items amongst a collection of size $N$, using as few tests as possible. For the adaptive testing regime, we show that a simple scheme is able to find all defective items in at most $K$ tests, which is optimal. For the non-adaptive setting, we first come up with a necessary and sufficient condition for any collection of tests to be feasible for recovering all the defectives. Using this, we are able to show that any feasible non-adaptive strategy requires at least $\\Omega(K^2)$ tests. In terms of achievability, it is easy to show that a collection of $O(K^2 \\log (N/K))$ randomly constructed tests is feasible. We show via carefully constructed explicit designs that one can do significantly better. We provide two simple schemes for $K = 1, 2$ which only require one and two tests respectively irrespective of the number of items $N$. Note that this is in contrast to standard binary group testing, where at least $\\Omega(\\log N)$ tests are required. The case of $K \\ge 3$ is more challenging and here we come up with an iterative design which requires only $\\text{poly}(\\log \\log N)$ tests.","sentences":["In this paper, we introduce a variation of the group testing problem where each test is specified by an ordered subset of items, and returns the first defective item in the specified order.","We refer to this as \\textit{cascaded group testing} and the goal is to identify a small set of $K$ defective items amongst a collection of size $N$, using as few tests as possible.","For the adaptive testing regime, we show that a simple scheme is able to find all defective items in at most $K$ tests, which is optimal.","For the non-adaptive setting, we first come up with a necessary and sufficient condition for any collection of tests to be feasible for recovering all the defectives.","Using this, we are able to show that any feasible non-adaptive strategy requires at least $\\Omega(K^2)$ tests.","In terms of achievability, it is easy to show that a collection of $O(K^2 \\log (N/K))$ randomly constructed tests is feasible.","We show via carefully constructed explicit designs that one can do significantly better.","We provide two simple schemes for $K = 1, 2$ which only require one and two tests respectively irrespective of the number of items $N$. Note that this is in contrast to standard binary group testing, where at least $\\Omega(\\log N)$ tests are required.","The case of $K \\ge 3$ is more challenging and here we come up with an iterative design which requires only $\\text{poly}(\\log \\log N)$ tests."],"url":"http://arxiv.org/abs/2405.17917v1","category":"cs.IT"}
{"created":"2024-05-28 07:24:56","title":"Reliable Object Tracking by Multimodal Hybrid Feature Extraction and Transformer-Based Fusion","abstract":"Visual object tracking, which is primarily based on visible light image sequences, encounters numerous challenges in complicated scenarios, such as low light conditions, high dynamic ranges, and background clutter. To address these challenges, incorporating the advantages of multiple visual modalities is a promising solution for achieving reliable object tracking. However, the existing approaches usually integrate multimodal inputs through adaptive local feature interactions, which cannot leverage the full potential of visual cues, thus resulting in insufficient feature modeling. In this study, we propose a novel multimodal hybrid tracker (MMHT) that utilizes frame-event-based data for reliable single object tracking. The MMHT model employs a hybrid backbone consisting of an artificial neural network (ANN) and a spiking neural network (SNN) to extract dominant features from different visual modalities and then uses a unified encoder to align the features across different domains. Moreover, we propose an enhanced transformer-based module to fuse multimodal features using attention mechanisms. With these methods, the MMHT model can effectively construct a multiscale and multidimensional visual feature space and achieve discriminative feature modeling. Extensive experiments demonstrate that the MMHT model exhibits competitive performance in comparison with that of other state-of-the-art methods. Overall, our results highlight the effectiveness of the MMHT model in terms of addressing the challenges faced in visual object tracking tasks.","sentences":["Visual object tracking, which is primarily based on visible light image sequences, encounters numerous challenges in complicated scenarios, such as low light conditions, high dynamic ranges, and background clutter.","To address these challenges, incorporating the advantages of multiple visual modalities is a promising solution for achieving reliable object tracking.","However, the existing approaches usually integrate multimodal inputs through adaptive local feature interactions, which cannot leverage the full potential of visual cues, thus resulting in insufficient feature modeling.","In this study, we propose a novel multimodal hybrid tracker (MMHT) that utilizes frame-event-based data for reliable single object tracking.","The MMHT model employs a hybrid backbone consisting of an artificial neural network (ANN) and a spiking neural network (SNN) to extract dominant features from different visual modalities and then uses a unified encoder to align the features across different domains.","Moreover, we propose an enhanced transformer-based module to fuse multimodal features using attention mechanisms.","With these methods, the MMHT model can effectively construct a multiscale and multidimensional visual feature space and achieve discriminative feature modeling.","Extensive experiments demonstrate that the MMHT model exhibits competitive performance in comparison with that of other state-of-the-art methods.","Overall, our results highlight the effectiveness of the MMHT model in terms of addressing the challenges faced in visual object tracking tasks."],"url":"http://arxiv.org/abs/2405.17903v1","category":"cs.CV"}
{"created":"2024-05-28 07:24:07","title":"Near-Infrared and Low-Rank Adaptation of Vision Transformers in Remote Sensing","abstract":"Plant health can be monitored dynamically using multispectral sensors that measure Near-Infrared reflectance (NIR). Despite this potential, obtaining and annotating high-resolution NIR images poses a significant challenge for training deep neural networks. Typically, large networks pre-trained on the RGB domain are utilized to fine-tune infrared images. This practice introduces a domain shift issue because of the differing visual traits between RGB and NIR images.As an alternative to fine-tuning, a method called low-rank adaptation (LoRA) enables more efficient training by optimizing rank-decomposition matrices while keeping the original network weights frozen. However, existing parameter-efficient adaptation strategies for remote sensing images focus on RGB images and overlook domain shift issues in the NIR domain. Therefore, this study investigates the potential benefits of using vision transformer (ViT) backbones pre-trained in the RGB domain, with low-rank adaptation for downstream tasks in the NIR domain. Extensive experiments demonstrate that employing LoRA with pre-trained ViT backbones yields the best performance for downstream tasks applied to NIR images.","sentences":["Plant health can be monitored dynamically using multispectral sensors that measure Near-Infrared reflectance (NIR).","Despite this potential, obtaining and annotating high-resolution NIR images poses a significant challenge for training deep neural networks.","Typically, large networks pre-trained on the RGB domain are utilized to fine-tune infrared images.","This practice introduces a domain shift issue because of the differing visual traits between RGB and NIR images.","As an alternative to fine-tuning, a method called low-rank adaptation (LoRA) enables more efficient training by optimizing rank-decomposition matrices while keeping the original network weights frozen.","However, existing parameter-efficient adaptation strategies for remote sensing images focus on RGB images and overlook domain shift issues in the NIR domain.","Therefore, this study investigates the potential benefits of using vision transformer (ViT) backbones pre-trained in the RGB domain, with low-rank adaptation for downstream tasks in the NIR domain.","Extensive experiments demonstrate that employing LoRA with pre-trained ViT backbones yields the best performance for downstream tasks applied to NIR images."],"url":"http://arxiv.org/abs/2405.17901v1","category":"cs.CV"}
{"created":"2024-05-28 07:18:52","title":"FlashST: A Simple and Universal Prompt-Tuning Framework for Traffic Prediction","abstract":"The objective of traffic prediction is to accurately forecast and analyze the dynamics of transportation patterns, considering both space and time. However, the presence of distribution shift poses a significant challenge in this field, as existing models struggle to generalize well when faced with test data that significantly differs from the training distribution. To tackle this issue, this paper introduces a simple and universal spatio-temporal prompt-tuning framework-FlashST, which adapts pre-trained models to the specific characteristics of diverse downstream datasets, improving generalization in diverse traffic prediction scenarios. Specifically, the FlashST framework employs a lightweight spatio-temporal prompt network for in-context learning, capturing spatio-temporal invariant knowledge and facilitating effective adaptation to diverse scenarios. Additionally, we incorporate a distribution mapping mechanism to align the data distributions of pre-training and downstream data, facilitating effective knowledge transfer in spatio-temporal forecasting. Empirical evaluations demonstrate the effectiveness of our FlashST across different spatio-temporal prediction tasks using diverse urban datasets. Code is available at https://github.com/HKUDS/FlashST.","sentences":["The objective of traffic prediction is to accurately forecast and analyze the dynamics of transportation patterns, considering both space and time.","However, the presence of distribution shift poses a significant challenge in this field, as existing models struggle to generalize well when faced with test data that significantly differs from the training distribution.","To tackle this issue, this paper introduces a simple and universal spatio-temporal prompt-tuning framework-FlashST, which adapts pre-trained models to the specific characteristics of diverse downstream datasets, improving generalization in diverse traffic prediction scenarios.","Specifically, the FlashST framework employs a lightweight spatio-temporal prompt network for in-context learning, capturing spatio-temporal invariant knowledge and facilitating effective adaptation to diverse scenarios.","Additionally, we incorporate a distribution mapping mechanism to align the data distributions of pre-training and downstream data, facilitating effective knowledge transfer in spatio-temporal forecasting.","Empirical evaluations demonstrate the effectiveness of our FlashST across different spatio-temporal prediction tasks using diverse urban datasets.","Code is available at https://github.com/HKUDS/FlashST."],"url":"http://arxiv.org/abs/2405.17898v1","category":"cs.LG"}
{"created":"2024-05-28 07:17:43","title":"Enhanced dissipation and temporal decay in the Euler-Poisson-Navier-Stokes equations","abstract":"This paper investigates the global well-posedness and large-time behavior of solutions for a coupled fluid model in $\\mathbb{R}^3$ consisting of the isothermal compressible Euler-Poisson system and incompressible Navier-Stokes equations coupled through the drag force. Notably, we exploit the dissipation effects inherent in the Poisson equation to achieve a faster decay of fluid density compared to velocities. This strategic utilization of dissipation, together with the influence of the electric field and the damping structure induced by the drag force, leads to a remarkable decay behavior: the fluid density converges to equilibrium at a rate of $(1+t)^{-11/4}$, significantly faster than the decay rates of velocity differences $(1+t)^{-7/4}$ and velocities themselves $(1+t)^{-3/4}$ in the $L^2$ norm. Furthermore, under the condition of vanishing coupled incompressible flow, we demonstrate an exponential decay to a constant state for the solution of the corresponding system, the damped Euler-Poisson system.","sentences":["This paper investigates the global well-posedness and large-time behavior of solutions for a coupled fluid model in $\\mathbb{R}^3$ consisting of the isothermal compressible Euler-Poisson system and incompressible Navier-Stokes equations coupled through the drag force.","Notably, we exploit the dissipation effects inherent in the Poisson equation to achieve a faster decay of fluid density compared to velocities.","This strategic utilization of dissipation, together with the influence of the electric field and the damping structure induced by the drag force, leads to a remarkable decay behavior: the fluid density converges to equilibrium at a rate of $(1+t)^{-11/4}$, significantly faster than the decay rates of velocity differences $(1+t)^{-7/4}$ and velocities themselves $(1+t)^{-3/4}$ in the $L^2$ norm.","Furthermore, under the condition of vanishing coupled incompressible flow, we demonstrate an exponential decay to a constant state for the solution of the corresponding system, the damped Euler-Poisson system."],"url":"http://arxiv.org/abs/2405.17895v1","category":"math.AP"}
{"created":"2024-05-28 07:09:42","title":"Graphomotor and Handwriting Disabilities Rating Scale (GHDRS):towards complex and objective assessment","abstract":"Graphomotor and handwriting disabilities (GD and HD, respectively) could significantly reduce children's quality of life. Effective remediation depends on proper diagnosis; however, current approaches to diagnosis and assessment of GD and HD have several limitations and knowledge gaps, e.g. they are subjective, they do not facilitate identification of specific manifestations, etc. The aim of this work is to introduce a new scale (GHDRS Graphomotor and Handwriting Disabilities Rating Scale) that will enable experts to perform objective and complex computeraided diagnosis and assessment of GD and HD. The scale supports quantification of 17 manifestations associated with the process/product of drawing/ handwriting. The whole methodology of GHDRS design is made maximally transparent so that it could be adapted for other languages.","sentences":["Graphomotor and handwriting disabilities (GD and HD, respectively) could significantly reduce children's quality of life.","Effective remediation depends on proper diagnosis; however, current approaches to diagnosis and assessment of GD and HD have several limitations and knowledge gaps, e.g. they are subjective, they do not facilitate identification of specific manifestations, etc.","The aim of this work is to introduce a new scale (GHDRS Graphomotor and Handwriting Disabilities Rating Scale) that will enable experts to perform objective and complex computeraided diagnosis and assessment of GD and HD.","The scale supports quantification of 17 manifestations associated with the process/product of drawing/ handwriting.","The whole methodology of GHDRS design is made maximally transparent so that it could be adapted for other languages."],"url":"http://arxiv.org/abs/2405.17886v1","category":"cs.CV"}
{"created":"2024-05-28 06:57:01","title":"An Information Theoretic Metric for Evaluating Unlearning Models","abstract":"Machine unlearning (MU) addresses privacy concerns by removing information of `forgetting data' samples from trained models. Typically, evaluating MU methods involves comparing unlearned models to those retrained from scratch without forgetting data, using metrics such as membership inference attacks (MIA) and accuracy measurements. These evaluations implicitly assume that if the output logits of the unlearned and retrained models are similar, the unlearned model has successfully forgotten the data. Here, we challenge if this assumption is valid. In particular, we conduct a simple experiment of training only the last layer of a given original model using a novel masked-distillation technique while keeping the rest fixed. Surprisingly, simply altering the last layer yields favorable outcomes in the existing evaluation metrics, while the model does not successfully unlearn the samples or classes. For better evaluating the MU methods, we propose a metric that quantifies the residual information about forgetting data samples in intermediate features using mutual information, called information difference index or IDI for short. The IDI provides a comprehensive evaluation of MU methods by efficiently analyzing the internal structure of DNNs. Our metric is scalable to large datasets and adaptable to various model architectures. Additionally, we present COLapse-and-Align (COLA), a simple contrastive-based method that effectively unlearns intermediate features.","sentences":["Machine unlearning (MU) addresses privacy concerns by removing information of `forgetting data' samples from trained models.","Typically, evaluating MU methods involves comparing unlearned models to those retrained from scratch without forgetting data, using metrics such as membership inference attacks (MIA) and accuracy measurements.","These evaluations implicitly assume that if the output logits of the unlearned and retrained models are similar, the unlearned model has successfully forgotten the data.","Here, we challenge if this assumption is valid.","In particular, we conduct a simple experiment of training only the last layer of a given original model using a novel masked-distillation technique while keeping the rest fixed.","Surprisingly, simply altering the last layer yields favorable outcomes in the existing evaluation metrics, while the model does not successfully unlearn the samples or classes.","For better evaluating the MU methods, we propose a metric that quantifies the residual information about forgetting data samples in intermediate features using mutual information, called information difference index or IDI for short.","The IDI provides a comprehensive evaluation of MU methods by efficiently analyzing the internal structure of DNNs.","Our metric is scalable to large datasets and adaptable to various model architectures.","Additionally, we present COLapse-and-Align (COLA), a simple contrastive-based method that effectively unlearns intermediate features."],"url":"http://arxiv.org/abs/2405.17878v1","category":"cs.LG"}
{"created":"2024-05-28 06:51:42","title":"NUTS, NARS, and Speech","abstract":"To investigate whether \"Intelligence is the capacity of an information-processing system to adapt to its environment while operating with insufficient knowledge and resources\", we look at utilising the non axiomatic reasoning system (NARS) for speech recognition. This article presents NUTS: raNdom dimensionality redUction non axiomaTic reasoning few Shot learner for perception. NUTS consists of naive dimensionality reduction, some pre-processing, and then non axiomatic reasoning (NARS). With only 2 training examples NUTS performs similarly to the Whisper Tiny model for discrete word identification.","sentences":["To investigate whether \"Intelligence is the capacity of an information-processing system to adapt to its environment while operating with insufficient knowledge and resources\", we look at utilising the non axiomatic reasoning system (NARS) for speech recognition.","This article presents NUTS: raNdom dimensionality redUction non axiomaTic reasoning few Shot learner for perception.","NUTS consists of naive dimensionality reduction, some pre-processing, and then non axiomatic reasoning (NARS).","With only 2 training examples NUTS performs similarly to the Whisper Tiny model for discrete word identification."],"url":"http://arxiv.org/abs/2405.17874v1","category":"cs.LG"}
{"created":"2024-05-28 06:33:43","title":"Nonreciprocal singularities dominated by the dissipative photon-magnon coupling in non-Hermitian systems","abstract":"We investigated the magnon-photon coupling in an open cavity magnonic system, which leads to two different nonreciprocal singularities dominated by the dissipative coupling. One type of singularity is the exceptional point, which is just on the exceptional surface in parameter space. The other type of singularity is the bound state in the continuum discovered in the level-attraction-like coupling, which is above the exceptional surface. In experiment, we realized the two different singularities with nonreciprocity and selectivity in an open cavity magnonic system with suitable dissipation rating. Our results can be understood well with the pseudo-Hermitian theory of magnon-polariton system.","sentences":["We investigated the magnon-photon coupling in an open cavity magnonic system, which leads to two different nonreciprocal singularities dominated by the dissipative coupling.","One type of singularity is the exceptional point, which is just on the exceptional surface in parameter space.","The other type of singularity is the bound state in the continuum discovered in the level-attraction-like coupling, which is above the exceptional surface.","In experiment, we realized the two different singularities with nonreciprocity and selectivity in an open cavity magnonic system with suitable dissipation rating.","Our results can be understood well with the pseudo-Hermitian theory of magnon-polariton system."],"url":"http://arxiv.org/abs/2405.17869v1","category":"cond-mat.mes-hall"}
{"created":"2024-05-28 06:16:57","title":"Adapting Pre-Trained Vision Models for Novel Instance Detection and Segmentation","abstract":"Novel Instance Detection and Segmentation (NIDS) aims at detecting and segmenting novel object instances given a few examples of each instance. We propose a unified framework (NIDS-Net) comprising object proposal generation, embedding creation for both instance templates and proposal regions, and embedding matching for instance label assignment. Leveraging recent advancements in large vision methods, we utilize the Grounding DINO and Segment Anything Model (SAM) to obtain object proposals with accurate bounding boxes and masks. Central to our approach is the generation of high-quality instance embeddings. We utilize foreground feature averages of patch embeddings from the DINOv2 ViT backbone, followed by refinement through a weight adapter mechanism that we introduce. We show experimentally that our weight adapter can adjust the embeddings locally within their feature space and effectively limit overfitting. This methodology enables a straightforward matching strategy, resulting in significant performance gains. Our framework surpasses current state-of-the-art methods, demonstrating notable improvements of 22.3, 46.2, 10.3, and 24.0 in average precision (AP) across four detection datasets. In instance segmentation tasks on seven core datasets of the BOP challenge, our method outperforms the top RGB methods by 3.6 AP and remains competitive with the best RGB-D method. Code is available at: https://github.com/YoungSean/NIDS-Net","sentences":["Novel Instance Detection and Segmentation (NIDS) aims at detecting and segmenting novel object instances given a few examples of each instance.","We propose a unified framework (NIDS-Net) comprising object proposal generation, embedding creation for both instance templates and proposal regions, and embedding matching for instance label assignment.","Leveraging recent advancements in large vision methods, we utilize the Grounding DINO and Segment Anything Model (SAM) to obtain object proposals with accurate bounding boxes and masks.","Central to our approach is the generation of high-quality instance embeddings.","We utilize foreground feature averages of patch embeddings from the DINOv2 ViT backbone, followed by refinement through a weight adapter mechanism that we introduce.","We show experimentally that our weight adapter can adjust the embeddings locally within their feature space and effectively limit overfitting.","This methodology enables a straightforward matching strategy, resulting in significant performance gains.","Our framework surpasses current state-of-the-art methods, demonstrating notable improvements of 22.3, 46.2, 10.3, and 24.0 in average precision (AP) across four detection datasets.","In instance segmentation tasks on seven core datasets of the BOP challenge, our method outperforms the top RGB methods by 3.6 AP and remains competitive with the best RGB-D method.","Code is available at: https://github.com/YoungSean/NIDS-Net"],"url":"http://arxiv.org/abs/2405.17859v1","category":"cs.CV"}
{"created":"2024-05-28 05:45:30","title":"Ai.llude: Encouraging Rewriting AI-Generated Text to Support Creative Expression","abstract":"In each step of the creative writing process, writers must grapple with their creative goals and individual perspectives. This process affects the writer's sense of authenticity and their engagement with the written output. Fluent text generation by AIs risks undermining the reflective loop of rewriting. We hypothesize that deliberately generating imperfect intermediate text can encourage rewriting and prompt higher level decision making. Using logs from 27 writing sessions using a text generation AI, we characterize how writers adapt and rewrite AI suggestions, and show that intermediate suggestions significantly motivate and increase rewriting. We discuss the implications of this finding, and future steps for investigating how to leverage intermediate text in AI writing support tools to support ownership over creative expression.","sentences":["In each step of the creative writing process, writers must grapple with their creative goals and individual perspectives.","This process affects the writer's sense of authenticity and their engagement with the written output.","Fluent text generation by AIs risks undermining the reflective loop of rewriting.","We hypothesize that deliberately generating imperfect intermediate text can encourage rewriting and prompt higher level decision making.","Using logs from 27 writing sessions using a text generation AI, we characterize how writers adapt and rewrite AI suggestions, and show that intermediate suggestions significantly motivate and increase rewriting.","We discuss the implications of this finding, and future steps for investigating how to leverage intermediate text in AI writing support tools to support ownership over creative expression."],"url":"http://arxiv.org/abs/2405.17843v1","category":"cs.HC"}
{"created":"2024-05-28 05:30:18","title":"PeerFL: A Simulator for Peer-to-Peer Federated Learning at Scale","abstract":"This work integrates peer-to-peer federated learning tools with NS3, a widely used network simulator, to create a novel simulator designed to allow heterogeneous device experiments in federated learning. This cross-platform adaptability addresses a critical gap in existing simulation tools, enhancing the overall utility and user experience. NS3 is leveraged to simulate WiFi dynamics to facilitate federated learning experiments with participants that move around physically during training, leading to dynamic network characteristics. Our experiments showcase the simulator's efficiency in computational resource utilization at scale, with a maximum of 450 heterogeneous devices modelled as participants in federated learning. This positions it as a valuable tool for simulation-based investigations in peer-to-peer federated learning. The framework is open source and available for use and extension to the community.","sentences":["This work integrates peer-to-peer federated learning tools with NS3, a widely used network simulator, to create a novel simulator designed to allow heterogeneous device experiments in federated learning.","This cross-platform adaptability addresses a critical gap in existing simulation tools, enhancing the overall utility and user experience.","NS3 is leveraged to simulate WiFi dynamics to facilitate federated learning experiments with participants that move around physically during training, leading to dynamic network characteristics.","Our experiments showcase the simulator's efficiency in computational resource utilization at scale, with a maximum of 450 heterogeneous devices modelled as participants in federated learning.","This positions it as a valuable tool for simulation-based investigations in peer-to-peer federated learning.","The framework is open source and available for use and extension to the community."],"url":"http://arxiv.org/abs/2405.17839v1","category":"cs.DC"}
{"created":"2024-05-28 04:13:21","title":"Mani-GS: Gaussian Splatting Manipulation with Triangular Mesh","abstract":"Neural 3D representations such as Neural Radiance Fields (NeRF), excel at producing photo-realistic rendering results but lack the flexibility for manipulation and editing which is crucial for content creation. Previous works have attempted to address this issue by deforming a NeRF in canonical space or manipulating the radiance field based on an explicit mesh. However, manipulating NeRF is not highly controllable and requires a long training and inference time. With the emergence of 3D Gaussian Splatting (3DGS), extremely high-fidelity novel view synthesis can be achieved using an explicit point-based 3D representation with much faster training and rendering speed. However, there is still a lack of effective means to manipulate 3DGS freely while maintaining rendering quality. In this work, we aim to tackle the challenge of achieving manipulable photo-realistic rendering. We propose to utilize a triangular mesh to manipulate 3DGS directly with self-adaptation. This approach reduces the need to design various algorithms for different types of Gaussian manipulation. By utilizing a triangle shape-aware Gaussian binding and adapting method, we can achieve 3DGS manipulation and preserve high-fidelity rendering after manipulation. Our approach is capable of handling large deformations, local manipulations, and soft body simulations while keeping high-quality rendering. Furthermore, we demonstrate that our method is also effective with inaccurate meshes extracted from 3DGS. Experiments conducted demonstrate the effectiveness of our method and its superiority over baseline approaches.","sentences":["Neural 3D representations such as Neural Radiance Fields (NeRF), excel at producing photo-realistic rendering results but lack the flexibility for manipulation and editing which is crucial for content creation.","Previous works have attempted to address this issue by deforming a NeRF in canonical space or manipulating the radiance field based on an explicit mesh.","However, manipulating NeRF is not highly controllable and requires a long training and inference time.","With the emergence of 3D Gaussian Splatting (3DGS), extremely high-fidelity novel view synthesis can be achieved using an explicit point-based 3D representation with much faster training and rendering speed.","However, there is still a lack of effective means to manipulate 3DGS freely while maintaining rendering quality.","In this work, we aim to tackle the challenge of achieving manipulable photo-realistic rendering.","We propose to utilize a triangular mesh to manipulate 3DGS directly with self-adaptation.","This approach reduces the need to design various algorithms for different types of Gaussian manipulation.","By utilizing a triangle shape-aware Gaussian binding and adapting method, we can achieve 3DGS manipulation and preserve high-fidelity rendering after manipulation.","Our approach is capable of handling large deformations, local manipulations, and soft body simulations while keeping high-quality rendering.","Furthermore, we demonstrate that our method is also effective with inaccurate meshes extracted from 3DGS.","Experiments conducted demonstrate the effectiveness of our method and its superiority over baseline approaches."],"url":"http://arxiv.org/abs/2405.17811v1","category":"cs.GR"}
{"created":"2024-05-28 03:53:10","title":"Bandwidth Efficient Cache Selection and Content Advertisement","abstract":"Caching is extensively used in various networking environments to optimize performance by reducing latency, bandwidth, and energy consumption. To optimize performance, caches often advertise their content using indicators, which are data structures that trade space efficiency for accuracy. However, this tradeoff introduces the risk of false indications. Existing solutions for cache content advertisement and cache selection often lead to inefficiencies, failing to adapt to dynamic network conditions. This paper introduces SALSA2, a Scalable Adaptive and Learning-based Selection and Advertisement Algorithm, which addresses these limitations through a dynamic and adaptive approach. SALSA2 accurately estimates mis-indication probabilities by considering inter-cache dependencies and dynamically adjusts the size and frequency of indicator advertisements to minimize transmission overhead while maintaining high accuracy. Our extensive simulation study, conducted using a variety of real-world cache traces, demonstrates that SALSA2 achieves up to 84\\% bandwidth savings compared to the state-of-the-art solution and close-to-optimal service cost in most scenarios. These results highlight SALSA2's effectiveness in enhancing cache management, making it a robust and versatile solution for modern networking challenges.","sentences":["Caching is extensively used in various networking environments to optimize performance by reducing latency, bandwidth, and energy consumption.","To optimize performance, caches often advertise their content using indicators, which are data structures that trade space efficiency for accuracy.","However, this tradeoff introduces the risk of false indications.","Existing solutions for cache content advertisement and cache selection often lead to inefficiencies, failing to adapt to dynamic network conditions.","This paper introduces SALSA2, a Scalable Adaptive and Learning-based Selection and Advertisement Algorithm, which addresses these limitations through a dynamic and adaptive approach.","SALSA2 accurately estimates mis-indication probabilities by considering inter-cache dependencies and dynamically adjusts the size and frequency of indicator advertisements to minimize transmission overhead while maintaining high accuracy.","Our extensive simulation study, conducted using a variety of real-world cache traces, demonstrates that SALSA2 achieves up to 84\\% bandwidth savings compared to the state-of-the-art solution and close-to-optimal service cost in most scenarios.","These results highlight SALSA2's effectiveness in enhancing cache management, making it a robust and versatile solution for modern networking challenges."],"url":"http://arxiv.org/abs/2405.17801v2","category":"cs.NI"}
{"created":"2024-05-28 03:45:32","title":"LNS2+RL: Combining Multi-agent Reinforcement Learning with Large Neighborhood Search in Multi-agent Path Finding","abstract":"Multi-Agent Path Finding (MAPF) is a critical component of logistics and warehouse management, which focuses on planning collision-free paths for a team of robots in a known environment. Recent work introduced a novel MAPF approach, LNS2, which proposed to repair a quickly-obtainable set of infeasible paths via iterative re-planning, by relying on a fast, yet lower-quality, priority-based planner. At the same time, there has been a recent push for Multi-Agent Reinforcement Learning (MARL) based MAPF algorithms, which let agents learn decentralized policies that exhibit improved cooperation over such priority planning, although inevitably remaining slower. In this paper, we introduce a new MAPF algorithm, LNS2+RL, which combines the distinct yet complementary characteristics of LNS2 and MARL to effectively balance their individual limitations and get the best from both worlds. During early iterations, LNS2+RL relies on MARL for low-level re-planning, which we show eliminates collisions much more than a priority-based planner. There, our MARL-based planner allows agents to reason about past and future/predicted information to gradually learn cooperative decision-making through a finely designed curriculum learning. At later stages of planning, LNS2+RL adaptively switches to priority-based planning to quickly resolve the remaining collisions, naturally trading-off solution quality and computational efficiency. Our comprehensive experiments on challenging tasks across various team sizes, world sizes, and map structures consistently demonstrate the superior performance of LNS2+RL compared to many MAPF algorithms, including LNS2, LaCAM, and EECBS, where LNS2+RL shows significantly better performance in complex scenarios. We finally experimentally validate our algorithm in a hybrid simulation of a warehouse mockup involving a team of 100 (real-world and simulated) robots.","sentences":["Multi-Agent Path Finding (MAPF) is a critical component of logistics and warehouse management, which focuses on planning collision-free paths for a team of robots in a known environment.","Recent work introduced a novel MAPF approach, LNS2, which proposed to repair a quickly-obtainable set of infeasible paths via iterative re-planning, by relying on a fast, yet lower-quality, priority-based planner.","At the same time, there has been a recent push for Multi-Agent Reinforcement Learning (MARL) based MAPF algorithms, which let agents learn decentralized policies that exhibit improved cooperation over such priority planning, although inevitably remaining slower.","In this paper, we introduce a new MAPF algorithm, LNS2+RL, which combines the distinct yet complementary characteristics of LNS2 and MARL to effectively balance their individual limitations and get the best from both worlds.","During early iterations, LNS2+RL relies on MARL for low-level re-planning, which we show eliminates collisions much more than a priority-based planner.","There, our MARL-based planner allows agents to reason about past and future/predicted information to gradually learn cooperative decision-making through a finely designed curriculum learning.","At later stages of planning, LNS2+RL adaptively switches to priority-based planning to quickly resolve the remaining collisions, naturally trading-off solution quality and computational efficiency.","Our comprehensive experiments on challenging tasks across various team sizes, world sizes, and map structures consistently demonstrate the superior performance of LNS2+RL compared to many MAPF algorithms, including LNS2, LaCAM, and EECBS, where LNS2+RL shows significantly better performance in complex scenarios.","We finally experimentally validate our algorithm in a hybrid simulation of a warehouse mockup involving a team of 100 (real-world and simulated) robots."],"url":"http://arxiv.org/abs/2405.17794v1","category":"cs.RO"}
{"created":"2024-05-28 03:35:46","title":"Instruct-ReID++: Towards Universal Purpose Instruction-Guided Person Re-identification","abstract":"Human intelligence can retrieve any person according to both visual and language descriptions. However, the current computer vision community studies specific person re-identification (ReID) tasks in different scenarios separately, which limits the applications in the real world. This paper strives to resolve this problem by proposing a novel instruct-ReID task that requires the model to retrieve images according to the given image or language instructions. Instruct-ReID is the first exploration of a general ReID setting, where existing 6 ReID tasks can be viewed as special cases by assigning different instructions. To facilitate research in this new instruct-ReID task, we propose a large-scale OmniReID++ benchmark equipped with diverse data and comprehensive evaluation methods e.g., task specific and task-free evaluation settings. In the task-specific evaluation setting, gallery sets are categorized according to specific ReID tasks. We propose a novel baseline model, IRM, with an adaptive triplet loss to handle various retrieval tasks within a unified framework. For task-free evaluation setting, where target person images are retrieved from task-agnostic gallery sets, we further propose a new method called IRM++ with novel memory bank-assisted learning. Extensive evaluations of IRM and IRM++ on OmniReID++ benchmark demonstrate the superiority of our proposed methods, achieving state-of-the-art performance on 10 test sets. The datasets, the model, and the code will be available at https://github.com/hwz-zju/Instruct-ReID","sentences":["Human intelligence can retrieve any person according to both visual and language descriptions.","However, the current computer vision community studies specific person re-identification (ReID) tasks in different scenarios separately, which limits the applications in the real world.","This paper strives to resolve this problem by proposing a novel instruct-ReID task that requires the model to retrieve images according to the given image or language instructions.","Instruct-ReID is the first exploration of a general ReID setting, where existing 6 ReID tasks can be viewed as special cases by assigning different instructions.","To facilitate research in this new instruct-ReID task, we propose a large-scale OmniReID++ benchmark equipped with diverse data and comprehensive evaluation methods e.g., task specific and task-free evaluation settings.","In the task-specific evaluation setting, gallery sets are categorized according to specific ReID tasks.","We propose a novel baseline model, IRM, with an adaptive triplet loss to handle various retrieval tasks within a unified framework.","For task-free evaluation setting, where target person images are retrieved from task-agnostic gallery sets, we further propose a new method called IRM++ with novel memory bank-assisted learning.","Extensive evaluations of IRM and IRM++ on OmniReID++ benchmark demonstrate the superiority of our proposed methods, achieving state-of-the-art performance on 10 test sets.","The datasets, the model, and the code will be available at https://github.com/hwz-zju/Instruct-ReID"],"url":"http://arxiv.org/abs/2405.17790v1","category":"cs.CV"}
{"created":"2024-05-28 03:33:26","title":"Dyadic Regression with Sample Selection","abstract":"This paper addresses the sample selection problem in panel dyadic regression analysis. Dyadic data often include many zeros in the main outcomes due to the underlying network formation process. This not only contaminates popular estimators used in practice but also complicates the inference due to the dyadic dependence structure. We extend Kyriazidou (1997)'s approach to dyadic data and characterize the asymptotic distribution of our proposed estimator. The convergence rates are $\\sqrt{n}$ or $\\sqrt{n^{2}h_{n}}$, depending on the degeneracy of the H\\'{a}jek projection part of the estimator, where $n$ is the number of nodes and $h_{n}$ is a bandwidth. We propose a bias-corrected confidence interval and a variance estimator that adapts to the degeneracy. A Monte Carlo simulation shows the good finite performance of our estimator and highlights the importance of bias correction in both asymptotic regimes when the fraction of zeros in outcomes varies. We illustrate our procedure using data from Moretti and Wilson (2017)'s paper on migration.","sentences":["This paper addresses the sample selection problem in panel dyadic regression analysis.","Dyadic data often include many zeros in the main outcomes due to the underlying network formation process.","This not only contaminates popular estimators used in practice but also complicates the inference due to the dyadic dependence structure.","We extend Kyriazidou (1997)'s approach to dyadic data and characterize the asymptotic distribution of our proposed estimator.","The convergence rates are $\\sqrt{n}$ or $\\sqrt{n^{2}h_{n}}$, depending on the degeneracy of the H\\'{a}jek projection part of the estimator, where $n$ is the number of nodes and $h_{n}$ is a bandwidth.","We propose a bias-corrected confidence interval and a variance estimator that adapts to the degeneracy.","A Monte Carlo simulation shows the good finite performance of our estimator and highlights the importance of bias correction in both asymptotic regimes when the fraction of zeros in outcomes varies.","We illustrate our procedure using data from Moretti and Wilson (2017)'s paper on migration."],"url":"http://arxiv.org/abs/2405.17787v1","category":"econ.EM"}
{"created":"2024-05-28 03:28:00","title":"Adaptive Horizon Actor-Critic for Policy Learning in Contact-Rich Differentiable Simulation","abstract":"Model-Free Reinforcement Learning~(MFRL), leveraging the policy gradient theorem, has demonstrated considerable success in continuous control tasks. However, these approaches are plagued by high gradient variance due to zeroth-order gradient estimation, resulting in suboptimal policies. Conversely, First-Order Model-Based Reinforcement Learning~(FO-MBRL) methods, employing differentiable simulation, provide gradients with reduced variance but are susceptible to sampling error in scenarios involving stiff dynamics, such as physical contact. This paper investigates the source of this error and introduces Adaptive Horizon Actor-Critic (AHAC), an FO-MBRL algorithm that reduces gradient error by adapting the model-based horizon to avoid stiff dynamics. Empirical findings reveal that AHAC outperforms MFRL baselines, attaining 40\\% more reward across a set of locomotion tasks, and efficiently scaling to high-dimensional control environments with improved wall-clock-time efficiency.","sentences":["Model-Free Reinforcement Learning~(MFRL), leveraging the policy gradient theorem, has demonstrated considerable success in continuous control tasks.","However, these approaches are plagued by high gradient variance due to zeroth-order gradient estimation, resulting in suboptimal policies.","Conversely, First-Order Model-Based Reinforcement Learning~(FO-MBRL) methods, employing differentiable simulation, provide gradients with reduced variance but are susceptible to sampling error in scenarios involving stiff dynamics, such as physical contact.","This paper investigates the source of this error and introduces Adaptive Horizon Actor-Critic (AHAC), an FO-MBRL algorithm that reduces gradient error by adapting the model-based horizon to avoid stiff dynamics.","Empirical findings reveal that AHAC outperforms MFRL baselines, attaining 40\\% more reward across a set of locomotion tasks, and efficiently scaling to high-dimensional control environments with improved wall-clock-time efficiency."],"url":"http://arxiv.org/abs/2405.17784v1","category":"cs.LG"}
{"created":"2024-05-28 03:25:31","title":"Dissipation-induced bound states as a two-level system","abstract":"Potential wells are employed to constrain quantum particles into forming discrete energy levels, acting as artificial few-level systems. In contrast, an anti-parity-time ($\\mathcal{PT}$) symmetric system can have a single pair of real energy levels, while all the remaining levels are unstable due to the negative imaginary part of the energy. In this work, we investigate the formation of bound states in a tight-binding chain induced by a harmonic imaginary potential. Exact solutions show that the real parts of energy levels are equidistant, while the imaginary parts are semi-negative definite and equidistant. This allows for the formation of an effective two-level system. For a given initial state with a wide range of profiles, the evolved state always converges to a superposition of two stable eigenstates. In addition, these two states are orthogonal under the Dirac inner product and can be mutually switched by applying a $\\pi$ pulse of a linear field. Our finding provides an alternative method for fabricating quantum devices through dissipation.","sentences":["Potential wells are employed to constrain quantum particles into forming discrete energy levels, acting as artificial few-level systems.","In contrast, an anti-parity-time ($\\mathcal{PT}$) symmetric system can have a single pair of real energy levels, while all the remaining levels are unstable due to the negative imaginary part of the energy.","In this work, we investigate the formation of bound states in a tight-binding chain induced by a harmonic imaginary potential.","Exact solutions show that the real parts of energy levels are equidistant, while the imaginary parts are semi-negative definite and equidistant.","This allows for the formation of an effective two-level system.","For a given initial state with a wide range of profiles, the evolved state always converges to a superposition of two stable eigenstates.","In addition, these two states are orthogonal under the Dirac inner product and can be mutually switched by applying a $\\pi$ pulse of a linear field.","Our finding provides an alternative method for fabricating quantum devices through dissipation."],"url":"http://arxiv.org/abs/2405.17781v1","category":"quant-ph"}
{"created":"2024-05-28 03:20:05","title":"Unmasking Vulnerabilities: Cardinality Sketches under Adaptive Inputs","abstract":"Cardinality sketches are popular data structures that enhance the efficiency of working with large data sets. The sketches are randomized representations of sets that are only of logarithmic size but can support set merges and approximate cardinality (i.e., distinct count) queries. When queries are not adaptive, that is, they do not depend on preceding query responses, the design provides strong guarantees of correctly answering a number of queries exponential in the sketch size $k$.   In this work, we investigate the performance of cardinality sketches in adaptive settings and unveil inherent vulnerabilities. We design an attack against the ``standard'' estimators that constructs an adversarial input by post-processing responses to a set of simple non-adaptive queries of size linear in the sketch size $k$. Empirically, our attack used only $4k$ queries with the widely used HyperLogLog (HLL++)~\\citep{hyperloglog:2007,hyperloglogpractice:EDBT2013} sketch. The simple attack technique suggests it can be effective with post-processed natural workloads. Finally and importantly, we demonstrate that the vulnerability is inherent as \\emph{any} estimator applied to known sketch structures can be attacked using a number of queries that is quadratic in $k$, matching a generic upper bound.","sentences":["Cardinality sketches are popular data structures that enhance the efficiency of working with large data sets.","The sketches are randomized representations of sets that are only of logarithmic size but can support set merges and approximate cardinality (i.e., distinct count) queries.","When queries are not adaptive, that is, they do not depend on preceding query responses, the design provides strong guarantees of correctly answering a number of queries exponential in the sketch size $k$.   In this work, we investigate the performance of cardinality sketches in adaptive settings and unveil inherent vulnerabilities.","We design an attack against the ``standard'' estimators that constructs an adversarial input by post-processing responses to a set of simple non-adaptive queries of size linear in the sketch size $k$. Empirically, our attack used only $4k$ queries with the widely used HyperLogLog (HLL++)~\\citep{hyperloglog:2007,hyperloglogpractice:EDBT2013} sketch.","The simple attack technique suggests it can be effective with post-processed natural workloads.","Finally and importantly, we demonstrate that the vulnerability is inherent as \\emph{any} estimator applied to known sketch structures can be attacked using a number of queries that is quadratic in $k$, matching a generic upper bound."],"url":"http://arxiv.org/abs/2405.17780v1","category":"cs.DS"}
{"created":"2024-05-28 03:03:32","title":"Gradually Vanishing Gap in Prototypical Network for Unsupervised Domain Adaptation","abstract":"Unsupervised domain adaptation (UDA) is a critical problem for transfer learning, which aims to transfer the semantic information from labeled source domain to unlabeled target domain. Recent advancements in UDA models have demonstrated significant generalization capabilities on the target domain. However, the generalization boundary of UDA models remains unclear. When the domain discrepancy is too large, the model can not preserve the distribution structure, leading to distribution collapse during the alignment. To address this challenge, we propose an efficient UDA framework named Gradually Vanishing Gap in Prototypical Network (GVG-PN), which achieves transfer learning from both global and local perspectives. From the global alignment standpoint, our model generates a domain-biased intermediate domain that helps preserve the distribution structures. By entangling cross-domain features, our model progressively reduces the risk of distribution collapse. However, only relying on global alignment is insufficient to preserve the distribution structure. To further enhance the inner relationships of features, we introduce the local perspective. We utilize the graph convolutional network (GCN) as an intuitive method to explore the internal relationships between features, ensuring the preservation of manifold structures and generating domain-biased prototypes. Additionally, we consider the discriminability of the inner relationships between features. We propose a pro-contrastive loss to enhance the discriminability at the prototype level by separating hard negative pairs. By incorporating both GCN and the pro-contrastive loss, our model fully explores fine-grained semantic relationships. Experiments on several UDA benchmarks validated that the proposed GVG-PN can clearly outperform the SOTA models.","sentences":["Unsupervised domain adaptation (UDA) is a critical problem for transfer learning, which aims to transfer the semantic information from labeled source domain to unlabeled target domain.","Recent advancements in UDA models have demonstrated significant generalization capabilities on the target domain.","However, the generalization boundary of UDA models remains unclear.","When the domain discrepancy is too large, the model can not preserve the distribution structure, leading to distribution collapse during the alignment.","To address this challenge, we propose an efficient UDA framework named Gradually Vanishing Gap in Prototypical Network (GVG-PN), which achieves transfer learning from both global and local perspectives.","From the global alignment standpoint, our model generates a domain-biased intermediate domain that helps preserve the distribution structures.","By entangling cross-domain features, our model progressively reduces the risk of distribution collapse.","However, only relying on global alignment is insufficient to preserve the distribution structure.","To further enhance the inner relationships of features, we introduce the local perspective.","We utilize the graph convolutional network (GCN) as an intuitive method to explore the internal relationships between features, ensuring the preservation of manifold structures and generating domain-biased prototypes.","Additionally, we consider the discriminability of the inner relationships between features.","We propose a pro-contrastive loss to enhance the discriminability at the prototype level by separating hard negative pairs.","By incorporating both GCN and the pro-contrastive loss, our model fully explores fine-grained semantic relationships.","Experiments on several UDA benchmarks validated that the proposed GVG-PN can clearly outperform the SOTA models."],"url":"http://arxiv.org/abs/2405.17774v1","category":"cs.CV"}
{"created":"2024-05-28 02:55:40","title":"Risk-Neutral Generative Networks","abstract":"We present a functional generative approach to extract risk-neutral densities from market prices of options. Specifically, we model the log-returns on the time-to-maturity continuum as a stochastic curve driven by standard normal. We then use neural nets to represent the term structures of the location, the scale, and the higher-order moments, and impose stringent conditions on the learning process to ensure the neural net-based curve representation is free of static arbitrage. This specification is structurally clear in that it separates the modeling of randomness from the modeling of the term structures of the parameters. It is data adaptive in that we use neural nets to represent the shape of the stochastic curve. It is also generative in that the functional form of the stochastic curve, although parameterized by neural nets, is an explicit and deterministic function of the standard normal. This explicitness allows for the efficient generation of samples to price options across strikes and maturities, without compromising data adaptability. We have validated the effectiveness of this approach by benchmarking it against a comprehensive set of baseline models. Experiments show that the extracted risk-neutral densities accommodate a diverse range of shapes. Its accuracy significantly outperforms the extensive set of baseline models--including three parametric models and nine stochastic process models--in terms of accuracy and stability. The success of this approach is attributed to its capacity to offer flexible term structures for risk-neutral skewness and kurtosis.","sentences":["We present a functional generative approach to extract risk-neutral densities from market prices of options.","Specifically, we model the log-returns on the time-to-maturity continuum as a stochastic curve driven by standard normal.","We then use neural nets to represent the term structures of the location, the scale, and the higher-order moments, and impose stringent conditions on the learning process to ensure the neural net-based curve representation is free of static arbitrage.","This specification is structurally clear in that it separates the modeling of randomness from the modeling of the term structures of the parameters.","It is data adaptive in that we use neural nets to represent the shape of the stochastic curve.","It is also generative in that the functional form of the stochastic curve, although parameterized by neural nets, is an explicit and deterministic function of the standard normal.","This explicitness allows for the efficient generation of samples to price options across strikes and maturities, without compromising data adaptability.","We have validated the effectiveness of this approach by benchmarking it against a comprehensive set of baseline models.","Experiments show that the extracted risk-neutral densities accommodate a diverse range of shapes.","Its accuracy significantly outperforms the extensive set of baseline models--including three parametric models and nine stochastic process models--in terms of accuracy and stability.","The success of this approach is attributed to its capacity to offer flexible term structures for risk-neutral skewness and kurtosis."],"url":"http://arxiv.org/abs/2405.17770v1","category":"q-fin.MF"}
{"created":"2024-05-28 02:03:13","title":"Bi-directional models of `radically synthetic' differential geometry","abstract":"The radically synthetic foundation for smooth geometry formulated in [Law11] postulates a space T with the property that it has a unique point and, out of the monoid T^T of endomorphisms, it extracts a submonoid R which, in many cases, is the (commutative) multiplication of a rig structure. The rig R is said to be bi-directional if its subobject of invertible elements has two connected components. In this case, R may be equipped with a pre-order compatible with the rig structure. We adjust the construction of `well-adapted' models of Synthetic Differential Geometry in order to build the first pre-cohesive toposes with a bi-directional R. We also show that, in one of these pre-cohesive variants, the pre-order on R, derived radically synthetically from bi-directionality, coincides with that defined in the original model.","sentences":["The radically synthetic foundation for smooth geometry formulated in [Law11] postulates a space T with the property that it has a unique point and, out of the monoid T^T of endomorphisms, it extracts a submonoid R which, in many cases, is the (commutative) multiplication of a rig structure.","The rig R is said to be bi-directional if its subobject of invertible elements has two connected components.","In this case, R may be equipped with a pre-order compatible with the rig structure.","We adjust the construction of `well-adapted' models of Synthetic Differential Geometry in order to build the first pre-cohesive toposes with a bi-directional R. We also show that, in one of these pre-cohesive variants, the pre-order on R, derived radically synthetically from bi-directionality, coincides with that defined in the original model."],"url":"http://arxiv.org/abs/2405.17748v1","category":"math.CT"}
{"created":"2024-05-28 01:53:26","title":"LoRA-Switch: Boosting the Efficiency of Dynamic LLM Adapters via System-Algorithm Co-design","abstract":"Recent literature has found that an effective method to customize or further improve large language models (LLMs) is to add dynamic adapters, such as low-rank adapters (LoRA) with Mixture-of-Experts (MoE) structures. Though such dynamic adapters incur modest computational complexity, they surprisingly lead to huge inference latency overhead, slowing down the decoding speed by 2.5+ times. In this paper, we analyze the fine-grained costs of the dynamic adapters and find that the fragmented CUDA kernel calls are the root cause. Therefore, we propose LoRA-Switch, a system-algorithm co-designed architecture for efficient dynamic adapters. Unlike most existing dynamic structures that adopt layer-wise or block-wise dynamic routing, LoRA-Switch introduces a token-wise routing mechanism. It switches the LoRA adapters and weights for each token and merges them into the backbone for inference. For efficiency, this switching is implemented with an optimized CUDA kernel, which fuses the merging operations for all LoRA adapters at once. Based on experiments with popular open-source LLMs on common benchmarks, our approach has demonstrated similar accuracy improvement as existing dynamic adapters, while reducing the decoding latency by more than 2.4 times.","sentences":["Recent literature has found that an effective method to customize or further improve large language models (LLMs) is to add dynamic adapters, such as low-rank adapters (LoRA) with Mixture-of-Experts (MoE) structures.","Though such dynamic adapters incur modest computational complexity, they surprisingly lead to huge inference latency overhead, slowing down the decoding speed by 2.5+ times.","In this paper, we analyze the fine-grained costs of the dynamic adapters and find that the fragmented CUDA kernel calls are the root cause.","Therefore, we propose LoRA-Switch, a system-algorithm co-designed architecture for efficient dynamic adapters.","Unlike most existing dynamic structures that adopt layer-wise or block-wise dynamic routing, LoRA-Switch introduces a token-wise routing mechanism.","It switches the LoRA adapters and weights for each token and merges them into the backbone for inference.","For efficiency, this switching is implemented with an optimized CUDA kernel, which fuses the merging operations for all LoRA adapters at once.","Based on experiments with popular open-source LLMs on common benchmarks, our approach has demonstrated similar accuracy improvement as existing dynamic adapters, while reducing the decoding latency by more than 2.4 times."],"url":"http://arxiv.org/abs/2405.17741v1","category":"cs.AI"}
{"created":"2024-05-28 01:19:18","title":"Evaluating NoSQL Databases for OLAP Workloads: A Benchmarking Study of MongoDB, Redis, Kudu and ArangoDB","abstract":"In the era of big data, conventional RDBMS models have become impractical for handling colossal workloads. Consequently, NoSQL databases have emerged as the preferred storage solutions for executing processing-intensive Online Analytical Processing (OLAP) tasks. Within the realm of NoSQL databases, various classifications exist based on their data storage mechanisms, making it challenging to select the most suitable one for a given OLAP workload. While each NoSQL database boasts distinct advantages, inherent scalability, adaptability to diverse data formats, and high data availability are universally recognized benefits crucial for managing OLAP workloads effectively. Existing research predominantly evaluates individual databases within custom data pipeline setups, lacking a standardized approach for comparative analysis across different databases to identify the optimal data pipeline for OLAP workloads. In this paper, we present our experimental insights into how various NoSQL databases handle OLAP workloads within a standardized data processing pipeline. Our experimental pipeline comprises Apache Spark for large-scale transformations, data cleansing, and schema normalization, diverse NoSQL databases as data stores, and a Business Intelligence tool for data analysis and visualization.","sentences":["In the era of big data, conventional RDBMS models have become impractical for handling colossal workloads.","Consequently, NoSQL databases have emerged as the preferred storage solutions for executing processing-intensive Online Analytical Processing (OLAP) tasks.","Within the realm of NoSQL databases, various classifications exist based on their data storage mechanisms, making it challenging to select the most suitable one for a given OLAP workload.","While each NoSQL database boasts distinct advantages, inherent scalability, adaptability to diverse data formats, and high data availability are universally recognized benefits crucial for managing OLAP workloads effectively.","Existing research predominantly evaluates individual databases within custom data pipeline setups, lacking a standardized approach for comparative analysis across different databases to identify the optimal data pipeline for OLAP workloads.","In this paper, we present our experimental insights into how various NoSQL databases handle OLAP workloads within a standardized data processing pipeline.","Our experimental pipeline comprises Apache Spark for large-scale transformations, data cleansing, and schema normalization, diverse NoSQL databases as data stores, and a Business Intelligence tool for data analysis and visualization."],"url":"http://arxiv.org/abs/2405.17731v1","category":"cs.DB"}
{"created":"2024-05-28 00:36:25","title":"MindFormer: A Transformer Architecture for Multi-Subject Brain Decoding via fMRI","abstract":"Research efforts to understand neural signals have been ongoing for many years, with visual decoding from fMRI signals attracting considerable attention. Particularly, the advent of image diffusion models has advanced the reconstruction of images from fMRI data significantly. However, existing approaches often introduce inter- and intra- subject variations in the reconstructed images, which can compromise accuracy. To address current limitations in multi-subject brain decoding, we introduce a new Transformer architecture called MindFormer. This model is specifically designed to generate fMRI-conditioned feature vectors that can be used for conditioning Stable Diffusion model. More specifically, MindFormer incorporates two key innovations: 1) a novel training strategy based on the IP-Adapter to extract semantically meaningful features from fMRI signals, and 2) a subject specific token and linear layer that effectively capture individual differences in fMRI signals while synergistically combines multi subject fMRI data for training. Our experimental results demonstrate that Stable Diffusion, when integrated with MindFormer, produces semantically consistent images across different subjects. This capability significantly surpasses existing models in multi-subject brain decoding. Such advancements not only improve the accuracy of our reconstructions but also deepen our understanding of neural processing variations among individuals.","sentences":["Research efforts to understand neural signals have been ongoing for many years, with visual decoding from fMRI signals attracting considerable attention.","Particularly, the advent of image diffusion models has advanced the reconstruction of images from fMRI data significantly.","However, existing approaches often introduce inter- and intra- subject variations in the reconstructed images, which can compromise accuracy.","To address current limitations in multi-subject brain decoding, we introduce a new Transformer architecture called MindFormer.","This model is specifically designed to generate fMRI-conditioned feature vectors that can be used for conditioning Stable Diffusion model.","More specifically, MindFormer incorporates two key innovations: 1) a novel training strategy based on the IP-Adapter to extract semantically meaningful features from fMRI signals, and 2) a subject specific token and linear layer that effectively capture individual differences in fMRI signals while synergistically combines multi subject fMRI data for training.","Our experimental results demonstrate that Stable Diffusion, when integrated with MindFormer, produces semantically consistent images across different subjects.","This capability significantly surpasses existing models in multi-subject brain decoding.","Such advancements not only improve the accuracy of our reconstructions but also deepen our understanding of neural processing variations among individuals."],"url":"http://arxiv.org/abs/2405.17720v1","category":"cs.CV"}
{"created":"2024-05-28 00:25:41","title":"AdapNet: Adaptive Noise-Based Network for Low-Quality Image Retrieval","abstract":"Image retrieval aims to identify visually similar images within a database using a given query image. Traditional methods typically employ both global and local features extracted from images for matching, and may also apply re-ranking techniques to enhance accuracy. However, these methods often fail to account for the noise present in query images, which can stem from natural or human-induced factors, thereby negatively impacting retrieval performance. To mitigate this issue, we introduce a novel setting for low-quality image retrieval, and propose an Adaptive Noise-Based Network (AdapNet) to learn robust abstract representations. Specifically, we devise a quality compensation block trained to compensate for various low-quality factors in input images. Besides, we introduce an innovative adaptive noise-based loss function, which dynamically adjusts its focus on the gradient in accordance with image quality, thereby augmenting the learning of unknown noisy samples during training and enhancing intra-class compactness. To assess the performance, we construct two datasets with low-quality queries, which is built by applying various types of noise on clean query images on the standard Revisited Oxford and Revisited Paris datasets. Comprehensive experimental results illustrate that AdapNet surpasses state-of-the-art methods on the Noise Revisited Oxford and Noise Revisited Paris benchmarks, while maintaining competitive performance on high-quality datasets. The code and constructed datasets will be made available.","sentences":["Image retrieval aims to identify visually similar images within a database using a given query image.","Traditional methods typically employ both global and local features extracted from images for matching, and may also apply re-ranking techniques to enhance accuracy.","However, these methods often fail to account for the noise present in query images, which can stem from natural or human-induced factors, thereby negatively impacting retrieval performance.","To mitigate this issue, we introduce a novel setting for low-quality image retrieval, and propose an Adaptive Noise-Based Network (AdapNet) to learn robust abstract representations.","Specifically, we devise a quality compensation block trained to compensate for various low-quality factors in input images.","Besides, we introduce an innovative adaptive noise-based loss function, which dynamically adjusts its focus on the gradient in accordance with image quality, thereby augmenting the learning of unknown noisy samples during training and enhancing intra-class compactness.","To assess the performance, we construct two datasets with low-quality queries, which is built by applying various types of noise on clean query images on the standard Revisited Oxford and Revisited Paris datasets.","Comprehensive experimental results illustrate that AdapNet surpasses state-of-the-art methods on the Noise Revisited Oxford and Noise Revisited Paris benchmarks, while maintaining competitive performance on high-quality datasets.","The code and constructed datasets will be made available."],"url":"http://arxiv.org/abs/2405.17718v1","category":"cs.CV"}
{"created":"2024-05-27 23:51:20","title":"OPERA: Automatic Offline Policy Evaluation with Re-weighted Aggregates of Multiple Estimators","abstract":"Offline policy evaluation (OPE) allows us to evaluate and estimate a new sequential decision-making policy's performance by leveraging historical interaction data collected from other policies. Evaluating a new policy online without a confident estimate of its performance can lead to costly, unsafe, or hazardous outcomes, especially in education and healthcare. Several OPE estimators have been proposed in the last decade, many of which have hyperparameters and require training. Unfortunately, choosing the best OPE algorithm for each task and domain is still unclear. In this paper, we propose a new algorithm that adaptively blends a set of OPE estimators given a dataset without relying on an explicit selection using a statistical procedure. We prove that our estimator is consistent and satisfies several desirable properties for policy evaluation. Additionally, we demonstrate that when compared to alternative approaches, our estimator can be used to select higher-performing policies in healthcare and robotics. Our work contributes to improving ease of use for a general-purpose, estimator-agnostic, off-policy evaluation framework for offline RL.","sentences":["Offline policy evaluation (OPE) allows us to evaluate and estimate a new sequential decision-making policy's performance by leveraging historical interaction data collected from other policies.","Evaluating a new policy online without a confident estimate of its performance can lead to costly, unsafe, or hazardous outcomes, especially in education and healthcare.","Several OPE estimators have been proposed in the last decade, many of which have hyperparameters and require training.","Unfortunately, choosing the best OPE algorithm for each task and domain is still unclear.","In this paper, we propose a new algorithm that adaptively blends a set of OPE estimators given a dataset without relying on an explicit selection using a statistical procedure.","We prove that our estimator is consistent and satisfies several desirable properties for policy evaluation.","Additionally, we demonstrate that when compared to alternative approaches, our estimator can be used to select higher-performing policies in healthcare and robotics.","Our work contributes to improving ease of use for a general-purpose, estimator-agnostic, off-policy evaluation framework for offline RL."],"url":"http://arxiv.org/abs/2405.17708v1","category":"cs.LG"}
{"created":"2024-05-27 23:39:17","title":"Video Enriched Retrieval Augmented Generation Using Aligned Video Captions","abstract":"In this work, we propose the use of \"aligned visual captions\" as a mechanism for integrating information contained within videos into retrieval augmented generation (RAG) based chat assistant systems. These captions are able to describe the visual and audio content of videos in a large corpus while having the advantage of being in a textual format that is both easy to reason about & incorporate into large language model (LLM) prompts, but also typically require less multimedia content to be inserted into the multimodal LLM context window, where typical configurations can aggressively fill up the context window by sampling video frames from the source video. Furthermore, visual captions can be adapted to specific use cases by prompting the original foundational model / captioner for particular visual details or fine tuning. In hopes of helping advancing progress in this area, we curate a dataset and describe automatic evaluation procedures on common RAG tasks.","sentences":["In this work, we propose the use of \"aligned visual captions\" as a mechanism for integrating information contained within videos into retrieval augmented generation (RAG) based chat assistant systems.","These captions are able to describe the visual and audio content of videos in a large corpus while having the advantage of being in a textual format that is both easy to reason about & incorporate into large language model (LLM) prompts, but also typically require less multimedia content to be inserted into the multimodal LLM context window, where typical configurations can aggressively fill up the context window by sampling video frames from the source video.","Furthermore, visual captions can be adapted to specific use cases by prompting the original foundational model / captioner for particular visual details or fine tuning.","In hopes of helping advancing progress in this area, we curate a dataset and describe automatic evaluation procedures on common RAG tasks."],"url":"http://arxiv.org/abs/2405.17706v1","category":"cs.AI"}
{"created":"2024-05-27 23:38:10","title":"DC-Gaussian: Improving 3D Gaussian Splatting for Reflective Dash Cam Videos","abstract":"We present DC-Gaussian, a new method for generating novel views from in-vehicle dash cam videos. While neural rendering techniques have made significant strides in driving scenarios, existing methods are primarily designed for videos collected by autonomous vehicles. However, these videos are limited in both quantity and diversity compared to dash cam videos, which are more widely used across various types of vehicles and capture a broader range of scenarios. Dash cam videos often suffer from severe obstructions such as reflections and occlusions on the windshields, which significantly impede the application of neural rendering techniques. To address this challenge, we develop DC-Gaussian based on the recent real-time neural rendering technique 3D Gaussian Splatting (3DGS). Our approach includes an adaptive image decomposition module to model reflections and occlusions in a unified manner. Additionally, we introduce illumination-aware obstruction modeling to manage reflections and occlusions under varying lighting conditions. Lastly, we employ a geometry-guided Gaussian enhancement strategy to improve rendering details by incorporating additional geometry priors. Experiments on self-captured and public dash cam videos show that our method not only achieves state-of-the-art performance in novel view synthesis, but also accurately reconstructing captured scenes getting rid of obstructions.","sentences":["We present DC-Gaussian, a new method for generating novel views from in-vehicle dash cam videos.","While neural rendering techniques have made significant strides in driving scenarios, existing methods are primarily designed for videos collected by autonomous vehicles.","However, these videos are limited in both quantity and diversity compared to dash cam videos, which are more widely used across various types of vehicles and capture a broader range of scenarios.","Dash cam videos often suffer from severe obstructions such as reflections and occlusions on the windshields, which significantly impede the application of neural rendering techniques.","To address this challenge, we develop DC-Gaussian based on the recent real-time neural rendering technique 3D Gaussian Splatting (3DGS).","Our approach includes an adaptive image decomposition module to model reflections and occlusions in a unified manner.","Additionally, we introduce illumination-aware obstruction modeling to manage reflections and occlusions under varying lighting conditions.","Lastly, we employ a geometry-guided Gaussian enhancement strategy to improve rendering details by incorporating additional geometry priors.","Experiments on self-captured and public dash cam videos show that our method not only achieves state-of-the-art performance in novel view synthesis, but also accurately reconstructing captured scenes getting rid of obstructions."],"url":"http://arxiv.org/abs/2405.17705v2","category":"cs.CV"}
{"created":"2024-05-27 23:32:06","title":"Consistency Regularisation for Unsupervised Domain Adaptation in Monocular Depth Estimation","abstract":"In monocular depth estimation, unsupervised domain adaptation has recently been explored to relax the dependence on large annotated image-based depth datasets. However, this comes at the cost of training multiple models or requiring complex training protocols. We formulate unsupervised domain adaptation for monocular depth estimation as a consistency-based semi-supervised learning problem by assuming access only to the source domain ground truth labels. To this end, we introduce a pairwise loss function that regularises predictions on the source domain while enforcing perturbation consistency across multiple augmented views of the unlabelled target samples. Importantly, our approach is simple and effective, requiring only training of a single model in contrast to the prior work. In our experiments, we rely on the standard depth estimation benchmarks KITTI and NYUv2 to demonstrate state-of-the-art results compared to related approaches. Furthermore, we analyse the simplicity and effectiveness of our approach in a series of ablation studies. The code is available at \\url{https://github.com/AmirMaEl/SemiSupMDE}.","sentences":["In monocular depth estimation, unsupervised domain adaptation has recently been explored to relax the dependence on large annotated image-based depth datasets.","However, this comes at the cost of training multiple models or requiring complex training protocols.","We formulate unsupervised domain adaptation for monocular depth estimation as a consistency-based semi-supervised learning problem by assuming access only to the source domain ground truth labels.","To this end, we introduce a pairwise loss function that regularises predictions on the source domain while enforcing perturbation consistency across multiple augmented views of the unlabelled target samples.","Importantly, our approach is simple and effective, requiring only training of a single model in contrast to the prior work.","In our experiments, we rely on the standard depth estimation benchmarks KITTI and NYUv2 to demonstrate state-of-the-art results compared to related approaches.","Furthermore, we analyse the simplicity and effectiveness of our approach in a series of ablation studies.","The code is available at \\url{https://github.com/AmirMaEl/SemiSupMDE}."],"url":"http://arxiv.org/abs/2405.17704v1","category":"cs.CV"}
{"created":"2024-05-27 23:03:21","title":"Physics-guided Full Waveform Inversion using Encoder-Solver Convolutional Neural Networks","abstract":"Full Waveform Inversion (FWI) is an inverse problem for estimating the wave velocity distribution in a given domain, based on observed data on the boundaries. The inversion is computationally demanding because we are required to solve multiple forward problems, either in time or frequency domains, to simulate data that are then iteratively fitted to the observed data. We consider FWI in the frequency domain, where the Helmholtz equation is used as a forward model, and its repeated solution is the main computational bottleneck of the inversion process. To ease this cost, we integrate a learning process of an encoder-solver preconditioner that is based on convolutional neural networks (CNNs). The encoder-solver is trained to effectively precondition the discretized Helmholtz operator given velocity medium parameters. Then, by re-training the CNN between the iterations of the optimization process, the encoder-solver is adapted to the iteratively evolving velocity medium as part of the inversion. Without retraining, the performance of the solver deteriorates as the medium changes. Using our light retraining procedures, we obtain the forward simulations effectively throughout the process. We demonstrate our approach to solving FWI problems using 2D geophysical models with high-frequency data.","sentences":["Full Waveform Inversion (FWI) is an inverse problem for estimating the wave velocity distribution in a given domain, based on observed data on the boundaries.","The inversion is computationally demanding because we are required to solve multiple forward problems, either in time or frequency domains, to simulate data that are then iteratively fitted to the observed data.","We consider FWI in the frequency domain, where the Helmholtz equation is used as a forward model, and its repeated solution is the main computational bottleneck of the inversion process.","To ease this cost, we integrate a learning process of an encoder-solver preconditioner that is based on convolutional neural networks (CNNs).","The encoder-solver is trained to effectively precondition the discretized Helmholtz operator given velocity medium parameters.","Then, by re-training the CNN between the iterations of the optimization process, the encoder-solver is adapted to the iteratively evolving velocity medium as part of the inversion.","Without retraining, the performance of the solver deteriorates as the medium changes.","Using our light retraining procedures, we obtain the forward simulations effectively throughout the process.","We demonstrate our approach to solving FWI problems using 2D geophysical models with high-frequency data."],"url":"http://arxiv.org/abs/2405.17696v1","category":"cs.LG"}
{"created":"2024-05-27 23:00:40","title":"Tamed Langevin sampling under weaker conditions","abstract":"Motivated by applications to deep learning which often fail standard Lipschitz smoothness requirements, we examine the problem of sampling from distributions that are not log-concave and are only weakly dissipative, with log-gradients allowed to grow superlinearly at infinity. In terms of structure, we only assume that the target distribution satisfies either a log-Sobolev or a Poincar\\'e inequality and a local Lipschitz smoothness assumption with modulus growing possibly polynomially at infinity. This set of assumptions greatly exceeds the operational limits of the \"vanilla\" unadjusted Langevin algorithm (ULA), making sampling from such distributions a highly involved affair. To account for this, we introduce a taming scheme which is tailored to the growth and decay properties of the target distribution, and we provide explicit non-asymptotic guarantees for the proposed sampler in terms of the Kullback-Leibler (KL) divergence, total variation, and Wasserstein distance to the target distribution.","sentences":["Motivated by applications to deep learning which often fail standard Lipschitz smoothness requirements, we examine the problem of sampling from distributions that are not log-concave and are only weakly dissipative, with log-gradients allowed to grow superlinearly at infinity.","In terms of structure, we only assume that the target distribution satisfies either a log-Sobolev or a Poincar\\'e inequality and a local Lipschitz smoothness assumption with modulus growing possibly polynomially at infinity.","This set of assumptions greatly exceeds the operational limits of the \"vanilla\" unadjusted Langevin algorithm (ULA), making sampling from such distributions a highly involved affair.","To account for this, we introduce a taming scheme which is tailored to the growth and decay properties of the target distribution, and we provide explicit non-asymptotic guarantees for the proposed sampler in terms of the Kullback-Leibler (KL) divergence, total variation, and Wasserstein distance to the target distribution."],"url":"http://arxiv.org/abs/2405.17693v1","category":"stat.ML"}
{"created":"2024-05-27 22:52:23","title":"Ontology-Enhanced Decision-Making for Autonomous Agents in Dynamic and Partially Observable Environments","abstract":"Agents, whether software or hardware, perceive their environment through sensors and act using actuators, often operating in dynamic, partially observable settings. They face challenges like incomplete and noisy data, unforeseen situations, and the need to adapt goals in real-time. Traditional reasoning and ML methods, including Reinforcement Learning (RL), help but are limited by data needs, predefined goals, and extensive exploration periods. Ontologies offer a solution by integrating diverse information sources, enhancing decision-making in complex environments. This thesis introduces an ontology-enhanced decision-making model (OntoDeM) for autonomous agents. OntoDeM enriches agents' domain knowledge, allowing them to interpret unforeseen events, generate or adapt goals, and make better decisions. Key contributions include: 1. An ontology-based method to improve agents' real-time observations using prior knowledge. 2. The OntoDeM model for handling dynamic, unforeseen situations by evolving or generating new goals. 3. Implementation and evaluation in four real-world applications, demonstrating its effectiveness. Compared to traditional and advanced learning algorithms, OntoDeM shows superior performance in improving agents' observations and decision-making in dynamic, partially observable environments.","sentences":["Agents, whether software or hardware, perceive their environment through sensors and act using actuators, often operating in dynamic, partially observable settings.","They face challenges like incomplete and noisy data, unforeseen situations, and the need to adapt goals in real-time.","Traditional reasoning and ML methods, including Reinforcement Learning (RL), help but are limited by data needs, predefined goals, and extensive exploration periods.","Ontologies offer a solution by integrating diverse information sources, enhancing decision-making in complex environments.","This thesis introduces an ontology-enhanced decision-making model (OntoDeM) for autonomous agents.","OntoDeM enriches agents' domain knowledge, allowing them to interpret unforeseen events, generate or adapt goals, and make better decisions.","Key contributions include: 1.","An ontology-based method to improve agents' real-time observations using prior knowledge.","2.","The OntoDeM model for handling dynamic, unforeseen situations by evolving or generating new goals.","3. Implementation and evaluation in four real-world applications, demonstrating its effectiveness.","Compared to traditional and advanced learning algorithms, OntoDeM shows superior performance in improving agents' observations and decision-making in dynamic, partially observable environments."],"url":"http://arxiv.org/abs/2405.17691v1","category":"cs.AI"}
{"created":"2024-05-27 22:15:23","title":"Deciphering Movement: Unified Trajectory Generation Model for Multi-Agent","abstract":"Understanding multi-agent behavior is critical across various fields. The conventional approach involves analyzing agent movements through three primary tasks: trajectory prediction, imputation, and spatial-temporal recovery. Considering the unique input formulation and constraint of these tasks, most existing methods are tailored to address only one specific task. However, in real-world applications, these scenarios frequently occur simultaneously. Consequently, methods designed for one task often fail to adapt to others, resulting in performance drops. To overcome this limitation, we propose a Unified Trajectory Generation model, UniTraj, that processes arbitrary trajectories as masked inputs, adaptable to diverse scenarios. Specifically, we introduce a Ghost Spatial Masking (GSM) module embedded within a Transformer encoder for spatial feature extraction. We further extend recent successful State Space Models (SSMs), particularly the Mamba model, into a Bidirectional Temporal Mamba to effectively capture temporal dependencies. Additionally, we incorporate a Bidirectional Temporal Scaled (BTS) module to comprehensively scan trajectories while maintaining the temporal missing relationships within the sequence. We curate and benchmark three practical sports game datasets, Basketball-U, Football-U, and Soccer-U, for evaluation. Extensive experiments demonstrate the superior performance of our model. To the best of our knowledge, this is the first work that addresses this unified problem through a versatile generative framework, thereby enhancing our understanding of multi-agent movement. Our datasets, code, and model weights are available at https://github.com/colorfulfuture/UniTraj-pytorch.","sentences":["Understanding multi-agent behavior is critical across various fields.","The conventional approach involves analyzing agent movements through three primary tasks: trajectory prediction, imputation, and spatial-temporal recovery.","Considering the unique input formulation and constraint of these tasks, most existing methods are tailored to address only one specific task.","However, in real-world applications, these scenarios frequently occur simultaneously.","Consequently, methods designed for one task often fail to adapt to others, resulting in performance drops.","To overcome this limitation, we propose a Unified Trajectory Generation model, UniTraj, that processes arbitrary trajectories as masked inputs, adaptable to diverse scenarios.","Specifically, we introduce a Ghost Spatial Masking (GSM) module embedded within a Transformer encoder for spatial feature extraction.","We further extend recent successful State Space Models (SSMs), particularly the Mamba model, into a Bidirectional Temporal Mamba to effectively capture temporal dependencies.","Additionally, we incorporate a Bidirectional Temporal Scaled (BTS) module to comprehensively scan trajectories while maintaining the temporal missing relationships within the sequence.","We curate and benchmark three practical sports game datasets, Basketball-U, Football-U, and Soccer-U, for evaluation.","Extensive experiments demonstrate the superior performance of our model.","To the best of our knowledge, this is the first work that addresses this unified problem through a versatile generative framework, thereby enhancing our understanding of multi-agent movement.","Our datasets, code, and model weights are available at https://github.com/colorfulfuture/UniTraj-pytorch."],"url":"http://arxiv.org/abs/2405.17680v1","category":"cs.CV"}
{"created":"2024-05-27 22:10:17","title":"TIMA: Text-Image Mutual Awareness for Balancing Zero-Shot Adversarial Robustness and Generalization Ability","abstract":"This work addresses the challenge of achieving zero-shot adversarial robustness while preserving zero-shot generalization in large-scale foundation models, with a focus on the popular Contrastive Language-Image Pre-training (CLIP). Although foundation models were reported to have exceptional zero-shot generalization, they are highly vulnerable to adversarial perturbations. Existing methods achieve a comparable good tradeoff between zero-shot adversarial robustness and generalization under small adversarial perturbations. However, they fail to achieve a good tradeoff under large adversarial perturbations. To this end, we propose a novel Text-Image Mutual Awareness (TIMA) method that strikes a balance between zero-shot adversarial robustness and generalization. More precisely, we propose an Image-Aware Text (IAT) tuning mechanism that increases the inter-class distance of text embeddings by incorporating the Minimum Hyperspherical Energy (MHE). Simultaneously, fixed pre-trained image embeddings are used as cross-modal auxiliary supervision to maintain the similarity between the MHE-tuned and original text embeddings by the knowledge distillation, preserving semantic information between different classes. Besides, we introduce a Text-Aware Image (TAI) tuning mechanism, which increases inter-class distance between image embeddings during the training stage by Text-distance based Adaptive Margin (TAM). Similarly, a knowledge distillation is utilized to retain the similarity between fine-tuned and pre-trained image embeddings. Extensive experimental results demonstrate the effectiveness of our approach, showing impressive zero-shot performance against a wide range of adversarial perturbations while preserving the zero-shot generalization capabilities of the original CLIP model.","sentences":["This work addresses the challenge of achieving zero-shot adversarial robustness while preserving zero-shot generalization in large-scale foundation models, with a focus on the popular Contrastive Language-Image Pre-training (CLIP).","Although foundation models were reported to have exceptional zero-shot generalization, they are highly vulnerable to adversarial perturbations.","Existing methods achieve a comparable good tradeoff between zero-shot adversarial robustness and generalization under small adversarial perturbations.","However, they fail to achieve a good tradeoff under large adversarial perturbations.","To this end, we propose a novel Text-Image Mutual Awareness (TIMA) method that strikes a balance between zero-shot adversarial robustness and generalization.","More precisely, we propose an Image-Aware Text (IAT) tuning mechanism that increases the inter-class distance of text embeddings by incorporating the Minimum Hyperspherical Energy (MHE).","Simultaneously, fixed pre-trained image embeddings are used as cross-modal auxiliary supervision to maintain the similarity between the MHE-tuned and original text embeddings by the knowledge distillation, preserving semantic information between different classes.","Besides, we introduce a Text-Aware Image (TAI) tuning mechanism, which increases inter-class distance between image embeddings during the training stage by Text-distance based Adaptive Margin (TAM).","Similarly, a knowledge distillation is utilized to retain the similarity between fine-tuned and pre-trained image embeddings.","Extensive experimental results demonstrate the effectiveness of our approach, showing impressive zero-shot performance against a wide range of adversarial perturbations while preserving the zero-shot generalization capabilities of the original CLIP model."],"url":"http://arxiv.org/abs/2405.17678v1","category":"cs.CV"}
{"created":"2024-05-27 22:06:42","title":"Understanding differences in applying DETR to natural and medical images","abstract":"Transformer-based detectors have shown success in computer vision tasks with natural images. These models, exemplified by the Deformable DETR, are optimized through complex engineering strategies tailored to the typical characteristics of natural scenes. However, medical imaging data presents unique challenges such as extremely large image sizes, fewer and smaller regions of interest, and object classes which can be differentiated only through subtle differences. This study evaluates the applicability of these transformer-based design choices when applied to a screening mammography dataset that represents these distinct medical imaging data characteristics. Our analysis reveals that common design choices from the natural image domain, such as complex encoder architectures, multi-scale feature fusion, query initialization, and iterative bounding box refinement, do not improve and sometimes even impair object detection performance in medical imaging. In contrast, simpler and shallower architectures often achieve equal or superior results. This finding suggests that the adaptation of transformer models for medical imaging data requires a reevaluation of standard practices, potentially leading to more efficient and specialized frameworks for medical diagnosis.","sentences":["Transformer-based detectors have shown success in computer vision tasks with natural images.","These models, exemplified by the Deformable DETR, are optimized through complex engineering strategies tailored to the typical characteristics of natural scenes.","However, medical imaging data presents unique challenges such as extremely large image sizes, fewer and smaller regions of interest, and object classes which can be differentiated only through subtle differences.","This study evaluates the applicability of these transformer-based design choices when applied to a screening mammography dataset that represents these distinct medical imaging data characteristics.","Our analysis reveals that common design choices from the natural image domain, such as complex encoder architectures, multi-scale feature fusion, query initialization, and iterative bounding box refinement, do not improve and sometimes even impair object detection performance in medical imaging.","In contrast, simpler and shallower architectures often achieve equal or superior results.","This finding suggests that the adaptation of transformer models for medical imaging data requires a reevaluation of standard practices, potentially leading to more efficient and specialized frameworks for medical diagnosis."],"url":"http://arxiv.org/abs/2405.17677v1","category":"cs.CV"}
{"created":"2024-05-27 21:33:56","title":"Enhanced Robot Arm at the Edge with NLP and Vision Systems","abstract":"This paper introduces a \"proof of concept\" for a new approach to assistive robotics, integrating edge computing with Natural Language Processing (NLP) and computer vision to enhance the interaction between humans and robotic systems. Our \"proof of concept\" demonstrates the feasibility of using large language models (LLMs) and vision systems in tandem for interpreting and executing complex commands conveyed through natural language. This integration aims to improve the intuitiveness and accessibility of assistive robotic systems, making them more adaptable to the nuanced needs of users with disabilities. By leveraging the capabilities of edge computing, our system has the potential to minimize latency and support offline capability, enhancing the autonomy and responsiveness of assistive robots. Experimental results from our implementation on a robotic arm show promising outcomes in terms of accurate intent interpretation and object manipulation based on verbal commands. This research lays the groundwork for future developments in assistive robotics, focusing on creating highly responsive, user-centric systems that can significantly improve the quality of life for individuals with disabilities.","sentences":["This paper introduces a \"proof of concept\" for a new approach to assistive robotics, integrating edge computing with Natural Language Processing (NLP) and computer vision to enhance the interaction between humans and robotic systems.","Our \"proof of concept\" demonstrates the feasibility of using large language models (LLMs) and vision systems in tandem for interpreting and executing complex commands conveyed through natural language.","This integration aims to improve the intuitiveness and accessibility of assistive robotic systems, making them more adaptable to the nuanced needs of users with disabilities.","By leveraging the capabilities of edge computing, our system has the potential to minimize latency and support offline capability, enhancing the autonomy and responsiveness of assistive robots.","Experimental results from our implementation on a robotic arm show promising outcomes in terms of accurate intent interpretation and object manipulation based on verbal commands.","This research lays the groundwork for future developments in assistive robotics, focusing on creating highly responsive, user-centric systems that can significantly improve the quality of life for individuals with disabilities."],"url":"http://arxiv.org/abs/2405.17665v1","category":"cs.RO"}
{"created":"2024-05-27 21:30:52","title":"Adaptive Device-Edge Collaboration on DNN Inference in AIoT: A Digital Twin-Assisted Approach","abstract":"Device-edge collaboration on deep neural network (DNN) inference is a promising approach to efficiently utilizing network resources for supporting artificial intelligence of things (AIoT) applications. In this paper, we propose a novel digital twin (DT)-assisted approach to device-edge collaboration on DNN inference that determines whether and when to stop local inference at a device and upload the intermediate results to complete the inference on an edge server. Instead of determining the collaboration for each DNN inference task only upon its generation, multi-step decision-making is performed during the on-device inference to adapt to the dynamic computing workload status at the device and the edge server. To enhance the adaptivity, a DT is constructed to evaluate all potential offloading decisions for each DNN inference task, which provides augmented training data for a machine learning-assisted decision-making algorithm. Then, another DT is constructed to estimate the inference status at the device to avoid frequently fetching the status information from the device, thus reducing the signaling overhead. We also derive necessary conditions for optimal offloading decisions to reduce the offloading decision space. Simulation results demon-strate the outstanding performance of our DT-assisted approach in terms of balancing the tradeoff among inference accuracy, delay, and energy consumption.","sentences":["Device-edge collaboration on deep neural network (DNN) inference is a promising approach to efficiently utilizing network resources for supporting artificial intelligence of things (AIoT) applications.","In this paper, we propose a novel digital twin (DT)-assisted approach to device-edge collaboration on DNN inference that determines whether and when to stop local inference at a device and upload the intermediate results to complete the inference on an edge server.","Instead of determining the collaboration for each DNN inference task only upon its generation, multi-step decision-making is performed during the on-device inference to adapt to the dynamic computing workload status at the device and the edge server.","To enhance the adaptivity, a DT is constructed to evaluate all potential offloading decisions for each DNN inference task, which provides augmented training data for a machine learning-assisted decision-making algorithm.","Then, another DT is constructed to estimate the inference status at the device to avoid frequently fetching the status information from the device, thus reducing the signaling overhead.","We also derive necessary conditions for optimal offloading decisions to reduce the offloading decision space.","Simulation results demon-strate the outstanding performance of our DT-assisted approach in terms of balancing the tradeoff among inference accuracy, delay, and energy consumption."],"url":"http://arxiv.org/abs/2405.17664v1","category":"cs.DC"}
{"created":"2024-05-27 21:28:26","title":"What's the Opposite of a Face? Finding Shared Decodable Concepts and their Negations in the Brain","abstract":"Prior work has offered evidence for functional localization in the brain; different anatomical regions preferentially activate for certain types of visual input. For example, the fusiform face area preferentially activates for visual stimuli that include a face. However, the spectrum of visual semantics is extensive, and only a few semantically-tuned patches of cortex have so far been identified in the human brain. Using a multimodal (natural language and image) neural network architecture (CLIP) we train a highly accurate contrastive model that maps brain responses during naturalistic image viewing to CLIP embeddings. We then use a novel adaptation of the DBSCAN clustering algorithm to cluster the parameters of these participant-specific contrastive models. This reveals what we call Shared Decodable Concepts (SDCs): clusters in CLIP space that are decodable from common sets of voxels across multiple participants.   Examining the images most and least associated with each SDC cluster gives us additional insight into the semantic properties of each SDC. We note SDCs for previously reported visual features (e.g. orientation tuning in early visual cortex) as well as visual semantic concepts such as faces, places and bodies. In cases where our method finds multiple clusters for a visuo-semantic concept, the least associated images allow us to dissociate between confounding factors. For example, we discovered two clusters of food images, one driven by color, the other by shape. We also uncover previously unreported areas such as regions of extrastriate body area (EBA) tuned for legs/hands and sensitivity to numerosity in right intraparietal sulcus, and more. Thus, our contrastive-learning methodology better characterizes new and existing visuo-semantic representations in the brain by leveraging multimodal neural network representations and a novel adaptation of clustering algorithms.","sentences":["Prior work has offered evidence for functional localization in the brain; different anatomical regions preferentially activate for certain types of visual input.","For example, the fusiform face area preferentially activates for visual stimuli that include a face.","However, the spectrum of visual semantics is extensive, and only a few semantically-tuned patches of cortex have so far been identified in the human brain.","Using a multimodal (natural language and image) neural network architecture (CLIP) we train a highly accurate contrastive model that maps brain responses during naturalistic image viewing to CLIP embeddings.","We then use a novel adaptation of the DBSCAN clustering algorithm to cluster the parameters of these participant-specific contrastive models.","This reveals what we call Shared Decodable Concepts (SDCs): clusters in CLIP space that are decodable from common sets of voxels across multiple participants.   ","Examining the images most and least associated with each SDC cluster gives us additional insight into the semantic properties of each SDC.","We note SDCs for previously reported visual features (e.g. orientation tuning in early visual cortex) as well as visual semantic concepts such as faces, places and bodies.","In cases where our method finds multiple clusters for a visuo-semantic concept, the least associated images allow us to dissociate between confounding factors.","For example, we discovered two clusters of food images, one driven by color, the other by shape.","We also uncover previously unreported areas such as regions of extrastriate body area (EBA) tuned for legs/hands and sensitivity to numerosity in right intraparietal sulcus, and more.","Thus, our contrastive-learning methodology better characterizes new and existing visuo-semantic representations in the brain by leveraging multimodal neural network representations and a novel adaptation of clustering algorithms."],"url":"http://arxiv.org/abs/2405.17663v1","category":"cs.LG"}
{"created":"2024-05-27 21:23:20","title":"RefDrop: Controllable Consistency in Image or Video Generation via Reference Feature Guidance","abstract":"There is a rapidly growing interest in controlling consistency across multiple generated images using diffusion models. Among various methods, recent works have found that simply manipulating attention modules by concatenating features from multiple reference images provides an efficient approach to enhancing consistency without fine-tuning. Despite its popularity and success, few studies have elucidated the underlying mechanisms that contribute to its effectiveness. In this work, we reveal that the popular approach is a linear interpolation of image self-attention and cross-attention between synthesized content and reference features, with a constant rank-1 coefficient. Motivated by this observation, we find that a rank-1 coefficient is not necessary and simplifies the controllable generation mechanism. The resulting algorithm, which we coin as RefDrop, allows users to control the influence of reference context in a direct and precise manner. Besides further enhancing consistency in single-subject image generation, our method also enables more interesting applications, such as the consistent generation of multiple subjects, suppressing specific features to encourage more diverse content, and high-quality personalized video generation by boosting temporal consistency. Even compared with state-of-the-art image-prompt-based generators, such as IP-Adapter, RefDrop is competitive in terms of controllability and quality while avoiding the need to train a separate image encoder for feature injection from reference images, making it a versatile plug-and-play solution for any image or video diffusion model.","sentences":["There is a rapidly growing interest in controlling consistency across multiple generated images using diffusion models.","Among various methods, recent works have found that simply manipulating attention modules by concatenating features from multiple reference images provides an efficient approach to enhancing consistency without fine-tuning.","Despite its popularity and success, few studies have elucidated the underlying mechanisms that contribute to its effectiveness.","In this work, we reveal that the popular approach is a linear interpolation of image self-attention and cross-attention between synthesized content and reference features, with a constant rank-1 coefficient.","Motivated by this observation, we find that a rank-1 coefficient is not necessary and simplifies the controllable generation mechanism.","The resulting algorithm, which we coin as RefDrop, allows users to control the influence of reference context in a direct and precise manner.","Besides further enhancing consistency in single-subject image generation, our method also enables more interesting applications, such as the consistent generation of multiple subjects, suppressing specific features to encourage more diverse content, and high-quality personalized video generation by boosting temporal consistency.","Even compared with state-of-the-art image-prompt-based generators, such as IP-Adapter, RefDrop is competitive in terms of controllability and quality while avoiding the need to train a separate image encoder for feature injection from reference images, making it a versatile plug-and-play solution for any image or video diffusion model."],"url":"http://arxiv.org/abs/2405.17661v1","category":"cs.CV"}
{"created":"2024-05-27 20:57:19","title":"Alignment is Key for Applying Diffusion Models to Retrosynthesis","abstract":"Retrosynthesis, the task of identifying precursors for a given molecule, can be naturally framed as a conditional graph generation task. Diffusion models are a particularly promising modelling approach, enabling post-hoc conditioning and trading off quality for speed during generation. We show mathematically that permutation equivariant denoisers severely limit the expressiveness of graph diffusion models and thus their adaptation to retrosynthesis. To address this limitation, we relax the equivariance requirement such that it only applies to aligned permutations of the conditioning and the generated graphs obtained through atom mapping. Our new denoiser achieves the highest top-$1$ accuracy ($54.7$\\%) across template-free and template-based methods on USPTO-50k. We also demonstrate the ability for flexible post-training conditioning and good sample quality with small diffusion step counts, highlighting the potential for interactive applications and additional controls for multi-step planning.","sentences":["Retrosynthesis, the task of identifying precursors for a given molecule, can be naturally framed as a conditional graph generation task.","Diffusion models are a particularly promising modelling approach, enabling post-hoc conditioning and trading off quality for speed during generation.","We show mathematically that permutation equivariant denoisers severely limit the expressiveness of graph diffusion models and thus their adaptation to retrosynthesis.","To address this limitation, we relax the equivariance requirement such that it only applies to aligned permutations of the conditioning and the generated graphs obtained through atom mapping.","Our new denoiser achieves the highest top-$1$ accuracy ($54.7$\\%) across template-free and template-based methods on USPTO-50k.","We also demonstrate the ability for flexible post-training conditioning and good sample quality with small diffusion step counts, highlighting the potential for interactive applications and additional controls for multi-step planning."],"url":"http://arxiv.org/abs/2405.17656v1","category":"cs.LG"}
{"created":"2024-05-27 19:28:33","title":"Symmetric Reinforcement Learning Loss for Robust Learning on Diverse Tasks and Model Scales","abstract":"Reinforcement learning (RL) training is inherently unstable due to factors such as moving targets and high gradient variance. Reinforcement Learning from Human Feedback (RLHF) and Reinforcement Learning from AI Feedback (RLAIF) can introduce additional difficulty. Differing preferences can complicate the alignment process, and prediction errors in a trained reward model can become more severe as the LLM generates unseen outputs. To enhance training robustness, RL has adopted techniques from supervised learning, such as ensembles and layer normalization. In this work, we improve the stability of RL training by adapting the reverse cross entropy (RCE) from supervised learning for noisy data to define a symmetric RL loss. We demonstrate performance improvements across various tasks and scales. We conduct experiments in discrete action tasks (Atari games) and continuous action space tasks (MuJoCo benchmark and Box2D) using Symmetric A2C (SA2C) and Symmetric PPO (SPPO), with and without added noise with especially notable performance in SPPO across different hyperparameters. Furthermore, we validate the benefits of the symmetric RL loss when using SPPO for large language models through improved performance in RLHF tasks, such as IMDB positive sentiment sentiment and TL;DR summarization tasks.","sentences":["Reinforcement learning (RL) training is inherently unstable due to factors such as moving targets and high gradient variance.","Reinforcement Learning from Human Feedback (RLHF) and Reinforcement Learning from AI Feedback (RLAIF) can introduce additional difficulty.","Differing preferences can complicate the alignment process, and prediction errors in a trained reward model can become more severe as the LLM generates unseen outputs.","To enhance training robustness, RL has adopted techniques from supervised learning, such as ensembles and layer normalization.","In this work, we improve the stability of RL training by adapting the reverse cross entropy (RCE) from supervised learning for noisy data to define a symmetric RL loss.","We demonstrate performance improvements across various tasks and scales.","We conduct experiments in discrete action tasks (Atari games) and continuous action space tasks (MuJoCo benchmark and Box2D) using Symmetric A2C (SA2C) and Symmetric PPO (SPPO), with and without added noise with especially notable performance in SPPO across different hyperparameters.","Furthermore, we validate the benefits of the symmetric RL loss when using SPPO for large language models through improved performance in RLHF tasks, such as IMDB positive sentiment sentiment and TL;DR summarization tasks."],"url":"http://arxiv.org/abs/2405.17618v2","category":"cs.LG"}
{"created":"2024-05-27 19:07:13","title":"LoRA-XS: Low-Rank Adaptation with Extremely Small Number of Parameters","abstract":"The recent trend in scaling language models has led to a growing demand for parameter-efficient tuning (PEFT) methods such as LoRA (Low-Rank Adaptation). LoRA consistently matches or surpasses the full fine-tuning baseline with fewer parameters. However, handling numerous task-specific or user-specific LoRA modules on top of a base model still presents significant storage challenges. To address this, we introduce LoRA-XS (Low-Rank Adaptation with eXtremely Small number of parameters), a novel approach leveraging Singular Value Decomposition (SVD) for parameter-efficient fine-tuning. LoRA-XS introduces a small r x r weight matrix between frozen LoRA matrices, which are constructed by SVD of the original weight matrix. Training only r x r weight matrices ensures independence from model dimensions, enabling more parameter-efficient fine-tuning, especially for larger models. LoRA-XS achieves a remarkable reduction of trainable parameters by over 100x in 7B models compared to LoRA. Our benchmarking across various scales, including GLUE, GSM8k, and MATH benchmarks, shows that our approach outperforms LoRA and recent state-of-the-art approaches like VeRA in terms of parameter efficiency while maintaining competitive performance.","sentences":["The recent trend in scaling language models has led to a growing demand for parameter-efficient tuning (PEFT) methods such as LoRA (Low-Rank Adaptation).","LoRA consistently matches or surpasses the full fine-tuning baseline with fewer parameters.","However, handling numerous task-specific or user-specific LoRA modules on top of a base model still presents significant storage challenges.","To address this, we introduce LoRA-XS (Low-Rank Adaptation with eXtremely Small number of parameters), a novel approach leveraging Singular Value Decomposition (SVD) for parameter-efficient fine-tuning.","LoRA-XS introduces a small r x r weight matrix between frozen LoRA matrices, which are constructed by SVD of the original weight matrix.","Training only r x r weight matrices ensures independence from model dimensions, enabling more parameter-efficient fine-tuning, especially for larger models.","LoRA-XS achieves a remarkable reduction of trainable parameters by over 100x in 7B models compared to LoRA.","Our benchmarking across various scales, including GLUE, GSM8k, and MATH benchmarks, shows that our approach outperforms LoRA and recent state-of-the-art approaches like VeRA in terms of parameter efficiency while maintaining competitive performance."],"url":"http://arxiv.org/abs/2405.17604v1","category":"cs.LG"}
{"created":"2024-05-27 18:32:03","title":"Tleco: A Toolkit for Modeling Radiative Signatures from Relativistic Outflows","abstract":"A wide range of astrophysical sources exhibit extreme and rapidly varying electromagnetic emission indicative of efficient non-thermal particle acceleration. Understanding these sources often involves comparing data with a broad range of theoretical scenarios. To this end, it is beneficial to have tools that enable not only fast and efficient parametric investigation of the predictions of a specific scenario but also the flexibility to explore different theoretical ideas. In this paper, we introduce \\texttt{Tleco}, a versatile and lightweight toolkit for developing numerical models of relativistic outflows, including their particle acceleration mechanisms and resultant electromagnetic signature. Built on the Rust programming language and wrapped into a Python library, \\texttt{Tleco} offers efficient algorithms for evolving relativistic particle distributions and for solving the resulting emissions in a customizable fashion. \\texttt{Tleco} uses a fully implicit discretization algorithm to solve the Fokker-Planck (FP) equation with user-defined diffusion, advection, cooling, injection, and escape, and offers prescriptions for radiative emission and cooling. These include, but are not limited to, synchrotron, inverse-Compton, and self-synchrotron absorption. \\texttt{Tleco} is designed to be user-friendly and adaptable to model particle acceleration and the resulting electromagnetic spectrum and temporal variability in a wide variety of astrophysical scenarios, including, but not limited to, gamma-ray bursts, pulsar wind nebulae, and jets from active galactic nuclei. In this work, we outline the core algorithms and proceed to evaluate and demonstrate their effectiveness. The code is open-source and available in the GitHub repository: \\href{https://github.com/zkdavis/Tleco","sentences":["A wide range of astrophysical sources exhibit extreme and rapidly varying electromagnetic emission indicative of efficient non-thermal particle acceleration.","Understanding these sources often involves comparing data with a broad range of theoretical scenarios.","To this end, it is beneficial to have tools that enable not only fast and efficient parametric investigation of the predictions of a specific scenario but also the flexibility to explore different theoretical ideas.","In this paper, we introduce \\texttt{Tleco}, a versatile and lightweight toolkit for developing numerical models of relativistic outflows, including their particle acceleration mechanisms and resultant electromagnetic signature.","Built on the Rust programming language and wrapped into a Python library, \\texttt{Tleco} offers efficient algorithms for evolving relativistic particle distributions and for solving the resulting emissions in a customizable fashion.","\\texttt{Tleco} uses a fully implicit discretization algorithm to solve the Fokker-Planck (FP) equation with user-defined diffusion, advection, cooling, injection, and escape, and offers prescriptions for radiative emission and cooling.","These include, but are not limited to, synchrotron, inverse-Compton, and self-synchrotron absorption.","\\texttt{Tleco} is designed to be user-friendly and adaptable to model particle acceleration and the resulting electromagnetic spectrum and temporal variability in a wide variety of astrophysical scenarios, including, but not limited to, gamma-ray bursts, pulsar wind nebulae, and jets from active galactic nuclei.","In this work, we outline the core algorithms and proceed to evaluate and demonstrate their effectiveness.","The code is open-source and available in the GitHub repository: \\href{https://github.com/zkdavis/Tleco"],"url":"http://arxiv.org/abs/2405.17581v1","category":"astro-ph.HE"}
{"created":"2024-05-27 18:15:05","title":"Hamiltonian Mechanics of Feature Learning: Bottleneck Structure in Leaky ResNets","abstract":"We study Leaky ResNets, which interpolate between ResNets ($\\tilde{L}=0$) and Fully-Connected nets ($\\tilde{L}\\to\\infty$) depending on an 'effective depth' hyper-parameter $\\tilde{L}$. In the infinite depth limit, we study 'representation geodesics' $A_{p}$: continuous paths in representation space (similar to NeuralODEs) from input $p=0$ to output $p=1$ that minimize the parameter norm of the network. We give a Lagrangian and Hamiltonian reformulation, which highlight the importance of two terms: a kinetic energy which favors small layer derivatives $\\partial_{p}A_{p}$ and a potential energy that favors low-dimensional representations, as measured by the 'Cost of Identity'. The balance between these two forces offers an intuitive understanding of feature learning in ResNets. We leverage this intuition to explain the emergence of a bottleneck structure, as observed in previous work: for large $\\tilde{L}$ the potential energy dominates and leads to a separation of timescales, where the representation jumps rapidly from the high dimensional inputs to a low-dimensional representation, move slowly inside the space of low-dimensional representations, before jumping back to the potentially high-dimensional outputs. Inspired by this phenomenon, we train with an adaptive layer step-size to adapt to the separation of timescales.","sentences":["We study Leaky ResNets, which interpolate between ResNets ($\\tilde{L}=0$) and Fully-Connected nets ($\\tilde{L}\\to\\infty$) depending on an 'effective depth' hyper-parameter $\\tilde{L}$. In the infinite depth limit, we study 'representation geodesics' $A_{p}$: continuous paths in representation space (similar to NeuralODEs) from input $p=0$ to output $p=1$ that minimize the parameter norm of the network.","We give a Lagrangian and Hamiltonian reformulation, which highlight the importance of two terms: a kinetic energy which favors small layer derivatives $\\partial_{p}A_{p}$ and a potential energy that favors low-dimensional representations, as measured by the 'Cost of Identity'.","The balance between these two forces offers an intuitive understanding of feature learning in ResNets.","We leverage this intuition to explain the emergence of a bottleneck structure, as observed in previous work: for large $\\tilde{L}$ the potential energy dominates and leads to a separation of timescales, where the representation jumps rapidly from the high dimensional inputs to a low-dimensional representation, move slowly inside the space of low-dimensional representations, before jumping back to the potentially high-dimensional outputs.","Inspired by this phenomenon, we train with an adaptive layer step-size to adapt to the separation of timescales."],"url":"http://arxiv.org/abs/2405.17573v1","category":"stat.ML"}
{"created":"2024-05-27 18:03:00","title":"Strategic Code: A Unified Spatio-Temporal Framework for Quantum Error-Correction","abstract":"Quantum error-correcting code (QECC) is the central ingredient in fault-tolerant quantum information processing. An emerging paradigm of dynamical QECC shows that one can robustly encode logical quantum information both temporally and spatially in a more resource-efficient manner than traditional QECCs. Nevertheless, an overarching theory of how dynamical QECCs achieve fault-tolerance is lacking. In this work, we bridge this gap by proposing a unified spatio-temporal QECC framework called the ``strategic code'' built around an ``interrogator'' device which sequentially measures and evolves the spatial QECC in an adaptive manner based on the ``quantum combs'' formalism, a generalization of the channel-state duality. The strategic code covers all existing dynamical and static QECC, as well as all physically plausible QECCs to be discovered in the future, including those that involve adaptivity in its operational dynamics. Within this framework, we show an algebraic and an information-theoretic necessary and sufficient error-correction conditions for a strategic code, which consider spatially and temporally correlated errors. These conditions include the analogous known static QECC conditions as a special case. Lastly, we also propose an optimization-theoretic approach to obtain an approximate strategic code adapting to a correlated error.","sentences":["Quantum error-correcting code (QECC) is the central ingredient in fault-tolerant quantum information processing.","An emerging paradigm of dynamical QECC shows that one can robustly encode logical quantum information both temporally and spatially in a more resource-efficient manner than traditional QECCs.","Nevertheless, an overarching theory of how dynamical QECCs achieve fault-tolerance is lacking.","In this work, we bridge this gap by proposing a unified spatio-temporal QECC framework called the ``strategic code'' built around an ``interrogator'' device which sequentially measures and evolves the spatial QECC in an adaptive manner based on the ``quantum combs'' formalism, a generalization of the channel-state duality.","The strategic code covers all existing dynamical and static QECC, as well as all physically plausible QECCs to be discovered in the future, including those that involve adaptivity in its operational dynamics.","Within this framework, we show an algebraic and an information-theoretic necessary and sufficient error-correction conditions for a strategic code, which consider spatially and temporally correlated errors.","These conditions include the analogous known static QECC conditions as a special case.","Lastly, we also propose an optimization-theoretic approach to obtain an approximate strategic code adapting to a correlated error."],"url":"http://arxiv.org/abs/2405.17567v1","category":"quant-ph"}
{"created":"2024-05-28 17:59:51","title":"On the Origin of Llamas: Model Tree Heritage Recovery","abstract":"The rapid growth of neural network models shared on the internet has made model weights an important data modality. However, this information is underutilized as the weights are uninterpretable, and publicly available models are disorganized. Inspired by Darwin's tree of life, we define the Model Tree which describes the origin of models i.e., the parent model that was used to fine-tune the target model. Similarly to the natural world, the tree structure is unknown. In this paper, we introduce the task of Model Tree Heritage Recovery (MoTHer Recovery) for discovering Model Trees in the ever-growing universe of neural networks. Our hypothesis is that model weights encode this information, the challenge is to decode the underlying tree structure given the weights. Beyond the immediate application of model authorship attribution, MoTHer recovery holds exciting long-term applications akin to indexing the internet by search engines. Practically, for each pair of models, this task requires: i) determining if they are related, and ii) establishing the direction of the relationship. We find that certain distributional properties of the weights evolve monotonically during training, which enables us to classify the relationship between two given models. MoTHer recovery reconstructs entire model hierarchies, represented by a directed tree, where a parent model gives rise to multiple child models through additional training. Our approach successfully reconstructs complex Model Trees, as well as the structure of \"in-the-wild\" model families such as Llama 2 and Stable Diffusion.","sentences":["The rapid growth of neural network models shared on the internet has made model weights an important data modality.","However, this information is underutilized as the weights are uninterpretable, and publicly available models are disorganized.","Inspired by Darwin's tree of life, we define the Model Tree which describes the origin of models i.e., the parent model that was used to fine-tune the target model.","Similarly to the natural world, the tree structure is unknown.","In this paper, we introduce the task of Model Tree Heritage Recovery (MoTHer Recovery) for discovering Model Trees in the ever-growing universe of neural networks.","Our hypothesis is that model weights encode this information, the challenge is to decode the underlying tree structure given the weights.","Beyond the immediate application of model authorship attribution, MoTHer recovery holds exciting long-term applications akin to indexing the internet by search engines.","Practically, for each pair of models, this task requires: i) determining if they are related, and ii) establishing the direction of the relationship.","We find that certain distributional properties of the weights evolve monotonically during training, which enables us to classify the relationship between two given models.","MoTHer recovery reconstructs entire model hierarchies, represented by a directed tree, where a parent model gives rise to multiple child models through additional training.","Our approach successfully reconstructs complex Model Trees, as well as the structure of \"in-the-wild\" model families such as Llama 2 and Stable Diffusion."],"url":"http://arxiv.org/abs/2405.18432v1","category":"cs.LG"}
{"created":"2024-05-28 17:57:15","title":"A physics-inspired evolutionary machine learning method: from the Schr\u00f6dinger equation to an orbital-free-DFT kinetic energy functional","abstract":"We introduce a machine learning (ML) supervised model function that is inspired by the variational principle of physics. This ML hypothesis evolutionary method, termed ML-Omega, allows us to go from data to differential equation(s) underlying the physical (chemical, engineering, etc.) phenomena the data are derived from. The fundamental equations of physics can be derived from this ML-Omega evolutionary method when provided the proper training data. By training the ML-Omega model function with only three hydrogen-like atom energies, the method can find Schr\\\"odinger's exact functional and, from it, Schr\\\"odinger's fundamental equation. Then, in the field of density functional theory (DFT), when the model function is trained with the energies from the known Thomas-Fermi (TF) formula E = -0.7687Z^7/3, it correctly finds the exact TF functional. Finally, the method is applied to find a local orbital-free (OF) functional expression of the independent electron kinetic energy functional Ts based on the gamma-TF-lambda-vW model. By considering the theoretical energies of only 5 atoms (He, Be, Ne, Mg, Ar) as the training set, the evolutionary ML-Omega method finds an ML-Omega-OF-DFT local Ts functional (gamma-TF-lambda-vW (0.964, 1/4)) that outperforms all the OF- DFT functionals of a representative group. Moreover, our ML-Omega-OF functional overcomes the LDA's and some local GGA-DFT's functionals' difficulty to describe the stretched bond region at the correct spin configuration of diatomic molecules. Although our evolutionary ML-Omega model function can work without an explicit prior-form functional, by using the techniques of symbolic regression, in this work we exploit prior-form functional expressions to make the training process faster in the example problems presented here.","sentences":["We introduce a machine learning (ML) supervised model function that is inspired by the variational principle of physics.","This ML hypothesis evolutionary method, termed ML-Omega, allows us to go from data to differential equation(s) underlying the physical (chemical, engineering, etc.)","phenomena the data are derived from.","The fundamental equations of physics can be derived from this ML-Omega evolutionary method when provided the proper training data.","By training the ML-Omega model function with only three hydrogen-like atom energies, the method can find Schr\\\"odinger's exact functional and, from it, Schr\\\"odinger's fundamental equation.","Then, in the field of density functional theory (DFT), when the model function is trained with the energies from the known Thomas-Fermi (TF) formula E = -0.7687Z^7/3, it correctly finds the exact TF functional.","Finally, the method is applied to find a local orbital-free (OF) functional expression of the independent electron kinetic energy functional Ts based on the gamma-TF-lambda-vW model.","By considering the theoretical energies of only 5 atoms (He, Be, Ne, Mg, Ar) as the training set, the evolutionary ML-Omega method finds an ML-Omega-OF-DFT local Ts functional (gamma-TF-lambda-vW (0.964, 1/4)) that outperforms all the OF- DFT functionals of a representative group.","Moreover, our ML-Omega-OF functional overcomes the LDA's and some local GGA-DFT's functionals' difficulty to describe the stretched bond region at the correct spin configuration of diatomic molecules.","Although our evolutionary ML-Omega model function can work without an explicit prior-form functional, by using the techniques of symbolic regression, in this work we exploit prior-form functional expressions to make the training process faster in the example problems presented here."],"url":"http://arxiv.org/abs/2405.18417v1","category":"physics.chem-ph"}
{"created":"2024-05-28 17:56:46","title":"Don't Forget to Connect! Improving RAG with Graph-based Reranking","abstract":"Retrieval Augmented Generation (RAG) has greatly improved the performance of Large Language Model (LLM) responses by grounding generation with context from existing documents. These systems work well when documents are clearly relevant to a question context. But what about when a document has partial information, or less obvious connections to the context? And how should we reason about connections between documents? In this work, we seek to answer these two core questions about RAG generation. We introduce G-RAG, a reranker based on graph neural networks (GNNs) between the retriever and reader in RAG. Our method combines both connections between documents and semantic information (via Abstract Meaning Representation graphs) to provide a context-informed ranker for RAG. G-RAG outperforms state-of-the-art approaches while having smaller computational footprint. Additionally, we assess the performance of PaLM 2 as a reranker and find it to significantly underperform G-RAG. This result emphasizes the importance of reranking for RAG even when using Large Language Models.","sentences":["Retrieval Augmented Generation (RAG) has greatly improved the performance of Large Language Model (LLM) responses by grounding generation with context from existing documents.","These systems work well when documents are clearly relevant to a question context.","But what about when a document has partial information, or less obvious connections to the context?","And how should we reason about connections between documents?","In this work, we seek to answer these two core questions about RAG generation.","We introduce G-RAG, a reranker based on graph neural networks (GNNs) between the retriever and reader in RAG.","Our method combines both connections between documents and semantic information (via Abstract Meaning Representation graphs) to provide a context-informed ranker for RAG.","G-RAG outperforms state-of-the-art approaches while having smaller computational footprint.","Additionally, we assess the performance of PaLM 2 as a reranker and find it to significantly underperform G-RAG.","This result emphasizes the importance of reranking for RAG even when using Large Language Models."],"url":"http://arxiv.org/abs/2405.18414v1","category":"cs.CL"}
{"created":"2024-05-28 17:54:00","title":"The adhesive contact problem for a piecewise-homogeneous orthotropic plate with an elastic patch","abstract":"A piecewise-homogeneous elastic orthotropic plate, reinforced with a finite patch of the wedgeshaped, which meets the interface at a right angle and is loaded with tangential and normal forces is considered. By using methods of the theory of analytic functions, the problem is reduced to the system of singular integro-differential equations (SIDE) with fixed singularity. Under tension-compression of patch by using an integral transformation a Riemann problem is obtained, the solution of which is presented in explicit form. The tangential contact stresses along the contact line are determined and their asymptotic behavior in the neighborhood of singular points is established.","sentences":["A piecewise-homogeneous elastic orthotropic plate, reinforced with a finite patch of the wedgeshaped, which meets the interface at a right angle and is loaded with tangential and normal forces is considered.","By using methods of the theory of analytic functions, the problem is reduced to the system of singular integro-differential equations (SIDE) with fixed singularity.","Under tension-compression of patch by using an integral transformation a Riemann problem is obtained, the solution of which is presented in explicit form.","The tangential contact stresses along the contact line are determined and their asymptotic behavior in the neighborhood of singular points is established."],"url":"http://arxiv.org/abs/2405.18411v1","category":"math-ph"}
{"created":"2024-05-28 17:53:47","title":"Towards a Sampling Theory for Implicit Neural Representations","abstract":"Implicit neural representations (INRs) have emerged as a powerful tool for solving inverse problems in computer vision and computational imaging. INRs represent images as continuous domain functions realized by a neural network taking spatial coordinates as inputs. However, unlike traditional pixel representations, little is known about the sample complexity of estimating images using INRs in the context of linear inverse problems. Towards this end, we study the sampling requirements for recovery of a continuous domain image from its low-pass Fourier coefficients by fitting a single hidden-layer INR with ReLU activation and a Fourier features layer using a generalized form of weight decay regularization. Our key insight is to relate minimizers of this non-convex parameter space optimization problem to minimizers of a convex penalty defined over an infinite-dimensional space of measures. We identify a sufficient number of samples for which an image realized by a width-1 INR is exactly recoverable by solving the INR training problem, and give a conjecture for the general width-$W$ case. To validate our theory, we empirically assess the probability of achieving exact recovery of images realized by low-width single hidden-layer INRs, and illustrate the performance of INR on super-resolution recovery of more realistic continuous domain phantom images.","sentences":["Implicit neural representations (INRs) have emerged as a powerful tool for solving inverse problems in computer vision and computational imaging.","INRs represent images as continuous domain functions realized by a neural network taking spatial coordinates as inputs.","However, unlike traditional pixel representations, little is known about the sample complexity of estimating images using INRs in the context of linear inverse problems.","Towards this end, we study the sampling requirements for recovery of a continuous domain image from its low-pass Fourier coefficients by fitting a single hidden-layer INR with ReLU activation and a Fourier features layer using a generalized form of weight decay regularization.","Our key insight is to relate minimizers of this non-convex parameter space optimization problem to minimizers of a convex penalty defined over an infinite-dimensional space of measures.","We identify a sufficient number of samples for which an image realized by a width-1 INR is exactly recoverable by solving the INR training problem, and give a conjecture for the general width-$W$ case.","To validate our theory, we empirically assess the probability of achieving exact recovery of images realized by low-width single hidden-layer INRs, and illustrate the performance of INR on super-resolution recovery of more realistic continuous domain phantom images."],"url":"http://arxiv.org/abs/2405.18410v1","category":"eess.IV"}
{"created":"2024-05-28 17:43:16","title":"Explicit Formulae to Interchangeably use Hyperplanes and Hyperballs using Inversive Geometry","abstract":"Many algorithms require discriminative boundaries, such as separating hyperplanes or hyperballs, or are specifically designed to work on spherical data. By applying inversive geometry, we show that the two discriminative boundaries can be used interchangeably, and that general Euclidean data can be transformed into spherical data, whenever a change in point distances is acceptable. We provide explicit formulae to embed general Euclidean data into spherical data and to unembed it back. We further show a duality between hyperspherical caps, i.e., the volume created by a separating hyperplane on spherical data, and hyperballs and provide explicit formulae to map between the two. We further provide equations to translate inner products and Euclidean distances between the two spaces, to avoid explicit embedding and unembedding. We also provide a method to enforce projections of the general Euclidean space onto hemi-hyperspheres and propose an intrinsic dimensionality based method to obtain \"all-purpose\" parameters. To show the usefulness of the cap-ball-duality, we discuss example applications in machine learning and vector similarity search.","sentences":["Many algorithms require discriminative boundaries, such as separating hyperplanes or hyperballs, or are specifically designed to work on spherical data.","By applying inversive geometry, we show that the two discriminative boundaries can be used interchangeably, and that general Euclidean data can be transformed into spherical data, whenever a change in point distances is acceptable.","We provide explicit formulae to embed general Euclidean data into spherical data and to unembed it back.","We further show a duality between hyperspherical caps, i.e., the volume created by a separating hyperplane on spherical data, and hyperballs and provide explicit formulae to map between the two.","We further provide equations to translate inner products and Euclidean distances between the two spaces, to avoid explicit embedding and unembedding.","We also provide a method to enforce projections of the general Euclidean space onto hemi-hyperspheres and propose an intrinsic dimensionality based method to obtain \"all-purpose\" parameters.","To show the usefulness of the cap-ball-duality, we discuss example applications in machine learning and vector similarity search."],"url":"http://arxiv.org/abs/2405.18401v1","category":"cs.LG"}
{"created":"2024-05-28 17:29:51","title":"Global solutions to the Euler-Coriolis system","abstract":"We prove the global well-posedness and scattering for the 3D incompressible Euler-Coriolis system with sufficiently small, regular and suitably localized initial data. Equivalently, we obtain the asymptotic stability for \"rigid body\" rotational solutions to the pure Euler equations. This extends the recent work of Guo, Pausader and Widmayer to the general non-axisymmetric setting.","sentences":["We prove the global well-posedness and scattering for the 3D incompressible Euler-Coriolis system with sufficiently small, regular and suitably localized initial data.","Equivalently, we obtain the asymptotic stability for \"rigid body\" rotational solutions to the pure Euler equations.","This extends the recent work of Guo, Pausader and Widmayer to the general non-axisymmetric setting."],"url":"http://arxiv.org/abs/2405.18390v1","category":"math.AP"}
{"created":"2024-05-28 17:27:24","title":"A Review and Implementation of Object Detection Models and Optimizations for Real-time Medical Mask Detection during the COVID-19 Pandemic","abstract":"Convolutional Neural Networks (CNN) are commonly used for the problem of object detection thanks to their increased accuracy. Nevertheless, the performance of CNN-based detection models is ambiguous when detection speed is considered. To the best of our knowledge, there has not been sufficient evaluation of the available methods in terms of the speed/accuracy trade-off in related literature. This work assesses the most fundamental object detection models on the Common Objects in Context (COCO) dataset with respect to this trade-off, their memory consumption, and computational and storage cost. Next, we select a highly efficient model called YOLOv5 to train on the topical and unexplored dataset of human faces with medical masks, the Properly-Wearing Masked Faces Dataset (PWMFD), and analyze the benefits of specific optimization techniques for real-time medical mask detection: transfer learning, data augmentations, and a Squeeze-and-Excitation attention mechanism. Using our findings in the context of the COVID-19 pandemic, we propose an optimized model based on YOLOv5s using transfer learning for the detection of correctly and incorrectly worn medical masks that surpassed more than two times in speed (69 frames per second) the state-of-the-art model SE-YOLOv3 on the PWMFD dataset while maintaining the same level of mean Average Precision (67%).","sentences":["Convolutional Neural Networks (CNN) are commonly used for the problem of object detection thanks to their increased accuracy.","Nevertheless, the performance of CNN-based detection models is ambiguous when detection speed is considered.","To the best of our knowledge, there has not been sufficient evaluation of the available methods in terms of the speed/accuracy trade-off in related literature.","This work assesses the most fundamental object detection models on the Common Objects in Context (COCO) dataset with respect to this trade-off, their memory consumption, and computational and storage cost.","Next, we select a highly efficient model called YOLOv5 to train on the topical and unexplored dataset of human faces with medical masks, the Properly-Wearing Masked Faces Dataset (PWMFD), and analyze the benefits of specific optimization techniques for real-time medical mask detection: transfer learning, data augmentations, and a Squeeze-and-Excitation attention mechanism.","Using our findings in the context of the COVID-19 pandemic, we propose an optimized model based on YOLOv5s using transfer learning for the detection of correctly and incorrectly worn medical masks that surpassed more than two times in speed (69 frames per second) the state-of-the-art model SE-YOLOv3 on the PWMFD dataset while maintaining the same level of mean Average Precision (67%)."],"url":"http://arxiv.org/abs/2405.18387v1","category":"cs.CV"}
{"created":"2024-05-28 17:59:42","title":"Feasibility of Privacy-Preserving Entity Resolution on Confidential Healthcare Datasets Using Homomorphic Encryption","abstract":"Patient datasets contain confidential information which is protected by laws and regulations such as HIPAA and GDPR. Ensuring comprehensive patient information necessitates privacy-preserving entity resolution (PPER), which identifies identical patient entities across multiple databases from different healthcare organizations while maintaining data privacy. Existing methods often lack cryptographic security or are computationally impractical for real-world datasets. We introduce a PPER pipeline based on AMPPERE, a secure abstract computation model utilizing cryptographic tools like homomorphic encryption. Our tailored approach incorporates extensive parallelization techniques and optimal parameters specifically for patient datasets. Experimental results demonstrate the proposed method's effectiveness in terms of accuracy and efficiency compared to various baselines.","sentences":["Patient datasets contain confidential information which is protected by laws and regulations such as HIPAA and GDPR.","Ensuring comprehensive patient information necessitates privacy-preserving entity resolution (PPER), which identifies identical patient entities across multiple databases from different healthcare organizations while maintaining data privacy.","Existing methods often lack cryptographic security or are computationally impractical for real-world datasets.","We introduce a PPER pipeline based on AMPPERE, a secure abstract computation model utilizing cryptographic tools like homomorphic encryption.","Our tailored approach incorporates extensive parallelization techniques and optimal parameters specifically for patient datasets.","Experimental results demonstrate the proposed method's effectiveness in terms of accuracy and efficiency compared to various baselines."],"url":"http://arxiv.org/abs/2405.18430v1","category":"cs.CE"}
{"created":"2024-05-28 17:59:01","title":"3DitScene: Editing Any Scene via Language-guided Disentangled Gaussian Splatting","abstract":"Scene image editing is crucial for entertainment, photography, and advertising design. Existing methods solely focus on either 2D individual object or 3D global scene editing. This results in a lack of a unified approach to effectively control and manipulate scenes at the 3D level with different levels of granularity. In this work, we propose 3DitScene, a novel and unified scene editing framework leveraging language-guided disentangled Gaussian Splatting that enables seamless editing from 2D to 3D, allowing precise control over scene composition and individual objects. We first incorporate 3D Gaussians that are refined through generative priors and optimization techniques. Language features from CLIP then introduce semantics into 3D geometry for object disentanglement. With the disentangled Gaussians, 3DitScene allows for manipulation at both the global and individual levels, revolutionizing creative expression and empowering control over scenes and objects. Experimental results demonstrate the effectiveness and versatility of 3DitScene in scene image editing. Code and online demo can be found at our project homepage: https://zqh0253.github.io/3DitScene/.","sentences":["Scene image editing is crucial for entertainment, photography, and advertising design.","Existing methods solely focus on either 2D individual object or 3D global scene editing.","This results in a lack of a unified approach to effectively control and manipulate scenes at the 3D level with different levels of granularity.","In this work, we propose 3DitScene, a novel and unified scene editing framework leveraging language-guided disentangled Gaussian Splatting that enables seamless editing from 2D to 3D, allowing precise control over scene composition and individual objects.","We first incorporate 3D Gaussians that are refined through generative priors and optimization techniques.","Language features from CLIP then introduce semantics into 3D geometry for object disentanglement.","With the disentangled Gaussians, 3DitScene allows for manipulation at both the global and individual levels, revolutionizing creative expression and empowering control over scenes and objects.","Experimental results demonstrate the effectiveness and versatility of 3DitScene in scene image editing.","Code and online demo can be found at our project homepage: https://zqh0253.github.io/3DitScene/."],"url":"http://arxiv.org/abs/2405.18424v1","category":"cs.CV"}
{"created":"2024-05-28 17:58:46","title":"Bifurcations in Latch-Mediated Spring Actuation (LaMSA) Systems","abstract":"In nature, different species of smaller animals produce ultra-fast movements to aid in their locomotion or protect themselves against predators. These ultra-fast impulsive motions are possible, as often times, there exist a small latch in the organism that could hold the potential energy of the system, and once released, generate an impulsive motion. These types of systems are classified as Latch Mediated Spring Actuated (LaMSA) systems, a multi-dimensional, multi-mode hybrid system that switches between a latched and an unlatched state. The LaMSA mechanism has been studied extensively in the field of biology and is observed in a wide range of animal species, such as the mantis shrimp, grasshoppers, and trap-jaw ants. In recent years, research has been done in mathematically modeling the LaMSA behavior with physical implementations of the mechanism. A significant focus is given to mimicking the physiological behavior of the species and following an end-to-end trajectory of impulsive motion. This paper introduces a foundational analysis of the theoretical dynamics of the contact latch-based LaMSA mechanism. The authors answer the question on what makes these small-scale systems impulsive, with a focus on the intrinsic properties of the system using bifurcations. Necessary and sufficient conditions are derived for the existence of the saddle fixed points. The authors propose a mathematical explanation for mediating the latch when a saddle node exists, and the impulsive behavior after the bifurcation happens.","sentences":["In nature, different species of smaller animals produce ultra-fast movements to aid in their locomotion or protect themselves against predators.","These ultra-fast impulsive motions are possible, as often times, there exist a small latch in the organism that could hold the potential energy of the system, and once released, generate an impulsive motion.","These types of systems are classified as Latch Mediated Spring Actuated (LaMSA) systems, a multi-dimensional, multi-mode hybrid system that switches between a latched and an unlatched state.","The LaMSA mechanism has been studied extensively in the field of biology and is observed in a wide range of animal species, such as the mantis shrimp, grasshoppers, and trap-jaw ants.","In recent years, research has been done in mathematically modeling the LaMSA behavior with physical implementations of the mechanism.","A significant focus is given to mimicking the physiological behavior of the species and following an end-to-end trajectory of impulsive motion.","This paper introduces a foundational analysis of the theoretical dynamics of the contact latch-based LaMSA mechanism.","The authors answer the question on what makes these small-scale systems impulsive, with a focus on the intrinsic properties of the system using bifurcations.","Necessary and sufficient conditions are derived for the existence of the saddle fixed points.","The authors propose a mathematical explanation for mediating the latch when a saddle node exists, and the impulsive behavior after the bifurcation happens."],"url":"http://arxiv.org/abs/2405.18421v1","category":"eess.SY"}
{"created":"2024-05-28 17:57:12","title":"3D StreetUnveiler with Semantic-Aware 2DGS","abstract":"Unveiling an empty street from crowded observations captured by in-car cameras is crucial for autonomous driving. However, removing all temporary static objects, such as stopped vehicles and standing pedestrians, presents a significant challenge. Unlike object-centric 3D inpainting, which relies on thorough observation in a small scene, street scenes involve long trajectories that differ from previous 3D inpainting tasks. The camera-centric moving environment of captured videos further complicates the task due to the limited degree and time duration of object observation. To address these obstacles, we introduce StreetUnveiler to reconstruct an empty street. StreetUnveiler learns a 3D representation of the empty street from crowded observations. Our representation is based on the hard-label semantic 2D Gaussian Splatting (2DGS) for its scalability and ability to identify Gaussians to be removed. We inpaint rendered image after removing unwanted Gaussians to provide pseudo-labels and subsequently re-optimize the 2DGS. Given its temporal continuous movement, we divide the empty street scene into observed, partial-observed, and unobserved regions, which we propose to locate through a rendered alpha map. This decomposition helps us to minimize the regions that need to be inpainted. To enhance the temporal consistency of the inpainting, we introduce a novel time-reversal framework to inpaint frames in reverse order and use later frames as references for earlier frames to fully utilize the long-trajectory observations. Our experiments conducted on the street scene dataset successfully reconstructed a 3D representation of the empty street. The mesh representation of the empty street can be extracted for further applications. Project page and more visualizations can be found at: https://streetunveiler.github.io","sentences":["Unveiling an empty street from crowded observations captured by in-car cameras is crucial for autonomous driving.","However, removing all temporary static objects, such as stopped vehicles and standing pedestrians, presents a significant challenge.","Unlike object-centric 3D inpainting, which relies on thorough observation in a small scene, street scenes involve long trajectories that differ from previous 3D inpainting tasks.","The camera-centric moving environment of captured videos further complicates the task due to the limited degree and time duration of object observation.","To address these obstacles, we introduce StreetUnveiler to reconstruct an empty street.","StreetUnveiler learns a 3D representation of the empty street from crowded observations.","Our representation is based on the hard-label semantic 2D Gaussian Splatting (2DGS) for its scalability and ability to identify Gaussians to be removed.","We inpaint rendered image after removing unwanted Gaussians to provide pseudo-labels and subsequently re-optimize the 2DGS.","Given its temporal continuous movement, we divide the empty street scene into observed, partial-observed, and unobserved regions, which we propose to locate through a rendered alpha map.","This decomposition helps us to minimize the regions that need to be inpainted.","To enhance the temporal consistency of the inpainting, we introduce a novel time-reversal framework to inpaint frames in reverse order and use later frames as references for earlier frames to fully utilize the long-trajectory observations.","Our experiments conducted on the street scene dataset successfully reconstructed a 3D representation of the empty street.","The mesh representation of the empty street can be extracted for further applications.","Project page and more visualizations can be found at: https://streetunveiler.github.io"],"url":"http://arxiv.org/abs/2405.18416v1","category":"cs.CV"}
{"created":"2024-05-28 17:54:03","title":"Tensor Methods in High Dimensional Data Analysis: Opportunities and Challenges","abstract":"Large amount of multidimensional data represented by multiway arrays or tensors are prevalent in modern applications across various fields such as chemometrics, genomics, physics, psychology, and signal processing. The structural complexity of such data provides vast new opportunities for modeling and analysis, but efficiently extracting information content from them, both statistically and computationally, presents unique and fundamental challenges. Addressing these challenges requires an interdisciplinary approach that brings together tools and insights from statistics, optimization and numerical linear algebra among other fields. Despite these hurdles, significant progress has been made in the last decade. This review seeks to examine some of the key advancements and identify common threads among them, under eight different statistical settings.","sentences":["Large amount of multidimensional data represented by multiway arrays or tensors are prevalent in modern applications across various fields such as chemometrics, genomics, physics, psychology, and signal processing.","The structural complexity of such data provides vast new opportunities for modeling and analysis, but efficiently extracting information content from them, both statistically and computationally, presents unique and fundamental challenges.","Addressing these challenges requires an interdisciplinary approach that brings together tools and insights from statistics, optimization and numerical linear algebra among other fields.","Despite these hurdles, significant progress has been made in the last decade.","This review seeks to examine some of the key advancements and identify common threads among them, under eight different statistical settings."],"url":"http://arxiv.org/abs/2405.18412v1","category":"math.ST"}
{"created":"2024-05-28 17:45:07","title":"Distributed quantum multiparameter estimation with optimal local measurements","abstract":"We study the multiparameter sensitivity bounds of a sensor made by an array of $d$ spatially-distributed Mach-Zehnder interferometers (MZIs). A generic single non-classical state is mixed with $d-1$ vacuums to create a $d$-modes entangled state, each mode entering one input port of a MZI, while a coherent state enters its second port. We show that local measurements, independently performed on each MZI, are sufficient to provide a sensitivity saturating the quantum Cram\\'er-Rao bound. The sensor can overcome the shot noise limit for the estimation of arbitrary linear combinations of the $d$ phase shifts, provided that the non-classical probe state has an anti-squeezed quadrature variance. We compare the sensitivity bounds of this sensor with that achievable with $d$ independent MZIs, each probed with a nonclassical state and a coherent state. We find that the $d$ independent interferometers can achieve the same sensitivity of the entangled protocol but at the cost of using additional $d$ non-classical states rather than a single one. When using in the two protocols the same average number of particles per shot $\\bar{n}_T$, we find analytically a sensitivity scaling $1/\\bar{n}_T^2$ for the entangled case which provides a gain factor $d$ with respect to the separable case where the sensitivity scales as $d/\\bar{n}_T^2$. We have numerical evidences that the gain factor $d$ is also obtained when fixing the total average number of particles, namely when optimizing with respect to the number of repeated measurements.","sentences":["We study the multiparameter sensitivity bounds of a sensor made by an array of $d$ spatially-distributed Mach-Zehnder interferometers (MZIs).","A generic single non-classical state is mixed with $d-1$ vacuums to create a $d$-modes entangled state, each mode entering one input port of a MZI, while a coherent state enters its second port.","We show that local measurements, independently performed on each MZI, are sufficient to provide a sensitivity saturating the quantum Cram\\'er-Rao bound.","The sensor can overcome the shot noise limit for the estimation of arbitrary linear combinations of the $d$ phase shifts, provided that the non-classical probe state has an anti-squeezed quadrature variance.","We compare the sensitivity bounds of this sensor with that achievable with $d$ independent MZIs, each probed with a nonclassical state and a coherent state.","We find that the $d$ independent interferometers can achieve the same sensitivity of the entangled protocol but at the cost of using additional $d$ non-classical states rather than a single one.","When using in the two protocols the same average number of particles per shot $\\bar{n}_T$, we find analytically a sensitivity scaling $1/\\bar{n}_T^2$ for the entangled case which provides a gain factor $d$ with respect to the separable case where the sensitivity scales as $d/\\bar{n}_T^2$. We have numerical evidences that the gain factor $d$ is also obtained when fixing the total average number of particles, namely when optimizing with respect to the number of repeated measurements."],"url":"http://arxiv.org/abs/2405.18404v1","category":"quant-ph"}
{"created":"2024-05-28 17:44:48","title":"Batch VUV4 Characterization for the SBC-LAr10 scintillating bubble chamber","abstract":"The Scintillating Bubble Chamber (SBC) collaboration purchased 32 Hamamatsu VUV4 silicon photomultipliers (SiPMs) for use in SBC-LAr10, a bubble chamber containing 10~kg of liquid argon. The VUV4 SiPMs, or Quads, underwent a characterization at two temperatures which measured the breakdown voltage ($V_{\\text{BD}}$), the SiPM gain ($g_{\\text{SiPM}}$), the rate of change of $g_{\\text{SiPM}}$ with respect to voltage ($m$), the dark count rate (DCR), and the probability of a correlated avalanche (P$_{\\text{CA}}$) as well as the temperature coefficients of these parameters. A Peltier-based chilled vacuum chamber was developed at Queen's University to cool down the Quads to $233.15\\pm0.2$~K and $255.15\\pm0.2$~K with average stability of $\\pm20$~mK. A mostly assumption-free analysis was derived to estimate $V_{\\text{BD}}$ to tens of mV precision and DCR close to Poissonian error. The temperature dependence of $V_{\\text{BD}}$ was found to be $56\\pm2$~mV~K$^{-1}$, and $m$ on average across all Quads was found to be $(459\\pm3(\\rm{stat.})\\pm23(\\rm{sys.}))\\times 10^{3}~e^-$~PE$^{-1}$~V$^{-1}$. The average DCR temperature coefficient was estimated to be $0.099\\pm0.008$~K$^{-1}$ corresponding to a reduction factor of 7 for every 20~K drop in temperature. The average temperature dependence of P$_{\\text{CA}}$ was estimated to be $4000\\pm1000$~ppm~K$^{-1}$. P$_{\\text{CA}}$ estimated from the average across all SiPMs is a better estimator than the P$_{\\text{CA}}$ calculated from individual SiPMs, whereas all of the other parameters, the opposite is true. All the estimated parameters were measured to the precision required for SBC-LAr10, and the Quads will be used in conditions to optimize the signal-to-noise ratio.","sentences":["The Scintillating Bubble Chamber (SBC) collaboration purchased 32 Hamamatsu VUV4 silicon photomultipliers (SiPMs) for use in SBC-LAr10, a bubble chamber containing 10~kg of liquid argon.","The VUV4 SiPMs, or Quads, underwent a characterization at two temperatures which measured the breakdown voltage ($V_{\\text{BD}}$), the SiPM gain ($g_{\\text{SiPM}}$), the rate of change of $g_{\\text{SiPM}}$ with respect to voltage ($m$), the dark count rate (DCR), and the probability of a correlated avalanche (P$_{\\text{CA}}$) as well as the temperature coefficients of these parameters.","A Peltier-based chilled vacuum chamber was developed at Queen's University to cool down the Quads to $233.15\\pm0.2$~K and $255.15\\pm0.2$~K with average stability of $\\pm20$~mK. A mostly assumption-free analysis was derived to estimate $V_{\\text{BD}}$ to tens of mV precision and DCR close to Poissonian error.","The temperature dependence of $V_{\\text{BD}}$ was found to be $56\\pm2$~mV~K$^{-1}$, and $m$ on average across all Quads was found to be $(459\\pm3(\\rm{stat.})\\pm23(\\rm{sys.}))\\times 10^{3}~e^-$~PE$^{-1}$~V$^{-1}$. The average DCR temperature coefficient was estimated to be $0.099\\pm0.008$~K$^{-1}$ corresponding to a reduction factor of 7 for every 20~K drop in temperature.","The average temperature dependence of P$_{\\text{CA}}$ was estimated to be $4000\\pm1000$~ppm~K$^{-1}$. P$_{\\text{CA}}$ estimated from the average across all SiPMs is a better estimator than the P$_{\\text{CA}}$ calculated from individual SiPMs, whereas all of the other parameters, the opposite is true.","All the estimated parameters were measured to the precision required for SBC-LAr10, and the Quads will be used in conditions to optimize the signal-to-noise ratio."],"url":"http://arxiv.org/abs/2405.18403v1","category":"physics.ins-det"}
{"created":"2024-05-28 17:36:11","title":"What can machine learning help with microstructure-informed materials modeling and design?","abstract":"Machine learning techniques have been widely employed as effective tools in addressing various engineering challenges in recent years, particularly for the challenging task of microstructure-informed materials modeling. This work provides a comprehensive review of the current machine learning-assisted and data-driven advancements in this field, including microstructure characterization and reconstruction, multiscale simulation, correlations among process, microstructure, and properties, as well as microstructure optimization and inverse design. It outlines the achievements of existing research through best practices and suggests potential avenues for future investigations. Moreover, it prepares the readers with educative instructions of basic knowledge and an overview on machine learning, microstructure descriptors and machine learning-assisted material modeling, lowering the interdisciplinary hurdles. It should help to stimulate and attract more research attention to the rapidly growing field of machine learning-based modeling and design of microstructured materials.","sentences":["Machine learning techniques have been widely employed as effective tools in addressing various engineering challenges in recent years, particularly for the challenging task of microstructure-informed materials modeling.","This work provides a comprehensive review of the current machine learning-assisted and data-driven advancements in this field, including microstructure characterization and reconstruction, multiscale simulation, correlations among process, microstructure, and properties, as well as microstructure optimization and inverse design.","It outlines the achievements of existing research through best practices and suggests potential avenues for future investigations.","Moreover, it prepares the readers with educative instructions of basic knowledge and an overview on machine learning, microstructure descriptors and machine learning-assisted material modeling, lowering the interdisciplinary hurdles.","It should help to stimulate and attract more research attention to the rapidly growing field of machine learning-based modeling and design of microstructured materials."],"url":"http://arxiv.org/abs/2405.18396v1","category":"cond-mat.mtrl-sci"}
{"created":"2024-05-28 17:35:05","title":"MC-GTA: Metric-Constrained Model-Based Clustering using Goodness-of-fit Tests with Autocorrelations","abstract":"A wide range of (multivariate) temporal (1D) and spatial (2D) data analysis tasks, such as grouping vehicle sensor trajectories, can be formulated as clustering with given metric constraints. Existing metric-constrained clustering algorithms overlook the rich correlation between feature similarity and metric distance, i.e., metric autocorrelation. The model-based variations of these clustering algorithms (e.g. TICC and STICC) achieve SOTA performance, yet suffer from computational instability and complexity by using a metric-constrained Expectation-Maximization procedure. In order to address these two problems, we propose a novel clustering algorithm, MC-GTA (Model-based Clustering via Goodness-of-fit Tests with Autocorrelations). Its objective is only composed of pairwise weighted sums of feature similarity terms (square Wasserstein-2 distance) and metric autocorrelation terms (a novel multivariate generalization of classic semivariogram). We show that MC-GTA is effectively minimizing the total hinge loss for intra-cluster observation pairs not passing goodness-of-fit tests, i.e., statistically not originating from the same distribution. Experiments on 1D/2D synthetic and real-world datasets demonstrate that MC-GTA successfully incorporates metric autocorrelation. It outperforms strong baselines by large margins (up to 14.3% in ARI and 32.1% in NMI) with faster and stabler optimization (>10x speedup).","sentences":["A wide range of (multivariate) temporal (1D) and spatial (2D) data analysis tasks, such as grouping vehicle sensor trajectories, can be formulated as clustering with given metric constraints.","Existing metric-constrained clustering algorithms overlook the rich correlation between feature similarity and metric distance, i.e., metric autocorrelation.","The model-based variations of these clustering algorithms (e.g. TICC and STICC) achieve SOTA performance, yet suffer from computational instability and complexity by using a metric-constrained Expectation-Maximization procedure.","In order to address these two problems, we propose a novel clustering algorithm, MC-GTA (Model-based Clustering via Goodness-of-fit Tests with Autocorrelations).","Its objective is only composed of pairwise weighted sums of feature similarity terms (square Wasserstein-2 distance) and metric autocorrelation terms (a novel multivariate generalization of classic semivariogram).","We show that MC-GTA is effectively minimizing the total hinge loss for intra-cluster observation pairs not passing goodness-of-fit tests, i.e., statistically not originating from the same distribution.","Experiments on 1D/2D synthetic and real-world datasets demonstrate that MC-GTA successfully incorporates metric autocorrelation.","It outperforms strong baselines by large margins (up to 14.3% in ARI and 32.1% in NMI) with faster and stabler optimization (>10x speedup)."],"url":"http://arxiv.org/abs/2405.18395v1","category":"cs.LG"}
{"created":"2024-05-28 17:33:54","title":"Scaling Laws and Compute-Optimal Training Beyond Fixed Training Durations","abstract":"Scale has become a main ingredient in obtaining strong machine learning models. As a result, understanding a model's scaling properties is key to effectively designing both the right training setup as well as future generations of architectures. In this work, we argue that scale and training research has been needlessly complex due to reliance on the cosine schedule, which prevents training across different lengths for the same model size. We investigate the training behavior of a direct alternative - constant learning rate and cooldowns - and find that it scales predictably and reliably similar to cosine. Additionally, we show that stochastic weight averaging yields improved performance along the training trajectory, without additional training costs, across different scales. Importantly, with these findings we demonstrate that scaling experiments can be performed with significantly reduced compute and GPU hours by utilizing fewer but reusable training runs. Our code is available at https://github.com/epfml/schedules-and-scaling.","sentences":["Scale has become a main ingredient in obtaining strong machine learning models.","As a result, understanding a model's scaling properties is key to effectively designing both the right training setup as well as future generations of architectures.","In this work, we argue that scale and training research has been needlessly complex due to reliance on the cosine schedule, which prevents training across different lengths for the same model size.","We investigate the training behavior of a direct alternative - constant learning rate and cooldowns - and find that it scales predictably and reliably similar to cosine.","Additionally, we show that stochastic weight averaging yields improved performance along the training trajectory, without additional training costs, across different scales.","Importantly, with these findings we demonstrate that scaling experiments can be performed with significantly reduced compute and GPU hours by utilizing fewer but reusable training runs.","Our code is available at https://github.com/epfml/schedules-and-scaling."],"url":"http://arxiv.org/abs/2405.18392v2","category":"cs.LG"}
