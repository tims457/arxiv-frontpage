{"created":"2024-01-18 18:59:58","title":"ParaHome: Parameterizing Everyday Home Activities Towards 3D Generative Modeling of Human-Object Interactions","abstract":"To enable machines to learn how humans interact with the physical world in our daily activities, it is crucial to provide rich data that encompasses the 3D motion of humans as well as the motion of objects in a learnable 3D representation. Ideally, this data should be collected in a natural setup, capturing the authentic dynamic 3D signals during human-object interactions. To address this challenge, we introduce the ParaHome system, designed to capture and parameterize dynamic 3D movements of humans and objects within a common home environment. Our system consists of a multi-view setup with 70 synchronized RGB cameras, as well as wearable motion capture devices equipped with an IMU-based body suit and hand motion capture gloves. By leveraging the ParaHome system, we collect a novel large-scale dataset of human-object interaction. Notably, our dataset offers key advancement over existing datasets in three main aspects: (1) capturing 3D body and dexterous hand manipulation motion alongside 3D object movement within a contextual home environment during natural activities; (2) encompassing human interaction with multiple objects in various episodic scenarios with corresponding descriptions in texts; (3) including articulated objects with multiple parts expressed with parameterized articulations. Building upon our dataset, we introduce new research tasks aimed at building a generative model for learning and synthesizing human-object interactions in a real-world room setting.","sentences":["To enable machines to learn how humans interact with the physical world in our daily activities, it is crucial to provide rich data that encompasses the 3D motion of humans as well as the motion of objects in a learnable 3D representation.","Ideally, this data should be collected in a natural setup, capturing the authentic dynamic 3D signals during human-object interactions.","To address this challenge, we introduce the ParaHome system, designed to capture and parameterize dynamic 3D movements of humans and objects within a common home environment.","Our system consists of a multi-view setup with 70 synchronized RGB cameras, as well as wearable motion capture devices equipped with an IMU-based body suit and hand motion capture gloves.","By leveraging the ParaHome system, we collect a novel large-scale dataset of human-object interaction.","Notably, our dataset offers key advancement over existing datasets in three main aspects: (1) capturing 3D body and dexterous hand manipulation motion alongside 3D object movement within a contextual home environment during natural activities; (2) encompassing human interaction with multiple objects in various episodic scenarios with corresponding descriptions in texts; (3) including articulated objects with multiple parts expressed with parameterized articulations.","Building upon our dataset, we introduce new research tasks aimed at building a generative model for learning and synthesizing human-object interactions in a real-world room setting."],"url":"http://arxiv.org/abs/2401.10232v1","category":"cs.CV"}
{"created":"2024-01-18 18:59:35","title":"Simultaneous Tactile Estimation and Control for Extrinsic Dexterity","abstract":"We introduce a novel approach that combines tactile estimation and control for in-hand object manipulation. By integrating measurements from robot kinematics and an image-based tactile sensor, our framework estimates and tracks object pose while simultaneously generating motion plans to control the pose of a grasped object. This approach consists of a discrete pose estimator that uses the Viterbi decoding algorithm to find the most likely sequence of object poses in a coarsely discretized grid, and a continuous pose estimator-controller to refine the pose estimate and accurately manipulate the pose of the grasped object. Our method is tested on diverse objects and configurations, achieving desired manipulation objectives and outperforming single-shot methods in estimation accuracy. The proposed approach holds potential for tasks requiring precise manipulation in scenarios where visual perception is limited, laying the foundation for closed-loop behavior applications such as assembly and tool use. Please see supplementary videos for real-world demonstration at https://sites.google.com/view/texterity.","sentences":["We introduce a novel approach that combines tactile estimation and control for in-hand object manipulation.","By integrating measurements from robot kinematics and an image-based tactile sensor, our framework estimates and tracks object pose while simultaneously generating motion plans to control the pose of a grasped object.","This approach consists of a discrete pose estimator that uses the Viterbi decoding algorithm to find the most likely sequence of object poses in a coarsely discretized grid, and a continuous pose estimator-controller to refine the pose estimate and accurately manipulate the pose of the grasped object.","Our method is tested on diverse objects and configurations, achieving desired manipulation objectives and outperforming single-shot methods in estimation accuracy.","The proposed approach holds potential for tasks requiring precise manipulation in scenarios where visual perception is limited, laying the foundation for closed-loop behavior applications such as assembly and tool use.","Please see supplementary videos for real-world demonstration at https://sites.google.com/view/texterity."],"url":"http://arxiv.org/abs/2401.10230v1","category":"cs.RO"}
{"created":"2024-01-18 18:59:34","title":"OMG-Seg: Is One Model Good Enough For All Segmentation?","abstract":"In this work, we address various segmentation tasks, each traditionally tackled by distinct or partially unified models. We propose OMG-Seg, One Model that is Good enough to efficiently and effectively handle all the segmentation tasks, including image semantic, instance, and panoptic segmentation, as well as their video counterparts, open vocabulary settings, prompt-driven, interactive segmentation like SAM, and video object segmentation. To our knowledge, this is the first model to handle all these tasks in one model and achieve satisfactory performance. We show that OMG-Seg, a transformer-based encoder-decoder architecture with task-specific queries and outputs, can support over ten distinct segmentation tasks and yet significantly reduce computational and parameter overhead across various tasks and datasets. We rigorously evaluate the inter-task influences and correlations during co-training. Code and models are available at https://github.com/lxtGH/OMG-Seg.","sentences":["In this work, we address various segmentation tasks, each traditionally tackled by distinct or partially unified models.","We propose OMG-Seg, One Model that is Good enough to efficiently and effectively handle all the segmentation tasks, including image semantic, instance, and panoptic segmentation, as well as their video counterparts, open vocabulary settings, prompt-driven, interactive segmentation like SAM, and video object segmentation.","To our knowledge, this is the first model to handle all these tasks in one model and achieve satisfactory performance.","We show that OMG-Seg, a transformer-based encoder-decoder architecture with task-specific queries and outputs, can support over ten distinct segmentation tasks and yet significantly reduce computational and parameter overhead across various tasks and datasets.","We rigorously evaluate the inter-task influences and correlations during co-training.","Code and models are available at https://github.com/lxtGH/OMG-Seg."],"url":"http://arxiv.org/abs/2401.10229v1","category":"cs.CV"}
{"created":"2024-01-18 18:59:30","title":"RAP-SAM: Towards Real-Time All-Purpose Segment Anything","abstract":"Advanced by transformer architecture, vision foundation models (VFMs) achieve remarkable progress in performance and generalization ability. Segment Anything Model (SAM) is one remarkable model that can achieve generalized segmentation. However, most VFMs cannot run in realtime, which makes it difficult to transfer them into several products. On the other hand, current real-time segmentation mainly has one purpose, such as semantic segmentation on the driving scene. We argue that diverse outputs are needed for real applications. Thus, this work explores a new real-time segmentation setting, named all-purpose segmentation in real-time, to transfer VFMs in real-time deployment. It contains three different tasks, including interactive segmentation, panoptic segmentation, and video segmentation. We aim to use one model to achieve the above tasks in real-time. We first benchmark several strong baselines. Then, we present Real-Time All Purpose SAM (RAP-SAM). It contains an efficient encoder and an efficient decoupled decoder to perform prompt-driven decoding. Moreover, we further explore different training strategies and tuning methods to boost co-training performance further. Our code and model are available at https://github.com/xushilin1/RAP-SAM/.","sentences":["Advanced by transformer architecture, vision foundation models (VFMs) achieve remarkable progress in performance and generalization ability.","Segment Anything Model (SAM) is one remarkable model that can achieve generalized segmentation.","However, most VFMs cannot run in realtime, which makes it difficult to transfer them into several products.","On the other hand, current real-time segmentation mainly has one purpose, such as semantic segmentation on the driving scene.","We argue that diverse outputs are needed for real applications.","Thus, this work explores a new real-time segmentation setting, named all-purpose segmentation in real-time, to transfer VFMs in real-time deployment.","It contains three different tasks, including interactive segmentation, panoptic segmentation, and video segmentation.","We aim to use one model to achieve the above tasks in real-time.","We first benchmark several strong baselines.","Then, we present Real-Time All Purpose SAM (RAP-SAM).","It contains an efficient encoder and an efficient decoupled decoder to perform prompt-driven decoding.","Moreover, we further explore different training strategies and tuning methods to boost co-training performance further.","Our code and model are available at https://github.com/xushilin1/RAP-SAM/."],"url":"http://arxiv.org/abs/2401.10228v1","category":"cs.CV"}
{"created":"2024-01-18 18:59:13","title":"Towards Language-Driven Video Inpainting via Multimodal Large Language Models","abstract":"We introduce a new task -- language-driven video inpainting, which uses natural language instructions to guide the inpainting process. This approach overcomes the limitations of traditional video inpainting methods that depend on manually labeled binary masks, a process often tedious and labor-intensive. We present the Remove Objects from Videos by Instructions (ROVI) dataset, containing 5,650 videos and 9,091 inpainting results, to support training and evaluation for this task. We also propose a novel diffusion-based language-driven video inpainting framework, the first end-to-end baseline for this task, integrating Multimodal Large Language Models to understand and execute complex language-based inpainting requests effectively. Our comprehensive results showcase the dataset's versatility and the model's effectiveness in various language-instructed inpainting scenarios. We will make datasets, code, and models publicly available.","sentences":["We introduce a new task -- language-driven video inpainting, which uses natural language instructions to guide the inpainting process.","This approach overcomes the limitations of traditional video inpainting methods that depend on manually labeled binary masks, a process often tedious and labor-intensive.","We present the Remove Objects from Videos by Instructions (ROVI) dataset, containing 5,650 videos and 9,091 inpainting results, to support training and evaluation for this task.","We also propose a novel diffusion-based language-driven video inpainting framework, the first end-to-end baseline for this task, integrating Multimodal Large Language Models to understand and execute complex language-based inpainting requests effectively.","Our comprehensive results showcase the dataset's versatility and the model's effectiveness in various language-instructed inpainting scenarios.","We will make datasets, code, and models publicly available."],"url":"http://arxiv.org/abs/2401.10226v1","category":"cs.CV"}
{"created":"2024-01-18 18:59:09","title":"The Manga Whisperer: Automatically Generating Transcriptions for Comics","abstract":"In the past few decades, Japanese comics, commonly referred to as Manga, have transcended both cultural and linguistic boundaries to become a true worldwide sensation. Yet, the inherent reliance on visual cues and illustration within manga renders it largely inaccessible to individuals with visual impairments. In this work, we seek to address this substantial barrier, with the aim of ensuring that manga can be appreciated and actively engaged by everyone. Specifically, we tackle the problem of diarisation i.e. generating a transcription of who said what and when, in a fully automatic way.   To this end, we make the following contributions: (1) we present a unified model, Magi, that is able to (a) detect panels, text boxes and character boxes, (b) cluster characters by identity (without knowing the number of clusters apriori), and (c) associate dialogues to their speakers; (2) we propose a novel approach that is able to sort the detected text boxes in their reading order and generate a dialogue transcript; (3) we annotate an evaluation benchmark for this task using publicly available [English] manga pages. The code, evaluation datasets and the pre-trained model can be found at: https://github.com/ragavsachdeva/magi.","sentences":["In the past few decades, Japanese comics, commonly referred to as Manga, have transcended both cultural and linguistic boundaries to become a true worldwide sensation.","Yet, the inherent reliance on visual cues and illustration within manga renders it largely inaccessible to individuals with visual impairments.","In this work, we seek to address this substantial barrier, with the aim of ensuring that manga can be appreciated and actively engaged by everyone.","Specifically, we tackle the problem of diarisation i.e. generating a transcription of who said what and when, in a fully automatic way.   ","To this end, we make the following contributions: (1) we present a unified model, Magi, that is able to (a) detect panels, text boxes and character boxes, (b) cluster characters by identity (without knowing the number of clusters apriori), and (c) associate dialogues to their speakers; (2) we propose a novel approach that is able to sort the detected text boxes in their reading order and generate a dialogue transcript; (3) we annotate an evaluation benchmark for this task using publicly available [English] manga pages.","The code, evaluation datasets and the pre-trained model can be found at: https://github.com/ragavsachdeva/magi."],"url":"http://arxiv.org/abs/2401.10224v1","category":"cs.CV"}
{"created":"2024-01-18 18:58:44","title":"Edit One for All: Interactive Batch Image Editing","abstract":"In recent years, image editing has advanced remarkably. With increased human control, it is now possible to edit an image in a plethora of ways; from specifying in text what we want to change, to straight up dragging the contents of the image in an interactive point-based manner. However, most of the focus has remained on editing single images at a time. Whether and how we can simultaneously edit large batches of images has remained understudied. With the goal of minimizing human supervision in the editing process, this paper presents a novel method for interactive batch image editing using StyleGAN as the medium. Given an edit specified by users in an example image (e.g., make the face frontal), our method can automatically transfer that edit to other test images, so that regardless of their initial state (pose), they all arrive at the same final state (e.g., all facing front). Extensive experiments demonstrate that edits performed using our method have similar visual quality to existing single-image-editing methods, while having more visual consistency and saving significant time and human effort.","sentences":["In recent years, image editing has advanced remarkably.","With increased human control, it is now possible to edit an image in a plethora of ways; from specifying in text what we want to change, to straight up dragging the contents of the image in an interactive point-based manner.","However, most of the focus has remained on editing single images at a time.","Whether and how we can simultaneously edit large batches of images has remained understudied.","With the goal of minimizing human supervision in the editing process, this paper presents a novel method for interactive batch image editing using StyleGAN as the medium.","Given an edit specified by users in an example image (e.g., make the face frontal), our method can automatically transfer that edit to other test images, so that regardless of their initial state (pose), they all arrive at the same final state (e.g., all facing front).","Extensive experiments demonstrate that edits performed using our method have similar visual quality to existing single-image-editing methods, while having more visual consistency and saving significant time and human effort."],"url":"http://arxiv.org/abs/2401.10219v1","category":"cs.CV"}
{"created":"2024-01-18 18:57:40","title":"Explaining the Implicit Neural Canvas: Connecting Pixels to Neurons by Tracing their Contributions","abstract":"The many variations of Implicit Neural Representations (INRs), where a neural network is trained as a continuous representation of a signal, have tremendous practical utility for downstream tasks including novel view synthesis, video compression, and image superresolution. Unfortunately, the inner workings of these networks are seriously under-studied. Our work, eXplaining the Implicit Neural Canvas (XINC), is a unified framework for explaining properties of INRs by examining the strength of each neuron's contribution to each output pixel. We call the aggregate of these contribution maps the Implicit Neural Canvas and we use this concept to demonstrate that the INRs which we study learn to ''see'' the frames they represent in surprising ways. For example, INRs tend to have highly distributed representations. While lacking high-level object semantics, they have a significant bias for color and edges, and are almost entirely space-agnostic. We arrive at our conclusions by examining how objects are represented across time in video INRs, using clustering to visualize similar neurons across layers and architectures, and show that this is dominated by motion. These insights demonstrate the general usefulness of our analysis framework. Our project page is available at https://namithap10.github.io/xinc.","sentences":["The many variations of Implicit Neural Representations (INRs), where a neural network is trained as a continuous representation of a signal, have tremendous practical utility for downstream tasks including novel view synthesis, video compression, and image superresolution.","Unfortunately, the inner workings of these networks are seriously under-studied.","Our work, eXplaining the Implicit Neural Canvas (XINC), is a unified framework for explaining properties of INRs by examining the strength of each neuron's contribution to each output pixel.","We call the aggregate of these contribution maps the Implicit Neural Canvas and we use this concept to demonstrate that the INRs which we study learn to ''see'' the frames they represent in surprising ways.","For example, INRs tend to have highly distributed representations.","While lacking high-level object semantics, they have a significant bias for color and edges, and are almost entirely space-agnostic.","We arrive at our conclusions by examining how objects are represented across time in video INRs, using clustering to visualize similar neurons across layers and architectures, and show that this is dominated by motion.","These insights demonstrate the general usefulness of our analysis framework.","Our project page is available at https://namithap10.github.io/xinc."],"url":"http://arxiv.org/abs/2401.10217v1","category":"cs.CV"}
{"created":"2024-01-18 18:57:10","title":"Enabling Efficient Equivariant Operations in the Fourier Basis via Gaunt Tensor Products","abstract":"Developing equivariant neural networks for the E(3) group plays an important role in modeling 3D data across real-world applications. Enforcing this equivariance primarily involves the tensor products of irreducible representations (irreps). However, the computational complexity of such operations increases significantly as higher-order tensors are used. In this work, we propose a systematic approach to substantially accelerate the computation of the tensor products of irreps. We mathematically connect the commonly used Clebsch-Gordan coefficients to the Gaunt coefficients, which are integrals of products of three spherical harmonics. Through Gaunt coefficients, the tensor product of irreps becomes equivalent to the multiplication between spherical functions represented by spherical harmonics. This perspective further allows us to change the basis for the equivariant operations from spherical harmonics to a 2D Fourier basis. Consequently, the multiplication between spherical functions represented by a 2D Fourier basis can be efficiently computed via the convolution theorem and Fast Fourier Transforms. This transformation reduces the complexity of full tensor products of irreps from $\\mathcal{O}(L^6)$ to $\\mathcal{O}(L^3)$, where $L$ is the max degree of irreps. Leveraging this approach, we introduce the Gaunt Tensor Product, which serves as a new method to construct efficient equivariant operations across different model architectures. Our experiments on the Open Catalyst Project and 3BPA datasets demonstrate both the increased efficiency and improved performance of our approach.","sentences":["Developing equivariant neural networks for the E(3) group plays an important role in modeling 3D data across real-world applications.","Enforcing this equivariance primarily involves the tensor products of irreducible representations (irreps).","However, the computational complexity of such operations increases significantly as higher-order tensors are used.","In this work, we propose a systematic approach to substantially accelerate the computation of the tensor products of irreps.","We mathematically connect the commonly used Clebsch-Gordan coefficients to the Gaunt coefficients, which are integrals of products of three spherical harmonics.","Through Gaunt coefficients, the tensor product of irreps becomes equivalent to the multiplication between spherical functions represented by spherical harmonics.","This perspective further allows us to change the basis for the equivariant operations from spherical harmonics to a 2D Fourier basis.","Consequently, the multiplication between spherical functions represented by a 2D Fourier basis can be efficiently computed via the convolution theorem and Fast Fourier Transforms.","This transformation reduces the complexity of full tensor products of irreps from $\\mathcal{O}(L^6)$ to $\\mathcal{O}(L^3)$, where $L$ is the max degree of irreps.","Leveraging this approach, we introduce the Gaunt Tensor Product, which serves as a new method to construct efficient equivariant operations across different model architectures.","Our experiments on the Open Catalyst Project and 3BPA datasets demonstrate both the increased efficiency and improved performance of our approach."],"url":"http://arxiv.org/abs/2401.10216v1","category":"cs.LG"}
{"created":"2024-01-18 18:56:34","title":"GPAvatar: Generalizable and Precise Head Avatar from Image(s)","abstract":"Head avatar reconstruction, crucial for applications in virtual reality, online meetings, gaming, and film industries, has garnered substantial attention within the computer vision community. The fundamental objective of this field is to faithfully recreate the head avatar and precisely control expressions and postures. Existing methods, categorized into 2D-based warping, mesh-based, and neural rendering approaches, present challenges in maintaining multi-view consistency, incorporating non-facial information, and generalizing to new identities. In this paper, we propose a framework named GPAvatar that reconstructs 3D head avatars from one or several images in a single forward pass. The key idea of this work is to introduce a dynamic point-based expression field driven by a point cloud to precisely and effectively capture expressions. Furthermore, we use a Multi Tri-planes Attention (MTA) fusion module in the tri-planes canonical field to leverage information from multiple input images. The proposed method achieves faithful identity reconstruction, precise expression control, and multi-view consistency, demonstrating promising results for free-viewpoint rendering and novel view synthesis.","sentences":["Head avatar reconstruction, crucial for applications in virtual reality, online meetings, gaming, and film industries, has garnered substantial attention within the computer vision community.","The fundamental objective of this field is to faithfully recreate the head avatar and precisely control expressions and postures.","Existing methods, categorized into 2D-based warping, mesh-based, and neural rendering approaches, present challenges in maintaining multi-view consistency, incorporating non-facial information, and generalizing to new identities.","In this paper, we propose a framework named GPAvatar that reconstructs 3D head avatars from one or several images in a single forward pass.","The key idea of this work is to introduce a dynamic point-based expression field driven by a point cloud to precisely and effectively capture expressions.","Furthermore, we use a Multi Tri-planes Attention (MTA) fusion module in the tri-planes canonical field to leverage information from multiple input images.","The proposed method achieves faithful identity reconstruction, precise expression control, and multi-view consistency, demonstrating promising results for free-viewpoint rendering and novel view synthesis."],"url":"http://arxiv.org/abs/2401.10215v1","category":"cs.CV"}
{"created":"2024-01-18 18:55:27","title":"Tailoring Semantic Communication at Network Edge: A Novel Approach Using Dynamic Knowledge Distillation","abstract":"Semantic Communication (SemCom) systems, empowered by deep learning (DL), represent a paradigm shift in data transmission. These systems prioritize the significance of content over sheer data volume. However, existing SemCom designs face challenges when applied to diverse computational capabilities and network conditions, particularly in time-sensitive applications. A key challenge is the assumption that diverse devices can uniformly benefit from a standard, large DL model in SemCom systems. This assumption becomes increasingly impractical, especially in high-speed, high-reliability applications such as industrial automation or critical healthcare. Therefore, this paper introduces a novel SemCom framework tailored for heterogeneous, resource-constrained edge devices and computation-intensive servers. Our approach employs dynamic knowledge distillation (KD) to customize semantic models for each device, balancing computational and communication constraints while ensuring Quality of Service (QoS). We formulate an optimization problem and develop an adaptive algorithm that iteratively refines semantic knowledge on edge devices, resulting in better models tailored to their resource profiles. This algorithm strategically adjusts the granularity of distilled knowledge, enabling devices to maintain high semantic accuracy for precise inference tasks, even under unstable network conditions. Extensive simulations demonstrate that our approach significantly reduces model complexity for edge devices, leading to better semantic extraction and achieving the desired QoS.","sentences":["Semantic Communication (SemCom) systems, empowered by deep learning (DL), represent a paradigm shift in data transmission.","These systems prioritize the significance of content over sheer data volume.","However, existing SemCom designs face challenges when applied to diverse computational capabilities and network conditions, particularly in time-sensitive applications.","A key challenge is the assumption that diverse devices can uniformly benefit from a standard, large DL model in SemCom systems.","This assumption becomes increasingly impractical, especially in high-speed, high-reliability applications such as industrial automation or critical healthcare.","Therefore, this paper introduces a novel SemCom framework tailored for heterogeneous, resource-constrained edge devices and computation-intensive servers.","Our approach employs dynamic knowledge distillation (KD) to customize semantic models for each device, balancing computational and communication constraints while ensuring Quality of Service (QoS).","We formulate an optimization problem and develop an adaptive algorithm that iteratively refines semantic knowledge on edge devices, resulting in better models tailored to their resource profiles.","This algorithm strategically adjusts the granularity of distilled knowledge, enabling devices to maintain high semantic accuracy for precise inference tasks, even under unstable network conditions.","Extensive simulations demonstrate that our approach significantly reduces model complexity for edge devices, leading to better semantic extraction and achieving the desired QoS."],"url":"http://arxiv.org/abs/2401.10214v1","category":"cs.NI"}
{"created":"2024-01-18 18:55:06","title":"Non-perturbative Wavefunction of the Universe in Inflation with (Resonant) Features","abstract":"We study the statistics of scalar perturbations in models of inflation with small and rapid oscillations in the inflaton potential (resonant non-Gaussianity). We do so by deriving the wavefunction $\\Psi[\\zeta(\\boldsymbol{x})]$ non-perturbatively in $\\zeta$, but at first order in the amplitude of the oscillations. The expression of the wavefunction of the universe (WFU) is explicit and does not require solving partial differential equations. One finds qualitative deviations from perturbation theory for $ |\\zeta| \\gtrsim \\alpha^{-2}$, where $\\alpha \\gg 1$ is the number of oscillations per Hubble time. Notably, the WFU exhibits distinct behaviours for negative and positive values of $\\zeta$ (troughs and peaks respectively). While corrections for $\\zeta <0$ remain relatively small, of the order of the oscillation amplitude, positive $\\zeta$ yields substantial effects, growing exponentially as $e^{\\pi\\alpha/2}$ in the limit of large $\\zeta$. This indicates that even minute oscillations give large effects on the tail of the distribution.","sentences":["We study the statistics of scalar perturbations in models of inflation with small and rapid oscillations in the inflaton potential (resonant non-Gaussianity).","We do so by deriving the wavefunction $\\Psi[\\zeta(\\boldsymbol{x})]$ non-perturbatively in $\\zeta$, but at first order in the amplitude of the oscillations.","The expression of the wavefunction of the universe (WFU) is explicit and does not require solving partial differential equations.","One finds qualitative deviations from perturbation theory for $ |\\zeta| \\gtrsim \\alpha^{-2}$, where $\\alpha \\gg 1$ is the number of oscillations per Hubble time.","Notably, the WFU exhibits distinct behaviours for negative and positive values of $\\zeta$ (troughs and peaks respectively).","While corrections for $\\zeta <0$ remain relatively small, of the order of the oscillation amplitude, positive $\\zeta$ yields substantial effects, growing exponentially as $e^{\\pi\\alpha/2}$ in the limit of large $\\zeta$. This indicates that even minute oscillations give large effects on the tail of the distribution."],"url":"http://arxiv.org/abs/2401.10212v1","category":"hep-th"}
{"created":"2024-01-18 18:50:16","title":"MM-Interleaved: Interleaved Image-Text Generative Modeling via Multi-modal Feature Synchronizer","abstract":"Developing generative models for interleaved image-text data has both research and practical value. It requires models to understand the interleaved sequences and subsequently generate images and text. However, existing attempts are limited by the issue that the fixed number of visual tokens cannot efficiently capture image details, which is particularly problematic in the multi-image scenarios. To address this, this paper presents MM-Interleaved, an end-to-end generative model for interleaved image-text data. It introduces a multi-scale and multi-image feature synchronizer module, allowing direct access to fine-grained image features in the previous context during the generation process. MM-Interleaved is end-to-end pre-trained on both paired and interleaved image-text corpora. It is further enhanced through a supervised fine-tuning phase, wherein the model improves its ability to follow complex multi-modal instructions. Experiments demonstrate the versatility of MM-Interleaved in recognizing visual details following multi-modal instructions and generating consistent images following both textual and visual conditions. Code and models are available at \\url{https://github.com/OpenGVLab/MM-Interleaved}.","sentences":["Developing generative models for interleaved image-text data has both research and practical value.","It requires models to understand the interleaved sequences and subsequently generate images and text.","However, existing attempts are limited by the issue that the fixed number of visual tokens cannot efficiently capture image details, which is particularly problematic in the multi-image scenarios.","To address this, this paper presents MM-Interleaved, an end-to-end generative model for interleaved image-text data.","It introduces a multi-scale and multi-image feature synchronizer module, allowing direct access to fine-grained image features in the previous context during the generation process.","MM-Interleaved is end-to-end pre-trained on both paired and interleaved image-text corpora.","It is further enhanced through a supervised fine-tuning phase, wherein the model improves its ability to follow complex multi-modal instructions.","Experiments demonstrate the versatility of MM-Interleaved in recognizing visual details following multi-modal instructions and generating consistent images following both textual and visual conditions.","Code and models are available at \\url{https://github.com/OpenGVLab/MM-Interleaved}."],"url":"http://arxiv.org/abs/2401.10208v1","category":"cs.CV"}
{"created":"2024-01-18 18:44:10","title":"Maximal-Capacity Discrete Memoryless Channel Identification","abstract":"The problem of identifying the channel with the highest capacity among several discrete memoryless channels (DMCs) is considered. The problem is cast as a pure-exploration multi-armed bandit problem, which follows the practical use of training sequences to sense the communication channel statistics. A capacity estimator is proposed and tight confidence bounds on the estimator error are derived. Based on this capacity estimator, a gap-elimination algorithm termed BestChanID is proposed, which is oblivious to the capacity-achieving input distribution and is guaranteed to output the DMC with the largest capacity, with a desired confidence. Furthermore, two additional algorithms NaiveChanSel and MedianChanEl, that output with certain confidence a DMC with capacity close to the maximal, are introduced. Each of those algorithms is beneficial in a different regime and can be used as a subroutine in BestChanID. The sample complexity of all algorithms is analyzed as a function of the desired confidence parameter, the number of channels, and the channels' input and output alphabet sizes. The cost of best channel identification is shown to scale quadratically with the alphabet size, and a fundamental lower bound for the required number of channel senses to identify the best channel with a certain confidence is derived.","sentences":["The problem of identifying the channel with the highest capacity among several discrete memoryless channels (DMCs) is considered.","The problem is cast as a pure-exploration multi-armed bandit problem, which follows the practical use of training sequences to sense the communication channel statistics.","A capacity estimator is proposed and tight confidence bounds on the estimator error are derived.","Based on this capacity estimator, a gap-elimination algorithm termed BestChanID is proposed, which is oblivious to the capacity-achieving input distribution and is guaranteed to output the DMC with the largest capacity, with a desired confidence.","Furthermore, two additional algorithms NaiveChanSel and MedianChanEl, that output with certain confidence a DMC with capacity close to the maximal, are introduced.","Each of those algorithms is beneficial in a different regime and can be used as a subroutine in BestChanID.","The sample complexity of all algorithms is analyzed as a function of the desired confidence parameter, the number of channels, and the channels' input and output alphabet sizes.","The cost of best channel identification is shown to scale quadratically with the alphabet size, and a fundamental lower bound for the required number of channel senses to identify the best channel with a certain confidence is derived."],"url":"http://arxiv.org/abs/2401.10204v1","category":"cs.IT"}
{"created":"2024-01-18 18:42:28","title":"Quantum State Obfuscation from Classical Oracles","abstract":"A major unresolved question in quantum cryptography is whether it is possible to obfuscate arbitrary quantum computation. Indeed, there is much yet to understand about the feasibility of quantum obfuscation even in the classical oracle model, where one is given for free the ability to obfuscate any classical circuit.   In this work, we develop a new array of techniques that we use to construct a quantum state obfuscator, a powerful notion formalized recently by Coladangelo and Gunn (arXiv:2311.07794) in their pursuit of better software copy-protection schemes. Quantum state obfuscation refers to the task of compiling a quantum program, consisting of a quantum circuit $C$ with a classical description and an auxiliary quantum state $\\ket{\\psi}$, into a functionally-equivalent obfuscated quantum program that hides as much as possible about $C$ and $\\ket{\\psi}$. We prove the security of our obfuscator when applied to any pseudo-deterministic quantum program, i.e. one that computes a (nearly) deterministic classical input / classical output functionality. Our security proof is with respect to an efficient classical oracle, which may be heuristically instantiated using quantum-secure indistinguishability obfuscation for classical circuits.   Our result improves upon the recent work of Bartusek, Kitagawa, Nishimaki and Yamakawa (STOC 2023) who also showed how to obfuscate pseudo-deterministic quantum circuits in the classical oracle model, but only ones with a completely classical description. Furthermore, our result answers a question of Coladangelo and Gunn, who provide a construction of quantum state indistinguishability obfuscation with respect to a quantum oracle. Indeed, our quantum state obfuscator together with Coladangelo-Gunn gives the first candidate realization of a ``best-possible'' copy-protection scheme for all polynomial-time functionalities.","sentences":["A major unresolved question in quantum cryptography is whether it is possible to obfuscate arbitrary quantum computation.","Indeed, there is much yet to understand about the feasibility of quantum obfuscation even in the classical oracle model, where one is given for free the ability to obfuscate any classical circuit.   ","In this work, we develop a new array of techniques that we use to construct a quantum state obfuscator, a powerful notion formalized recently by Coladangelo and Gunn (arXiv:2311.07794) in their pursuit of better software copy-protection schemes.","Quantum state obfuscation refers to the task of compiling a quantum program, consisting of a quantum circuit $C$ with a classical description and an auxiliary quantum state $\\ket{\\psi}$, into a functionally-equivalent obfuscated quantum program that hides as much as possible about $C$ and $\\ket{\\psi}$. We prove the security of our obfuscator when applied to any pseudo-deterministic quantum program, i.e. one that computes a (nearly) deterministic classical input / classical output functionality.","Our security proof is with respect to an efficient classical oracle, which may be heuristically instantiated using quantum-secure indistinguishability obfuscation for classical circuits.   ","Our result improves upon the recent work of Bartusek, Kitagawa, Nishimaki and Yamakawa (STOC 2023) who also showed how to obfuscate pseudo-deterministic quantum circuits in the classical oracle model, but only ones with a completely classical description.","Furthermore, our result answers a question of Coladangelo and Gunn, who provide a construction of quantum state indistinguishability obfuscation with respect to a quantum oracle.","Indeed, our quantum state obfuscator together with Coladangelo-Gunn gives the first candidate realization of a ``best-possible'' copy-protection scheme for all polynomial-time functionalities."],"url":"http://arxiv.org/abs/2401.10200v1","category":"quant-ph"}
{"created":"2024-01-18 18:35:32","title":"Perfect pulsed inline twin-beam squeezers","abstract":"Perfect inline squeezers are both spectrally pure and have identical input and output temporal modes, allowing one to squeeze an arbitrary input quantum state in the sole input mode on which the device acts, while the quantum states of any other modes are unaffected. We study theoretically how to obtain a perfect pulsed inline squeezer in twin-beam systems by considering three commonly used configurations: unpoled single pass, poled single pass, and poled double pass. By obtaining analytical relations between the input and output temporal modes from the Bloch-Messiah decomposition of the discretized Heisenberg-picture propagator, we find that a double pass structure produces a perfect pulsed inline squeezer when operated in a frequency degenerate, symmetric group-velocity matched type-II configuration.","sentences":["Perfect inline squeezers are both spectrally pure and have identical input and output temporal modes, allowing one to squeeze an arbitrary input quantum state in the sole input mode on which the device acts, while the quantum states of any other modes are unaffected.","We study theoretically how to obtain a perfect pulsed inline squeezer in twin-beam systems by considering three commonly used configurations: unpoled single pass, poled single pass, and poled double pass.","By obtaining analytical relations between the input and output temporal modes from the Bloch-Messiah decomposition of the discretized Heisenberg-picture propagator, we find that a double pass structure produces a perfect pulsed inline squeezer when operated in a frequency degenerate, symmetric group-velocity matched type-II configuration."],"url":"http://arxiv.org/abs/2401.10197v1","category":"quant-ph"}
{"created":"2024-01-18 18:25:29","title":"Divide and not forget: Ensemble of selectively trained experts in Continual Learning","abstract":"Class-incremental learning is becoming more popular as it helps models widen their applicability while not forgetting what they already know. A trend in this area is to use a mixture-of-expert technique, where different models work together to solve the task. However, the experts are usually trained all at once using whole task data, which makes them all prone to forgetting and increasing computational burden. To address this limitation, we introduce a novel approach named SEED. SEED selects only one, the most optimal expert for a considered task, and uses data from this task to fine-tune only this expert. For this purpose, each expert represents each class with a Gaussian distribution, and the optimal expert is selected based on the similarity of those distributions. Consequently, SEED increases diversity and heterogeneity within the experts while maintaining the high stability of this ensemble method. The extensive experiments demonstrate that SEED achieves state-of-the-art performance in exemplar-free settings across various scenarios, showing the potential of expert diversification through data in continual learning.","sentences":["Class-incremental learning is becoming more popular as it helps models widen their applicability while not forgetting what they already know.","A trend in this area is to use a mixture-of-expert technique, where different models work together to solve the task.","However, the experts are usually trained all at once using whole task data, which makes them all prone to forgetting and increasing computational burden.","To address this limitation, we introduce a novel approach named SEED.","SEED selects only one, the most optimal expert for a considered task, and uses data from this task to fine-tune only this expert.","For this purpose, each expert represents each class with a Gaussian distribution, and the optimal expert is selected based on the similarity of those distributions.","Consequently, SEED increases diversity and heterogeneity within the experts while maintaining the high stability of this ensemble method.","The extensive experiments demonstrate that SEED achieves state-of-the-art performance in exemplar-free settings across various scenarios, showing the potential of expert diversification through data in continual learning."],"url":"http://arxiv.org/abs/2401.10191v1","category":"cs.LG"}
{"created":"2024-01-18 18:23:10","title":"A Kaczmarz-inspired approach to accelerate the optimization of neural network wavefunctions","abstract":"Neural network wavefunctions optimized using the variational Monte Carlo method have been shown to produce highly accurate results for the electronic structure of atoms and small molecules, but the high cost of optimizing such wavefunctions prevents their application to larger systems. We propose the Subsampled Projected-Increment Natural Gradient Descent (SPRING) optimizer to reduce this bottleneck. SPRING combines ideas from the recently introduced minimum-step stochastic reconfiguration optimizer (MinSR) and the classical randomized Kaczmarz method for solving linear least-squares problems. We demonstrate that SPRING outperforms both MinSR and the popular Kronecker-Factored Approximate Curvature method (KFAC) across a number of small atoms and molecules, given that the learning rates of all methods are optimally tuned. For example, on the oxygen atom, SPRING attains chemical accuracy after forty thousand training iterations, whereas both MinSR and KFAC fail to do so even after one hundred thousand iterations.","sentences":["Neural network wavefunctions optimized using the variational Monte Carlo method have been shown to produce highly accurate results for the electronic structure of atoms and small molecules, but the high cost of optimizing such wavefunctions prevents their application to larger systems.","We propose the Subsampled Projected-Increment Natural Gradient Descent (SPRING) optimizer to reduce this bottleneck.","SPRING combines ideas from the recently introduced minimum-step stochastic reconfiguration optimizer (MinSR) and the classical randomized Kaczmarz method for solving linear least-squares problems.","We demonstrate that SPRING outperforms both MinSR and the popular Kronecker-Factored Approximate Curvature method (KFAC) across a number of small atoms and molecules, given that the learning rates of all methods are optimally tuned.","For example, on the oxygen atom, SPRING attains chemical accuracy after forty thousand training iterations, whereas both MinSR and KFAC fail to do so even after one hundred thousand iterations."],"url":"http://arxiv.org/abs/2401.10190v1","category":"physics.comp-ph"}
{"created":"2024-01-18 18:16:48","title":"Fast Kronecker Matrix-Matrix Multiplication on GPUs","abstract":"Kronecker Matrix-Matrix Multiplication (Kron-Matmul) is the multiplication of a matrix with the Kronecker Product of several smaller matrices. Kron-Matmul is a core operation for many scientific and machine learning computations. State-of-the-art Kron-Matmul implementations utilize existing tensor algebra operations, such as matrix multiplication, transpose, and tensor matrix multiplication. However, this design choice prevents several Kron-Matmul specific optimizations, thus, leaving significant performance on the table. To address this issue, we present FastKron, an efficient technique for Kron-Matmul on single and multiple GPUs. FastKron is independent of linear algebra operations enabling several new optimizations for Kron-Matmul. Thus, it performs up to 40.7x and 7.85x faster than existing implementations on 1 and 16 GPUs respectively.","sentences":["Kronecker Matrix-Matrix Multiplication (Kron-Matmul) is the multiplication of a matrix with the Kronecker Product of several smaller matrices.","Kron-Matmul is a core operation for many scientific and machine learning computations.","State-of-the-art Kron-Matmul implementations utilize existing tensor algebra operations, such as matrix multiplication, transpose, and tensor matrix multiplication.","However, this design choice prevents several Kron-Matmul specific optimizations, thus, leaving significant performance on the table.","To address this issue, we present FastKron, an efficient technique for Kron-Matmul on single and multiple GPUs.","FastKron is independent of linear algebra operations enabling several new optimizations for Kron-Matmul.","Thus, it performs up to 40.7x and 7.85x faster than existing implementations on 1 and 16 GPUs respectively."],"url":"http://arxiv.org/abs/2401.10187v1","category":"cs.DC"}
{"created":"2024-01-18 18:15:46","title":"Beyond Reference-Based Metrics: Analyzing Behaviors of Open LLMs on Data-to-Text Generation","abstract":"We investigate to which extent open large language models (LLMs) can generate coherent and relevant text from structured data. To prevent bias from benchmarks leaked into LLM training data, we collect Quintd-1: an ad-hoc benchmark for five data-to-text (D2T) generation tasks, consisting of structured data records in standard formats gathered from public APIs. We leverage reference-free evaluation metrics and LLMs' in-context learning capabilities, allowing us to test the models with no human-written references. Our evaluation focuses on annotating semantic accuracy errors on token-level, combining human annotators and a metric based on GPT-4. Our systematic examination of the models' behavior across domains and tasks suggests that state-of-the-art open LLMs with 7B parameters can generate fluent and coherent text from various standard data formats in zero-shot settings. However, we also show that semantic accuracy of the outputs remains a major issue: on our benchmark, 80% of outputs of open LLMs contain a semantic error according to human annotators (91% according to GPT-4). Our code, data, and model outputs are available at https://d2t-llm.github.io.","sentences":["We investigate to which extent open large language models (LLMs) can generate coherent and relevant text from structured data.","To prevent bias from benchmarks leaked into LLM training data, we collect Quintd-1: an ad-hoc benchmark for five data-to-text (D2T) generation tasks, consisting of structured data records in standard formats gathered from public APIs.","We leverage reference-free evaluation metrics and LLMs' in-context learning capabilities, allowing us to test the models with no human-written references.","Our evaluation focuses on annotating semantic accuracy errors on token-level, combining human annotators and a metric based on GPT-4.","Our systematic examination of the models' behavior across domains and tasks suggests that state-of-the-art open LLMs with 7B parameters can generate fluent and coherent text from various standard data formats in zero-shot settings.","However, we also show that semantic accuracy of the outputs remains a major issue: on our benchmark, 80% of outputs of open LLMs contain a semantic error according to human annotators (91% according to GPT-4).","Our code, data, and model outputs are available at https://d2t-llm.github.io."],"url":"http://arxiv.org/abs/2401.10186v1","category":"cs.CL"}
{"created":"2024-01-18 18:12:35","title":"Transfer Learning in Human Activity Recognition: A Survey","abstract":"Sensor-based human activity recognition (HAR) has been an active research area, owing to its applications in smart environments, assisted living, fitness, healthcare, etc. Recently, deep learning based end-to-end training has resulted in state-of-the-art performance in domains such as computer vision and natural language, where large amounts of annotated data are available. However, large quantities of annotated data are not available for sensor-based HAR. Moreover, the real-world settings on which the HAR is performed differ in terms of sensor modalities, classification tasks, and target users. To address this problem, transfer learning has been employed extensively. In this survey, we focus on these transfer learning methods in the application domains of smart home and wearables-based HAR. In particular, we provide a problem-solution perspective by categorizing and presenting the works in terms of their contributions and the challenges they address. We also present an updated view of the state-of-the-art for both application domains. Based on our analysis of 205 papers, we highlight the gaps in the literature and provide a roadmap for addressing them. This survey provides a reference to the HAR community, by summarizing the existing works and providing a promising research agenda.","sentences":["Sensor-based human activity recognition (HAR) has been an active research area, owing to its applications in smart environments, assisted living, fitness, healthcare, etc.","Recently, deep learning based end-to-end training has resulted in state-of-the-art performance in domains such as computer vision and natural language, where large amounts of annotated data are available.","However, large quantities of annotated data are not available for sensor-based HAR.","Moreover, the real-world settings on which the HAR is performed differ in terms of sensor modalities, classification tasks, and target users.","To address this problem, transfer learning has been employed extensively.","In this survey, we focus on these transfer learning methods in the application domains of smart home and wearables-based HAR.","In particular, we provide a problem-solution perspective by categorizing and presenting the works in terms of their contributions and the challenges they address.","We also present an updated view of the state-of-the-art for both application domains.","Based on our analysis of 205 papers, we highlight the gaps in the literature and provide a roadmap for addressing them.","This survey provides a reference to the HAR community, by summarizing the existing works and providing a promising research agenda."],"url":"http://arxiv.org/abs/2401.10185v1","category":"cs.LG"}
{"created":"2024-01-18 18:12:28","title":"Comparing Traditional and LLM-based Search for Image Geolocation","abstract":"Web search engines have long served as indispensable tools for information retrieval; user behavior and query formulation strategies have been well studied. The introduction of search engines powered by large language models (LLMs) suggested more conversational search and new types of query strategies. In this paper, we compare traditional and LLM-based search for the task of image geolocation, i.e., determining the location where an image was captured. Our work examines user interactions, with a particular focus on query formulation strategies. In our study, 60 participants were assigned either traditional or LLM-based search engines as assistants for geolocation. Participants using traditional search more accurately predicted the location of the image compared to those using the LLM-based search. Distinct strategies emerged between users depending on the type of assistant. Participants using the LLM-based search issued longer, more natural language queries, but had shorter search sessions. When reformulating their search queries, traditional search participants tended to add more terms to their initial queries, whereas participants using the LLM-based search consistently rephrased their initial queries.","sentences":["Web search engines have long served as indispensable tools for information retrieval; user behavior and query formulation strategies have been well studied.","The introduction of search engines powered by large language models (LLMs) suggested more conversational search and new types of query strategies.","In this paper, we compare traditional and LLM-based search for the task of image geolocation, i.e., determining the location where an image was captured.","Our work examines user interactions, with a particular focus on query formulation strategies.","In our study, 60 participants were assigned either traditional or LLM-based search engines as assistants for geolocation.","Participants using traditional search more accurately predicted the location of the image compared to those using the LLM-based search.","Distinct strategies emerged between users depending on the type of assistant.","Participants using the LLM-based search issued longer, more natural language queries, but had shorter search sessions.","When reformulating their search queries, traditional search participants tended to add more terms to their initial queries, whereas participants using the LLM-based search consistently rephrased their initial queries."],"url":"http://arxiv.org/abs/2401.10184v1","category":"cs.IR"}
{"created":"2024-01-18 18:10:48","title":"Experimental demonstration of quantum illumination using polarization-entangled photon pairs and CHSH value as measure","abstract":"Entangled light sources for illuminating objects offers advantages over conventional illumination methods by enhancing the detection sensitivity of a reflecting object. The crux of the quantum advantage lies in way we can practically leverage quantum correlations to isolate the background noise and detect the low reflectivity object. In this work we experimentally demonstrated the advantages of using polarization-entangled photon pairs for quantum illumination and show that the quantum correlation measure using CHSH value is robust against background noise and losses. We also show that the residual of quantum correlations help in identifying the object of reflectivity, $\\eta$ as low as 0.05 and when signal-to-noise ratio is as low as 0.003 for $\\eta=0.7$, surpassing the earlier demonstrated results. Robustness of correlation measure with photon attenuation in atmospheric condition is analysed to show the practical feasibility of the real time application.","sentences":["Entangled light sources for illuminating objects offers advantages over conventional illumination methods by enhancing the detection sensitivity of a reflecting object.","The crux of the quantum advantage lies in way we can practically leverage quantum correlations to isolate the background noise and detect the low reflectivity object.","In this work we experimentally demonstrated the advantages of using polarization-entangled photon pairs for quantum illumination and show that the quantum correlation measure using CHSH value is robust against background noise and losses.","We also show that the residual of quantum correlations help in identifying the object of reflectivity, $\\eta$ as low as 0.05 and when signal-to-noise ratio is as low as 0.003 for $\\eta=0.7$, surpassing the earlier demonstrated results.","Robustness of correlation measure with photon attenuation in atmospheric condition is analysed to show the practical feasibility of the real time application."],"url":"http://arxiv.org/abs/2401.10182v1","category":"quant-ph"}
{"created":"2024-01-18 18:05:35","title":"Comprehensive OOD Detection Improvements","abstract":"As machine learning becomes increasingly prevalent in impactful decisions, recognizing when inference data is outside the model's expected input distribution is paramount for giving context to predictions. Out-of-distribution (OOD) detection methods have been created for this task. Such methods can be split into representation-based or logit-based methods from whether they respectively utilize the model's embeddings or predictions for OOD detection. In contrast to most papers which solely focus on one such group, we address both. We employ dimensionality reduction on feature embeddings in representation-based methods for both time speedups and improved performance. Additionally, we propose DICE-COL, a modification of the popular logit-based method Directed Sparsification (DICE) that resolves an unnoticed flaw. We demonstrate the effectiveness of our methods on the OpenOODv1.5 benchmark framework, where they significantly improve performance and set state-of-the-art results.","sentences":["As machine learning becomes increasingly prevalent in impactful decisions, recognizing when inference data is outside the model's expected input distribution is paramount for giving context to predictions.","Out-of-distribution (OOD) detection methods have been created for this task.","Such methods can be split into representation-based or logit-based methods from whether they respectively utilize the model's embeddings or predictions for OOD detection.","In contrast to most papers which solely focus on one such group, we address both.","We employ dimensionality reduction on feature embeddings in representation-based methods for both time speedups and improved performance.","Additionally, we propose DICE-COL, a modification of the popular logit-based method Directed Sparsification (DICE) that resolves an unnoticed flaw.","We demonstrate the effectiveness of our methods on the OpenOODv1.5 benchmark framework, where they significantly improve performance and set state-of-the-art results."],"url":"http://arxiv.org/abs/2401.10176v1","category":"cs.LG"}
{"created":"2024-01-18 18:03:07","title":"DualTake: Predicting Takeovers across Mobilities for Future Personalized Mobility Services","abstract":"A hybrid society is expected to emerge in the near future, with different mobilities interacting together, including cars, micro-mobilities, pedestrians, and robots. People may utilize multiple types of mobilities in their daily lives. As vehicle automation advances, driver modeling flourishes to provide personalized intelligent services. Thus, modeling drivers across mobilities would pave the road for future society mobility-as-a-service, and it is particularly interesting to predict driver behaviors in newer mobilities with traditional mobility data. In this work, we present takeover prediction on a micro-mobility, with car simulation data.The promising model performance demonstrates the feasibility of driver modeling across mobilities, as the first in the field.","sentences":["A hybrid society is expected to emerge in the near future, with different mobilities interacting together, including cars, micro-mobilities, pedestrians, and robots.","People may utilize multiple types of mobilities in their daily lives.","As vehicle automation advances, driver modeling flourishes to provide personalized intelligent services.","Thus, modeling drivers across mobilities would pave the road for future society mobility-as-a-service, and it is particularly interesting to predict driver behaviors in newer mobilities with traditional mobility data.","In this work, we present takeover prediction on a micro-mobility, with car simulation data.","The promising model performance demonstrates the feasibility of driver modeling across mobilities, as the first in the field."],"url":"http://arxiv.org/abs/2401.10175v1","category":"cs.HC"}
{"created":"2024-01-18 18:01:19","title":"SHINOBI: Shape and Illumination using Neural Object Decomposition via BRDF Optimization In-the-wild","abstract":"We present SHINOBI, an end-to-end framework for the reconstruction of shape, material, and illumination from object images captured with varying lighting, pose, and background. Inverse rendering of an object based on unconstrained image collections is a long-standing challenge in computer vision and graphics and requires a joint optimization over shape, radiance, and pose. We show that an implicit shape representation based on a multi-resolution hash encoding enables faster and robust shape reconstruction with joint camera alignment optimization that outperforms prior work. Further, to enable the editing of illumination and object reflectance (i.e. material) we jointly optimize BRDF and illumination together with the object's shape. Our method is class-agnostic and works on in-the-wild image collections of objects to produce relightable 3D assets for several use cases such as AR/VR, movies, games, etc. Project page: https://shinobi.aengelhardt.com Video: https://www.youtube.com/watch?v=iFENQ6AcYd8&feature=youtu.be","sentences":["We present SHINOBI, an end-to-end framework for the reconstruction of shape, material, and illumination from object images captured with varying lighting, pose, and background.","Inverse rendering of an object based on unconstrained image collections is a long-standing challenge in computer vision and graphics and requires a joint optimization over shape, radiance, and pose.","We show that an implicit shape representation based on a multi-resolution hash encoding enables faster and robust shape reconstruction with joint camera alignment optimization that outperforms prior work.","Further, to enable the editing of illumination and object reflectance (i.e. material) we jointly optimize BRDF and illumination together with the object's shape.","Our method is class-agnostic and works on in-the-wild image collections of objects to produce relightable 3D assets for several use cases such as AR/VR, movies, games, etc.","Project page: https://shinobi.aengelhardt.com Video: https://www.youtube.com/watch?v=iFENQ6AcYd8&feature=youtu.be"],"url":"http://arxiv.org/abs/2401.10171v1","category":"cs.CV"}
{"created":"2024-01-18 17:55:39","title":"VMamba: Visual State Space Model","abstract":"Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs) stand as the two most popular foundation models for visual representation learning. While CNNs exhibit remarkable scalability with linear complexity w.r.t. image resolution, ViTs surpass them in fitting capabilities despite contending with quadratic complexity. A closer inspection reveals that ViTs achieve superior visual modeling performance through the incorporation of global receptive fields and dynamic weights. This observation motivates us to propose a novel architecture that inherits these components while enhancing computational efficiency. To this end, we draw inspiration from the recently introduced state space model and propose the Visual State Space Model (VMamba), which achieves linear complexity without sacrificing global receptive fields. To address the encountered direction-sensitive issue, we introduce the Cross-Scan Module (CSM) to traverse the spatial domain and convert any non-causal visual image into order patch sequences. Extensive experimental results substantiate that VMamba not only demonstrates promising capabilities across various visual perception tasks, but also exhibits more pronounced advantages over established benchmarks as the image resolution increases. Source code has been available at https://github.com/MzeroMiko/VMamba.","sentences":["Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs) stand as the two most popular foundation models for visual representation learning.","While CNNs exhibit remarkable scalability with linear complexity w.r.t. image resolution, ViTs surpass them in fitting capabilities despite contending with quadratic complexity.","A closer inspection reveals that ViTs achieve superior visual modeling performance through the incorporation of global receptive fields and dynamic weights.","This observation motivates us to propose a novel architecture that inherits these components while enhancing computational efficiency.","To this end, we draw inspiration from the recently introduced state space model and propose the Visual State Space Model (VMamba), which achieves linear complexity without sacrificing global receptive fields.","To address the encountered direction-sensitive issue, we introduce the Cross-Scan Module (CSM) to traverse the spatial domain and convert any non-causal visual image into order patch sequences.","Extensive experimental results substantiate that VMamba not only demonstrates promising capabilities across various visual perception tasks, but also exhibits more pronounced advantages over established benchmarks as the image resolution increases.","Source code has been available at https://github.com/MzeroMiko/VMamba."],"url":"http://arxiv.org/abs/2401.10166v1","category":"cs.CV"}
{"created":"2024-01-18 17:49:32","title":"Anomalies and gauging of U(1) symmetries","abstract":"We propose the Symmetry TFT for theories with a $U(1)$ symmetry in arbitrary dimension. The Symmetry TFT describes the structure of the symmetry, its anomalies, and the possible topological manipulations. It is constructed as a BF theory of gauge fields for groups $U(1)$ and $\\mathbb{R}$, and contains a continuum of topological operators. We also propose an operation that produces the Symmetry TFT for the theory obtained by dynamically gauging the $U(1)$ symmetry. We discuss many examples. As an interesting outcome, we obtain the Symmetry TFT for the non-invertible $\\mathbb{Q}/\\mathbb{Z}$ chiral symmetry in four dimensions.","sentences":["We propose the Symmetry TFT for theories with a $U(1)$ symmetry in arbitrary dimension.","The Symmetry TFT describes the structure of the symmetry, its anomalies, and the possible topological manipulations.","It is constructed as a BF theory of gauge fields for groups $U(1)$ and $\\mathbb{R}$, and contains a continuum of topological operators.","We also propose an operation that produces the Symmetry TFT for the theory obtained by dynamically gauging the $U(1)$ symmetry.","We discuss many examples.","As an interesting outcome, we obtain the Symmetry TFT for the non-invertible $\\mathbb{Q}/\\mathbb{Z}$ chiral symmetry in four dimensions."],"url":"http://arxiv.org/abs/2401.10165v1","category":"hep-th"}
{"created":"2024-01-18 17:41:03","title":"An Exploration to the Correlation Structure and Clustering of Macroeconomic Variables (MEV)","abstract":"As a quantitative characterization of the complicated economy, Macroeconomic Variables (MEVs), including GDP, inflation, unemployment, income, spending, interest rate, etc., are playing a crucial role in banks' portfolio management and stress testing exercise. In recent years, especially during the COVID-19 period and the current high inflation environment, people are frequently talking about the changing \"correlation structure\" of MEVs. In this paper, we use a principal component based algorithm to better understand MEVs' correlation structure in a given period. We also demonstrate how this method can be used to visualize historical MEVs pattern changes between 2000 and 2022. Further, we use this method to compare different hypothetical or historical macroeconomic scenarios and present our key findings.","sentences":["As a quantitative characterization of the complicated economy, Macroeconomic Variables (MEVs), including GDP, inflation, unemployment, income, spending, interest rate, etc., are playing a crucial role in banks' portfolio management and stress testing exercise.","In recent years, especially during the COVID-19 period and the current high inflation environment, people are frequently talking about the changing \"correlation structure\" of MEVs.","In this paper, we use a principal component based algorithm to better understand MEVs' correlation structure in a given period.","We also demonstrate how this method can be used to visualize historical MEVs pattern changes between 2000 and 2022.","Further, we use this method to compare different hypothetical or historical macroeconomic scenarios and present our key findings."],"url":"http://arxiv.org/abs/2401.10162v1","category":"q-fin.RM"}
{"created":"2024-01-18 17:30:25","title":"Model-Assisted Learning for Adaptive Cooperative Perception of Connected Autonomous Vehicles","abstract":"Cooperative perception (CP) is a key technology to facilitate consistent and accurate situational awareness for connected and autonomous vehicles (CAVs). To tackle the network resource inefficiency issue in traditional broadcast-based CP, unicast-based CP has been proposed to associate CAV pairs for cooperative perception via vehicle-to-vehicle transmission. In this paper, we investigate unicast-based CP among CAV pairs. With the consideration of dynamic perception workloads and channel conditions due to vehicle mobility and dynamic radio resource availability, we propose an adaptive cooperative perception scheme for CAV pairs in a mixed-traffic autonomous driving scenario with both CAVs and human-driven vehicles. We aim to determine when to switch between cooperative perception and stand-alone perception for each CAV pair, and allocate communication and computing resources to cooperative CAV pairs for maximizing the computing efficiency gain under perception task delay requirements. A model-assisted multi-agent reinforcement learning (MARL) solution is developed, which integrates MARL for an adaptive CAV cooperation decision and an optimization model for communication and computing resource allocation. Simulation results demonstrate the effectiveness of the proposed scheme in achieving high computing efficiency gain, as compared with benchmark schemes.","sentences":["Cooperative perception (CP) is a key technology to facilitate consistent and accurate situational awareness for connected and autonomous vehicles (CAVs).","To tackle the network resource inefficiency issue in traditional broadcast-based CP, unicast-based CP has been proposed to associate CAV pairs for cooperative perception via vehicle-to-vehicle transmission.","In this paper, we investigate unicast-based CP among CAV pairs.","With the consideration of dynamic perception workloads and channel conditions due to vehicle mobility and dynamic radio resource availability, we propose an adaptive cooperative perception scheme for CAV pairs in a mixed-traffic autonomous driving scenario with both CAVs and human-driven vehicles.","We aim to determine when to switch between cooperative perception and stand-alone perception for each CAV pair, and allocate communication and computing resources to cooperative CAV pairs for maximizing the computing efficiency gain under perception task delay requirements.","A model-assisted multi-agent reinforcement learning (MARL) solution is developed, which integrates MARL for an adaptive CAV cooperation decision and an optimization model for communication and computing resource allocation.","Simulation results demonstrate the effectiveness of the proposed scheme in achieving high computing efficiency gain, as compared with benchmark schemes."],"url":"http://arxiv.org/abs/2401.10156v1","category":"cs.NI"}
{"created":"2024-01-18 17:22:37","title":"Motion-Zero: Zero-Shot Moving Object Control Framework for Diffusion-Based Video Generation","abstract":"Recent large-scale pre-trained diffusion models have demonstrated a powerful generative ability to produce high-quality videos from detailed text descriptions. However, exerting control over the motion of objects in videos generated by any video diffusion model is a challenging problem. In this paper, we propose a novel zero-shot moving object trajectory control framework, Motion-Zero, to enable a bounding-box-trajectories-controlled text-to-video diffusion model.To this end, an initial noise prior module is designed to provide a position-based prior to improve the stability of the appearance of the moving object and the accuracy of position. In addition, based on the attention map of the U-net, spatial constraints are directly applied to the denoising process of diffusion models, which further ensures the positional and spatial consistency of moving objects during the inference. Furthermore, temporal consistency is guaranteed with a proposed shift temporal attention mechanism. Our method can be flexibly applied to various state-of-the-art video diffusion models without any training process. Extensive experiments demonstrate our proposed method can control the motion trajectories of objects and generate high-quality videos.","sentences":["Recent large-scale pre-trained diffusion models have demonstrated a powerful generative ability to produce high-quality videos from detailed text descriptions.","However, exerting control over the motion of objects in videos generated by any video diffusion model is a challenging problem.","In this paper, we propose a novel zero-shot moving object trajectory control framework, Motion-Zero, to enable a bounding-box-trajectories-controlled text-to-video diffusion model.","To this end, an initial noise prior module is designed to provide a position-based prior to improve the stability of the appearance of the moving object and the accuracy of position.","In addition, based on the attention map of the U-net, spatial constraints are directly applied to the denoising process of diffusion models, which further ensures the positional and spatial consistency of moving objects during the inference.","Furthermore, temporal consistency is guaranteed with a proposed shift temporal attention mechanism.","Our method can be flexibly applied to various state-of-the-art video diffusion models without any training process.","Extensive experiments demonstrate our proposed method can control the motion trajectories of objects and generate high-quality videos."],"url":"http://arxiv.org/abs/2401.10150v1","category":"cs.CV"}
{"created":"2024-01-18 17:22:22","title":"Multi-Agent Reinforcement Learning for Maritime Operational Technology Cyber Security","abstract":"This paper demonstrates the potential for autonomous cyber defence to be applied on industrial control systems and provides a baseline environment to further explore Multi-Agent Reinforcement Learning's (MARL) application to this problem domain. It introduces a simulation environment, IPMSRL, of a generic Integrated Platform Management System (IPMS) and explores the use of MARL for autonomous cyber defence decision-making on generic maritime based IPMS Operational Technology (OT). OT cyber defensive actions are less mature than they are for Enterprise IT. This is due to the relatively brittle nature of OT infrastructure originating from the use of legacy systems, design-time engineering assumptions, and lack of full-scale modern security controls. There are many obstacles to be tackled across the cyber landscape due to continually increasing cyber-attack sophistication and the limitations of traditional IT-centric cyber defence solutions. Traditional IT controls are rarely deployed on OT infrastructure, and where they are, some threats aren't fully addressed. In our experiments, a shared critic implementation of Multi Agent Proximal Policy Optimisation (MAPPO) outperformed Independent Proximal Policy Optimisation (IPPO). MAPPO reached an optimal policy (episode outcome mean of 1) after 800K timesteps, whereas IPPO was only able to reach an episode outcome mean of 0.966 after one million timesteps. Hyperparameter tuning greatly improved training performance. Across one million timesteps the tuned hyperparameters reached an optimal policy whereas the default hyperparameters only managed to win sporadically, with most simulations resulting in a draw. We tested a real-world constraint, attack detection alert success, and found that when alert success probability is reduced to 0.75 or 0.9, the MARL defenders were still able to win in over 97.5% or 99.5% of episodes, respectively.","sentences":["This paper demonstrates the potential for autonomous cyber defence to be applied on industrial control systems and provides a baseline environment to further explore Multi-Agent Reinforcement Learning's (MARL) application to this problem domain.","It introduces a simulation environment, IPMSRL, of a generic Integrated Platform Management System (IPMS) and explores the use of MARL for autonomous cyber defence decision-making on generic maritime based IPMS Operational Technology (OT).","OT cyber defensive actions are less mature than they are for Enterprise IT.","This is due to the relatively brittle nature of OT infrastructure originating from the use of legacy systems, design-time engineering assumptions, and lack of full-scale modern security controls.","There are many obstacles to be tackled across the cyber landscape due to continually increasing cyber-attack sophistication and the limitations of traditional IT-centric cyber defence solutions.","Traditional IT controls are rarely deployed on OT infrastructure, and where they are, some threats aren't fully addressed.","In our experiments, a shared critic implementation of Multi Agent Proximal Policy Optimisation (MAPPO) outperformed Independent Proximal Policy Optimisation (IPPO).","MAPPO reached an optimal policy (episode outcome mean of 1) after 800K timesteps, whereas IPPO was only able to reach an episode outcome mean of 0.966 after one million timesteps.","Hyperparameter tuning greatly improved training performance.","Across one million timesteps the tuned hyperparameters reached an optimal policy whereas the default hyperparameters only managed to win sporadically, with most simulations resulting in a draw.","We tested a real-world constraint, attack detection alert success, and found that when alert success probability is reduced to 0.75 or 0.9, the MARL defenders were still able to win in over 97.5% or 99.5% of episodes, respectively."],"url":"http://arxiv.org/abs/2401.10149v1","category":"cs.LG"}
{"created":"2024-01-18 17:20:29","title":"Strong decay of correlations for Gibbs states in any dimension","abstract":"Quantum systems in thermal equilibrium are described using Gibbs states. The correlations in such states determine how difficult it is to describe or simulate them. In this article, we show that systems with short-range interactions that are above a critical temperature satisfy a mixing condition, that is that for any regions $A$, $C$ the distance of the reduced state $\\rho_{AC}$ on these regions to the product of its marginals, $$\\| \\rho_{AC} \\rho_A^{-1} \\otimes \\rho_C^{-1} - \\mathbf{1}_{AC}\\| \\, ,$$ decays exponentially with the distance between regions $A$ and $C$. This mixing condition is stronger than other commonly studied measures of correlation. In particular, it implies the exponential decay of the mutual information between distant regions. The mixing condition has been used, for example, to prove positive log-Sobolev constants. On the way, we investigate the relations to other notions of decay of correlations in quantum many-body systems and show that many of them are equivalent under the assumption that there exists a local effective Hamiltonian. The proof employs a variety of tools such as Araki's expansionals and quantum belief propagation.","sentences":["Quantum systems in thermal equilibrium are described using Gibbs states.","The correlations in such states determine how difficult it is to describe or simulate them.","In this article, we show that systems with short-range interactions that are above a critical temperature satisfy a mixing condition, that is that for any regions $A$, $C$ the distance of the reduced state $\\rho_{AC}$ on these regions to the product of its marginals, $$\\| \\rho_{AC} \\rho_A^{-1} \\otimes \\rho_C^{-1} - \\mathbf{1}_{AC}\\| \\, ,$$ decays exponentially with the distance between regions $A$ and $C$.","This mixing condition is stronger than other commonly studied measures of correlation.","In particular, it implies the exponential decay of the mutual information between distant regions.","The mixing condition has been used, for example, to prove positive log-Sobolev constants.","On the way, we investigate the relations to other notions of decay of correlations in quantum many-body systems and show that many of them are equivalent under the assumption that there exists a local effective Hamiltonian.","The proof employs a variety of tools such as Araki's expansionals and quantum belief propagation."],"url":"http://arxiv.org/abs/2401.10147v1","category":"quant-ph"}
{"created":"2024-01-18 17:12:35","title":"Resource Theory of Non-Revivals with Applications to Quantum Many-Body Scars","abstract":"The study of state revivals has a long history in dynamical systems. We introduce a resource theory to understand the use of state revivals in quantum physics, especially in quantum many-body scarred systems. In this theory, a state is said to contain no amount of resource if it experiences perfect revivals under some unitary evolution. All other states are said to be resourceful. We show that this resource bounds information scrambling. Furthermore, we show that quantum many-body scarred dynamics can produce revivals in the Hayden-Preskill decoding protocol and can also be used to recover damaged quantum information. Our theory establishes a framework to study information retrieval and its applications in quantum many-body physics.","sentences":["The study of state revivals has a long history in dynamical systems.","We introduce a resource theory to understand the use of state revivals in quantum physics, especially in quantum many-body scarred systems.","In this theory, a state is said to contain no amount of resource if it experiences perfect revivals under some unitary evolution.","All other states are said to be resourceful.","We show that this resource bounds information scrambling.","Furthermore, we show that quantum many-body scarred dynamics can produce revivals in the Hayden-Preskill decoding protocol and can also be used to recover damaged quantum information.","Our theory establishes a framework to study information retrieval and its applications in quantum many-body physics."],"url":"http://arxiv.org/abs/2401.10142v1","category":"quant-ph"}
{"created":"2024-01-18 17:07:54","title":"FSSH-2: Fewest Switches Surface Hopping with robust switching probability","abstract":"This study introduces the FSSH-2 scheme, a redefined and numerically stable adiabatic Fewest Switches Surface Hopping (FSSH) method for mixed quantum-classical dynamics. It reformulates the standard FSSH hopping probability without non-adiabatic coupling vectors and allows for numerical time integration with larger step sizes. The advantages of FSSH-2 are demonstrated by numerical experiments for five different model systems in one and two spatial dimensions with up to three electronic states.","sentences":["This study introduces the FSSH-2 scheme, a redefined and numerically stable adiabatic Fewest Switches Surface Hopping (FSSH) method for mixed quantum-classical dynamics.","It reformulates the standard FSSH hopping probability without non-adiabatic coupling vectors and allows for numerical time integration with larger step sizes.","The advantages of FSSH-2 are demonstrated by numerical experiments for five different model systems in one and two spatial dimensions with up to three electronic states."],"url":"http://arxiv.org/abs/2401.10140v1","category":"physics.comp-ph"}
{"created":"2024-01-18 17:06:16","title":"Wallets' explorations across non-fungible token collections","abstract":"Non-fungible tokens (NFTs), which are immutable and transferable tokens on blockchain networks, have been used to certify the ownership of digital images often grouped in collections. Depending on individual interests, wallets explore and purchase NFTs in one or more image collections. Among many potential factors of shaping purchase trajectories, this paper specifically examines how visual similarities between collections affect wallets' explorations. Our model shows that wallets' explorations are not random but tend to favor collections having similar visual features to their previous purchases. The model also predicts the extent to which the next collection is close to the most recent collection of purchases with respect to visual features. These results are expected to enhance and support recommendation systems for the NFT market.","sentences":["Non-fungible tokens (NFTs), which are immutable and transferable tokens on blockchain networks, have been used to certify the ownership of digital images often grouped in collections.","Depending on individual interests, wallets explore and purchase NFTs in one or more image collections.","Among many potential factors of shaping purchase trajectories, this paper specifically examines how visual similarities between collections affect wallets' explorations.","Our model shows that wallets' explorations are not random but tend to favor collections having similar visual features to their previous purchases.","The model also predicts the extent to which the next collection is close to the most recent collection of purchases with respect to visual features.","These results are expected to enhance and support recommendation systems for the NFT market."],"url":"http://arxiv.org/abs/2401.10138v1","category":"physics.soc-ph"}
{"created":"2024-01-18 17:05:51","title":"Universal adjointation of isometry operations using transformation of quantum supermaps","abstract":"The full characterization of the possible transformations of quantum operations is indispensable to developing algorithms in higher-order quantum computation, which is the quantum version of functional programming. Although universal transformations of unitary operations have been well investigated, their extensions to non-unitary operations are still missing, except for a few examples. Here we construct \\emph{isometry adjointation} protocols, transforming an input isometry operation into its adjoint operation. This task reduces to the transformation of unitary operation or that of quantum states in special cases. Parallel and sequential isometry adjointation protocols are constructed by transforming unitary inversion protocols using the composition of quantum combs. This construction achieves the optimal approximation error, which implies that the optimal performance does not depend on the output dimension of the isometry operation. In particular, we explicitly obtain the asymptotically optimal parallel protocol achieving the approximation error $\\epsilon = \\Theta(d^2/n)$, where $d$ is the input dimension of the isometry operation and $n$ is the number of calls of the isometry operation. We also construct the protocols for the related tasks called isometry inversion and universal error detection. We conduct semidefinite programming to investigate the optimal performances of the tasks using general protocols including indefinite causal order protocols. The numerical results show that the optimal performances of general protocols do not depend on the output dimension of the isometry operation for isometry adjointation and universal error detection, which is shown analytically for parallel and sequential protocols. They also exhibit the advantage of indefinite causal order protocols over sequential protocols for isometry inversion and universal error detection.","sentences":["The full characterization of the possible transformations of quantum operations is indispensable to developing algorithms in higher-order quantum computation, which is the quantum version of functional programming.","Although universal transformations of unitary operations have been well investigated, their extensions to non-unitary operations are still missing, except for a few examples.","Here we construct \\emph{isometry adjointation} protocols, transforming an input isometry operation into its adjoint operation.","This task reduces to the transformation of unitary operation or that of quantum states in special cases.","Parallel and sequential isometry adjointation protocols are constructed by transforming unitary inversion protocols using the composition of quantum combs.","This construction achieves the optimal approximation error, which implies that the optimal performance does not depend on the output dimension of the isometry operation.","In particular, we explicitly obtain the asymptotically optimal parallel protocol achieving the approximation error $\\epsilon = \\Theta(d^2/n)$, where $d$ is the input dimension of the isometry operation and $n$ is the number of calls of the isometry operation.","We also construct the protocols for the related tasks called isometry inversion and universal error detection.","We conduct semidefinite programming to investigate the optimal performances of the tasks using general protocols including indefinite causal order protocols.","The numerical results show that the optimal performances of general protocols do not depend on the output dimension of the isometry operation for isometry adjointation and universal error detection, which is shown analytically for parallel and sequential protocols.","They also exhibit the advantage of indefinite causal order protocols over sequential protocols for isometry inversion and universal error detection."],"url":"http://arxiv.org/abs/2401.10137v1","category":"quant-ph"}
{"created":"2024-01-18 17:05:10","title":"The Role of Data Filtering in Open Source Software Ranking and Selection","abstract":"Faced with over 100M open source projects most empirical investigations select a subset. Most research papers in leading venues investigated filtering projects by some measure of popularity with explicit or implicit arguments that unpopular projects are not of interest, may not even represent \"real\" software projects, or that less popular projects are not worthy of study. However, such filtering may have enormous effects on the results of the studies if and precisely because the sought-out response or prediction is in any way related to the filtering criteria.   We exemplify the impact of this practice on research outcomes: how filtering of projects listed on GitHub affects the assessment of their popularity. We randomly sample over 100,000 repositories and use multiple regression to model the number of stars (a proxy for popularity) based on the number of commits, the duration of the project, the number of authors, and the number of core developers. Comparing control with the entire dataset with a filtered model projects having ten or more authors we find that while certain characteristics of the repository consistently predict popularity, the filtering process significantly alters the relation ships between these characteristics and the response. The number of commits exhibited a positive correlation with popularity in the control sample but showed a negative correlation in the filtered sample. These findings highlight the potential biases introduced by data filtering and emphasize the need for careful sample selection in empirical research of mining software repositories. We recommend that empirical work should either analyze complete datasets such as World of Code, or employ stratified random sampling from a complete dataset to ensure that filtering is not biasing the results.","sentences":["Faced with over 100M open source projects most empirical investigations select a subset.","Most research papers in leading venues investigated filtering projects by some measure of popularity with explicit or implicit arguments that unpopular projects are not of interest, may not even represent \"real\" software projects, or that less popular projects are not worthy of study.","However, such filtering may have enormous effects on the results of the studies if and precisely because the sought-out response or prediction is in any way related to the filtering criteria.   ","We exemplify the impact of this practice on research outcomes: how filtering of projects listed on GitHub affects the assessment of their popularity.","We randomly sample over 100,000 repositories and use multiple regression to model the number of stars (a proxy for popularity) based on the number of commits, the duration of the project, the number of authors, and the number of core developers.","Comparing control with the entire dataset with a filtered model projects having ten or more authors we find that while certain characteristics of the repository consistently predict popularity, the filtering process significantly alters the relation ships between these characteristics and the response.","The number of commits exhibited a positive correlation with popularity in the control sample but showed a negative correlation in the filtered sample.","These findings highlight the potential biases introduced by data filtering and emphasize the need for careful sample selection in empirical research of mining software repositories.","We recommend that empirical work should either analyze complete datasets such as World of Code, or employ stratified random sampling from a complete dataset to ensure that filtering is not biasing the results."],"url":"http://arxiv.org/abs/2401.10136v1","category":"cs.SE"}
{"created":"2024-01-18 17:03:59","title":"Spatial-Temporal Large Language Model for Traffic Prediction","abstract":"Traffic prediction, a critical component for intelligent transportation systems, endeavors to foresee future traffic at specific locations using historical data. Although existing traffic prediction models often emphasize developing complex neural network structures, their accuracy has not seen improvements accordingly. Recently, Large Language Models (LLMs) have shown outstanding capabilities in time series analysis. Differing from existing models, LLMs progress mainly through parameter expansion and extensive pre-training while maintaining their fundamental structures. In this paper, we propose a Spatial-Temporal Large Language Model (ST-LLM) for traffic prediction. Specifically, ST-LLM redefines the timesteps at each location as tokens and incorporates a spatial-temporal embedding module to learn the spatial location and global temporal representations of tokens. Then these representations are fused to provide each token with unified spatial and temporal information. Furthermore, we propose a novel partially frozen attention strategy of the LLM, which is designed to capture spatial-temporal dependencies for traffic prediction. Comprehensive experiments on real traffic datasets offer evidence that ST-LLM outperforms state-of-the-art models. Notably, the ST-LLM also exhibits robust performance in both few-shot and zero-shot prediction scenarios.","sentences":["Traffic prediction, a critical component for intelligent transportation systems, endeavors to foresee future traffic at specific locations using historical data.","Although existing traffic prediction models often emphasize developing complex neural network structures, their accuracy has not seen improvements accordingly.","Recently, Large Language Models (LLMs) have shown outstanding capabilities in time series analysis.","Differing from existing models, LLMs progress mainly through parameter expansion and extensive pre-training while maintaining their fundamental structures.","In this paper, we propose a Spatial-Temporal Large Language Model (ST-LLM) for traffic prediction.","Specifically, ST-LLM redefines the timesteps at each location as tokens and incorporates a spatial-temporal embedding module to learn the spatial location and global temporal representations of tokens.","Then these representations are fused to provide each token with unified spatial and temporal information.","Furthermore, we propose a novel partially frozen attention strategy of the LLM, which is designed to capture spatial-temporal dependencies for traffic prediction.","Comprehensive experiments on real traffic datasets offer evidence that ST-LLM outperforms state-of-the-art models.","Notably, the ST-LLM also exhibits robust performance in both few-shot and zero-shot prediction scenarios."],"url":"http://arxiv.org/abs/2401.10134v1","category":"cs.LG"}
{"created":"2024-01-18 17:03:22","title":"Interplay between Sensing and Communication in Cell-Free Massive MIMO with URLLC Users","abstract":"This paper studies integrated sensing and communication (ISAC) in the downlink of a cell-free massive multiple-input multiple-output (MIMO) system with multi-static sensing and ultra-reliable low-latency communication (URLLC) users. We propose a successive convex approximation-based power allocation algorithm that maximizes energy efficiency while satisfying the sensing and URLLC requirements. In addition, we provide a new definition for network availability, which accounts for both sensing and URLLC requirements. The impact of blocklength, sensing requirement, and required reliability as a function of decoding error probability on network availability and energy efficiency is investigated. The proposed power allocation algorithm is compared to a communication-centric approach where only the URLLC requirement is considered. It is shown that the URLLC-only approach is incapable of meeting sensing requirements, while the proposed ISAC algorithm fulfills both sensing and URLLC requirements, albeit with an associated increase in energy consumption. This increment can be reduced up to 75% by utilizing additional symbols for sensing. It is also demonstrated that larger blocklengths enhance network availability and offer greater robustness against stringent reliability requirements.","sentences":["This paper studies integrated sensing and communication (ISAC) in the downlink of a cell-free massive multiple-input multiple-output (MIMO) system with multi-static sensing and ultra-reliable low-latency communication (URLLC) users.","We propose a successive convex approximation-based power allocation algorithm that maximizes energy efficiency while satisfying the sensing and URLLC requirements.","In addition, we provide a new definition for network availability, which accounts for both sensing and URLLC requirements.","The impact of blocklength, sensing requirement, and required reliability as a function of decoding error probability on network availability and energy efficiency is investigated.","The proposed power allocation algorithm is compared to a communication-centric approach where only the URLLC requirement is considered.","It is shown that the URLLC-only approach is incapable of meeting sensing requirements, while the proposed ISAC algorithm fulfills both sensing and URLLC requirements, albeit with an associated increase in energy consumption.","This increment can be reduced up to 75% by utilizing additional symbols for sensing.","It is also demonstrated that larger blocklengths enhance network availability and offer greater robustness against stringent reliability requirements."],"url":"http://arxiv.org/abs/2401.10133v1","category":"cs.IT"}
{"created":"2024-01-18 16:59:37","title":"Biorthogonal measures, polymer partition functions, and random matrices","abstract":"We develop the study of a particular class of biorthogonal measures, encompassing at the same time several random matrix models and partition functions of polymers. This general framework allows us to characterize the partition functions of the Log Gamma polymer and the mixed polymer in terms of explicit biorthogonal measures, as it was previously done for the homogeneous O'Connell-Yor polymer by Imamura and Sasamoto. In addition, we show that the biorthogonal measures associated to these three polymer models (Log Gamma, O'Connell-Yor, and mixed polymer) converge to random matrix eigenvalue distributions in small temperature limits. We also clarify the connection between different Fredholm determinant representations and explain how our results might be useful for asymptotic analysis and large deviation estimates.","sentences":["We develop the study of a particular class of biorthogonal measures, encompassing at the same time several random matrix models and partition functions of polymers.","This general framework allows us to characterize the partition functions of the Log Gamma polymer and the mixed polymer in terms of explicit biorthogonal measures, as it was previously done for the homogeneous O'Connell-Yor polymer by Imamura and Sasamoto.","In addition, we show that the biorthogonal measures associated to these three polymer models (Log Gamma, O'Connell-Yor, and mixed polymer) converge to random matrix eigenvalue distributions in small temperature limits.","We also clarify the connection between different Fredholm determinant representations and explain how our results might be useful for asymptotic analysis and large deviation estimates."],"url":"http://arxiv.org/abs/2401.10130v1","category":"math-ph"}
{"created":"2024-01-18 16:51:51","title":"Differentially Private Approval-Based Committee Voting","abstract":"In this paper, we investigate tradeoffs between differential privacy (DP) and several voting axioms for approval-based committee voting, including proportionality, Pareto efficiency, Condorcet criterion, and strategyproofness. For all the axioms except strategyproofness, we show their incompatibility with DP, and provide both upper and lower bounds for their tradeoffs with DP. Furthermore, we show that any $\\epsilon$-DP mechanism satisfies $e^{-\\epsilon}$-cardinality strategyproofness, and the satisfaction can be further improved if the mechanism satisfies monotonicity.","sentences":["In this paper, we investigate tradeoffs between differential privacy (DP) and several voting axioms for approval-based committee voting, including proportionality, Pareto efficiency, Condorcet criterion, and strategyproofness.","For all the axioms except strategyproofness, we show their incompatibility with DP, and provide both upper and lower bounds for their tradeoffs with DP.","Furthermore, we show that any $\\epsilon$-DP mechanism satisfies $e^{-\\epsilon}$-cardinality strategyproofness, and the satisfaction can be further improved if the mechanism satisfies monotonicity."],"url":"http://arxiv.org/abs/2401.10122v1","category":"cs.GT"}
{"created":"2024-01-18 16:51:02","title":"A Novel Noise-Aware Classical Optimizer for Variational Quantum Algorithms","abstract":"A key component of variational quantum algorithms (VQAs) is the choice of classical optimizer employed to update the parameterization of an ansatz. It is well recognized that quantum algorithms will, for the foreseeable future, necessarily be run on noisy devices with limited fidelities. Thus, the evaluation of an objective function (e.g., the guiding function in the quantum approximate optimization algorithm (QAOA) or the expectation of the electronic Hamiltonian in variational quantum eigensolver (VQE)) required by a classical optimizer is subject not only to stochastic error from estimating an expected value but also to error resulting from intermittent hardware noise. Model-based derivative-free optimization methods have emerged as popular choices of a classical optimizer in the noisy VQA setting, based on empirical studies. However, these optimization methods were not explicitly designed with the consideration of noise. In this work we adapt recent developments from the ``noise-aware numerical optimization'' literature to these commonly used derivative-free model-based methods. We introduce the key defining characteristics of these novel noise-aware derivative-free model-based methods that separate them from standard model-based methods. We study an implementation of such noise-aware derivative-free model-based methods and compare its performance on demonstrative VQA simulations to classical solvers packaged in \\texttt{scikit-quant}.","sentences":["A key component of variational quantum algorithms (VQAs) is the choice of classical optimizer employed to update the parameterization of an ansatz.","It is well recognized that quantum algorithms will, for the foreseeable future, necessarily be run on noisy devices with limited fidelities.","Thus, the evaluation of an objective function (e.g., the guiding function in the quantum approximate optimization algorithm (QAOA) or the expectation of the electronic Hamiltonian in variational quantum eigensolver (VQE)) required by a classical optimizer is subject not only to stochastic error from estimating an expected value but also to error resulting from intermittent hardware noise.","Model-based derivative-free optimization methods have emerged as popular choices of a classical optimizer in the noisy VQA setting, based on empirical studies.","However, these optimization methods were not explicitly designed with the consideration of noise.","In this work we adapt recent developments from the ``noise-aware numerical optimization'' literature to these commonly used derivative-free model-based methods.","We introduce the key defining characteristics of these novel noise-aware derivative-free model-based methods that separate them from standard model-based methods.","We study an implementation of such noise-aware derivative-free model-based methods and compare its performance on demonstrative VQA simulations to classical solvers packaged in \\texttt{scikit-quant}."],"url":"http://arxiv.org/abs/2401.10121v1","category":"quant-ph"}
{"created":"2024-01-18 16:51:01","title":"Binary Quantum Control Optimization with Uncertain Hamiltonians","abstract":"Optimizing the controls of quantum systems plays a crucial role in advancing quantum technologies. The time-varying noises in quantum systems and the widespread use of inhomogeneous quantum ensembles raise the need for high-quality quantum controls under uncertainties. In this paper, we consider a stochastic discrete optimization formulation of a binary optimal quantum control problem involving Hamiltonians with predictable uncertainties. We propose a sample-based reformulation that optimizes both risk-neutral and risk-averse measurements of control policies, and solve these with two gradient-based algorithms using sum-up-rounding approaches. Furthermore, we discuss the differentiability of the objective function and prove upper bounds of the gaps between the optimal solutions to binary control problems and their continuous relaxations. We conduct numerical studies on various sized problem instances based of two applications of quantum pulse optimization; we evaluate different strategies to mitigate the impact of uncertainties in quantum systems. We demonstrate that the controls of our stochastic optimization model achieve significantly higher quality and robustness compared to the controls of a deterministic model.","sentences":["Optimizing the controls of quantum systems plays a crucial role in advancing quantum technologies.","The time-varying noises in quantum systems and the widespread use of inhomogeneous quantum ensembles raise the need for high-quality quantum controls under uncertainties.","In this paper, we consider a stochastic discrete optimization formulation of a binary optimal quantum control problem involving Hamiltonians with predictable uncertainties.","We propose a sample-based reformulation that optimizes both risk-neutral and risk-averse measurements of control policies, and solve these with two gradient-based algorithms using sum-up-rounding approaches.","Furthermore, we discuss the differentiability of the objective function and prove upper bounds of the gaps between the optimal solutions to binary control problems and their continuous relaxations.","We conduct numerical studies on various sized problem instances based of two applications of quantum pulse optimization; we evaluate different strategies to mitigate the impact of uncertainties in quantum systems.","We demonstrate that the controls of our stochastic optimization model achieve significantly higher quality and robustness compared to the controls of a deterministic model."],"url":"http://arxiv.org/abs/2401.10120v1","category":"quant-ph"}
{"created":"2024-01-18 16:50:55","title":"Towards Principled Graph Transformers","abstract":"Graph learning architectures based on the k-dimensional Weisfeiler-Leman (k-WL) hierarchy offer a theoretically well-understood expressive power. However, such architectures often fail to deliver solid predictive performance on real-world tasks, limiting their practical impact. In contrast, global attention-based models such as graph transformers demonstrate strong performance in practice, but comparing their expressive power with the k-WL hierarchy remains challenging, particularly since these architectures rely on positional or structural encodings for their expressivity and predictive performance. To address this, we show that the recently proposed Edge Transformer, a global attention model operating on node pairs instead of nodes, has at least 3-WL expressive power. Empirically, we demonstrate that the Edge Transformer surpasses other theoretically aligned architectures regarding predictive performance while not relying on positional or structural encodings.","sentences":["Graph learning architectures based on the k-dimensional Weisfeiler-Leman (k-WL) hierarchy offer a theoretically well-understood expressive power.","However, such architectures often fail to deliver solid predictive performance on real-world tasks, limiting their practical impact.","In contrast, global attention-based models such as graph transformers demonstrate strong performance in practice, but comparing their expressive power with the k-WL hierarchy remains challenging, particularly since these architectures rely on positional or structural encodings for their expressivity and predictive performance.","To address this, we show that the recently proposed Edge Transformer, a global attention model operating on node pairs instead of nodes, has at least 3-WL expressive power.","Empirically, we demonstrate that the Edge Transformer surpasses other theoretically aligned architectures regarding predictive performance while not relying on positional or structural encodings."],"url":"http://arxiv.org/abs/2401.10119v1","category":"cs.LG"}
{"created":"2024-01-18 16:47:17","title":"Techniques for Authenticating Quantile Digests","abstract":"We investigate two possible techniques to authenticate the q-digest data structure, along with a worst-case study of the computational complexity both in time and space of the proposed solutions, and considerations on the feasibility of the presented approaches in real-world scenarios. We conclude the discussion by presenting some considerations on the information complexity of the queries in the two proposed approaches, and by presenting some interesting ideas that could be the subject of future studies on the topic.","sentences":["We investigate two possible techniques to authenticate the q-digest data structure, along with a worst-case study of the computational complexity both in time and space of the proposed solutions, and considerations on the feasibility of the presented approaches in real-world scenarios.","We conclude the discussion by presenting some considerations on the information complexity of the queries in the two proposed approaches, and by presenting some interesting ideas that could be the subject of future studies on the topic."],"url":"http://arxiv.org/abs/2401.10118v1","category":"cs.DS"}
{"created":"2024-01-18 16:35:37","title":"Exposing Lip-syncing Deepfakes from Mouth Inconsistencies","abstract":"A lip-syncing deepfake is a digitally manipulated video in which a person's lip movements are created convincingly using AI models to match altered or entirely new audio. Lip-syncing deepfakes are a dangerous type of deepfakes as the artifacts are limited to the lip region and more difficult to discern. In this paper, we describe a novel approach, LIP-syncing detection based on mouth INConsistency (LIPINC), for lip-syncing deepfake detection by identifying temporal inconsistencies in the mouth region. These inconsistencies are seen in the adjacent frames and throughout the video. Our model can successfully capture these irregularities and outperforms the state-of-the-art methods on several benchmark deepfake datasets.","sentences":["A lip-syncing deepfake is a digitally manipulated video in which a person's lip movements are created convincingly using AI models to match altered or entirely new audio.","Lip-syncing deepfakes are a dangerous type of deepfakes as the artifacts are limited to the lip region and more difficult to discern.","In this paper, we describe a novel approach, LIP-syncing detection based on mouth INConsistency (LIPINC), for lip-syncing deepfake detection by identifying temporal inconsistencies in the mouth region.","These inconsistencies are seen in the adjacent frames and throughout the video.","Our model can successfully capture these irregularities and outperforms the state-of-the-art methods on several benchmark deepfake datasets."],"url":"http://arxiv.org/abs/2401.10113v1","category":"cs.CV"}
{"created":"2024-01-18 16:27:18","title":"Marrying Adapters and Mixup to Efficiently Enhance the Adversarial Robustness of Pre-Trained Language Models for Text Classification","abstract":"Existing works show that augmenting training data of neural networks using both clean and adversarial examples can enhance their generalizability under adversarial attacks. However, this training approach often leads to performance degradation on clean inputs. Additionally, it requires frequent re-training of the entire model to account for new attack types, resulting in significant and costly computations. Such limitations make adversarial training mechanisms less practical, particularly for complex Pre-trained Language Models (PLMs) with millions or even billions of parameters. To overcome these challenges while still harnessing the theoretical benefits of adversarial training, this study combines two concepts: (1) adapters, which enable parameter-efficient fine-tuning, and (2) Mixup, which train NNs via convex combinations of pairs data pairs. Intuitively, we propose to fine-tune PLMs through convex combinations of non-data pairs of fine-tuned adapters, one trained with clean and another trained with adversarial examples. Our experiments show that the proposed method achieves the best trade-off between training efficiency and predictive performance, both with and without attacks compared to other baselines on a variety of downstream tasks.","sentences":["Existing works show that augmenting training data of neural networks using both clean and adversarial examples can enhance their generalizability under adversarial attacks.","However, this training approach often leads to performance degradation on clean inputs.","Additionally, it requires frequent re-training of the entire model to account for new attack types, resulting in significant and costly computations.","Such limitations make adversarial training mechanisms less practical, particularly for complex Pre-trained Language Models (PLMs) with millions or even billions of parameters.","To overcome these challenges while still harnessing the theoretical benefits of adversarial training, this study combines two concepts: (1) adapters, which enable parameter-efficient fine-tuning, and (2) Mixup, which train NNs via convex combinations of pairs data pairs.","Intuitively, we propose to fine-tune PLMs through convex combinations of non-data pairs of fine-tuned adapters, one trained with clean and another trained with adversarial examples.","Our experiments show that the proposed method achieves the best trade-off between training efficiency and predictive performance, both with and without attacks compared to other baselines on a variety of downstream tasks."],"url":"http://arxiv.org/abs/2401.10111v1","category":"cs.CL"}
{"created":"2024-01-18 16:27:09","title":"VIPTR: A Vision Permutable Extractor for Fast and Efficient Scene Text Recognition","abstract":"Scene Text Recognition (STR) is a challenging task that involves recognizing text within images of natural scenes. Although current state-of-the-art models for STR exhibit high performance, they typically suffer from low inference efficiency due to their reliance on hybrid architectures comprised of visual encoders and sequence decoders. In this work, we propose the VIsion Permutable extractor for fast and efficient scene Text Recognition (VIPTR), which achieves an impressive balance between high performance and rapid inference speeds in the domain of STR. Specifically, VIPTR leverages a visual-semantic extractor with a pyramid structure, characterized by multiple self-attention layers, while eschewing the traditional sequence decoder. This design choice results in a lightweight and efficient model capable of handling inputs of varying sizes. Extensive experimental results on various standard datasets for both Chinese and English scene text recognition validate the superiority of VIPTR. Notably, the VIPTR-T (Tiny) variant delivers highly competitive accuracy on par with other lightweight models and achieves SOTA inference speeds. Meanwhile, the VIPTR-L (Large) variant attains greater recognition accuracy, while maintaining a low parameter count and favorable inference speed. Our proposed method provides a compelling solution for the STR challenge, which blends high accuracy with efficiency and greatly benefits real-world applications requiring fast and reliable text recognition. The code is publicly available at https://github.com/cxfyxl/VIPTR.","sentences":["Scene Text Recognition (STR) is a challenging task that involves recognizing text within images of natural scenes.","Although current state-of-the-art models for STR exhibit high performance, they typically suffer from low inference efficiency due to their reliance on hybrid architectures comprised of visual encoders and sequence decoders.","In this work, we propose the VIsion Permutable extractor for fast and efficient scene Text Recognition (VIPTR), which achieves an impressive balance between high performance and rapid inference speeds in the domain of STR.","Specifically, VIPTR leverages a visual-semantic extractor with a pyramid structure, characterized by multiple self-attention layers, while eschewing the traditional sequence decoder.","This design choice results in a lightweight and efficient model capable of handling inputs of varying sizes.","Extensive experimental results on various standard datasets for both Chinese and English scene text recognition validate the superiority of VIPTR.","Notably, the VIPTR-T (Tiny) variant delivers highly competitive accuracy on par with other lightweight models and achieves SOTA inference speeds.","Meanwhile, the VIPTR-L (Large) variant attains greater recognition accuracy, while maintaining a low parameter count and favorable inference speed.","Our proposed method provides a compelling solution for the STR challenge, which blends high accuracy with efficiency and greatly benefits real-world applications requiring fast and reliable text recognition.","The code is publicly available at https://github.com/cxfyxl/VIPTR."],"url":"http://arxiv.org/abs/2401.10110v1","category":"cs.CV"}
{"created":"2024-01-18 16:24:30","title":"Information sets from defining sets for Reed-Muller codes of first and second order","abstract":"Reed-Muller codes belong to the family of affine-invariant codes. As such codes they have a defining set that determines them uniquely, and they are extensions of cyclic group codes. In this paper we identify those cyclic codes with multidimensional abelian codes and we use the techniques introduced in \\cite{BS} to construct information sets for them from their defining set. For first and second order Reed-Muller codes, we describe a direct method to construct information sets in terms of their basic parameters.","sentences":["Reed-Muller codes belong to the family of affine-invariant codes.","As such codes they have a defining set that determines them uniquely, and they are extensions of cyclic group codes.","In this paper we identify those cyclic codes with multidimensional abelian codes and we use the techniques introduced in \\cite{BS} to construct information sets for them from their defining set.","For first and second order Reed-Muller codes, we describe a direct method to construct information sets in terms of their basic parameters."],"url":"http://arxiv.org/abs/2401.10109v1","category":"cs.IT"}
{"created":"2024-01-18 16:10:07","title":"Counterfactual Reasoning with Probabilistic Graphical Models for Analyzing Socioecological Systems","abstract":"Causal and counterfactual reasoning are emerging directions in data science that allow us to reason about hypothetical scenarios. This is particularly useful in domains where experimental data are usually not available. In the context of environmental and ecological sciences, causality enables us, for example, to predict how an ecosystem would respond to hypothetical interventions. A structural causal model is a class of probabilistic graphical models for causality, which, due to its intuitive nature, can be easily understood by experts in multiple fields. However, certain queries, called unidentifiable, cannot be calculated in an exact and precise manner. This paper proposes applying a novel and recent technique for bounding unidentifiable queries within the domain of socioecological systems. Our findings indicate that traditional statistical analysis, including probabilistic graphical models, can identify the influence between variables. However, such methods do not offer insights into the nature of the relationship, specifically whether it involves necessity or sufficiency. This is where counterfactual reasoning becomes valuable.","sentences":["Causal and counterfactual reasoning are emerging directions in data science that allow us to reason about hypothetical scenarios.","This is particularly useful in domains where experimental data are usually not available.","In the context of environmental and ecological sciences, causality enables us, for example, to predict how an ecosystem would respond to hypothetical interventions.","A structural causal model is a class of probabilistic graphical models for causality, which, due to its intuitive nature, can be easily understood by experts in multiple fields.","However, certain queries, called unidentifiable, cannot be calculated in an exact and precise manner.","This paper proposes applying a novel and recent technique for bounding unidentifiable queries within the domain of socioecological systems.","Our findings indicate that traditional statistical analysis, including probabilistic graphical models, can identify the influence between variables.","However, such methods do not offer insights into the nature of the relationship, specifically whether it involves necessity or sufficiency.","This is where counterfactual reasoning becomes valuable."],"url":"http://arxiv.org/abs/2401.10101v1","category":"cs.AI"}
{"created":"2024-01-18 16:06:57","title":"Time-optimal state transfer for an open qubit","abstract":"Finding minimal time and establishing the structure of the corresponding optimal controls which can transfer a given initial state of a quantum system into a given target state is a key problem of quantum control. In this work, this problem is solved for a basic component of various quantum technology processes -- a qubit interacting with the environment and experiencing an arbitrary time-dependent coherent driving. We rigorously derive both upper and lower estimates for the minimal steering time. Surprisingly, we discover that the optimal controls have a very special form -- they consist of two impulses, at the beginning and at the end of the control period, which can be assisted by a smooth time-dependent control in between. Moreover, an important for practical applications explicit almost optimal state transfer protocol is provided which only consists of four impulses and gives an almost optimal time of motion. The results can be directly applied to a variety of experimental situations for estimation of the ultimate limits of state control for quantum technologies.","sentences":["Finding minimal time and establishing the structure of the corresponding optimal controls which can transfer a given initial state of a quantum system into a given target state is a key problem of quantum control.","In this work, this problem is solved for a basic component of various quantum technology processes -- a qubit interacting with the environment and experiencing an arbitrary time-dependent coherent driving.","We rigorously derive both upper and lower estimates for the minimal steering time.","Surprisingly, we discover that the optimal controls have a very special form -- they consist of two impulses, at the beginning and at the end of the control period, which can be assisted by a smooth time-dependent control in between.","Moreover, an important for practical applications explicit almost optimal state transfer protocol is provided which only consists of four impulses and gives an almost optimal time of motion.","The results can be directly applied to a variety of experimental situations for estimation of the ultimate limits of state control for quantum technologies."],"url":"http://arxiv.org/abs/2401.10099v1","category":"quant-ph"}
{"created":"2024-01-18 16:06:32","title":"Some simple theories of gravity with propagating nonmetricity","abstract":"We investigate symmetric Metric-Affine Theories of Gravity with a Lagrangian containing all operators of dimension up to four that are relevant to free propagation in flat space. Complementing recent work in the antisymmetric case, we derive the conditions for the existence of a single massive particle with good properties, in addition to the graviton.","sentences":["We investigate symmetric Metric-Affine Theories of Gravity with a Lagrangian containing all operators of dimension up to four that are relevant to free propagation in flat space.","Complementing recent work in the antisymmetric case, we derive the conditions for the existence of a single massive particle with good properties, in addition to the graviton."],"url":"http://arxiv.org/abs/2401.10097v1","category":"gr-qc"}
{"created":"2024-01-18 16:05:00","title":"Learning shallow quantum circuits","abstract":"Despite fundamental interests in learning quantum circuits, the existence of a computationally efficient algorithm for learning shallow quantum circuits remains an open question. Because shallow quantum circuits can generate distributions that are classically hard to sample from, existing learning algorithms do not apply. In this work, we present a polynomial-time classical algorithm for learning the description of any unknown $n$-qubit shallow quantum circuit $U$ (with arbitrary unknown architecture) within a small diamond distance using single-qubit measurement data on the output states of $U$. We also provide a polynomial-time classical algorithm for learning the description of any unknown $n$-qubit state $\\lvert \\psi \\rangle = U \\lvert 0^n \\rangle$ prepared by a shallow quantum circuit $U$ (on a 2D lattice) within a small trace distance using single-qubit measurements on copies of $\\lvert \\psi \\rangle$. Our approach uses a quantum circuit representation based on local inversions and a technique to combine these inversions. This circuit representation yields an optimization landscape that can be efficiently navigated and enables efficient learning of quantum circuits that are classically hard to simulate.","sentences":["Despite fundamental interests in learning quantum circuits, the existence of a computationally efficient algorithm for learning shallow quantum circuits remains an open question.","Because shallow quantum circuits can generate distributions that are classically hard to sample from, existing learning algorithms do not apply.","In this work, we present a polynomial-time classical algorithm for learning the description of any unknown $n$-qubit shallow quantum circuit $U$ (with arbitrary unknown architecture) within a small diamond distance using single-qubit measurement data on the output states of $U$. We also provide a polynomial-time classical algorithm for learning the description of any unknown $n$-qubit state $\\lvert \\psi \\rangle = U \\lvert 0^n \\rangle$ prepared by a shallow quantum circuit $U$ (on a 2D lattice) within a small trace distance using single-qubit measurements on copies of $\\lvert \\psi \\rangle$. Our approach uses a quantum circuit representation based on local inversions and a technique to combine these inversions.","This circuit representation yields an optimization landscape that can be efficiently navigated and enables efficient learning of quantum circuits that are classically hard to simulate."],"url":"http://arxiv.org/abs/2401.10095v1","category":"quant-ph"}
{"created":"2024-01-18 15:59:42","title":"Power in Numbers: Robust reading comprehension by finetuning with four adversarial sentences per example","abstract":"Recent models have achieved human level performance on the Stanford Question Answering Dataset when using F1 scores to evaluate the reading comprehension task. Yet, teaching machines to comprehend text has not been solved in the general case. By appending one adversarial sentence to the context paragraph, past research has shown that the F1 scores from reading comprehension models drop almost in half. In this paper, I replicate past adversarial research with a new model, ELECTRA-Small, and demonstrate that the new model's F1 score drops from 83.9% to 29.2%. To improve ELECTRA-Small's resistance to this attack, I finetune the model on SQuAD v1.1 training examples with one to five adversarial sentences appended to the context paragraph. Like past research, I find that the finetuned model on one adversarial sentence does not generalize well across evaluation datasets. However, when finetuned on four or five adversarial sentences the model attains an F1 score of more than 70% on most evaluation datasets with multiple appended and prepended adversarial sentences. The results suggest that with enough examples we can make models robust to adversarial attacks.","sentences":["Recent models have achieved human level performance on the Stanford Question Answering Dataset when using F1 scores to evaluate the reading comprehension task.","Yet, teaching machines to comprehend text has not been solved in the general case.","By appending one adversarial sentence to the context paragraph, past research has shown that the F1 scores from reading comprehension models drop almost in half.","In this paper, I replicate past adversarial research with a new model, ELECTRA-Small, and demonstrate that the new model's F1 score drops from 83.9% to 29.2%.","To improve ELECTRA-Small's resistance to this attack, I finetune the model on SQuAD v1.1 training examples with one to five adversarial sentences appended to the context paragraph.","Like past research, I find that the finetuned model on one adversarial sentence does not generalize well across evaluation datasets.","However, when finetuned on four or five adversarial sentences the model attains an F1 score of more than 70% on most evaluation datasets with multiple appended and prepended adversarial sentences.","The results suggest that with enough examples we can make models robust to adversarial attacks."],"url":"http://arxiv.org/abs/2401.10091v1","category":"cs.CL"}
{"created":"2024-01-18 15:56:23","title":"Cross-Modality Perturbation Synergy Attack for Person Re-identification","abstract":"In recent years, there has been significant research focusing on addressing security concerns in single-modal person re-identification (ReID) systems that are based on RGB images. However, the safety of cross-modality scenarios, which are more commonly encountered in practical applications involving images captured by infrared cameras, has not received adequate attention. The main challenge in cross-modality ReID lies in effectively dealing with visual differences between different modalities. For instance, infrared images are typically grayscale, unlike visible images that contain color information. Existing attack methods have primarily focused on the characteristics of the visible image modality, overlooking the features of other modalities and the variations in data distribution among different modalities. This oversight can potentially undermine the effectiveness of these methods in image retrieval across diverse modalities. This study represents the first exploration into the security of cross-modality ReID models and proposes a universal perturbation attack specifically designed for cross-modality ReID. This attack optimizes perturbations by leveraging gradients from diverse modality data, thereby disrupting the discriminator and reinforcing the differences between modalities. We conducted experiments on two widely used cross-modality datasets, namely RegDB and SYSU, which not only demonstrated the effectiveness of our method but also provided insights for future enhancements in the robustness of cross-modality ReID systems.","sentences":["In recent years, there has been significant research focusing on addressing security concerns in single-modal person re-identification (ReID) systems that are based on RGB images.","However, the safety of cross-modality scenarios, which are more commonly encountered in practical applications involving images captured by infrared cameras, has not received adequate attention.","The main challenge in cross-modality ReID lies in effectively dealing with visual differences between different modalities.","For instance, infrared images are typically grayscale, unlike visible images that contain color information.","Existing attack methods have primarily focused on the characteristics of the visible image modality, overlooking the features of other modalities and the variations in data distribution among different modalities.","This oversight can potentially undermine the effectiveness of these methods in image retrieval across diverse modalities.","This study represents the first exploration into the security of cross-modality ReID models and proposes a universal perturbation attack specifically designed for cross-modality ReID.","This attack optimizes perturbations by leveraging gradients from diverse modality data, thereby disrupting the discriminator and reinforcing the differences between modalities.","We conducted experiments on two widely used cross-modality datasets, namely RegDB and SYSU, which not only demonstrated the effectiveness of our method but also provided insights for future enhancements in the robustness of cross-modality ReID systems."],"url":"http://arxiv.org/abs/2401.10090v1","category":"cs.CV"}
{"created":"2024-01-18 15:53:34","title":"CLIP feature-based randomized control using images and text for multiple tasks and robots","abstract":"This study presents a control framework leveraging vision language models (VLMs) for multiple tasks and robots. Notably, existing control methods using VLMs have achieved high performance in various tasks and robots in the training environment. However, these methods incur high costs for learning control policies for tasks and robots other than those in the training environment. Considering the application of industrial and household robots, learning in novel environments where robots are introduced is challenging. To address this issue, we propose a control framework that does not require learning control policies. Our framework combines the vision-language CLIP model with a randomized control. CLIP computes the similarity between images and texts by embedding them in the feature space. This study employs CLIP to compute the similarity between camera images and text representing the target state. In our method, the robot is controlled by a randomized controller that simultaneously explores and increases the similarity gradients. Moreover, we fine-tune the CLIP to improve the performance of the proposed method. Consequently, we confirm the effectiveness of our approach through a multitask simulation and a real robot experiment using a two-wheeled robot and robot arm.","sentences":["This study presents a control framework leveraging vision language models (VLMs) for multiple tasks and robots.","Notably, existing control methods using VLMs have achieved high performance in various tasks and robots in the training environment.","However, these methods incur high costs for learning control policies for tasks and robots other than those in the training environment.","Considering the application of industrial and household robots, learning in novel environments where robots are introduced is challenging.","To address this issue, we propose a control framework that does not require learning control policies.","Our framework combines the vision-language CLIP model with a randomized control.","CLIP computes the similarity between images and texts by embedding them in the feature space.","This study employs CLIP to compute the similarity between camera images and text representing the target state.","In our method, the robot is controlled by a randomized controller that simultaneously explores and increases the similarity gradients.","Moreover, we fine-tune the CLIP to improve the performance of the proposed method.","Consequently, we confirm the effectiveness of our approach through a multitask simulation and a real robot experiment using a two-wheeled robot and robot arm."],"url":"http://arxiv.org/abs/2401.10085v1","category":"cs.RO"}
