{"created":"2024-04-05 17:59:59","title":"Incoherent polariton dynamics and nonlinearities in organic light-emitting diodes","abstract":"Organic light-emitting diodes (OLEDs) have redefined lighting with their environment-friendliness and flexibility. However, only 25 % of the electronic states of fluorescent molecules can emit light upon electrical excitation, limiting the overall efficiency of OLEDs. Strong light-matter coupling, achieved by confining light within OLEDs using mirrors, generates polaritons - hybrid light-matter states - that could activate the remaining 75 % electronic states. Here, we show how different processes in such polariton OLEDs can be expected to change using a phenomenological quantum master equation model. We are especially interested in reverse inter-system crossing happening directly from the dark triplet states to the emitting lower polariton. We derive a simple expression for the enhancement factor of polaritonic RISC in the linear regime. In addition, we explore the extension of our model to higher dimensions and study some potential effects of strong coupling on nonlinear processes such as triplet-triplet annihilation.","sentences":["Organic light-emitting diodes (OLEDs) have redefined lighting with their environment-friendliness and flexibility.","However, only 25 % of the electronic states of fluorescent molecules can emit light upon electrical excitation, limiting the overall efficiency of OLEDs.","Strong light-matter coupling, achieved by confining light within OLEDs using mirrors, generates polaritons - hybrid light-matter states - that could activate the remaining 75 % electronic states.","Here, we show how different processes in such polariton OLEDs can be expected to change using a phenomenological quantum master equation model.","We are especially interested in reverse inter-system crossing happening directly from the dark triplet states to the emitting lower polariton.","We derive a simple expression for the enhancement factor of polaritonic RISC in the linear regime.","In addition, we explore the extension of our model to higher dimensions and study some potential effects of strong coupling on nonlinear processes such as triplet-triplet annihilation."],"url":"http://arxiv.org/abs/2404.04257v1","category":"cond-mat.mtrl-sci"}
{"created":"2024-04-05 17:58:52","title":"Watermark-based Detection and Attribution of AI-Generated Content","abstract":"Several companies--such as Google, Microsoft, and OpenAI--have deployed techniques to watermark AI-generated content to enable proactive detection. However, existing literature mainly focuses on user-agnostic detection. Attribution aims to further trace back the user of a generative-AI service who generated a given content detected as AI-generated. Despite its growing importance, attribution is largely unexplored. In this work, we aim to bridge this gap by providing the first systematic study on watermark-based, user-aware detection and attribution of AI-generated content. Specifically, we theoretically study the detection and attribution performance via rigorous probabilistic analysis. Moreover, we develop an efficient algorithm to select watermarks for the users to enhance attribution performance. Both our theoretical and empirical results show that watermark-based detection and attribution inherit the accuracy and (non-)robustness properties of the watermarking method.","sentences":["Several companies--such as Google, Microsoft, and OpenAI--have deployed techniques to watermark AI-generated content to enable proactive detection.","However, existing literature mainly focuses on user-agnostic detection.","Attribution aims to further trace back the user of a generative-AI service who generated a given content detected as AI-generated.","Despite its growing importance, attribution is largely unexplored.","In this work, we aim to bridge this gap by providing the first systematic study on watermark-based, user-aware detection and attribution of AI-generated content.","Specifically, we theoretically study the detection and attribution performance via rigorous probabilistic analysis.","Moreover, we develop an efficient algorithm to select watermarks for the users to enhance attribution performance.","Both our theoretical and empirical results show that watermark-based detection and attribution inherit the accuracy and (non-)robustness properties of the watermarking method."],"url":"http://arxiv.org/abs/2404.04254v1","category":"cs.CR"}
{"created":"2024-04-05 17:58:37","title":"Growing Q-Networks: Solving Continuous Control Tasks with Adaptive Control Resolution","abstract":"Recent reinforcement learning approaches have shown surprisingly strong capabilities of bang-bang policies for solving continuous control benchmarks. The underlying coarse action space discretizations often yield favourable exploration characteristics while final performance does not visibly suffer in the absence of action penalization in line with optimal control theory. In robotics applications, smooth control signals are commonly preferred to reduce system wear and energy efficiency, but action costs can be detrimental to exploration during early training. In this work, we aim to bridge this performance gap by growing discrete action spaces from coarse to fine control resolution, taking advantage of recent results in decoupled Q-learning to scale our approach to high-dimensional action spaces up to dim(A) = 38. Our work indicates that an adaptive control resolution in combination with value decomposition yields simple critic-only algorithms that yield surprisingly strong performance on continuous control tasks.","sentences":["Recent reinforcement learning approaches have shown surprisingly strong capabilities of bang-bang policies for solving continuous control benchmarks.","The underlying coarse action space discretizations often yield favourable exploration characteristics while final performance does not visibly suffer in the absence of action penalization in line with optimal control theory.","In robotics applications, smooth control signals are commonly preferred to reduce system wear and energy efficiency, but action costs can be detrimental to exploration during early training.","In this work, we aim to bridge this performance gap by growing discrete action spaces from coarse to fine control resolution, taking advantage of recent results in decoupled Q-learning to scale our approach to high-dimensional action spaces up to dim(A) = 38.","Our work indicates that an adaptive control resolution in combination with value decomposition yields simple critic-only algorithms that yield surprisingly strong performance on continuous control tasks."],"url":"http://arxiv.org/abs/2404.04253v1","category":"cs.LG"}
{"created":"2024-04-05 17:58:36","title":"Bounds on galaxy stochasticity from halo occupation distribution modeling","abstract":"The joint probability distribution of matter overdensity and galaxy counts in cells is a powerful probe of cosmology, and the extent to which variance in galaxy counts at fixed matter density deviates from Poisson shot noise is not fully understood. The lack of informed bounds on this stochasticity is currently the limiting factor in constraining cosmology with the galaxy-matter PDF. We investigate stochasticity in the conditional distribution of galaxy counts at fixed matter density and present a halo occupation distribution (HOD)-based approach for obtaining plausible ranges for stochasticity parameters. To probe the high-dimensional space of possible galaxy-matter connections, we derive HODs which conserve linear galaxy bias and number density to produce redMaGiC-like galaxy catalogs within the AbacusSummit suite of N-body simulations. We study the impact of individual HOD parameters and cosmology on stochasticity and perform a Monte Carlo search in HOD parameter space, subject to the constraints on bias and density. In mock catalogs generated by the selected HODs, shot noise in galaxy counts spans both sub-Poisson and super-Poisson values, ranging from 80% to 133% of Poisson variance at mean matter density. Nearly all derived HODs show a positive relationship between local matter density and stochasticity. For galaxy catalogs with higher stochasticity, quadratic galaxy bias is required for an accurate description of the conditional PDF of galaxy counts at fixed matter density. The presence of galaxy assembly bias also substantially extends the range of stochasticity in the super-Poisson direction. This HOD-based approach leverages degrees of freedom in the galaxy-halo connection to obtain informed bounds on model nuisance parameters and can be adapted to other parametrizations of stochasticity, in particular to motivate prior ranges for cosmological analyses.","sentences":["The joint probability distribution of matter overdensity and galaxy counts in cells is a powerful probe of cosmology, and the extent to which variance in galaxy counts at fixed matter density deviates from Poisson shot noise is not fully understood.","The lack of informed bounds on this stochasticity is currently the limiting factor in constraining cosmology with the galaxy-matter PDF.","We investigate stochasticity in the conditional distribution of galaxy counts at fixed matter density and present a halo occupation distribution (HOD)-based approach for obtaining plausible ranges for stochasticity parameters.","To probe the high-dimensional space of possible galaxy-matter connections, we derive HODs which conserve linear galaxy bias and number density to produce redMaGiC-like galaxy catalogs within the AbacusSummit suite of N-body simulations.","We study the impact of individual HOD parameters and cosmology on stochasticity and perform a Monte Carlo search in HOD parameter space, subject to the constraints on bias and density.","In mock catalogs generated by the selected HODs, shot noise in galaxy counts spans both sub-Poisson and super-Poisson values, ranging from 80% to 133% of Poisson variance at mean matter density.","Nearly all derived HODs show a positive relationship between local matter density and stochasticity.","For galaxy catalogs with higher stochasticity, quadratic galaxy bias is required for an accurate description of the conditional PDF of galaxy counts at fixed matter density.","The presence of galaxy assembly bias also substantially extends the range of stochasticity in the super-Poisson direction.","This HOD-based approach leverages degrees of freedom in the galaxy-halo connection to obtain informed bounds on model nuisance parameters and can be adapted to other parametrizations of stochasticity, in particular to motivate prior ranges for cosmological analyses."],"url":"http://arxiv.org/abs/2404.04252v1","category":"astro-ph.CO"}
{"created":"2024-04-05 17:57:16","title":"Who Evaluates the Evaluations? Objectively Scoring Text-to-Image Prompt Coherence Metrics with T2IScoreScore (TS2)","abstract":"With advances in the quality of text-to-image (T2I) models has come interest in benchmarking their prompt faithfulness-the semantic coherence of generated images to the prompts they were conditioned on. A variety of T2I faithfulness metrics have been proposed, leveraging advances in cross-modal embeddings and vision-language models (VLMs). However, these metrics are not rigorously compared and benchmarked, instead presented against few weak baselines by correlation to human Likert scores over a set of easy-to-discriminate images.   We introduce T2IScoreScore (TS2), a curated set of semantic error graphs containing a prompt and a set increasingly erroneous images. These allow us to rigorously judge whether a given prompt faithfulness metric can correctly order images with respect to their objective error count and significantly discriminate between different error nodes, using meta-metric scores derived from established statistical tests. Surprisingly, we find that the state-of-the-art VLM-based metrics (e.g., TIFA, DSG, LLMScore, VIEScore) we tested fail to significantly outperform simple feature-based metrics like CLIPScore, particularly on a hard subset of naturally-occurring T2I model errors. TS2 will enable the development of better T2I prompt faithfulness metrics through more rigorous comparison of their conformity to expected orderings and separations under objective criteria.","sentences":["With advances in the quality of text-to-image (T2I) models has come interest in benchmarking their prompt faithfulness-the semantic coherence of generated images to the prompts they were conditioned on.","A variety of T2I faithfulness metrics have been proposed, leveraging advances in cross-modal embeddings and vision-language models (VLMs).","However, these metrics are not rigorously compared and benchmarked, instead presented against few weak baselines by correlation to human Likert scores over a set of easy-to-discriminate images.   ","We introduce T2IScoreScore (TS2), a curated set of semantic error graphs containing a prompt and a set increasingly erroneous images.","These allow us to rigorously judge whether a given prompt faithfulness metric can correctly order images with respect to their objective error count and significantly discriminate between different error nodes, using meta-metric scores derived from established statistical tests.","Surprisingly, we find that the state-of-the-art VLM-based metrics (e.g., TIFA, DSG, LLMScore, VIEScore) we tested fail to significantly outperform simple feature-based metrics like CLIPScore, particularly on a hard subset of naturally-occurring T2I model errors.","TS2 will enable the development of better T2I prompt faithfulness metrics through more rigorous comparison of their conformity to expected orderings and separations under objective criteria."],"url":"http://arxiv.org/abs/2404.04251v1","category":"cs.CV"}
{"created":"2024-04-05 17:54:12","title":"Humanoid Robots at work: where are we ?","abstract":"Launched by Elon Musk and its Optimus, we are witnessing a new race in which many companies have already engaged. The objective it to put at work a new generation of humanoid robots in demanding industrial environments within 2 or 3 years. Is this objective realistic ? The aim of this document and its main contributions is to provide some hints by covering the following topics: First an analysis of 12 companies based on eight criteria that will help us to distinguish companies based on their maturity and approach to the market; second as these humanoids are very complex systems we will provide an overview of the technological challenges to be addressed; third when humanoids are deployed at scale, Operation and Maintenance become critical and the we will explore what is new with these complex machines; Finally Pilots are the last step to test the feasibility of a new system before mass deployment. This is an important step to test the maturity of a product and the strategy of the humanoid supplier to address a market and two pragmatic approaches will be discussed.","sentences":["Launched by Elon Musk and its Optimus, we are witnessing a new race in which many companies have already engaged.","The objective it to put at work a new generation of humanoid robots in demanding industrial environments within 2 or 3 years.","Is this objective realistic ?","The aim of this document and its main contributions is to provide some hints by covering the following topics: First an analysis of 12 companies based on eight criteria that will help us to distinguish companies based on their maturity and approach to the market; second as these humanoids are very complex systems we will provide an overview of the technological challenges to be addressed; third when humanoids are deployed at scale, Operation and Maintenance become critical and the we will explore what is new with these complex machines; Finally Pilots are the last step to test the feasibility of a new system before mass deployment.","This is an important step to test the maturity of a product and the strategy of the humanoid supplier to address a market and two pragmatic approaches will be discussed."],"url":"http://arxiv.org/abs/2404.04249v1","category":"cs.CY"}
{"created":"2024-04-05 17:54:11","title":"Observation of Gravitational Waves from the Coalescence of a $2.5-4.5~M_\\odot$ Compact Object and a Neutron Star","abstract":"We report the observation of a coalescing compact binary with component masses $2.5-4.5~M_\\odot$ and $1.2-2.0~M_\\odot$ (all measurements quoted at the 90% credible level). The gravitational-wave signal GW230529_181500 was observed during the fourth observing run of the LIGO-Virgo-KAGRA detector network on 2023 May 29 by the LIGO Livingston Observatory. The primary component of the source has a mass less than $5~M_\\odot$ at 99% credibility. We cannot definitively determine from gravitational-wave data alone whether either component of the source is a neutron star or a black hole. However, given existing estimates of the maximum neutron star mass, we find the most probable interpretation of the source to be the coalescence of a neutron star with a black hole that has a mass between the most massive neutron stars and the least massive black holes observed in the Galaxy. We estimate a merger rate density of $55^{+127}_{-47}~\\text{Gpc}^{-3}\\,\\text{yr}^{-1}$ for compact binary coalescences with properties similar to the source of GW230529_181500; assuming that the source is a neutron star-black hole merger, GW230529_181500-like sources constitute about 60% of the total merger rate inferred for neutron star-black hole coalescences. The discovery of this system implies an increase in the expected rate of neutron star-black hole mergers with electromagnetic counterparts and provides further evidence for compact objects existing within the purported lower mass gap.","sentences":["We report the observation of a coalescing compact binary with component masses $2.5-4.5~M_\\odot$ and $1.2-2.0~M_\\odot$ (all measurements quoted at the 90% credible level).","The gravitational-wave signal GW230529_181500 was observed during the fourth observing run of the LIGO-Virgo-KAGRA detector network on 2023 May 29 by the LIGO Livingston Observatory.","The primary component of the source has a mass less than $5~M_\\odot$ at 99% credibility.","We cannot definitively determine from gravitational-wave data alone whether either component of the source is a neutron star or a black hole.","However, given existing estimates of the maximum neutron star mass, we find the most probable interpretation of the source to be the coalescence of a neutron star with a black hole that has a mass between the most massive neutron stars and the least massive black holes observed in the Galaxy.","We estimate a merger rate density of $55^{+127}_{-47}~\\text{Gpc}^{-3}\\,\\text{yr}^{-1}$ for compact binary coalescences with properties similar to the source of GW230529_181500; assuming that the source is a neutron star-black hole merger, GW230529_181500-like sources constitute about 60% of the total merger rate inferred for neutron star-black hole coalescences.","The discovery of this system implies an increase in the expected rate of neutron star-black hole mergers with electromagnetic counterparts and provides further evidence for compact objects existing within the purported lower mass gap."],"url":"http://arxiv.org/abs/2404.04248v1","category":"astro-ph.HE"}
{"created":"2024-04-05 17:45:22","title":"Identity Decoupling for Multi-Subject Personalization of Text-to-Image Models","abstract":"Text-to-image diffusion models have shown remarkable success in generating a personalized subject based on a few reference images. However, current methods struggle with handling multiple subjects simultaneously, often resulting in mixed identities with combined attributes from different subjects. In this work, we present MuDI, a novel framework that enables multi-subject personalization by effectively decoupling identities from multiple subjects. Our main idea is to utilize segmented subjects generated by the Segment Anything Model for both training and inference, as a form of data augmentation for training and initialization for the generation process. Our experiments demonstrate that MuDI can produce high-quality personalized images without identity mixing, even for highly similar subjects as shown in Figure 1. In human evaluation, MuDI shows twice as many successes for personalizing multiple subjects without identity mixing over existing baselines and is preferred over 70% compared to the strongest baseline. More results are available at https://mudi-t2i.github.io/.","sentences":["Text-to-image diffusion models have shown remarkable success in generating a personalized subject based on a few reference images.","However, current methods struggle with handling multiple subjects simultaneously, often resulting in mixed identities with combined attributes from different subjects.","In this work, we present MuDI, a novel framework that enables multi-subject personalization by effectively decoupling identities from multiple subjects.","Our main idea is to utilize segmented subjects generated by the Segment Anything Model for both training and inference, as a form of data augmentation for training and initialization for the generation process.","Our experiments demonstrate that MuDI can produce high-quality personalized images without identity mixing, even for highly similar subjects as shown in Figure 1.","In human evaluation, MuDI shows twice as many successes for personalizing multiple subjects without identity mixing over existing baselines and is preferred over 70% compared to the strongest baseline.","More results are available at https://mudi-t2i.github.io/."],"url":"http://arxiv.org/abs/2404.04243v1","category":"cs.CV"}
{"created":"2024-04-05 17:45:07","title":"Physical Property Understanding from Language-Embedded Feature Fields","abstract":"Can computers perceive the physical properties of objects solely through vision? Research in cognitive science and vision science has shown that humans excel at identifying materials and estimating their physical properties based purely on visual appearance. In this paper, we present a novel approach for dense prediction of the physical properties of objects using a collection of images. Inspired by how humans reason about physics through vision, we leverage large language models to propose candidate materials for each object. We then construct a language-embedded point cloud and estimate the physical properties of each 3D point using a zero-shot kernel regression approach. Our method is accurate, annotation-free, and applicable to any object in the open world. Experiments demonstrate the effectiveness of the proposed approach in various physical property reasoning tasks, such as estimating the mass of common objects, as well as other properties like friction and hardness.","sentences":["Can computers perceive the physical properties of objects solely through vision?","Research in cognitive science and vision science has shown that humans excel at identifying materials and estimating their physical properties based purely on visual appearance.","In this paper, we present a novel approach for dense prediction of the physical properties of objects using a collection of images.","Inspired by how humans reason about physics through vision, we leverage large language models to propose candidate materials for each object.","We then construct a language-embedded point cloud and estimate the physical properties of each 3D point using a zero-shot kernel regression approach.","Our method is accurate, annotation-free, and applicable to any object in the open world.","Experiments demonstrate the effectiveness of the proposed approach in various physical property reasoning tasks, such as estimating the mass of common objects, as well as other properties like friction and hardness."],"url":"http://arxiv.org/abs/2404.04242v1","category":"cs.CV"}
{"created":"2024-04-05 17:41:52","title":"Dynamic Conditional Optimal Transport through Simulation-Free Flows","abstract":"We study the geometry of conditional optimal transport (COT) and prove a dynamical formulation which generalizes the Benamou-Brenier Theorem. With these tools, we propose a simulation-free flow-based method for conditional generative modeling. Our method couples an arbitrary source distribution to a specified target distribution through a triangular COT plan. We build on the framework of flow matching to train a conditional generative model by approximating the geodesic path of measures induced by this COT plan. Our theory and methods are applicable in the infinite-dimensional setting, making them well suited for inverse problems. Empirically, we demonstrate our proposed method on two image-to-image translation tasks and an infinite-dimensional Bayesian inverse problem.","sentences":["We study the geometry of conditional optimal transport (COT) and prove a dynamical formulation which generalizes the Benamou-Brenier Theorem.","With these tools, we propose a simulation-free flow-based method for conditional generative modeling.","Our method couples an arbitrary source distribution to a specified target distribution through a triangular COT plan.","We build on the framework of flow matching to train a conditional generative model by approximating the geodesic path of measures induced by this COT plan.","Our theory and methods are applicable in the infinite-dimensional setting, making them well suited for inverse problems.","Empirically, we demonstrate our proposed method on two image-to-image translation tasks and an infinite-dimensional Bayesian inverse problem."],"url":"http://arxiv.org/abs/2404.04240v1","category":"cs.LG"}
{"created":"2024-04-05 17:29:47","title":"player2vec: A Language Modeling Approach to Understand Player Behavior in Games","abstract":"Methods for learning latent user representations from historical behavior logs have gained traction for recommendation tasks in e-commerce, content streaming, and other settings. However, this area still remains relatively underexplored in video and mobile gaming contexts. In this work, we present a novel method for overcoming this limitation by extending a long-range Transformer model from the natural language processing domain to player behavior data. We discuss specifics of behavior tracking in games and propose preprocessing and tokenization approaches by viewing in-game events in an analogous way to words in sentences, thus enabling learning player representations in a self-supervised manner in the absence of ground-truth annotations. We experimentally demonstrate the efficacy of the proposed approach in fitting the distribution of behavior events by evaluating intrinsic language modeling metrics. Furthermore, we qualitatively analyze the emerging structure of the learned embedding space and show its value for generating insights into behavior patterns to inform downstream applications.","sentences":["Methods for learning latent user representations from historical behavior logs have gained traction for recommendation tasks in e-commerce, content streaming, and other settings.","However, this area still remains relatively underexplored in video and mobile gaming contexts.","In this work, we present a novel method for overcoming this limitation by extending a long-range Transformer model from the natural language processing domain to player behavior data.","We discuss specifics of behavior tracking in games and propose preprocessing and tokenization approaches by viewing in-game events in an analogous way to words in sentences, thus enabling learning player representations in a self-supervised manner in the absence of ground-truth annotations.","We experimentally demonstrate the efficacy of the proposed approach in fitting the distribution of behavior events by evaluating intrinsic language modeling metrics.","Furthermore, we qualitatively analyze the emerging structure of the learned embedding space and show its value for generating insights into behavior patterns to inform downstream applications."],"url":"http://arxiv.org/abs/2404.04234v1","category":"cs.LG"}
{"created":"2024-04-05 17:26:22","title":"Benchmarking and Improving Compositional Generalization of Multi-aspect Controllable Text Generation","abstract":"Compositional generalization, representing the model's ability to generate text with new attribute combinations obtained by recombining single attributes from the training data, is a crucial property for multi-aspect controllable text generation (MCTG) methods. Nonetheless, a comprehensive compositional generalization evaluation benchmark of MCTG is still lacking. We propose CompMCTG, a benchmark encompassing diverse multi-aspect labeled datasets and a crafted three-dimensional evaluation protocol, to holistically evaluate the compositional generalization of MCTG approaches. We observe that existing MCTG works generally confront a noticeable performance drop in compositional testing. To mitigate this issue, we introduce Meta-MCTG, a training framework incorporating meta-learning, where we enable models to learn how to generalize by simulating compositional generalization scenarios in the training phase. We demonstrate the effectiveness of Meta-MCTG through achieving obvious improvement (by at most 3.64%) for compositional testing performance in 94.4% cases.","sentences":["Compositional generalization, representing the model's ability to generate text with new attribute combinations obtained by recombining single attributes from the training data, is a crucial property for multi-aspect controllable text generation (MCTG) methods.","Nonetheless, a comprehensive compositional generalization evaluation benchmark of MCTG is still lacking.","We propose CompMCTG, a benchmark encompassing diverse multi-aspect labeled datasets and a crafted three-dimensional evaluation protocol, to holistically evaluate the compositional generalization of MCTG approaches.","We observe that existing MCTG works generally confront a noticeable performance drop in compositional testing.","To mitigate this issue, we introduce Meta-MCTG, a training framework incorporating meta-learning, where we enable models to learn how to generalize by simulating compositional generalization scenarios in the training phase.","We demonstrate the effectiveness of Meta-MCTG through achieving obvious improvement (by at most 3.64%) for compositional testing performance in 94.4% cases."],"url":"http://arxiv.org/abs/2404.04232v1","category":"cs.CL"}
{"created":"2024-04-05 17:21:15","title":"The Standard Model Gauge Group, SMEFT, and Generalized Symmetries","abstract":"We discuss heavy particles that can be used to pin down the faithful Standard Model (SM) gauge group and their patterns in the SM effective field theory (SMEFT). These heavy particles are not invariant under a specific $\\mathbb{Z}_6$ subgroup of $SU(3)_c\\times SU(2)_L \\times U(1)_Y$, which however acts trivially on all the SM particles, hence the faithful SM gauge group remains undetermined. Different realizations of the faithful SM gauge group correspond to different spectra of heavy particles, and they also correspond to distinct sets of line operators with one-form global symmetry acting on them. We show that the heavy particles not invariant under the $\\mathbb{Z}_6$ group cannot appear in tree-level ultraviolet completions of SMEFT, this enforces us to consider one-loop UV completions of SMEFT to identify the $\\mathbb{Z}_6$ non-invariant heavy particles. We demonstrate with examples that correlations between Wilson coefficients provide an efficient way to examine models with $\\mathbb{Z}_6$ non-invariant heavy particles. Finally, we prove that all the scalars that can trigger electroweak symmetry breaking must be invariant under the $\\mathbb{Z}_6$ group, hence they cannot be used to probe the faithful SM gauge group.","sentences":["We discuss heavy particles that can be used to pin down the faithful Standard Model (SM) gauge group and their patterns in the SM effective field theory (SMEFT).","These heavy particles are not invariant under a specific $\\mathbb{Z}_6$ subgroup of $SU(3)_c\\times SU(2)_L \\times U(1)_Y$, which however acts trivially on all the SM particles, hence the faithful SM gauge group remains undetermined.","Different realizations of the faithful SM gauge group correspond to different spectra of heavy particles, and they also correspond to distinct sets of line operators with one-form global symmetry acting on them.","We show that the heavy particles not invariant under the $\\mathbb{Z}_6$ group cannot appear in tree-level ultraviolet completions of SMEFT, this enforces us to consider one-loop UV completions of SMEFT to identify the $\\mathbb{Z}_6$ non-invariant heavy particles.","We demonstrate with examples that correlations between Wilson coefficients provide an efficient way to examine models with $\\mathbb{Z}_6$ non-invariant heavy particles.","Finally, we prove that all the scalars that can trigger electroweak symmetry breaking must be invariant under the $\\mathbb{Z}_6$ group, hence they cannot be used to probe the faithful SM gauge group."],"url":"http://arxiv.org/abs/2404.04229v1","category":"hep-ph"}
{"created":"2024-04-05 17:16:10","title":"Twins in rotational spectroscopy: Does a rotational spectrum uniquely identify a molecule?","abstract":"Rotational spectroscopy is the most accurate method for determining structures of molecules in the gas phase. It is often assumed that a rotational spectrum is a unique \"fingerprint\" of a molecule. The availability of large molecular databases and the development of artificial intelligence methods for spectroscopy makes the testing of this assumption timely. In this paper, we pose the determination of molecular structures from rotational spectra as an inverse problem. Within this framework, we adopt a funnel-based approach to search for molecular twins, which are two or more molecules, which have similar rotational spectra but distinctly different molecular structures. We demonstrate that there are twins within standard levels of computational accuracy by generating rotational constants for many molecules from several large molecular databases, indicating the inverse problem is ill-posed. However, some twins can be distinguished by increasing the accuracy of the theoretical methods or by performing additional experiments.","sentences":["Rotational spectroscopy is the most accurate method for determining structures of molecules in the gas phase.","It is often assumed that a rotational spectrum is a unique \"fingerprint\" of a molecule.","The availability of large molecular databases and the development of artificial intelligence methods for spectroscopy makes the testing of this assumption timely.","In this paper, we pose the determination of molecular structures from rotational spectra as an inverse problem.","Within this framework, we adopt a funnel-based approach to search for molecular twins, which are two or more molecules, which have similar rotational spectra but distinctly different molecular structures.","We demonstrate that there are twins within standard levels of computational accuracy by generating rotational constants for many molecules from several large molecular databases, indicating the inverse problem is ill-posed.","However, some twins can be distinguished by increasing the accuracy of the theoretical methods or by performing additional experiments."],"url":"http://arxiv.org/abs/2404.04225v1","category":"physics.chem-ph"}
{"created":"2024-04-05 17:15:48","title":"Active Causal Learning for Decoding Chemical Complexities with Targeted Interventions","abstract":"Predicting and enhancing inherent properties based on molecular structures is paramount to design tasks in medicine, materials science, and environmental management. Most of the current machine learning and deep learning approaches have become standard for predictions, but they face challenges when applied across different datasets due to reliance on correlations between molecular representation and target properties. These approaches typically depend on large datasets to capture the diversity within the chemical space, facilitating a more accurate approximation, interpolation, or extrapolation of the chemical behavior of molecules. In our research, we introduce an active learning approach that discerns underlying cause-effect relationships through strategic sampling with the use of a graph loss function. This method identifies the smallest subset of the dataset capable of encoding the most information representative of a much larger chemical space. The identified causal relations are then leveraged to conduct systematic interventions, optimizing the design task within a chemical space that the models have not encountered previously. While our implementation focused on the QM9 quantum-chemical dataset for a specific design task-finding molecules with a large dipole moment-our active causal learning approach, driven by intelligent sampling and interventions, holds potential for broader applications in molecular, materials design and discovery.","sentences":["Predicting and enhancing inherent properties based on molecular structures is paramount to design tasks in medicine, materials science, and environmental management.","Most of the current machine learning and deep learning approaches have become standard for predictions, but they face challenges when applied across different datasets due to reliance on correlations between molecular representation and target properties.","These approaches typically depend on large datasets to capture the diversity within the chemical space, facilitating a more accurate approximation, interpolation, or extrapolation of the chemical behavior of molecules.","In our research, we introduce an active learning approach that discerns underlying cause-effect relationships through strategic sampling with the use of a graph loss function.","This method identifies the smallest subset of the dataset capable of encoding the most information representative of a much larger chemical space.","The identified causal relations are then leveraged to conduct systematic interventions, optimizing the design task within a chemical space that the models have not encountered previously.","While our implementation focused on the QM9 quantum-chemical dataset for a specific design task-finding molecules with a large dipole moment-our active causal learning approach, driven by intelligent sampling and interventions, holds potential for broader applications in molecular, materials design and discovery."],"url":"http://arxiv.org/abs/2404.04224v1","category":"cs.LG"}
{"created":"2024-04-05 17:06:03","title":"Multi-modal perception for soft robotic interactions using generative models","abstract":"Perception is essential for the active interaction of physical agents with the external environment. The integration of multiple sensory modalities, such as touch and vision, enhances this perceptual process, creating a more comprehensive and robust understanding of the world. Such fusion is particularly useful for highly deformable bodies such as soft robots. Developing a compact, yet comprehensive state representation from multi-sensory inputs can pave the way for the development of complex control strategies. This paper introduces a perception model that harmonizes data from diverse modalities to build a holistic state representation and assimilate essential information. The model relies on the causality between sensory input and robotic actions, employing a generative model to efficiently compress fused information and predict the next observation. We present, for the first time, a study on how touch can be predicted from vision and proprioception on soft robots, the importance of the cross-modal generation and why this is essential for soft robotic interactions in unstructured environments.","sentences":["Perception is essential for the active interaction of physical agents with the external environment.","The integration of multiple sensory modalities, such as touch and vision, enhances this perceptual process, creating a more comprehensive and robust understanding of the world.","Such fusion is particularly useful for highly deformable bodies such as soft robots.","Developing a compact, yet comprehensive state representation from multi-sensory inputs can pave the way for the development of complex control strategies.","This paper introduces a perception model that harmonizes data from diverse modalities to build a holistic state representation and assimilate essential information.","The model relies on the causality between sensory input and robotic actions, employing a generative model to efficiently compress fused information and predict the next observation.","We present, for the first time, a study on how touch can be predicted from vision and proprioception on soft robots, the importance of the cross-modal generation and why this is essential for soft robotic interactions in unstructured environments."],"url":"http://arxiv.org/abs/2404.04220v1","category":"cs.RO"}
{"created":"2024-04-05 17:05:45","title":"Continual Policy Distillation of Reinforcement Learning-based Controllers for Soft Robotic In-Hand Manipulation","abstract":"Dexterous manipulation, often facilitated by multi-fingered robotic hands, holds solid impact for real-world applications. Soft robotic hands, due to their compliant nature, offer flexibility and adaptability during object grasping and manipulation. Yet, benefits come with challenges, particularly in the control development for finger coordination. Reinforcement Learning (RL) can be employed to train object-specific in-hand manipulation policies, but limiting adaptability and generalizability. We introduce a Continual Policy Distillation (CPD) framework to acquire a versatile controller for in-hand manipulation, to rotate different objects in shape and size within a four-fingered soft gripper. The framework leverages Policy Distillation (PD) to transfer knowledge from expert policies to a continually evolving student policy network. Exemplar-based rehearsal methods are then integrated to mitigate catastrophic forgetting and enhance generalization. The performance of the CPD framework over various replay strategies demonstrates its effectiveness in consolidating knowledge from multiple experts and achieving versatile and adaptive behaviours for in-hand manipulation tasks.","sentences":["Dexterous manipulation, often facilitated by multi-fingered robotic hands, holds solid impact for real-world applications.","Soft robotic hands, due to their compliant nature, offer flexibility and adaptability during object grasping and manipulation.","Yet, benefits come with challenges, particularly in the control development for finger coordination.","Reinforcement Learning (RL) can be employed to train object-specific in-hand manipulation policies, but limiting adaptability and generalizability.","We introduce a Continual Policy Distillation (CPD) framework to acquire a versatile controller for in-hand manipulation, to rotate different objects in shape and size within a four-fingered soft gripper.","The framework leverages Policy Distillation (PD) to transfer knowledge from expert policies to a continually evolving student policy network.","Exemplar-based rehearsal methods are then integrated to mitigate catastrophic forgetting and enhance generalization.","The performance of the CPD framework over various replay strategies demonstrates its effectiveness in consolidating knowledge from multiple experts and achieving versatile and adaptive behaviours for in-hand manipulation tasks."],"url":"http://arxiv.org/abs/2404.04219v1","category":"cs.RO"}
{"created":"2024-04-05 16:30:45","title":"Enhancing IoT Intelligence: A Transformer-based Reinforcement Learning Methodology","abstract":"The proliferation of the Internet of Things (IoT) has led to an explosion of data generated by interconnected devices, presenting both opportunities and challenges for intelligent decision-making in complex environments. Traditional Reinforcement Learning (RL) approaches often struggle to fully harness this data due to their limited ability to process and interpret the intricate patterns and dependencies inherent in IoT applications. This paper introduces a novel framework that integrates transformer architectures with Proximal Policy Optimization (PPO) to address these challenges. By leveraging the self-attention mechanism of transformers, our approach enhances RL agents' capacity for understanding and acting within dynamic IoT environments, leading to improved decision-making processes. We demonstrate the effectiveness of our method across various IoT scenarios, from smart home automation to industrial control systems, showing marked improvements in decision-making efficiency and adaptability. Our contributions include a detailed exploration of the transformer's role in processing heterogeneous IoT data, a comprehensive evaluation of the framework's performance in diverse environments, and a benchmark against traditional RL methods. The results indicate significant advancements in enabling RL agents to navigate the complexities of IoT ecosystems, highlighting the potential of our approach to revolutionize intelligent automation and decision-making in the IoT landscape.","sentences":["The proliferation of the Internet of Things (IoT) has led to an explosion of data generated by interconnected devices, presenting both opportunities and challenges for intelligent decision-making in complex environments.","Traditional Reinforcement Learning (RL) approaches often struggle to fully harness this data due to their limited ability to process and interpret the intricate patterns and dependencies inherent in IoT applications.","This paper introduces a novel framework that integrates transformer architectures with Proximal Policy Optimization (PPO) to address these challenges.","By leveraging the self-attention mechanism of transformers, our approach enhances RL agents' capacity for understanding and acting within dynamic IoT environments, leading to improved decision-making processes.","We demonstrate the effectiveness of our method across various IoT scenarios, from smart home automation to industrial control systems, showing marked improvements in decision-making efficiency and adaptability.","Our contributions include a detailed exploration of the transformer's role in processing heterogeneous IoT data, a comprehensive evaluation of the framework's performance in diverse environments, and a benchmark against traditional RL methods.","The results indicate significant advancements in enabling RL agents to navigate the complexities of IoT ecosystems, highlighting the potential of our approach to revolutionize intelligent automation and decision-making in the IoT landscape."],"url":"http://arxiv.org/abs/2404.04205v1","category":"cs.LG"}
{"created":"2024-04-05 16:29:58","title":"Social Skill Training with Large Language Models","abstract":"People rely on social skills like conflict resolution to communicate effectively and to thrive in both work and personal life. However, practice environments for social skills are typically out of reach for most people. How can we make social skill training more available, accessible, and inviting? Drawing upon interdisciplinary research from communication and psychology, this perspective paper identifies social skill barriers to enter specialized fields. Then we present a solution that leverages large language models for social skill training via a generic framework. Our AI Partner, AI Mentor framework merges experiential learning with realistic practice and tailored feedback. This work ultimately calls for cross-disciplinary innovation to address the broader implications for workforce development and social equality.","sentences":["People rely on social skills like conflict resolution to communicate effectively and to thrive in both work and personal life.","However, practice environments for social skills are typically out of reach for most people.","How can we make social skill training more available, accessible, and inviting?","Drawing upon interdisciplinary research from communication and psychology, this perspective paper identifies social skill barriers to enter specialized fields.","Then we present a solution that leverages large language models for social skill training via a generic framework.","Our AI Partner, AI Mentor framework merges experiential learning with realistic practice and tailored feedback.","This work ultimately calls for cross-disciplinary innovation to address the broader implications for workforce development and social equality."],"url":"http://arxiv.org/abs/2404.04204v1","category":"cs.CL"}
{"created":"2024-04-05 16:26:40","title":"On a generalization of compact and connected spaces","abstract":"In this paper we will give two different natural generalizations of compact spaces and connected spaces simultaneously. We will show that these generalizations coincide for the subspaces of the real line and that they differ for subspaces of plane.","sentences":["In this paper we will give two different natural generalizations of compact spaces and connected spaces simultaneously.","We will show that these generalizations coincide for the subspaces of the real line and that they differ for subspaces of plane."],"url":"http://arxiv.org/abs/2404.04203v1","category":"math.GN"}
{"created":"2024-04-05 16:25:39","title":"Deep-learning Segmentation of Small Volumes in CT images for Radiotherapy Treatment Planning","abstract":"Our understanding of organs at risk is progressing to include physical small tissues such as coronary arteries and the radiosensitivities of many small organs and tissues are high. Therefore, the accurate segmentation of small volumes in external radiotherapy is crucial to protect them from over-irradiation. Moreover, with the development of the particle therapy and on-board imaging, the treatment becomes more accurate and precise. The purpose of this work is to optimize organ segmentation algorithms for small organs. We used 50 three-dimensional (3-D) computed tomography (CT) head and neck images from StructSeg2019 challenge to develop a general-purpose V-Net model to segment 20 organs in the head and neck region. We applied specific strategies to improve the segmentation accuracy of the small volumes in this anatomical region, i.e., the lens of the eye. Then, we used 17 additional head images from OSF healthcare to validate the robustness of the V Net model optimized for small-volume segmentation. With the study of the StructSeg2019 images, we found that the optimization of the image normalization range and classification threshold yielded a segmentation improvement of the lens of the eye of approximately 50%, compared to the use of the V-Net not optimized for small volumes. We used the optimized model to segment 17 images acquired using heterogeneous protocols. We obtained comparable Dice coefficient values for the clinical and StructSeg2019 images (0.61 plus/minus 0.07 and 0.58 plus/minus 0.10 for the left and right lens of the eye, respectively)","sentences":["Our understanding of organs at risk is progressing to include physical small tissues such as coronary arteries and the radiosensitivities of many small organs and tissues are high.","Therefore, the accurate segmentation of small volumes in external radiotherapy is crucial to protect them from over-irradiation.","Moreover, with the development of the particle therapy and on-board imaging, the treatment becomes more accurate and precise.","The purpose of this work is to optimize organ segmentation algorithms for small organs.","We used 50 three-dimensional (3-D) computed tomography (CT) head and neck images from StructSeg2019 challenge to develop a general-purpose V-Net model to segment 20 organs in the head and neck region.","We applied specific strategies to improve the segmentation accuracy of the small volumes in this anatomical region, i.e., the lens of the eye.","Then, we used 17 additional head images from OSF healthcare to validate the robustness of the V Net model optimized for small-volume segmentation.","With the study of the StructSeg2019 images, we found that the optimization of the image normalization range and classification threshold yielded a segmentation improvement of the lens of the eye of approximately 50%, compared to the use of the V-Net not optimized for small volumes.","We used the optimized model to segment 17 images acquired using heterogeneous protocols.","We obtained comparable Dice coefficient values for the clinical and StructSeg2019 images (0.61 plus/minus 0.07 and 0.58 plus/minus 0.10 for the left and right lens of the eye, respectively)"],"url":"http://arxiv.org/abs/2404.04202v1","category":"eess.IV"}
{"created":"2024-04-05 16:07:44","title":"Markovian description of a wide class of feedback-controlled systems: Application to the feedback flashing ratchet","abstract":"In feedback-controlled systems, an external agent -- the feedback controller -- measures the state of the system and modifies its subsequent dynamics depending on the outcome of the measurement. In this paper, we build a Markovian description for the joint stochastic process that comprises both the system and the controller variables. This Markovian description is valid for a wide class of feedback-controlled systems, allowing for the inclusion of errors in the measurement. The general framework is motivated and illustrated with the paradigmatic example of the feedback flashing ratchet.","sentences":["In feedback-controlled systems, an external agent -- the feedback controller -- measures the state of the system and modifies its subsequent dynamics depending on the outcome of the measurement.","In this paper, we build a Markovian description for the joint stochastic process that comprises both the system and the controller variables.","This Markovian description is valid for a wide class of feedback-controlled systems, allowing for the inclusion of errors in the measurement.","The general framework is motivated and illustrated with the paradigmatic example of the feedback flashing ratchet."],"url":"http://arxiv.org/abs/2404.04195v1","category":"cond-mat.stat-mech"}
{"created":"2024-04-05 16:05:42","title":"ToolEENet: Tool Affordance 6D Pose Estimation","abstract":"The exploration of robotic dexterous hands utilizing tools has recently attracted considerable attention. A significant challenge in this field is the precise awareness of a tool's pose when grasped, as occlusion by the hand often degrades the quality of the estimation. Additionally, the tool's overall pose often fails to accurately represent the contact interaction, thereby limiting the effectiveness of vision-guided, contact-dependent activities. To overcome this limitation, we present the innovative TOOLEE dataset, which, to the best of our knowledge, is the first to feature affordance segmentation of a tool's end-effector (EE) along with its defined 6D pose based on its usage. Furthermore, we propose the ToolEENet framework for accurate 6D pose estimation of the tool's EE. This framework begins by segmenting the tool's EE from raw RGBD data, then uses a diffusion model-based pose estimator for 6D pose estimation at a category-specific level. Addressing the issue of symmetry in pose estimation, we introduce a symmetry-aware pose representation that enhances the consistency of pose estimation. Our approach excels in this field, demonstrating high levels of precision and generalization. Furthermore, it shows great promise for application in contact-based manipulation scenarios. All data and codes are available on the project website: https://yuyangtu.github.io/projectToolEENet.html","sentences":["The exploration of robotic dexterous hands utilizing tools has recently attracted considerable attention.","A significant challenge in this field is the precise awareness of a tool's pose when grasped, as occlusion by the hand often degrades the quality of the estimation.","Additionally, the tool's overall pose often fails to accurately represent the contact interaction, thereby limiting the effectiveness of vision-guided, contact-dependent activities.","To overcome this limitation, we present the innovative TOOLEE dataset, which, to the best of our knowledge, is the first to feature affordance segmentation of a tool's end-effector (EE) along with its defined 6D pose based on its usage.","Furthermore, we propose the ToolEENet framework for accurate 6D pose estimation of the tool's EE.","This framework begins by segmenting the tool's EE from raw RGBD data, then uses a diffusion model-based pose estimator for 6D pose estimation at a category-specific level.","Addressing the issue of symmetry in pose estimation, we introduce a symmetry-aware pose representation that enhances the consistency of pose estimation.","Our approach excels in this field, demonstrating high levels of precision and generalization.","Furthermore, it shows great promise for application in contact-based manipulation scenarios.","All data and codes are available on the project website: https://yuyangtu.github.io/projectToolEENet.html"],"url":"http://arxiv.org/abs/2404.04193v1","category":"cs.RO"}
{"created":"2024-04-05 16:04:23","title":"Gravitational collapse in effective loop quantum gravity: beyond marginally bound configurations","abstract":"We study gravitational collapse in effective loop quantum gravity, focusing on non-marginally bound configurations in Lema\\^itre-Tolman-Bondi spacetimes. In the homogeneous limit we recover the effective dynamics of loop quantum cosmology for Friedman cosmologies with spatial curvature. We study a particular family of configurations with a homogeneous interior and a sharp boundary where the dust energy density rapidly and continuously decreases to zero. For these configurations, the gravitational collapse continues to the Planck regime when a bounce occurs, at which point the dust ball starts to expand, and a shock wave forms in the gravitational field within the order of a Planck time after the bounce. The shock slowly moves outwards, eventually reaching the horizon which then disappears, at which time there is no longer a black hole. If the initial configuration is bound, the shock asymptotes to a maximal radius, whereas for unbound initial configurations the shock escapes to infinity. In all cases, the black hole lifetime is proportional to the square of the black hole mass, and additionally depends on how strongly bound the dust profile is; this last quantity also affects the vacuum region outside the dust profile which is not solely determined by the black hole mass and charge as in spherically symmetric general relativity. We also use numerics to study a wide range of other types of initial configurations, both bound and unbound, with qualitatively similar results.","sentences":["We study gravitational collapse in effective loop quantum gravity, focusing on non-marginally bound configurations in Lema\\^itre-Tolman-Bondi spacetimes.","In the homogeneous limit we recover the effective dynamics of loop quantum cosmology for Friedman cosmologies with spatial curvature.","We study a particular family of configurations with a homogeneous interior and a sharp boundary where the dust energy density rapidly and continuously decreases to zero.","For these configurations, the gravitational collapse continues to the Planck regime when a bounce occurs, at which point the dust ball starts to expand, and a shock wave forms in the gravitational field within the order of a Planck time after the bounce.","The shock slowly moves outwards, eventually reaching the horizon which then disappears, at which time there is no longer a black hole.","If the initial configuration is bound, the shock asymptotes to a maximal radius, whereas for unbound initial configurations the shock escapes to infinity.","In all cases, the black hole lifetime is proportional to the square of the black hole mass, and additionally depends on how strongly bound the dust profile is; this last quantity also affects the vacuum region outside the dust profile which is not solely determined by the black hole mass and charge as in spherically symmetric general relativity.","We also use numerics to study a wide range of other types of initial configurations, both bound and unbound, with qualitatively similar results."],"url":"http://arxiv.org/abs/2404.04192v1","category":"gr-qc"}
{"created":"2024-04-05 16:01:21","title":"Reliable Feature Selection for Adversarially Robust Cyber-Attack Detection","abstract":"The growing cybersecurity threats make it essential to use high-quality data to train Machine Learning (ML) models for network traffic analysis, without noisy or missing data. By selecting the most relevant features for cyber-attack detection, it is possible to improve both the robustness and computational efficiency of the models used in a cybersecurity system. This work presents a feature selection and consensus process that combines multiple methods and applies them to several network datasets. Two different feature sets were selected and were used to train multiple ML models with regular and adversarial training. Finally, an adversarial evasion robustness benchmark was performed to analyze the reliability of the different feature sets and their impact on the susceptibility of the models to adversarial examples. By using an improved dataset with more data diversity, selecting the best time-related features and a more specific feature set, and performing adversarial training, the ML models were able to achieve a better adversarially robust generalization. The robustness of the models was significantly improved without their generalization to regular traffic flows being affected, without increases of false alarms, and without requiring too many computational resources, which enables a reliable detection of suspicious activity and perturbed traffic flows in enterprise computer networks.","sentences":["The growing cybersecurity threats make it essential to use high-quality data to train Machine Learning (ML) models for network traffic analysis, without noisy or missing data.","By selecting the most relevant features for cyber-attack detection, it is possible to improve both the robustness and computational efficiency of the models used in a cybersecurity system.","This work presents a feature selection and consensus process that combines multiple methods and applies them to several network datasets.","Two different feature sets were selected and were used to train multiple ML models with regular and adversarial training.","Finally, an adversarial evasion robustness benchmark was performed to analyze the reliability of the different feature sets and their impact on the susceptibility of the models to adversarial examples.","By using an improved dataset with more data diversity, selecting the best time-related features and a more specific feature set, and performing adversarial training, the ML models were able to achieve a better adversarially robust generalization.","The robustness of the models was significantly improved without their generalization to regular traffic flows being affected, without increases of false alarms, and without requiring too many computational resources, which enables a reliable detection of suspicious activity and perturbed traffic flows in enterprise computer networks."],"url":"http://arxiv.org/abs/2404.04188v1","category":"cs.CR"}
{"created":"2024-04-05 15:59:44","title":"Probabilistically Informed Robot Object Search with Multiple Regions","abstract":"The increasing use of autonomous robot systems in hazardous environments underscores the need for efficient search and rescue operations. Despite significant advancements, existing literature on object search often falls short in overcoming the difficulty of long planning horizons and dealing with sensor limitations, such as noise. This study introduces a novel approach that formulates the search problem as a belief Markov decision processes with options (BMDP-O) to make Monte Carlo tree search (MCTS) a viable tool for overcoming these challenges in large scale environments. The proposed formulation incorporates sequences of actions (options) to move between regions of interest, enabling the algorithm to efficiently scale to large environments. This approach also enables the use of customizable fields of view, for use with multiple types of sensors. Experimental results demonstrate the superiority of this approach in large environments when compared to the problem without options and alternative tools such as receding horizon planners. Given compute time for the proposed formulation is relatively high, a further approximated \"lite\" formulation is proposed. The lite formulation finds objects in a comparable number of steps with faster computation.","sentences":["The increasing use of autonomous robot systems in hazardous environments underscores the need for efficient search and rescue operations.","Despite significant advancements, existing literature on object search often falls short in overcoming the difficulty of long planning horizons and dealing with sensor limitations, such as noise.","This study introduces a novel approach that formulates the search problem as a belief Markov decision processes with options (BMDP-O) to make Monte Carlo tree search (MCTS) a viable tool for overcoming these challenges in large scale environments.","The proposed formulation incorporates sequences of actions (options) to move between regions of interest, enabling the algorithm to efficiently scale to large environments.","This approach also enables the use of customizable fields of view, for use with multiple types of sensors.","Experimental results demonstrate the superiority of this approach in large environments when compared to the problem without options and alternative tools such as receding horizon planners.","Given compute time for the proposed formulation is relatively high, a further approximated \"lite\" formulation is proposed.","The lite formulation finds objects in a comparable number of steps with faster computation."],"url":"http://arxiv.org/abs/2404.04186v1","category":"cs.RO"}
{"created":"2024-04-05 15:52:02","title":"Zak-OTFS for Integration of Sensing and Communication","abstract":"The Zak-OTFS input/output (I/O) relation is predictable and non-fading when the delay and Doppler periods are greater than the effective channel delay and Doppler spreads, a condition which we refer to as the crystallization condition. The filter taps can simply be read off from the response to a single Zak-OTFS point (impulse) pulsone waveform, and the I/O relation can be reconstructed for a sampled system that operates under finite duration and bandwidth constraints. Predictability opens up the possibility of a model-free mode of operation. The time-domain realization of a Zak-OTFS point pulsone is a pulse train modulated by a tone, hence the name, pulsone. The Peak-to-Average Power Ratio (PAPR) of a pulsone is about $15$ dB, and we describe a general method for constructing a spread pulsone for which the time-domain realization has a PAPR of about 6dB. We construct the spread pulsone by applying a type of discrete spreading filter to a Zak-OTFS point pulsone. The self-ambiguity function of the point pulsone is supported on the period lattice ${\\Lambda}_{p}$, and by applying a discrete chirp filter, we obtain a spread pulsone with a self-ambiguity function that is supported on a rotated lattice ${\\Lambda^*}$. We show that if the channel satisfies the crystallization conditions with respect to ${\\Lambda^*}$ then the effective DD domain filter taps can simply be read off from the cross-ambiguity between the channel response to the spread pulsone and the transmitted spread pulsone. If, in addition, the channel satisfies the crystallization conditions with respect to the period lattice ${\\Lambda}_{p}$, then in an OTFS frame consisting of a spread pilot pulsone and point data pulsones, after cancelling the received signal corresponding to the spread pulsone, we can recover the channel response to any data pulsone.","sentences":["The Zak-OTFS input/output (I/O) relation is predictable and non-fading when the delay and Doppler periods are greater than the effective channel delay and Doppler spreads, a condition which we refer to as the crystallization condition.","The filter taps can simply be read off from the response to a single Zak-OTFS point (impulse) pulsone waveform, and the I/O relation can be reconstructed for a sampled system that operates under finite duration and bandwidth constraints.","Predictability opens up the possibility of a model-free mode of operation.","The time-domain realization of a Zak-OTFS point pulsone is a pulse train modulated by a tone, hence the name, pulsone.","The Peak-to-Average Power Ratio (PAPR) of a pulsone is about $15$ dB, and we describe a general method for constructing a spread pulsone for which the time-domain realization has a PAPR of about 6dB.","We construct the spread pulsone by applying a type of discrete spreading filter to a Zak-OTFS point pulsone.","The self-ambiguity function of the point pulsone is supported on the period lattice ${\\Lambda}_{p}$, and by applying a discrete chirp filter, we obtain a spread pulsone with a self-ambiguity function that is supported on a rotated lattice ${\\Lambda^*}$. We show that if the channel satisfies the crystallization conditions with respect to ${\\Lambda^*}$ then the effective DD domain filter taps can simply be read off from the cross-ambiguity between the channel response to the spread pulsone and the transmitted spread pulsone.","If, in addition, the channel satisfies the crystallization conditions with respect to the period lattice ${\\Lambda}_{p}$, then in an OTFS frame consisting of a spread pilot pulsone and point data pulsones, after cancelling the received signal corresponding to the spread pulsone, we can recover the channel response to any data pulsone."],"url":"http://arxiv.org/abs/2404.04182v1","category":"eess.SP"}
{"created":"2024-04-05 15:48:36","title":"SCAResNet: A ResNet Variant Optimized for Tiny Object Detection in Transmission and Distribution Towers","abstract":"Traditional deep learning-based object detection networks often resize images during the data preprocessing stage to achieve a uniform size and scale in the feature map. Resizing is done to facilitate model propagation and fully connected classification. However, resizing inevitably leads to object deformation and loss of valuable information in the images. This drawback becomes particularly pronounced for tiny objects like distribution towers with linear shapes and few pixels. To address this issue, we propose abandoning the resizing operation. Instead, we introduce Positional-Encoding Multi-head Criss-Cross Attention. This allows the model to capture contextual information and learn from multiple representation subspaces, effectively enriching the semantics of distribution towers. Additionally, we enhance Spatial Pyramid Pooling by reshaping three pooled feature maps into a new unified one while also reducing the computational burden. This approach allows images of different sizes and scales to generate feature maps with uniform dimensions and can be employed in feature map propagation. Our SCAResNet incorporates these aforementioned improvements into the backbone network ResNet. We evaluated our SCAResNet using the Electric Transmission and Distribution Infrastructure Imagery dataset from Duke University. Without any additional tricks, we employed various object detection models with Gaussian Receptive Field based Label Assignment as the baseline. When incorporating the SCAResNet into the baseline model, we achieved a 2.1% improvement in mAPs. This demonstrates the advantages of our SCAResNet in detecting transmission and distribution towers and its value in tiny object detection. The source code is available at https://github.com/LisavilaLee/SCAResNet_mmdet.","sentences":["Traditional deep learning-based object detection networks often resize images during the data preprocessing stage to achieve a uniform size and scale in the feature map.","Resizing is done to facilitate model propagation and fully connected classification.","However, resizing inevitably leads to object deformation and loss of valuable information in the images.","This drawback becomes particularly pronounced for tiny objects like distribution towers with linear shapes and few pixels.","To address this issue, we propose abandoning the resizing operation.","Instead, we introduce Positional-Encoding Multi-head Criss-Cross Attention.","This allows the model to capture contextual information and learn from multiple representation subspaces, effectively enriching the semantics of distribution towers.","Additionally, we enhance Spatial Pyramid Pooling by reshaping three pooled feature maps into a new unified one while also reducing the computational burden.","This approach allows images of different sizes and scales to generate feature maps with uniform dimensions and can be employed in feature map propagation.","Our SCAResNet incorporates these aforementioned improvements into the backbone network ResNet.","We evaluated our SCAResNet using the Electric Transmission and Distribution Infrastructure Imagery dataset from Duke University.","Without any additional tricks, we employed various object detection models with Gaussian Receptive Field based Label Assignment as the baseline.","When incorporating the SCAResNet into the baseline model, we achieved a 2.1% improvement in mAPs.","This demonstrates the advantages of our SCAResNet in detecting transmission and distribution towers and its value in tiny object detection.","The source code is available at https://github.com/LisavilaLee/SCAResNet_mmdet."],"url":"http://arxiv.org/abs/2404.04179v1","category":"cs.CV"}
{"created":"2024-04-05 15:38:26","title":"Gravitational lensing by a Lorentz-violating black hole","abstract":"In this work, we study the gravitational lensing by a Lorentz-violating (LV) black hole inspired by the recent contribution [1]. Explicitly, we concentrate on a specific application: we perform the computation of gravitational lensing effects under the strong field limit. In particular, we analytically derive the deflection angle so that the lens equation can also be addressed. This methodological approach yields physically measurable outcomes, including the determination of relativistic image positions and their corresponding magnifications. As an application of this methodology, we consider the gravitational lensing by Sagittarius A${}^*$ and obtain the corresponding observables expressed as functions of the LV parameter.","sentences":["In this work, we study the gravitational lensing by a Lorentz-violating (LV) black hole inspired by the recent contribution [1].","Explicitly, we concentrate on a specific application: we perform the computation of gravitational lensing effects under the strong field limit.","In particular, we analytically derive the deflection angle so that the lens equation can also be addressed.","This methodological approach yields physically measurable outcomes, including the determination of relativistic image positions and their corresponding magnifications.","As an application of this methodology, we consider the gravitational lensing by Sagittarius A${}^*$ and obtain the corresponding observables expressed as functions of the LV parameter."],"url":"http://arxiv.org/abs/2404.04176v1","category":"gr-qc"}
{"created":"2024-04-05 15:33:00","title":"Adaptive generalized conditional gradient method for multiobjective optimization","abstract":"In this paper, we propose a generalized conditional gradient method for multiobjective optimization, which can be viewed as an improved extension of the classical Frank-Wolfe (conditional gradient) method for single-objective optimization. The proposed method works for both constrained and unconstrained benchmark multiobjective optimization problems, where the objective function is the summation of a smooth function and a possibly nonsmooth convex function. The method combines the so-called normalized descent direction as an adaptive procedure and the line search technique. We prove the convergence of the algorithm with respect to Pareto optimality under mild assumptions. The iteration complexity for obtaining an approximate Pareto critical point and the convergence rate in terms of a merit function is also analyzed. Finally, we report some numerical results, which demonstrate the feasibility and competitiveness of the proposed method.","sentences":["In this paper, we propose a generalized conditional gradient method for multiobjective optimization, which can be viewed as an improved extension of the classical Frank-Wolfe (conditional gradient) method for single-objective optimization.","The proposed method works for both constrained and unconstrained benchmark multiobjective optimization problems, where the objective function is the summation of a smooth function and a possibly nonsmooth convex function.","The method combines the so-called normalized descent direction as an adaptive procedure and the line search technique.","We prove the convergence of the algorithm with respect to Pareto optimality under mild assumptions.","The iteration complexity for obtaining an approximate Pareto critical point and the convergence rate in terms of a merit function is also analyzed.","Finally, we report some numerical results, which demonstrate the feasibility and competitiveness of the proposed method."],"url":"http://arxiv.org/abs/2404.04174v1","category":"math.OC"}
{"created":"2024-04-05 15:22:02","title":"Do Sentence Transformers Learn Quasi-Geospatial Concepts from General Text?","abstract":"Sentence transformers are language models designed to perform semantic search. This study investigates the capacity of sentence transformers, fine-tuned on general question-answering datasets for asymmetric semantic search, to associate descriptions of human-generated routes across Great Britain with queries often used to describe hiking experiences. We find that sentence transformers have some zero-shot capabilities to understand quasi-geospatial concepts, such as route types and difficulty, suggesting their potential utility for routing recommendation systems.","sentences":["Sentence transformers are language models designed to perform semantic search.","This study investigates the capacity of sentence transformers, fine-tuned on general question-answering datasets for asymmetric semantic search, to associate descriptions of human-generated routes across Great Britain with queries often used to describe hiking experiences.","We find that sentence transformers have some zero-shot capabilities to understand quasi-geospatial concepts, such as route types and difficulty, suggesting their potential utility for routing recommendation systems."],"url":"http://arxiv.org/abs/2404.04169v1","category":"cs.CL"}
{"created":"2024-04-05 15:20:31","title":"Jet angularities in dijet production in proton-proton and heavy-ion collisions at RHIC","abstract":"We study jet angularities for dijet production at the Relativistic Heavy Ion Collider (RHIC) in proton-proton (pp) and nucleus-nucleus (AA) collisions at 200 GeV nucleon-nucleon center-of-mass collision energy. In particular, we provide $\\mathrm{NLL}$ resummed predictions for angularity observables of groomed and ungroomed jets produced in $\\rm pp$ collisions matched to next-to-leading order QCD calculations resulting in $\\mathrm{NLO+NLL^\\prime}$ accuracy. Our parton-level predictions are corrected for non-perturbative effects, such as hadronization and underlying event, using parton-to-hadron level transfer matrices obtained with the Sherpa event generator. Furthermore, we use the Q-Pythia and JEWEL generators to estimate the impact of the interaction between quarks and gluons produced by the parton shower with the dense medium formed in heavy-ion collisions on the considered jet angularities.","sentences":["We study jet angularities for dijet production at the Relativistic Heavy Ion Collider (RHIC) in proton-proton (pp) and nucleus-nucleus (AA) collisions at 200 GeV nucleon-nucleon center-of-mass collision energy.","In particular, we provide $\\mathrm{NLL}$ resummed predictions for angularity observables of groomed and ungroomed jets produced in $\\rm pp$ collisions matched to next-to-leading order QCD calculations resulting in $\\mathrm{NLO+NLL^\\prime}$ accuracy.","Our parton-level predictions are corrected for non-perturbative effects, such as hadronization and underlying event, using parton-to-hadron level transfer matrices obtained with the Sherpa event generator.","Furthermore, we use the Q-Pythia and JEWEL generators to estimate the impact of the interaction between quarks and gluons produced by the parton shower with the dense medium formed in heavy-ion collisions on the considered jet angularities."],"url":"http://arxiv.org/abs/2404.04168v1","category":"hep-ph"}
{"created":"2024-04-05 15:20:02","title":"Chinese Tiny LLM: Pretraining a Chinese-Centric Large Language Model","abstract":"In this study, we introduce CT-LLM, a 2B large language model (LLM) that illustrates a pivotal shift towards prioritizing the Chinese language in developing LLMs. Uniquely initiated from scratch, CT-LLM diverges from the conventional methodology by primarily incorporating Chinese textual data, utilizing an extensive corpus of 1,200 billion tokens, including 800 billion Chinese tokens, 300 billion English tokens, and 100 billion code tokens. This strategic composition facilitates the model's exceptional proficiency in understanding and processing Chinese, a capability further enhanced through alignment techniques. Demonstrating remarkable performance on the CHC-Bench, CT-LLM excels in Chinese language tasks, and showcases its adeptness in English through SFT. This research challenges the prevailing paradigm of training LLMs predominantly on English corpora and then adapting them to other languages, broadening the horizons for LLM training methodologies. By open-sourcing the full process of training a Chinese LLM, including a detailed data processing procedure with the obtained Massive Appropriate Pretraining Chinese Corpus (MAP-CC), a well-chosen multidisciplinary Chinese Hard Case Benchmark (CHC-Bench), and the 2B-size Chinese Tiny LLM (CT-LLM), we aim to foster further exploration and innovation in both academia and industry, paving the way for more inclusive and versatile language models.","sentences":["In this study, we introduce CT-LLM, a 2B large language model (LLM) that illustrates a pivotal shift towards prioritizing the Chinese language in developing LLMs.","Uniquely initiated from scratch, CT-LLM diverges from the conventional methodology by primarily incorporating Chinese textual data, utilizing an extensive corpus of 1,200 billion tokens, including 800 billion Chinese tokens, 300 billion English tokens, and 100 billion code tokens.","This strategic composition facilitates the model's exceptional proficiency in understanding and processing Chinese, a capability further enhanced through alignment techniques.","Demonstrating remarkable performance on the CHC-Bench, CT-LLM excels in Chinese language tasks, and showcases its adeptness in English through SFT.","This research challenges the prevailing paradigm of training LLMs predominantly on English corpora and then adapting them to other languages, broadening the horizons for LLM training methodologies.","By open-sourcing the full process of training a Chinese LLM, including a detailed data processing procedure with the obtained Massive Appropriate Pretraining Chinese Corpus (MAP-CC), a well-chosen multidisciplinary Chinese Hard Case Benchmark (CHC-Bench), and the 2B-size Chinese Tiny LLM (CT-LLM), we aim to foster further exploration and innovation in both academia and industry, paving the way for more inclusive and versatile language models."],"url":"http://arxiv.org/abs/2404.04167v1","category":"cs.CL"}
{"created":"2024-04-05 15:19:54","title":"Even-carry polynomials and cohomology of line bundles on the incidence correspondence in positive characteristic","abstract":"We consider the cohomology groups of line bundles $\\mathcal{L}$ on the \\emph{incidence correspondence}, that is, a general hypersurface $X \\subset \\mathbb{P}^{n-1} \\times \\mathbb{P}^{n-1}$ of degrees $(1,1)$. Whereas the characteristic $0$ situation is completely understood, the cohomology in characteristic $p$ depends in a mysterious way on the base-$p$ digits of the degrees $(d, e)$ of $\\mathcal{L}$. Gao and Raicu (following Linyuan Liu) prove a recursive description of the cohomology for $n = 3$, which relates to Nim polynomials when $p = 2$. In this paper, we devise a suitable generalization of Nim polynomials, which we call \\emph{even-carry polynomials,} by which we can solve the recurrence of Liu--Gao--Raicu to yield an explicit formula for the cohomology for $n = 3$ and general $p$. We also make some conjectures on the general form of the cohomology for general $n$ and $p$.","sentences":["We consider the cohomology groups of line bundles $\\mathcal{L}$ on the \\emph{incidence correspondence}, that is, a general hypersurface $X \\subset \\mathbb{P}^{n-1} \\times \\mathbb{P}^{n-1}$ of degrees $(1,1)$. Whereas the characteristic $0$ situation is completely understood, the cohomology in characteristic $p$ depends in a mysterious way on the base-$p$ digits of the degrees $(d, e)$ of $\\mathcal{L}$. Gao and Raicu (following Linyuan Liu) prove a recursive description of the cohomology for $n = 3$, which relates to Nim polynomials when $p = 2$.","In this paper, we devise a suitable generalization of Nim polynomials, which we call \\emph{even-carry polynomials,} by which we can solve the recurrence of Liu--Gao--Raicu to yield an explicit formula for the cohomology for $n = 3$ and general $p$. We also make some conjectures on the general form of the cohomology for general $n$ and $p$."],"url":"http://arxiv.org/abs/2404.04166v1","category":"math.AG"}
{"created":"2024-04-05 15:16:16","title":"Dwell in the Beginning: How Language Models Embed Long Documents for Dense Retrieval","abstract":"This study investigates the existence of positional biases in Transformer-based models for text representation learning, particularly in the context of web document retrieval. We build on previous research that demonstrated loss of information in the middle of input sequences for causal language models, extending it to the domain of representation learning. We examine positional biases at various stages of training for an encoder-decoder model, including language model pre-training, contrastive pre-training, and contrastive fine-tuning. Experiments with the MS-MARCO document collection reveal that after contrastive pre-training the model already generates embeddings that better capture early contents of the input, with fine-tuning further aggravating this effect.","sentences":["This study investigates the existence of positional biases in Transformer-based models for text representation learning, particularly in the context of web document retrieval.","We build on previous research that demonstrated loss of information in the middle of input sequences for causal language models, extending it to the domain of representation learning.","We examine positional biases at various stages of training for an encoder-decoder model, including language model pre-training, contrastive pre-training, and contrastive fine-tuning.","Experiments with the MS-MARCO document collection reveal that after contrastive pre-training the model already generates embeddings that better capture early contents of the input, with fine-tuning further aggravating this effect."],"url":"http://arxiv.org/abs/2404.04163v1","category":"cs.IR"}
{"created":"2024-04-05 15:12:08","title":"Optimal rigidity estimates for varifolds almost minimizing the Willmore energy","abstract":"For an integral $2$-varifold $V=\\underline{v}(\\Sigma,\\theta_{\\ge 1})$ in $\\mathbb{R}^n$ with generalized mean curvature $H\\in L^2$ such that $\\mu(\\mathbb{R}^n)=4\\pi$ and $\\int_{\\Sigma}|H|^2d\\mu\\le 16\\pi(1+\\delta^2)$ , we show that $\\Sigma$ is $W^{2,2}$ close to the standard embedding of the round sphere in a quantitative way when $\\delta< \\delta_0\\ll 1$. For $n=3$, we prove that the sharp constant is $\\delta_0^2=2\\pi$.","sentences":["For an integral $2$-varifold $V=\\underline{v}(\\Sigma,\\theta_{\\ge 1})$ in $\\mathbb{R}^n$ with generalized mean curvature $H\\in L^2$ such that $\\mu(\\mathbb{R}^n)=4\\pi$ and $\\int_{\\Sigma}|H|^2d\\mu\\le 16\\pi(1+\\delta^2)$ , we show that $\\Sigma$ is $W^{2,2}$ close to the standard embedding of the round sphere in a quantitative way when $\\delta< \\delta_0\\ll 1$. For $n=3$, we prove that the sharp constant is $\\delta_0^2=2\\pi$."],"url":"http://arxiv.org/abs/2404.04160v1","category":"math.DG"}
{"created":"2024-04-05 15:11:09","title":"Noisy Label Processing for Classification: A Survey","abstract":"In recent years, deep neural networks (DNNs) have gained remarkable achievement in computer vision tasks, and the success of DNNs often depends greatly on the richness of data. However, the acquisition process of data and high-quality ground truth requires a lot of manpower and money. In the long, tedious process of data annotation, annotators are prone to make mistakes, resulting in incorrect labels of images, i.e., noisy labels. The emergence of noisy labels is inevitable. Moreover, since research shows that DNNs can easily fit noisy labels, the existence of noisy labels will cause significant damage to the model training process. Therefore, it is crucial to combat noisy labels for computer vision tasks, especially for classification tasks. In this survey, we first comprehensively review the evolution of different deep learning approaches for noisy label combating in the image classification task. In addition, we also review different noise patterns that have been proposed to design robust algorithms. Furthermore, we explore the inner pattern of real-world label noise and propose an algorithm to generate a synthetic label noise pattern guided by real-world data. We test the algorithm on the well-known real-world dataset CIFAR-10N to form a new real-world data-guided synthetic benchmark and evaluate some typical noise-robust methods on the benchmark.","sentences":["In recent years, deep neural networks (DNNs) have gained remarkable achievement in computer vision tasks, and the success of DNNs often depends greatly on the richness of data.","However, the acquisition process of data and high-quality ground truth requires a lot of manpower and money.","In the long, tedious process of data annotation, annotators are prone to make mistakes, resulting in incorrect labels of images, i.e., noisy labels.","The emergence of noisy labels is inevitable.","Moreover, since research shows that DNNs can easily fit noisy labels, the existence of noisy labels will cause significant damage to the model training process.","Therefore, it is crucial to combat noisy labels for computer vision tasks, especially for classification tasks.","In this survey, we first comprehensively review the evolution of different deep learning approaches for noisy label combating in the image classification task.","In addition, we also review different noise patterns that have been proposed to design robust algorithms.","Furthermore, we explore the inner pattern of real-world label noise and propose an algorithm to generate a synthetic label noise pattern guided by real-world data.","We test the algorithm on the well-known real-world dataset CIFAR-10N to form a new real-world data-guided synthetic benchmark and evaluate some typical noise-robust methods on the benchmark."],"url":"http://arxiv.org/abs/2404.04159v1","category":"cs.CV"}
{"created":"2024-04-05 14:53:20","title":"Dissipative particle systems on expanders","abstract":"We consider a general framework for multi-type interacting particle systems on graphs, where particles move one at a time by random walk steps, different types may have different speeds, and may interact, possibly randomly, when they meet. We study the equilibrium time of the process, by which we mean the number of steps taken until no further interactions can occur. Under a rather general framework, we obtain high probability upper and lower bounds on the equilibrium time that match up to a constant factor and are of order $n\\log n$ if there are order $n$ vertices and particles. We also obtain similar results for the balanced two-type annihilation model of chemical reactions; here, the balanced case (equal density of types) does not fit into our general framework and makes the analysis considerably more difficult. Our models do not admit any exact solution as for integrable systems or the duality approach available for some other particle systems, so we develop a variety of combinatorial tools for comparing processes in the absence of monotonicity.","sentences":["We consider a general framework for multi-type interacting particle systems on graphs, where particles move one at a time by random walk steps, different types may have different speeds, and may interact, possibly randomly, when they meet.","We study the equilibrium time of the process, by which we mean the number of steps taken until no further interactions can occur.","Under a rather general framework, we obtain high probability upper and lower bounds on the equilibrium time that match up to a constant factor and are of order $n\\log n$ if there are order $n$ vertices and particles.","We also obtain similar results for the balanced two-type annihilation model of chemical reactions; here, the balanced case (equal density of types) does not fit into our general framework and makes the analysis considerably more difficult.","Our models do not admit any exact solution as for integrable systems or the duality approach available for some other particle systems, so we develop a variety of combinatorial tools for comparing processes in the absence of monotonicity."],"url":"http://arxiv.org/abs/2404.04149v1","category":"math.PR"}
{"created":"2024-04-05 14:48:29","title":"A robust approach with numerical demonstrations for the inverse scattering problem using a Carleman contraction map","abstract":"This paper addresses the inverse scattering problem in the domain Omega. The input data, measured outside Omega, involve the waves generated by the interaction of plane waves with various directions and unknown scatterers fully occluded inside Omega. The output of this problem is the spatially dielectric constant of these scatterers. Our approach to solving this problem consists of two primary stages. Initially, we eliminate the unknown dielectric constant from the governing equation, resulting in a system of partial differential equations. Subsequently, we develop the Carleman contraction mapping method to effectively tackle this system. It is noteworthy to highlight this method's robustness. It does not request a precise initial guess of the true solution, and its computational cost is not expensive. Some numerical examples are presented.","sentences":["This paper addresses the inverse scattering problem in the domain Omega.","The input data, measured outside Omega, involve the waves generated by the interaction of plane waves with various directions and unknown scatterers fully occluded inside Omega.","The output of this problem is the spatially dielectric constant of these scatterers.","Our approach to solving this problem consists of two primary stages.","Initially, we eliminate the unknown dielectric constant from the governing equation, resulting in a system of partial differential equations.","Subsequently, we develop the Carleman contraction mapping method to effectively tackle this system.","It is noteworthy to highlight this method's robustness.","It does not request a precise initial guess of the true solution, and its computational cost is not expensive.","Some numerical examples are presented."],"url":"http://arxiv.org/abs/2404.04145v1","category":"math.NA"}
{"created":"2024-04-05 14:43:51","title":"Quadratic Rastall Gravity: from low-mass HESS J1731-347 to high-mass PSR J0952-0607 pulsars","abstract":"Similar to Rastall gravity we introduce matter-geometry nonminimal coupling which is proportional to the gradient of quadratic curvature invariants. Those are mimicking the conformal trace anomaly when backreaction of the quantum fields to a curved spacetime geometry is considered. We consider a static spherically symmetric stellar structure with anisotropic fluid and Krori-Barua metric potentials model to examine the theory. Confronting the model with NICER+XMM-Newton observational constraints on the pulsar PSR J0740$+$6620 quantifies the amount of the nonminimal coupling via a dimensionless parameter $\\epsilon\\simeq -0.01$. We verify that the conformal symmetry is broken everywhere inside the pulsar as the trace anomaly $\\Delta>0$, or equivalently the trace of the stress-energy tensor $\\mathfrak{T}<0$, whereas the adiabatic sound speed does not violate the conjecture conformal upper limit $v_r^2/c^2 = 1/3$. The maximum compactness accordingly is $C_\\text{max}=0.752$ which is $4\\%$ higher than GR. Notably, if the conformal sound speed constraint is hold, observational data excludes $\\epsilon \\geq 0$ up to $\\geq 1.6\\sigma$. The stellar model is consistent with the self-bound structure with soft linear equation of state. Investigating possible connection with MIT bag model of strange quarks sets physical bounds from microscopic physics which confirm the negative value of the parameter $\\epsilon$. We estimate a radius $R=13.21 \\pm 0.96$ km of the most massive observed compact star PSR J0952$-$0607 with $M=2.35\\pm0.17 M_\\odot$. Finally, we show that the corresponding mass-radius diagram fits well lowest-mass pulsar HESS J1731$-$347 and highest-mass pulsar PSR J0952$-$0607 ever observed as well as the intermediate mass range as obtained by NICER and LIGO/Virgo observations.","sentences":["Similar to Rastall gravity we introduce matter-geometry nonminimal coupling which is proportional to the gradient of quadratic curvature invariants.","Those are mimicking the conformal trace anomaly when backreaction of the quantum fields to a curved spacetime geometry is considered.","We consider a static spherically symmetric stellar structure with anisotropic fluid and Krori-Barua metric potentials model to examine the theory.","Confronting the model with NICER+XMM-Newton observational constraints on the pulsar PSR J0740$+$6620 quantifies the amount of the nonminimal coupling via a dimensionless parameter $\\epsilon\\simeq -0.01$.","We verify that the conformal symmetry is broken everywhere inside the pulsar as the trace anomaly $\\Delta>0$, or equivalently the trace of the stress-energy tensor $\\mathfrak{T}<0$, whereas the adiabatic sound speed does not violate the conjecture conformal upper limit $v_r^2/c^2 = 1/3$.","The maximum compactness accordingly is $C_\\text{max}=0.752$ which is $4\\%$ higher than GR.","Notably, if the conformal sound speed constraint is hold, observational data excludes $\\epsilon \\geq 0$ up to $\\geq 1.6\\sigma$.","The stellar model is consistent with the self-bound structure with soft linear equation of state.","Investigating possible connection with MIT bag model of strange quarks sets physical bounds from microscopic physics which confirm the negative value of the parameter $\\epsilon$. We estimate a radius $R=13.21 \\pm 0.96$ km of the most massive observed compact star PSR J0952$-$0607 with $M=2.35\\pm0.17 M_\\odot$. Finally, we show that the corresponding mass-radius diagram fits well lowest-mass pulsar HESS J1731$-$347 and highest-mass pulsar PSR J0952$-$0607 ever observed as well as the intermediate mass range as obtained by NICER and LIGO/Virgo observations."],"url":"http://arxiv.org/abs/2404.04143v1","category":"astro-ph.HE"}
{"created":"2024-04-05 14:37:49","title":"Precision Guided Approach to Mitigate Data Poisoning Attacks in Federated Learning","abstract":"Federated Learning (FL) is a collaborative learning paradigm enabling participants to collectively train a shared machine learning model while preserving the privacy of their sensitive data. Nevertheless, the inherent decentralized and data-opaque characteristics of FL render its susceptibility to data poisoning attacks. These attacks introduce malformed or malicious inputs during local model training, subsequently influencing the global model and resulting in erroneous predictions. Current FL defense strategies against data poisoning attacks either involve a trade-off between accuracy and robustness or necessitate the presence of a uniformly distributed root dataset at the server. To overcome these limitations, we present FedZZ, which harnesses a zone-based deviating update (ZBDU) mechanism to effectively counter data poisoning attacks in FL. Further, we introduce a precision-guided methodology that actively characterizes these client clusters (zones), which in turn aids in recognizing and discarding malicious updates at the server. Our evaluation of FedZZ across two widely recognized datasets: CIFAR10 and EMNIST, demonstrate its efficacy in mitigating data poisoning attacks, surpassing the performance of prevailing state-of-the-art methodologies in both single and multi-client attack scenarios and varying attack volumes. Notably, FedZZ also functions as a robust client selection strategy, even in highly non-IID and attack-free scenarios. Moreover, in the face of escalating poisoning rates, the model accuracy attained by FedZZ displays superior resilience compared to existing techniques. For instance, when confronted with a 50% presence of malicious clients, FedZZ sustains an accuracy of 67.43%, while the accuracy of the second-best solution, FL-Defender, diminishes to 43.36%.","sentences":["Federated Learning (FL) is a collaborative learning paradigm enabling participants to collectively train a shared machine learning model while preserving the privacy of their sensitive data.","Nevertheless, the inherent decentralized and data-opaque characteristics of FL render its susceptibility to data poisoning attacks.","These attacks introduce malformed or malicious inputs during local model training, subsequently influencing the global model and resulting in erroneous predictions.","Current FL defense strategies against data poisoning attacks either involve a trade-off between accuracy and robustness or necessitate the presence of a uniformly distributed root dataset at the server.","To overcome these limitations, we present FedZZ, which harnesses a zone-based deviating update (ZBDU) mechanism to effectively counter data poisoning attacks in FL.","Further, we introduce a precision-guided methodology that actively characterizes these client clusters (zones), which in turn aids in recognizing and discarding malicious updates at the server.","Our evaluation of FedZZ across two widely recognized datasets: CIFAR10 and EMNIST, demonstrate its efficacy in mitigating data poisoning attacks, surpassing the performance of prevailing state-of-the-art methodologies in both single and multi-client attack scenarios and varying attack volumes.","Notably, FedZZ also functions as a robust client selection strategy, even in highly non-IID and attack-free scenarios.","Moreover, in the face of escalating poisoning rates, the model accuracy attained by FedZZ displays superior resilience compared to existing techniques.","For instance, when confronted with a 50% presence of malicious clients, FedZZ sustains an accuracy of 67.43%, while the accuracy of the second-best solution, FL-Defender, diminishes to 43.36%."],"url":"http://arxiv.org/abs/2404.04139v1","category":"cs.CR"}
{"created":"2024-04-05 14:35:39","title":"Rare events, time crystals and symmetry-breaking dynamical phase transitions","abstract":"In this PhD thesis, I investigate the properties of symmetry-breaking dynamical phase transitions that manifest in the fluctuations of time-integrated observables within classical systems. In particular, I analyze how these phase transitions impose stringent constraints on the structure of the eigenvectors of the system dynamical generator of the dynamics. Additionally, I identify a dynamical phase transition to a time-crystal phase in a model of driven-diffusive lattice gas. The study of this transition then allows the identification of the \"packing-field\" mechanism responsible for its emergence. This mechanism is then exploited to propose new transport models displaying time-crystal behavior.","sentences":["In this PhD thesis, I investigate the properties of symmetry-breaking dynamical phase transitions that manifest in the fluctuations of time-integrated observables within classical systems.","In particular, I analyze how these phase transitions impose stringent constraints on the structure of the eigenvectors of the system dynamical generator of the dynamics.","Additionally, I identify a dynamical phase transition to a time-crystal phase in a model of driven-diffusive lattice gas.","The study of this transition then allows the identification of the \"packing-field\" mechanism responsible for its emergence.","This mechanism is then exploited to propose new transport models displaying time-crystal behavior."],"url":"http://arxiv.org/abs/2404.04135v1","category":"cond-mat.stat-mech"}
{"created":"2024-04-05 14:29:24","title":"Strong magneto-optical responses of an ensemble of defect-bound excitons in aged WS$_{2}$ and WSe$_{2}$ monolayers","abstract":"Transition metal dichalcogenide (TMD) monolayers present a singular coupling in their spin and valley degrees of freedom. Moreover, by applying an external magnetic field it is possible to break the energy degeneracy between their K and $-$K valleys. Thus, this analogous valley Zeeman effect opens the possibility of controlling and distinguishing the spin and valley of charge carriers in TMDs by their optical transition energies, making these materials promising for the next generation of spintronic and photonic devices. However, the free excitons of pristine TMD monolayer samples present a moderate valley Zeeman splitting, which is measured by their g-factor values that are approximately $-4$. Therefore, for application purposes it is mandatory alternative excitonic states with higher magnetic responses. Here we investigate the valley Zeeman effect in aged WS$_{2}$ and WSe$_{2}$ grown monolayers by magneto-photoluminescence measurements at cryogenic temperatures. These samples present a lower energy defect-bound exciton emission related to defects adsorbed during the aging process. While the free excitons of these samples exhibit g-factors between $-3$ and $-4$, their defect-bound excitons present giant effective g-factor values of $-(25.0 \\pm 0.2)$ and $-(19.1 \\pm 0.2)$ for WS$_{2}$ and WSe$_{2}$ aged monolayers, respectively. In addition, we observe a significant spin polarization of charge carriers in the defective mid gap states induced by the external magnetic fields. We explain this spin polarized population in terms of a spin-flip transition mechanism, which is also responsible for the magnetic dependent light emission of the defect-bound exciton states. Our work sheds light in the potential of aged TMDs as candidates for spintronic based devices.","sentences":["Transition metal dichalcogenide (TMD) monolayers present a singular coupling in their spin and valley degrees of freedom.","Moreover, by applying an external magnetic field it is possible to break the energy degeneracy between their K and $-$K valleys.","Thus, this analogous valley Zeeman effect opens the possibility of controlling and distinguishing the spin and valley of charge carriers in TMDs by their optical transition energies, making these materials promising for the next generation of spintronic and photonic devices.","However, the free excitons of pristine TMD monolayer samples present a moderate valley Zeeman splitting, which is measured by their g-factor values that are approximately $-4$. Therefore, for application purposes it is mandatory alternative excitonic states with higher magnetic responses.","Here we investigate the valley Zeeman effect in aged WS$_{2}$ and WSe$_{2}$ grown monolayers by magneto-photoluminescence measurements at cryogenic temperatures.","These samples present a lower energy defect-bound exciton emission related to defects adsorbed during the aging process.","While the free excitons of these samples exhibit g-factors between $-3$ and $-4$, their defect-bound excitons present giant effective g-factor values of $-(25.0 \\pm 0.2)$ and $-(19.1 \\pm 0.2)$ for WS$_{2}$ and WSe$_{2}$ aged monolayers, respectively.","In addition, we observe a significant spin polarization of charge carriers in the defective mid gap states induced by the external magnetic fields.","We explain this spin polarized population in terms of a spin-flip transition mechanism, which is also responsible for the magnetic dependent light emission of the defect-bound exciton states.","Our work sheds light in the potential of aged TMDs as candidates for spintronic based devices."],"url":"http://arxiv.org/abs/2404.04131v1","category":"cond-mat.mes-hall"}
{"created":"2024-04-05 14:23:43","title":"Generalizable Temperature Nowcasting with Physics-Constrained RNNs for Predictive Maintenance of Wind Turbine Components","abstract":"Machine learning plays an important role in the operation of current wind energy production systems. One central application is predictive maintenance to increase efficiency and lower electricity costs by reducing downtimes. Integrating physics-based knowledge in neural networks to enforce their physical plausibilty is a promising method to improve current approaches, but incomplete system information often impedes their application in real world scenarios. We describe a simple and efficient way for physics-constrained deep learning-based predictive maintenance for wind turbine gearbox bearings with partial system knowledge. The approach is based on temperature nowcasting constrained by physics, where unknown system coefficients are treated as learnable neural network parameters. Results show improved generalization performance to unseen environments compared to a baseline neural network, which is especially important in low data scenarios often encountered in real-world applications.","sentences":["Machine learning plays an important role in the operation of current wind energy production systems.","One central application is predictive maintenance to increase efficiency and lower electricity costs by reducing downtimes.","Integrating physics-based knowledge in neural networks to enforce their physical plausibilty is a promising method to improve current approaches, but incomplete system information often impedes their application in real world scenarios.","We describe a simple and efficient way for physics-constrained deep learning-based predictive maintenance for wind turbine gearbox bearings with partial system knowledge.","The approach is based on temperature nowcasting constrained by physics, where unknown system coefficients are treated as learnable neural network parameters.","Results show improved generalization performance to unseen environments compared to a baseline neural network, which is especially important in low data scenarios often encountered in real-world applications."],"url":"http://arxiv.org/abs/2404.04126v1","category":"cs.LG"}
{"created":"2024-04-05 14:19:20","title":"The global bifurcation of periodic internal waves with point vortex and capillary effect","abstract":"In this paper, we first construct two-dimensional periodic interface waves with point vortex and capillary effect and then obtain the global structure of the set of solutions. This is done using the local and global bifurcation argument. Especially, we establish a global continuation theorem by using the degree for $C^1$ Fredholm mappings. As far as we know, the global result is new and general, which is promising to deal with other new phenomena in water waves.","sentences":["In this paper, we first construct two-dimensional periodic interface waves with point vortex and capillary effect and then obtain the global structure of the set of solutions.","This is done using the local and global bifurcation argument.","Especially, we establish a global continuation theorem by using the degree for $C^1$ Fredholm mappings.","As far as we know, the global result is new and general, which is promising to deal with other new phenomena in water waves."],"url":"http://arxiv.org/abs/2404.04119v1","category":"math.AP"}
{"created":"2024-04-05 14:16:37","title":"Meyer sets, Pisot numbers, and self-similarity in symbolic dynamical systems","abstract":"Aperiodic order refers to the mathematical formalisation of quasicrystals. Substitutions and cut and project sets are among their main actors; they also play a key role in the study of dynamical systems, whether they are symbolic, generated by tilings, or point sets. We focus here on the relations between quasicrystals and self-similarity from an arithmetical and dynamical viewpoint, illustrating how efficiently aperiodic order irrigates various domains of mathematics and theoretical computer science, on a journey from Diophantine approximation to computability theory. In particular, we see how Pisot numbers allow the definition of simple model sets, and how they also intervene for scaling factors for invariance by multiplication of Meyer sets. We focus in particular on the characterisation due to Yves Meyer: any Pisot or Salem number is a parameter of dilation that preserves some Meyer set.","sentences":["Aperiodic order refers to the mathematical formalisation of quasicrystals.","Substitutions and cut and project sets are among their main actors; they also play a key role in the study of dynamical systems, whether they are symbolic, generated by tilings, or point sets.","We focus here on the relations between quasicrystals and self-similarity from an arithmetical and dynamical viewpoint, illustrating how efficiently aperiodic order irrigates various domains of mathematics and theoretical computer science, on a journey from Diophantine approximation to computability theory.","In particular, we see how Pisot numbers allow the definition of simple model sets, and how they also intervene for scaling factors for invariance by multiplication of Meyer sets.","We focus in particular on the characterisation due to Yves Meyer: any Pisot or Salem number is a parameter of dilation that preserves some Meyer set."],"url":"http://arxiv.org/abs/2404.04116v1","category":"math.DS"}
{"created":"2024-04-05 14:04:07","title":"Large language models as oracles for instantiating ontologies with domain-specific knowledge","abstract":"Background. Endowing intelligent systems with semantic data commonly requires designing and instantiating ontologies with domain-specific knowledge. Especially in the early phases, those activities are typically performed manually by human experts possibly leveraging on their own experience. The resulting process is therefore time-consuming, error-prone, and often biased by the personal background of the ontology designer. Objective. To mitigate that issue, we propose a novel domain-independent approach to automatically instantiate ontologies with domain-specific knowledge, by leveraging on large language models (LLMs) as oracles. Method. Starting from (i) an initial schema composed by inter-related classes andproperties and (ii) a set of query templates, our method queries the LLM multi- ple times, and generates instances for both classes and properties from its replies. Thus, the ontology is automatically filled with domain-specific knowledge, compliant to the initial schema. As a result, the ontology is quickly and automatically enriched with manifold instances, which experts may consider to keep, adjust, discard, or complement according to their own needs and expertise. Contribution. We formalise our method in general way and instantiate it over various LLMs, as well as on a concrete case study. We report experiments rooted in the nutritional domain where an ontology of food meals and their ingredients is semi-automatically instantiated from scratch, starting from a categorisation of meals and their relationships. There, we analyse the quality of the generated ontologies and compare ontologies attained by exploiting different LLMs. Finally, we provide a SWOT analysis of the proposed method.","sentences":["Background.","Endowing intelligent systems with semantic data commonly requires designing and instantiating ontologies with domain-specific knowledge.","Especially in the early phases, those activities are typically performed manually by human experts possibly leveraging on their own experience.","The resulting process is therefore time-consuming, error-prone, and often biased by the personal background of the ontology designer.","Objective.","To mitigate that issue, we propose a novel domain-independent approach to automatically instantiate ontologies with domain-specific knowledge, by leveraging on large language models (LLMs) as oracles.","Method.","Starting from (i) an initial schema composed by inter-related classes andproperties and (ii) a set of query templates, our method queries the LLM multi- ple times, and generates instances for both classes and properties from its replies.","Thus, the ontology is automatically filled with domain-specific knowledge, compliant to the initial schema.","As a result, the ontology is quickly and automatically enriched with manifold instances, which experts may consider to keep, adjust, discard, or complement according to their own needs and expertise.","Contribution.","We formalise our method in general way and instantiate it over various LLMs, as well as on a concrete case study.","We report experiments rooted in the nutritional domain where an ontology of food meals and their ingredients is semi-automatically instantiated from scratch, starting from a categorisation of meals and their relationships.","There, we analyse the quality of the generated ontologies and compare ontologies attained by exploiting different LLMs.","Finally, we provide a SWOT analysis of the proposed method."],"url":"http://arxiv.org/abs/2404.04108v1","category":"cs.AI"}
{"created":"2024-04-05 14:02:04","title":"Intervention-Assisted Policy Gradient Methods for Online Stochastic Queuing Network Optimization: Technical Report","abstract":"Deep Reinforcement Learning (DRL) offers a powerful approach to training neural network control policies for stochastic queuing networks (SQN). However, traditional DRL methods rely on offline simulations or static datasets, limiting their real-world application in SQN control. This work proposes Online Deep Reinforcement Learning-based Controls (ODRLC) as an alternative, where an intelligent agent interacts directly with a real environment and learns an optimal control policy from these online interactions. SQNs present a challenge for ODRLC due to the unbounded nature of the queues within the network resulting in an unbounded state-space. An unbounded state-space is particularly challenging for neural network policies as neural networks are notoriously poor at extrapolating to unseen states. To address this challenge, we propose an intervention-assisted framework that leverages strategic interventions from known stable policies to ensure the queue sizes remain bounded. This framework combines the learning power of neural networks with the guaranteed stability of classical control policies for SQNs. We introduce a method to design these intervention-assisted policies to ensure strong stability of the network. Furthermore, we extend foundational DRL theorems for intervention-assisted policies and develop two practical algorithms specifically for ODRLC of SQNs. Finally, we demonstrate through experiments that our proposed algorithms outperform both classical control approaches and prior ODRLC algorithms.","sentences":["Deep Reinforcement Learning (DRL) offers a powerful approach to training neural network control policies for stochastic queuing networks (SQN).","However, traditional DRL methods rely on offline simulations or static datasets, limiting their real-world application in SQN control.","This work proposes Online Deep Reinforcement Learning-based Controls (ODRLC) as an alternative, where an intelligent agent interacts directly with a real environment and learns an optimal control policy from these online interactions.","SQNs present a challenge for ODRLC due to the unbounded nature of the queues within the network resulting in an unbounded state-space.","An unbounded state-space is particularly challenging for neural network policies as neural networks are notoriously poor at extrapolating to unseen states.","To address this challenge, we propose an intervention-assisted framework that leverages strategic interventions from known stable policies to ensure the queue sizes remain bounded.","This framework combines the learning power of neural networks with the guaranteed stability of classical control policies for SQNs.","We introduce a method to design these intervention-assisted policies to ensure strong stability of the network.","Furthermore, we extend foundational DRL theorems for intervention-assisted policies and develop two practical algorithms specifically for ODRLC of SQNs.","Finally, we demonstrate through experiments that our proposed algorithms outperform both classical control approaches and prior ODRLC algorithms."],"url":"http://arxiv.org/abs/2404.04106v1","category":"cs.AI"}
{"created":"2024-04-05 14:00:37","title":"Judgment in macroeconomic output growth predictions: Efficiency, accuracy and persistence","abstract":"The present study applies observations of individual predictions of the first three releases of the US output growth rate to evaluate how the applied judgment affects prediction efficiency and accuracy as well as if judgment is persistent. While the first two issues have been assessed in other studies, there is little evidence on the formation of judgment in macroeconomic projections. Most of the forecasters produce unbiased predictions, but employing the median Bloomberg projection as baseline, it turns out that judgment generally does not improve accuracy. There seems to be persistence in the judgment applied by forecasters in the sense that the sign of the adjustment in the first release prediction carries over to the projections of the two following revisions. One possible explanation is that forecasters use some kind of anchor-and-adjustment heuristic.","sentences":["The present study applies observations of individual predictions of the first three releases of the US output growth rate to evaluate how the applied judgment affects prediction efficiency and accuracy as well as if judgment is persistent.","While the first two issues have been assessed in other studies, there is little evidence on the formation of judgment in macroeconomic projections.","Most of the forecasters produce unbiased predictions, but employing the median Bloomberg projection as baseline, it turns out that judgment generally does not improve accuracy.","There seems to be persistence in the judgment applied by forecasters in the sense that the sign of the adjustment in the first release prediction carries over to the projections of the two following revisions.","One possible explanation is that forecasters use some kind of anchor-and-adjustment heuristic."],"url":"http://arxiv.org/abs/2404.04105v1","category":"econ.GN"}
{"created":"2024-04-05 14:00:07","title":"3D Facial Expressions through Analysis-by-Neural-Synthesis","abstract":"While existing methods for 3D face reconstruction from in-the-wild images excel at recovering the overall face shape, they commonly miss subtle, extreme, asymmetric, or rarely observed expressions. We improve upon these methods with SMIRK (Spatial Modeling for Image-based Reconstruction of Kinesics), which faithfully reconstructs expressive 3D faces from images. We identify two key limitations in existing methods: shortcomings in their self-supervised training formulation, and a lack of expression diversity in the training images. For training, most methods employ differentiable rendering to compare a predicted face mesh with the input image, along with a plethora of additional loss functions. This differentiable rendering loss not only has to provide supervision to optimize for 3D face geometry, camera, albedo, and lighting, which is an ill-posed optimization problem, but the domain gap between rendering and input image further hinders the learning process. Instead, SMIRK replaces the differentiable rendering with a neural rendering module that, given the rendered predicted mesh geometry, and sparsely sampled pixels of the input image, generates a face image. As the neural rendering gets color information from sampled image pixels, supervising with neural rendering-based reconstruction loss can focus solely on the geometry. Further, it enables us to generate images of the input identity with varying expressions while training. These are then utilized as input to the reconstruction model and used as supervision with ground truth geometry. This effectively augments the training data and enhances the generalization for diverse expressions. Our qualitative, quantitative and particularly our perceptual evaluations demonstrate that SMIRK achieves the new state-of-the art performance on accurate expression reconstruction. Project webpage: https://georgeretsi.github.io/smirk/.","sentences":["While existing methods for 3D face reconstruction from in-the-wild images excel at recovering the overall face shape, they commonly miss subtle, extreme, asymmetric, or rarely observed expressions.","We improve upon these methods with SMIRK (Spatial Modeling for Image-based Reconstruction of Kinesics), which faithfully reconstructs expressive 3D faces from images.","We identify two key limitations in existing methods: shortcomings in their self-supervised training formulation, and a lack of expression diversity in the training images.","For training, most methods employ differentiable rendering to compare a predicted face mesh with the input image, along with a plethora of additional loss functions.","This differentiable rendering loss not only has to provide supervision to optimize for 3D face geometry, camera, albedo, and lighting, which is an ill-posed optimization problem, but the domain gap between rendering and input image further hinders the learning process.","Instead, SMIRK replaces the differentiable rendering with a neural rendering module that, given the rendered predicted mesh geometry, and sparsely sampled pixels of the input image, generates a face image.","As the neural rendering gets color information from sampled image pixels, supervising with neural rendering-based reconstruction loss can focus solely on the geometry.","Further, it enables us to generate images of the input identity with varying expressions while training.","These are then utilized as input to the reconstruction model and used as supervision with ground truth geometry.","This effectively augments the training data and enhances the generalization for diverse expressions.","Our qualitative, quantitative and particularly our perceptual evaluations demonstrate that SMIRK achieves the new state-of-the art performance on accurate expression reconstruction.","Project webpage: https://georgeretsi.github.io/smirk/."],"url":"http://arxiv.org/abs/2404.04104v1","category":"cs.CV"}
{"created":"2024-04-05 13:59:12","title":"Improving Factual Accuracy of Neural Table-to-Text Output by Addressing Input Problems in ToTTo","abstract":"Neural Table-to-Text models tend to hallucinate, producing texts that contain factual errors. We investigate whether such errors in the output can be traced back to problems with the input. We manually annotated 1,837 texts generated by multiple models in the politics domain of the ToTTo dataset. We identify the input problems that are responsible for many output errors and show that fixing these inputs reduces factual errors by between 52% and 76% (depending on the model). In addition, we observe that models struggle in processing tabular inputs that are structured in a non-standard way, particularly when the input lacks distinct row and column values or when the column headers are not correctly mapped to corresponding values.","sentences":["Neural Table-to-Text models tend to hallucinate, producing texts that contain factual errors.","We investigate whether such errors in the output can be traced back to problems with the input.","We manually annotated 1,837 texts generated by multiple models in the politics domain of the ToTTo dataset.","We identify the input problems that are responsible for many output errors and show that fixing these inputs reduces factual errors by between 52% and 76% (depending on the model).","In addition, we observe that models struggle in processing tabular inputs that are structured in a non-standard way, particularly when the input lacks distinct row and column values or when the column headers are not correctly mapped to corresponding values."],"url":"http://arxiv.org/abs/2404.04103v1","category":"cs.CL"}
{"created":"2024-04-05 13:58:51","title":"Robust Preference Optimization with Provable Noise Tolerance for LLMs","abstract":"The preference alignment aims to enable large language models (LLMs) to generate responses that conform to human values, which is essential for developing general AI systems. Ranking-based methods -- a promising class of alignment approaches -- learn human preferences from datasets containing response pairs by optimizing the log-likelihood margins between preferred and dis-preferred responses. However, due to the inherent differences in annotators' preferences, ranking labels of comparisons for response pairs are unavoidably noisy. This seriously hurts the reliability of existing ranking-based methods. To address this problem, we propose a provably noise-tolerant preference alignment method, namely RObust Preference Optimization (ROPO). To the best of our knowledge, ROPO is the first preference alignment method with noise-tolerance guarantees. The key idea of ROPO is to dynamically assign conservative gradient weights to response pairs with high label uncertainty, based on the log-likelihood margins between the responses. By effectively suppressing the gradients of noisy samples, our weighting strategy ensures that the expected risk has the same gradient direction independent of the presence and proportion of noise. Experiments on three open-ended text generation tasks with four base models ranging in size from 2.8B to 13B demonstrate that ROPO significantly outperforms existing ranking-based methods.","sentences":["The preference alignment aims to enable large language models (LLMs) to generate responses that conform to human values, which is essential for developing general AI systems.","Ranking-based methods -- a promising class of alignment approaches -- learn human preferences from datasets containing response pairs by optimizing the log-likelihood margins between preferred and dis-preferred responses.","However, due to the inherent differences in annotators' preferences, ranking labels of comparisons for response pairs are unavoidably noisy.","This seriously hurts the reliability of existing ranking-based methods.","To address this problem, we propose a provably noise-tolerant preference alignment method, namely RObust Preference Optimization (ROPO).","To the best of our knowledge, ROPO is the first preference alignment method with noise-tolerance guarantees.","The key idea of ROPO is to dynamically assign conservative gradient weights to response pairs with high label uncertainty, based on the log-likelihood margins between the responses.","By effectively suppressing the gradients of noisy samples, our weighting strategy ensures that the expected risk has the same gradient direction independent of the presence and proportion of noise.","Experiments on three open-ended text generation tasks with four base models ranging in size from 2.8B to 13B demonstrate that ROPO significantly outperforms existing ranking-based methods."],"url":"http://arxiv.org/abs/2404.04102v1","category":"cs.LG"}
{"created":"2024-04-05 13:49:19","title":"Subscription-Based Inventory Planning for E-Grocery Retailing","abstract":"The growing e-grocery sector faces challenges in becoming profitable due to heightened customer expectations and logistical complexities. This paper addresses the impact of uncertainty in customer demand on inventory planning for online grocery retailers. Given the perishable nature of grocery products and intense market competition, retailers must ensure product availability while minimising overstocking costs. We propose introducing subscription offers as a solution to mitigate these inventory challenges. Unlike existing literature focusing on uniform subscription models that may harm profitability, our approach considers the synergy between implementing product subscriptions and cost savings from improved inventory planning. We present a three-step procedure enabling retailers to understand uncertainty costs, quantify the value of gathering additional planning information, and implement profitability-enhancing subscription offers. This holistic approach ensures the development of sustainable subscription models in the e-grocery domain.","sentences":["The growing e-grocery sector faces challenges in becoming profitable due to heightened customer expectations and logistical complexities.","This paper addresses the impact of uncertainty in customer demand on inventory planning for online grocery retailers.","Given the perishable nature of grocery products and intense market competition, retailers must ensure product availability while minimising overstocking costs.","We propose introducing subscription offers as a solution to mitigate these inventory challenges.","Unlike existing literature focusing on uniform subscription models that may harm profitability, our approach considers the synergy between implementing product subscriptions and cost savings from improved inventory planning.","We present a three-step procedure enabling retailers to understand uncertainty costs, quantify the value of gathering additional planning information, and implement profitability-enhancing subscription offers.","This holistic approach ensures the development of sustainable subscription models in the e-grocery domain."],"url":"http://arxiv.org/abs/2404.04097v1","category":"econ.GN"}
{"created":"2024-04-05 13:44:39","title":"Dynamic Prompt Optimizing for Text-to-Image Generation","abstract":"Text-to-image generative models, specifically those based on diffusion models like Imagen and Stable Diffusion, have made substantial advancements. Recently, there has been a surge of interest in the delicate refinement of text prompts. Users assign weights or alter the injection time steps of certain words in the text prompts to improve the quality of generated images. However, the success of fine-control prompts depends on the accuracy of the text prompts and the careful selection of weights and time steps, which requires significant manual intervention. To address this, we introduce the \\textbf{P}rompt \\textbf{A}uto-\\textbf{E}diting (PAE) method. Besides refining the original prompts for image generation, we further employ an online reinforcement learning strategy to explore the weights and injection time steps of each word, leading to the dynamic fine-control prompts. The reward function during training encourages the model to consider aesthetic score, semantic consistency, and user preferences. Experimental results demonstrate that our proposed method effectively improves the original prompts, generating visually more appealing images while maintaining semantic alignment. Code is available at https://github.com/Mowenyii/PAE.","sentences":["Text-to-image generative models, specifically those based on diffusion models like Imagen and Stable Diffusion, have made substantial advancements.","Recently, there has been a surge of interest in the delicate refinement of text prompts.","Users assign weights or alter the injection time steps of certain words in the text prompts to improve the quality of generated images.","However, the success of fine-control prompts depends on the accuracy of the text prompts and the careful selection of weights and time steps, which requires significant manual intervention.","To address this, we introduce the \\textbf{P}rompt \\textbf{A}uto-\\textbf{E}diting (PAE) method.","Besides refining the original prompts for image generation, we further employ an online reinforcement learning strategy to explore the weights and injection time steps of each word, leading to the dynamic fine-control prompts.","The reward function during training encourages the model to consider aesthetic score, semantic consistency, and user preferences.","Experimental results demonstrate that our proposed method effectively improves the original prompts, generating visually more appealing images while maintaining semantic alignment.","Code is available at https://github.com/Mowenyii/PAE."],"url":"http://arxiv.org/abs/2404.04095v1","category":"cs.CV"}
{"created":"2024-04-05 13:41:11","title":"Almost zero transfer in continuous-time quantum walks on weighted tree graphs","abstract":"We study the probability flux on the central vertex in continuous-time quantum walks on weighted tree graphs. In a weighted graph, each edge has a weight we call hopping. This hopping sets the jump rate of the particle between the vertices connected by the edge. Here, the edges of the central vertex (root) have a hopping parameter $J$ larger than those of the other edges. For star graphs, this hopping gives only how often the walker visits the central vertex over time. However, for weighted spider graphs $S_{n,2}$ and $S_{n,3}$, the probability on the central vertex drops with $J^2$ for walks starting from a state of any superposition of leaf vertices. We map Cayley trees $C_{3,2}$ and $C_{3,3}$ into these spider graphs and observe the same dependency. Our results suggest this is a general feature of such walks on weighted trees and a way of probing decoherence effects in an open quantum system context.","sentences":["We study the probability flux on the central vertex in continuous-time quantum walks on weighted tree graphs.","In a weighted graph, each edge has a weight we call hopping.","This hopping sets the jump rate of the particle between the vertices connected by the edge.","Here, the edges of the central vertex (root) have a hopping parameter $J$ larger than those of the other edges.","For star graphs, this hopping gives only how often the walker visits the central vertex over time.","However, for weighted spider graphs $S_{n,2}$ and $S_{n,3}$, the probability on the central vertex drops with $J^2$ for walks starting from a state of any superposition of leaf vertices.","We map Cayley trees $C_{3,2}$ and $C_{3,3}$ into these spider graphs and observe the same dependency.","Our results suggest this is a general feature of such walks on weighted trees and a way of probing decoherence effects in an open quantum system context."],"url":"http://arxiv.org/abs/2404.04094v1","category":"quant-ph"}
{"created":"2024-04-05 13:39:25","title":"From STPA to Safe Behavior Models","abstract":"Model checking is a proven approach for checking whether the behavior model of a safety-critical system fulfills safety properties that are stated as LTL formulas.We propose rules for generating such LTL formulas automatically based on the result of the risk analysis technique System-Theoretic Process Analysis (STPA). Additionally, we propose a synthesis of a Safe Behavior Model from these generated LTL formulas. To also cover liveness properties in the model, we extend STPA with Desired Control Actions. We demonstrate our approach on an example system using SCCharts for the behavior model. The resulting model is not necessarily complete but provides a good foundation that already covers safety and liveness properties.","sentences":["Model checking is a proven approach for checking whether the behavior model of a safety-critical system fulfills safety properties that are stated as LTL formulas.","We propose rules for generating such LTL formulas automatically based on the result of the risk analysis technique System-Theoretic Process Analysis (STPA).","Additionally, we propose a synthesis of a Safe Behavior Model from these generated LTL formulas.","To also cover liveness properties in the model, we extend STPA with Desired Control Actions.","We demonstrate our approach on an example system using SCCharts for the behavior model.","The resulting model is not necessarily complete but provides a good foundation that already covers safety and liveness properties."],"url":"http://arxiv.org/abs/2404.04093v1","category":"cs.SE"}
{"created":"2024-04-05 13:37:41","title":"Generating functions for irreversible Hamiltonian systems","abstract":"The definition of conservative-irreversible functions is extended to smooth manifolds. The local representation of these functions is studied and reveals that not each conservative-irreversible function is given by the weighted product of almost Poisson brackets. The biquadratic functions given by conservative-irreversible functions are studied and reveal a possibility for an algebraic framework on arbitrary and in particular complex algebras.","sentences":["The definition of conservative-irreversible functions is extended to smooth manifolds.","The local representation of these functions is studied and reveals that not each conservative-irreversible function is given by the weighted product of almost Poisson brackets.","The biquadratic functions given by conservative-irreversible functions are studied and reveal a possibility for an algebraic framework on arbitrary and in particular complex algebras."],"url":"http://arxiv.org/abs/2404.04092v1","category":"math-ph"}
{"created":"2024-04-05 13:24:57","title":"Center-of-mass energy dependence of intrinsic-$k_T$ distributions obtained from Drell-Yan production","abstract":"The internal motion of partons inside hadrons has been studied through its impact on very low transverse momentum spectra of Drell-Yan (DY) pairs created in hadron-hadron collisions. We study DY production at next-to-leading order using the Parton Branching (PB) method which describes the evolution of transverse momentum dependent parton distributions. The main focus is on studying the intrinsic transverse momentum distribution (intrinsic-$k_T$) as a function of the center-of-mass energy $\\sqrt s$. While collinear parton shower Monte Carlo event generators require intrinsic transverse momentum distributions strongly dependent on $\\sqrt s$, this is not the case for the PB method. We perform a detailed study of the impact of soft parton emissions. We show that by requiring a minimal transverse momentum, $q_0$, of a radiated parton, a dependence of the width of the intrinsic-$k_T$ distribution as a function of $\\sqrt{s}$ is observed. This dependence becomes stronger with increasing $q_0$.","sentences":["The internal motion of partons inside hadrons has been studied through its impact on very low transverse momentum spectra of Drell-Yan (DY) pairs created in hadron-hadron collisions.","We study DY production at next-to-leading order using the Parton Branching (PB) method which describes the evolution of transverse momentum dependent parton distributions.","The main focus is on studying the intrinsic transverse momentum distribution (intrinsic-$k_T$) as a function of the center-of-mass energy $\\sqrt s$. While collinear parton shower Monte Carlo event generators require intrinsic transverse momentum distributions strongly dependent on $\\sqrt s$, this is not the case for the PB method.","We perform a detailed study of the impact of soft parton emissions.","We show that by requiring a minimal transverse momentum, $q_0$, of a radiated parton, a dependence of the width of the intrinsic-$k_T$ distribution as a function of $\\sqrt{s}$ is observed.","This dependence becomes stronger with increasing $q_0$."],"url":"http://arxiv.org/abs/2404.04088v1","category":"hep-ph"}
{"created":"2024-04-05 13:19:54","title":"A note on the cohomology of moduli spaces of local shtukas","abstract":"We study localized versions of the spectral action of Fargues--Scholze, using methods from higher algebra. As our main motivation and application, we deduce a formula for the cohomology of moduli spaces of local shtukas under certain genericity assumptions, and discuss its relation with the Kottwitz conjecture.","sentences":["We study localized versions of the spectral action of Fargues--Scholze, using methods from higher algebra.","As our main motivation and application, we deduce a formula for the cohomology of moduli spaces of local shtukas under certain genericity assumptions, and discuss its relation with the Kottwitz conjecture."],"url":"http://arxiv.org/abs/2404.04083v1","category":"math.NT"}
{"created":"2024-04-05 13:12:17","title":"Self-Sensing Feedback Control of an Electrohydraulic Robotic Shoulder","abstract":"The human shoulder, with its glenohumeral joint, tendons, ligaments, and muscles, allows for the execution of complex tasks with precision and efficiency. However, current robotic shoulder designs lack the compliance and compactness inherent in their biological counterparts. A major limitation of these designs is their reliance on external sensors like rotary encoders, which restrict mechanical joint design and introduce bulk to the system. To address this constraint, we present a bio-inspired antagonistic robotic shoulder with two degrees of freedom powered by self-sensing hydraulically amplified self-healing electrostatic actuators. Our artificial muscle design decouples the high-voltage electrostatic actuation from the pair of low-voltage self-sensing electrodes. This approach allows for proprioceptive feedback control of trajectories in the task space while eliminating the necessity for any additional sensors. We assess the platform's efficacy by comparing it to a feedback control based on position data provided by a motion capture system. The study demonstrates closed-loop controllable robotic manipulators based on an inherent self-sensing capability of electrohydraulic actuators. The proposed architecture can serve as a basis for complex musculoskeletal joint arrangements.","sentences":["The human shoulder, with its glenohumeral joint, tendons, ligaments, and muscles, allows for the execution of complex tasks with precision and efficiency.","However, current robotic shoulder designs lack the compliance and compactness inherent in their biological counterparts.","A major limitation of these designs is their reliance on external sensors like rotary encoders, which restrict mechanical joint design and introduce bulk to the system.","To address this constraint, we present a bio-inspired antagonistic robotic shoulder with two degrees of freedom powered by self-sensing hydraulically amplified self-healing electrostatic actuators.","Our artificial muscle design decouples the high-voltage electrostatic actuation from the pair of low-voltage self-sensing electrodes.","This approach allows for proprioceptive feedback control of trajectories in the task space while eliminating the necessity for any additional sensors.","We assess the platform's efficacy by comparing it to a feedback control based on position data provided by a motion capture system.","The study demonstrates closed-loop controllable robotic manipulators based on an inherent self-sensing capability of electrohydraulic actuators.","The proposed architecture can serve as a basis for complex musculoskeletal joint arrangements."],"url":"http://arxiv.org/abs/2404.04079v1","category":"cs.RO"}
{"created":"2024-04-05 13:08:19","title":"Strangeness $+1$ light multiquark baryons: a jinx?","abstract":"In view of the renewing experimental interest for searching strangeness $+1$ baryons at J-PARC, we study the existence of light baryon resonances with strangeness +1 generated in the $K$-$(N^*/\\Delta^*)$ system, where $N^*$ represents either $N^*(1535)$/$N^*(1650)$/$N^*(1700)$, and $\\Delta^*$ corresponds to $\\Delta(1620)$. The description of the properties of the aforementioned states requires considering the dynamics involved in the coupled pseudoscalar-baryon and vector-baryon systems with strangeness $S=0$ in the s-wave. For the purpose of our current study, we consider the pseudoscalar-baryon (PB) and vector-baryon channels (VB) to which the mentioned $N^*$ and $\\Delta^*$ resonances couple and solve the Faddeev equations for the coupled channel system $K$-$\\text{PB}$, $K$-$\\text{VB}$, with all interactions being in the s-wave. Despite some strong attraction present in two of the subsystems, we do not find clear evidence supporting the formation of strangeness +1 states, with spin-parity $J^P=1/2^+$, in the energy region $2000-2200$ MeV. However, the case of spin-parity $J^P=3/2^+$ seems more promising, showing the formation of a resonance with a mass around 2167 MeV, with a width of 90-100 MeV. We suggest that a signal of such a state could be found in processes with final states like $KN$, $K^*(892) N$.","sentences":["In view of the renewing experimental interest for searching strangeness $+1$ baryons at J-PARC, we study the existence of light baryon resonances with strangeness +1 generated in the $K$-$(N^*/\\Delta^*)$ system, where $N^*$ represents either $N^*(1535)$/$N^*(1650)$/$N^*(1700)$, and $\\Delta^*$ corresponds to $\\Delta(1620)$. The description of the properties of the aforementioned states requires considering the dynamics involved in the coupled pseudoscalar-baryon and vector-baryon systems with strangeness $S=0$ in the s-wave.","For the purpose of our current study, we consider the pseudoscalar-baryon (PB) and vector-baryon channels (VB) to which the mentioned $N^*$ and $\\Delta^*$ resonances couple and solve the Faddeev equations for the coupled channel system $K$-$\\text{PB}$, $K$-$\\text{VB}$, with all interactions being in the s-wave.","Despite some strong attraction present in two of the subsystems, we do not find clear evidence supporting the formation of strangeness +1 states, with spin-parity $J^P=1/2^+$, in the energy region $2000-2200$ MeV.","However, the case of spin-parity $J^P=3/2^+$ seems more promising, showing the formation of a resonance with a mass around 2167 MeV, with a width of 90-100 MeV. We suggest that a signal of such a state could be found in processes with final states like $KN$, $K^*(892) N$."],"url":"http://arxiv.org/abs/2404.04078v1","category":"hep-ph"}
{"created":"2024-04-05 13:07:34","title":"The forgotten pillar of sustainability: development of the S-assessment tool to evaluate Organizational Social Sustainability","abstract":"Pursuing sustainable development has become a global imperative, underscored adopting of the 2030 Agenda for Sustainable Development and its 17 Sustainable Development Goals (SDG). At the heart of this agenda lies the recognition of social sustainability as a pivotal component, emphasizing the need for inclusive societies where every individual can thrive. Despite its significance, social sustainability remains a \"forgotten pillar,\" often overshadowed by environmental concerns. In response, this paper presents the development and validation of the S-Assessment Tool for Social Sustainability, a comprehensive questionnaire designed to evaluate organizations' performance across critical dimensions such as health and wellness, gender equality, decent work, and economic growth, reducing inequalities, and responsible production and consumption. The questionnaire was constructed on the critical dimensions identified through a systematic and narrative hybrid approach to the analysis of peer-reviewed literature. The framework has been structured around the values of the SDGs. It aims to empower organizations to better understand and address their social impact, fostering positive change and contributing to the collective effort towards a more equitable and sustainable future. Through collaborative partnerships and rigorous methodology, this research underscores the importance of integrating social sustainability into organizational practices and decision-making processes, ultimately advancing the broader agenda of sustainable development.","sentences":["Pursuing sustainable development has become a global imperative, underscored adopting of the 2030 Agenda for Sustainable Development and its 17 Sustainable Development Goals (SDG).","At the heart of this agenda lies the recognition of social sustainability as a pivotal component, emphasizing the need for inclusive societies where every individual can thrive.","Despite its significance, social sustainability remains a \"forgotten pillar,\" often overshadowed by environmental concerns.","In response, this paper presents the development and validation of the S-Assessment Tool for Social Sustainability, a comprehensive questionnaire designed to evaluate organizations' performance across critical dimensions such as health and wellness, gender equality, decent work, and economic growth, reducing inequalities, and responsible production and consumption.","The questionnaire was constructed on the critical dimensions identified through a systematic and narrative hybrid approach to the analysis of peer-reviewed literature.","The framework has been structured around the values of the SDGs.","It aims to empower organizations to better understand and address their social impact, fostering positive change and contributing to the collective effort towards a more equitable and sustainable future.","Through collaborative partnerships and rigorous methodology, this research underscores the importance of integrating social sustainability into organizational practices and decision-making processes, ultimately advancing the broader agenda of sustainable development."],"url":"http://arxiv.org/abs/2404.04077v1","category":"econ.GN"}
{"created":"2024-04-05 13:05:12","title":"Neutrinos as possible probes for quantum gravity","abstract":"In this paper, we aim to explore the interplay between neutrinos and quantum gravity, illustrating some proposals about the use of these particles as probes for the supposed quantized structure of spacetime. The residual signatures of a more fundamental theory of quantum gravity can manifest themselves modifying the free particle dispersion relations and the connected velocity. In neutrino sector these supposed effects can modify the time of flight for astrophysical particles with different energies and can affect the usual neutrino oscillation pattern introducing species depending perturbations. We will highlight how perturbations caused by non-standard interactions in the solar neutrino sector can mimic the presumed quantum gravity effects. In fact, the mathematical formulation of non-standard interactions is equivalent to that of CPT-odd perturbations. We will, therefore, emphasize the need to identify the nature of different contributions in order to disentangle them in the search for quantum gravity effects. As a final point we will discuss the possibility to detect in the neutrino sector decoherence effects caused by the quantum gravity supposed perturbations. By reviewing current experimental constraints and observations, we seek to shed light on the intricate relationship between neutrinos and quantum gravity, and discuss the challenges and future directions in this fascinating field of research.","sentences":["In this paper, we aim to explore the interplay between neutrinos and quantum gravity, illustrating some proposals about the use of these particles as probes for the supposed quantized structure of spacetime.","The residual signatures of a more fundamental theory of quantum gravity can manifest themselves modifying the free particle dispersion relations and the connected velocity.","In neutrino sector these supposed effects can modify the time of flight for astrophysical particles with different energies and can affect the usual neutrino oscillation pattern introducing species depending perturbations.","We will highlight how perturbations caused by non-standard interactions in the solar neutrino sector can mimic the presumed quantum gravity effects.","In fact, the mathematical formulation of non-standard interactions is equivalent to that of CPT-odd perturbations.","We will, therefore, emphasize the need to identify the nature of different contributions in order to disentangle them in the search for quantum gravity effects.","As a final point we will discuss the possibility to detect in the neutrino sector decoherence effects caused by the quantum gravity supposed perturbations.","By reviewing current experimental constraints and observations, we seek to shed light on the intricate relationship between neutrinos and quantum gravity, and discuss the challenges and future directions in this fascinating field of research."],"url":"http://arxiv.org/abs/2404.04076v1","category":"gr-qc"}
{"created":"2024-04-05 13:03:13","title":"DGP-LVM: Derivative Gaussian process latent variable model","abstract":"We develop a framework for derivative Gaussian process latent variable models (DGP-LVM) that can handle multi-dimensional output data using modified derivative covariance functions. The modifications account for complexities in the underlying data generating process such as scaled derivatives, varying information across multiple output dimensions as well as interactions between outputs. Further, our framework provides uncertainty estimates for each latent variable samples using Bayesian inference. Through extensive simulations, we demonstrate that latent variable estimation accuracy can be drastically increased by including derivative information due to our proposed covariance function modifications. The developments are motivated by a concrete biological research problem involving the estimation of the unobserved cellular ordering from single-cell RNA (scRNA) sequencing data for gene expression and its corresponding derivative information known as RNA velocity. Since the RNA velocity is only an estimate of the exact derivative information, the derivative covariance functions need to account for potential scale differences. In a real-world case study, we illustrate the application of DGP-LVMs to such scRNA sequencing data. While motivated by this biological problem, our framework is generally applicable to all kinds of latent variable estimation problems involving derivative information irrespective of the field of study.","sentences":["We develop a framework for derivative Gaussian process latent variable models (DGP-LVM) that can handle multi-dimensional output data using modified derivative covariance functions.","The modifications account for complexities in the underlying data generating process such as scaled derivatives, varying information across multiple output dimensions as well as interactions between outputs.","Further, our framework provides uncertainty estimates for each latent variable samples using Bayesian inference.","Through extensive simulations, we demonstrate that latent variable estimation accuracy can be drastically increased by including derivative information due to our proposed covariance function modifications.","The developments are motivated by a concrete biological research problem involving the estimation of the unobserved cellular ordering from single-cell RNA (scRNA) sequencing data for gene expression and its corresponding derivative information known as RNA velocity.","Since the RNA velocity is only an estimate of the exact derivative information, the derivative covariance functions need to account for potential scale differences.","In a real-world case study, we illustrate the application of DGP-LVMs to such scRNA sequencing data.","While motivated by this biological problem, our framework is generally applicable to all kinds of latent variable estimation problems involving derivative information irrespective of the field of study."],"url":"http://arxiv.org/abs/2404.04074v1","category":"stat.ME"}
{"created":"2024-04-05 12:51:37","title":"CLUE: A Clinical Language Understanding Evaluation for LLMs","abstract":"Large Language Models (LLMs) have shown the potential to significantly contribute to patient care, diagnostics, and administrative processes. Emerging biomedical LLMs address healthcare-specific challenges, including privacy demands and computational constraints. However, evaluation of these models has primarily been limited to non-clinical tasks, which do not reflect the complexity of practical clinical applications. Additionally, there has been no thorough comparison between biomedical and general-domain LLMs for clinical tasks. To fill this gap, we present the Clinical Language Understanding Evaluation (CLUE), a benchmark tailored to evaluate LLMs on real-world clinical tasks. CLUE includes two novel datasets derived from MIMIC IV discharge letters and four existing tasks designed to test the practical applicability of LLMs in healthcare settings. Our evaluation covers several biomedical and general domain LLMs, providing insights into their clinical performance and applicability. CLUE represents a step towards a standardized approach to evaluating and developing LLMs in healthcare to align future model development with the real-world needs of clinical application. We publish our evaluation and data generation scripts: https://github.com/dadaamin/CLUE","sentences":["Large Language Models (LLMs) have shown the potential to significantly contribute to patient care, diagnostics, and administrative processes.","Emerging biomedical LLMs address healthcare-specific challenges, including privacy demands and computational constraints.","However, evaluation of these models has primarily been limited to non-clinical tasks, which do not reflect the complexity of practical clinical applications.","Additionally, there has been no thorough comparison between biomedical and general-domain LLMs for clinical tasks.","To fill this gap, we present the Clinical Language Understanding Evaluation (CLUE), a benchmark tailored to evaluate LLMs on real-world clinical tasks.","CLUE includes two novel datasets derived from MIMIC IV discharge letters and four existing tasks designed to test the practical applicability of LLMs in healthcare settings.","Our evaluation covers several biomedical and general domain LLMs, providing insights into their clinical performance and applicability.","CLUE represents a step towards a standardized approach to evaluating and developing LLMs in healthcare to align future model development with the real-world needs of clinical application.","We publish our evaluation and data generation scripts: https://github.com/dadaamin/CLUE"],"url":"http://arxiv.org/abs/2404.04067v1","category":"cs.CL"}
{"created":"2024-04-05 12:45:10","title":"VoicePilot: Harnessing LLMs as Speech Interfaces for Physically Assistive Robots","abstract":"Physically assistive robots present an opportunity to significantly increase the well-being and independence of individuals with motor impairments or other forms of disability who are unable to complete activities of daily living. Speech interfaces, especially ones that utilize Large Language Models (LLMs), can enable individuals to effectively and naturally communicate high-level commands and nuanced preferences to robots. Frameworks for integrating LLMs as interfaces to robots for high level task planning and code generation have been proposed, but fail to incorporate human-centric considerations which are essential while developing assistive interfaces. In this work, we present a framework for incorporating LLMs as speech interfaces for physically assistive robots, constructed iteratively with 3 stages of testing involving a feeding robot, culminating in an evaluation with 11 older adults at an independent living facility. We use both quantitative and qualitative data from the final study to validate our framework and additionally provide design guidelines for using LLMs as speech interfaces for assistive robots. Videos and supporting files are located on our project website: https://sites.google.com/andrew.cmu.edu/voicepilot/","sentences":["Physically assistive robots present an opportunity to significantly increase the well-being and independence of individuals with motor impairments or other forms of disability who are unable to complete activities of daily living.","Speech interfaces, especially ones that utilize Large Language Models (LLMs), can enable individuals to effectively and naturally communicate high-level commands and nuanced preferences to robots.","Frameworks for integrating LLMs as interfaces to robots for high level task planning and code generation have been proposed, but fail to incorporate human-centric considerations which are essential while developing assistive interfaces.","In this work, we present a framework for incorporating LLMs as speech interfaces for physically assistive robots, constructed iteratively with 3 stages of testing involving a feeding robot, culminating in an evaluation with 11 older adults at an independent living facility.","We use both quantitative and qualitative data from the final study to validate our framework and additionally provide design guidelines for using LLMs as speech interfaces for assistive robots.","Videos and supporting files are located on our project website: https://sites.google.com/andrew.cmu.edu/voicepilot/"],"url":"http://arxiv.org/abs/2404.04066v1","category":"cs.RO"}
{"created":"2024-04-05 12:41:53","title":"Fusing Dictionary Learning and Support Vector Machines for Unsupervised Anomaly Detection","abstract":"We study in this paper the improvement of one-class support vector machines (OC-SVM) through sparse representation techniques for unsupervised anomaly detection. As Dictionary Learning (DL) became recently a common analysis technique that reveals hidden sparse patterns of data, our approach uses this insight to endow unsupervised detection with more control on pattern finding and dimensions. We introduce a new anomaly detection model that unifies the OC-SVM and DL residual functions into a single composite objective, subsequently solved through K-SVD-type iterative algorithms. A closed-form of the alternating K-SVD iteration is explicitly derived for the new composite model and practical implementable schemes are discussed. The standard DL model is adapted for the Dictionary Pair Learning (DPL) context, where the usual sparsity constraints are naturally eliminated. Finally, we extend both objectives to the more general setting that allows the use of kernel functions. The empirical convergence properties of the resulting algorithms are provided and an in-depth analysis of their parametrization is performed while also demonstrating their numerical performance in comparison with existing methods.","sentences":["We study in this paper the improvement of one-class support vector machines (OC-SVM) through sparse representation techniques for unsupervised anomaly detection.","As Dictionary Learning (DL) became recently a common analysis technique that reveals hidden sparse patterns of data, our approach uses this insight to endow unsupervised detection with more control on pattern finding and dimensions.","We introduce a new anomaly detection model that unifies the OC-SVM and DL residual functions into a single composite objective, subsequently solved through K-SVD-type iterative algorithms.","A closed-form of the alternating K-SVD iteration is explicitly derived for the new composite model and practical implementable schemes are discussed.","The standard DL model is adapted for the Dictionary Pair Learning (DPL) context, where the usual sparsity constraints are naturally eliminated.","Finally, we extend both objectives to the more general setting that allows the use of kernel functions.","The empirical convergence properties of the resulting algorithms are provided and an in-depth analysis of their parametrization is performed while also demonstrating their numerical performance in comparison with existing methods."],"url":"http://arxiv.org/abs/2404.04064v1","category":"cs.LG"}
{"created":"2024-04-05 12:39:29","title":"The De Giorgi method for local and nonlocal systems","abstract":"We extend the De Giorgi iteration technique to the vectorial setting. For this we replace the usual scalar truncation operator by a vectorial shortening operator. As an application, we prove local boundedness for local and nonlocal nonlinear systems. Furthermore, we show convex hull properties, which are a generalization of the maximum principle to the case of systems.","sentences":["We extend the De Giorgi iteration technique to the vectorial setting.","For this we replace the usual scalar truncation operator by a vectorial shortening operator.","As an application, we prove local boundedness for local and nonlocal nonlinear systems.","Furthermore, we show convex hull properties, which are a generalization of the maximum principle to the case of systems."],"url":"http://arxiv.org/abs/2404.04063v1","category":"math.AP"}
{"created":"2024-04-05 12:34:56","title":"KRATOS: A large suite of N-body simulations to interpret the stellar kinematics of LMC-like discs","abstract":"We present KRATOS, a comprehensive suite of 28 open access pure N-body simulations of isolated and interacting LMC-like galaxies, to study the formation of substructures in their disc after the interaction with an SMC-mass galaxy. The primary objective of this paper is to provide theoretical models that help interpreting the formation of general structures of an LMC-like galaxy under various tidal interaction scenarios. This is the first paper of a series that will be dedicated to the analysis of this complex interaction. Simulations are grouped in 11 sets of at most three configurations each containing: (1) a control model of an isolated LMC-like galaxy; (2) a model that contains the interaction with an SMC-mass galaxy, and; (3) the most realistic configuration where both an SMC-mass and MW-mass galaxies may interact with the LMC-like galaxy. In each simulation, we analyse the orbital history between the three galaxies and examine the morphological and kinematic features of the LMC-like disc galaxy throughout the interaction. This includes investigating the disc scale height and velocity maps. When a bar develops, our analysis involves characterising its strength, length, off-centeredness and pattern speed. The diverse outcomes found in the KRATOS simulations, including the presence of bars, warped discs, or various spiral arm shapes (along with the high spatial, temporal, and mass resolution used), demonstrate their capability to explore a range of LMC-like galaxy morphologies. Those directly correspond to distinct disc kinematic maps, making them well-suited for a first-order interpretation of the LMC's kinematic maps. From the simulations we note that tidal interactions can: boost the disc scale height; both destroy and create bars, and; naturally explain the off-center stellar bars. The bar length and pattern speed of long-lived bars are not appreciably altered by the interaction.","sentences":["We present KRATOS, a comprehensive suite of 28 open access pure N-body simulations of isolated and interacting LMC-like galaxies, to study the formation of substructures in their disc after the interaction with an SMC-mass galaxy.","The primary objective of this paper is to provide theoretical models that help interpreting the formation of general structures of an LMC-like galaxy under various tidal interaction scenarios.","This is the first paper of a series that will be dedicated to the analysis of this complex interaction.","Simulations are grouped in 11 sets of at most three configurations each containing: (1) a control model of an isolated LMC-like galaxy; (2) a model that contains the interaction with an SMC-mass galaxy, and; (3) the most realistic configuration where both an SMC-mass and MW-mass galaxies may interact with the LMC-like galaxy.","In each simulation, we analyse the orbital history between the three galaxies and examine the morphological and kinematic features of the LMC-like disc galaxy throughout the interaction.","This includes investigating the disc scale height and velocity maps.","When a bar develops, our analysis involves characterising its strength, length, off-centeredness and pattern speed.","The diverse outcomes found in the KRATOS simulations, including the presence of bars, warped discs, or various spiral arm shapes (along with the high spatial, temporal, and mass resolution used), demonstrate their capability to explore a range of LMC-like galaxy morphologies.","Those directly correspond to distinct disc kinematic maps, making them well-suited for a first-order interpretation of the LMC's kinematic maps.","From the simulations we note that tidal interactions can: boost the disc scale height; both destroy and create bars, and; naturally explain the off-center stellar bars.","The bar length and pattern speed of long-lived bars are not appreciably altered by the interaction."],"url":"http://arxiv.org/abs/2404.04061v1","category":"astro-ph.GA"}
{"created":"2024-04-05 12:30:19","title":"Score identity Distillation: Exponentially Fast Distillation of Pretrained Diffusion Models for One-Step Generation","abstract":"We introduce Score identity Distillation (SiD), an innovative data-free method that distills the generative capabilities of pretrained diffusion models into a single-step generator. SiD not only facilitates an exponentially fast reduction in Fr\\'echet inception distance (FID) during distillation but also approaches or even exceeds the FID performance of the original teacher diffusion models. By reformulating forward diffusion processes as semi-implicit distributions, we leverage three score-related identities to create an innovative loss mechanism. This mechanism achieves rapid FID reduction by training the generator using its own synthesized images, eliminating the need for real data or reverse-diffusion-based generation, all accomplished within significantly shortened generation time. Upon evaluation across four benchmark datasets, the SiD algorithm demonstrates high iteration efficiency during distillation and surpasses competing distillation approaches, whether they are one-step or few-step, data-free, or dependent on training data, in terms of generation quality. This achievement not only redefines the benchmarks for efficiency and effectiveness in diffusion distillation but also in the broader field of diffusion-based generation. Our PyTorch implementation will be publicly accessible on GitHub.","sentences":["We introduce Score identity Distillation (SiD), an innovative data-free method that distills the generative capabilities of pretrained diffusion models into a single-step generator.","SiD not only facilitates an exponentially fast reduction in Fr\\'echet inception distance (FID) during distillation but also approaches or even exceeds the FID performance of the original teacher diffusion models.","By reformulating forward diffusion processes as semi-implicit distributions, we leverage three score-related identities to create an innovative loss mechanism.","This mechanism achieves rapid FID reduction by training the generator using its own synthesized images, eliminating the need for real data or reverse-diffusion-based generation, all accomplished within significantly shortened generation time.","Upon evaluation across four benchmark datasets, the SiD algorithm demonstrates high iteration efficiency during distillation and surpasses competing distillation approaches, whether they are one-step or few-step, data-free, or dependent on training data, in terms of generation quality.","This achievement not only redefines the benchmarks for efficiency and effectiveness in diffusion distillation but also in the broader field of diffusion-based generation.","Our PyTorch implementation will be publicly accessible on GitHub."],"url":"http://arxiv.org/abs/2404.04057v1","category":"cs.LG"}
{"created":"2024-04-05 12:22:52","title":"Constructive proofs for some semilinear PDEs on $H^2(e^{|x|^2/4},\\mathbb{R}^d)$","abstract":"We develop computer-assisted tools to study semilinear equations of the form \\begin{equation*} -\\Delta u -\\frac{x}{2}\\cdot \\nabla{u}= f(x,u,\\nabla u) ,\\quad x\\in\\mathbb{R}^d. \\end{equation*} Such equations appear naturally in several contexts, and in particular when looking for self-similar solutions of parabolic PDEs. We develop a general methodology, allowing us not only to prove the existence of solutions, but also to describe them very precisely. We introduce a spectral approach based on an eigenbasis of $\\mathcal{L}:= -\\Delta -\\frac{x}{2}\\cdot \\nabla$ in spherical coordinates, together with a quadrature rule allowing to deal with nonlinearities, in order to get accurate approximate solutions. We then use a Newton-Kantorovich argument, in an appropriate weighted Sobolev space, to prove the existence of a nearby exact solution. We apply our approach to nonlinear heat equations, to nonlinear Schr\\\"odinger equations and to a generalised viscous Burgers equation, and obtain both radial and non-radial self-similar profiles.","sentences":["We develop computer-assisted tools to study semilinear equations of the form \\begin{equation*} -\\Delta u -\\frac{x}{2}\\cdot \\nabla{u}= f(x,u,\\nabla u) ,\\quad x\\in\\mathbb{R}^d.","\\end{equation*} Such equations appear naturally in several contexts, and in particular when looking for self-similar solutions of parabolic PDEs.","We develop a general methodology, allowing us not only to prove the existence of solutions, but also to describe them very precisely.","We introduce a spectral approach based on an eigenbasis of $\\mathcal{L}:= -\\Delta -\\frac{x}{2}\\cdot \\nabla$ in spherical coordinates, together with a quadrature rule allowing to deal with nonlinearities, in order to get accurate approximate solutions.","We then use a Newton-Kantorovich argument, in an appropriate weighted Sobolev space, to prove the existence of a nearby exact solution.","We apply our approach to nonlinear heat equations, to nonlinear Schr\\\"odinger equations and to a generalised viscous Burgers equation, and obtain both radial and non-radial self-similar profiles."],"url":"http://arxiv.org/abs/2404.04054v1","category":"math.AP"}
{"created":"2024-04-05 12:17:40","title":"Attosecond Rabi Oscillations in High Harmonic Generation Resonantly Driven by Extreme Ultraviolet Laser Fields","abstract":"High-order harmonic generation driven by intense extreme ultraviolet (EUV) fields merges quantum optics and attosecond science, giving rise to an appealing route for the generation of coherent EUV and soft X-ray light for high-resolution imaging and spectroscopies. We theoretically investigate ultrafast resonant dynamics during the interaction of He atoms with strong extreme ultraviolet pulses. At high driving intensities, we identify record fast attosecond Rabi oscillations imprinting observable signatures in the high harmonic spectrum. At field strengths suppressing the Coulomb potential barrier for all the bounded states, we demonstrate the survival of the attosecond two-level dynamics for several Rabi cycles. Consequently, this intense EUV laser-atom interaction reveals a new strong-field scenario where the resonant coupling of two-level bound-bound transitions prevails, contrasting with the dominance of bound-continuum transitions in the conventional strong-field infrared regimes. These findings set an interesting perspective for extreme attosecond nonlinear optics with intense short-wavelength fields.","sentences":["High-order harmonic generation driven by intense extreme ultraviolet (EUV) fields merges quantum optics and attosecond science, giving rise to an appealing route for the generation of coherent EUV and soft X-ray light for high-resolution imaging and spectroscopies.","We theoretically investigate ultrafast resonant dynamics during the interaction of He atoms with strong extreme ultraviolet pulses.","At high driving intensities, we identify record fast attosecond Rabi oscillations imprinting observable signatures in the high harmonic spectrum.","At field strengths suppressing the Coulomb potential barrier for all the bounded states, we demonstrate the survival of the attosecond two-level dynamics for several Rabi cycles.","Consequently, this intense EUV laser-atom interaction reveals a new strong-field scenario where the resonant coupling of two-level bound-bound transitions prevails, contrasting with the dominance of bound-continuum transitions in the conventional strong-field infrared regimes.","These findings set an interesting perspective for extreme attosecond nonlinear optics with intense short-wavelength fields."],"url":"http://arxiv.org/abs/2404.04053v1","category":"physics.atom-ph"}
{"created":"2024-04-05 12:10:27","title":"Generalization of Ramanujan Famous Nested Radicals to the nth Root and their Evaluation","abstract":"Srinivasa Ramanujan posed a problem on infinite nested radical of the square root in the Journal of Indian Mathematical Society in 1911. He had generated the problem years before in the form of an example illustrating a more general theorem. Of course, how we would figure the solution out without Ramanujan theorem was scarcely obvious. Generation of infinite nested radicals, the roots being of higher order i.e. proceeding from the cube roots to the nth root as well as their evaluation may seem to be somewhat complex. For this purpose a general solution in the form of a theorem needs to be provided whereby symmetric patterns of infinite nested radicals of any order of roots may be evaluated including that of Ramanujan involving square root. In our work, we have rendered the required solution.","sentences":["Srinivasa Ramanujan posed a problem on infinite nested radical of the square root in the Journal of Indian Mathematical Society in 1911.","He had generated the problem years before in the form of an example illustrating a more general theorem.","Of course, how we would figure the solution out without Ramanujan theorem was scarcely obvious.","Generation of infinite nested radicals, the roots being of higher order i.e. proceeding from the cube roots to the nth root as well as their evaluation may seem to be somewhat complex.","For this purpose a general solution in the form of a theorem needs to be provided whereby symmetric patterns of infinite nested radicals of any order of roots may be evaluated including that of Ramanujan involving square root.","In our work, we have rendered the required solution."],"url":"http://arxiv.org/abs/2404.04051v1","category":"math.GM"}
{"created":"2024-04-05 12:09:36","title":"No Time to Train: Empowering Non-Parametric Networks for Few-shot 3D Scene Segmentation","abstract":"To reduce the reliance on large-scale datasets, recent works in 3D segmentation resort to few-shot learning. Current 3D few-shot segmentation methods first pre-train models on 'seen' classes, and then evaluate their generalization performance on 'unseen' classes. However, the prior pre-training stage not only introduces excessive time overhead but also incurs a significant domain gap on 'unseen' classes. To tackle these issues, we propose a Non-parametric Network for few-shot 3D Segmentation, Seg-NN, and its Parametric variant, Seg-PN. Without training, Seg-NN extracts dense representations by hand-crafted filters and achieves comparable performance to existing parametric models. Due to the elimination of pre-training, Seg-NN can alleviate the domain gap issue and save a substantial amount of time. Based on Seg-NN, Seg-PN only requires training a lightweight QUEry-Support Transferring (QUEST) module, which enhances the interaction between the support set and query set. Experiments suggest that Seg-PN outperforms previous state-of-the-art method by +4.19% and +7.71% mIoU on S3DIS and ScanNet datasets respectively, while reducing training time by -90%, indicating its effectiveness and efficiency.","sentences":["To reduce the reliance on large-scale datasets, recent works in 3D segmentation resort to few-shot learning.","Current 3D few-shot segmentation methods first pre-train models on 'seen' classes, and then evaluate their generalization performance on 'unseen' classes.","However, the prior pre-training stage not only introduces excessive time overhead but also incurs a significant domain gap on 'unseen' classes.","To tackle these issues, we propose a Non-parametric Network for few-shot 3D Segmentation, Seg-NN, and its Parametric variant, Seg-PN.","Without training, Seg-NN extracts dense representations by hand-crafted filters and achieves comparable performance to existing parametric models.","Due to the elimination of pre-training, Seg-NN can alleviate the domain gap issue and save a substantial amount of time.","Based on Seg-NN, Seg-PN only requires training a lightweight QUEry-Support Transferring (QUEST) module, which enhances the interaction between the support set and query set.","Experiments suggest that Seg-PN outperforms previous state-of-the-art method by +4.19% and +7.71% mIoU on S3DIS and ScanNet datasets respectively, while reducing training time by -90%, indicating its effectiveness and efficiency."],"url":"http://arxiv.org/abs/2404.04050v1","category":"cs.CV"}
{"created":"2024-04-05 12:05:20","title":"Cycle Life Prediction for Lithium-ion Batteries: Machine Learning and More","abstract":"Batteries are dynamic systems with complicated nonlinear aging, highly dependent on cell design, chemistry, manufacturing, and operational conditions. Prediction of battery cycle life and estimation of aging states is important to accelerate battery R&D, testing, and to further the understanding of how batteries degrade. Beyond testing, battery management systems rely on real-time models and onboard diagnostics and prognostics for safe operation. Estimating the state of health and remaining useful life of a battery is important to optimize performance and use resources optimally.   This tutorial begins with an overview of first-principles, machine learning, and hybrid battery models. Then, a typical pipeline for the development of interpretable machine learning models is explained and showcased for cycle life prediction from laboratory testing data. We highlight the challenges of machine learning models, motivating the incorporation of physics in hybrid modeling approaches, which are needed to decipher the aging trajectory of batteries but require more data and further work on the physics of battery degradation. The tutorial closes with a discussion on generalization and further research directions.","sentences":["Batteries are dynamic systems with complicated nonlinear aging, highly dependent on cell design, chemistry, manufacturing, and operational conditions.","Prediction of battery cycle life and estimation of aging states is important to accelerate battery R&D, testing, and to further the understanding of how batteries degrade.","Beyond testing, battery management systems rely on real-time models and onboard diagnostics and prognostics for safe operation.","Estimating the state of health and remaining useful life of a battery is important to optimize performance and use resources optimally.   ","This tutorial begins with an overview of first-principles, machine learning, and hybrid battery models.","Then, a typical pipeline for the development of interpretable machine learning models is explained and showcased for cycle life prediction from laboratory testing data.","We highlight the challenges of machine learning models, motivating the incorporation of physics in hybrid modeling approaches, which are needed to decipher the aging trajectory of batteries but require more data and further work on the physics of battery degradation.","The tutorial closes with a discussion on generalization and further research directions."],"url":"http://arxiv.org/abs/2404.04049v1","category":"eess.SY"}
{"created":"2024-04-05 11:59:47","title":"Impact of Black Hole Parameters on Photon Sphere and Shadow Radius: New Analytical Approach","abstract":"In this letter, we present a novel approach to investigate the behavior of the photon sphere and shadow radius. Our method leverages extended gravitational decoupling and unveils two key analytic results. First, the additional matter field alters the photon sphere radius: it increases if $g'(r_{ph}^{(0)})>0$ and decreases if $g'(r_{ph}^{(0)})<0$ (where $g'$ represents the derivative of a specific metric function evaluated at the original photon sphere radius). Second, the presence of the matter field can modify the black hole shadow size. If $g\\left(r_{ph}^{(0)}\\right)>0$, the shadow shrinks, while it grows for $g\\left(r_{ph}^{(0)}\\right)<0$. These findings offer a deeper understanding of how matter distribution affects the characteristics of black holes and their observable features. By providing a systematic framework supported by diverse illustrative examples, our investigation not only sheds light on these fundamental aspects but also quantifiably advances the theoretical framework in black hole astrophysics.","sentences":["In this letter, we present a novel approach to investigate the behavior of the photon sphere and shadow radius.","Our method leverages extended gravitational decoupling and unveils two key analytic results.","First, the additional matter field alters the photon sphere radius: it increases if $g'(r_{ph}^{(0)})>0$ and decreases if $g'(r_{ph}^{(0)})<0$ (where $g'$ represents the derivative of a specific metric function evaluated at the original photon sphere radius).","Second, the presence of the matter field can modify the black hole shadow size.","If $g\\left(r_{ph}^{(0)}\\right)>0$, the shadow shrinks, while it grows for $g\\left(r_{ph}^{(0)}\\right)<0$. These findings offer a deeper understanding of how matter distribution affects the characteristics of black holes and their observable features.","By providing a systematic framework supported by diverse illustrative examples, our investigation not only sheds light on these fundamental aspects but also quantifiably advances the theoretical framework in black hole astrophysics."],"url":"http://arxiv.org/abs/2404.04046v1","category":"gr-qc"}
{"created":"2024-04-05 11:55:52","title":"A Comparison of Methods for Evaluating Generative IR","abstract":"Information retrieval systems increasingly incorporate generative components. For example, in a retrieval augmented generation (RAG) system, a retrieval component might provide a source of ground truth, while a generative component summarizes and augments its responses. In other systems, a large language model (LLM) might directly generate responses without consulting a retrieval component. While there are multiple definitions of generative information retrieval (Gen-IR) systems, in this paper we focus on those systems where the system's response is not drawn from a fixed collection of documents or passages. The response to a query may be entirely new text never. Since traditional IR evaluation methods break down under this model, we explore various methods that extend traditional offline evaluation approaches to the Gen-IR context. Offline IR evaluation traditionally employs paid human assessors, but increasingly LLMs are replacing human assessment, demonstrating capabilities similar or superior to crowdsourced labels. Given that Gen-IR systems do not generate responses from a fixed set, we assume that methods for Gen-IR evaluation must largely depend on LLM-generated labels. Along with methods based on binary and graded relevance, we explore methods based on explicit subtopics, pairwise preferences, and embeddings. We first validate these methods against human assessments on several TREC Deep Learning Track tasks; we then apply these methods to evaluate the output of several purely generative systems. For each method we consider both its ability to act autonomously, without the need for human labels or other input, and its ability to support human auditing. To trust these methods, we must be assured that their results align with human assessments. In order to do so, evaluation criteria must be transparent, so that outcomes can be audited by human assessors.","sentences":["Information retrieval systems increasingly incorporate generative components.","For example, in a retrieval augmented generation (RAG) system, a retrieval component might provide a source of ground truth, while a generative component summarizes and augments its responses.","In other systems, a large language model (LLM) might directly generate responses without consulting a retrieval component.","While there are multiple definitions of generative information retrieval (Gen-IR) systems, in this paper we focus on those systems where the system's response is not drawn from a fixed collection of documents or passages.","The response to a query may be entirely new text never.","Since traditional IR evaluation methods break down under this model, we explore various methods that extend traditional offline evaluation approaches to the Gen-IR context.","Offline IR evaluation traditionally employs paid human assessors, but increasingly LLMs are replacing human assessment, demonstrating capabilities similar or superior to crowdsourced labels.","Given that Gen-IR systems do not generate responses from a fixed set, we assume that methods for Gen-IR evaluation must largely depend on LLM-generated labels.","Along with methods based on binary and graded relevance, we explore methods based on explicit subtopics, pairwise preferences, and embeddings.","We first validate these methods against human assessments on several TREC Deep Learning Track tasks; we then apply these methods to evaluate the output of several purely generative systems.","For each method we consider both its ability to act autonomously, without the need for human labels or other input, and its ability to support human auditing.","To trust these methods, we must be assured that their results align with human assessments.","In order to do so, evaluation criteria must be transparent, so that outcomes can be audited by human assessors."],"url":"http://arxiv.org/abs/2404.04044v1","category":"cs.IR"}
{"created":"2024-04-05 11:52:02","title":"Teaching Llama a New Language Through Cross-Lingual Knowledge Transfer","abstract":"This paper explores cost-efficient methods to adapt pretrained Large Language Models (LLMs) to new lower-resource languages, with a specific focus on Estonian. Leveraging the Llama 2 model, we investigate the impact of combining cross-lingual instruction-tuning with additional monolingual pretraining. Our results demonstrate that even a relatively small amount of additional monolingual pretraining followed by cross-lingual instruction-tuning significantly enhances results on Estonian. Furthermore, we showcase cross-lingual knowledge transfer from high-quality English instructions to Estonian, resulting in improvements in commonsense reasoning and multi-turn conversation capabilities. Our best model, named \\textsc{Llammas}, represents the first open-source instruction-following LLM for Estonian. Additionally, we publish Alpaca-est, the first general task instruction dataset for Estonia. These contributions mark the initial progress in the direction of developing open-source LLMs for Estonian.","sentences":["This paper explores cost-efficient methods to adapt pretrained Large Language Models (LLMs) to new lower-resource languages, with a specific focus on Estonian.","Leveraging the Llama 2 model, we investigate the impact of combining cross-lingual instruction-tuning with additional monolingual pretraining.","Our results demonstrate that even a relatively small amount of additional monolingual pretraining followed by cross-lingual instruction-tuning significantly enhances results on Estonian.","Furthermore, we showcase cross-lingual knowledge transfer from high-quality English instructions to Estonian, resulting in improvements in commonsense reasoning and multi-turn conversation capabilities.","Our best model, named \\textsc{Llammas}, represents the first open-source instruction-following LLM for Estonian.","Additionally, we publish Alpaca-est, the first general task instruction dataset for Estonia.","These contributions mark the initial progress in the direction of developing open-source LLMs for Estonian."],"url":"http://arxiv.org/abs/2404.04042v1","category":"cs.CL"}
{"created":"2024-04-05 11:49:29","title":"Dynamic Risk Assessment Methodology with an LDM-based System for Parking Scenarios","abstract":"This paper describes the methodology for building a dynamic risk assessment for ADAS (Advanced Driving Assistance Systems) algorithms in parking scenarios, fusing exterior and interior perception for a better understanding of the scene and a more comprehensive risk estimation. This includes the definition of a dynamic risk methodology that depends on the situation from inside and outside the vehicle, the creation of a multi-sensor dataset of risk assessment for ADAS benchmarking purposes, and a Local Dynamic Map (LDM) that fuses data from the exterior and interior of the car to build an LDM-based Dynamic Risk Assessment System (DRAS).","sentences":["This paper describes the methodology for building a dynamic risk assessment for ADAS (Advanced Driving Assistance Systems) algorithms in parking scenarios, fusing exterior and interior perception for a better understanding of the scene and a more comprehensive risk estimation.","This includes the definition of a dynamic risk methodology that depends on the situation from inside and outside the vehicle, the creation of a multi-sensor dataset of risk assessment for ADAS benchmarking purposes, and a Local Dynamic Map (LDM) that fuses data from the exterior and interior of the car to build an LDM-based Dynamic Risk Assessment System (DRAS)."],"url":"http://arxiv.org/abs/2404.04040v1","category":"cs.CV"}
{"created":"2024-04-05 11:45:03","title":"InstructHumans: Editing Animated 3D Human Textures with Instructions","abstract":"We present InstructHumans, a novel framework for instruction-driven 3D human texture editing. Existing text-based editing methods use Score Distillation Sampling (SDS) to distill guidance from generative models. This work shows that naively using such scores is harmful to editing as they destroy consistency with the source avatar. Instead, we propose an alternate SDS for Editing (SDS-E) that selectively incorporates subterms of SDS across diffusion timesteps. We further enhance SDS-E with spatial smoothness regularization and gradient-based viewpoint sampling to achieve high-quality edits with sharp and high-fidelity detailing. InstructHumans significantly outperforms existing 3D editing methods, consistent with the initial avatar while faithful to the textual instructions. Project page: https://jyzhu.top/instruct-humans .","sentences":["We present InstructHumans, a novel framework for instruction-driven 3D human texture editing.","Existing text-based editing methods use Score Distillation Sampling (SDS) to distill guidance from generative models.","This work shows that naively using such scores is harmful to editing as they destroy consistency with the source avatar.","Instead, we propose an alternate SDS for Editing (SDS-E) that selectively incorporates subterms of SDS across diffusion timesteps.","We further enhance SDS-E with spatial smoothness regularization and gradient-based viewpoint sampling to achieve high-quality edits with sharp and high-fidelity detailing.","InstructHumans significantly outperforms existing 3D editing methods, consistent with the initial avatar while faithful to the textual instructions.","Project page: https://jyzhu.top/instruct-humans ."],"url":"http://arxiv.org/abs/2404.04037v1","category":"cs.CV"}
{"created":"2024-04-05 11:37:40","title":"A Dataset for Physical and Abstract Plausibility and Sources of Human Disagreement","abstract":"We present a novel dataset for physical and abstract plausibility of events in English. Based on naturally occurring sentences extracted from Wikipedia, we infiltrate degrees of abstractness, and automatically generate perturbed pseudo-implausible events. We annotate a filtered and balanced subset for plausibility using crowd-sourcing, and perform extensive cleansing to ensure annotation quality. In-depth quantitative analyses indicate that annotators favor plausibility over implausibility and disagree more on implausible events. Furthermore, our plausibility dataset is the first to capture abstractness in events to the same extent as concreteness, and we find that event abstractness has an impact on plausibility ratings: more concrete event participants trigger a perception of implausibility.","sentences":["We present a novel dataset for physical and abstract plausibility of events in English.","Based on naturally occurring sentences extracted from Wikipedia, we infiltrate degrees of abstractness, and automatically generate perturbed pseudo-implausible events.","We annotate a filtered and balanced subset for plausibility using crowd-sourcing, and perform extensive cleansing to ensure annotation quality.","In-depth quantitative analyses indicate that annotators favor plausibility over implausibility and disagree more on implausible events.","Furthermore, our plausibility dataset is the first to capture abstractness in events to the same extent as concreteness, and we find that event abstractness has an impact on plausibility ratings: more concrete event participants trigger a perception of implausibility."],"url":"http://arxiv.org/abs/2404.04035v1","category":"cs.CL"}
{"created":"2024-04-05 11:37:02","title":"Arboreal Galois groups for cubic polynomials with colliding critical points","abstract":"Let $K$ be a field, and let $f\\in K(z)$ be a rational function of degree $d\\geq 2$. The Galois group of the field extension generated by the preimages of $x_0\\in K$ under all iterates of $f$ naturally embeds in the automorphism group of an infinite $d$-ary rooted tree. In some cases the Galois group can be the full automorphism group of the tree, but in other cases it is known to have infinite index. In this paper, we consider a previously unstudied such case: that $f$ is a polynomial of degree $d=3$, and the two finite critical points of $f$ collide at the $\\ell$-th iteration, for some $\\ell\\geq 2$. We describe an explicit subgroup $Q_{\\ell,\\infty}$ of automorphisms of the $3$-ary tree in which the resulting Galois group must always embed, and we present sufficient conditions for this embedding to be an isomorphism.","sentences":["Let $K$ be a field, and let $f\\in K(z)$ be a rational function of degree $d\\geq 2$.","The Galois group of the field extension generated by the preimages of $x_0\\in K$ under all iterates of $f$ naturally embeds in the automorphism group of an infinite $d$-ary rooted tree.","In some cases the Galois group can be the full automorphism group of the tree, but in other cases it is known to have infinite index.","In this paper, we consider a previously unstudied such case: that $f$ is a polynomial of degree $d=3$, and the two finite critical points of $f$ collide at the $\\ell$-th iteration, for some $\\ell\\geq 2$. We describe an explicit subgroup $Q_{\\ell,\\infty}$ of automorphisms of the $3$-ary tree in which the resulting Galois group must always embed, and we present sufficient conditions for this embedding to be an isomorphism."],"url":"http://arxiv.org/abs/2404.04034v1","category":"math.NT"}
{"created":"2024-04-05 11:35:21","title":"Impacts of non-thermal emission on the images of black hole shadow and extended jets in two-temperature GRMHD simulations","abstract":"The recent 230 GHz observations from the Event Horizon Telescope collaboration are able to image the innermost structure of the M87 galaxy showing the shadow of the black hole, photon ring, and a ring-like structure that agrees with thermal synchrotron emission from the accretion disc. However, at lower frequencies, M87 is characterized by a large-scale jet with clear signatures of non-thermal emission. It is necessary to explore the impacts of non-thermal emission on black hole shadow images and extended jets, especially at lower frequencies. In this study, we aim to compare models with different electron heating prescriptions to one another and to investigate how these prescriptions and non-thermal electron distributions may affect black hole shadow images and broadband spectrum energy distribution function (SED). We perform general relativistic radiative transfer (GRRT) calculations in various two-temperature general relativistic magnetohydrodynamic (GRMHD) models utilizing different black hole spins and different electron heating prescriptions coupling with different electron distribution functions (eDFs). Through the comparison with GRRT images and SEDs, we found that when considering variable kappa eDF, parameterized prescription of R-beta model with Rh = 1 is similar to the model with electron heating in the morphology of images, and the SEDs at the high-frequency. This is consistent with previous studies using thermal eDFs. However, the nuance between them could be differentiated through the diffuse extended structure seen in GRRT images, especially at a lower frequency, and the behavior of SEDs at low frequency. The emission from the nearside jet region is enhanced for reconnection heating case and it will increase if including the contribution from the regions with stronger magnetization or considering magnetic energy contribution to kappa eDF mainly in the magnetized regions.","sentences":["The recent 230 GHz observations from the Event Horizon Telescope collaboration are able to image the innermost structure of the M87 galaxy showing the shadow of the black hole, photon ring, and a ring-like structure that agrees with thermal synchrotron emission from the accretion disc.","However, at lower frequencies, M87 is characterized by a large-scale jet with clear signatures of non-thermal emission.","It is necessary to explore the impacts of non-thermal emission on black hole shadow images and extended jets, especially at lower frequencies.","In this study, we aim to compare models with different electron heating prescriptions to one another and to investigate how these prescriptions and non-thermal electron distributions may affect black hole shadow images and broadband spectrum energy distribution function (SED).","We perform general relativistic radiative transfer (GRRT) calculations in various two-temperature general relativistic magnetohydrodynamic (GRMHD) models utilizing different black hole spins and different electron heating prescriptions coupling with different electron distribution functions (eDFs).","Through the comparison with GRRT images and SEDs, we found that when considering variable kappa eDF, parameterized prescription of R-beta model with Rh = 1 is similar to the model with electron heating in the morphology of images, and the SEDs at the high-frequency.","This is consistent with previous studies using thermal eDFs.","However, the nuance between them could be differentiated through the diffuse extended structure seen in GRRT images, especially at a lower frequency, and the behavior of SEDs at low frequency.","The emission from the nearside jet region is enhanced for reconnection heating case and it will increase if including the contribution from the regions with stronger magnetization or considering magnetic energy contribution to kappa eDF mainly in the magnetized regions."],"url":"http://arxiv.org/abs/2404.04033v1","category":"astro-ph.HE"}
{"created":"2024-04-05 11:23:35","title":"Effect of magnetospheric conditions on the morphology of Jupiter's UV main auroral emission, as observed by Juno-UVS","abstract":"Auroral emissions are a reflection of magnetospheric processes, and, at Jupiter, it is not entirely certain how the morphology of the UV main emission (ME) varies with magnetospheric compression or the strength of the central current sheet. This work leverages the observations from Juno-UVS to link ME variability with magnetospheric states. Novel arc-detection techniques are used to determine new reference ovals for the ME from perijoves 1 through 54, in both hemispheres, and analyse how the size and shape of the ME vary compared to this reference oval. The morphology and brightness of the ME vary in local time: the dawn-side ME is typically expanded and the dusk-side ME typically contracted compared to the reference oval, and the dusk-side ME being typically twice as bright as the dawn-side ME. Both the northern and southern ME, and the day-side and night-side ME, expand and contract from their reference ovals synchronously, which indicates that the variable size of the ME is caused by a process occurring throughout the jovian magnetosphere. The poleward latitudinal shift of the auroral footprint of Ganymede correlates with the poleward motion of the ME, whereas a similar relation is not present for the footprint of Io. Additionally, the expansion of the ME correlates well with an increase in magnetodisc current. These two results suggest that a changing current-sheet magnetic field is partially responsible for the variable size of the ME. Finally, magnetospheric compression is linked to a global ME contraction and brightening, though this brightening occurs predominantly in the day-side ME. This observation, and the observation that the dusk-side ME is typically brighter than the dawn-side ME, stands in contrast to the modelled and observed behaviour of field-aligned currents and thus weakens the theoretical link between field-aligned currents and the generation of the auroral ME.","sentences":["Auroral emissions are a reflection of magnetospheric processes, and, at Jupiter, it is not entirely certain how the morphology of the UV main emission (ME) varies with magnetospheric compression or the strength of the central current sheet.","This work leverages the observations from Juno-UVS to link ME variability with magnetospheric states.","Novel arc-detection techniques are used to determine new reference ovals for the ME from perijoves 1 through 54, in both hemispheres, and analyse how the size and shape of the ME vary compared to this reference oval.","The morphology and brightness of the ME vary in local time: the dawn-side ME is typically expanded and the dusk-side ME typically contracted compared to the reference oval, and the dusk-side ME being typically twice as bright as the dawn-side ME.","Both the northern and southern ME, and the day-side and night-side ME, expand and contract from their reference ovals synchronously, which indicates that the variable size of the ME is caused by a process occurring throughout the jovian magnetosphere.","The poleward latitudinal shift of the auroral footprint of Ganymede correlates with the poleward motion of the ME, whereas a similar relation is not present for the footprint of Io.","Additionally, the expansion of the ME correlates well with an increase in magnetodisc current.","These two results suggest that a changing current-sheet magnetic field is partially responsible for the variable size of the ME.","Finally, magnetospheric compression is linked to a global ME contraction and brightening, though this brightening occurs predominantly in the day-side ME.","This observation, and the observation that the dusk-side ME is typically brighter than the dawn-side ME, stands in contrast to the modelled and observed behaviour of field-aligned currents and thus weakens the theoretical link between field-aligned currents and the generation of the auroral ME."],"url":"http://arxiv.org/abs/2404.04030v1","category":"astro-ph.EP"}
{"created":"2024-04-05 11:13:59","title":"Framework to generate perfusion map from CT and CTA images in patients with acute ischemic stroke: A longitudinal and cross-sectional study","abstract":"Stroke is a leading cause of disability and death. Effective treatment decisions require early and informative vascular imaging. 4D perfusion imaging is ideal but rarely available within the first hour after stroke, whereas plain CT and CTA usually are. Hence, we propose a framework to extract a predicted perfusion map (PPM) derived from CT and CTA images. In all eighteen patients, we found significantly high spatial similarity (with average Spearman's correlation = 0.7893) between our predicted perfusion map (PPM) and the T-max map derived from 4D-CTP. Voxelwise correlations between the PPM and National Institutes of Health Stroke Scale (NIHSS) subscores for L/R hand motor, gaze, and language on a large cohort of 2,110 subjects reliably mapped symptoms to expected infarct locations. Therefore our PPM could serve as an alternative for 4D perfusion imaging, if the latter is unavailable, to investigate blood perfusion in the first hours after hospital admission.","sentences":["Stroke is a leading cause of disability and death.","Effective treatment decisions require early and informative vascular imaging.","4D perfusion imaging is ideal but rarely available within the first hour after stroke, whereas plain CT and CTA usually are.","Hence, we propose a framework to extract a predicted perfusion map (PPM) derived from CT and CTA images.","In all eighteen patients, we found significantly high spatial similarity (with average Spearman's correlation = 0.7893) between our predicted perfusion map (PPM) and the T-max map derived from 4D-CTP.","Voxelwise correlations between the PPM and National Institutes of Health Stroke Scale (NIHSS) subscores for L/R hand motor, gaze, and language on a large cohort of 2,110 subjects reliably mapped symptoms to expected infarct locations.","Therefore our PPM could serve as an alternative for 4D perfusion imaging, if the latter is unavailable, to investigate blood perfusion in the first hours after hospital admission."],"url":"http://arxiv.org/abs/2404.04025v1","category":"cs.CV"}
{"created":"2024-04-05 11:07:57","title":"Colored Gaussian DAG models","abstract":"We study submodels of Gaussian DAG models defined by partial homogeneity constraints imposed on the model error variances and structural coefficients. We represent these models with colored DAGs and investigate their properties for use in statistical and causal inference. Local and global Markov properties are provided and shown to characterize the colored DAG model. Additional properties relevant to causal discovery are studied, including the existence and non-existence of faithful distributions and structural identifiability. Extending prior work of Peters and B\\\"uhlman and Wu and Drton, we prove structural identifiability under the assumption of homogeneous structural coefficients, as well as for a family of models with partially homogenous structural coefficients. The latter models, termed BPEC-DAGs, capture additional insights as they cluster the direct causes of each node into communities according to their effect on their common target. An analogue of the GES algorithm for learning BPEC-DAGs is given and evaluated on real and synthetic data. Regarding model geometry, we prove that these models are contractible, smooth, algebraic manifolds and compute their dimension. We also provide a proof of a conjecture of Sullivant which generalizes to colored DAG models, colored undirected graphical models and ancestral graph models.","sentences":["We study submodels of Gaussian DAG models defined by partial homogeneity constraints imposed on the model error variances and structural coefficients.","We represent these models with colored DAGs and investigate their properties for use in statistical and causal inference.","Local and global Markov properties are provided and shown to characterize the colored DAG model.","Additional properties relevant to causal discovery are studied, including the existence and non-existence of faithful distributions and structural identifiability.","Extending prior work of Peters and B\\\"uhlman and Wu and Drton, we prove structural identifiability under the assumption of homogeneous structural coefficients, as well as for a family of models with partially homogenous structural coefficients.","The latter models, termed BPEC-DAGs, capture additional insights as they cluster the direct causes of each node into communities according to their effect on their common target.","An analogue of the GES algorithm for learning BPEC-DAGs is given and evaluated on real and synthetic data.","Regarding model geometry, we prove that these models are contractible, smooth, algebraic manifolds and compute their dimension.","We also provide a proof of a conjecture of Sullivant which generalizes to colored DAG models, colored undirected graphical models and ancestral graph models."],"url":"http://arxiv.org/abs/2404.04024v1","category":"math.ST"}
{"created":"2024-04-05 11:05:31","title":"Vacuum correlations of the stress-energy-momentum tensor with constituent quarks","abstract":"The two point correlation function of the stress-energy-momentum tensor describes the propagation of a space-time \"micro-earthquake\" in the vacuum. In the framework of the path integral formulation of field theory in curved space-time, we derive the Ward-Takashi identity for two-point Green's function of the stress-energy-momentum tensor for a general case of a non-conformal theory. The identity constrains the longitudinal part of the correlator, with the vacuum expectation value of the stress-energy-momentum, non-zero in a non-conformal theory. The obtained formula is demonstrated on the free massive Dirac fermion theory, treated at the one-loop level. This example befits a class of phenomenological chiral quarks models which have been used successfully in numerous applications in the soft non-perturbative regime of strong interactions. We discuss the constraints following from the Ward-Takahashi identity for the correlation functions in these models. We also show how the temporal representation of the two-point correlators, which is an object amenable to lattice QCD, displays an expected exponential fall-off.","sentences":["The two point correlation function of the stress-energy-momentum tensor describes the propagation of a space-time \"micro-earthquake\" in the vacuum.","In the framework of the path integral formulation of field theory in curved space-time, we derive the Ward-Takashi identity for two-point Green's function of the stress-energy-momentum tensor for a general case of a non-conformal theory.","The identity constrains the longitudinal part of the correlator, with the vacuum expectation value of the stress-energy-momentum, non-zero in a non-conformal theory.","The obtained formula is demonstrated on the free massive Dirac fermion theory, treated at the one-loop level.","This example befits a class of phenomenological chiral quarks models which have been used successfully in numerous applications in the soft non-perturbative regime of strong interactions.","We discuss the constraints following from the Ward-Takahashi identity for the correlation functions in these models.","We also show how the temporal representation of the two-point correlators, which is an object amenable to lattice QCD, displays an expected exponential fall-off."],"url":"http://arxiv.org/abs/2404.04021v1","category":"hep-ph"}
{"created":"2024-04-05 11:02:09","title":"Bifurcation diagrams of semilinear elliptic equations for supercritical nonlinearities in two dimensions","abstract":"We consider the Gelfand problem with general supercritical nonlinearities in the two-dimensional unit ball. In this paper, we prove the non-existence of an unstable solution for any small parameter and the uniformly boundedness of finite Morse index solutions. As a result, we obtain the existence of a radial singular solution and prove that the bifurcation curve has infinitely many turning points. We remark that these properties are well-known in $N$ dimensions with $3\\le N \\le 9$ and less known in two dimensions. The key idea of the proof is to utilize an interaction between a key gradient estimate of solutions and the supercriticality of the nonlinearities.","sentences":["We consider the Gelfand problem with general supercritical nonlinearities in the two-dimensional unit ball.","In this paper, we prove the non-existence of an unstable solution for any small parameter and the uniformly boundedness of finite Morse index solutions.","As a result, we obtain the existence of a radial singular solution and prove that the bifurcation curve has infinitely many turning points.","We remark that these properties are well-known in $N$ dimensions with $3\\le N \\le 9$ and less known in two dimensions.","The key idea of the proof is to utilize an interaction between a key gradient estimate of solutions and the supercriticality of the nonlinearities."],"url":"http://arxiv.org/abs/2404.04019v1","category":"math.AP"}
{"created":"2024-04-05 11:00:51","title":"Highly efficient NURBS-based isogeometric analysis for coupled nonlinear diffusion-reaction equations with and without advection","abstract":"Nonlinear diffusion-reaction systems model a multitude of physical phenomena. A common situation is biological development modeling where such systems have been widely used to study spatiotemporal phenomena in cell biology. Systems of coupled diffusion-reaction equations are usually subject to some complicated features directly related to their multiphysics nature. Moreover, the presence of advection is source of numerical instabilities, in general, and adds another challenge to these systems. In this study, we propose a NURBS-based isogeometric analysis (IgA) combined with a second-order Strang operator splitting to deal with the multiphysics nature of the problem. The advection part is treated in a semi-Lagrangian framework and the resulting diffusion-reaction equations are then solved using an efficient time-stepping algorithm based on operator splitting. The accuracy of the method is studied by means of a advection-diffusion-reaction system with analytical solution. To further examine the performance of the new method on complex geometries, the well-known Schnakenberg-Turing problem is considered with and without advection. Finally, a Gray-Scott system on a circular domain is also presented. The results obtained demonstrate the efficiency of our new algorithm to accurately reproduce the solution in the presence of complex patterns on complex geometries. Moreover, the new method clarifies the effect of geometry on Turing patterns.","sentences":["Nonlinear diffusion-reaction systems model a multitude of physical phenomena.","A common situation is biological development modeling where such systems have been widely used to study spatiotemporal phenomena in cell biology.","Systems of coupled diffusion-reaction equations are usually subject to some complicated features directly related to their multiphysics nature.","Moreover, the presence of advection is source of numerical instabilities, in general, and adds another challenge to these systems.","In this study, we propose a NURBS-based isogeometric analysis (IgA) combined with a second-order Strang operator splitting to deal with the multiphysics nature of the problem.","The advection part is treated in a semi-Lagrangian framework and the resulting diffusion-reaction equations are then solved using an efficient time-stepping algorithm based on operator splitting.","The accuracy of the method is studied by means of a advection-diffusion-reaction system with analytical solution.","To further examine the performance of the new method on complex geometries, the well-known Schnakenberg-Turing problem is considered with and without advection.","Finally, a Gray-Scott system on a circular domain is also presented.","The results obtained demonstrate the efficiency of our new algorithm to accurately reproduce the solution in the presence of complex patterns on complex geometries.","Moreover, the new method clarifies the effect of geometry on Turing patterns."],"url":"http://arxiv.org/abs/2404.04017v1","category":"math.NA"}
{"created":"2024-04-05 10:58:17","title":"Flavor-spin symmetry of the $P^N_\u03c8/H_{\u03a9_{ccc}}^N$ and $P^\u039b_{\u03c8s}/H^\u039b_{\u03a9_{ccc}s}$ molecular states","abstract":"Based on a contact lagrangian that incorporates the SU(3) flavor and SU(2) spin symmetries, we discuss the symmetry properties of the interactions among the heavy flavor meson-baryon $P_{\\psi}^N$, $P_{\\psi s}^\\Lambda$ (with quark components [$n\\bar{c}$][$nnc$], [$s\\bar{c}$][$nnc$], or [$n\\bar{c}$][$nsc$]) systems and di-baryon $H_{\\Omega_{ccc}}^N$, $H^{\\Lambda}_{\\Omega_{ccc}s}$ (with quark components [$nnc$][$ncc$], [$nnc$][$scc$] or [$nsc$][$ncc$]) systems ($n=u$, $d$). The light quark components of the $P_{\\psi}^N$ ($P_{\\psi s}^\\Lambda$) and $H_{\\Omega_{ccc}}^N$ ($H_{\\Omega_{ccc}s}^\\Lambda$) systems have identical flavors, the interactions generated from the exchanges of light mesons in the $P_{\\psi}^N$ ($P^\\Lambda_{\\psi s}$) systems should be very similar to that of the $H_{\\Omega_{ccc}}^N$ ($H^{\\Lambda}_{\\Omega_{ccc}s}$) systems. We perform the single-channel and multi-channel calculations on the $P_{\\psi}^N/P^\\Lambda_{\\psi s}/H_{\\Omega_{ccc}}^N/H^{\\Lambda}_{\\Omega_{ccc}s}$ systems and introduce the SU(3) breaking effect to identify the different mass spectra among the $P_{\\psi}^N$ ($H_{\\Omega_{ccc}}^N$) and $P^\\Lambda_{\\psi s}$ ($H^{\\Lambda}_{\\Omega_{ccc}s}$) systems. We suggest two kinds of evidences for the existence of the flavor-spin symmetry among the heavy flavor $P_{\\psi}^N/H_{\\Omega_{ccc}}^N/P^\\Lambda_{\\psi s}/H^{\\Lambda}_{\\Omega_{ccc}s}$ molecule community, i.e., the mass arrangements of the $P_{\\psi}^N/H_{\\Omega_{ccc}}^N/P^\\Lambda_{\\psi s}/H^{\\Lambda}_{\\Omega_{ccc}s}$ mass spectra and the binding energies of the heavy flavor meson-baryon (di-baryon) systems attributed to the same contact potentials.","sentences":["Based on a contact lagrangian that incorporates the SU(3) flavor and SU(2) spin symmetries, we discuss the symmetry properties of the interactions among the heavy flavor meson-baryon $P_{\\psi}^N$, $P_{\\psi s}^\\Lambda$ (with quark components [$n\\bar{c}$][$nnc$], [$s\\bar{c}$][$nnc$], or [$n\\bar{c}$][$nsc$]) systems and di-baryon $H_{\\Omega_{ccc}}^N$, $H^{\\Lambda}_{\\Omega_{ccc}s}$ (with quark components [$nnc$][$ncc$], [$nnc$][$scc$] or [$nsc$][$ncc$]) systems ($n=u$, $d$).","The light quark components of the $P_{\\psi}^N$ ($P_{\\psi s}^\\Lambda$) and $H_{\\Omega_{ccc}}^N$ ($H_{\\Omega_{ccc}s}^\\Lambda$) systems have identical flavors, the interactions generated from the exchanges of light mesons in the $P_{\\psi}^N$ ($P^\\Lambda_{\\psi s}$) systems should be very similar to that of the $H_{\\Omega_{ccc}}^N$ ($H^{\\Lambda}_{\\Omega_{ccc}s}$) systems.","We perform the single-channel and multi-channel calculations on the $P_{\\psi}^N/P^\\Lambda_{\\psi s}/H_{\\Omega_{ccc}}^N/H^{\\Lambda}_{\\Omega_{ccc}s}$ systems and introduce the SU(3) breaking effect to identify the different mass spectra among the $P_{\\psi}^N$ ($H_{\\Omega_{ccc}}^N$) and $P^\\Lambda_{\\psi s}$ ($H^{\\Lambda}_{\\Omega_{ccc}s}$) systems.","We suggest two kinds of evidences for the existence of the flavor-spin symmetry among the heavy flavor $P_{\\psi}^N/H_{\\Omega_{ccc}}^N/P^\\Lambda_{\\psi s}/H^{\\Lambda}_{\\Omega_{ccc}s}$ molecule community, i.e., the mass arrangements of the $P_{\\psi}^N/H_{\\Omega_{ccc}}^N/P^\\Lambda_{\\psi s}/H^{\\Lambda}_{\\Omega_{ccc}s}$ mass spectra and the binding energies of the heavy flavor meson-baryon (di-baryon) systems attributed to the same contact potentials."],"url":"http://arxiv.org/abs/2404.04016v1","category":"hep-ph"}
{"created":"2024-04-05 10:51:40","title":"A Flexible Evolutionary Algorithm With Dynamic Mutation Rate Archive","abstract":"We propose a new, flexible approach for dynamically maintaining successful mutation rates in evolutionary algorithms using $k$-bit flip mutations. The algorithm adds successful mutation rates to an archive of promising rates that are favored in subsequent steps. Rates expire when their number of unsuccessful trials has exceeded a threshold, while rates currently not present in the archive can enter it in two ways: (i) via user-defined minimum selection probabilities for rates combined with a successful step or (ii) via a stagnation detection mechanism increasing the value for a promising rate after the current bit-flip neighborhood has been explored with high probability. For the minimum selection probabilities, we suggest different options, including heavy-tailed distributions.   We conduct rigorous runtime analysis of the flexible evolutionary algorithm on the OneMax and Jump functions, on general unimodal functions, on minimum spanning trees, and on a class of hurdle-like functions with varying hurdle width that benefit particularly from the archive of promising mutation rates. In all cases, the runtime bounds are close to or even outperform the best known results for both stagnation detection and heavy-tailed mutations.","sentences":["We propose a new, flexible approach for dynamically maintaining successful mutation rates in evolutionary algorithms using $k$-bit flip mutations.","The algorithm adds successful mutation rates to an archive of promising rates that are favored in subsequent steps.","Rates expire when their number of unsuccessful trials has exceeded a threshold, while rates currently not present in the archive can enter it in two ways: (i) via user-defined minimum selection probabilities for rates combined with a successful step or (ii) via a stagnation detection mechanism increasing the value for a promising rate after the current bit-flip neighborhood has been explored with high probability.","For the minimum selection probabilities, we suggest different options, including heavy-tailed distributions.   ","We conduct rigorous runtime analysis of the flexible evolutionary algorithm on the OneMax and Jump functions, on general unimodal functions, on minimum spanning trees, and on a class of hurdle-like functions with varying hurdle width that benefit particularly from the archive of promising mutation rates.","In all cases, the runtime bounds are close to or even outperform the best known results for both stagnation detection and heavy-tailed mutations."],"url":"http://arxiv.org/abs/2404.04015v1","category":"cs.NE"}
{"created":"2024-04-05 10:40:20","title":"Tidal heating as a discriminator for horizons in equatorial eccentric extreme mass ratio inspirals","abstract":"Tidal heating in a binary black hole system is driven by the absorption of energy and angular momentum by the black hole's horizon. Previous works have shown that this phenomenon becomes particularly significant during the late stages of an extreme mass ratio inspiral (EMRI) into a rapidly spinning massive black hole, a key focus for future low-frequency gravitational-wave observations by (for instance) the LISA mission. Past analyses have largely focused on quasi-circular inspiral geometry, with some of the most detailed studies looking at equatorial cases. Though useful for illustrating the physical principles, this limit is not very realistic astrophysically, since the population of EMRI events is expected to arise from compact objects scattered onto relativistic orbits in galactic centers through many-body events. In this work, we extend those results by studying the importance of tidal heating in equatorial EMRIs with generic eccentricities. Our results suggest that accurate modeling of tidal heating is crucial to prevent significant dephasing and systematic errors in EMRI parameter estimation. We examine a phenomenological model for EMRIs around exotic compact objects by parameterizing deviations from the black hole picture in terms of the fraction of radiation absorbed compared to the BH case. Based on a mismatch calculation we find that reflectivities as small as $|\\mathcal{R}|^2 \\sim \\mathcal{O}(10^{-5})$ are distinguishable from the BH case, irrespective of the value of the eccentricity. We stress, however, that this finding should be corroborated by future parameter estimation studies.","sentences":["Tidal heating in a binary black hole system is driven by the absorption of energy and angular momentum by the black hole's horizon.","Previous works have shown that this phenomenon becomes particularly significant during the late stages of an extreme mass ratio inspiral (EMRI) into a rapidly spinning massive black hole, a key focus for future low-frequency gravitational-wave observations by (for instance) the LISA mission.","Past analyses have largely focused on quasi-circular inspiral geometry, with some of the most detailed studies looking at equatorial cases.","Though useful for illustrating the physical principles, this limit is not very realistic astrophysically, since the population of EMRI events is expected to arise from compact objects scattered onto relativistic orbits in galactic centers through many-body events.","In this work, we extend those results by studying the importance of tidal heating in equatorial EMRIs with generic eccentricities.","Our results suggest that accurate modeling of tidal heating is crucial to prevent significant dephasing and systematic errors in EMRI parameter estimation.","We examine a phenomenological model for EMRIs around exotic compact objects by parameterizing deviations from the black hole picture in terms of the fraction of radiation absorbed compared to the BH case.","Based on a mismatch calculation we find that reflectivities as small as $|\\mathcal{R}|^2 \\sim \\mathcal{O}(10^{-5})$ are distinguishable from the BH case, irrespective of the value of the eccentricity.","We stress, however, that this finding should be corroborated by future parameter estimation studies."],"url":"http://arxiv.org/abs/2404.04013v1","category":"gr-qc"}
{"created":"2024-04-05 10:39:11","title":"Next Generation Multiple Access for IMT Towards 2030 and Beyond","abstract":"Multiple access techniques are fundamental to the design of wireless communication systems, since many crucial components of such systems depend on the choice of the multiple access technique. Because of the importance of multiple access, there has been an ongoing quest during the past decade to develop next generation multiple access (NGMA). Among those potential candidates for NGMA, non-orthogonal multiple access (NOMA) has received significant attention from both the industrial and academic research communities, and has been highlighted in the recently published International Mobile Telecommunications (IMT)-2030 Framework. However, there is still no consensus in the research community about how exactly NOMA assisted NGMA should be designed. This perspective is to outline three important features of NOMA assisted NGMA, namely multi-domain utilization, multi-mode compatibility, and multi-dimensional optimality, where important directions for future research into the design of NOMA assisted NGMA are also discussed.","sentences":["Multiple access techniques are fundamental to the design of wireless communication systems, since many crucial components of such systems depend on the choice of the multiple access technique.","Because of the importance of multiple access, there has been an ongoing quest during the past decade to develop next generation multiple access (NGMA).","Among those potential candidates for NGMA, non-orthogonal multiple access (NOMA) has received significant attention from both the industrial and academic research communities, and has been highlighted in the recently published International Mobile Telecommunications (IMT)-2030 Framework.","However, there is still no consensus in the research community about how exactly NOMA assisted NGMA should be designed.","This perspective is to outline three important features of NOMA assisted NGMA, namely multi-domain utilization, multi-mode compatibility, and multi-dimensional optimality, where important directions for future research into the design of NOMA assisted NGMA are also discussed."],"url":"http://arxiv.org/abs/2404.04012v1","category":"cs.IT"}
{"created":"2024-04-05 10:38:33","title":"Validation of critical maneuvers based on shared control","abstract":"This paper presents the validation of shared control strategies for critical maneuvers in automated driving systems. Shared control involves collaboration between the driver and automation, allowing both parties to actively engage and cooperate at different levels of the driving task. The involvement of the driver adds complexity to the control loop, necessitating comprehensive validation methodologies. The proposed approach focuses on two critical maneuvers: overtaking in low visibility scenarios and lateral evasive actions. A modular architecture with an arbitration module and shared control algorithms is implemented, primarily focusing on the lateral control of the vehicle. The validation is conducted using a dynamic simulator, involving 8 real drivers interacting with a virtual environment. The results demonstrate improved safety and user acceptance, indicating the effectiveness of the shared control strategies in comparison with no shared-control support. Future work involves implementing shared control in drive-by-wire systems to enhance safety and driver comfort during critical maneuvers. Overall, this research contributes to the development and validation of shared control approaches in automated driving systems.","sentences":["This paper presents the validation of shared control strategies for critical maneuvers in automated driving systems.","Shared control involves collaboration between the driver and automation, allowing both parties to actively engage and cooperate at different levels of the driving task.","The involvement of the driver adds complexity to the control loop, necessitating comprehensive validation methodologies.","The proposed approach focuses on two critical maneuvers: overtaking in low visibility scenarios and lateral evasive actions.","A modular architecture with an arbitration module and shared control algorithms is implemented, primarily focusing on the lateral control of the vehicle.","The validation is conducted using a dynamic simulator, involving 8 real drivers interacting with a virtual environment.","The results demonstrate improved safety and user acceptance, indicating the effectiveness of the shared control strategies in comparison with no shared-control support.","Future work involves implementing shared control in drive-by-wire systems to enhance safety and driver comfort during critical maneuvers.","Overall, this research contributes to the development and validation of shared control approaches in automated driving systems."],"url":"http://arxiv.org/abs/2404.04011v1","category":"cs.HC"}
{"created":"2024-04-05 10:36:11","title":"Maximal mass of the neutron star with a deconfined quark core","abstract":"The nature of equation of state for the matter in the neutron star plays an important role in determining its maximal mass. In addition, it must comply with the condition of causality. Noting that the central density of a maximally massive neutron star is well above the nuclear saturation density, a deconfined quark core in the central region is motivated in this paper. We analyze this scenario by employing the MIT bag model to represent the core region and one of the unified equations of state for the region outside the core. Such combination is found to solve the problem of causality violation. In each case of the combined equations of state, the radial profile of $\\rho r^2$ displays a peak and dominant contribution to the total mass of the star comes from the region around the peak value of $\\rho r^2$, whereas the contribution is small from the regions near the center and the surface. This peak occurs in the region of hadronic matter for the combinations considered in this paper. Importantly, we find that the position of the peak in $\\rho r^2$ is well-correlated with the maximal mass -- the highest value of $1.98\\ M_\\odot$ obtains for the case with the peak occurring farthest from the center. This gravitational threshold being obtained for a non-rotating neutron star, we expect the threshold to lie well above 2 $ M_\\odot$ for a rapidly rotating neutron star, that may explain the existance of massive pulsars from recent astronomical observations.","sentences":["The nature of equation of state for the matter in the neutron star plays an important role in determining its maximal mass.","In addition, it must comply with the condition of causality.","Noting that the central density of a maximally massive neutron star is well above the nuclear saturation density, a deconfined quark core in the central region is motivated in this paper.","We analyze this scenario by employing the MIT bag model to represent the core region and one of the unified equations of state for the region outside the core.","Such combination is found to solve the problem of causality violation.","In each case of the combined equations of state, the radial profile of $\\rho r^2$ displays a peak and dominant contribution to the total mass of the star comes from the region around the peak value of $\\rho r^2$, whereas the contribution is small from the regions near the center and the surface.","This peak occurs in the region of hadronic matter for the combinations considered in this paper.","Importantly, we find that the position of the peak in $\\rho r^2$ is well-correlated with the maximal mass -- the highest value of $1.98\\ M_\\odot$ obtains for the case with the peak occurring farthest from the center.","This gravitational threshold being obtained for a non-rotating neutron star, we expect the threshold to lie well above 2 $ M_\\odot$ for a rapidly rotating neutron star, that may explain the existance of massive pulsars from recent astronomical observations."],"url":"http://arxiv.org/abs/2404.04009v1","category":"astro-ph.HE"}
{"created":"2024-04-05 10:25:26","title":"Approximate UMAP allows for high-rate online visualization of high-dimensional data streams","abstract":"In the BCI field, introspection and interpretation of brain signals are desired for providing feedback or to guide rapid paradigm prototyping but are challenging due to the high noise level and dimensionality of the signals. Deep neural networks are often introspected by transforming their learned feature representations into 2- or 3-dimensional subspace visualizations using projection algorithms like Uniform Manifold Approximation and Projection (UMAP). Unfortunately, these methods are computationally expensive, making the projection of data streams in real-time a non-trivial task. In this study, we introduce a novel variant of UMAP, called approximate UMAP (aUMAP). It aims at generating rapid projections for real-time introspection. To study its suitability for real-time projecting, we benchmark the methods against standard UMAP and its neural network counterpart parametric UMAP. Our results show that approximate UMAP delivers projections that replicate the projection space of standard UMAP while decreasing projection speed by an order of magnitude and maintaining the same training time.","sentences":["In the BCI field, introspection and interpretation of brain signals are desired for providing feedback or to guide rapid paradigm prototyping but are challenging due to the high noise level and dimensionality of the signals.","Deep neural networks are often introspected by transforming their learned feature representations into 2- or 3-dimensional subspace visualizations using projection algorithms like Uniform Manifold Approximation and Projection (UMAP).","Unfortunately, these methods are computationally expensive, making the projection of data streams in real-time a non-trivial task.","In this study, we introduce a novel variant of UMAP, called approximate UMAP (aUMAP).","It aims at generating rapid projections for real-time introspection.","To study its suitability for real-time projecting, we benchmark the methods against standard UMAP and its neural network counterpart parametric UMAP.","Our results show that approximate UMAP delivers projections that replicate the projection space of standard UMAP while decreasing projection speed by an order of magnitude and maintaining the same training time."],"url":"http://arxiv.org/abs/2404.04001v1","category":"cs.LG"}
{"created":"2024-04-05 10:23:20","title":"Finsler-Laplace-Beltrami Operators with Application to Shape Analysis","abstract":"The Laplace-Beltrami operator (LBO) emerges from studying manifolds equipped with a Riemannian metric. It is often called the Swiss army knife of geometry processing as it allows to capture intrinsic shape information and gives rise to heat diffusion, geodesic distances, and a multitude of shape descriptors. It also plays a central role in geometric deep learning. In this work, we explore Finsler manifolds as a generalization of Riemannian manifolds. We revisit the Finsler heat equation and derive a Finsler heat kernel and a Finsler-Laplace-Beltrami Operator (FLBO): a novel theoretically justified anisotropic Laplace-Beltrami operator (ALBO). In experimental evaluations we demonstrate that the proposed FLBO is a valuable alternative to the traditional Riemannian-based LBO and ALBOs for spatial filtering and shape correspondence estimation. We hope that the proposed Finsler heat kernel and the FLBO will inspire further exploration of Finsler geometry in the computer vision community.","sentences":["The Laplace-Beltrami operator (LBO) emerges from studying manifolds equipped with a Riemannian metric.","It is often called the Swiss army knife of geometry processing as it allows to capture intrinsic shape information and gives rise to heat diffusion, geodesic distances, and a multitude of shape descriptors.","It also plays a central role in geometric deep learning.","In this work, we explore Finsler manifolds as a generalization of Riemannian manifolds.","We revisit the Finsler heat equation and derive a Finsler heat kernel and a Finsler-Laplace-Beltrami Operator (FLBO): a novel theoretically justified anisotropic Laplace-Beltrami operator (ALBO).","In experimental evaluations we demonstrate that the proposed FLBO is a valuable alternative to the traditional Riemannian-based LBO and ALBOs for spatial filtering and shape correspondence estimation.","We hope that the proposed Finsler heat kernel and the FLBO will inspire further exploration of Finsler geometry in the computer vision community."],"url":"http://arxiv.org/abs/2404.03999v1","category":"cs.CV"}
{"created":"2024-04-05 10:19:04","title":"Demonstration Guided Multi-Objective Reinforcement Learning","abstract":"Multi-objective reinforcement learning (MORL) is increasingly relevant due to its resemblance to real-world scenarios requiring trade-offs between multiple objectives. Catering to diverse user preferences, traditional reinforcement learning faces amplified challenges in MORL. To address the difficulty of training policies from scratch in MORL, we introduce demonstration-guided multi-objective reinforcement learning (DG-MORL). This novel approach utilizes prior demonstrations, aligns them with user preferences via corner weight support, and incorporates a self-evolving mechanism to refine suboptimal demonstrations. Our empirical studies demonstrate DG-MORL's superiority over existing MORL algorithms, establishing its robustness and efficacy, particularly under challenging conditions. We also provide an upper bound of the algorithm's sample complexity.","sentences":["Multi-objective reinforcement learning (MORL) is increasingly relevant due to its resemblance to real-world scenarios requiring trade-offs between multiple objectives.","Catering to diverse user preferences, traditional reinforcement learning faces amplified challenges in MORL.","To address the difficulty of training policies from scratch in MORL, we introduce demonstration-guided multi-objective reinforcement learning (DG-MORL).","This novel approach utilizes prior demonstrations, aligns them with user preferences via corner weight support, and incorporates a self-evolving mechanism to refine suboptimal demonstrations.","Our empirical studies demonstrate DG-MORL's superiority over existing MORL algorithms, establishing its robustness and efficacy, particularly under challenging conditions.","We also provide an upper bound of the algorithm's sample complexity."],"url":"http://arxiv.org/abs/2404.03997v1","category":"cs.LG"}
{"created":"2024-04-05 10:15:24","title":"Fast Genetic Algorithm for feature selection -- A qualitative approximation approach","abstract":"Evolutionary Algorithms (EAs) are often challenging to apply in real-world settings since evolutionary computations involve a large number of evaluations of a typically expensive fitness function. For example, an evaluation could involve training a new machine learning model. An approximation (also known as meta-model or a surrogate) of the true function can be used in such applications to alleviate the computation cost. In this paper, we propose a two-stage surrogate-assisted evolutionary approach to address the computational issues arising from using Genetic Algorithm (GA) for feature selection in a wrapper setting for large datasets. We define 'Approximation Usefulness' to capture the necessary conditions to ensure correctness of the EA computations when an approximation is used. Based on this definition, we propose a procedure to construct a lightweight qualitative meta-model by the active selection of data instances. We then use a meta-model to carry out the feature selection task. We apply this procedure to the GA-based algorithm CHC (Cross generational elitist selection, Heterogeneous recombination and Cataclysmic mutation) to create a Qualitative approXimations variant, CHCQX. We show that CHCQX converges faster to feature subset solutions of significantly higher accuracy (as compared to CHC), particularly for large datasets with over 100K instances. We also demonstrate the applicability of the thinking behind our approach more broadly to Swarm Intelligence (SI), another branch of the Evolutionary Computation (EC) paradigm with results of PSOQX, a qualitative approximation adaptation of the Particle Swarm Optimization (PSO) method. A GitHub repository with the complete implementation is available.","sentences":["Evolutionary Algorithms (EAs) are often challenging to apply in real-world settings since evolutionary computations involve a large number of evaluations of a typically expensive fitness function.","For example, an evaluation could involve training a new machine learning model.","An approximation (also known as meta-model or a surrogate) of the true function can be used in such applications to alleviate the computation cost.","In this paper, we propose a two-stage surrogate-assisted evolutionary approach to address the computational issues arising from using Genetic Algorithm (GA) for feature selection in a wrapper setting for large datasets.","We define 'Approximation Usefulness' to capture the necessary conditions to ensure correctness of the EA computations when an approximation is used.","Based on this definition, we propose a procedure to construct a lightweight qualitative meta-model by the active selection of data instances.","We then use a meta-model to carry out the feature selection task.","We apply this procedure to the GA-based algorithm CHC (Cross generational elitist selection, Heterogeneous recombination and Cataclysmic mutation) to create a Qualitative approXimations variant, CHCQX.","We show that CHCQX converges faster to feature subset solutions of significantly higher accuracy (as compared to CHC), particularly for large datasets with over 100K instances.","We also demonstrate the applicability of the thinking behind our approach more broadly to Swarm Intelligence (SI), another branch of the Evolutionary Computation (EC) paradigm with results of PSOQX, a qualitative approximation adaptation of the Particle Swarm Optimization (PSO) method.","A GitHub repository with the complete implementation is available."],"url":"http://arxiv.org/abs/2404.03996v1","category":"cs.NE"}
{"created":"2024-04-05 10:11:08","title":"Balancing Progress and Responsibility: A Synthesis of Sustainability Trade-Offs of AI-Based Systems","abstract":"Recent advances in artificial intelligence (AI) capabilities have increased the eagerness of companies to integrate AI into software systems. While AI can be used to have a positive impact on several dimensions of sustainability, this is often overshadowed by its potential negative influence. While many studies have explored sustainability factors in isolation, there is insufficient holistic coverage of potential sustainability benefits or costs that practitioners need to consider during decision-making for AI adoption. We therefore aim to synthesize trade-offs related to sustainability in the context of integrating AI into software systems. We want to make the sustainability benefits and costs of integrating AI more transparent and accessible for practitioners.   The study was conducted in collaboration with a Dutch financial organization. We first performed a rapid review that led to the inclusion of 151 research papers. Afterward, we conducted six semi-structured interviews to enrich the data with industry perspectives. The combined results showcase the potential sustainability benefits and costs of integrating AI. The labels synthesized from the review regarding potential sustainability benefits were clustered into 16 themes, with \"energy management\" being the most frequently mentioned one. 11 themes were identified in the interviews, with the top mentioned theme being \"employee wellbeing\". Regarding sustainability costs, the review discovered seven themes, with \"deployment issues\" being the most popular one, followed by \"ethics & society\". \"Environmental issues\" was the top theme from the interviews. Our results provide valuable insights to organizations and practitioners for understanding the potential sustainability implications of adopting AI.","sentences":["Recent advances in artificial intelligence (AI) capabilities have increased the eagerness of companies to integrate AI into software systems.","While AI can be used to have a positive impact on several dimensions of sustainability, this is often overshadowed by its potential negative influence.","While many studies have explored sustainability factors in isolation, there is insufficient holistic coverage of potential sustainability benefits or costs that practitioners need to consider during decision-making for AI adoption.","We therefore aim to synthesize trade-offs related to sustainability in the context of integrating AI into software systems.","We want to make the sustainability benefits and costs of integrating AI more transparent and accessible for practitioners.   ","The study was conducted in collaboration with a Dutch financial organization.","We first performed a rapid review that led to the inclusion of 151 research papers.","Afterward, we conducted six semi-structured interviews to enrich the data with industry perspectives.","The combined results showcase the potential sustainability benefits and costs of integrating AI.","The labels synthesized from the review regarding potential sustainability benefits were clustered into 16 themes, with \"energy management\" being the most frequently mentioned one.","11 themes were identified in the interviews, with the top mentioned theme being \"employee wellbeing\".","Regarding sustainability costs, the review discovered seven themes, with \"deployment issues\" being the most popular one, followed by \"ethics & society\".","\"Environmental issues\" was the top theme from the interviews.","Our results provide valuable insights to organizations and practitioners for understanding the potential sustainability implications of adopting AI."],"url":"http://arxiv.org/abs/2404.03995v1","category":"cs.SE"}
{"created":"2024-04-05 10:08:34","title":"Pros and Cons! Evaluating ChatGPT on Software Vulnerability","abstract":"This paper proposes a pipeline for quantitatively evaluating interactive LLMs such as ChatGPT using publicly available dataset. We carry out an extensive technical evaluation of ChatGPT using Big-Vul covering five different common software vulnerability tasks. We evaluate the multitask and multilingual aspects of ChatGPT based on this dataset. We found that the existing state-of-the-art methods are generally superior to ChatGPT in software vulnerability detection. Although ChatGPT improves accuracy when providing context information, it still has limitations in accurately predicting severity ratings for certain CWE types. In addition, ChatGPT demonstrates some ability in locating vulnerabilities for certain CWE types, but its performance varies among different CWE types. ChatGPT exhibits limited vulnerability repair capabilities in both providing and not providing context information. Finally, ChatGPT shows uneven performance in generating CVE descriptions for various CWE types, with limited accuracy in detailed information. Overall, though ChatGPT performs well in some aspects, it still needs improvement in understanding the subtle differences in code vulnerabilities and the ability to describe vulnerabilities in order to fully realize its potential. Our evaluation framework provides valuable insights for further enhancing ChatGPT' s software vulnerability handling capabilities.","sentences":["This paper proposes a pipeline for quantitatively evaluating interactive LLMs such as ChatGPT using publicly available dataset.","We carry out an extensive technical evaluation of ChatGPT using Big-Vul covering five different common software vulnerability tasks.","We evaluate the multitask and multilingual aspects of ChatGPT based on this dataset.","We found that the existing state-of-the-art methods are generally superior to ChatGPT in software vulnerability detection.","Although ChatGPT improves accuracy when providing context information, it still has limitations in accurately predicting severity ratings for certain CWE types.","In addition, ChatGPT demonstrates some ability in locating vulnerabilities for certain CWE types, but its performance varies among different CWE types.","ChatGPT exhibits limited vulnerability repair capabilities in both providing and not providing context information.","Finally, ChatGPT shows uneven performance in generating CVE descriptions for various CWE types, with limited accuracy in detailed information.","Overall, though ChatGPT performs well in some aspects, it still needs improvement in understanding the subtle differences in code vulnerabilities and the ability to describe vulnerabilities in order to fully realize its potential.","Our evaluation framework provides valuable insights for further enhancing ChatGPT' s software vulnerability handling capabilities."],"url":"http://arxiv.org/abs/2404.03994v1","category":"cs.SE"}
{"created":"2024-04-05 10:02:32","title":"Rolling the dice for better deep learning performance: A study of randomness techniques in deep neural networks","abstract":"This paper investigates how various randomization techniques impact Deep Neural Networks (DNNs). Randomization, like weight noise and dropout, aids in reducing overfitting and enhancing generalization, but their interactions are poorly understood. The study categorizes randomness techniques into four types and proposes new methods: adding noise to the loss function and random masking of gradient updates. Using Particle Swarm Optimizer (PSO) for hyperparameter optimization, it explores optimal configurations across MNIST, FASHION-MNIST, CIFAR10, and CIFAR100 datasets. Over 30,000 configurations are evaluated, revealing data augmentation and weight initialization randomness as main performance contributors. Correlation analysis shows different optimizers prefer distinct randomization types. The complete implementation and dataset are available on GitHub.","sentences":["This paper investigates how various randomization techniques impact Deep Neural Networks (DNNs).","Randomization, like weight noise and dropout, aids in reducing overfitting and enhancing generalization, but their interactions are poorly understood.","The study categorizes randomness techniques into four types and proposes new methods: adding noise to the loss function and random masking of gradient updates.","Using Particle Swarm Optimizer (PSO) for hyperparameter optimization, it explores optimal configurations across MNIST, FASHION-MNIST, CIFAR10, and CIFAR100 datasets.","Over 30,000 configurations are evaluated, revealing data augmentation and weight initialization randomness as main performance contributors.","Correlation analysis shows different optimizers prefer distinct randomization types.","The complete implementation and dataset are available on GitHub."],"url":"http://arxiv.org/abs/2404.03992v1","category":"cs.LG"}
{"created":"2024-04-05 09:52:59","title":"Instruments And Effects Of Monetary And Fiscal Policy: The Relationship Between Inflation, Vat, And Deposit Interest Rate","abstract":"In this study, we aimed to examine the effect of VAT revenues and Deposit Interest Rates on Inflation in Turkey between 1985-2022. Within the framework of econometric analysis of the obtained data, the analysis was carried out using ADF unit root test, Johansen Co-Integration Test, Error Terms and VECM (Vector Error Correction Model) models. According to the analysis results, it was understood that the data were stationary at the I(I) level, it was determined that there was a cointegrated relationship between them in the long term, and by estimating the error term, causality findings were determined within the framework of VECM analysis. According to the causality results of the Wald Test; causality is found from Deposit Interest Rate to VAT and Inflation, and from Inflation to VAT and Deposit Interest Rate (bidirectional), while causality is also found from VAT to Inflation and Deposit Interest Rates.","sentences":["In this study, we aimed to examine the effect of VAT revenues and Deposit Interest Rates on Inflation in Turkey between 1985-2022.","Within the framework of econometric analysis of the obtained data, the analysis was carried out using ADF unit root test, Johansen Co-Integration Test, Error Terms and VECM (Vector Error Correction Model) models.","According to the analysis results, it was understood that the data were stationary at the I(I) level, it was determined that there was a cointegrated relationship between them in the long term, and by estimating the error term, causality findings were determined within the framework of VECM analysis.","According to the causality results of the Wald Test; causality is found from Deposit Interest Rate to VAT and Inflation, and from Inflation to VAT and Deposit Interest Rate (bidirectional), while causality is also found from VAT to Inflation and Deposit Interest Rates."],"url":"http://arxiv.org/abs/2404.03989v1","category":"econ.GN"}
{"created":"2024-04-05 09:48:00","title":"Investigating the Robustness of Modelling Decisions for Few-Shot Cross-Topic Stance Detection: A Preregistered Study","abstract":"For a viewpoint-diverse news recommender, identifying whether two news articles express the same viewpoint is essential. One way to determine \"same or different\" viewpoint is stance detection. In this paper, we investigate the robustness of operationalization choices for few-shot stance detection, with special attention to modelling stance across different topics. Our experiments test pre-registered hypotheses on stance detection. Specifically, we compare two stance task definitions (Pro/Con versus Same Side Stance), two LLM architectures (bi-encoding versus cross-encoding), and adding Natural Language Inference knowledge, with pre-trained RoBERTa models trained with shots of 100 examples from 7 different stance detection datasets. Some of our hypotheses and claims from earlier work can be confirmed, while others give more inconsistent results. The effect of the Same Side Stance definition on performance differs per dataset and is influenced by other modelling choices. We found no relationship between the number of training topics in the training shots and performance. In general, cross-encoding out-performs bi-encoding, and adding NLI training to our models gives considerable improvement, but these results are not consistent across all datasets. Our results indicate that it is essential to include multiple datasets and systematic modelling experiments when aiming to find robust modelling choices for the concept `stance'.","sentences":["For a viewpoint-diverse news recommender, identifying whether two news articles express the same viewpoint is essential.","One way to determine \"same or different\" viewpoint is stance detection.","In this paper, we investigate the robustness of operationalization choices for few-shot stance detection, with special attention to modelling stance across different topics.","Our experiments test pre-registered hypotheses on stance detection.","Specifically, we compare two stance task definitions (Pro/Con versus Same Side Stance), two LLM architectures (bi-encoding versus cross-encoding), and adding Natural Language Inference knowledge, with pre-trained RoBERTa models trained with shots of 100 examples from 7 different stance detection datasets.","Some of our hypotheses and claims from earlier work can be confirmed, while others give more inconsistent results.","The effect of the Same Side Stance definition on performance differs per dataset and is influenced by other modelling choices.","We found no relationship between the number of training topics in the training shots and performance.","In general, cross-encoding out-performs bi-encoding, and adding NLI training to our models gives considerable improvement, but these results are not consistent across all datasets.","Our results indicate that it is essential to include multiple datasets and systematic modelling experiments when aiming to find robust modelling choices for the concept `stance'."],"url":"http://arxiv.org/abs/2404.03987v1","category":"cs.CL"}
{"created":"2024-04-05 09:22:43","title":"Approximation Schemes for Geometric Knapsack for Packing Spheres and Fat Objects","abstract":"We study the geometric knapsack problem in which we are given a set of $d$-dimensional objects (each with associated profits) and the goal is to find the maximum profit subset that can be packed non-overlappingly into a given $d$-dimensional (unit hypercube) knapsack. Even if $d=2$ and all input objects are disks, this problem is known to be NP-hard [Demaine, Fekete, Lang, 2010]. In this paper, we give polynomial-time $(1+\\varepsilon)$-approximation algorithms for the following types of input objects in any constant dimension $d$:   - disks and hyperspheres,   - a class of fat convex polygons that generalizes regular $k$-gons for $k\\ge 5$ (formally, polygons with a constant number of edges, whose lengths are in a bounded range, and in which each angle is strictly larger than $\\pi/2$)   - arbitrary fat convex objects that are sufficiently small compared to the knapsack.   We remark that in our \\textsf{PTAS} for disks and hyperspheres, we output the computed set of objects, but for a $O_\\varepsilon(1)$ of them we determine their coordinates only up to an exponentially small error. However, it is not clear whether there always exists a $(1+\\varepsilon)$-approximate solution that uses only rational coordinates for the disks' centers. We leave this as an open problem which is related to well-studied geometric questions in the realm of circle packing.","sentences":["We study the geometric knapsack problem in which we are given a set of $d$-dimensional objects (each with associated profits) and the goal is to find the maximum profit subset that can be packed non-overlappingly into a given $d$-dimensional (unit hypercube) knapsack.","Even if $d=2$ and all input objects are disks, this problem is known to be NP-hard [Demaine, Fekete, Lang, 2010].","In this paper, we give polynomial-time $(1+\\varepsilon)$-approximation algorithms for the following types of input objects in any constant dimension $d$:   - disks and hyperspheres,   - a class of fat convex polygons that generalizes regular $k$-gons for $k\\ge 5$ (formally, polygons with a constant number of edges, whose lengths are in a bounded range, and in which each angle is strictly larger than $\\pi/2$)   - arbitrary fat convex objects that are sufficiently small compared to the knapsack.   ","We remark that in our \\textsf{PTAS} for disks and hyperspheres, we output the computed set of objects, but for a $O_\\varepsilon(1)$ of them we determine their coordinates only up to an exponentially small error.","However, it is not clear whether there always exists a $(1+\\varepsilon)$-approximate solution that uses only rational coordinates for the disks' centers.","We leave this as an open problem which is related to well-studied geometric questions in the realm of circle packing."],"url":"http://arxiv.org/abs/2404.03981v1","category":"cs.CG"}
{"created":"2024-04-05 09:21:29","title":"Stability in Graphs with Matroid Constraints","abstract":"We study the following Independent Stable Set problem. Let G be an undirected graph and M = (V(G),I) be a matroid whose elements are the vertices of G. For an integer k\\geq 1, the task is to decide whether G contains a set S\\subseteq V(G) of size at least k which is independent (stable) in G and independent in M. This problem generalizes several well-studied algorithmic problems, including Rainbow Independent Set, Rainbow Matching, and Bipartite Matching with Separation. We show that   - When the matroid M is represented by the independence oracle, then for any computable function f, no algorithm can solve Independent Stable Set using f(k)n^{o(k)} calls to the oracle.   - On the other hand, when the graph G is of degeneracy d, then the problem is solvable in time O((d+1)^kn), and hence is FPT parameterized by d+k. Moreover, when the degeneracy d is a constant (which is not a part of the input), the problem admits a kernel polynomial in k. More precisely, we prove that for every integer d\\geq 0, the problem admits a kernelization algorithm that in time n^{O(d)} outputs an equivalent framework with a graph on dk^{O(d)} vertices. A lower bound complements this when d is part of the input: Independent Stable Set does not admit a polynomial kernel when parameterized by k+d unless NP \\subseteq coNP/poly. This lower bound holds even when M is a partition matroid.   - Another set of results concerns the scenario when the graph G is chordal. In this case, our computational lower bound excludes an FPT algorithm when the input matroid is given by its independence oracle. However, we demonstrate that Independent Stable Set can be solved in 2^{O(k)}||M||^{O(1)} time when M is a linear matroid given by its representation. In the same setting, Independent Stable Set does not have a polynomial kernel when parameterized by k unless NP\\subseteq coNP/poly.","sentences":["We study the following Independent Stable Set problem.","Let G be an undirected graph and M = (V(G),I) be a matroid whose elements are the vertices of G. For an integer k\\geq 1, the task is to decide whether G contains a set S\\subseteq V(G) of size at least k which is independent (stable) in G and independent in M. This problem generalizes several well-studied algorithmic problems, including Rainbow Independent Set, Rainbow Matching, and Bipartite Matching with Separation.","We show that   - When the matroid M is represented by the independence oracle, then for any computable function f, no algorithm can solve Independent Stable Set using f(k)n^{o(k)} calls to the oracle.   ","-","On the other hand, when the graph G is of degeneracy d, then the problem is solvable in time O((d+1)^kn), and hence is FPT parameterized by d+k.","Moreover, when the degeneracy d is a constant (which is not a part of the input), the problem admits a kernel polynomial in k. More precisely, we prove that for every integer d\\geq 0, the problem admits a kernelization algorithm that in time n^{O(d)} outputs an equivalent framework with a graph on dk^{O(d)} vertices.","A lower bound complements this when d is part of the input: Independent Stable Set does not admit a polynomial kernel when parameterized by k+d unless NP \\subseteq coNP/poly.","This lower bound holds even when M is a partition matroid.   ","- Another set of results concerns the scenario when the graph G is chordal.","In this case, our computational lower bound excludes an FPT algorithm when the input matroid is given by its independence oracle.","However, we demonstrate that Independent Stable Set can be solved in 2^{O(k)}||M||^{O(1)} time when M is a linear matroid given by its representation.","In the same setting, Independent Stable Set does not have a polynomial kernel when parameterized by k unless NP\\subseteq coNP/poly."],"url":"http://arxiv.org/abs/2404.03979v1","category":"cs.DS"}
{"created":"2024-04-05 09:19:55","title":"Random Walk in Random Permutation Set Theory","abstract":"Random walk is an explainable approach for modeling natural processes at the molecular level. The Random Permutation Set Theory (RPST) serves as a framework for uncertainty reasoning, extending the applicability of Dempster-Shafer Theory. Recent explorations indicate a promising link between RPST and random walk. In this study, we conduct an analysis and construct a random walk model based on the properties of RPST, with Monte Carlo simulations of such random walk. Our findings reveal that the random walk generated through RPST exhibits characteristics similar to those of a Gaussian random walk and can be transformed into a Wiener process through a specific limiting scaling procedure. This investigation establishes a novel connection between RPST and random walk theory, thereby not only expanding the applicability of RPST, but also demonstrating the potential for combining the strengths of both approaches to improve problem-solving abilities.","sentences":["Random walk is an explainable approach for modeling natural processes at the molecular level.","The Random Permutation Set Theory (RPST) serves as a framework for uncertainty reasoning, extending the applicability of Dempster-Shafer Theory.","Recent explorations indicate a promising link between RPST and random walk.","In this study, we conduct an analysis and construct a random walk model based on the properties of RPST, with Monte Carlo simulations of such random walk.","Our findings reveal that the random walk generated through RPST exhibits characteristics similar to those of a Gaussian random walk and can be transformed into a Wiener process through a specific limiting scaling procedure.","This investigation establishes a novel connection between RPST and random walk theory, thereby not only expanding the applicability of RPST, but also demonstrating the potential for combining the strengths of both approaches to improve problem-solving abilities."],"url":"http://arxiv.org/abs/2404.03978v1","category":"cs.AI"}
{"created":"2024-04-05 09:18:50","title":"SEME at SemEval-2024 Task 2: Comparing Masked and Generative Language Models on Natural Language Inference for Clinical Trials","abstract":"This paper describes our submission to Task 2 of SemEval-2024: Safe Biomedical Natural Language Inference for Clinical Trials. The Multi-evidence Natural Language Inference for Clinical Trial Data (NLI4CT) consists of a Textual Entailment (TE) task focused on the evaluation of the consistency and faithfulness of Natural Language Inference (NLI) models applied to Clinical Trial Reports (CTR). We test 2 distinct approaches, one based on finetuning and ensembling Masked Language Models and the other based on prompting Large Language Models using templates, in particular, using Chain-Of-Thought and Contrastive Chain-Of-Thought. Prompting Flan-T5-large in a 2-shot setting leads to our best system that achieves 0.57 F1 score, 0.64 Faithfulness, and 0.56 Consistency.","sentences":["This paper describes our submission to Task 2 of SemEval-2024: Safe Biomedical Natural Language Inference for Clinical Trials.","The Multi-evidence Natural Language Inference for Clinical Trial Data (NLI4CT) consists of a Textual Entailment (TE) task focused on the evaluation of the consistency and faithfulness of Natural Language Inference (NLI) models applied to Clinical Trial Reports (CTR).","We test 2 distinct approaches, one based on finetuning and ensembling Masked Language Models and the other based on prompting Large Language Models using templates, in particular, using Chain-Of-Thought and Contrastive Chain-Of-Thought.","Prompting Flan-T5-large in a 2-shot setting leads to our best system that achieves 0.57 F1 score, 0.64 Faithfulness, and 0.56 Consistency."],"url":"http://arxiv.org/abs/2404.03977v1","category":"cs.CL"}
{"created":"2024-04-05 09:16:39","title":"A theoretical framework for dynamical fee choice in AMMs","abstract":"In the ever evolving landscape of decentralized finance automated market makers (AMMs) play a key role: they provide a market place for trading assets in a decentralized manner. For so-called bluechip pairs, arbitrage activity provides a major part of the revenue generation of AMMs but also a major source of loss due to the so-called informed orderflow. Finding ways to minimize those losses while still keeping uninformed trading activity alive is a major problem in the field. In this paper we will investigate the mechanics of said arbitrage and try to understand how AMMs can maximize the revenue creation or in other words minimize the losses. To that end, we model the dynamics of arbitrage activity for a concrete implementation of a pool and study its sensitivity to the choice of fee aiming to maximize the value retention. We manage to map the ensuing dynamics to that of a random walk with a specific reward scheme that provides a convenient starting point for further studies.","sentences":["In the ever evolving landscape of decentralized finance automated market makers (AMMs) play a key role: they provide a market place for trading assets in a decentralized manner.","For so-called bluechip pairs, arbitrage activity provides a major part of the revenue generation of AMMs but also a major source of loss due to the so-called informed orderflow.","Finding ways to minimize those losses while still keeping uninformed trading activity alive is a major problem in the field.","In this paper we will investigate the mechanics of said arbitrage and try to understand how AMMs can maximize the revenue creation or in other words minimize the losses.","To that end, we model the dynamics of arbitrage activity for a concrete implementation of a pool and study its sensitivity to the choice of fee aiming to maximize the value retention.","We manage to map the ensuing dynamics to that of a random walk with a specific reward scheme that provides a convenient starting point for further studies."],"url":"http://arxiv.org/abs/2404.03976v1","category":"q-fin.ST"}
{"created":"2024-04-05 09:14:09","title":"On the Antiferromagnetic$\\unicode{x2013}$Ferromagnetic Phase Transition in Pinwheel Artificial Spin Ice","abstract":"Nanopatterned magnetic thin films offer a platform for exploration of tailored magnetic properties such as emergent long-range order. A prominent example is artificial spin ice (ASI), where an arrangement of nanoscale magnetic elements, acting as macrospins, interact via their dipolar fields. In this study, we discuss the transition from antiferromagnetic (AF) to ferromagnetic (FM) long-range order in a square lattice ASI, as the magnetic elements are gradually rotated through 45{\\deg} to a \"pinwheel\" configuration. The AF$\\unicode{x2013}$FM transition is observed experimentally using synchrotron radiation x-ray spectromicroscopy and occurs for a critical rotation angle of the nanomagnets, contingent upon the dipolar coupling determined by their separation in the lattice. Large-scale magnetic dipole simulations show that the point-dipole approximation fails to capture the correct AF$\\unicode{x2013}$FM transition angle. However, excellent agreement with experimental data is obtained using a dumbbell-dipole model which better reflects the actual dipolar fields of the magnets. This model explains the coupling-dependence of the transition angle, another feature not captured by the pointdipole model. Our findings resolve a discrepancy between measurement and theory in previous work on \"pinwheel\" ASIs. Control of the AF$\\unicode{x2013}$FM transition and this revised model open for improved design of magnetic order in nanostructured systems.","sentences":["Nanopatterned magnetic thin films offer a platform for exploration of tailored magnetic properties such as emergent long-range order.","A prominent example is artificial spin ice (ASI), where an arrangement of nanoscale magnetic elements, acting as macrospins, interact via their dipolar fields.","In this study, we discuss the transition from antiferromagnetic (AF) to ferromagnetic (FM) long-range order in a square lattice ASI, as the magnetic elements are gradually rotated through 45{\\deg} to a \"pinwheel\" configuration.","The AF$\\unicode{x2013}$FM transition is observed experimentally using synchrotron radiation x-ray spectromicroscopy and occurs for a critical rotation angle of the nanomagnets, contingent upon the dipolar coupling determined by their separation in the lattice.","Large-scale magnetic dipole simulations show that the point-dipole approximation fails to capture the correct AF$\\unicode{x2013}$FM transition angle.","However, excellent agreement with experimental data is obtained using a dumbbell-dipole model which better reflects the actual dipolar fields of the magnets.","This model explains the coupling-dependence of the transition angle, another feature not captured by the pointdipole model.","Our findings resolve a discrepancy between measurement and theory in previous work on \"pinwheel\" ASIs.","Control of the AF$\\unicode{x2013}$FM transition and this revised model open for improved design of magnetic order in nanostructured systems."],"url":"http://arxiv.org/abs/2404.03973v1","category":"cond-mat.mes-hall"}
{"created":"2024-04-05 09:02:29","title":"k-space Physics-informed Neural Network (k-PINN) for Compressed Spectral Mapping and Efficient Inversion of Vibrations in Thin Composite Laminates","abstract":"The vibrational response of structural components carries valuable information about their underlying mechanical properties, health status and operational conditions. This underscores the need for the development of efficient physics-based inversion algorithms which, given a limited set of sensing data points and in the presence of measurement noise, can reconstruct the response at locations where measurement data is not available and/or identify the unknown mechanical properties. Addressing this challenge, Physics-Informed Neural Networks (PINNs) have emerged as a promising approach. PINNs seamlessly integrate governing equations into their architecture and have gained significant interest in solving inversion problems. In the context of learning and inversion of multimodal, multiscale vibrational responses, this paper introduces a novel spectral extension of PINNs, utilizing Fourier basis functions in the wavenumber domain, commonly known as k-space. The proposed k-space PINN (k-PINN), offers a robust framework for adjusting complexity and wavenumber composition of the response. Notably, the spectral formulation of k-PINN, coupled with the generally sparse representation of vibrations in k-space, facilitate efficient reconstruction and learning of broadband vibrations and alleviate the spectral bias associated with standard PINN. Additionally, the spectral solution space introduced by k-PINN substantially reduces the computational cost associated with computing physics-informed loss terms. We evaluate the effectiveness of the proposed methodology on reconstructing the bending vibrational mode shapes of a thin composite laminate and identifying its effective bending stiffness coefficients. It is shown that the proposed k-PINN methodology outperforms the standard PINN in terms of both learning and computational efficiency.","sentences":["The vibrational response of structural components carries valuable information about their underlying mechanical properties, health status and operational conditions.","This underscores the need for the development of efficient physics-based inversion algorithms which, given a limited set of sensing data points and in the presence of measurement noise, can reconstruct the response at locations where measurement data is not available and/or identify the unknown mechanical properties.","Addressing this challenge, Physics-Informed Neural Networks (PINNs) have emerged as a promising approach.","PINNs seamlessly integrate governing equations into their architecture and have gained significant interest in solving inversion problems.","In the context of learning and inversion of multimodal, multiscale vibrational responses, this paper introduces a novel spectral extension of PINNs, utilizing Fourier basis functions in the wavenumber domain, commonly known as k-space.","The proposed k-space PINN (k-PINN), offers a robust framework for adjusting complexity and wavenumber composition of the response.","Notably, the spectral formulation of k-PINN, coupled with the generally sparse representation of vibrations in k-space, facilitate efficient reconstruction and learning of broadband vibrations and alleviate the spectral bias associated with standard PINN.","Additionally, the spectral solution space introduced by k-PINN substantially reduces the computational cost associated with computing physics-informed loss terms.","We evaluate the effectiveness of the proposed methodology on reconstructing the bending vibrational mode shapes of a thin composite laminate and identifying its effective bending stiffness coefficients.","It is shown that the proposed k-PINN methodology outperforms the standard PINN in terms of both learning and computational efficiency."],"url":"http://arxiv.org/abs/2404.03966v1","category":"physics.app-ph"}
{"created":"2024-04-05 08:52:32","title":"RaSim: A Range-aware High-fidelity RGB-D Data Simulation Pipeline for Real-world Applications","abstract":"In robotic vision, a de-facto paradigm is to learn in simulated environments and then transfer to real-world applications, which poses an essential challenge in bridging the sim-to-real domain gap. While mainstream works tackle this problem in the RGB domain, we focus on depth data synthesis and develop a range-aware RGB-D data simulation pipeline (RaSim). In particular, high-fidelity depth data is generated by imitating the imaging principle of real-world sensors. A range-aware rendering strategy is further introduced to enrich data diversity. Extensive experiments show that models trained with RaSim can be directly applied to real-world scenarios without any finetuning and excel at downstream RGB-D perception tasks.","sentences":["In robotic vision, a de-facto paradigm is to learn in simulated environments and then transfer to real-world applications, which poses an essential challenge in bridging the sim-to-real domain gap.","While mainstream works tackle this problem in the RGB domain, we focus on depth data synthesis and develop a range-aware RGB-D data simulation pipeline (RaSim).","In particular, high-fidelity depth data is generated by imitating the imaging principle of real-world sensors.","A range-aware rendering strategy is further introduced to enrich data diversity.","Extensive experiments show that models trained with RaSim can be directly applied to real-world scenarios without any finetuning and excel at downstream RGB-D perception tasks."],"url":"http://arxiv.org/abs/2404.03962v1","category":"cs.CV"}
{"created":"2024-04-05 08:50:46","title":"On the critical competition between singlet exciton decay and free charge generation in non-fullerene-based organic solar cells with low energetic offsets","abstract":"In this era of non-fullerene acceptor (NFA) based organic solar cells, reducing voltage losses while maintaining high photocurrents is the holy grail of current research. Recent focus lies in understanding the manifold fundamental mechanisms in organic blends with minimal energy offsets - particularly the relationship between ionization energy offset ({\\Delta}IE) and free charge generation. We quantitatively probe this relationship in multiple NFA-based blends by mixing Y5 and Y6 NFAs with PM6 of varying molecular weights, covering a 15% to 1% power conversion efficiency (PCE) range and a progression of {\\Delta}IE. Spectroelectrochemistry reveals a critical {\\Delta}IE of approximately 0.3 eV, below which the PCE sharply declines. Transient absorption spectroscopy consistently reveals that a smaller {\\Delta}IE slows the dissociation of the NFA's local singlet exciton (LE) into free charges, albeit restorable by an electric field. Bias-dependent time delayed collection experiments quantify the free charge generation efficiency, while photoluminescence quantum efficiency measurements assess photocurrent loss from LE decay. Combined with transient photoluminescence experiments, we find that the decay of singlet excitons is the primary competition to free charge generation in low-offset NFA-based organic solar cells, with neither noticeable losses from charge-transfer (CT) decay nor evidence for LE-CT hybridization. Our experimental data align with Marcus theory calculations, supported by density functional theory simulations, for zero-field free charge generation and exciton decay efficiencies. We find that efficient photocurrent generation generally requires that the CT state is located below the LE, but that this restriction is lifted in systems with a small reorganization energy for charge transfer.","sentences":["In this era of non-fullerene acceptor (NFA) based organic solar cells, reducing voltage losses while maintaining high photocurrents is the holy grail of current research.","Recent focus lies in understanding the manifold fundamental mechanisms in organic blends with minimal energy offsets - particularly the relationship between ionization energy offset ({\\Delta}IE) and free charge generation.","We quantitatively probe this relationship in multiple NFA-based blends by mixing Y5 and Y6 NFAs with PM6 of varying molecular weights, covering a 15% to 1% power conversion efficiency (PCE) range and a progression of {\\Delta}IE.","Spectroelectrochemistry reveals a critical {\\Delta}IE of approximately 0.3 eV, below which the PCE sharply declines.","Transient absorption spectroscopy consistently reveals that a smaller {\\Delta}IE slows the dissociation of the NFA's local singlet exciton (LE) into free charges, albeit restorable by an electric field.","Bias-dependent time delayed collection experiments quantify the free charge generation efficiency, while photoluminescence quantum efficiency measurements assess photocurrent loss from LE decay.","Combined with transient photoluminescence experiments, we find that the decay of singlet excitons is the primary competition to free charge generation in low-offset NFA-based organic solar cells, with neither noticeable losses from charge-transfer (CT) decay nor evidence for LE-CT hybridization.","Our experimental data align with Marcus theory calculations, supported by density functional theory simulations, for zero-field free charge generation and exciton decay efficiencies.","We find that efficient photocurrent generation generally requires that the CT state is located below the LE, but that this restriction is lifted in systems with a small reorganization energy for charge transfer."],"url":"http://arxiv.org/abs/2404.03960v1","category":"cond-mat.mtrl-sci"}
{"created":"2024-04-05 08:49:29","title":"Minor Containment and Disjoint Paths in almost-linear time","abstract":"We give an algorithm that, given graphs $G$ and $H$, tests whether $H$ is a minor of $G$ in time ${\\cal O}_H(n^{1+o(1)})$; here, $n$ is the number of vertices of $G$ and the ${\\cal O}_H(\\cdot)$-notation hides factors that depend on $H$ and are computable. By the Graph Minor Theorem, this implies the existence of an $n^{1+o(1)}$-time membership test for every minor-closed class of graphs.   More generally, we give an ${\\cal O}_{H,|X|}(m^{1+o(1)})$-time algorithm for the rooted version of the problem, in which $G$ comes with a set of roots $X\\subseteq V(G)$ and some of the branch sets of the sought minor model of $H$ are required to contain prescribed subsets of $X$; here, $m$ is the total number of vertices and edges of $G$. This captures the Disjoint Paths problem, for which we obtain an ${\\cal O}_{k}(m^{1+o(1)})$-time algorithm, where $k$ is the number of terminal pairs. For all the mentioned problems, the fastest algorithms known before are due to Kawarabayashi, Kobayashi, and Reed [JCTB 2012], and have a time complexity that is quadratic in the number of vertices of $G$.   Our algorithm has two main ingredients: First, we show that by using the dynamic treewidth data structure of Korhonen, Majewski, Nadara, Pilipczuk, and Soko{\\l}owski [FOCS 2023], the irrelevant vertex technique of Robertson and Seymour can be implemented in almost-linear time on apex-minor-free graphs. Then, we apply the recent advances in almost-linear time flow/cut algorithms to give an almost-linear time implementation of the recursive understanding technique, which effectively reduces the problem to apex-minor-free graphs.","sentences":["We give an algorithm that, given graphs $G$ and $H$, tests whether $H$ is a minor of $G$ in time ${\\cal O}_H(n^{1+o(1)})$; here, $n$ is the number of vertices of $G$ and the ${\\cal O}_H(\\cdot)$-notation hides factors that depend on $H$ and are computable.","By the Graph Minor Theorem, this implies the existence of an $n^{1+o(1)}$-time membership test for every minor-closed class of graphs.   ","More generally, we give an ${\\cal O}_{H,|X|}(m^{1+o(1)})$-time algorithm for the rooted version of the problem, in which $G$ comes with a set of roots $X\\subseteq V(G)$ and some of the branch sets of the sought minor model of $H$ are required to contain prescribed subsets of $X$; here, $m$ is the total number of vertices and edges of $G$. This captures the Disjoint Paths problem, for which we obtain an ${\\cal O}_{k}(m^{1+o(1)})$-time algorithm, where $k$ is the number of terminal pairs.","For all the mentioned problems, the fastest algorithms known before are due to Kawarabayashi, Kobayashi, and Reed [JCTB 2012], and have a time complexity that is quadratic in the number of vertices of $G$.   Our algorithm has two main ingredients:","First, we show that by using the dynamic treewidth data structure of Korhonen, Majewski, Nadara, Pilipczuk, and Soko{\\l}owski","[FOCS 2023], the irrelevant vertex technique of Robertson and Seymour can be implemented in almost-linear time on apex-minor-free graphs.","Then, we apply the recent advances in almost-linear time flow/cut algorithms to give an almost-linear time implementation of the recursive understanding technique, which effectively reduces the problem to apex-minor-free graphs."],"url":"http://arxiv.org/abs/2404.03958v1","category":"cs.DS"}
{"created":"2024-04-05 08:48:53","title":"Bayesian Graphs of Intelligent Causation","abstract":"Probabilistic Graphical Bayesian models of causation have continued to impact on strategic analyses designed to help evaluate the efficacy of different interventions on systems. However, the standard causal algebras upon which these inferences are based typically assume that the intervened population does not react intelligently to frustrate an intervention. In an adversarial setting this is rarely an appropriate assumption. In this paper, we extend an established Bayesian methodology called Adversarial Risk Analysis to apply it to settings that can legitimately be designated as causal in this graphical sense. To embed this technology we first need to generalize the concept of a causal graph. We then proceed to demonstrate how the predicable intelligent reactions of adversaries to circumvent an intervention when they hear about it can be systematically modelled within such graphical frameworks, importing these recent developments from Bayesian game theory. The new methodologies and supporting protocols are illustrated through applications associated with an adversary attempting to infiltrate a friendly state.","sentences":["Probabilistic Graphical Bayesian models of causation have continued to impact on strategic analyses designed to help evaluate the efficacy of different interventions on systems.","However, the standard causal algebras upon which these inferences are based typically assume that the intervened population does not react intelligently to frustrate an intervention.","In an adversarial setting this is rarely an appropriate assumption.","In this paper, we extend an established Bayesian methodology called Adversarial Risk Analysis to apply it to settings that can legitimately be designated as causal in this graphical sense.","To embed this technology we first need to generalize the concept of a causal graph.","We then proceed to demonstrate how the predicable intelligent reactions of adversaries to circumvent an intervention when they hear about it can be systematically modelled within such graphical frameworks, importing these recent developments from Bayesian game theory.","The new methodologies and supporting protocols are illustrated through applications associated with an adversary attempting to infiltrate a friendly state."],"url":"http://arxiv.org/abs/2404.03957v1","category":"stat.ME"}
{"created":"2024-04-05 08:41:34","title":"Universal time scalings of sensitivity in Markovian quantum metrology","abstract":"Assuming a Markovian time evolution of a quantum sensing system, we provide a general characterization of the optimal sensitivity scalings with time, under the most general quantum control protocols. We allow the estimated parameter to influence both the Hamiltonian as well as the dissipative part of the quantum master equation. We focus on the asymptotic-time as well as the short-time sensitivity scalings, and investigate the relevant time scales on which the transition between the two regimes appears. This allows us to characterize, via simple algebraic conditions (in terms of the Hamiltonian, the jump operators as well as their parameter derivatives), the four classes of metrological models that represent: quadratic-linear, quadratic-quadratic, linear-linear and linear-quadratic time scalings. We also provide universal numerical methods to obtain quantitative bounds on sensitivity that are the tightest that exist in the literature.","sentences":["Assuming a Markovian time evolution of a quantum sensing system, we provide a general characterization of the optimal sensitivity scalings with time, under the most general quantum control protocols.","We allow the estimated parameter to influence both the Hamiltonian as well as the dissipative part of the quantum master equation.","We focus on the asymptotic-time as well as the short-time sensitivity scalings, and investigate the relevant time scales on which the transition between the two regimes appears.","This allows us to characterize, via simple algebraic conditions (in terms of the Hamiltonian, the jump operators as well as their parameter derivatives), the four classes of metrological models that represent: quadratic-linear, quadratic-quadratic, linear-linear and linear-quadratic time scalings.","We also provide universal numerical methods to obtain quantitative bounds on sensitivity that are the tightest that exist in the literature."],"url":"http://arxiv.org/abs/2404.03954v1","category":"quant-ph"}
{"created":"2024-04-05 08:41:18","title":"Towards Understanding the Impact of Code Modifications on Software Quality Metrics","abstract":"Context: In the realm of software development, maintaining high software quality is a persistent challenge. However, this challenge is often impeded by the lack of comprehensive understanding of how specific code modifications influence quality metrics.   Objective: This study ventures to bridge this gap through an approach that aspires to assess and interpret the impact of code modifications. The underlying hypothesis posits that code modifications inducing similar changes in software quality metrics can be grouped into distinct clusters, which can be effectively described using an AI language model, thus providing a simple understanding of code changes and their quality implications.   Method: To validate this hypothesis, we built and analyzed a dataset from popular GitHub repositories, segmented into individual code modifications. Each project was evaluated against software quality metrics pre and post-application. Machine learning techniques were utilized to cluster these modifications based on the induced changes in the metrics. Simultaneously, an AI language model was employed to generate descriptions of each modification's function.   Results: The results reveal distinct clusters of code modifications, each accompanied by a concise description, revealing their collective impact on software quality metrics.   Conclusions: The findings suggest that this research is a significant step towards a comprehensive understanding of the complex relationship between code changes and software quality, which has the potential to transform software maintenance strategies and enable the development of more accurate quality prediction models.","sentences":["Context: In the realm of software development, maintaining high software quality is a persistent challenge.","However, this challenge is often impeded by the lack of comprehensive understanding of how specific code modifications influence quality metrics.   ","Objective: This study ventures to bridge this gap through an approach that aspires to assess and interpret the impact of code modifications.","The underlying hypothesis posits that code modifications inducing similar changes in software quality metrics can be grouped into distinct clusters, which can be effectively described using an AI language model, thus providing a simple understanding of code changes and their quality implications.   ","Method: To validate this hypothesis, we built and analyzed a dataset from popular GitHub repositories, segmented into individual code modifications.","Each project was evaluated against software quality metrics pre and post-application.","Machine learning techniques were utilized to cluster these modifications based on the induced changes in the metrics.","Simultaneously, an AI language model was employed to generate descriptions of each modification's function.   ","Results:","The results reveal distinct clusters of code modifications, each accompanied by a concise description, revealing their collective impact on software quality metrics.   ","Conclusions: The findings suggest that this research is a significant step towards a comprehensive understanding of the complex relationship between code changes and software quality, which has the potential to transform software maintenance strategies and enable the development of more accurate quality prediction models."],"url":"http://arxiv.org/abs/2404.03953v1","category":"cs.SE"}
{"created":"2024-04-05 08:39:41","title":"Minimal sized generating sets of permutation groups","abstract":"We present a randomised variant of an algorithm of Lucchini and Thakkar for finding a smallest sized generating set in a finite group, which has polynomial time expected running time in finite permutation groups.","sentences":["We present a randomised variant of an algorithm of Lucchini and Thakkar for finding a smallest sized generating set in a finite group, which has polynomial time expected running time in finite permutation groups."],"url":"http://arxiv.org/abs/2404.03952v1","category":"math.GR"}
{"created":"2024-04-05 08:27:08","title":"Lyapunov Exponents and Phase Transition of Hayward AdS Black Hole","abstract":"In this paper, we study the relationship between the phase transition and Lyapunov exponents for 4D Hayward anti-de Sitter (AdS) black hole. We consider the motion of massless and massive particles around an unstable circular orbit of the Hayward AdS black hole in the equatorial plane and calculate the corresponding Lyapunov exponents. The phase transition is found to be well described by the multivaled Lyapunov exponents. It is also found that different phases of Hayward AdS black hole coincide with different branches of the Lyapunov exponents. We also study the discontinuous change in the Lyapunov exponents and find that it can serve as an order parameter near the critical point. The critical exponent of change in Lyapunov exponent near the critical point is found to be $1/2$.","sentences":["In this paper, we study the relationship between the phase transition and Lyapunov exponents for 4D Hayward anti-de Sitter (AdS) black hole.","We consider the motion of massless and massive particles around an unstable circular orbit of the Hayward AdS black hole in the equatorial plane and calculate the corresponding Lyapunov exponents.","The phase transition is found to be well described by the multivaled Lyapunov exponents.","It is also found that different phases of Hayward AdS black hole coincide with different branches of the Lyapunov exponents.","We also study the discontinuous change in the Lyapunov exponents and find that it can serve as an order parameter near the critical point.","The critical exponent of change in Lyapunov exponent near the critical point is found to be $1/2$."],"url":"http://arxiv.org/abs/2404.03947v1","category":"hep-th"}
{"created":"2024-04-05 16:35:42","title":"Emergent photons and fractionalized excitations in a quantum spin liquid","abstract":"A quantum spin liquid (QSL) arises from a highly entangled superposition of many degenerate classical ground states in a frustrated magnet, and is characterized by emergent gauge fields and deconfined fractionalized excitations (spinons). Because such a novel phase of matter is relevant to high-transition-temperature superconductivity and quantum computation, the microscopic understanding of QSL states is a long-sought goal in condensed matter physics. The 3D pyrochlore lattice of corner-sharing tetrahedra can host a QSL with U(1) gauge fields called quantum spin ice (QSI), which is a quantum (with effective $S=1/2$) analog of the classical (with large effective moment) spin ice. A key difference between QSI and classical spin ice is the predicted presence of the linearly dispersing collective excitations near zero energy, dubbed the \"photons\", arising from emergent quantum electrodynamics, in addition to the spinons at higher energies. Recently, 3D pyrochlore systems Ce2M2O7 (M = Sn, Zr, Hf) have been suggested as effective $S=1/2$ QSI candidates, but there has been no evidence of quasielastic magnetic scattering signals from photons, a key signature for a QSI. Here, we use polarized neutron scattering experiments on single crystals of Ce2Zr2O7 to conclusively demonstrate the presence of magnetic excitations near zero energy at 50 mK in addition to signatures of spinons at higher energies. By comparing the energy (E), wave vector (Q), and polarization dependence of the magnetic excitations with theoretical calculations, we conclude that Ce2Zr2O7 is the first example of a dipolar-octupolar $\\pi$ flux QSI with dominant dipolar Ising interactions, therefore identifying a microscopic Hamiltonian responsible for a QSL.","sentences":["A quantum spin liquid (QSL) arises from a highly entangled superposition of many degenerate classical ground states in a frustrated magnet, and is characterized by emergent gauge fields and deconfined fractionalized excitations (spinons).","Because such a novel phase of matter is relevant to high-transition-temperature superconductivity and quantum computation, the microscopic understanding of QSL states is a long-sought goal in condensed matter physics.","The 3D pyrochlore lattice of corner-sharing tetrahedra can host a QSL with U(1) gauge fields called quantum spin ice (QSI), which is a quantum (with effective $S=1/2$) analog of the classical (with large effective moment) spin ice.","A key difference between QSI and classical spin ice is the predicted presence of the linearly dispersing collective excitations near zero energy, dubbed the \"photons\", arising from emergent quantum electrodynamics, in addition to the spinons at higher energies.","Recently, 3D pyrochlore systems Ce2M2O7 (M = Sn, Zr, Hf) have been suggested as effective $S=1/2$ QSI candidates, but there has been no evidence of quasielastic magnetic scattering signals from photons, a key signature for a QSI.","Here, we use polarized neutron scattering experiments on single crystals of Ce2Zr2O7 to conclusively demonstrate the presence of magnetic excitations near zero energy at 50 mK in addition to signatures of spinons at higher energies.","By comparing the energy (E), wave vector (Q), and polarization dependence of the magnetic excitations with theoretical calculations, we conclude that Ce2Zr2O7 is the first example of a dipolar-octupolar $\\pi$ flux QSI with dominant dipolar Ising interactions, therefore identifying a microscopic Hamiltonian responsible for a QSL."],"url":"http://arxiv.org/abs/2404.04207v1","category":"cond-mat.str-el"}
{"created":"2024-04-05 16:02:37","title":"Are We Up to the Challenge? An analysis of the FCC Broadband Data Collection Fixed Internet Availability Challenges","abstract":"In 2021, the Broadband Equity, Access, and Deployment (BEAD) program allocated $42.45 billion to enhance high-speed internet access across the United States. As part of this funding initiative, The Federal Communications Commission (FCC) developed a national coverage map to guide the allocation of BEAD funds. This map was the key determinant to direct BEAD investments to areas in need of broadband infrastructure improvements. The FCC encouraged public participation in refining this coverage map through the submission of \"challenges\" to either locations on the map or the status of broadband at any location on the map. These challenges allowed citizens and organizations to report discrepancies between the map's data and actual broadband availability, ensuring a more equitable distribution of funds. In this paper, we present a study analyzing the nature and distribution of these challenges across different access technologies and geographic areas. Among several other insights, we observe, for example, that the majority of challenges (about 58%) were submitted against terrestrial fixed wireless technologies as well as that the state of Nebraska had the strongest engagement in the challenge process with more than 75% of its broadband-serviceable locations having submitted at least one challenge.","sentences":["In 2021, the Broadband Equity, Access, and Deployment (BEAD) program allocated $42.45 billion to enhance high-speed internet access across the United States.","As part of this funding initiative, The Federal Communications Commission (FCC) developed a national coverage map to guide the allocation of BEAD funds.","This map was the key determinant to direct BEAD investments to areas in need of broadband infrastructure improvements.","The FCC encouraged public participation in refining this coverage map through the submission of \"challenges\" to either locations on the map or the status of broadband at any location on the map.","These challenges allowed citizens and organizations to report discrepancies between the map's data and actual broadband availability, ensuring a more equitable distribution of funds.","In this paper, we present a study analyzing the nature and distribution of these challenges across different access technologies and geographic areas.","Among several other insights, we observe, for example, that the majority of challenges (about 58%) were submitted against terrestrial fixed wireless technologies as well as that the state of Nebraska had the strongest engagement in the challenge process with more than 75% of its broadband-serviceable locations having submitted at least one challenge."],"url":"http://arxiv.org/abs/2404.04189v1","category":"cs.NI"}
{"created":"2024-04-05 14:42:56","title":"Aperture photometry on asteroid trails: detection of the fastest rotating near-Earth object","abstract":"Context. Near-Earth objects (NEOs) on an impact course with Earth can move at high angular speed. Understanding their properties, including rotation state, is crucial for assessing impact risks and mitigation strategies. Traditional photometric methods face challenges in collecting data on fast-moving NEOs accurately. Aims. This study introduces an innovative approach to aperture photometry tailored to analyzing trailed images of fast-moving NEOs. Our primary aim is to extract rotation state information from these observations, particularly focusing on the efficacy of this technique for fast rotators. Methods. We applied our approach to analyze the trailed images of three asteroids: 2023 CX1, 2024 BX1, and 2024 EF, which were either on a collision courses or performing a close fly-by with Earth. By adjusting aperture sizes, we controlled the effective exposure times to increase the sampling rates of the photometric variations. This enabled us to detect short rotation periods that would be challenging with conventional methods. Results. Our analysis revealed that trailed photometry significantly reduces overhead time associated with CCD read-out, enhancing the sampling rate of the photometric variations. We demonstrated that this technique is particularly effective for fast-moving objects, providing reliable photometric data when the object is at its brightest and closest to Earth. For asteroid 2024 BX1, we detected a rotation period as short as 2.5888 +- 0.0002 seconds, the fastest ever recorded. Our findings underscore the efficacy of trailed observations coupled with aperture photometry for studying the rotation characteristics of small NEOs, offering crucial insights for impact risk assessment and mitigation strategies.","sentences":["Context.","Near-Earth objects (NEOs) on an impact course with Earth can move at high angular speed.","Understanding their properties, including rotation state, is crucial for assessing impact risks and mitigation strategies.","Traditional photometric methods face challenges in collecting data on fast-moving NEOs accurately.","Aims.","This study introduces an innovative approach to aperture photometry tailored to analyzing trailed images of fast-moving NEOs.","Our primary aim is to extract rotation state information from these observations, particularly focusing on the efficacy of this technique for fast rotators.","Methods.","We applied our approach to analyze the trailed images of three asteroids: 2023 CX1, 2024 BX1, and 2024 EF, which were either on a collision courses or performing a close fly-by with Earth.","By adjusting aperture sizes, we controlled the effective exposure times to increase the sampling rates of the photometric variations.","This enabled us to detect short rotation periods that would be challenging with conventional methods.","Results.","Our analysis revealed that trailed photometry significantly reduces overhead time associated with CCD read-out, enhancing the sampling rate of the photometric variations.","We demonstrated that this technique is particularly effective for fast-moving objects, providing reliable photometric data when the object is at its brightest and closest to Earth.","For asteroid 2024 BX1, we detected a rotation period as short as 2.5888 +- 0.0002 seconds, the fastest ever recorded.","Our findings underscore the efficacy of trailed observations coupled with aperture photometry for studying the rotation characteristics of small NEOs, offering crucial insights for impact risk assessment and mitigation strategies."],"url":"http://arxiv.org/abs/2404.04142v1","category":"astro-ph.EP"}
{"created":"2024-04-05 11:39:53","title":"Which Experimental Design is Better Suited for VQA Tasks? Eye Tracking Study on Cognitive Load, Performance, and Gaze Allocations","abstract":"We conducted an eye-tracking user study with 13 participants to investigate the influence of stimulus-question ordering and question modality on participants using visual question-answering (VQA) tasks. We examined cognitive load, task performance, and gaze allocations across five distinct experimental designs, aiming to identify setups that minimize the cognitive burden on participants. The collected performance and gaze data were analyzed using quantitative and qualitative methods. Our results indicate a significant impact of stimulus-question ordering on cognitive load and task performance, as well as a noteworthy effect of question modality on task performance. These findings offer insights for the experimental design of controlled user studies in visualization research.","sentences":["We conducted an eye-tracking user study with 13 participants to investigate the influence of stimulus-question ordering and question modality on participants using visual question-answering (VQA) tasks.","We examined cognitive load, task performance, and gaze allocations across five distinct experimental designs, aiming to identify setups that minimize the cognitive burden on participants.","The collected performance and gaze data were analyzed using quantitative and qualitative methods.","Our results indicate a significant impact of stimulus-question ordering on cognitive load and task performance, as well as a noteworthy effect of question modality on task performance.","These findings offer insights for the experimental design of controlled user studies in visualization research."],"url":"http://arxiv.org/abs/2404.04036v1","category":"cs.HC"}
{"created":"2024-04-05 11:25:51","title":"Numerical study of neutral and charged microgel suspensions: from single-particle to collective behavior","abstract":"We perform extensive Molecular Dynamics simulations of an ensemble of realistic microgel particles in swollen conditions in a wide range of packing fractions $\\zeta$. We compare neutral and charged microgels, where we consider charges distribution adherent to experimental conditions. Through a detailed analysis of single-particle behavior, we are able to identify the different regimes occurring upon increasing concentration: from shrinking to deformation and interpenetration, always connecting our findings to available experimental observations. We then link these single-particle features to the collective behavior of the suspension, finding evidence of a structural reentrance, that has no counterpart in the dynamics. Hence, while the maximum of the radial distribution function displays a non-monotonic behavior with increasing $\\zeta$, the dynamics, quantified by the microgels' mean-squared displacement, always slows down. Key similarities and differences between neutral and charged microgels are identified. Importantly, at high enough $\\zeta$ we also detect the fusion of the shells of charged microgels, that was previously invoked to explain key experimental findings. This highlights the fact that even for standard poly(N-isopropylacrylamide) microgels, commonly considered as a prototype of soft colloid, charge effects are relevant. Overall, our study establishes a powerful framework to uncover the physics of microgel suspensions under several different conditions. Indeed, it can be readily extended to tackle different regimes, e.g. high temperature, and systems, e.g. complex microgel topologies such as ultra-low-crosslinked ones, where experimental evidence is still limited.","sentences":["We perform extensive Molecular Dynamics simulations of an ensemble of realistic microgel particles in swollen conditions in a wide range of packing fractions $\\zeta$. We compare neutral and charged microgels, where we consider charges distribution adherent to experimental conditions.","Through a detailed analysis of single-particle behavior, we are able to identify the different regimes occurring upon increasing concentration: from shrinking to deformation and interpenetration, always connecting our findings to available experimental observations.","We then link these single-particle features to the collective behavior of the suspension, finding evidence of a structural reentrance, that has no counterpart in the dynamics.","Hence, while the maximum of the radial distribution function displays a non-monotonic behavior with increasing $\\zeta$, the dynamics, quantified by the microgels' mean-squared displacement, always slows down.","Key similarities and differences between neutral and charged microgels are identified.","Importantly, at high enough $\\zeta$ we also detect the fusion of the shells of charged microgels, that was previously invoked to explain key experimental findings.","This highlights the fact that even for standard poly(N-isopropylacrylamide) microgels, commonly considered as a prototype of soft colloid, charge effects are relevant.","Overall, our study establishes a powerful framework to uncover the physics of microgel suspensions under several different conditions.","Indeed, it can be readily extended to tackle different regimes, e.g. high temperature, and systems, e.g. complex microgel topologies such as ultra-low-crosslinked ones, where experimental evidence is still limited."],"url":"http://arxiv.org/abs/2404.04032v1","category":"cond-mat.soft"}
{"created":"2024-04-05 11:16:18","title":"Elastic Curves with Variable Bending Stiffness","abstract":"We study stationary points of the bending energy of curves $\\gamma\\colon[a,b]\\to\\mathbb{R}^n$ subject to constraints on the arc-length and total torsion while simultaneously allowing for a variable bending stiffness along the arc-length of the curve. Physically, this can be understood as a model for an elastic wire with isotropic cross-section of varying thickness. We derive the corresponding Euler-Lagrange equations for variations that are compactly supported away from the end points thus obtaining characterizations for elastic curves with variable bending stiffness. Moreover, we provide a collection of alternative characterizations, e.g., in terms of the curvature function. Adding to numerous known results relating elastic curves to dynamics, we establish connections between elastic curves with variable bending stiffness and damped pendulums and the flow of vortex filaments with finite thickness.","sentences":["We study stationary points of the bending energy of curves $\\gamma\\colon[a,b]\\to\\mathbb{R}^n$ subject to constraints on the arc-length and total torsion while simultaneously allowing for a variable bending stiffness along the arc-length of the curve.","Physically, this can be understood as a model for an elastic wire with isotropic cross-section of varying thickness.","We derive the corresponding Euler-Lagrange equations for variations that are compactly supported away from the end points thus obtaining characterizations for elastic curves with variable bending stiffness.","Moreover, we provide a collection of alternative characterizations, e.g., in terms of the curvature function.","Adding to numerous known results relating elastic curves to dynamics, we establish connections between elastic curves with variable bending stiffness and damped pendulums and the flow of vortex filaments with finite thickness."],"url":"http://arxiv.org/abs/2404.04027v1","category":"math.DG"}
{"created":"2024-04-05 10:23:10","title":"Physics-Inspired Synthesized Underwater Image Dataset","abstract":"This paper introduces the physics-inspired synthesized underwater image dataset (PHISWID), a dataset tailored for enhancing underwater image processing through physics-inspired image synthesis. Deep learning approaches to underwater image enhancement typically demand extensive datasets, yet acquiring paired clean and degraded underwater ones poses significant challenges. While several underwater image datasets have been proposed using physics-based synthesis, a publicly accessible collection has been lacking. Additionally, most underwater image synthesis approaches do not intend to reproduce atmospheric scenes, resulting in incomplete enhancement. PHISWID addresses this gap by offering a set of paired ground-truth (atmospheric) and synthetically degraded underwater images, showcasing not only color degradation but also the often-neglected effects of marine snow, a composite of organic matter and sand particles that considerably impairs underwater image clarity. The dataset applies these degradations to atmospheric RGB-D images, enhancing the dataset's realism and applicability. PHISWID is particularly valuable for training deep neural networks in a supervised learning setting and for objectively assessing image quality in benchmark analyses. Our results reveal that even a basic U-Net architecture, when trained with PHISWID, substantially outperforms existing methods in underwater image enhancement. We intend to release PHISWID publicly, contributing a significant resource to the advancement of underwater imaging technology.","sentences":["This paper introduces the physics-inspired synthesized underwater image dataset (PHISWID), a dataset tailored for enhancing underwater image processing through physics-inspired image synthesis.","Deep learning approaches to underwater image enhancement typically demand extensive datasets, yet acquiring paired clean and degraded underwater ones poses significant challenges.","While several underwater image datasets have been proposed using physics-based synthesis, a publicly accessible collection has been lacking.","Additionally, most underwater image synthesis approaches do not intend to reproduce atmospheric scenes, resulting in incomplete enhancement.","PHISWID addresses this gap by offering a set of paired ground-truth (atmospheric) and synthetically degraded underwater images, showcasing not only color degradation but also the often-neglected effects of marine snow, a composite of organic matter and sand particles that considerably impairs underwater image clarity.","The dataset applies these degradations to atmospheric RGB-D images, enhancing the dataset's realism and applicability.","PHISWID is particularly valuable for training deep neural networks in a supervised learning setting and for objectively assessing image quality in benchmark analyses.","Our results reveal that even a basic U-Net architecture, when trained with PHISWID, substantially outperforms existing methods in underwater image enhancement.","We intend to release PHISWID publicly, contributing a significant resource to the advancement of underwater imaging technology."],"url":"http://arxiv.org/abs/2404.03998v1","category":"cs.CV"}
{"created":"2024-04-05 09:39:47","title":"ROMA-iQSS: An Objective Alignment Approach via State-Based Value Learning and ROund-Robin Multi-Agent Scheduling","abstract":"Effective multi-agent collaboration is imperative for solving complex, distributed problems. In this context, two key challenges must be addressed: first, autonomously identifying optimal objectives for collective outcomes; second, aligning these objectives among agents. Traditional frameworks, often reliant on centralized learning, struggle with scalability and efficiency in large multi-agent systems. To overcome these issues, we introduce a decentralized state-based value learning algorithm that enables agents to independently discover optimal states. Furthermore, we introduce a novel mechanism for multi-agent interaction, wherein less proficient agents follow and adopt policies from more experienced ones, thereby indirectly guiding their learning process. Our theoretical analysis shows that our approach leads decentralized agents to an optimal collective policy. Empirical experiments further demonstrate that our method outperforms existing decentralized state-based and action-based value learning strategies by effectively identifying and aligning optimal objectives.","sentences":["Effective multi-agent collaboration is imperative for solving complex, distributed problems.","In this context, two key challenges must be addressed: first, autonomously identifying optimal objectives for collective outcomes; second, aligning these objectives among agents.","Traditional frameworks, often reliant on centralized learning, struggle with scalability and efficiency in large multi-agent systems.","To overcome these issues, we introduce a decentralized state-based value learning algorithm that enables agents to independently discover optimal states.","Furthermore, we introduce a novel mechanism for multi-agent interaction, wherein less proficient agents follow and adopt policies from more experienced ones, thereby indirectly guiding their learning process.","Our theoretical analysis shows that our approach leads decentralized agents to an optimal collective policy.","Empirical experiments further demonstrate that our method outperforms existing decentralized state-based and action-based value learning strategies by effectively identifying and aligning optimal objectives."],"url":"http://arxiv.org/abs/2404.03984v1","category":"cs.MA"}
{"created":"2024-04-05 08:27:36","title":"Re-pseudonymization Strategies for Smart Meter Data Are Not Robust to Deep Learning Profiling Attacks","abstract":"Smart meters, devices measuring the electricity and gas consumption of a household, are currently being deployed at a fast rate throughout the world. The data they collect are extremely useful, including in the fight against climate change. However, these data and the information that can be inferred from them are highly sensitive. Re-pseudonymization, i.e., the frequent replacement of random identifiers over time, is widely used to share smart meter data while mitigating the risk of re-identification. We here show how, in spite of re-pseudonymization, households' consumption records can be pieced together with high accuracy in large-scale datasets. We propose the first deep learning-based profiling attack against re-pseudonymized smart meter data. Our attack combines neural network embeddings, which are used to extract features from weekly consumption records and are tailored to the smart meter identification task, with a nearest neighbor classifier. We evaluate six neural networks architectures as the embedding model. Our results suggest that the Transformer and CNN-LSTM architectures vastly outperform previous methods as well as other architectures, successfully identifying the correct household 73.4% of the time among 5139 households based on electricity and gas consumption records (54.5% for electricity only). We further show that the features extracted by the embedding model maintain their effectiveness when transferred to a set of users disjoint from the one used to train the model. Finally, we extensively evaluate the robustness of our results. Taken together, our results strongly suggest that even frequent re-pseudonymization strategies can be reversed, strongly limiting their ability to prevent re-identification in practice.","sentences":["Smart meters, devices measuring the electricity and gas consumption of a household, are currently being deployed at a fast rate throughout the world.","The data they collect are extremely useful, including in the fight against climate change.","However, these data and the information that can be inferred from them are highly sensitive.","Re-pseudonymization, i.e., the frequent replacement of random identifiers over time, is widely used to share smart meter data while mitigating the risk of re-identification.","We here show how, in spite of re-pseudonymization, households' consumption records can be pieced together with high accuracy in large-scale datasets.","We propose the first deep learning-based profiling attack against re-pseudonymized smart meter data.","Our attack combines neural network embeddings, which are used to extract features from weekly consumption records and are tailored to the smart meter identification task, with a nearest neighbor classifier.","We evaluate six neural networks architectures as the embedding model.","Our results suggest that the Transformer and CNN-LSTM architectures vastly outperform previous methods as well as other architectures, successfully identifying the correct household 73.4% of the time among 5139 households based on electricity and gas consumption records (54.5% for electricity only).","We further show that the features extracted by the embedding model maintain their effectiveness when transferred to a set of users disjoint from the one used to train the model.","Finally, we extensively evaluate the robustness of our results.","Taken together, our results strongly suggest that even frequent re-pseudonymization strategies can be reversed, strongly limiting their ability to prevent re-identification in practice."],"url":"http://arxiv.org/abs/2404.03948v1","category":"cs.CR"}
{"created":"2024-04-05 17:59:44","title":"Sigma: Siamese Mamba Network for Multi-Modal Semantic Segmentation","abstract":"Multi-modal semantic segmentation significantly enhances AI agents' perception and scene understanding, especially under adverse conditions like low-light or overexposed environments. Leveraging additional modalities (X-modality) like thermal and depth alongside traditional RGB provides complementary information, enabling more robust and reliable segmentation. In this work, we introduce Sigma, a Siamese Mamba network for multi-modal semantic segmentation, utilizing the Selective Structured State Space Model, Mamba. Unlike conventional methods that rely on CNNs, with their limited local receptive fields, or Vision Transformers (ViTs), which offer global receptive fields at the cost of quadratic complexity, our model achieves global receptive fields coverage with linear complexity. By employing a Siamese encoder and innovating a Mamba fusion mechanism, we effectively select essential information from different modalities. A decoder is then developed to enhance the channel-wise modeling ability of the model. Our method, Sigma, is rigorously evaluated on both RGB-Thermal and RGB-Depth segmentation tasks, demonstrating its superiority and marking the first successful application of State Space Models (SSMs) in multi-modal perception tasks. Code is available at https://github.com/zifuwan/Sigma.","sentences":["Multi-modal semantic segmentation significantly enhances AI agents' perception and scene understanding, especially under adverse conditions like low-light or overexposed environments.","Leveraging additional modalities (X-modality) like thermal and depth alongside traditional RGB provides complementary information, enabling more robust and reliable segmentation.","In this work, we introduce Sigma, a Siamese Mamba network for multi-modal semantic segmentation, utilizing the Selective Structured State Space Model, Mamba.","Unlike conventional methods that rely on CNNs, with their limited local receptive fields, or Vision Transformers (ViTs), which offer global receptive fields at the cost of quadratic complexity, our model achieves global receptive fields coverage with linear complexity.","By employing a Siamese encoder and innovating a Mamba fusion mechanism, we effectively select essential information from different modalities.","A decoder is then developed to enhance the channel-wise modeling ability of the model.","Our method, Sigma, is rigorously evaluated on both RGB-Thermal and RGB-Depth segmentation tasks, demonstrating its superiority and marking the first successful application of State Space Models (SSMs) in multi-modal perception tasks.","Code is available at https://github.com/zifuwan/Sigma."],"url":"http://arxiv.org/abs/2404.04256v1","category":"cs.CV"}
{"created":"2024-04-05 17:59:19","title":"Zeno physics of the Ising chain with symmetry-breaking boundary dephasing","abstract":"In few-qubit systems, the quantum Zeno effect arises when measurement occurs sufficiently frequently that the spins are unable to relax between measurements. This can compete with Hamiltonian terms, resulting in interesting relaxation processes which depend non-monotonically on the ratio of measurement rate to coherent oscillations. While Zeno physics for a single qubit is well-understood, an interesting open question is how the Zeno effect is modified by coupling the measured spin to a non-trivial bulk. In this work, we study the effect of coupling a one-dimensional transverse field Ising to a Zeno spin which lives at the boundary. We find that sharp singularities occur in the boundary relaxation dynamics, which can be tied to the emergence or destruction of edge modes that can be found analytically. Finally, we provide numerical evidence that the dynamical singularities are stable in the presence of integrability-breaking interactions.","sentences":["In few-qubit systems, the quantum Zeno effect arises when measurement occurs sufficiently frequently that the spins are unable to relax between measurements.","This can compete with Hamiltonian terms, resulting in interesting relaxation processes which depend non-monotonically on the ratio of measurement rate to coherent oscillations.","While Zeno physics for a single qubit is well-understood, an interesting open question is how the Zeno effect is modified by coupling the measured spin to a non-trivial bulk.","In this work, we study the effect of coupling a one-dimensional transverse field Ising to a Zeno spin which lives at the boundary.","We find that sharp singularities occur in the boundary relaxation dynamics, which can be tied to the emergence or destruction of edge modes that can be found analytically.","Finally, we provide numerical evidence that the dynamical singularities are stable in the presence of integrability-breaking interactions."],"url":"http://arxiv.org/abs/2404.04255v1","category":"cond-mat.str-el"}
{"created":"2024-04-05 17:37:50","title":"Nightclub bar dynamics: statistics of serving times","abstract":"In this work, we investigate the statistical properties of drink serving in a nightclub bar, utilizing a stochastic model to characterize pedestrian dynamics within the venue. Our model comprises a system of n agents moving across an underlying square lattice of size l representing the nightclub venue. Each agent can exist in one of three states: thirsty, served, or dancing. The dynamics governing the state changes are influenced by a memory time, denoted as {\\tau}, which reflects their drinking habits. Agents' movement throughout the lattice is controlled by a parameter {\\alpha} which measures the impetus towards/away from the bar. When {\\alpha} = 0, a power-law distribution emerges due to the non-objectivity of the agents. As {\\alpha} moves into intermediate values, an exponential behavior is observed, as it becomes possible to mitigate the drastic jamming effects in this scenario. However, for higher {\\alpha} values, the power-law distribution resurfaces due to increased jamming. We also demonstrate that the average concentration of served, thirsty, and dancing agents provide a reliable indicator of when the system reaches a jammed state. Subsequently, we construct a comprehensive map of the system's stationary state, supporting the idea that for high densities, {\\alpha} is not relevant, but for lower densities, the optimal values of measurements occurs at high values of {\\alpha}. To complete the analysis, we evaluate the conditional persistence, which measures the probability of an agent failing to receive their drink despite attempting to do so. In addition to contributing to the field of pedestrian dynamics, the present results serve as valuable indicators to assist commercial establishments in providing better services to their clients, tailored to the average drinking habits of their customers.","sentences":["In this work, we investigate the statistical properties of drink serving in a nightclub bar, utilizing a stochastic model to characterize pedestrian dynamics within the venue.","Our model comprises a system of n agents moving across an underlying square lattice of size l representing the nightclub venue.","Each agent can exist in one of three states: thirsty, served, or dancing.","The dynamics governing the state changes are influenced by a memory time, denoted as {\\tau}, which reflects their drinking habits.","Agents' movement throughout the lattice is controlled by a parameter {\\alpha} which measures the impetus towards/away from the bar.","When {\\alpha} = 0, a power-law distribution emerges due to the non-objectivity of the agents.","As {\\alpha} moves into intermediate values, an exponential behavior is observed, as it becomes possible to mitigate the drastic jamming effects in this scenario.","However, for higher {\\alpha} values, the power-law distribution resurfaces due to increased jamming.","We also demonstrate that the average concentration of served, thirsty, and dancing agents provide a reliable indicator of when the system reaches a jammed state.","Subsequently, we construct a comprehensive map of the system's stationary state, supporting the idea that for high densities, {\\alpha} is not relevant, but for lower densities, the optimal values of measurements occurs at high values of {\\alpha}.","To complete the analysis, we evaluate the conditional persistence, which measures the probability of an agent failing to receive their drink despite attempting to do so.","In addition to contributing to the field of pedestrian dynamics, the present results serve as valuable indicators to assist commercial establishments in providing better services to their clients, tailored to the average drinking habits of their customers."],"url":"http://arxiv.org/abs/2404.04238v1","category":"physics.soc-ph"}
{"created":"2024-04-05 17:36:26","title":"Cleared for Takeoff? Compositional & Conditional Reasoning may be the Achilles Heel to (Flight-Booking) Language Agents","abstract":"The rapid progress of large language models (LLMs) has seen them excel and frequently surpass human performance on standard benchmarks. This has enabled many downstream applications, such as LLM agents, to rely on their sophisticated reasoning to navigate complex task requirements. However, LLMs are known to unexpectedly falter in simple tasks and under seemingly straightforward circumstances - underscoring the need for better and more diverse evaluation setups to measure their true capabilities. To this end, we choose to study compositional and conditional reasoning, two cornerstones of human cognition, and introduce GroundCocoa - a lexically diverse benchmark connecting these reasoning skills to the real-world problem of flight booking. Our task involves aligning detailed user preferences with available flight options presented in a multiple-choice format. Results indicate a significant disparity in performance among current state-of-the-art LLMs with even the best performing model, GPT-4 Turbo, not exceeding 67% accuracy despite advanced prompting techniques.","sentences":["The rapid progress of large language models (LLMs) has seen them excel and frequently surpass human performance on standard benchmarks.","This has enabled many downstream applications, such as LLM agents, to rely on their sophisticated reasoning to navigate complex task requirements.","However, LLMs are known to unexpectedly falter in simple tasks and under seemingly straightforward circumstances - underscoring the need for better and more diverse evaluation setups to measure their true capabilities.","To this end, we choose to study compositional and conditional reasoning, two cornerstones of human cognition, and introduce GroundCocoa - a lexically diverse benchmark connecting these reasoning skills to the real-world problem of flight booking.","Our task involves aligning detailed user preferences with available flight options presented in a multiple-choice format.","Results indicate a significant disparity in performance among current state-of-the-art LLMs with even the best performing model, GPT-4 Turbo, not exceeding 67% accuracy despite advanced prompting techniques."],"url":"http://arxiv.org/abs/2404.04237v1","category":"cs.CL"}
{"created":"2024-04-05 17:21:51","title":"Grand canonically optimized grain boundary phases in hexagonal close-packed titanium","abstract":"Grain boundaries (GBs) profoundly influence the properties and performance of materials, emphasizing the importance of understanding the GB structure and phase behavior. As recent computational studies have demonstrated the existence of multiple GB phases associated with varying the atomic density at the interface, we introduce a validated, open-source GRand canonical Interface Predictor (GRIP) tool that automates high-throughput, grand canonical optimization of GB structures. While previous studies of GB phases have almost exclusively focused on cubic systems, we demonstrate the utility of GRIP in an application to hexagonal close-packed titanium. We perform a systematic high-throughput exploration of tilt GBs in titanium and discover previously unreported structures and phase transitions. In low-angle boundaries, we demonstrate a coupling between point defect absorption and the change in the GB dislocation network topology due to GB phase transformations, which has important implications for the accommodation of radiation-induced defects.","sentences":["Grain boundaries (GBs) profoundly influence the properties and performance of materials, emphasizing the importance of understanding the GB structure and phase behavior.","As recent computational studies have demonstrated the existence of multiple GB phases associated with varying the atomic density at the interface, we introduce a validated, open-source GRand canonical Interface Predictor (GRIP) tool that automates high-throughput, grand canonical optimization of GB structures.","While previous studies of GB phases have almost exclusively focused on cubic systems, we demonstrate the utility of GRIP in an application to hexagonal close-packed titanium.","We perform a systematic high-throughput exploration of tilt GBs in titanium and discover previously unreported structures and phase transitions.","In low-angle boundaries, we demonstrate a coupling between point defect absorption and the change in the GB dislocation network topology due to GB phase transformations, which has important implications for the accommodation of radiation-induced defects."],"url":"http://arxiv.org/abs/2404.04230v1","category":"cond-mat.mtrl-sci"}
{"created":"2024-04-05 17:19:45","title":"Beaded metamaterials","abstract":"From the pragmatic to the symbolic, textiles play a prominent role in some of the most demanding yet ubiquitous scenarios, such as covering the complex and dynamic geometries of the human body. Textiles are made by repeated manipulations of slender fibers into structures with emergent properties. Today, these ancient metamaterials are being examined in a new light, propelled by the idea that their geometric structures can be leveraged to engineer functional soft materials. However, per their inherent softness, textiles and other compliant materials cannot typically withstand compressive forces.   This limitation hinders the transfer of soft matter's rich shape-morphing capabilities to broader research areas that require load-bearing capabilities. Here we introduce \\textit{beading} as a versatile platform that links centuries of human ingenuity encoded in the world of textiles with the current demand for smart, programmable materials. By incorporating discrete rigid units, i.e. \\textit{beads}, into various fiber-based assemblies, beadwork adds tunable stiffness to otherwise flaccid fabrics, creating new opportunities for textiles to become load-bearing. We select a shell-like bead design as a model experimental system and thoroughly describe how its mechanics are captured by friction, the material properties of the constituent elements, and geometry. The fundamental characterization in this study demonstrates the range of complex behaviors possible with this class of material, inspiring the application of soft matter principles to fields that ultimately demand rigidity, such as robotics and architecture.","sentences":["From the pragmatic to the symbolic, textiles play a prominent role in some of the most demanding yet ubiquitous scenarios, such as covering the complex and dynamic geometries of the human body.","Textiles are made by repeated manipulations of slender fibers into structures with emergent properties.","Today, these ancient metamaterials are being examined in a new light, propelled by the idea that their geometric structures can be leveraged to engineer functional soft materials.","However, per their inherent softness, textiles and other compliant materials cannot typically withstand compressive forces.   ","This limitation hinders the transfer of soft matter's rich shape-morphing capabilities to broader research areas that require load-bearing capabilities.","Here we introduce \\textit{beading} as a versatile platform that links centuries of human ingenuity encoded in the world of textiles with the current demand for smart, programmable materials.","By incorporating discrete rigid units, i.e. \\textit{beads}, into various fiber-based assemblies, beadwork adds tunable stiffness to otherwise flaccid fabrics, creating new opportunities for textiles to become load-bearing.","We select a shell-like bead design as a model experimental system and thoroughly describe how its mechanics are captured by friction, the material properties of the constituent elements, and geometry.","The fundamental characterization in this study demonstrates the range of complex behaviors possible with this class of material, inspiring the application of soft matter principles to fields that ultimately demand rigidity, such as robotics and architecture."],"url":"http://arxiv.org/abs/2404.04227v1","category":"cond-mat.soft"}
{"created":"2024-04-05 17:12:14","title":"The effects of HIV self-testing on HIV incidence and awareness of status among men who have sex with men in the United States: Insights from a novel compartmental model","abstract":"The OraQuick In-Home HIV self-test represents a fast, inexpensive, and convenient method for users to assess their HIV status. If integrated thoughtfully into existing testing practices, accompanied by efficient pathways to formal diagnosis, self-testing could both enhance HIV awareness and reduce HIV incidence. However, currently available self-tests are less sensitive, particularly for recent infection, than gold-standard laboratory tests. It is important to understand the impact if some portion of standard testing is replaced by self-tests. We introduced a novel compartmental model to evaluate the effects of self-testing among gay, bisexual and other men who have sex with men (MSM) in the United States for the period 2020 to 2030. We varied the model for different screening rates, self-test proportions, and delays to diagnosis for those identified through self-tests to determine the potential impact on HIV incidence and awareness of status. When HIV self-tests are strictly supplemental, self-testing can decrease HIV incidence among MSM in the US by up to 10% and increase awareness of status among MSM from 85% to 91% over a 10-year period, provided linkage to care and formal diagnosis occur promptly following a positive self-test (90 days or less). As self-tests replace a higher percentage laboratory-based testing algorithms, increases in overall testing rates were necessary to ensure reductions in HIV incidence. However, such increases were small (under 10% for prompt engagement in care and moderate levels of replacement). Improvements in self-test sensitivity and/or decreases in the detection period may further reduce any necessary increases in overall testing. Our study suggests that, if properly utilized, self-testing can provide significant long-term reductions to HIV incidence and improve awareness of HIV status.","sentences":["The OraQuick In-Home HIV self-test represents a fast, inexpensive, and convenient method for users to assess their HIV status.","If integrated thoughtfully into existing testing practices, accompanied by efficient pathways to formal diagnosis, self-testing could both enhance HIV awareness and reduce HIV incidence.","However, currently available self-tests are less sensitive, particularly for recent infection, than gold-standard laboratory tests.","It is important to understand the impact if some portion of standard testing is replaced by self-tests.","We introduced a novel compartmental model to evaluate the effects of self-testing among gay, bisexual and other men who have sex with men (MSM) in the United States for the period 2020 to 2030.","We varied the model for different screening rates, self-test proportions, and delays to diagnosis for those identified through self-tests to determine the potential impact on HIV incidence and awareness of status.","When HIV self-tests are strictly supplemental, self-testing can decrease HIV incidence among MSM in the US by up to 10% and increase awareness of status among MSM from 85% to 91% over a 10-year period, provided linkage to care and formal diagnosis occur promptly following a positive self-test (90 days or less).","As self-tests replace a higher percentage laboratory-based testing algorithms, increases in overall testing rates were necessary to ensure reductions in HIV incidence.","However, such increases were small (under 10% for prompt engagement in care and moderate levels of replacement).","Improvements in self-test sensitivity and/or decreases in the detection period may further reduce any necessary increases in overall testing.","Our study suggests that, if properly utilized, self-testing can provide significant long-term reductions to HIV incidence and improve awareness of HIV status."],"url":"http://arxiv.org/abs/2404.04222v1","category":"q-bio.PE"}
{"created":"2024-04-05 17:02:52","title":"Particle chirality does not matter in strong turbulence","abstract":"We use three-dimensional direct numerical simulations of homogeneous isotropic turbulence in a cubic domain to investigate the dynamics of heavy, chiral, finite-size inertial particles and their effects on the flow. Using an immersed-boundary method and a complex collision model, four-way coupled simulations have been performed and the effects of particle-to-fluid density ratio, turbulence strength, and particle volume fraction have been analysed. We find that freely falling particles on the one hand add energy to the turbulent flow but, on the other hand, they also enhance the flow dissipation: depending on the combination of flow parameters, the former or the latter mechanism prevails, thus yielding enhanced or weakened turbulence. Furthermore, particle chirality entails a preferential angular velocity which induces a net vorticity in the fluid phase. As turbulence strengthens, the energy introduced by the falling particles becomes less relevant and stronger velocity fluctuations alter the solid phase dynamics, making the effect of chirality irrelevant. Moreover, comparing the time-history of collision events for chiral particles and spheres (at the same volume fraction) suggests that the former tend to entangle, in contrast to the latter which rebound impulsively.","sentences":["We use three-dimensional direct numerical simulations of homogeneous isotropic turbulence in a cubic domain to investigate the dynamics of heavy, chiral, finite-size inertial particles and their effects on the flow.","Using an immersed-boundary method and a complex collision model, four-way coupled simulations have been performed and the effects of particle-to-fluid density ratio, turbulence strength, and particle volume fraction have been analysed.","We find that freely falling particles on the one hand add energy to the turbulent flow but, on the other hand, they also enhance the flow dissipation: depending on the combination of flow parameters, the former or the latter mechanism prevails, thus yielding enhanced or weakened turbulence.","Furthermore, particle chirality entails a preferential angular velocity which induces a net vorticity in the fluid phase.","As turbulence strengthens, the energy introduced by the falling particles becomes less relevant and stronger velocity fluctuations alter the solid phase dynamics, making the effect of chirality irrelevant.","Moreover, comparing the time-history of collision events for chiral particles and spheres (at the same volume fraction) suggests that the former tend to entangle, in contrast to the latter which rebound impulsively."],"url":"http://arxiv.org/abs/2404.04217v1","category":"physics.flu-dyn"}
{"created":"2024-04-05 16:59:01","title":"Quantum-informed simulations for mechanics of materials: DFTB+MBD framework","abstract":"The macroscopic behaviors of materials are determined by interactions that occur at multiple lengths and time scales. Depending on the application, describing, predicting, and understanding these behaviors require models that rely on insights from electronic and atomic scales. In such cases, classical simplified approximations at those scales are insufficient, and quantum-based modeling is required. In this paper, we study how quantum effects can modify the mechanical properties of systems relevant to materials engineering. We base our study on a high-fidelity modeling framework that combines two computationally efficient models rooted in quantum first principles: Density Functional Tight Binding (DFTB) and many-body dispersion (MBD). The MBD model is applied to accurately describe non-covalent van der Waals interactions. Through various benchmark applications, we demonstrate the capabilities of this framework and the limitations of simplified modeling. We provide an open-source repository containing all codes, datasets, and examples presented in this work. This repository serves as a practical toolkit that we hope will support the development of future research in effective large-scale and multiscale modeling with quantum-mechanical fidelity.","sentences":["The macroscopic behaviors of materials are determined by interactions that occur at multiple lengths and time scales.","Depending on the application, describing, predicting, and understanding these behaviors require models that rely on insights from electronic and atomic scales.","In such cases, classical simplified approximations at those scales are insufficient, and quantum-based modeling is required.","In this paper, we study how quantum effects can modify the mechanical properties of systems relevant to materials engineering.","We base our study on a high-fidelity modeling framework that combines two computationally efficient models rooted in quantum first principles: Density Functional Tight Binding (DFTB) and many-body dispersion (MBD).","The MBD model is applied to accurately describe non-covalent van der Waals interactions.","Through various benchmark applications, we demonstrate the capabilities of this framework and the limitations of simplified modeling.","We provide an open-source repository containing all codes, datasets, and examples presented in this work.","This repository serves as a practical toolkit that we hope will support the development of future research in effective large-scale and multiscale modeling with quantum-mechanical fidelity."],"url":"http://arxiv.org/abs/2404.04216v1","category":"cs.CE"}
{"created":"2024-04-05 16:48:59","title":"Aging following a zero-temperature quench in the $d=3$ Ising model","abstract":"Aging in phase-ordering kinetics of the $d=3$ Ising model following a quench from infinite to zero temperature is studied by means of Monte Carlo simulations. In this model the two-time spin-spin autocorrelator $C_\\text{ag}$ is expected to obey dynamical scaling and to follow asymptotically a power-law decay with the autocorrelation exponent $\\lambda$. Previous work indicated that the lower Fisher-Huse bound of $\\lambda\\geq d/2 = 1.5$ is violated in this model. Using much larger systems than previously studied, the instantaneous exponent for $\\lambda$ we obtain at late times does \\emph{not} disagree with this bound. By conducting systematic fits to the data of $C_\\text{ag}$ using different ansaetze for the leading correction term, we find $\\lambda = 1.58(14)$ with most of error attributed to the systematic uncertainty regarding the ansaetze. This result is in contrast to the recent report that below the roughening transition universality might be violated.","sentences":["Aging in phase-ordering kinetics of the $d=3$ Ising model following a quench from infinite to zero temperature is studied by means of Monte Carlo simulations.","In this model the two-time spin-spin autocorrelator $C_\\text{ag}$ is expected to obey dynamical scaling and to follow asymptotically a power-law decay with the autocorrelation exponent $\\lambda$. Previous work indicated that the lower Fisher-Huse bound of $\\lambda\\geq d/2 = 1.5$ is violated in this model.","Using much larger systems than previously studied, the instantaneous exponent for $\\lambda$ we obtain at late times does \\emph{not} disagree with this bound.","By conducting systematic fits to the data of $C_\\text{ag}$ using different ansaetze for the leading correction term, we find $\\lambda = 1.58(14)$ with most of error attributed to the systematic uncertainty regarding the ansaetze.","This result is in contrast to the recent report that below the roughening transition universality might be violated."],"url":"http://arxiv.org/abs/2404.04214v1","category":"cond-mat.stat-mech"}
{"created":"2024-04-05 16:13:35","title":"Exploring Probabilistic Models for Semi-supervised Learning","abstract":"This thesis studies advanced probabilistic models, including both their theoretical foundations and practical applications, for different semi-supervised learning (SSL) tasks. The proposed probabilistic methods are able to improve the safety of AI systems in real applications by providing reliable uncertainty estimates quickly, and at the same time, achieve competitive performance compared to their deterministic counterparts. The experimental results indicate that the methods proposed in the thesis have great value in safety-critical areas, such as the autonomous driving or medical imaging analysis domain, and pave the way for the future discovery of highly effective and efficient probabilistic approaches in the SSL sector.","sentences":["This thesis studies advanced probabilistic models, including both their theoretical foundations and practical applications, for different semi-supervised learning (SSL) tasks.","The proposed probabilistic methods are able to improve the safety of AI systems in real applications by providing reliable uncertainty estimates quickly, and at the same time, achieve competitive performance compared to their deterministic counterparts.","The experimental results indicate that the methods proposed in the thesis have great value in safety-critical areas, such as the autonomous driving or medical imaging analysis domain, and pave the way for the future discovery of highly effective and efficient probabilistic approaches in the SSL sector."],"url":"http://arxiv.org/abs/2404.04199v1","category":"cs.LG"}
{"created":"2024-04-05 16:08:59","title":"Rigidity of stable Lyapunov exponents for codimension one Anosov covering maps on nilmanifolds","abstract":"Let $\\Psi$ be an endomorphism of a nilmanifold $M = N/\\Gamma$. We show that the preimages of a point under $\\Psi$ become dense exponentially if and only if $\\Psi$ is totally non-invertible, which means $(M, \\Psi)$ has no invertible factors of quotients of factors. As an application, let $f$ be a non-invertible Anosov covering map on $M$ with one-dimensional stable bundle, if $f$ has such linear part $\\Psi$ and is topologically conjugate to $\\Psi$, then every periodic point of $f$ admits the same stable Lyapunov exponent with $\\Psi$, and hence the conjugacy is automatically smooth along each stable leaf. Conversely, if $\\Psi$ is horizontally irreducible, which means the induced horizontal toral endomorphism is irreducible, then $f$ admitting a constant periodic stable Lyapunov exponent implies that there exists a topological conjugacy to $\\Psi$.   In summary, for an Anosov covering map on a nilmanifold with one-dimensional stable bundle and totally non-invertible, horizontally irreducible linear part, we get the equivalence among the existence of invariant unstable bundle, the existence of topological conjugacy to linear part, and a constant periodic stable Lyapunov exponent.","sentences":["Let $\\Psi$ be an endomorphism of a nilmanifold $M =","N/\\Gamma$. We show that the preimages of a point under $\\Psi$ become dense exponentially if and only if $\\Psi$ is totally non-invertible, which means $(M, \\Psi)$ has no invertible factors of quotients of factors.","As an application, let $f$ be a non-invertible Anosov covering map on $M$ with one-dimensional stable bundle, if $f$ has such linear part $\\Psi$ and is topologically conjugate to $\\Psi$, then every periodic point of $f$ admits the same stable Lyapunov exponent with $\\Psi$, and hence the conjugacy is automatically smooth along each stable leaf.","Conversely, if $\\Psi$ is horizontally irreducible, which means the induced horizontal toral endomorphism is irreducible, then $f$ admitting a constant periodic stable Lyapunov exponent implies that there exists a topological conjugacy to $\\Psi$.   In summary, for an Anosov covering map on a nilmanifold with one-dimensional stable bundle and totally non-invertible, horizontally irreducible linear part, we get the equivalence among the existence of invariant unstable bundle, the existence of topological conjugacy to linear part, and a constant periodic stable Lyapunov exponent."],"url":"http://arxiv.org/abs/2404.04196v1","category":"math.DS"}
{"created":"2024-04-05 16:08:59","title":"Convex MPC and Thrust Allocation with Deadband for Spacecraft Rendezvous","abstract":"This paper delves into a rendezvous scenario involving a chaser and a target spacecraft, focusing on the application of Model Predictive Control (MPC) to design a controller capable of guiding the chaser toward the target. The operational principle of spacecraft thrusters, requiring a minimum activation time that leads to the existence of a control deadband, introduces mixed-integer constraints into the optimization, posing a considerable computational challenge due to the exponential complexity on the number of integer constraints. We address this complexity by presenting two solver algorithms that efficiently approximate the optimal solution in significantly less time than standard solvers, making them well-suited for real-time applications.","sentences":["This paper delves into a rendezvous scenario involving a chaser and a target spacecraft, focusing on the application of Model Predictive Control (MPC) to design a controller capable of guiding the chaser toward the target.","The operational principle of spacecraft thrusters, requiring a minimum activation time that leads to the existence of a control deadband, introduces mixed-integer constraints into the optimization, posing a considerable computational challenge due to the exponential complexity on the number of integer constraints.","We address this complexity by presenting two solver algorithms that efficiently approximate the optimal solution in significantly less time than standard solvers, making them well-suited for real-time applications."],"url":"http://arxiv.org/abs/2404.04197v1","category":"eess.SY"}
{"created":"2024-04-05 16:03:07","title":"Low-energy $S$-wave scattering of $\\text{H}+e^-$ by a Lagrange-mesh method","abstract":"A method combining the Lagrange-mesh and the complex Kohn variational methods is developed for computing the $\\mathcal{S}$ matrix of a 2$+$1 elastic scattering in the frame of three-body Coulomb systems. Resonance parameters can be obtained from values of the $\\mathcal{S}$ matrix at several scattering energies. The method is illustrated with the $S$-wave low-energy scattering of an electron onto hydrogen. The computed phase shifts are at least as accurate as the literature results, and the resonance parameters are more accurate than the best literature results by several orders of magnitude. Both the infinite and finite proton mass cases are considered.","sentences":["A method combining the Lagrange-mesh and the complex Kohn variational methods is developed for computing the $\\mathcal{S}$ matrix of a 2$+$1 elastic scattering in the frame of three-body Coulomb systems.","Resonance parameters can be obtained from values of the $\\mathcal{S}$ matrix at several scattering energies.","The method is illustrated with the $S$-wave low-energy scattering of an electron onto hydrogen.","The computed phase shifts are at least as accurate as the literature results, and the resonance parameters are more accurate than the best literature results by several orders of magnitude.","Both the infinite and finite proton mass cases are considered."],"url":"http://arxiv.org/abs/2404.04191v1","category":"quant-ph"}
{"created":"2024-04-05 16:00:39","title":"Structured free-space optical fields for transverse and longitudinal control of electron matter waves","abstract":"Controlling free-electron momentum states is of high interest in electron microscopy to achieve momentum and energy resolved probing and manipulation of physical systems. Free-electron and light interactions have emerged as a powerful technique to accomplish this. Here, we demonstrate both longitudinal and transverse phase control of a slow electron wavepacket by extending the Kapitza-Dirac effect to spatially-structured pulsed laser beams. This extension enables both inelastic and elastic stimulated Compton scattering. The interaction reveals the formation of distinct electron transverse momentum orders, each demonstrating a comb-like electron energy spectrum. By exerting complete control over light parameters, including wavelength, field intensity, pulse duration, and spatial mode order, as well as their combinations, it is possible to coherently control the population of these electron energy-momentum states that are separated by a few meV energy and multiple photon momentum orders. This free-space electron-light interaction phenomenon possesses the capability to coherently control the energy and momentum of electron beams in electron microscopes. Moreover, it has the potential to facilitate the selective probing of various material excitations, including plasmons, excitons, and phonons, and performing Talbot-Lau matter-wave interferometry with transversely shaped electron beams.","sentences":["Controlling free-electron momentum states is of high interest in electron microscopy to achieve momentum and energy resolved probing and manipulation of physical systems.","Free-electron and light interactions have emerged as a powerful technique to accomplish this.","Here, we demonstrate both longitudinal and transverse phase control of a slow electron wavepacket by extending the Kapitza-Dirac effect to spatially-structured pulsed laser beams.","This extension enables both inelastic and elastic stimulated Compton scattering.","The interaction reveals the formation of distinct electron transverse momentum orders, each demonstrating a comb-like electron energy spectrum.","By exerting complete control over light parameters, including wavelength, field intensity, pulse duration, and spatial mode order, as well as their combinations, it is possible to coherently control the population of these electron energy-momentum states that are separated by a few meV energy and multiple photon momentum orders.","This free-space electron-light interaction phenomenon possesses the capability to coherently control the energy and momentum of electron beams in electron microscopes.","Moreover, it has the potential to facilitate the selective probing of various material excitations, including plasmons, excitons, and phonons, and performing Talbot-Lau matter-wave interferometry with transversely shaped electron beams."],"url":"http://arxiv.org/abs/2404.04187v1","category":"quant-ph"}
{"created":"2024-04-05 15:53:32","title":"RACS and SADL: Towards Robust SMR in the Wide-Area Network","abstract":"Consensus algorithms deployed in the crash fault tolerant setting chose a leader-based architecture in order to achieve the lowest latency possible. However, when deployed in the wide area they face two key robustness challenges. First, they lose liveness when the network is unreliable because they rely on timeouts to find a leader. Second, they cannot have a high replication factor because of the high load imposed on the leader-replica making it a bottleneck. This effectively limits the replication factor allowed, for a given level of throughput, thus lowering the fault tolerance threshold.   In this paper, we propose RACS and SADL, a modular state machine replication algorithm that addresses these two robustness challenges. To achieve robustness under adversarial network conditions, we propose RACS, a novel crash fault-tolerant consensus algorithm. RACS consists of two modes of operations: synchronous and asynchronous, that always ensure liveness. RACS leverages the synchronous network to minimize the communication cost to O(n) and matches the lower bound of O(n2) at adversarial-case executions. To avoid the leader bottleneck and to allow higher replication factor, without sacrificing the throughput, we then propose SADL, a novel consensus-agnostic asynchronous dissemination layer. SADL separates client command dissemination from the critical path of consensus and distributes the overhead evenly among all the replicas. The combination of RACS and SADL (SADL-RACS) provides a robust and high-performing state machine replication system. We implement and evaluate RACS and SADL-RACS in a wide-area deployment running on Amazon EC2.","sentences":["Consensus algorithms deployed in the crash fault tolerant setting chose a leader-based architecture in order to achieve the lowest latency possible.","However, when deployed in the wide area they face two key robustness challenges.","First, they lose liveness when the network is unreliable because they rely on timeouts to find a leader.","Second, they cannot have a high replication factor because of the high load imposed on the leader-replica making it a bottleneck.","This effectively limits the replication factor allowed, for a given level of throughput, thus lowering the fault tolerance threshold.   ","In this paper, we propose RACS and SADL, a modular state machine replication algorithm that addresses these two robustness challenges.","To achieve robustness under adversarial network conditions, we propose RACS, a novel crash fault-tolerant consensus algorithm.","RACS consists of two modes of operations: synchronous and asynchronous, that always ensure liveness.","RACS leverages the synchronous network to minimize the communication cost to O(n) and matches the lower bound of O(n2) at adversarial-case executions.","To avoid the leader bottleneck and to allow higher replication factor, without sacrificing the throughput, we then propose SADL, a novel consensus-agnostic asynchronous dissemination layer.","SADL separates client command dissemination from the critical path of consensus and distributes the overhead evenly among all the replicas.","The combination of RACS and SADL (SADL-RACS) provides a robust and high-performing state machine replication system.","We implement and evaluate RACS and SADL-RACS in a wide-area deployment running on Amazon EC2."],"url":"http://arxiv.org/abs/2404.04183v1","category":"cs.DC"}
{"created":"2024-04-05 15:51:27","title":"Ambiguity in the use of SIR models to fit epidemic incidence data","abstract":"When fitting a multi-parameter model to a data set, computer algorithms may suggest that a range of parameters provide equally reasonable fits, making the parameter estimation difficult. Here, we prove this fact for an SIR model. We say a set of parameter values is a good fit to outbreak data if the solution has the data's three most significant characteristics: the standard deviation, the mean time, and the total number of cases. In our model, in addition to the \"basic reproduction number\" $R_0$, three other parameters need to be estimated to fit a solution to outbreak data. We will show that those parameters can be chosen so that each gives a linear transformation of a solution's incidence data. As a result, we show that for every choice of $R_0>1$, there is a good fit for each outbreak. We also illustrate our results by providing the least square best fits of the New York City and London data sets of the Omicron variant of COVID-19. Furthermore, we show how versions of the SIR model with $N$ compartments have far more good fits- - indeed a high dimensional set of good fits -- for each target -- showing that more complicated models may have an even greater problem in overparametrizing outbreak characteristics.","sentences":["When fitting a multi-parameter model to a data set, computer algorithms may suggest that a range of parameters provide equally reasonable fits, making the parameter estimation difficult.","Here, we prove this fact for an SIR model.","We say a set of parameter values is a good fit to outbreak data if the solution has the data's three most significant characteristics: the standard deviation, the mean time, and the total number of cases.","In our model, in addition to the \"basic reproduction number\" $R_0$, three other parameters need to be estimated to fit a solution to outbreak data.","We will show that those parameters can be chosen so that each gives a linear transformation of a solution's incidence data.","As a result, we show that for every choice of $R_0>1$, there is a good fit for each outbreak.","We also illustrate our results by providing the least square best fits of the New York City and London data sets of the Omicron variant of COVID-19.","Furthermore, we show how versions of the SIR model with $N$ compartments have far more good fits- - indeed a high dimensional set of good fits -- for each target -- showing that more complicated models may have an even greater problem in overparametrizing outbreak characteristics."],"url":"http://arxiv.org/abs/2404.04181v1","category":"q-bio.PE"}
{"created":"2024-04-05 15:39:02","title":"Discriminating chaotic and integrable regimes in quenched field Floquet system using saturation of Out-of-time-order correlation","abstract":"The dynamic region of out-of-time-ordered correlators (OTOCs) is a valuable discriminator of chaos in classical and semiclassical systems, as it captures the characteristic exponential growth. However, in spin systems, it does not reliably quantify chaos, exhibiting similar behavior in both integrable and chaotic systems. Instead, we leverage the saturation behavior of OTOCs as a means to differentiate between chaotic and integrable regimes. We use integrable and nonintegrable quenched field Floquet systems to describe this discriminator. In the integrable system, the saturation region of OTOCs exhibits oscillatory behavior, whereas, in the chaotic system, it shows exact saturation i.e., system gets thermalized. To gain a clearer understanding of the oscillations, we calculate the inverse participation ratio (IPR) for the normalized Fourier spectrum of OTOC. In order to further substantiate our findings, we propose the nearest-neighbor spacing distribution (NNSD) of time-dependent unitary operators. This distribution effectively differentiates chaotic and regular regions, corroborating the outcomes derived from the saturation behavior of OTOC.","sentences":["The dynamic region of out-of-time-ordered correlators (OTOCs) is a valuable discriminator of chaos in classical and semiclassical systems, as it captures the characteristic exponential growth.","However, in spin systems, it does not reliably quantify chaos, exhibiting similar behavior in both integrable and chaotic systems.","Instead, we leverage the saturation behavior of OTOCs as a means to differentiate between chaotic and integrable regimes.","We use integrable and nonintegrable quenched field Floquet systems to describe this discriminator.","In the integrable system, the saturation region of OTOCs exhibits oscillatory behavior, whereas, in the chaotic system, it shows exact saturation i.e., system gets thermalized.","To gain a clearer understanding of the oscillations, we calculate the inverse participation ratio (IPR) for the normalized Fourier spectrum of OTOC.","In order to further substantiate our findings, we propose the nearest-neighbor spacing distribution (NNSD) of time-dependent unitary operators.","This distribution effectively differentiates chaotic and regular regions, corroborating the outcomes derived from the saturation behavior of OTOC."],"url":"http://arxiv.org/abs/2404.04177v1","category":"quant-ph"}
{"created":"2024-04-05 15:35:37","title":"Interplay of network structure and talent configuration on wealth dynamics","abstract":"The economic success of individuals is often determined by a combination of talent, luck, and assistance from others. We introduce a new agent-based model that simultaneously considers talent, luck, and social interaction. This model allows us to explore how network structure (how agents interact) and talent distribution among agents affect the dynamics of capital accumulation through analytical and numerical methods. We identify a phenomenon as \"talent configuration effect\", which refers to the influence of how talent is allocated to individuals (nodes) in the network. We analyze this effect through two key properties: talent assortativity (TA) and talent-degree correlation (TD). In particular, we focus on three economic indicators: growth rate ($n_{\\rm rate}$), Gini coefficient (inequality: $n_{\\rm Gini}$), and meritocratic fairness ($n_{LT}$). This investigation helps us understand the interplay between talent configuration and network structure on capital dynamics. We find that, in the short term, positive correlations exist between TA and TD for all three economic indicators. Furthermore, the dominant factor influencing capital dynamics depends on the network topology. In scale free networks, TD has a stronger influence on the economic indices than TA. Conversely, in lattice-like networks, TA plays a more significant role. Our findings intuitively explain why highly talented agents are more likely to become central hubs in the network and why social connections tend to form between individuals with similar talent levels (socioeconomic homophily).","sentences":["The economic success of individuals is often determined by a combination of talent, luck, and assistance from others.","We introduce a new agent-based model that simultaneously considers talent, luck, and social interaction.","This model allows us to explore how network structure (how agents interact) and talent distribution among agents affect the dynamics of capital accumulation through analytical and numerical methods.","We identify a phenomenon as \"talent configuration effect\", which refers to the influence of how talent is allocated to individuals (nodes) in the network.","We analyze this effect through two key properties: talent assortativity (TA) and talent-degree correlation (TD).","In particular, we focus on three economic indicators: growth rate ($n_{\\rm rate}$), Gini coefficient (inequality: $n_{\\rm Gini}$), and meritocratic fairness ($n_{LT}$).","This investigation helps us understand the interplay between talent configuration and network structure on capital dynamics.","We find that, in the short term, positive correlations exist between TA and TD for all three economic indicators.","Furthermore, the dominant factor influencing capital dynamics depends on the network topology.","In scale free networks, TD has a stronger influence on the economic indices than TA.","Conversely, in lattice-like networks, TA plays a more significant role.","Our findings intuitively explain why highly talented agents are more likely to become central hubs in the network and why social connections tend to form between individuals with similar talent levels (socioeconomic homophily)."],"url":"http://arxiv.org/abs/2404.04175v1","category":"physics.soc-ph"}
{"created":"2024-04-05 15:32:49","title":"H3DFact: Heterogeneous 3D Integrated CIM for Factorization with Holographic Perceptual Representations","abstract":"Disentangling attributes of various sensory signals is central to human-like perception and reasoning and a critical task for higher-order cognitive and neuro-symbolic AI systems. An elegant approach to represent this intricate factorization is via high-dimensional holographic vectors drawing on brain-inspired vector symbolic architectures. However, holographic factorization involves iterative computation with high-dimensional matrix-vector multiplications and suffers from non-convergence problems.   In this paper, we present H3DFact, a heterogeneous 3D integrated in-memory compute engine capable of efficiently factorizing high-dimensional holographic representations. H3DFact exploits the computation-in-superposition capability of holographic vectors and the intrinsic stochasticity associated with memristive-based 3D compute-in-memory. Evaluated on large-scale factorization and perceptual problems, H3DFact demonstrates superior capability in factorization accuracy and operational capacity by up to five orders of magnitude, with 5.5x compute density, 1.2x energy efficiency improvements, and 5.9x less silicon footprint compared to iso-capacity 2D designs.","sentences":["Disentangling attributes of various sensory signals is central to human-like perception and reasoning and a critical task for higher-order cognitive and neuro-symbolic AI systems.","An elegant approach to represent this intricate factorization is via high-dimensional holographic vectors drawing on brain-inspired vector symbolic architectures.","However, holographic factorization involves iterative computation with high-dimensional matrix-vector multiplications and suffers from non-convergence problems.   ","In this paper, we present H3DFact, a heterogeneous 3D integrated in-memory compute engine capable of efficiently factorizing high-dimensional holographic representations.","H3DFact exploits the computation-in-superposition capability of holographic vectors and the intrinsic stochasticity associated with memristive-based 3D compute-in-memory.","Evaluated on large-scale factorization and perceptual problems, H3DFact demonstrates superior capability in factorization accuracy and operational capacity by up to five orders of magnitude, with 5.5x compute density, 1.2x energy efficiency improvements, and 5.9x less silicon footprint compared to iso-capacity 2D designs."],"url":"http://arxiv.org/abs/2404.04173v1","category":"cs.AR"}
{"created":"2024-04-05 15:32:14","title":"Thermal Area Law in Long-Range Interacting Systems","abstract":"The area law of the bipartite information measure characterizes one of the most fundamental aspects of quantum many-body physics. In thermal equilibrium, the area law for the mutual information universally holds at arbitrary temperatures as long as the systems have short-range interactions. In systems with power-law decaying interactions, $r^{-\\alpha}$ ($r$: distance), conditions for the thermal area law are elusive. In this work, we aim to clarify the optimal condition $\\alpha> \\alpha_c$ such that the thermal area law universally holds. A standard approach to considering the conditions is to focus on the magnitude of the boundary interaction between two subsystems. However, we find here that the thermal area law is more robust than this conventional argument suggests. We show the optimal threshold for the thermal area law by $\\alpha_c= (D+1)/2$ ($D$: the spatial dimension of the lattice), assuming a power-law decay of the clustering for the bipartite correlations. Remarkably, this condition encompasses even the thermodynamically unstable regimes $\\alpha < D$. We verify this condition numerically, finding that it is qualitatively accurate for both integrable and non-integrable systems. Unconditional proof of the thermal area law is possible by developing the power-law clustering theorem for $\\alpha > D$ above a threshold temperature. Furthermore, the numerical calculation for the logarithmic negativity shows that the same criterion $\\alpha > (D+1)/2$ applies to the thermal area law for quantum entanglement.","sentences":["The area law of the bipartite information measure characterizes one of the most fundamental aspects of quantum many-body physics.","In thermal equilibrium, the area law for the mutual information universally holds at arbitrary temperatures as long as the systems have short-range interactions.","In systems with power-law decaying interactions, $r^{-\\alpha}$ ($r$: distance), conditions for the thermal area law are elusive.","In this work, we aim to clarify the optimal condition $\\alpha> \\alpha_c$ such that the thermal area law universally holds.","A standard approach to considering the conditions is to focus on the magnitude of the boundary interaction between two subsystems.","However, we find here that the thermal area law is more robust than this conventional argument suggests.","We show the optimal threshold for the thermal area law by $\\alpha_c= (D+1)/2$ ($D$: the spatial dimension of the lattice), assuming a power-law decay of the clustering for the bipartite correlations.","Remarkably, this condition encompasses even the thermodynamically unstable regimes $\\alpha < D$.","We verify this condition numerically, finding that it is qualitatively accurate for both integrable and non-integrable systems.","Unconditional proof of the thermal area law is possible by developing the power-law clustering theorem for $\\alpha > D$ above a threshold temperature.","Furthermore, the numerical calculation for the logarithmic negativity shows that the same criterion $\\alpha > (D+1)/2$ applies to the thermal area law for quantum entanglement."],"url":"http://arxiv.org/abs/2404.04172v1","category":"quant-ph"}
{"created":"2024-04-05 15:24:59","title":"Directed Aggregation of Cellulose Nanocrystals to Enhance Chiral Twist","abstract":"Cellulose nanocrystals (CNCs) are bioderived nanoparticles that can be isolated from any source of natural cellulose via sulfuric acid hydrolysis. Arising from a combination of the negatively-charged sulfate half-ester groups grafted during this process and their elongated morphology, CNCs typically form colloidal cholesteric liquid crystalline phases in aqueous suspension. Recently, the chiral strength of such a CNC mesophase was correlated to the presence of CNCs with a 'bundle' morphology, analogous to the case of chiral dopants in molecular liquid crystal systems. This indicates the central role these composite particles play in the chiral behavior of CNCs, however the origin and formation pathway of the CNC bundles remains elusive. In this study, we systematically explore how different post-hydrolysis treatments alter the morphology of the CNCs (using electron microscopy, viscosimetry, and electron diffraction) and correlate this to changes in the observed liquid crystalline behavior. We found that the centrifugation step applied during CNC purification favors the formation of bundles of aligned crystallites, attached preferentially on their hydrophobic faces. This is in stark contrast to ionic treatments, where uncontrolled aggregation dominates. This reveals the importance of these often-disregarded purification steps on the final chiral and liquid crystalline properties of CNCs and promotes routes to tailor them towards a variety of applications.","sentences":["Cellulose nanocrystals (CNCs) are bioderived nanoparticles that can be isolated from any source of natural cellulose via sulfuric acid hydrolysis.","Arising from a combination of the negatively-charged sulfate half-ester groups grafted during this process and their elongated morphology, CNCs typically form colloidal cholesteric liquid crystalline phases in aqueous suspension.","Recently, the chiral strength of such a CNC mesophase was correlated to the presence of CNCs with a 'bundle' morphology, analogous to the case of chiral dopants in molecular liquid crystal systems.","This indicates the central role these composite particles play in the chiral behavior of CNCs, however the origin and formation pathway of the CNC bundles remains elusive.","In this study, we systematically explore how different post-hydrolysis treatments alter the morphology of the CNCs (using electron microscopy, viscosimetry, and electron diffraction) and correlate this to changes in the observed liquid crystalline behavior.","We found that the centrifugation step applied during CNC purification favors the formation of bundles of aligned crystallites, attached preferentially on their hydrophobic faces.","This is in stark contrast to ionic treatments, where uncontrolled aggregation dominates.","This reveals the importance of these often-disregarded purification steps on the final chiral and liquid crystalline properties of CNCs and promotes routes to tailor them towards a variety of applications."],"url":"http://arxiv.org/abs/2404.04171v1","category":"cond-mat.soft"}
{"created":"2024-04-05 15:22:23","title":"Stability Analysis of Adaptive Model Predictive Control Using the Circle and Tsypkin Criteria","abstract":"Absolute stability is a technique for analyzing the stability of Lur'e systems, which arise in diverse applications, such as oscillators with nonlinear damping or nonlinear stiffness. A special class of Lur'e systems consists of self-excited systems (SES), in which bounded oscillations arise from constant inputs. In many cases, SES can be stabilized by linear controllers, which motivates the present work, where the goal is to evaluate the effectiveness of adaptive model predictive control for Lur'e systems. In particular, the present paper considers predictive cost adaptive control (PCAC), which is equivalent to a linear, time-variant (LTV) controller. A closed-loop Lur'e system comprised of the positive feedback interconnection of the Lur'e system and the PCAC-based controller can thus be derived at each step. In this work, the circle and Tsypkin criteria are used to evaluate the absolute stability of the closed-loop Lur'e system, where the adaptive controller is viewed as instantaneously linear time-invariant. When the controller converges, the absolute stability criteria guarantee global asymptotic stability of the asymptotic closed-loop dynamics.","sentences":["Absolute stability is a technique for analyzing the stability of Lur'e systems, which arise in diverse applications, such as oscillators with nonlinear damping or nonlinear stiffness.","A special class of Lur'e systems consists of self-excited systems (SES), in which bounded oscillations arise from constant inputs.","In many cases, SES can be stabilized by linear controllers, which motivates the present work, where the goal is to evaluate the effectiveness of adaptive model predictive control for Lur'e systems.","In particular, the present paper considers predictive cost adaptive control (PCAC), which is equivalent to a linear, time-variant (LTV) controller.","A closed-loop Lur'e system comprised of the positive feedback interconnection of the Lur'e system and the PCAC-based controller can thus be derived at each step.","In this work, the circle and Tsypkin criteria are used to evaluate the absolute stability of the closed-loop Lur'e system, where the adaptive controller is viewed as instantaneously linear time-invariant.","When the controller converges, the absolute stability criteria guarantee global asymptotic stability of the asymptotic closed-loop dynamics."],"url":"http://arxiv.org/abs/2404.04170v1","category":"cs.SY"}
{"created":"2024-04-05 15:13:09","title":"Wireless Resource Optimization in Hybrid Semantic/Bit Communication Networks","abstract":"Recently, semantic communication (SemCom) has shown great potential in significant resource savings and efficient information exchanges, thus naturally introducing a novel and practical cellular network paradigm where two modes of SemCom and conventional bit communication (BitCom) coexist. Nevertheless, the involved wireless resource management becomes rather complicated and challenging, given the unique background knowledge matching and time-consuming semantic coding requirements in SemCom. To this end, this paper jointly investigates user association (UA), mode selection (MS), and bandwidth allocation (BA) problems in a hybrid semantic/bit communication network (HSB-Net). Concretely, we first identify a unified performance metric of message throughput for both SemCom and BitCom links. Next, we specially develop a knowledge matching-aware two-stage tandem packet queuing model and theoretically derive the average packet loss ratio and queuing latency. Combined with practical constraints, we then formulate a joint optimization problem for UA, MS, and BA to maximize the overall message throughput of HSB-Net. Afterward, we propose an optimal resource management strategy by utilizing a Lagrange primal-dual transformation method and a preference list-based heuristic algorithm with polynomial-time complexity. Numerical results not only demonstrate the accuracy of our analytical queuing model, but also validate the performance superiority of our proposed strategy compared with different benchmarks.","sentences":["Recently, semantic communication (SemCom) has shown great potential in significant resource savings and efficient information exchanges, thus naturally introducing a novel and practical cellular network paradigm where two modes of SemCom and conventional bit communication (BitCom) coexist.","Nevertheless, the involved wireless resource management becomes rather complicated and challenging, given the unique background knowledge matching and time-consuming semantic coding requirements in SemCom.","To this end, this paper jointly investigates user association (UA), mode selection (MS), and bandwidth allocation (BA) problems in a hybrid semantic/bit communication network (HSB-Net).","Concretely, we first identify a unified performance metric of message throughput for both SemCom and BitCom links.","Next, we specially develop a knowledge matching-aware two-stage tandem packet queuing model and theoretically derive the average packet loss ratio and queuing latency.","Combined with practical constraints, we then formulate a joint optimization problem for UA, MS, and BA to maximize the overall message throughput of HSB-Net.","Afterward, we propose an optimal resource management strategy by utilizing a Lagrange primal-dual transformation method and a preference list-based heuristic algorithm with polynomial-time complexity.","Numerical results not only demonstrate the accuracy of our analytical queuing model, but also validate the performance superiority of our proposed strategy compared with different benchmarks."],"url":"http://arxiv.org/abs/2404.04162v1","category":"cs.NI"}
{"created":"2024-04-05 15:10:30","title":"Hardness of circuit and monotone diameters of polytopes","abstract":"The Circuit diameter of polytopes was introduced by Borgwardt, Finhold and Hemmecke as a fundamental tool for the study of circuit augmentation schemes for linear programming and for estimating combinatorial diameters. Determining the complexity of computing the circuit diameter of polytopes was posed as an open problem by Sanit\\`a as well as by Kafer, and was recently reiterated by Borgwardt, Grewe, Kafer, Lee and Sanit\\`a.   In this paper, we solve this problem by showing that computing the circuit diameter of a polytope given in halfspace-description is strongly NP-hard. To prove this result, we show that computing the combinatorial diameter of the perfect matching polytope of a bipartite graph is NP-hard. This complements a result by Sanit\\`a (FOCS 2018) on the NP-hardness of computing the diameter of fractional matching polytopes and implies the new result that computing the diameter of a $\\{0,1\\}$-polytope is strongly NP-hard, which may be of independent interest. In our second main result, we give a precise graph-theoretic description of the monotone diameter of perfect matching polytopes and use this description to prove that computing the monotone (circuit) diameter of a given input polytope is strongly NP-hard as well.","sentences":["The Circuit diameter of polytopes was introduced by Borgwardt, Finhold and Hemmecke as a fundamental tool for the study of circuit augmentation schemes for linear programming and for estimating combinatorial diameters.","Determining the complexity of computing the circuit diameter of polytopes was posed as an open problem by Sanit\\`a as well as by Kafer, and was recently reiterated by Borgwardt, Grewe, Kafer, Lee and Sanit\\`a.   ","In this paper, we solve this problem by showing that computing the circuit diameter of a polytope given in halfspace-description is strongly NP-hard.","To prove this result, we show that computing the combinatorial diameter of the perfect matching polytope of a bipartite graph is NP-hard.","This complements a result by Sanit\\`a (FOCS 2018) on the NP-hardness of computing the diameter of fractional matching polytopes and implies the new result that computing the diameter of a $\\{0,1\\}$-polytope is strongly NP-hard, which may be of independent interest.","In our second main result, we give a precise graph-theoretic description of the monotone diameter of perfect matching polytopes and use this description to prove that computing the monotone (circuit) diameter of a given input polytope is strongly NP-hard as well."],"url":"http://arxiv.org/abs/2404.04158v1","category":"math.OC"}
{"created":"2024-04-05 15:08:07","title":"On the order of accuracy of finite-volume schemes on unstructured meshes","abstract":"We consider finite-volume schemes for linear hyperbolic systems with constant coefficients on unstructured meshes. Under the stability assumption, they exhibit the convergence rate between $p$ and $p+1$ where $p$ is the order of the truncation error. Our goal is to explain this effect. The central point of our study is that the truncation error on $(p+1)$-th order polynomials has zero average over the mesh period. This condition is verified for schemes with a polynomial reconstruction, multislope finite-volume methods, 1-exact edge-based schemes, and the flux correction method. We prove that this condition is necessary and, under additional assumptions, sufficient for the $(p+1)$-th order convergence. Furthermore, we apply the multislope method to a high-Reynolds number flow and explain its accuracy.","sentences":["We consider finite-volume schemes for linear hyperbolic systems with constant coefficients on unstructured meshes.","Under the stability assumption, they exhibit the convergence rate between $p$ and $p+1$ where $p$ is the order of the truncation error.","Our goal is to explain this effect.","The central point of our study is that the truncation error on $(p+1)$-th order polynomials has zero average over the mesh period.","This condition is verified for schemes with a polynomial reconstruction, multislope finite-volume methods, 1-exact edge-based schemes, and the flux correction method.","We prove that this condition is necessary and, under additional assumptions, sufficient for the $(p+1)$-th order convergence.","Furthermore, we apply the multislope method to a high-Reynolds number flow and explain its accuracy."],"url":"http://arxiv.org/abs/2404.04157v1","category":"math.NA"}
{"created":"2024-04-05 15:06:11","title":"Torque-Minimizing Control Allocation for Overactuated Quadrupedal Locomotion","abstract":"In this paper, we improve upon a method for optimal control of quadrupedal robots which utilizes a full-order model of the system. The original method utilizes offline nonlinear optimal control to synthesize a control scheme which exponentially orbitally stabilizes the closed-loop system. However, it is not able to handle the overactuated phases which frequently occur during quadrupedal locomotion as a result of the multi-contact nature of the system. We propose a modified method, which handles overactuated gait phases in a way that utilizes the full range of available actuators to minimize torque expenditure without requiring output trajectories to be modified. It is shown that the system under the proposed controller exhibits the same properties, i.e. exponential orbital stability, with the same or lower point-wise torque magnitude. A simulation study demonstrates that the reduction in torque may in certain cases be substantial.","sentences":["In this paper, we improve upon a method for optimal control of quadrupedal robots which utilizes a full-order model of the system.","The original method utilizes offline nonlinear optimal control to synthesize a control scheme which exponentially orbitally stabilizes the closed-loop system.","However, it is not able to handle the overactuated phases which frequently occur during quadrupedal locomotion as a result of the multi-contact nature of the system.","We propose a modified method, which handles overactuated gait phases in a way that utilizes the full range of available actuators to minimize torque expenditure without requiring output trajectories to be modified.","It is shown that the system under the proposed controller exhibits the same properties, i.e. exponential orbital stability, with the same or lower point-wise torque magnitude.","A simulation study demonstrates that the reduction in torque may in certain cases be substantial."],"url":"http://arxiv.org/abs/2404.04156v1","category":"eess.SY"}
{"created":"2024-04-05 15:04:57","title":"MarsSeg: Mars Surface Semantic Segmentation with Multi-level Extractor and Connector","abstract":"The segmentation and interpretation of the Martian surface play a pivotal role in Mars exploration, providing essential data for the trajectory planning and obstacle avoidance of rovers. However, the complex topography, similar surface features, and the lack of extensive annotated data pose significant challenges to the high-precision semantic segmentation of the Martian surface. To address these challenges, we propose a novel encoder-decoder based Mars segmentation network, termed MarsSeg. Specifically, we employ an encoder-decoder structure with a minimized number of down-sampling layers to preserve local details. To facilitate a high-level semantic understanding across the shadow multi-level feature maps, we introduce a feature enhancement connection layer situated between the encoder and decoder. This layer incorporates Mini Atrous Spatial Pyramid Pooling (Mini-ASPP), Polarized Self-Attention (PSA), and Strip Pyramid Pooling Module (SPPM). The Mini-ASPP and PSA are specifically designed for shadow feature enhancement, thereby enabling the expression of local details and small objects. Conversely, the SPPM is employed for deep feature enhancement, facilitating the extraction of high-level semantic category-related information. Experimental results derived from the Mars-Seg and AI4Mars datasets substantiate that the proposed MarsSeg outperforms other state-of-the-art methods in segmentation performance, validating the efficacy of each proposed component.","sentences":["The segmentation and interpretation of the Martian surface play a pivotal role in Mars exploration, providing essential data for the trajectory planning and obstacle avoidance of rovers.","However, the complex topography, similar surface features, and the lack of extensive annotated data pose significant challenges to the high-precision semantic segmentation of the Martian surface.","To address these challenges, we propose a novel encoder-decoder based Mars segmentation network, termed MarsSeg.","Specifically, we employ an encoder-decoder structure with a minimized number of down-sampling layers to preserve local details.","To facilitate a high-level semantic understanding across the shadow multi-level feature maps, we introduce a feature enhancement connection layer situated between the encoder and decoder.","This layer incorporates Mini Atrous Spatial Pyramid Pooling (Mini-ASPP), Polarized Self-Attention (PSA), and Strip Pyramid Pooling Module (SPPM).","The Mini-ASPP and PSA are specifically designed for shadow feature enhancement, thereby enabling the expression of local details and small objects.","Conversely, the SPPM is employed for deep feature enhancement, facilitating the extraction of high-level semantic category-related information.","Experimental results derived from the Mars-Seg and AI4Mars datasets substantiate that the proposed MarsSeg outperforms other state-of-the-art methods in segmentation performance, validating the efficacy of each proposed component."],"url":"http://arxiv.org/abs/2404.04155v1","category":"cs.CV"}
{"created":"2024-04-05 14:56:47","title":"Quantum radiation reaction: Analytical approximations and obtaining the spectrum from moments","abstract":"We derive analytical $\\chi\\ll1$ approximations for spin-dependent quantum radiation reaction for locally constant and locally monochromatic fields. We show how to factor out fast spin oscillations and obtain the degree of polarization in the plane orthogonal to the magnetic field from the Frobenius norm of the Mueller matrix. We show that spin effects lead to a transseries in $\\chi$, with powers $\\chi^k$, logarithms $(\\ln\\chi)^k$ and oscillating terms, $\\cos(\\dots/\\chi)$ and $\\sin(\\dots/\\chi)$. In our approach we can obtain each moment, $\\langle(kP)^m\\rangle$, of the lightfront longitudinal momentum independently of the other moments and without considering the spectrum. We show how to obtain a low-energy expansion of the spectrum from the moments by treating $m$ as a continuous, complex parameter and performing an inverse Mellin transform. We also show how to obtain the spectrum, without making a low-energy approximation, from a handful of moments using the principle of maximum entropy.","sentences":["We derive analytical $\\chi\\ll1$ approximations for spin-dependent quantum radiation reaction for locally constant and locally monochromatic fields.","We show how to factor out fast spin oscillations and obtain the degree of polarization in the plane orthogonal to the magnetic field from the Frobenius norm of the Mueller matrix.","We show that spin effects lead to a transseries in $\\chi$, with powers $\\chi^k$, logarithms $(\\ln\\chi)^k$ and oscillating terms, $\\cos(\\dots/\\chi)$ and $\\sin(\\dots/\\chi)$. In our approach we can obtain each moment, $\\langle(kP)^m\\rangle$, of the lightfront longitudinal momentum independently of the other moments and without considering the spectrum.","We show how to obtain a low-energy expansion of the spectrum from the moments by treating $m$ as a continuous, complex parameter and performing an inverse Mellin transform.","We also show how to obtain the spectrum, without making a low-energy approximation, from a handful of moments using the principle of maximum entropy."],"url":"http://arxiv.org/abs/2404.04152v1","category":"hep-ph"}
{"created":"2024-04-05 14:51:03","title":"GA-NIFS: An extremely nitrogen-loud and chemically stratified galaxy at $z\\sim 5.55$","abstract":"We report the chemical abundance pattern of GS\\_3073, a galaxy at $z=5.55$ which was previously confirmed to host an overmassive active black hole, by leveraging the detection of about 40 emission lines, combining JWST/NIRSpec observations and ground-based (VLT/VIMOS) data. By using rest-frame UV emission lines, which trace high-density ($\\sim 10^5~{\\rm cm}^{-3}$) and highly ionized gas, we derived an abundance ratio of $\\rm log(N/O) = 0.46^{+0.12}_{-0.09}$. At an estimated metallicity of $0.2~Z_{\\odot}$, this is the most extreme nitrogen-rich object found by JWST thus far. In comparison, the relative carbon abundance derived from the rest-frame UV emission lines is $\\rm log(C/O) = -0.30^{+0.12}_{-0.09}$, which is not significantly higher than those in local galaxies and stars with similar metallicities. We also detected coronal lines, including [FeVII]$\\lambda 6087$ and potentially [FeXIV]$\\lambda 5303$. We inferred a high Fe abundance of $\\rm [Fe/O] \\gtrsim 0.1$. Overall, the chemical abundance pattern of GS\\_3073 is compatible with enrichment by super-massive stars with $M_* \\gtrsim 1000~M_\\odot$, ejecta from asymptotic giant branch (AGB) stars, or winds from Wolf-Rayet (WR) stars, although the WR scenario is less likely. Interestingly, when using optical emission lines which trace lower density ($\\sim 10^3~{\\rm cm}^{-3}$) and lower ionization gas, we found a sub-solar N/O ratio. We interpret the difference in N/O derived from UV lines and optical lines as evidence for a stratified system, where the inner and denser region is both more chemically enriched and more ionized. Taking this luminous, well-studied system as a benchmark, our results suggest that nitrogen loudness in high-$z$ galaxies is confined to the central, dense, and highly ionized region of the galaxy, while the bulk of the galaxy evolves more normally.","sentences":["We report the chemical abundance pattern of GS\\_3073, a galaxy at $z=5.55$ which was previously confirmed to host an overmassive active black hole, by leveraging the detection of about 40 emission lines, combining JWST/NIRSpec observations and ground-based (VLT/VIMOS) data.","By using rest-frame UV emission lines, which trace high-density ($\\sim 10^5~{\\rm cm}^{-3}$) and highly ionized gas, we derived an abundance ratio of $\\rm log(N/O) =","0.46^{+0.12}_{-0.09}$.","At an estimated metallicity of $0.2~Z_{\\odot}$, this is the most extreme nitrogen-rich object found by JWST thus far.","In comparison, the relative carbon abundance derived from the rest-frame UV emission lines is $\\rm log(C/O) = -0.30^{+0.12}_{-0.09}$, which is not significantly higher than those in local galaxies and stars with similar metallicities.","We also detected coronal lines, including [FeVII]$\\lambda 6087$ and potentially","[FeXIV]$\\lambda 5303$. We inferred a high Fe abundance of $\\rm [Fe/O]","\\gtrsim 0.1$. Overall, the chemical abundance pattern of GS\\_3073 is compatible with enrichment by super-massive stars with $M_*","\\gtrsim 1000~M_\\odot$, ejecta from asymptotic giant branch (AGB) stars, or winds from Wolf-Rayet (WR) stars, although the WR scenario is less likely.","Interestingly, when using optical emission lines which trace lower density ($\\sim 10^3~{\\rm cm}^{-3}$) and lower ionization gas, we found a sub-solar N/O ratio.","We interpret the difference in N/O derived from UV lines and optical lines as evidence for a stratified system, where the inner and denser region is both more chemically enriched and more ionized.","Taking this luminous, well-studied system as a benchmark, our results suggest that nitrogen loudness in high-$z$ galaxies is confined to the central, dense, and highly ionized region of the galaxy, while the bulk of the galaxy evolves more normally."],"url":"http://arxiv.org/abs/2404.04148v1","category":"astro-ph.GA"}
{"created":"2024-04-05 14:50:11","title":"Braiding of Majorana bound states in a driven-dissipative Majorana box setup","abstract":"We investigate a system of Majorana box qubits, where each of the Coulomb blockaded boxes is driven by an applied AC voltage and is embedded in a dissipative environment. The AC voltage is applied between a pair of quantum dots, each of which is coupled by tunneling to a Majorana box qubit. Moreover, the dissipation is created by the coupling to an electromagnetic environment. Recent work has shown that in this case the Majorana bound states which form the computational basis can emerge as dark states, which are stabilized by the dissipation. In our work, we show that the same platform can be used to enable topological braiding of these dissipative Majorana bound states. We show that coupling three such Majorana boxes allows a braiding transformation by changing the tunnel amplitudes adiabatically in time.","sentences":["We investigate a system of Majorana box qubits, where each of the Coulomb blockaded boxes is driven by an applied AC voltage and is embedded in a dissipative environment.","The AC voltage is applied between a pair of quantum dots, each of which is coupled by tunneling to a Majorana box qubit.","Moreover, the dissipation is created by the coupling to an electromagnetic environment.","Recent work has shown that in this case the Majorana bound states which form the computational basis can emerge as dark states, which are stabilized by the dissipation.","In our work, we show that the same platform can be used to enable topological braiding of these dissipative Majorana bound states.","We show that coupling three such Majorana boxes allows a braiding transformation by changing the tunnel amplitudes adiabatically in time."],"url":"http://arxiv.org/abs/2404.04147v1","category":"cond-mat.mes-hall"}
{"created":"2024-04-05 14:49:47","title":"Nonlocally coupled moisture model for convective self-aggregation","abstract":"Clouds play a central role in climate physics by interacting with precipitation, radiation, and circulation. Although the self-aggregation of clouds is a fundamental problem in convective organization, a theoretical explanation of how it occurs has not been established owing to its complexity. Here, we introduce an idealized mathematical model of the phenomenon in which the state of the system is represented solely by the atmospheric columns' vertically integrated water vapor content. By analyzing the nonlinear dynamics of this simplified system, we mathematically elucidated the mechanisms that determine the onset of self-aggregation and the spatial scale of the self-aggregated state. Nonlocal coupling between atmospheric columns makes the system bistable with dry and moist equilibria, reflecting the effect of circulation driven by horizontal differential heating due to convection and radiation. The bistable self-aggregated state is realized when destabilization by nonlocal coupling triggered by finite-amplitude disturbances in the uniform state overwhelms the stabilization by diffusion. For globally coupled systems in which all the columns are equally coupled, the perturbation of the maximum wavelength has the maximum growth rate. A solution with an infinitely long wavelength exists, which can be understood as the dynamical system's heteroclinic trajectories describing the steady state's spatial evolution. In contrast, for nonlocally coupled systems with finite filter lengths, perturbation of the wavelength close to the characteristic length of the coupling is preferred. The results revealed that the balance between nonlocal coupling and diffusion is essential for understanding convective self-aggregation.","sentences":["Clouds play a central role in climate physics by interacting with precipitation, radiation, and circulation.","Although the self-aggregation of clouds is a fundamental problem in convective organization, a theoretical explanation of how it occurs has not been established owing to its complexity.","Here, we introduce an idealized mathematical model of the phenomenon in which the state of the system is represented solely by the atmospheric columns' vertically integrated water vapor content.","By analyzing the nonlinear dynamics of this simplified system, we mathematically elucidated the mechanisms that determine the onset of self-aggregation and the spatial scale of the self-aggregated state.","Nonlocal coupling between atmospheric columns makes the system bistable with dry and moist equilibria, reflecting the effect of circulation driven by horizontal differential heating due to convection and radiation.","The bistable self-aggregated state is realized when destabilization by nonlocal coupling triggered by finite-amplitude disturbances in the uniform state overwhelms the stabilization by diffusion.","For globally coupled systems in which all the columns are equally coupled, the perturbation of the maximum wavelength has the maximum growth rate.","A solution with an infinitely long wavelength exists, which can be understood as the dynamical system's heteroclinic trajectories describing the steady state's spatial evolution.","In contrast, for nonlocally coupled systems with finite filter lengths, perturbation of the wavelength close to the characteristic length of the coupling is preferred.","The results revealed that the balance between nonlocal coupling and diffusion is essential for understanding convective self-aggregation."],"url":"http://arxiv.org/abs/2404.04146v1","category":"physics.ao-ph"}
{"created":"2024-04-05 14:41:54","title":"Robust incoherent perfect absorption","abstract":"A coherent perfect absorber is capable of completely absorbing input waves. However, the coherent perfect absorption severely depends on the superposition of the input waves, and the perfect absorption is sensitive to the disorder of the absorber. Thus, a robust incoherent perfect absorption, being insensitive to the superposition of input waves and the system disorder, is desirable for practical applications. Here, we demonstrate that the linearly independent destructive interference at the port connections removes the constraint on the coherent input. We propose an approach using the interplay between the loss and localization to form the incoherent perfect absorption. The resonant incidence from either port is completely absorbed. Furthermore, we utilize the lattice configuration supporting the flat band to demonstrate the disorder-immune incoherent perfect absorption. Our findings provide insight into the fundamentals and applications for the perfect absorption of light, microwaves, sound, mechanical waves, and beyond.","sentences":["A coherent perfect absorber is capable of completely absorbing input waves.","However, the coherent perfect absorption severely depends on the superposition of the input waves, and the perfect absorption is sensitive to the disorder of the absorber.","Thus, a robust incoherent perfect absorption, being insensitive to the superposition of input waves and the system disorder, is desirable for practical applications.","Here, we demonstrate that the linearly independent destructive interference at the port connections removes the constraint on the coherent input.","We propose an approach using the interplay between the loss and localization to form the incoherent perfect absorption.","The resonant incidence from either port is completely absorbed.","Furthermore, we utilize the lattice configuration supporting the flat band to demonstrate the disorder-immune incoherent perfect absorption.","Our findings provide insight into the fundamentals and applications for the perfect absorption of light, microwaves, sound, mechanical waves, and beyond."],"url":"http://arxiv.org/abs/2404.04141v1","category":"physics.optics"}
{"created":"2024-04-05 14:29:39","title":"BinSym: Binary-Level Symbolic Execution using Formal Descriptions of Instruction Semantics","abstract":"BinSym is a framework for symbolic program analysis of software in binary form. Contrary to prior work, it operates directly on binary code instructions and does not require lifting them to an intermediate representation (IR). This is achieved by formulating the symbolic semantics on top of a formal description of binary code instruction semantics. By building on existing formal descriptions, BinSym eliminates the manual effort required by prior work to implement transformations to an IR, thereby reducing the margin for errors. Furthermore, BinSym's symbolic semantics can be directly related to the binary code, which improves symbolic execution speed by reducing solver query complexity.","sentences":["BinSym is a framework for symbolic program analysis of software in binary form.","Contrary to prior work, it operates directly on binary code instructions and does not require lifting them to an intermediate representation (IR).","This is achieved by formulating the symbolic semantics on top of a formal description of binary code instruction semantics.","By building on existing formal descriptions, BinSym eliminates the manual effort required by prior work to implement transformations to an IR, thereby reducing the margin for errors.","Furthermore, BinSym's symbolic semantics can be directly related to the binary code, which improves symbolic execution speed by reducing solver query complexity."],"url":"http://arxiv.org/abs/2404.04132v1","category":"cs.SE"}
{"created":"2024-04-05 14:25:09","title":"Balanced two-type annihilation: mean-field asymptotics","abstract":"We consider an interacting particle system where equal-sized populations of two types of particles move by random walk steps on a graph, the two types may have different speeds, and meetings of opposite-type particles result in annihilation. The key quantity of interest is the expected extinction time. Even for the mean-field setting of complete graphs, the correct order of magnitude was not previously known. Under essentially optimal assumptions on the starting configuration, we determine not only the order of magnitude but also the asymptotics: the expected extinction time on $K_{2n}$ is $(2+o(1))n\\log n$, independently of the relative speeds of the two types.","sentences":["We consider an interacting particle system where equal-sized populations of two types of particles move by random walk steps on a graph, the two types may have different speeds, and meetings of opposite-type particles result in annihilation.","The key quantity of interest is the expected extinction time.","Even for the mean-field setting of complete graphs, the correct order of magnitude was not previously known.","Under essentially optimal assumptions on the starting configuration, we determine not only the order of magnitude but also the asymptotics: the expected extinction time on $K_{2n}$ is $(2+o(1))n\\log n$, independently of the relative speeds of the two types."],"url":"http://arxiv.org/abs/2404.04128v1","category":"math.PR"}
{"created":"2024-04-05 14:23:49","title":"On the Feasibility of CubeSats Application Sandboxing for Space Missions","abstract":"This paper details our journey in designing and selecting a suitable application sandboxing mechanism for a satellite under development, with a focus on small satellites. Central to our study is the development of selection criteria for sandboxing and assessing its appropriateness for our satellite payload. We also test our approach on two already operational satellites, Suchai and SALSAT, to validate its effectiveness. These experiments highlight the practicality and efficiency of our chosen sandboxing method for real-world space systems. Our results provide insights and highlight the challenges involved in integrating application sandboxing in the space sector.","sentences":["This paper details our journey in designing and selecting a suitable application sandboxing mechanism for a satellite under development, with a focus on small satellites.","Central to our study is the development of selection criteria for sandboxing and assessing its appropriateness for our satellite payload.","We also test our approach on two already operational satellites, Suchai and SALSAT, to validate its effectiveness.","These experiments highlight the practicality and efficiency of our chosen sandboxing method for real-world space systems.","Our results provide insights and highlight the challenges involved in integrating application sandboxing in the space sector."],"url":"http://arxiv.org/abs/2404.04127v1","category":"cs.CR"}
{"created":"2024-04-05 14:18:06","title":"GNNBENCH: Fair and Productive Benchmarking for Single-GPU GNN System","abstract":"We hypothesize that the absence of a standardized benchmark has allowed several fundamental pitfalls in GNN System design and evaluation that the community has overlooked. In this work, we propose GNNBench, a plug-and-play benchmarking platform focused on system innovation. GNNBench presents a new protocol to exchange their captive tensor data, supports custom classes in System APIs, and allows automatic integration of the same system module to many deep learning frameworks, such as PyTorch and TensorFlow. To demonstrate the importance of such a benchmark framework, we integrated several GNN systems. Our results show that integration with GNNBench helped us identify several measurement issues that deserve attention from the community.","sentences":["We hypothesize that the absence of a standardized benchmark has allowed several fundamental pitfalls in GNN System design and evaluation that the community has overlooked.","In this work, we propose GNNBench, a plug-and-play benchmarking platform focused on system innovation.","GNNBench presents a new protocol to exchange their captive tensor data, supports custom classes in System APIs, and allows automatic integration of the same system module to many deep learning frameworks, such as PyTorch and TensorFlow.","To demonstrate the importance of such a benchmark framework, we integrated several GNN systems.","Our results show that integration with GNNBench helped us identify several measurement issues that deserve attention from the community."],"url":"http://arxiv.org/abs/2404.04118v1","category":"cs.LG"}
{"created":"2024-04-05 14:16:45","title":"The quadratic tracking problem for systems with persistent memory in $\\zzr^d$","abstract":"The classical quadratic regulator problem has rarely been studied for systems with persistent memory until recent times. In this paper we study the quadratic tracking problem on a \\emph{ finite time horizon} for a system described by a controlled linear Volterra integrodifferential equation in $\\zzr^d$. We use the Fredholm equation approach and we derive the synthesis of the optimal control in terms of a Riccati differential equation, independent of the reference signal, and of two equations which instead depend on the reference signal. In the final section we introduce a representation of the system in a state space \\emph{of finite memory } (as the tracking problem under study) and we show that the equations used in the synthesis can be formulated as a differential system in this space. This fact has to be contrasted with the semigroup approach which requires that the system be recasted in a space of infinite memory.","sentences":["The classical quadratic regulator problem has rarely been studied for systems with persistent memory until recent times.","In this paper we study the quadratic tracking problem on a \\emph{ finite time horizon} for a system described by a controlled linear Volterra integrodifferential equation in $\\zzr^d$. We use the Fredholm equation approach and we derive the synthesis of the optimal control in terms of a Riccati differential equation, independent of the reference signal, and of two equations which instead depend on the reference signal.","In the final section we introduce a representation of the system in a state space \\emph{of finite memory } (as the tracking problem under study) and we show that the equations used in the synthesis can be formulated as a differential system in this space.","This fact has to be contrasted with the semigroup approach which requires that the system be recasted in a space of infinite memory."],"url":"http://arxiv.org/abs/2404.04117v1","category":"math.OC"}
{"created":"2024-04-05 14:14:08","title":"The existence of stratified linearly steady two-mode water waves with stagnation points","abstract":"This paper focuses on the analysis of stratified steady periodic water waves that contain stagnation points. The initial step involves transforming the free-boundary problem into a quasilinear pseudodifferential equation through a conformal mapping technique, resulting in a periodic function of a single variable. By utilizing the theorems developed by Crandall and Rabinowitz, we establish the existence and formal stability of small-amplitude steady periodic capillary-gravity water waves in the presence of stratified linear flows. Notably, the stability of bifurcation solution curves is strongly influenced by the stratified nature of the system. Additionally, as the Bernoulli's function $\\beta$ approaches critical values, we observe that the linearized problem exhibits a two-dimensional kernel. Consequently, we apply a bifurcation theorem due to Kielh\\\"{o}fer that incorporates multiple-dimensional kernels and parameters, which enables us to establish the existence of two-mode water waves. As far as we know, the two-mode water waves in stratified flow are first constructed by us. Finally, we demonstrate the presence of internal stagnation points within these waves.","sentences":["This paper focuses on the analysis of stratified steady periodic water waves that contain stagnation points.","The initial step involves transforming the free-boundary problem into a quasilinear pseudodifferential equation through a conformal mapping technique, resulting in a periodic function of a single variable.","By utilizing the theorems developed by Crandall and Rabinowitz, we establish the existence and formal stability of small-amplitude steady periodic capillary-gravity water waves in the presence of stratified linear flows.","Notably, the stability of bifurcation solution curves is strongly influenced by the stratified nature of the system.","Additionally, as the Bernoulli's function $\\beta$ approaches critical values, we observe that the linearized problem exhibits a two-dimensional kernel.","Consequently, we apply a bifurcation theorem due to Kielh\\\"{o}fer that incorporates multiple-dimensional kernels and parameters, which enables us to establish the existence of two-mode water waves.","As far as we know, the two-mode water waves in stratified flow are first constructed by us.","Finally, we demonstrate the presence of internal stagnation points within these waves."],"url":"http://arxiv.org/abs/2404.04114v1","category":"math.AP"}
{"created":"2024-04-05 14:08:34","title":"Periodic travelling interfacial electrohydrodynamic waves: bifurcation and secondary bifurcation","abstract":"In this paper, two-dimensional periodic capillary-gravity waves travelling under the effect of a vertical electric field are considered. The full system is a nonlinear, two-layered and free boundary problem. The interface dynamics arises from the coupling between the Euler equations for the lower fluid layer and an electric contribution from the upper gas layer. To investigate the electrohydrodynamic wave interactions, we first introduce the naive flattening technique to transform the free boundary problem into a fixed boundary problem. Then we prove the existence of the small-amplitude electrohydrodynamic waves with constant vorticity $\\gamma$ by using local bifurcation theory. Moreover, we prove that these electrohydrodynamic waves are formally stable in linearized sense. Furthermore, we obtain a secondary bifurcation curve that emerges from the primary branch at a nonlaminar solution as $E_0$ being close to some special value. This secondary bifurcation curve consists of ripples solutions on the interface of a conducting fluid under normal electric fields. As far as we know, this new phenomenon in electrohydrodynamics (EHD) is first established mathematically. It is worth noting that the electric field $E_0$ plays a key role to control the shapes and types of waves on the interface.","sentences":["In this paper, two-dimensional periodic capillary-gravity waves travelling under the effect of a vertical electric field are considered.","The full system is a nonlinear, two-layered and free boundary problem.","The interface dynamics arises from the coupling between the Euler equations for the lower fluid layer and an electric contribution from the upper gas layer.","To investigate the electrohydrodynamic wave interactions, we first introduce the naive flattening technique to transform the free boundary problem into a fixed boundary problem.","Then we prove the existence of the small-amplitude electrohydrodynamic waves with constant vorticity $\\gamma$ by using local bifurcation theory.","Moreover, we prove that these electrohydrodynamic waves are formally stable in linearized sense.","Furthermore, we obtain a secondary bifurcation curve that emerges from the primary branch at a nonlaminar solution as $E_0$ being close to some special value.","This secondary bifurcation curve consists of ripples solutions on the interface of a conducting fluid under normal electric fields.","As far as we know, this new phenomenon in electrohydrodynamics (EHD) is first established mathematically.","It is worth noting that the electric field $E_0$ plays a key role to control the shapes and types of waves on the interface."],"url":"http://arxiv.org/abs/2404.04110v1","category":"math.AP"}
{"created":"2024-04-05 14:08:15","title":"Pseudospectral discretization of the time-dependent Schr\u00f6dinger equation","abstract":"The purpose of this document is to describe the solution and implementation of the time-independent and time-dependent Schr\\\"odinger using pseudospectral methods. Currently, the description is for single particle systems interacting with a classical electromagnetic field in spherical coordinates.","sentences":["The purpose of this document is to describe the solution and implementation of the time-independent and time-dependent Schr\\\"odinger using pseudospectral methods.","Currently, the description is for single particle systems interacting with a classical electromagnetic field in spherical coordinates."],"url":"http://arxiv.org/abs/2404.04109v1","category":"quant-ph"}
{"created":"2024-04-05 14:02:20","title":"Neutron optical tuning of Fe/11B4CTi multilayers for optimal polarization and increased reflectivity for polarizing neutron optics","abstract":"The concept of scattering length density tuning for improved polarization is investigated for Fe/11B4CTi multilayers and compared to the commonly used Fe/Si system in polarizing multilayer neutron optics. X-ray and neutron reflectivity, magnetization, and neutron polarization have been measured on such multilayers, highlighting differences from conventional Fe/Si multilayers. The multilayer systems were deposited with 25 {\\AA} period thickness, a layer thickness ratio of 0.35 and 20 periods, using ion-assisted DC magnetron sputtering. Replacing Si with 11B4CTi for these multilayers showed an increase in reflectivity due to a reduction in interface width. By tuning the ratio between 11B4C and Ti in the non-magnetic layers, a broad range of scattering length density values was achieved, facilitating scattering length density contrast matching between layers for spin-down neutrons, thereby enhancing polarization. These findings demonstrate the potential of Fe/11B4CTi multilayers as a promising option for polarizing neutron optics and highlight the concept of scattering length density tuning in a large range using 11B4CTi.","sentences":["The concept of scattering length density tuning for improved polarization is investigated for Fe/11B4CTi multilayers and compared to the commonly used Fe/Si system in polarizing multilayer neutron optics.","X-ray and neutron reflectivity, magnetization, and neutron polarization have been measured on such multilayers, highlighting differences from conventional Fe/Si multilayers.","The multilayer systems were deposited with 25 {\\AA} period thickness, a layer thickness ratio of 0.35 and 20 periods, using ion-assisted DC magnetron sputtering.","Replacing Si with 11B4CTi for these multilayers showed an increase in reflectivity due to a reduction in interface width.","By tuning the ratio between 11B4C and Ti in the non-magnetic layers, a broad range of scattering length density values was achieved, facilitating scattering length density contrast matching between layers for spin-down neutrons, thereby enhancing polarization.","These findings demonstrate the potential of Fe/11B4CTi multilayers as a promising option for polarizing neutron optics and highlight the concept of scattering length density tuning in a large range using 11B4CTi."],"url":"http://arxiv.org/abs/2404.04107v1","category":"cond-mat.mtrl-sci"}
{"created":"2024-04-05 13:49:39","title":"A MUSE View of the Core of the Giant Low Surface Brightness Galaxy Malin 1","abstract":"Aims. The central region of the Giant Low Surface Brightness galaxy Malin 1 has long been known to have a complex morphology with evidence of a bulge, disc, and potentially a bar hosting asymmetric star formation. In this work, we use VLT/MUSE data to resolve the central region of Malin 1 in order to determine its structure. Methods. We use careful light profile fitting in every image slice of the datacube to create wavelength-dependent models of each morphological component, from which we could cleanly extract their spectra. We then used the kinematics and emission line properties from these spectra to better understand the nature of each component extracted from our model fit. Results. We report the detection of a pair of distinct sources at the centre of this galaxy with a separation of ~1.05\", which corresponds to a separation on sky of ~1.9 kpc. The radial velocity data of each object confirms that they both lie in the kinematic core of the galaxy, and analysis of the emission lines reveals that the central compact source is more consistent with being ionized by star formation and/or a LINER, while the off-centre compact source lies closer to the separation between star-forming galaxies and AGN. Conclusions. This evidence suggests that the centre of Malin 1 hosts either a bar with asymmetric star formation or two distinct components in which the off-centre compact source could either be a star-forming clump containing one or more star clusters that is in the process of falling into the core of the galaxy and which will eventually merge with the central NSC, or a clump of gas infalling into the centre of the galaxy from either outside or from the disc and triggering star formation there.","sentences":["Aims.","The central region of the Giant Low Surface Brightness galaxy Malin 1 has long been known to have a complex morphology with evidence of a bulge, disc, and potentially a bar hosting asymmetric star formation.","In this work, we use VLT/MUSE data to resolve the central region of Malin 1 in order to determine its structure.","Methods.","We use careful light profile fitting in every image slice of the datacube to create wavelength-dependent models of each morphological component, from which we could cleanly extract their spectra.","We then used the kinematics and emission line properties from these spectra to better understand the nature of each component extracted from our model fit.","Results.","We report the detection of a pair of distinct sources at the centre of this galaxy with a separation of ~1.05\", which corresponds to a separation on sky of ~1.9 kpc.","The radial velocity data of each object confirms that they both lie in the kinematic core of the galaxy, and analysis of the emission lines reveals that the central compact source is more consistent with being ionized by star formation and/or a LINER, while the off-centre compact source lies closer to the separation between star-forming galaxies and AGN.","Conclusions.","This evidence suggests that the centre of Malin 1 hosts either a bar with asymmetric star formation or two distinct components in which the off-centre compact source could either be a star-forming clump containing one or more star clusters that is in the process of falling into the core of the galaxy and which will eventually merge with the central NSC, or a clump of gas infalling into the centre of the galaxy from either outside or from the disc and triggering star formation there."],"url":"http://arxiv.org/abs/2404.04099v1","category":"astro-ph.GA"}
{"created":"2024-04-05 13:29:06","title":"PASO -- Astronomy and Space Situational Awareness in a Dark Sky Destination","abstract":"The Pampilhosa da Serra Space Observatory (PASO) is located in the center of the continental Portuguese territory, in the heart of a certified Dark Sky destination by the Starlight Foundation (Aldeias do Xisto) and has been an instrumental asset to advance science, education and astrotourism certifications. PASO hosts astronomy and Space Situational Awareness (SSA) activities including a node of the Portuguese Space Surveillance \\& Tracking (SST) infrastructure network, such as a space radar currently in test phase using GEM radiotelescope, a double Wide Field of View Telescope system, a EUSST optical sensor telescope. These instruments allow surveillance of satellite and space debris in LEO, MEO and GEO orbits. The WFOV telescope offers spectroscopy capabilities enabling light curve analysis and cosmic sources monitoring. Instruments for Space Weather are being considered for installation to monitor solar activities and expand the range of SSA services.","sentences":["The Pampilhosa da Serra Space Observatory (PASO) is located in the center of the continental Portuguese territory, in the heart of a certified Dark Sky destination by the Starlight Foundation (Aldeias do Xisto) and has been an instrumental asset to advance science, education and astrotourism certifications.","PASO hosts astronomy and Space Situational Awareness (SSA) activities including a node of the Portuguese Space Surveillance \\& Tracking (SST) infrastructure network, such as a space radar currently in test phase using GEM radiotelescope, a double Wide Field of View Telescope system, a EUSST optical sensor telescope.","These instruments allow surveillance of satellite and space debris in LEO, MEO and GEO orbits.","The WFOV telescope offers spectroscopy capabilities enabling light curve analysis and cosmic sources monitoring.","Instruments for Space Weather are being considered for installation to monitor solar activities and expand the range of SSA services."],"url":"http://arxiv.org/abs/2404.04090v1","category":"astro-ph.IM"}
{"created":"2024-04-05 13:22:05","title":"Field Teams Coordination for Earthquake-Damaged Distribution System Energization","abstract":"The re-energization of electrical distribution systems in a post-disaster scenario is of grave importance as most modern infrastructure systems rely heavily on the presence of electricity. This paper introduces a method to coordinate the field teams for the optimal energization of an electrical distribution system after an earthquake-induced blackout. The proposed method utilizes a Markov Decision Process (MDP) to create an optimal energization strategy, which aims to minimize the expected time to energize each distribution system component. The travel duration of each team and the possible outcomes of the energization attempts are considered in the state transitions. The failure probabilities of the system components are computed using the fragility curves of structures and the Peak Ground Acceleration (PGA) values which are encoded to the MDP model via transition probabilities. Furthermore, the proposed solution offers several methods to determine the non-optimal actions during the construction of the MDP and eliminate them in order to improve the run-time performance without sacrificing the optimality of the solution.","sentences":["The re-energization of electrical distribution systems in a post-disaster scenario is of grave importance as most modern infrastructure systems rely heavily on the presence of electricity.","This paper introduces a method to coordinate the field teams for the optimal energization of an electrical distribution system after an earthquake-induced blackout.","The proposed method utilizes a Markov Decision Process (MDP) to create an optimal energization strategy, which aims to minimize the expected time to energize each distribution system component.","The travel duration of each team and the possible outcomes of the energization attempts are considered in the state transitions.","The failure probabilities of the system components are computed using the fragility curves of structures and the Peak Ground Acceleration (PGA) values which are encoded to the MDP model via transition probabilities.","Furthermore, the proposed solution offers several methods to determine the non-optimal actions during the construction of the MDP and eliminate them in order to improve the run-time performance without sacrificing the optimality of the solution."],"url":"http://arxiv.org/abs/2404.04087v1","category":"eess.SY"}
{"created":"2024-04-05 13:16:57","title":"Clock offset recovery with sublinear complexity enables synchronization on low-level hardware for quantum key distribution","abstract":"We introduce iQSync, a clock offset recovery method designed for implementation on low-level hardware, such as FPGAs or microcontrollers, for quantum key distribution (QKD). iQSync requires minimal memory, only a simple instruction set (e.g. no floating-point operations), and can be evaluated with sublinear time complexity, typically involving no more than a few thousand iterations of a simple loop. Furthermore, iQSync allows for a precise clock offset recovery within few seconds, even for large offsets, and is well suited for scenarios with high channel loss and low signal-to-noise ratio, irrespective of the prepare-and-measure QKD protocol used. We implemented the method on our QKD platform, demonstrating its performance and conformity with analytically derived success probabilities for channel attenuations exceeding 70 dB.","sentences":["We introduce iQSync, a clock offset recovery method designed for implementation on low-level hardware, such as FPGAs or microcontrollers, for quantum key distribution (QKD).","iQSync requires minimal memory, only a simple instruction set (e.g. no floating-point operations), and can be evaluated with sublinear time complexity, typically involving no more than a few thousand iterations of a simple loop.","Furthermore, iQSync allows for a precise clock offset recovery within few seconds, even for large offsets, and is well suited for scenarios with high channel loss and low signal-to-noise ratio, irrespective of the prepare-and-measure QKD protocol used.","We implemented the method on our QKD platform, demonstrating its performance and conformity with analytically derived success probabilities for channel attenuations exceeding 70 dB."],"url":"http://arxiv.org/abs/2404.04081v1","category":"quant-ph"}
{"created":"2024-04-05 13:13:02","title":"Queue-aware Network Control Algorithm with a High Quantum Computing Readiness-Evaluated in Discrete-time Flow Simulator for Fat-Pipe Networks","abstract":"The emerging technology of quantum computing has the potential to change the way how problems will be solved in the future. This work presents a centralized network control algorithm executable on already existing quantum computer which are based on the principle of quantum annealing like the D-Wave Advantage. We introduce a resource reoccupation algorithm for traffic engineering in wide-area networks. The proposed optimization algorithm changes traffic steering and resource allocation in case of overloaded transceivers. Settings of active components like fiber amplifiers and transceivers are not changed for the reason of stability. This algorithm is beneficial in situations when the network traffic is fluctuating in time scales of seconds or spontaneous bursts occur. Further, we developed a discrete-time flow simulator to study the algorithm's performance in wide-area networks. Our network simulator considers backlog and loss modeling of buffered transmission lines. Concurring flows are handled equally in case of a backlog.   This work provides an ILP-based network configuring algorithm that is applicable on quantum annealing computers. We showcase, that traffic losses can be reduced significantly by a factor of 2 if a resource reoccupation algorithm is applied in a network with bursty traffic. As resources are used more efficiently by reoccupation in heavy load situations, overprovisioning of networks can be reduced. Thus, this new form of network operation leads toward a zero-margin network. We show that our newly introduced network simulator enables analyses of short-time effects like buffering within fat-pipe networks. As the calculation of network configurations in real-sized networks is typically time-consuming, quantum computing can enable the proposed network configuration algorithm for application in real-sized wide-area networks.","sentences":["The emerging technology of quantum computing has the potential to change the way how problems will be solved in the future.","This work presents a centralized network control algorithm executable on already existing quantum computer which are based on the principle of quantum annealing like the D-Wave Advantage.","We introduce a resource reoccupation algorithm for traffic engineering in wide-area networks.","The proposed optimization algorithm changes traffic steering and resource allocation in case of overloaded transceivers.","Settings of active components like fiber amplifiers and transceivers are not changed for the reason of stability.","This algorithm is beneficial in situations when the network traffic is fluctuating in time scales of seconds or spontaneous bursts occur.","Further, we developed a discrete-time flow simulator to study the algorithm's performance in wide-area networks.","Our network simulator considers backlog and loss modeling of buffered transmission lines.","Concurring flows are handled equally in case of a backlog.   ","This work provides an ILP-based network configuring algorithm that is applicable on quantum annealing computers.","We showcase, that traffic losses can be reduced significantly by a factor of 2 if a resource reoccupation algorithm is applied in a network with bursty traffic.","As resources are used more efficiently by reoccupation in heavy load situations, overprovisioning of networks can be reduced.","Thus, this new form of network operation leads toward a zero-margin network.","We show that our newly introduced network simulator enables analyses of short-time effects like buffering within fat-pipe networks.","As the calculation of network configurations in real-sized networks is typically time-consuming, quantum computing can enable the proposed network configuration algorithm for application in real-sized wide-area networks."],"url":"http://arxiv.org/abs/2404.04080v1","category":"eess.SY"}
{"created":"2024-04-05 12:55:04","title":"High-Frequency Capacitive Sensing for Electrohydraulic Soft Actuators","abstract":"The need for compliant and proprioceptive actuators has grown more evident in pursuing more adaptable and versatile robotic systems. Hydraulically Amplified Self-Healing Electrostatic (HASEL) actuators offer distinctive advantages with their inherent softness and flexibility, making them promising candidates for various robotic tasks, including delicate interactions with humans and animals, biomimetic locomotion, prosthetics, and exoskeletons. This has resulted in a growing interest in the capacitive self-sensing capabilities of HASEL actuators to create miniature displacement estimation circuitry that does not require external sensors. However, achieving HASEL self-sensing for actuation frequencies above 1 Hz and with miniature high-voltage power supplies has remained limited. In this paper, we introduce the F-HASEL actuator, which adds an additional electrode pair used exclusively for capacitive sensing to a Peano-HASEL actuator. We demonstrate displacement estimation of the F-HASEL during high-frequency actuation up to 20 Hz and during external loading using miniaturized circuitry comprised of low-cost off-the-shelf components and a miniature high-voltage power supply. Finally, we propose a circuitry to estimate the displacement of multiple F-HASELs and demonstrate it in a wearable application to track joint rotations of a virtual reality user in real-time.","sentences":["The need for compliant and proprioceptive actuators has grown more evident in pursuing more adaptable and versatile robotic systems.","Hydraulically Amplified Self-Healing Electrostatic (HASEL) actuators offer distinctive advantages with their inherent softness and flexibility, making them promising candidates for various robotic tasks, including delicate interactions with humans and animals, biomimetic locomotion, prosthetics, and exoskeletons.","This has resulted in a growing interest in the capacitive self-sensing capabilities of HASEL actuators to create miniature displacement estimation circuitry that does not require external sensors.","However, achieving HASEL self-sensing for actuation frequencies above 1 Hz and with miniature high-voltage power supplies has remained limited.","In this paper, we introduce the F-HASEL actuator, which adds an additional electrode pair used exclusively for capacitive sensing to a Peano-HASEL actuator.","We demonstrate displacement estimation of the F-HASEL during high-frequency actuation up to 20 Hz and during external loading using miniaturized circuitry comprised of low-cost off-the-shelf components and a miniature high-voltage power supply.","Finally, we propose a circuitry to estimate the displacement of multiple F-HASELs and demonstrate it in a wearable application to track joint rotations of a virtual reality user in real-time."],"url":"http://arxiv.org/abs/2404.04071v1","category":"cs.RO"}
{"created":"2024-04-05 12:37:08","title":"Derivative-free tree optimization for complex systems","abstract":"A tremendous range of design tasks in materials, physics, and biology can be formulated as finding the optimum of an objective function depending on many parameters without knowing its closed-form expression or the derivative. Traditional derivative-free optimization techniques often rely on strong assumptions about objective functions, thereby failing at optimizing non-convex systems beyond 100 dimensions. Here, we present a tree search method for derivative-free optimization that enables accelerated optimal design of high-dimensional complex systems. Specifically, we introduce stochastic tree expansion, dynamic upper confidence bound, and short-range backpropagation mechanism to evade local optimum, iteratively approximating the global optimum using machine learning models. This development effectively confronts the dimensionally challenging problems, achieving convergence to global optima across various benchmark functions up to 2,000 dimensions, surpassing the existing methods by 10- to 20-fold. Our method demonstrates wide applicability to a wide range of real-world complex systems spanning materials, physics, and biology, considerably outperforming state-of-the-art algorithms. This enables efficient autonomous knowledge discovery and facilitates self-driving virtual laboratories. Although we focus on problems within the realm of natural science, the advancements in optimization techniques achieved herein are applicable to a broader spectrum of challenges across all quantitative disciplines.","sentences":["A tremendous range of design tasks in materials, physics, and biology can be formulated as finding the optimum of an objective function depending on many parameters without knowing its closed-form expression or the derivative.","Traditional derivative-free optimization techniques often rely on strong assumptions about objective functions, thereby failing at optimizing non-convex systems beyond 100 dimensions.","Here, we present a tree search method for derivative-free optimization that enables accelerated optimal design of high-dimensional complex systems.","Specifically, we introduce stochastic tree expansion, dynamic upper confidence bound, and short-range backpropagation mechanism to evade local optimum, iteratively approximating the global optimum using machine learning models.","This development effectively confronts the dimensionally challenging problems, achieving convergence to global optima across various benchmark functions up to 2,000 dimensions, surpassing the existing methods by 10- to 20-fold.","Our method demonstrates wide applicability to a wide range of real-world complex systems spanning materials, physics, and biology, considerably outperforming state-of-the-art algorithms.","This enables efficient autonomous knowledge discovery and facilitates self-driving virtual laboratories.","Although we focus on problems within the realm of natural science, the advancements in optimization techniques achieved herein are applicable to a broader spectrum of challenges across all quantitative disciplines."],"url":"http://arxiv.org/abs/2404.04062v1","category":"cs.LG"}
{"created":"2024-04-05 12:31:19","title":"On the Quest for Effectiveness in Human Oversight: Interdisciplinary Perspectives","abstract":"Human oversight is currently discussed as a potential safeguard to counter some of the negative aspects of high-risk AI applications. This prompts a critical examination of the role and conditions necessary for what is prominently termed effective or meaningful human oversight of these systems. This paper investigates effective human oversight by synthesizing insights from psychological, legal, philosophical, and technical domains. Based on the claim that the main objective of human oversight is risk mitigation, we propose a viable understanding of effectiveness in human oversight: for human oversight to be effective, the human overseer has to have (a) sufficient causal power with regards to the system and its effects, (b) suitable epistemic access to relevant aspects of the situation, (c) self-control over their own actions, and (d) fitting intentions for their role. Furthermore, we argue that this is equivalent to saying that a human overseer is effective if and only if they are morally responsible and have fitting intentions. Against this backdrop, we suggest facilitators and inhibitors of effectiveness in human oversight when striving for practical applicability. We discuss factors in three domains, namely, the technical design of the system, individual factors of human overseers, and the environmental circumstances in which the overseer operates. Finally, this paper scrutinizes the upcoming AI Act of the European Union -- in particular Article 14 on Human Oversight -- as an exemplary regulatory framework in which we study the practicality of our understanding of effective human oversight. By analyzing the provisions and implications of the European AI Act proposal, we pinpoint in how far that proposal aligns with our analyses regarding effective human oversight as well as how it might get enriched by our conceptual understanding of effectiveness in human oversight.","sentences":["Human oversight is currently discussed as a potential safeguard to counter some of the negative aspects of high-risk AI applications.","This prompts a critical examination of the role and conditions necessary for what is prominently termed effective or meaningful human oversight of these systems.","This paper investigates effective human oversight by synthesizing insights from psychological, legal, philosophical, and technical domains.","Based on the claim that the main objective of human oversight is risk mitigation, we propose a viable understanding of effectiveness in human oversight: for human oversight to be effective, the human overseer has to have (a) sufficient causal power with regards to the system and its effects, (b) suitable epistemic access to relevant aspects of the situation, (c) self-control over their own actions, and (d) fitting intentions for their role.","Furthermore, we argue that this is equivalent to saying that a human overseer is effective if and only if they are morally responsible and have fitting intentions.","Against this backdrop, we suggest facilitators and inhibitors of effectiveness in human oversight when striving for practical applicability.","We discuss factors in three domains, namely, the technical design of the system, individual factors of human overseers, and the environmental circumstances in which the overseer operates.","Finally, this paper scrutinizes the upcoming AI Act of the European Union -- in particular Article 14 on Human Oversight -- as an exemplary regulatory framework in which we study the practicality of our understanding of effective human oversight.","By analyzing the provisions and implications of the European AI Act proposal, we pinpoint in how far that proposal aligns with our analyses regarding effective human oversight as well as how it might get enriched by our conceptual understanding of effectiveness in human oversight."],"url":"http://arxiv.org/abs/2404.04059v1","category":"cs.CY"}
{"created":"2024-04-05 12:12:38","title":"An Insight of Heart-Like Systems with Percolation","abstract":"We study the signal percolation through heart-like biological system. Starting from an initial distribution of Waiting and Inactive cells with probabilities $p$ and $(1-p)$ respectively the signal propagation is observed in terms of Active cells. As the signal enters the system from one end, the number of arrival of Active sites at the other end is studied and analysis of the system behaviour is made by varying a few important parameters of the system like $p_{switch}$ (switching probability from Inactive to Waiting) and $p_{act}$ (switching probability from Waiting to active). In this connection, the non-regular heart rhythms are discussed. Fraction of percolating paths through the system is studied and showed a transition from $0$ to $1$ near $p=p_c$. Some other important quantities like tortuosity and cluster distribution are discussed and corresponding exponents have been found.","sentences":["We study the signal percolation through heart-like biological system.","Starting from an initial distribution of Waiting and Inactive cells with probabilities $p$ and $(1-p)$ respectively the signal propagation is observed in terms of Active cells.","As the signal enters the system from one end, the number of arrival of Active sites at the other end is studied and analysis of the system behaviour is made by varying a few important parameters of the system like $p_{switch}$ (switching probability from Inactive to Waiting) and $p_{act}$ (switching probability from Waiting to active).","In this connection, the non-regular heart rhythms are discussed.","Fraction of percolating paths through the system is studied and showed a transition from $0$ to $1$ near $p=p_c$. Some other important quantities like tortuosity and cluster distribution are discussed and corresponding exponents have been found."],"url":"http://arxiv.org/abs/2404.04052v1","category":"cond-mat.stat-mech"}
{"created":"2024-04-05 11:59:52","title":"Constraining stellar tidal quality factors from planet-induced stellar spin-up","abstract":"The dynamical evolution of tight star-planet systems is influenced by tidal interactions between the star and the planet, as was shown recently. The rate at which spins and orbits in such a system evolve depends on the stellar and planetary tidal dissipation efficiency. Here, we present a method to constrain the modified tidal quality factor $Q'_*$ of a planet-hosting star whose rotational evolution has been altered by its planet through angular momentum transfer from the planetary orbital motion to the rotation of the stellar convective zone. The altered rotation is estimated from an observed discrepancy of magnetic activity of the planet-hosting star and a coeval companion star, i.e. this method is applicable to star-planet systems with wide stellar companions. We give an example of the planet-hosting wide binary system HD189733 and find that the planet host's modified tidal quality factor is constrained to be $Q'_* \\leq 2.33 \\times 10^7$.","sentences":["The dynamical evolution of tight star-planet systems is influenced by tidal interactions between the star and the planet, as was shown recently.","The rate at which spins and orbits in such a system evolve depends on the stellar and planetary tidal dissipation efficiency.","Here, we present a method to constrain the modified tidal quality factor $Q'_*$ of a planet-hosting star whose rotational evolution has been altered by its planet through angular momentum transfer from the planetary orbital motion to the rotation of the stellar convective zone.","The altered rotation is estimated from an observed discrepancy of magnetic activity of the planet-hosting star and a coeval companion star, i.e. this method is applicable to star-planet systems with wide stellar companions.","We give an example of the planet-hosting wide binary system HD189733 and find that the planet host's modified tidal quality factor is constrained to be $Q'_*","\\leq 2.33","\\times 10^7$."],"url":"http://arxiv.org/abs/2404.04047v1","category":"astro-ph.SR"}
{"created":"2024-04-05 11:49:48","title":"The Origin of Mutational Epistasis","abstract":"The interconnected processes of protein folding, mutations, epistasis, and evolution have all been the subject of extensive analysis throughout the years due to their significance for structural and evolutionary biology. The origin (molecular basis) of epistasis (the non-additive interactions between mutations) is still, nonetheless, unknown. The existence of a new perspective on protein folding (a problem that needs to be conceived as an analytic whole) will enable us to shed light on the origin of mutational epistasis at the simplest level (within proteins) while also uncovering the reasons on why the genetic background in which they occur (a key component of molecular evolution) could foster changes in epistasis effects. Additionally, because mutations are the source of epistasis, more research is needed to determine the impact of posttranslational modifications (which have the potential to increase the diversity of the proteome by several orders of magnitude) on both mutational epistasis and protein evolvability. Finally, a protein evolution thermodynamic-based analysis that does not consider specific mutational steps or epistasis effects will be discussed. Our study explores the complex processes behind the evolution of proteins upon mutations, clearing up some previously unresolved issues and providing direction for further research in this area.","sentences":["The interconnected processes of protein folding, mutations, epistasis, and evolution have all been the subject of extensive analysis throughout the years due to their significance for structural and evolutionary biology.","The origin (molecular basis) of epistasis (the non-additive interactions between mutations) is still, nonetheless, unknown.","The existence of a new perspective on protein folding (a problem that needs to be conceived as an analytic whole) will enable us to shed light on the origin of mutational epistasis at the simplest level (within proteins) while also uncovering the reasons on why the genetic background in which they occur (a key component of molecular evolution) could foster changes in epistasis effects.","Additionally, because mutations are the source of epistasis, more research is needed to determine the impact of posttranslational modifications (which have the potential to increase the diversity of the proteome by several orders of magnitude) on both mutational epistasis and protein evolvability.","Finally, a protein evolution thermodynamic-based analysis that does not consider specific mutational steps or epistasis effects will be discussed.","Our study explores the complex processes behind the evolution of proteins upon mutations, clearing up some previously unresolved issues and providing direction for further research in this area."],"url":"http://arxiv.org/abs/2404.04041v1","category":"q-bio.PE"}
{"created":"2024-04-05 11:49:28","title":"Reconstructing a pseudotree from the distance matrix of its boundary","abstract":"A vertex $v$ of a connected graph $G$ is said to be a boundary vertex of $G$ if for some other vertex $u$ of $G$, no neighbor of $v$ is further away from $u$ than $v$. The boundary $\\partial(G)$ of $G$ is the set of all of its boundary vertices. The distance matrix $\\hat{D}_G$ of the boundary of a graph $G$ is the square matrix of order $\\kappa$, being $\\kappa$ the order of $\\partial(G)$, such that for every $i,j\\in \\partial(G)$, $[\\hat{D}_G]_{ij}=d_G(i,j)$. Given a square matrix $\\hat{B}$ of order $\\kappa$, we prove under which conditions $\\hat{B}$ is the distance matrix $\\hat{D}_T$ of the set of leaves of a tree $T$, which is precisely its boundary. We show that if $G$ is either a tree or a unicyclic graph with girth $g\\geq 5$ vertices, then $G$ is uniquely determined by the distance matrix $\\hat{D}_{G}$ of the boundary of $G$ and we also conjecture that this statement holds for every connected graph. Moreover, two algorithms for reconstructing a tree and a unicyclic graph from the distance matrix of their boundaries are given, whose time complexities in the worst case are, respectively, $O(\\kappa n)$ and $O(n^2)$.","sentences":["A vertex $v$ of a connected graph $G$ is said to be a boundary vertex of $G$ if for some other vertex $u$ of $G$, no neighbor of $v$ is further away from $u$ than $v$. The boundary $\\partial(G)$ of $G$ is the set of all of its boundary vertices.","The distance matrix $\\hat{D}_G$ of the boundary of a graph $G$ is the square matrix of order $\\kappa$, being $\\kappa$ the order of $\\partial(G)$, such that for every $i,j\\in \\partial(G)$, $[\\hat{D}_G]_{ij}=d_G(i,j)$.","Given a square matrix $\\hat{B}$ of order $\\kappa$, we prove under which conditions $\\hat{B}$ is the distance matrix $\\hat{D}_T$ of the set of leaves of a tree $T$, which is precisely its boundary.","We show that if $G$ is either a tree or a unicyclic graph with girth $g\\geq 5$ vertices, then $G$ is uniquely determined by the distance matrix $\\hat{D}_{G}$ of the boundary of $G$ and we also conjecture that this statement holds for every connected graph.","Moreover, two algorithms for reconstructing a tree and a unicyclic graph from the distance matrix of their boundaries are given, whose time complexities in the worst case are, respectively, $O(\\kappa n)$ and $O(n^2)$."],"url":"http://arxiv.org/abs/2404.04039v1","category":"math.CO"}
{"created":"2024-04-05 11:19:35","title":"$\\mathbb R$- and $\\mathbb C$-supercyclicity for some classes of operators","abstract":"The concept of $\\mathbb C$-supercyclic operators was introduced by Hilden and Wallen in \\cite{hilden} and, since then, a multitude of variants have been studied. In \\cite{herzog1992linear}, Herzog proved that every real or complex, separable, infinite dimensional Banach space supports a $\\mathbb C$-supercyclic operator. In the present paper we investigate different variants of supercyclicity, precisely $\\mathbb R^+$-, $\\mathbb R$- and $\\mathbb C$-supercyclicity in the context of composition operators. We characterize $\\mathbb R$-supercyclic composition operators on $L^p$, $1 \\leq p < \\infty$. Then, we turn our attention to dissipative composition operators, and we show that $\\mathbb R$- and $\\mathbb C$-supercyclicity are equivalent notions in this setting and they have a ``shift-like'' characterization.","sentences":["The concept of $\\mathbb C$-supercyclic operators was introduced by Hilden and Wallen in \\cite{hilden} and, since then, a multitude of variants have been studied.","In \\cite{herzog1992linear}, Herzog proved that every real or complex, separable, infinite dimensional Banach space supports a $\\mathbb C$-supercyclic operator.","In the present paper we investigate different variants of supercyclicity, precisely $\\mathbb R^+$-, $\\mathbb R$- and $\\mathbb C$-supercyclicity in the context of composition operators.","We characterize $\\mathbb R$-supercyclic composition operators on $L^p$, $1 \\leq p < \\infty$.","Then, we turn our attention to dissipative composition operators, and we show that $\\mathbb R$- and $\\mathbb","C$-supercyclicity are equivalent notions in this setting and they have a ``shift-like'' characterization."],"url":"http://arxiv.org/abs/2404.04028v1","category":"math.DS"}
{"created":"2024-04-05 11:14:19","title":"MM-Gaussian: 3D Gaussian-based Multi-modal Fusion for Localization and Reconstruction in Unbounded Scenes","abstract":"Localization and mapping are critical tasks for various applications such as autonomous vehicles and robotics. The challenges posed by outdoor environments present particular complexities due to their unbounded characteristics. In this work, we present MM-Gaussian, a LiDAR-camera multi-modal fusion system for localization and mapping in unbounded scenes. Our approach is inspired by the recently developed 3D Gaussians, which demonstrate remarkable capabilities in achieving high rendering quality and fast rendering speed. Specifically, our system fully utilizes the geometric structure information provided by solid-state LiDAR to address the problem of inaccurate depth encountered when relying solely on visual solutions in unbounded, outdoor scenarios. Additionally, we utilize 3D Gaussian point clouds, with the assistance of pixel-level gradient descent, to fully exploit the color information in photos, thereby achieving realistic rendering effects. To further bolster the robustness of our system, we designed a relocalization module, which assists in returning to the correct trajectory in the event of a localization failure. Experiments conducted in multiple scenarios demonstrate the effectiveness of our method.","sentences":["Localization and mapping are critical tasks for various applications such as autonomous vehicles and robotics.","The challenges posed by outdoor environments present particular complexities due to their unbounded characteristics.","In this work, we present MM-Gaussian, a LiDAR-camera multi-modal fusion system for localization and mapping in unbounded scenes.","Our approach is inspired by the recently developed 3D Gaussians, which demonstrate remarkable capabilities in achieving high rendering quality and fast rendering speed.","Specifically, our system fully utilizes the geometric structure information provided by solid-state LiDAR to address the problem of inaccurate depth encountered when relying solely on visual solutions in unbounded, outdoor scenarios.","Additionally, we utilize 3D Gaussian point clouds, with the assistance of pixel-level gradient descent, to fully exploit the color information in photos, thereby achieving realistic rendering effects.","To further bolster the robustness of our system, we designed a relocalization module, which assists in returning to the correct trajectory in the event of a localization failure.","Experiments conducted in multiple scenarios demonstrate the effectiveness of our method."],"url":"http://arxiv.org/abs/2404.04026v1","category":"cs.RO"}
{"created":"2024-04-05 11:07:17","title":"Phase Binarization in Mutually Synchronized Bias Field-free Spin Hall Nano-oscillators for Reservoir Computing","abstract":"Mutually coupled spin Hall nano-oscillators (SHNO) can exhibit binarized phase state, offering pathways to realize Ising machines and efficient neuromorphic hardware. Conventionally, phase binarization is achieved in coupled SHNOs via injecting an external microwave at twice of the oscillator frequency in presence of a biasing magnetic field. However, this technology poses potential challenges of higher energy consumption and complex circuit design. Moreover, fabrication-induced mismatch in SHNO dimensions may hinder mutual synchronization. Addressing these challenges, we demonstrate purely DC current-driven mutual synchronization and phase binarization of two non-identical nanoconstriction SHNOs without biasing magnetic field and microwave injection. We thoroughly investigate these phenomena and underlying mechanisms using micromagnetic simulation. We further demonstrate the bias field-free synchronized SHNO pair efficiently performing a reservoir computing benchmark learning task: sin and square wave classification, utilizing current tunable phase binarization. Our results showcase promising magnetization dynamics of coupled bias field-free SHNOs for future computing applications.","sentences":["Mutually coupled spin Hall nano-oscillators (SHNO) can exhibit binarized phase state, offering pathways to realize Ising machines and efficient neuromorphic hardware.","Conventionally, phase binarization is achieved in coupled SHNOs via injecting an external microwave at twice of the oscillator frequency in presence of a biasing magnetic field.","However, this technology poses potential challenges of higher energy consumption and complex circuit design.","Moreover, fabrication-induced mismatch in SHNO dimensions may hinder mutual synchronization.","Addressing these challenges, we demonstrate purely DC current-driven mutual synchronization and phase binarization of two non-identical nanoconstriction SHNOs without biasing magnetic field and microwave injection.","We thoroughly investigate these phenomena and underlying mechanisms using micromagnetic simulation.","We further demonstrate the bias field-free synchronized SHNO pair efficiently performing a reservoir computing benchmark learning task: sin and square wave classification, utilizing current tunable phase binarization.","Our results showcase promising magnetization dynamics of coupled bias field-free SHNOs for future computing applications."],"url":"http://arxiv.org/abs/2404.04023v1","category":"cond-mat.mes-hall"}
{"created":"2024-04-05 11:06:07","title":"Good Books are Complex Matters: Gauging Complexity Profiles Across Diverse Categories of Perceived Literary Quality","abstract":"In this study, we employ a classification approach to show that different categories of literary \"quality\" display unique linguistic profiles, leveraging a corpus that encompasses titles from the Norton Anthology, Penguin Classics series, and the Open Syllabus project, contrasted against contemporary bestsellers, Nobel prize winners and recipients of prestigious literary awards. Our analysis reveals that canonical and so called high-brow texts exhibit distinct textual features when compared to other quality categories such as bestsellers and popular titles as well as to control groups, likely responding to distinct (but not mutually exclusive) models of quality. We apply a classic machine learning approach, namely Random Forest, to distinguish quality novels from \"control groups\", achieving up to 77\\% F1 scores in differentiating between the categories. We find that quality category tend to be easier to distinguish from control groups than from other quality categories, suggesting than literary quality features might be distinguishable but shared through quality proxies.","sentences":["In this study, we employ a classification approach to show that different categories of literary \"quality\" display unique linguistic profiles, leveraging a corpus that encompasses titles from the Norton Anthology, Penguin Classics series, and the Open Syllabus project, contrasted against contemporary bestsellers, Nobel prize winners and recipients of prestigious literary awards.","Our analysis reveals that canonical and so called high-brow texts exhibit distinct textual features when compared to other quality categories such as bestsellers and popular titles as well as to control groups, likely responding to distinct (but not mutually exclusive) models of quality.","We apply a classic machine learning approach, namely Random Forest, to distinguish quality novels from \"control groups\", achieving up to 77\\% F1 scores in differentiating between the categories.","We find that quality category tend to be easier to distinguish from control groups than from other quality categories, suggesting than literary quality features might be distinguishable but shared through quality proxies."],"url":"http://arxiv.org/abs/2404.04022v1","category":"cs.CL"}
{"created":"2024-04-05 11:02:02","title":"Superior Genetic Algorithms for the Target Set Selection Problem Based on Power-Law Parameter Choices and Simple Greedy Heuristics","abstract":"The target set selection problem (TSS) asks for a set of vertices such that an influence spreading process started in these vertices reaches the whole graph. The current state of the art for this NP-hard problem are three recently proposed randomized search heuristics, namely a biased random-key genetic algorithm (BRKGA) obtained from extensive parameter tuning, a max-min ant system (MMAS), and a MMAS using Q-learning with a graph convolutional network.   We show that the BRKGA with two simple modifications and without the costly parameter tuning obtains significantly better results. Our first modification is to simply choose all parameters of the BRKGA in each iteration randomly from a power-law distribution. The resulting parameterless BRKGA is already competitive with the tuned BRKGA, as our experiments on the previously used benchmarks show.   We then add a natural greedy heuristic, namely to repeatedly discard small-degree vertices that are not necessary for reaching the whole graph. The resulting algorithm consistently outperforms all of the state-of-the-art algorithms.   Besides providing a superior algorithm for the TSS problem, this work shows that randomized parameter choices and elementary greedy heuristics can give better results than complex algorithms and costly parameter tuning.","sentences":["The target set selection problem (TSS) asks for a set of vertices such that an influence spreading process started in these vertices reaches the whole graph.","The current state of the art for this NP-hard problem are three recently proposed randomized search heuristics, namely a biased random-key genetic algorithm (BRKGA) obtained from extensive parameter tuning, a max-min ant system (MMAS), and a MMAS using Q-learning with a graph convolutional network.   ","We show that the BRKGA with two simple modifications and without the costly parameter tuning obtains significantly better results.","Our first modification is to simply choose all parameters of the BRKGA in each iteration randomly from a power-law distribution.","The resulting parameterless BRKGA is already competitive with the tuned BRKGA, as our experiments on the previously used benchmarks show.   ","We then add a natural greedy heuristic, namely to repeatedly discard small-degree vertices that are not necessary for reaching the whole graph.","The resulting algorithm consistently outperforms all of the state-of-the-art algorithms.   ","Besides providing a superior algorithm for the TSS problem, this work shows that randomized parameter choices and elementary greedy heuristics can give better results than complex algorithms and costly parameter tuning."],"url":"http://arxiv.org/abs/2404.04018v1","category":"cs.NE"}
{"created":"2024-04-05 10:35:53","title":"Two bifurcation sets of expansive Lorenz maps with a hole at the critical point","abstract":"Let $f$ be an expansive Lorenz map on $[0,1]$ and $c$ be the critical point. The survivor set we are discussing here is denoted as $S^+_{f}(a,b):=\\{x\\in[0,1]:f(b)\\leq f^{n}(x) \\leq f(a)\\ \\forall n\\geq0\\}$, where the hole $(a,b)\\subseteq [0,1]$ satisfies $a\\leq c \\leq b$ and $a\\neq b$. Let $a\\in[0,c]$ be fixed, we mainly focus on the following two bifurcation sets: $$ E_{f}(a):=\\{b\\in[c,1]:S^{+}_{f}(a,\\epsilon)\\neq S^{+}_{f}(a,b) \\ \\forall \\ \\epsilon>b\\}, \\ \\ {\\rm and} $$ $$ B_{f}(a):=\\{b\\in[c,1]:h_{top}(S^+_{f}(a,\\epsilon))\\neq h_{top}(S^+_{f}(a,b)) \\ \\forall \\ \\epsilon>b\\}. $$   By combinatorial renormalization tools, we give a complete characterization of the maximal plateau $P(b)$ such that for all $\\epsilon\\in P(b)$, $h_{top}(S^+_{f}(a,\\epsilon))=h_{top}(S^+_{f}(a,b))$. Moreover, we obtain a sufficient and necessary condition for $E_{f}(a)=B_{f}(a)$, which partially extends the results in \\cite{allaart2023} and \\cite{baker2020}.","sentences":["Let $f$ be an expansive Lorenz map on $[0,1]$ and $c$ be the critical point.","The survivor set we are discussing here is denoted as $S^+_{f}(a,b):=\\{x\\in[0,1]:f(b)\\leq f^{n}(x) \\leq f(a)\\ \\forall n\\geq0\\}$, where the hole $(a,b)\\subseteq","[0,1]$ satisfies $a\\leq c \\leq b$ and $a\\neq b$. Let $a\\in[0,c]$ be fixed, we mainly focus on the following two bifurcation sets: $$ E_{f}(a):=\\{b\\in[c,1]:S^{+}_{f}(a,\\epsilon)\\neq S^{+}_{f}(a,b) \\","\\forall \\ \\epsilon>b\\}, \\ \\ {\\rm and} $$ $$ B_{f}(a):=\\{b\\in[c,1]:h_{top}(S^+_{f}(a,\\epsilon))\\neq h_{top}(S^+_{f}(a,b))","\\","\\forall \\ \\epsilon>b\\}.","$$   By combinatorial renormalization tools, we give a complete characterization of the maximal plateau $P(b)$ such that for all $\\epsilon\\in P(b)$, $h_{top}(S^+_{f}(a,\\epsilon))=h_{top}(S^+_{f}(a,b))$.","Moreover, we obtain a sufficient and necessary condition for $E_{f}(a)=B_{f}(a)$, which partially extends the results in \\cite{allaart2023} and \\cite{baker2020}."],"url":"http://arxiv.org/abs/2404.04008v1","category":"math.DS"}
{"created":"2024-04-05 10:28:21","title":"The statistical mechanics and machine learning of the $\u03b1$-R\u00e9nyi ensemble","abstract":"We study the statistical physics of the classical Ising model in the so-called $\\alpha$-R\\'enyi ensemble, a finite-temperature thermal state approximation that minimizes a modified free energy based on the $\\alpha$-R\\'enyi entropy. We begin by characterizing its critical behavior in mean-field theory in different regimes of the R\\'enyi index $\\alpha$. Next, we re-introduce correlations and consider the model in one and two dimensions, presenting an exact analysis of the former and devising an unconventional Monte Carlo approach to the study of the latter. Remarkably, we find that while mean-field predicts a continuous phase transition below a threshold index value of $\\alpha \\sim 1.303$ and a first-order transition above it, the Monte Carlo results in two dimensions point to a continuous transition at all $\\alpha$. We conclude by performing a variational minimization of the $\\alpha$-R\\'enyi free energy using a recurrent neural network (RNN) ansatz where we find that the RNN performs well in two dimensions when compared to the Monte Carlo simulations. Our work highlights the potential opportunities and limitations associated with the use of the $\\alpha$-R\\'enyi ensemble formalism in probing the thermodynamic equilibrium properties of classical and quantum systems.","sentences":["We study the statistical physics of the classical Ising model in the so-called $\\alpha$-R\\'enyi ensemble, a finite-temperature thermal state approximation that minimizes a modified free energy based on the $\\alpha$-R\\'enyi entropy.","We begin by characterizing its critical behavior in mean-field theory in different regimes of the R\\'enyi index $\\alpha$. Next, we re-introduce correlations and consider the model in one and two dimensions, presenting an exact analysis of the former and devising an unconventional Monte Carlo approach to the study of the latter.","Remarkably, we find that while mean-field predicts a continuous phase transition below a threshold index value of $\\alpha \\sim 1.303$ and a first-order transition above it, the Monte Carlo results in two dimensions point to a continuous transition at all $\\alpha$. We conclude by performing a variational minimization of the $\\alpha$-R\\'enyi free energy using a recurrent neural network (RNN) ansatz where we find that the RNN performs well in two dimensions when compared to the Monte Carlo simulations.","Our work highlights the potential opportunities and limitations associated with the use of the $\\alpha$-R\\'enyi ensemble formalism in probing the thermodynamic equilibrium properties of classical and quantum systems."],"url":"http://arxiv.org/abs/2404.04005v1","category":"cond-mat.stat-mech"}
{"created":"2024-04-05 10:25:40","title":"Continual Learning with Weight Interpolation","abstract":"Continual learning poses a fundamental challenge for modern machine learning systems, requiring models to adapt to new tasks while retaining knowledge from previous ones. Addressing this challenge necessitates the development of efficient algorithms capable of learning from data streams and accumulating knowledge over time. This paper proposes a novel approach to continual learning utilizing the weight consolidation method. Our method, a simple yet powerful technique, enhances robustness against catastrophic forgetting by interpolating between old and new model weights after each novel task, effectively merging two models to facilitate exploration of local minima emerging after arrival of new concepts. Moreover, we demonstrate that our approach can complement existing rehearsal-based replay approaches, improving their accuracy and further mitigating the forgetting phenomenon. Additionally, our method provides an intuitive mechanism for controlling the stability-plasticity trade-off. Experimental results showcase the significant performance enhancement to state-of-the-art experience replay algorithms the proposed weight consolidation approach offers. Our algorithm can be downloaded from https://github.com/jedrzejkozal/weight-interpolation-cl.","sentences":["Continual learning poses a fundamental challenge for modern machine learning systems, requiring models to adapt to new tasks while retaining knowledge from previous ones.","Addressing this challenge necessitates the development of efficient algorithms capable of learning from data streams and accumulating knowledge over time.","This paper proposes a novel approach to continual learning utilizing the weight consolidation method.","Our method, a simple yet powerful technique, enhances robustness against catastrophic forgetting by interpolating between old and new model weights after each novel task, effectively merging two models to facilitate exploration of local minima emerging after arrival of new concepts.","Moreover, we demonstrate that our approach can complement existing rehearsal-based replay approaches, improving their accuracy and further mitigating the forgetting phenomenon.","Additionally, our method provides an intuitive mechanism for controlling the stability-plasticity trade-off.","Experimental results showcase the significant performance enhancement to state-of-the-art experience replay algorithms the proposed weight consolidation approach offers.","Our algorithm can be downloaded from https://github.com/jedrzejkozal/weight-interpolation-cl."],"url":"http://arxiv.org/abs/2404.04002v1","category":"cs.LG"}
{"created":"2024-04-05 10:04:21","title":"Algebraic localization-delocalization phase transition in moving potential wells on a lattice","abstract":"The localization and scattering properties of potential wells or barriers uniformly moving on a lattice are strongly dependent on the drift velocity owing to violation of the Galilean invariance of the discrete Schr\\\"odinger equation. Here a type of localization-delocalization phase transition of algebraic type is unravelled, which does not require any kind of disorder and arises when a power-law potential well drifts fast on a lattice. While for an algebraic exponent $\\alpha$ lower than the critical value $\\alpha_c=1$ dynamical delocalization is observed, for $\\alpha> \\alpha_c$ asymptotic localization, corresponding to an asymptotic frozen dynamics, is instead realized. At the critical phase transition point $\\alpha_=\\alpha_c=1$ an oscillatory dynamics is found, corresponding to Bloch oscillations. An experimentally-accessible photonic platform for the observation of the predicted algebraic phase transition, based on light dynamics in synthetic mesh lattices, is suggested.","sentences":["The localization and scattering properties of potential wells or barriers uniformly moving on a lattice are strongly dependent on the drift velocity owing to violation of the Galilean invariance of the discrete Schr\\\"odinger equation.","Here a type of localization-delocalization phase transition of algebraic type is unravelled, which does not require any kind of disorder and arises when a power-law potential well drifts fast on a lattice.","While for an algebraic exponent $\\alpha$ lower than the critical value $\\alpha_c=1$ dynamical delocalization is observed, for $\\alpha> \\alpha_c$ asymptotic localization, corresponding to an asymptotic frozen dynamics, is instead realized.","At the critical phase transition point $\\alpha_=\\alpha_c=1$ an oscillatory dynamics is found, corresponding to Bloch oscillations.","An experimentally-accessible photonic platform for the observation of the predicted algebraic phase transition, based on light dynamics in synthetic mesh lattices, is suggested."],"url":"http://arxiv.org/abs/2404.03993v1","category":"cond-mat.dis-nn"}
{"created":"2024-04-05 09:56:13","title":"A Bound Preserving Energy Stable Scheme for a Nonlocal Cahn-Hilliard Equation","abstract":"We present a finite-volume based numerical scheme for a nonlocal Cahn-Hilliard equation which combines ideas from recent numerical schemes for gradient flow equations and nonlocal Cahn-Hilliard equations. The equation of interest is a special case of a previously derived and studied system of equations which describes phase separation in ternary mixtures. We prove the scheme is both energy stable and respects the analytical bounds of the solution. Furthermore, we present numerical demonstrations of the theoretical results using both the Flory-Huggins (FH) and Ginzburg-Landau (GL) free-energy potentials.","sentences":["We present a finite-volume based numerical scheme for a nonlocal Cahn-Hilliard equation which combines ideas from recent numerical schemes for gradient flow equations and nonlocal Cahn-Hilliard equations.","The equation of interest is a special case of a previously derived and studied system of equations which describes phase separation in ternary mixtures.","We prove the scheme is both energy stable and respects the analytical bounds of the solution.","Furthermore, we present numerical demonstrations of the theoretical results using both the Flory-Huggins (FH) and Ginzburg-Landau (GL) free-energy potentials."],"url":"http://arxiv.org/abs/2404.03990v1","category":"math.NA"}
{"created":"2024-04-05 09:46:15","title":"Effect on spectral purity due to on-chip temporal manipulation of the pump","abstract":"Photonic Integrated Circuits (PIC)s are a promising contender for quantum information technologies. The spectral purity of photons is one of the key attributes of PIC photon-pair sources. The dual-pulse pump manipulation technique [1] showed >99% purity in ring-resonator photon-pair sources. Here, we have developed a PIC to shape a pulse into dual, triple and quadruple pulses and investigated the effect of these pump pulse configurations on the purity. Our results show that more complex configurations over dual-pulse do not result in comparatively higher purity but allow accurate control over choosing arbitrary values of the purity.","sentences":["Photonic Integrated Circuits (PIC)s are a promising contender for quantum information technologies.","The spectral purity of photons is one of the key attributes of PIC photon-pair sources.","The dual-pulse pump manipulation technique [1] showed >99% purity in ring-resonator photon-pair sources.","Here, we have developed a PIC to shape a pulse into dual, triple and quadruple pulses and investigated the effect of these pump pulse configurations on the purity.","Our results show that more complex configurations over dual-pulse do not result in comparatively higher purity but allow accurate control over choosing arbitrary values of the purity."],"url":"http://arxiv.org/abs/2404.03986v1","category":"quant-ph"}
{"created":"2024-04-05 09:22:17","title":"Phenomenology of a Rydberg impurity in an ideal Bose Einstein condensate","abstract":"We investigate the absorption spectrum of a Rydberg impurity immersed in and interacting with an ideal Bose-Einstein condensate. Here, the impurity-bath interaction can greatly exceed the mean interparticle distance; this discrepancy in length scales challenges the assumptions underlying the universal aspects of impurity atoms in dilute bosonic environments. Our analysis finds three distinct parameter regimes, each characterized by a unique spectral response. In the low-density regime, we find that the Rydberg impurity is dressed by the surrounding bath similarly to the known Bose polaron. Transitioning to intermediate densities, the impurity response, given by sharp quasiparticle peaks, fragments into an intricate pattern bearing the hallmarks of a diverse molecular structure. Finally, at high density, a universal Gaussian response emerges as the statistical nature of the bath dominates its quantum dynamics. We complement this analysis with a study of an ionic impurity, which behaves equivalently. Our exploration offers insights into the interplay between interaction range, density, and many-body behavior in impurity systems.","sentences":["We investigate the absorption spectrum of a Rydberg impurity immersed in and interacting with an ideal Bose-Einstein condensate.","Here, the impurity-bath interaction can greatly exceed the mean interparticle distance; this discrepancy in length scales challenges the assumptions underlying the universal aspects of impurity atoms in dilute bosonic environments.","Our analysis finds three distinct parameter regimes, each characterized by a unique spectral response.","In the low-density regime, we find that the Rydberg impurity is dressed by the surrounding bath similarly to the known Bose polaron.","Transitioning to intermediate densities, the impurity response, given by sharp quasiparticle peaks, fragments into an intricate pattern bearing the hallmarks of a diverse molecular structure.","Finally, at high density, a universal Gaussian response emerges as the statistical nature of the bath dominates its quantum dynamics.","We complement this analysis with a study of an ionic impurity, which behaves equivalently.","Our exploration offers insights into the interplay between interaction range, density, and many-body behavior in impurity systems."],"url":"http://arxiv.org/abs/2404.03980v1","category":"cond-mat.quant-gas"}
{"created":"2024-04-05 09:14:06","title":"EC 19529-4430: SALT identifies the most carbon- and metal-poor extreme helium star","abstract":"EC 19529-4430 was identified as a helium-rich star in the Edinburgh-Cape Survey of faint-blue objects and subsequently resolved as a metal-poor extreme helium (EHe) star in the SALT survey of chemically-peculiar hot subdwarfs. This paper presents a fine analysis of the SALT high-resolution spectrum. EC 19529-4430 has $T_{\\rm eff} = 20\\,700 \\pm250$\\,K, $\\log g /{\\rm cm\\,s^{-2}} = 3.49\\pm0.03$, and an overall metallicity some 1.3 dex below solar; surface hydrogen is $\\approx 0.5\\%$ by number. The surface CNO ratio 1:100:8 implies that the surface consists principally of CNO-processed helium and makes EC 19529-4430 the coolest known carbon-poor and nitrogen-rich EHe star. Metal-rich analogues include V652 Her and GALEX J184559.8-413827. Kinematically, its retrograde orbit indicates membership of the galactic halo. No pulsations were detected in TESS photometry and there is no evidence for a binary companion. EC 19529-4430 most likely formed from the merging of two helium white dwarfs, which themselves formed as a binary system some 11 Gyr ago.","sentences":["EC 19529-4430 was identified as a helium-rich star in the Edinburgh-Cape Survey of faint-blue objects and subsequently resolved as a metal-poor extreme helium (EHe) star in the SALT survey of chemically-peculiar hot subdwarfs.","This paper presents a fine analysis of the SALT high-resolution spectrum.","EC 19529-4430 has $T_{\\rm eff} = 20\\,700 \\pm250$\\,K, $\\log g /{\\rm cm\\,s^{-2}} = 3.49\\pm0.03$, and an overall metallicity some 1.3 dex below solar; surface hydrogen is $\\approx 0.5\\%$ by number.","The surface CNO ratio 1:100:8 implies that the surface consists principally of CNO-processed helium and makes EC 19529-4430 the coolest known carbon-poor and nitrogen-rich EHe star.","Metal-rich analogues include V652 Her and GALEX J184559.8-413827.","Kinematically, its retrograde orbit indicates membership of the galactic halo.","No pulsations were detected in TESS photometry and there is no evidence for a binary companion.","EC 19529-4430 most likely formed from the merging of two helium white dwarfs, which themselves formed as a binary system some 11 Gyr ago."],"url":"http://arxiv.org/abs/2404.03972v1","category":"astro-ph.SR"}
{"created":"2024-04-05 09:01:24","title":"Tensions between Preference and Performance: Designing for Visual Exploration of Multi-frequency Medical Network Data","abstract":"The analysis of complex high-dimensional data is a common task in many domains, resulting in bespoke visual exploration tools. Expectations and practices of domain experts as users do not always align with visualization theory. In this paper, we report on a design study in the medical domain where we developed two high-fidelity prototypes encoding EEG-derived brain network data with different types of visualizations. We evaluate these prototypes regarding effectiveness, efficiency, and preference with two groups: participants with domain knowledge (domain experts in medical research) and those without domain knowledge, both groups having little or no visualization experience. A requirement analysis and study of low-fidelity prototypes revealed a strong preference for a novel and aesthetically pleasing visualization design, as opposed to a design that is considered more optimal based on visualization theory. Our study highlights the pros and cons of both approaches, discussing trade-offs between task-specific measurements and subjective preference. While the aesthetically pleasing and novel low-fidelity prototype was favored, the results of our evaluation show that, in most cases, this was not reflected in participants' performance or subjective preference for the high-fidelity prototypes.","sentences":["The analysis of complex high-dimensional data is a common task in many domains, resulting in bespoke visual exploration tools.","Expectations and practices of domain experts as users do not always align with visualization theory.","In this paper, we report on a design study in the medical domain where we developed two high-fidelity prototypes encoding EEG-derived brain network data with different types of visualizations.","We evaluate these prototypes regarding effectiveness, efficiency, and preference with two groups: participants with domain knowledge (domain experts in medical research) and those without domain knowledge, both groups having little or no visualization experience.","A requirement analysis and study of low-fidelity prototypes revealed a strong preference for a novel and aesthetically pleasing visualization design, as opposed to a design that is considered more optimal based on visualization theory.","Our study highlights the pros and cons of both approaches, discussing trade-offs between task-specific measurements and subjective preference.","While the aesthetically pleasing and novel low-fidelity prototype was favored, the results of our evaluation show that, in most cases, this was not reflected in participants' performance or subjective preference for the high-fidelity prototypes."],"url":"http://arxiv.org/abs/2404.03965v1","category":"cs.HC"}
{"created":"2024-04-05 08:49:57","title":"Flavor and Fluctuations","abstract":"The Parisi-Sourlas approach to supersymmetry implies that, in spacetime dimensions greater than 1, there is a constraint on the minimal number of flavors, in order for a field theory to define a closed system. In particular, this number is greater than 1. This does not preclude that supersymmetry can be broken, however, and the known ways of breaking supersymmetry can be taken into account from this point of view, by using the so-called Nicolai map. This procedure is well-defined for abelian gauge theories and corresponds to the construction of the so-called trivializing maps for non-abelian gauge theories, that is, still, work in progress.","sentences":["The Parisi-Sourlas approach to supersymmetry implies that, in spacetime dimensions greater than 1, there is a constraint on the minimal number of flavors, in order for a field theory to define a closed system.","In particular, this number is greater than 1.","This does not preclude that supersymmetry can be broken, however, and the known ways of breaking supersymmetry can be taken into account from this point of view, by using the so-called Nicolai map.","This procedure is well-defined for abelian gauge theories and corresponds to the construction of the so-called trivializing maps for non-abelian gauge theories, that is, still, work in progress."],"url":"http://arxiv.org/abs/2404.03959v1","category":"hep-th"}
{"created":"2024-04-05 08:46:01","title":"Vulnerabilities of quantum key distribution systems in visible range","abstract":"Spectral loopholes in the 1000-2100 nm range have been the focus of attention of quantum hacking research aimed at searching and elimination of vulnerabilities in quantum key distribution systems. In this work, we concentrate on shorter wavelengths ranged from 400 nm up to 800 nm and experimentally study spectra of insertion losses for a number of fiber optical components to assess potentials for their implementation as countermeasures. We show that efficiency of the elements commonly used as countermeasures against hacking attacks in the telecom range can be significantly impaired in the visible range. It is found that the vulnerabilities detected in this range play an increasingly important role for hacking strategies such as the induced-photorefraction attack whose efficiency improves when the wavelength decreases.","sentences":["Spectral loopholes in the 1000-2100 nm range have been the focus of attention of quantum hacking research aimed at searching and elimination of vulnerabilities in quantum key distribution systems.","In this work, we concentrate on shorter wavelengths ranged from 400 nm up to 800 nm and experimentally study spectra of insertion losses for a number of fiber optical components to assess potentials for their implementation as countermeasures.","We show that efficiency of the elements commonly used as countermeasures against hacking attacks in the telecom range can be significantly impaired in the visible range.","It is found that the vulnerabilities detected in this range play an increasingly important role for hacking strategies such as the induced-photorefraction attack whose efficiency improves when the wavelength decreases."],"url":"http://arxiv.org/abs/2404.03956v1","category":"quant-ph"}
{"created":"2024-04-05 08:23:28","title":"Distributed Optimization for Energy Grids: A Tutorial on ADMM and ALADIN","abstract":"The ongoing transition towards energy and power systems dominated by a large number of renewable power injections to the distribution grid poses substantial challenges for system operation, coordination, and control. Optimization-based methods for coordination and control are of substantial research interest in this context. Hence, this chapter provides a tutorial introduction of distributed optimization algorithms for energy systems with a large share of renewables. Specifically, we focus on the Alternating Direction Method of Multipliers (ADMM) and on the Augmented Lagrangian Alternating Direction Inexact Newton (ALADIN) method as both algorithms are frequently considered for coordination and control of power and energy systems. We discuss the application of ALADIN and ADMM to AC optimal power flow problems and to energy management problems. Moreover, we give an outlook on open problems.","sentences":["The ongoing transition towards energy and power systems dominated by a large number of renewable power injections to the distribution grid poses substantial challenges for system operation, coordination, and control.","Optimization-based methods for coordination and control are of substantial research interest in this context.","Hence, this chapter provides a tutorial introduction of distributed optimization algorithms for energy systems with a large share of renewables.","Specifically, we focus on the Alternating Direction Method of Multipliers (ADMM) and on the Augmented Lagrangian Alternating Direction Inexact Newton (ALADIN) method as both algorithms are frequently considered for coordination and control of power and energy systems.","We discuss the application of ALADIN and ADMM to AC optimal power flow problems and to energy management problems.","Moreover, we give an outlook on open problems."],"url":"http://arxiv.org/abs/2404.03946v1","category":"math.OC"}
{"created":"2024-04-05 17:41:59","title":"Modeling Kinematic Uncertainty of Tendon-Driven Continuum Robots via Mixture Density Networks","abstract":"Tendon-driven continuum robot kinematic models are frequently computationally expensive, inaccurate due to unmodeled effects, or both. In particular, unmodeled effects produce uncertainties that arise during the robot's operation that lead to variability in the resulting geometry. We propose a novel solution to these issues through the development of a Gaussian mixture kinematic model. We train a mixture density network to output a Gaussian mixture model representation of the robot geometry given the current tendon displacements. This model computes a probability distribution that is more representative of the true distribution of geometries at a given configuration than a model that outputs a single geometry, while also reducing the computation time. We demonstrate one use of this model through a trajectory optimization method that explicitly reasons about the workspace uncertainty to minimize the probability of collision.","sentences":["Tendon-driven continuum robot kinematic models are frequently computationally expensive, inaccurate due to unmodeled effects, or both.","In particular, unmodeled effects produce uncertainties that arise during the robot's operation that lead to variability in the resulting geometry.","We propose a novel solution to these issues through the development of a Gaussian mixture kinematic model.","We train a mixture density network to output a Gaussian mixture model representation of the robot geometry given the current tendon displacements.","This model computes a probability distribution that is more representative of the true distribution of geometries at a given configuration than a model that outputs a single geometry, while also reducing the computation time.","We demonstrate one use of this model through a trajectory optimization method that explicitly reasons about the workspace uncertainty to minimize the probability of collision."],"url":"http://arxiv.org/abs/2404.04241v1","category":"cs.RO"}
{"created":"2024-04-05 17:20:05","title":"{\\sc SimBIG}: Cosmological Constraints using Simulation-Based Inference of Galaxy Clustering with Marked Power Spectra","abstract":"We present the first $\\Lambda$CDM cosmological analysis performed on a galaxy survey using marked power spectra. The marked power spectrum is the two-point function of a marked field, where galaxies are weighted by a function that depends on their local density. The presence of the mark leads these statistics to contain higher-order information of the original galaxy field, making them a good candidate to exploit the non-Gaussian information of a galaxy catalog. In this work we make use of \\simbig, a forward modeling framework for galaxy clustering analyses, and perform simulation-based inference using normalizing flows to infer the posterior distribution of the $\\Lambda$CDM cosmological parameters. We consider different mark configurations (ways to weight the galaxy field) and deploy them in the \\simbig~pipeline to analyze the corresponding marked power spectra measured from a subset of the BOSS galaxy sample. We analyze the redshift-space mark power spectra decomposed in $\\ell = 0, 2, 4$ multipoles and include scales up to the non-linear regime. Among the various mark configurations considered, the ones that give the most stringent cosmological constraints produce posterior median and $68\\%$ confidence limits on the growth of structure parameters equal to $\\Omega_m=0.273^{+0.040}_{-0.030}$ and $\\sigma_8=0.777^{+0.077}_{-0.071}$. Compared to a perturbation theory analysis using the power spectrum of the same dataset, the \\simbig~marked power spectra constraints on $\\sigma_8$ are up to $1.2\\times$ tighter, while no improvement is seen for the other cosmological parameters.","sentences":["We present the first $\\Lambda$CDM cosmological analysis performed on a galaxy survey using marked power spectra.","The marked power spectrum is the two-point function of a marked field, where galaxies are weighted by a function that depends on their local density.","The presence of the mark leads these statistics to contain higher-order information of the original galaxy field, making them a good candidate to exploit the non-Gaussian information of a galaxy catalog.","In this work we make use of \\simbig, a forward modeling framework for galaxy clustering analyses, and perform simulation-based inference using normalizing flows to infer the posterior distribution of the $\\Lambda$CDM cosmological parameters.","We consider different mark configurations (ways to weight the galaxy field) and deploy them in the \\simbig~pipeline to analyze the corresponding marked power spectra measured from a subset of the BOSS galaxy sample.","We analyze the redshift-space mark power spectra decomposed in $\\ell = 0, 2, 4$ multipoles and include scales up to the non-linear regime.","Among the various mark configurations considered, the ones that give the most stringent cosmological constraints produce posterior median and $68\\%$ confidence limits on the growth of structure parameters equal to $\\Omega_m=0.273^{+0.040}_{-0.030}$ and $\\sigma_8=0.777^{+0.077}_{-0.071}$. Compared to a perturbation theory analysis using the power spectrum of the same dataset, the \\simbig~marked power spectra constraints on $\\sigma_8$ are up to $1.2\\times$ tighter, while no improvement is seen for the other cosmological parameters."],"url":"http://arxiv.org/abs/2404.04228v1","category":"astro-ph.CO"}
{"created":"2024-04-05 17:15:34","title":"Early evolution of spin direction in dark matter halos and the effect of the surrounding large-scale tidal field","abstract":"It is usually assumed that the angular momentum (AM) of dark matter halos arises during the linear stages of structure formation, as a consequence of the coupling between the proto-haloes' shape and the tidal field produced by their surrounding density perturbations. This approach, known as linear tidal torque theory (TTT), has been shown to make fairly good predictions about the mean evolution of both the AM amplitude and orientation up to approximately the time when the proto-haloes collapse. After this point, proto-haloes are increasingly affected by non-linear processes that are not taken into account by the model. However, it has been seen in numerical simulations that, even at very early stages, the AM of proto-haloes is systematically reoriented towards perpendicularity with respect to the forming cosmic filaments, in contradiction with the fixed direction expected from the TTT. In this work we present a novel analytical approach that introduces an anisotropic scaling factor to the standard TTT equations, which allows the AM orientation to change in time, even during the linear regime. The amplitude and direction of this shift depend on the large scale tidal field around the forming proto-haloes. Our results significantly improve the predictions for the AM direction up to the time of protohalo collapse and, in some cases, even further in time.","sentences":["It is usually assumed that the angular momentum (AM) of dark matter halos arises during the linear stages of structure formation, as a consequence of the coupling between the proto-haloes' shape and the tidal field produced by their surrounding density perturbations.","This approach, known as linear tidal torque theory (TTT), has been shown to make fairly good predictions about the mean evolution of both the AM amplitude and orientation up to approximately the time when the proto-haloes collapse.","After this point, proto-haloes are increasingly affected by non-linear processes that are not taken into account by the model.","However, it has been seen in numerical simulations that, even at very early stages, the AM of proto-haloes is systematically reoriented towards perpendicularity with respect to the forming cosmic filaments, in contradiction with the fixed direction expected from the TTT.","In this work we present a novel analytical approach that introduces an anisotropic scaling factor to the standard TTT equations, which allows the AM orientation to change in time, even during the linear regime.","The amplitude and direction of this shift depend on the large scale tidal field around the forming proto-haloes.","Our results significantly improve the predictions for the AM direction up to the time of protohalo collapse and, in some cases, even further in time."],"url":"http://arxiv.org/abs/2404.04223v1","category":"astro-ph.CO"}
{"created":"2024-04-05 16:43:41","title":"Modelling handball outcomes using univariate and bivariate approaches","abstract":"Handball has received growing interest during the last years, including academic research for many different aspects of the sport. On the other hand modelling the outcome of the game has attracted less interest mainly because of the additional challenges that occur. Data analysis has revealed that the number of goals scored by each team are under-dispersed relative to a Poisson distribution and hence new models are needed for this purpose. Here we propose to circumvent the problem by modelling the score difference. This removes the need for special models since typical models for integer data like the Skellam distribution can provide sufficient fit and thus reveal some of the characteristics of the game. In the present paper we propose some models starting from a Skellam regression model and also considering zero inflated versions as well as other discrete distributions in $\\mathbb Z$. Furthermore, we develop some bivariate models using copulas to model the two halves of the game and thus providing insights on the game. Data from German Bundesliga are used to show the potential of the new models.","sentences":["Handball has received growing interest during the last years, including academic research for many different aspects of the sport.","On the other hand modelling the outcome of the game has attracted less interest mainly because of the additional challenges that occur.","Data analysis has revealed that the number of goals scored by each team are under-dispersed relative to a Poisson distribution and hence new models are needed for this purpose.","Here we propose to circumvent the problem by modelling the score difference.","This removes the need for special models since typical models for integer data like the Skellam distribution can provide sufficient fit and thus reveal some of the characteristics of the game.","In the present paper we propose some models starting from a Skellam regression model and also considering zero inflated versions as well as other discrete distributions in $\\mathbb Z$.","Furthermore, we develop some bivariate models using copulas to model the two halves of the game and thus providing insights on the game.","Data from German Bundesliga are used to show the potential of the new models."],"url":"http://arxiv.org/abs/2404.04213v1","category":"stat.ME"}
{"created":"2024-04-05 16:32:50","title":"Nanometer thick magneto-optical iron garnet films","abstract":"Here we demonstrate nanometer thick iron garnet films suitable for the magneto-optical applica-tions. Bismuth-substituted iron garnet films of compositions Bi{_1}Y{_2}Fe{_5}O{_{12}} and Bi{_1}Tm{_2}Fe{_5}O{_{12}} deposited on gadolinium gallium garnet substrate are fabricated and characterized. Their thicknesses range from 2 to 10 nm, which corresponds to just a few crystal lattice constants. Faraday rotation of the nanofilms reaches 29.7 deg/{\\mu}m at 420 nm which is comparable and even a bit better than single crystal micrometer thick films of similar composition. The film surface morphology by atomic force microscopy gives root mean square (RMS) roughness of the nanofilms as small as 0.13 nm that is also similar to the RMS of single crystal micrometer thick films. The Bi{_1}Tm{_2}Fe{_5}O{_{12}} films demonstrate effective uniaxial anisotropy. These all make the fabricated nanofilms very promising for their po-tential applications in magneto-optical devices and quantum technologies.","sentences":["Here we demonstrate nanometer thick iron garnet films suitable for the magneto-optical applica-tions.","Bismuth-substituted iron garnet films of compositions Bi{_1}Y{_2}Fe{_5}O{_{12}} and Bi{_1}Tm{_2}Fe{_5}O{_{12}} deposited on gadolinium gallium garnet substrate are fabricated and characterized.","Their thicknesses range from 2 to 10 nm, which corresponds to just a few crystal lattice constants.","Faraday rotation of the nanofilms reaches 29.7 deg/{\\mu}m at 420 nm which is comparable and even a bit better than single crystal micrometer thick films of similar composition.","The film surface morphology by atomic force microscopy gives root mean square (RMS) roughness of the nanofilms as small as 0.13 nm that is also similar to the RMS of single crystal micrometer thick films.","The Bi{_1}Tm{_2}Fe{_5}O{_{12}} films demonstrate effective uniaxial anisotropy.","These all make the fabricated nanofilms very promising for their po-tential applications in magneto-optical devices and quantum technologies."],"url":"http://arxiv.org/abs/2404.04206v1","category":"physics.app-ph"}
{"created":"2024-04-05 15:57:16","title":"Competing topological phases in a non-Hermitian time-reversal symmetry-broken Bernevig-Hughes-Zhang model","abstract":"The Bernevig-Hughes-Zhang (BHZ) model, which serves as a cornerstone in the study of the quantum spin Hall insulators, showcases robust spin-filtered helical edge states in a nanoribbon geometry. In the presence of an in-plane magnetic field, these (first-order) helical states gap out to be replaced by second-order corner states under suitable open-boundary conditions. Here, we show that the inclusion of a spin-dependent non-Hermitian balanced gain/loss potential induces a competition between these first and second-order topological phases. Surprisingly, the previously dormant first-order helical edge states in the nanoribbon resurface as the non-Hermitian effect intensifies, effectively neutralizing the role played by the magnetic field. By employing the projected spin spectra and the spin Chern number, we conclusively explain the resurgence of the first-order topological properties in the time-reversal symmetry-broken BHZ model in presence of non-Hermiticity. Finally, the biorthogonal spin-resolved Berry phase, exhibiting a non-trivial winding, definitively establishes the topological nature of these revived edge states, emphasizing the dominance of non-Hermiticity over the magnetic field.","sentences":["The Bernevig-Hughes-Zhang (BHZ) model, which serves as a cornerstone in the study of the quantum spin Hall insulators, showcases robust spin-filtered helical edge states in a nanoribbon geometry.","In the presence of an in-plane magnetic field, these (first-order) helical states gap out to be replaced by second-order corner states under suitable open-boundary conditions.","Here, we show that the inclusion of a spin-dependent non-Hermitian balanced gain/loss potential induces a competition between these first and second-order topological phases.","Surprisingly, the previously dormant first-order helical edge states in the nanoribbon resurface as the non-Hermitian effect intensifies, effectively neutralizing the role played by the magnetic field.","By employing the projected spin spectra and the spin Chern number, we conclusively explain the resurgence of the first-order topological properties in the time-reversal symmetry-broken BHZ model in presence of non-Hermiticity.","Finally, the biorthogonal spin-resolved Berry phase, exhibiting a non-trivial winding, definitively establishes the topological nature of these revived edge states, emphasizing the dominance of non-Hermiticity over the magnetic field."],"url":"http://arxiv.org/abs/2404.04184v1","category":"cond-mat.mes-hall"}
{"created":"2024-04-05 14:37:30","title":"Sparks in the Dark","abstract":"This study presents a novel method for the definition of signal regions in searches for new physics at collider experiments, specifically those conducted at CERN's Large Hadron Collider. By leveraging multi-dimensional histograms with precise arithmetic and utilizing the SparkDensityTree library, it is possible to identify high-density regions within the available phase space, potentially improving sensitivity to very small signals. Inspired by an ongoing search for dark mesons at the ATLAS experiment, CMS open data is used for this proof-of-concept intentionally targeting an already excluded signal. Several signal regions are defined based on density estimates of signal and background. These preliminary regions align well with the physical properties of the signal while effectively rejecting background events. While not explored in this work, this method is also scalable, which makes it ideal for large datasets such as those expected at the high-luminosity upgrade of the LHC. Finally, this method is flexible and can be easily extended, promising a boost to the signal region definition process for new physics searches at colliders.","sentences":["This study presents a novel method for the definition of signal regions in searches for new physics at collider experiments, specifically those conducted at CERN's Large Hadron Collider.","By leveraging multi-dimensional histograms with precise arithmetic and utilizing the SparkDensityTree library, it is possible to identify high-density regions within the available phase space, potentially improving sensitivity to very small signals.","Inspired by an ongoing search for dark mesons at the ATLAS experiment, CMS open data is used for this proof-of-concept intentionally targeting an already excluded signal.","Several signal regions are defined based on density estimates of signal and background.","These preliminary regions align well with the physical properties of the signal while effectively rejecting background events.","While not explored in this work, this method is also scalable, which makes it ideal for large datasets such as those expected at the high-luminosity upgrade of the LHC.","Finally, this method is flexible and can be easily extended, promising a boost to the signal region definition process for new physics searches at colliders."],"url":"http://arxiv.org/abs/2404.04138v1","category":"hep-ex"}
{"created":"2024-04-05 14:25:23","title":"Smart Contract Languages: a comparative analysis","abstract":"Decentralized blockchain platforms support the secure exchange of assets among users without relying on trusted third parties. These exchanges are programmed with smart contracts, computer programs directly executed by blockchain nodes. Multiple smart contract languages are available nowadays to developers, each with its own distinctive features, strengths, and weaknesses. In this paper, we examine the smart contract languages used in six major blockchain platforms: Ethereum, Solana, Cardano, Algorand, Aptos, and Tezos. Starting with a high-level overview of their design choices, we provide a comprehensive assessment that focuses on programming style, security, code readability, and usability, drawing on an original benchmark that encompasses a common set of use cases across all the smart contract languages under examination.","sentences":["Decentralized blockchain platforms support the secure exchange of assets among users without relying on trusted third parties.","These exchanges are programmed with smart contracts, computer programs directly executed by blockchain nodes.","Multiple smart contract languages are available nowadays to developers, each with its own distinctive features, strengths, and weaknesses.","In this paper, we examine the smart contract languages used in six major blockchain platforms: Ethereum, Solana, Cardano, Algorand, Aptos, and Tezos.","Starting with a high-level overview of their design choices, we provide a comprehensive assessment that focuses on programming style, security, code readability, and usability, drawing on an original benchmark that encompasses a common set of use cases across all the smart contract languages under examination."],"url":"http://arxiv.org/abs/2404.04129v1","category":"cs.CR"}
{"created":"2024-04-05 13:48:53","title":"Machine Learning-Aided Cooperative Localization under Dense Urban Environment","abstract":"Future wireless network technology provides automobiles with the connectivity feature to consolidate the concept of vehicular networks that collaborate on conducting cooperative driving tasks. The full potential of connected vehicles, which promises road safety and quality driving experience, can be leveraged if machine learning models guarantee the robustness in performing core functions including localization and controls. Location awareness, in particular, lends itself to the deployment of location-specific services and the improvement of the operation performance. The localization entails direct communication to the network infrastructure, and the resulting centralized positioning solutions readily become intractable as the network scales up. As an alternative to the centralized solutions, this article addresses decentralized principle of vehicular localization reinforced by machine learning techniques in dense urban environments with frequent inaccessibility to reliable measurement. As such, the collaboration of multiple vehicles enhances the positioning performance of machine learning approaches. A virtual testbed is developed to validate this machine learning model for real-map vehicular networks. Numerical results demonstrate universal feasibility of cooperative localization, in particular, for dense urban area configurations.","sentences":["Future wireless network technology provides automobiles with the connectivity feature to consolidate the concept of vehicular networks that collaborate on conducting cooperative driving tasks.","The full potential of connected vehicles, which promises road safety and quality driving experience, can be leveraged if machine learning models guarantee the robustness in performing core functions including localization and controls.","Location awareness, in particular, lends itself to the deployment of location-specific services and the improvement of the operation performance.","The localization entails direct communication to the network infrastructure, and the resulting centralized positioning solutions readily become intractable as the network scales up.","As an alternative to the centralized solutions, this article addresses decentralized principle of vehicular localization reinforced by machine learning techniques in dense urban environments with frequent inaccessibility to reliable measurement.","As such, the collaboration of multiple vehicles enhances the positioning performance of machine learning approaches.","A virtual testbed is developed to validate this machine learning model for real-map vehicular networks.","Numerical results demonstrate universal feasibility of cooperative localization, in particular, for dense urban area configurations."],"url":"http://arxiv.org/abs/2404.04096v1","category":"cs.IT"}
{"created":"2024-04-05 13:21:02","title":"Some conjectures around magnetic modular forms","abstract":"We study a class of meromorphic modular forms characterised by Fourier coefficients that satisfy certain divisibility properties. We present new candidates for these so-called magnetic modular forms, and we conjecture properties that these functions should obey. In particular, we conjecture that magnetic modular forms are closed under the standard operators acting on spaces of modular forms (SL$_2(\\mathbb{Z})$ action, Hecke and Atkin-Lehner operators), and that they are characterised by algebraic residues and vanishing period polynomials. We use our conjectures to construct examples of real-analytic modular forms with poles.","sentences":["We study a class of meromorphic modular forms characterised by Fourier coefficients that satisfy certain divisibility properties.","We present new candidates for these so-called magnetic modular forms, and we conjecture properties that these functions should obey.","In particular, we conjecture that magnetic modular forms are closed under the standard operators acting on spaces of modular forms (SL$_2(\\mathbb{Z})$ action, Hecke and Atkin-Lehner operators), and that they are characterised by algebraic residues and vanishing period polynomials.","We use our conjectures to construct examples of real-analytic modular forms with poles."],"url":"http://arxiv.org/abs/2404.04085v1","category":"math.NT"}
{"created":"2024-04-05 13:03:35","title":"Crosstalk-mitigated microelectronic control for optically-active spins","abstract":"To exploit the sub-nanometre dimensions of qubits for large-scale quantum information processing, corresponding control architectures require both energy and space efficiency, with the on-chip footprint of unit-cell electronics ideally micron-scale. However, the spin coherence of qubits in close packing is severely deteriorated by microwave crosstalk from neighbouring control sites. Here, we present a crosstalk-mitigation scheme using foundry microelectronics, to address solid-state spins at sub-100 um spacing without the need for qubit-detuning. Using nitrogen-vacancy centres in nanodiamonds as qubit prototypes, we first demonstrate 10 MHz Rabi oscillation at milliwatts of microwave power. Implementing the active cancellation, we then prove that the crosstalk field from neighbouring lattice sites can be reduced to undetectable levels. We finally extend the scheme to show increased qubit control, tripling the spin coherence under crosstalk mitigation. Compatible with integrated optics, our results present a step towards scalable control across quantum platforms using silicon microelectronics.","sentences":["To exploit the sub-nanometre dimensions of qubits for large-scale quantum information processing, corresponding control architectures require both energy and space efficiency, with the on-chip footprint of unit-cell electronics ideally micron-scale.","However, the spin coherence of qubits in close packing is severely deteriorated by microwave crosstalk from neighbouring control sites.","Here, we present a crosstalk-mitigation scheme using foundry microelectronics, to address solid-state spins at sub-100 um spacing without the need for qubit-detuning.","Using nitrogen-vacancy centres in nanodiamonds as qubit prototypes, we first demonstrate 10 MHz Rabi oscillation at milliwatts of microwave power.","Implementing the active cancellation, we then prove that the crosstalk field from neighbouring lattice sites can be reduced to undetectable levels.","We finally extend the scheme to show increased qubit control, tripling the spin coherence under crosstalk mitigation.","Compatible with integrated optics, our results present a step towards scalable control across quantum platforms using silicon microelectronics."],"url":"http://arxiv.org/abs/2404.04075v1","category":"quant-ph"}
{"created":"2024-04-05 12:54:09","title":"Hierarchical Neural Additive Models for Interpretable Demand Forecasts","abstract":"Demand forecasts are the crucial basis for numerous business decisions, ranging from inventory management to strategic facility planning. While machine learning (ML) approaches offer accuracy gains, their interpretability and acceptance are notoriously lacking. Addressing this dilemma, we introduce Hierarchical Neural Additive Models for time series (HNAM). HNAM expands upon Neural Additive Models (NAM) by introducing a time-series specific additive model with a level and interacting covariate components.   Covariate interactions are only allowed according to a user-specified interaction hierarchy. For example, weekday effects may be estimated independently of other covariates, whereas a holiday effect may depend on the weekday and an additional promotion may depend on both former covariates that are lower in the interaction hierarchy.   Thereby, HNAM yields an intuitive forecasting interface in which analysts can observe the contribution for each known covariate. We evaluate the proposed approach and benchmark its performance against other state-of-the-art machine learning and statistical models extensively on real-world retail data. The results reveal that HNAM offers competitive prediction performance whilst providing plausible explanations.","sentences":["Demand forecasts are the crucial basis for numerous business decisions, ranging from inventory management to strategic facility planning.","While machine learning (ML) approaches offer accuracy gains, their interpretability and acceptance are notoriously lacking.","Addressing this dilemma, we introduce Hierarchical Neural Additive Models for time series (HNAM).","HNAM expands upon Neural Additive Models (NAM) by introducing a time-series specific additive model with a level and interacting covariate components.   ","Covariate interactions are only allowed according to a user-specified interaction hierarchy.","For example, weekday effects may be estimated independently of other covariates, whereas a holiday effect may depend on the weekday and an additional promotion may depend on both former covariates that are lower in the interaction hierarchy.   ","Thereby, HNAM yields an intuitive forecasting interface in which analysts can observe the contribution for each known covariate.","We evaluate the proposed approach and benchmark its performance against other state-of-the-art machine learning and statistical models extensively on real-world retail data.","The results reveal that HNAM offers competitive prediction performance whilst providing plausible explanations."],"url":"http://arxiv.org/abs/2404.04070v1","category":"cs.LG"}
{"created":"2024-04-05 12:52:17","title":"Bidirectional Human Interactive AI Framework for Social Robot Navigation","abstract":"Trustworthiness is a crucial concept in the context of human-robot interaction. Cooperative robots must be transparent regarding their decision-making process, especially when operating in a human-oriented environment. This paper presents a comprehensive end-to-end framework aimed at fostering trustworthy bidirectional human-robot interaction in collaborative environments for the social navigation of mobile robots. Our method enables a mobile robot to predict the trajectory of people and adjust its route in a socially-aware manner. In case of conflict between human and robot decisions, detected through visual examination, the route is dynamically modified based on human preference while verbal communication is maintained. We present our pipeline, framework design, and preliminary experiments that form the foundation of our proposition.","sentences":["Trustworthiness is a crucial concept in the context of human-robot interaction.","Cooperative robots must be transparent regarding their decision-making process, especially when operating in a human-oriented environment.","This paper presents a comprehensive end-to-end framework aimed at fostering trustworthy bidirectional human-robot interaction in collaborative environments for the social navigation of mobile robots.","Our method enables a mobile robot to predict the trajectory of people and adjust its route in a socially-aware manner.","In case of conflict between human and robot decisions, detected through visual examination, the route is dynamically modified based on human preference while verbal communication is maintained.","We present our pipeline, framework design, and preliminary experiments that form the foundation of our proposition."],"url":"http://arxiv.org/abs/2404.04069v1","category":"cs.RO"}
{"created":"2024-04-05 11:24:41","title":"Willkommens-Merkel, Chaos-Johnson, and Tore-Klose: Modeling the Evaluative Meaning of German Personal Name Compounds","abstract":"We present a comprehensive computational study of the under-investigated phenomenon of personal name compounds (PNCs) in German such as Willkommens-Merkel ('Welcome-Merkel'). Prevalent in news, social media, and political discourse, PNCs are hypothesized to exhibit an evaluative function that is reflected in a more positive or negative perception as compared to the respective personal full name (such as Angela Merkel). We model 321 PNCs and their corresponding full names at discourse level, and show that PNCs bear an evaluative nature that can be captured through a variety of computational methods. Specifically, we assess through valence information whether a PNC is more positively or negatively evaluative than the person's name, by applying and comparing two approaches using (i) valence norms and (ii) pretrained language models (PLMs). We further enrich our data with personal, domain-specific, and extra-linguistic information and perform a range of regression analyses revealing that factors including compound and modifier valence, domain, and political party membership influence how a PNC is evaluated.","sentences":["We present a comprehensive computational study of the under-investigated phenomenon of personal name compounds (PNCs) in German such as Willkommens-Merkel ('Welcome-Merkel').","Prevalent in news, social media, and political discourse, PNCs are hypothesized to exhibit an evaluative function that is reflected in a more positive or negative perception as compared to the respective personal full name (such as Angela Merkel).","We model 321 PNCs and their corresponding full names at discourse level, and show that PNCs bear an evaluative nature that can be captured through a variety of computational methods.","Specifically, we assess through valence information whether a PNC is more positively or negatively evaluative than the person's name, by applying and comparing two approaches using (i) valence norms and (ii) pretrained language models (PLMs).","We further enrich our data with personal, domain-specific, and extra-linguistic information and perform a range of regression analyses revealing that factors including compound and modifier valence, domain, and political party membership influence how a PNC is evaluated."],"url":"http://arxiv.org/abs/2404.04031v1","category":"cs.CL"}
{"created":"2024-04-05 10:37:37","title":"Benchmarking the effective temperature scale of red giant branch stellar models: the case of the metal-poor halo giant HD 122563","abstract":"There is plenty of evidence in the literature of significant discrepancies between the observations and models of metal-poor red giant branch stars, in particular regarding the effective temperature, teff, scale. We revisit the benchmark star HD 122563 using the most recent observations from Gaia Data Release 3, to investigate if these new constraints may help in resolving this discrepancy. We review the most recent spectroscopic determinations of the metallicity of HD 122563 [Fe/H], and provide a new assessment of its fundamental parameters, i.e. bolometric luminosity, teff, surface gravity, plus a photometric determination of its metal content. Using these constraints, we compare the position of the star in the Hertzsprung-Russell (H-R) diagram with various recent sets of stellar evolution tracks. The H-R diagram analysis reveals a significant disagreement between observed and theoretical teff values, when adopting the most recent spectroscopic estimate of [Fe/H]. On the other hand, by using the photometric determination of [Fe/H] some of the selected sets of stellar tracks appear in fair agreement with observations. The sets with discrepant teff can be made to agree with observations either by modifying the prescription adopted to calculate the models' outer boundary conditions, and/or by reducing the adopted value of the mixing length parameter with respect to the solar-calibration. A definitive assessment of whether the teff scale of metal-poor stellar red giant branch models is consistent with observations requires an even more accurate determination of the fundamental parameters of HD 122563 and also a larger sample of calibrators. From the theoretical side, it is crucial to minimise the current uncertainties in the treatment (boundary conditions, temperature gradient) of the outer layers of stellar models with convective envelopes.","sentences":["There is plenty of evidence in the literature of significant discrepancies between the observations and models of metal-poor red giant branch stars, in particular regarding the effective temperature, teff, scale.","We revisit the benchmark star HD 122563 using the most recent observations from Gaia Data Release 3, to investigate if these new constraints may help in resolving this discrepancy.","We review the most recent spectroscopic determinations of the metallicity of HD 122563","[Fe/H], and provide a new assessment of its fundamental parameters, i.e. bolometric luminosity, teff, surface gravity, plus a photometric determination of its metal content.","Using these constraints, we compare the position of the star in the Hertzsprung-Russell (H-R) diagram with various recent sets of stellar evolution tracks.","The H-R diagram analysis reveals a significant disagreement between observed and theoretical teff values, when adopting the most recent spectroscopic estimate of [Fe/H].","On the other hand, by using the photometric determination of [Fe/H] some of the selected sets of stellar tracks appear in fair agreement with observations.","The sets with discrepant teff can be made to agree with observations either by modifying the prescription adopted to calculate the models' outer boundary conditions, and/or by reducing the adopted value of the mixing length parameter with respect to the solar-calibration.","A definitive assessment of whether the teff scale of metal-poor stellar red giant branch models is consistent with observations requires an even more accurate determination of the fundamental parameters of HD 122563 and also a larger sample of calibrators.","From the theoretical side, it is crucial to minimise the current uncertainties in the treatment (boundary conditions, temperature gradient) of the outer layers of stellar models with convective envelopes."],"url":"http://arxiv.org/abs/2404.04010v1","category":"astro-ph.SR"}
{"created":"2024-04-05 10:27:48","title":"Towards Safe Robot Use with Edged or Pointed Objects: A Surrogate Study Assembling a Human Hand Injury Protection Database","abstract":"The use of pointed or edged tools or objects is one of the most challenging aspects of today's application of physical human-robot interaction (pHRI). One reason for this is that the severity of harm caused by such edged or pointed impactors is less well studied than for blunt impactors. Consequently, the standards specify well-reasoned force and pressure thresholds for blunt impactors and advise avoiding any edges and corners in contacts. Nevertheless, pointed or edged impactor geometries cannot be completely ruled out in real pHRI applications. For example, to allow edged or pointed tools such as screwdrivers near human operators, the knowledge of injury severity needs to be extended so that robot integrators can perform well-reasoned, time-efficient risk assessments. In this paper, we provide the initial datasets on injury prevention for the human hand based on drop tests with surrogates for the human hand, namely pig claws and chicken drumsticks. We then demonstrate the ease and efficiency of robot use using the dataset for contact on two examples. Finally, our experiments provide a set of injuries that may also be expected for human subjects under certain robot mass-velocity constellations in collisions. To extend this work, testing on human samples and a collaborative effort from research institutes worldwide is needed to create a comprehensive human injury avoidance database for any pHRI scenario and thus for safe pHRI applications including edged and pointed geometries.","sentences":["The use of pointed or edged tools or objects is one of the most challenging aspects of today's application of physical human-robot interaction (pHRI).","One reason for this is that the severity of harm caused by such edged or pointed impactors is less well studied than for blunt impactors.","Consequently, the standards specify well-reasoned force and pressure thresholds for blunt impactors and advise avoiding any edges and corners in contacts.","Nevertheless, pointed or edged impactor geometries cannot be completely ruled out in real pHRI applications.","For example, to allow edged or pointed tools such as screwdrivers near human operators, the knowledge of injury severity needs to be extended so that robot integrators can perform well-reasoned, time-efficient risk assessments.","In this paper, we provide the initial datasets on injury prevention for the human hand based on drop tests with surrogates for the human hand, namely pig claws and chicken drumsticks.","We then demonstrate the ease and efficiency of robot use using the dataset for contact on two examples.","Finally, our experiments provide a set of injuries that may also be expected for human subjects under certain robot mass-velocity constellations in collisions.","To extend this work, testing on human samples and a collaborative effort from research institutes worldwide is needed to create a comprehensive human injury avoidance database for any pHRI scenario and thus for safe pHRI applications including edged and pointed geometries."],"url":"http://arxiv.org/abs/2404.04004v1","category":"cs.RO"}
{"created":"2024-04-05 10:01:31","title":"Towards Efficient and Accurate CT Segmentation via Edge-Preserving Probabilistic Downsampling","abstract":"Downsampling images and labels, often necessitated by limited resources or to expedite network training, leads to the loss of small objects and thin boundaries. This undermines the segmentation network's capacity to interpret images accurately and predict detailed labels, resulting in diminished performance compared to processing at original resolutions. This situation exemplifies the trade-off between efficiency and accuracy, with higher downsampling factors further impairing segmentation outcomes. Preserving information during downsampling is especially critical for medical image segmentation tasks. To tackle this challenge, we introduce a novel method named Edge-preserving Probabilistic Downsampling (EPD). It utilizes class uncertainty within a local window to produce soft labels, with the window size dictating the downsampling factor. This enables a network to produce quality predictions at low resolutions. Beyond preserving edge details more effectively than conventional nearest-neighbor downsampling, employing a similar algorithm for images, it surpasses bilinear interpolation in image downsampling, enhancing overall performance. Our method significantly improved Intersection over Union (IoU) to 2.85%, 8.65%, and 11.89% when downsampling data to 1/2, 1/4, and 1/8, respectively, compared to conventional interpolation methods.","sentences":["Downsampling images and labels, often necessitated by limited resources or to expedite network training, leads to the loss of small objects and thin boundaries.","This undermines the segmentation network's capacity to interpret images accurately and predict detailed labels, resulting in diminished performance compared to processing at original resolutions.","This situation exemplifies the trade-off between efficiency and accuracy, with higher downsampling factors further impairing segmentation outcomes.","Preserving information during downsampling is especially critical for medical image segmentation tasks.","To tackle this challenge, we introduce a novel method named Edge-preserving Probabilistic Downsampling (EPD).","It utilizes class uncertainty within a local window to produce soft labels, with the window size dictating the downsampling factor.","This enables a network to produce quality predictions at low resolutions.","Beyond preserving edge details more effectively than conventional nearest-neighbor downsampling, employing a similar algorithm for images, it surpasses bilinear interpolation in image downsampling, enhancing overall performance.","Our method significantly improved Intersection over Union (IoU) to 2.85%, 8.65%, and 11.89% when downsampling data to 1/2, 1/4, and 1/8, respectively, compared to conventional interpolation methods."],"url":"http://arxiv.org/abs/2404.03991v1","category":"eess.IV"}
{"created":"2024-04-05 09:28:03","title":"Ultra-deep cover: an exotic and jetted tidal disruption event candidate disguised as a gamma-ray burst","abstract":"Gamma-ray bursts (GRBs) are traditionally classified as either short GRBs with durations $\\lesssim 2$ s that are powered by compact object mergers, or long GRBs with durations $\\gtrsim 2$ s that powered by the deaths of massive stars. Recent results, however, have challenged this dichotomy and suggest that there exists a population of merger-driven long bursts. One such example, GRB 191019A, has a $t_{90} \\approx 64$ s but many of its other properties -- including its host galaxy, afterglow luminosity and lack of associated supernova -- are more consistent with a short GRB. Here we propose an alternative interpretation: that GRB 191019A (which is located in the nucleus of its host) is an atypical jetted tidal disruption event (TDE). In particular, we suggest the short timescale and rapid decline, not expected for standard TDEs, are the result of an \"ultra-deep\" encounter, in which the star came well within the tidal radius of the black hole and promptly self-intersected, circularised, accreted, and launched a relativistic outflow. This model reproduces the timescale and luminosity through a prompt super-Eddington accretion phase and accounts for the lack of late optical emission. This would make GRB 191019A only the fifth jetted TDE and the first discovered ultra-deep TDE. The ultra-deep TDE model can be distinguished from merger-driven long GRBs via the soft X-ray flash that results from prompt self-intersection of the debris stream; the detection of this flash will be possible with wide-field and soft-X-ray satellites such as $\\textit{Einstein Probe}$ or $\\textit{SVOM}$.","sentences":["Gamma-ray bursts (GRBs) are traditionally classified as either short GRBs with durations $\\lesssim 2$ s that are powered by compact object mergers, or long GRBs with durations $\\gtrsim 2$ s that powered by the deaths of massive stars.","Recent results, however, have challenged this dichotomy and suggest that there exists a population of merger-driven long bursts.","One such example, GRB 191019A, has a $t_{90} \\approx 64$ s but many of its other properties -- including its host galaxy, afterglow luminosity and lack of associated supernova -- are more consistent with a short GRB.","Here we propose an alternative interpretation: that GRB 191019A (which is located in the nucleus of its host) is an atypical jetted tidal disruption event (TDE).","In particular, we suggest the short timescale and rapid decline, not expected for standard TDEs, are the result of an \"ultra-deep\" encounter, in which the star came well within the tidal radius of the black hole and promptly self-intersected, circularised, accreted, and launched a relativistic outflow.","This model reproduces the timescale and luminosity through a prompt super-Eddington accretion phase and accounts for the lack of late optical emission.","This would make GRB 191019A only the fifth jetted TDE and the first discovered ultra-deep TDE.","The ultra-deep TDE model can be distinguished from merger-driven long GRBs via the soft X-ray flash that results from prompt self-intersection of the debris stream; the detection of this flash will be possible with wide-field and soft-X-ray satellites such as $\\textit{Einstein Probe}$ or $\\textit{SVOM}$."],"url":"http://arxiv.org/abs/2404.03982v1","category":"astro-ph.HE"}
{"created":"2024-04-05 09:05:33","title":"Regularization for electricity price forecasting","abstract":"The most commonly used form of regularization typically involves defining the penalty function as a L1 or L2 norm. However, numerous alternative approaches remain untested in practical applications. In this study, we apply ten different penalty functions to predict electricity prices and evaluate their performance under two different model structures and in two distinct electricity markets. The study reveals that LQ and elastic net consistently produce more accurate forecasts compared to other regularization types. In particular, they were the only types of penalty functions that consistently produced more accurate forecasts than the most commonly used LASSO. Furthermore, the results suggest that cross-validation outperforms Bayesian information criteria for parameter optimization, and performs as well as models with ex-post parameter selection.","sentences":["The most commonly used form of regularization typically involves defining the penalty function as a L1 or L2 norm.","However, numerous alternative approaches remain untested in practical applications.","In this study, we apply ten different penalty functions to predict electricity prices and evaluate their performance under two different model structures and in two distinct electricity markets.","The study reveals that LQ and elastic net consistently produce more accurate forecasts compared to other regularization types.","In particular, they were the only types of penalty functions that consistently produced more accurate forecasts than the most commonly used LASSO.","Furthermore, the results suggest that cross-validation outperforms Bayesian information criteria for parameter optimization, and performs as well as models with ex-post parameter selection."],"url":"http://arxiv.org/abs/2404.03968v1","category":"stat.AP"}
{"created":"2024-04-05 08:52:28","title":"Proposal on the Calculation of the Ionisation-Cluster Size Distribution","abstract":"A stochastic model for the calculation of the ionisation-cluster size distribution in nanodosimetry is proposed. It is based on a canonical ensemble and derives from the well-known nuclear droplet model. It is able to describe the ionisation-cluster size distributions caused by electrons. It can easily be extented to light ions. In principle, the model has no free parameters. The model especially can be seen as a refinement to B. Grosswendts model. It is shown that it leads to a cluster-size distribution function F2 being more similar to of the yield of double-strand breaks in the DNA than the one calculated by B. Grosswendt. However, the results are still subject to major uncertainties. The focus of this work is on presenting the model and demonstrating its feasibility.","sentences":["A stochastic model for the calculation of the ionisation-cluster size distribution in nanodosimetry is proposed.","It is based on a canonical ensemble and derives from the well-known nuclear droplet model.","It is able to describe the ionisation-cluster size distributions caused by electrons.","It can easily be extented to light ions.","In principle, the model has no free parameters.","The model especially can be seen as a refinement to B. Grosswendts model.","It is shown that it leads to a cluster-size distribution function F2 being more similar to of the yield of double-strand breaks in the DNA than the one calculated by B. Grosswendt.","However, the results are still subject to major uncertainties.","The focus of this work is on presenting the model and demonstrating its feasibility."],"url":"http://arxiv.org/abs/2404.03961v1","category":"physics.comp-ph"}
{"created":"2024-04-05 08:28:44","title":"Topological moir\u00e9 polaritons","abstract":"The combination of an in-plane honeycomb potential and of a photonic spin-orbit coupling (SOC) emulates a photonic/polaritonic analog of bilayer graphene. We show that modulating the SOC magnitude allows to change the overall lattice periodicity, emulating any type of moir\\'e-arranged bilayer graphene with a unique all-optical access to the moir\\'e band topology. We show that breaking the time-reversal symmetry by an effective exciton-polariton Zeeman splitting opens a large topological gap in the array of moir\\'e flat bands. This gap contains one-way topological edge states whose constant group velocity makes an increasingly sharp contrast with the flattening moir\\'e bands.","sentences":["The combination of an in-plane honeycomb potential and of a photonic spin-orbit coupling (SOC) emulates a photonic/polaritonic analog of bilayer graphene.","We show that modulating the SOC magnitude allows to change the overall lattice periodicity, emulating any type of moir\\'e-arranged bilayer graphene with a unique all-optical access to the moir\\'e band topology.","We show that breaking the time-reversal symmetry by an effective exciton-polariton Zeeman splitting opens a large topological gap in the array of moir\\'e flat bands.","This gap contains one-way topological edge states whose constant group velocity makes an increasingly sharp contrast with the flattening moir\\'e bands."],"url":"http://arxiv.org/abs/2404.03949v1","category":"cond-mat.mes-hall"}
{"created":"2024-04-05 17:54:55","title":"Dissipative Euler flows originating from circular vortex filaments","abstract":"In this paper, we prove the first existence result of weak solutions to the 3D Euler equation with initial vorticity concentrated in a circle and velocity field in $C([0,T],L^{2^-})$. The energy becomes finite and decreasing for positive times, with vorticity concentrated in a ring that thickens and moves in the direction of the symmetry axis. With our approach, there is no need to mollify the initial data or to rescale the time variable. We overcome the singularity of the initial data by applying convex integration within the appropriate time-weighted space.","sentences":["In this paper, we prove the first existence result of weak solutions to the 3D Euler equation with initial vorticity concentrated in a circle and velocity field in $C([0,T],L^{2^-})$.","The energy becomes finite and decreasing for positive times, with vorticity concentrated in a ring that thickens and moves in the direction of the symmetry axis.","With our approach, there is no need to mollify the initial data or to rescale the time variable.","We overcome the singularity of the initial data by applying convex integration within the appropriate time-weighted space."],"url":"http://arxiv.org/abs/2404.04250v1","category":"math.AP"}
{"created":"2024-04-05 16:42:28","title":"Unlocking Parameter-Efficient Fine-Tuning for Low-Resource Language Translation","abstract":"Parameter-efficient fine-tuning (PEFT) methods are increasingly vital in adapting large-scale pre-trained language models for diverse tasks, offering a balance between adaptability and computational efficiency. They are important in Low-Resource Language (LRL) Neural Machine Translation (NMT) to enhance translation accuracy with minimal resources. However, their practical effectiveness varies significantly across different languages. We conducted comprehensive empirical experiments with varying LRL domains and sizes to evaluate the performance of 8 PEFT methods with in total of 15 architectures using the SacreBLEU score. We showed that 6 PEFT architectures outperform the baseline for both in-domain and out-domain tests and the Houlsby+Inversion adapter has the best performance overall, proving the effectiveness of PEFT methods.","sentences":["Parameter-efficient fine-tuning (PEFT) methods are increasingly vital in adapting large-scale pre-trained language models for diverse tasks, offering a balance between adaptability and computational efficiency.","They are important in Low-Resource Language (LRL) Neural Machine Translation (NMT) to enhance translation accuracy with minimal resources.","However, their practical effectiveness varies significantly across different languages.","We conducted comprehensive empirical experiments with varying LRL domains and sizes to evaluate the performance of 8 PEFT methods with in total of 15 architectures using the SacreBLEU score.","We showed that 6 PEFT architectures outperform the baseline for both in-domain and out-domain tests and the Houlsby+Inversion adapter has the best performance overall, proving the effectiveness of PEFT methods."],"url":"http://arxiv.org/abs/2404.04212v1","category":"cs.CL"}
{"created":"2024-04-05 16:20:25","title":"V-Star: Learning Visibly Pushdown Grammars from Program Inputs","abstract":"Accurate description of program inputs remains a critical challenge in the field of programming languages. Active learning, as a well-established field, achieves exact learning for regular languages. We offer an innovative grammar inference tool, V-Star, based on the active learning of visibly pushdown automata. V-Star deduces nesting structures of program input languages from sample inputs, employing a novel inference mechanism based on nested patterns. This mechanism identifies token boundaries and converts languages such as XML documents into VPLs. We then adapted Angluin's L-Star, an exact learning algorithm, for VPA learning, which improves the precision of our tool. Our evaluation demonstrates that V-Star effectively and efficiently learns a variety of practical grammars, including S-Expressions, JSON, and XML, and outperforms other state-of-the-art tools.","sentences":["Accurate description of program inputs remains a critical challenge in the field of programming languages.","Active learning, as a well-established field, achieves exact learning for regular languages.","We offer an innovative grammar inference tool, V-Star, based on the active learning of visibly pushdown automata.","V-Star deduces nesting structures of program input languages from sample inputs, employing a novel inference mechanism based on nested patterns.","This mechanism identifies token boundaries and converts languages such as XML documents into VPLs.","We then adapted Angluin's L-Star, an exact learning algorithm, for VPA learning, which improves the precision of our tool.","Our evaluation demonstrates that V-Star effectively and efficiently learns a variety of practical grammars, including S-Expressions, JSON, and XML, and outperforms other state-of-the-art tools."],"url":"http://arxiv.org/abs/2404.04201v1","category":"cs.PL"}
{"created":"2024-04-05 14:39:13","title":"Improving Detection in Aerial Images by Capturing Inter-Object Relationships","abstract":"In many image domains, the spatial distribution of objects in a scene exhibits meaningful patterns governed by their semantic relationships. In most modern detection pipelines, however, the detection proposals are processed independently, overlooking the underlying relationships between objects. In this work, we introduce a transformer-based approach to capture these inter-object relationships to refine classification and regression outcomes for detected objects. Building on two-stage detectors, we tokenize the region of interest (RoI) proposals to be processed by a transformer encoder. Specific spatial and geometric relations are incorporated into the attention weights and adaptively modulated and regularized. Experimental results demonstrate that the proposed method achieves consistent performance improvement on three benchmarks including DOTA-v1.0, DOTA-v1.5, and HRSC 2016, especially ranking first on both DOTA-v1.5 and HRSC 2016. Specifically, our new method has an increase of 1.59 mAP on DOTA-v1.0, 4.88 mAP on DOTA-v1.5, and 2.1 mAP on HRSC 2016, respectively, compared to the baselines.","sentences":["In many image domains, the spatial distribution of objects in a scene exhibits meaningful patterns governed by their semantic relationships.","In most modern detection pipelines, however, the detection proposals are processed independently, overlooking the underlying relationships between objects.","In this work, we introduce a transformer-based approach to capture these inter-object relationships to refine classification and regression outcomes for detected objects.","Building on two-stage detectors, we tokenize the region of interest (RoI) proposals to be processed by a transformer encoder.","Specific spatial and geometric relations are incorporated into the attention weights and adaptively modulated and regularized.","Experimental results demonstrate that the proposed method achieves consistent performance improvement on three benchmarks including DOTA-v1.0, DOTA-v1.5, and HRSC 2016, especially ranking first on both DOTA-v1.5 and HRSC 2016.","Specifically, our new method has an increase of 1.59 mAP on DOTA-v1.0, 4.88 mAP on DOTA-v1.5, and 2.1 mAP on HRSC 2016, respectively, compared to the baselines."],"url":"http://arxiv.org/abs/2404.04140v1","category":"cs.CV"}
{"created":"2024-04-05 14:26:57","title":"A posteriori error analysis of a space-time hybridizable discontinuous Galerkin method for the advection-diffusion problem","abstract":"We present and analyze an a posteriori error estimator for a space-time hybridizable discontinuous Galerkin discretization of the time-dependent advection-diffusion problem. The residual-based error estimator is proven to be reliable and locally efficient. In the reliability analysis we combine a Peclet-robust coercivity type result and a saturation assumption, while local efficiency analysis is based on using bubble functions. The analysis considers both local space and time adaptivity and is verified by numerical simulations on problems which include boundary and interior layers.","sentences":["We present and analyze an a posteriori error estimator for a space-time hybridizable discontinuous Galerkin discretization of the time-dependent advection-diffusion problem.","The residual-based error estimator is proven to be reliable and locally efficient.","In the reliability analysis we combine a Peclet-robust coercivity type result and a saturation assumption, while local efficiency analysis is based on using bubble functions.","The analysis considers both local space and time adaptivity and is verified by numerical simulations on problems which include boundary and interior layers."],"url":"http://arxiv.org/abs/2404.04130v1","category":"math.NA"}
{"created":"2024-04-05 17:53:55","title":"On classification of global dynamics for energy-critical equivariant harmonic map heat flows and radial nonlinear heat equation","abstract":"We consider the global dynamics of finite energy solutions to energy-critical equivariant harmonic map heat flow (HMHF) and radial nonlinear heat equation (NLH). It is known that any finite energy equivariant solutions to (HMHF) decompose into finitely many harmonic maps (bubbles) separated by scales and a body map, as approaching to the maximal time of existence. Our main result for (HMHF) gives a complete classification of their dynamics for equivariance indices $D\\geq3$; (i) they exist globally in time, (ii) the number of bubbles and signs are determined by the energy class of the initial data, and (iii) the scales of bubbles are asymptotically given by a universal sequence of rates up to scaling symmetry. In parallel, we also obtain a complete classification of $\\dot{H}^{1}$-bounded radial solutions to (NLH) in dimensions $N\\geq7$, building upon soliton resolution for such solutions. To our knowledge, this provides the first rigorous classification of bubble tree dynamics within symmetry. We introduce a new approach based on the energy method that does not rely on maximum principle. The key ingredient of the proof is a monotonicity estimate near any bubble tree configurations, which in turn requires a delicate construction of modified multi-bubble profiles also.","sentences":["We consider the global dynamics of finite energy solutions to energy-critical equivariant harmonic map heat flow (HMHF) and radial nonlinear heat equation (NLH).","It is known that any finite energy equivariant solutions to (HMHF) decompose into finitely many harmonic maps (bubbles) separated by scales and a body map, as approaching to the maximal time of existence.","Our main result for (HMHF) gives a complete classification of their dynamics for equivariance indices $D\\geq3$; (i) they exist globally in time, (ii) the number of bubbles and signs are determined by the energy class of the initial data, and (iii) the scales of bubbles are asymptotically given by a universal sequence of rates up to scaling symmetry.","In parallel, we also obtain a complete classification of $\\dot{H}^{1}$-bounded radial solutions to (NLH) in dimensions $N\\geq7$, building upon soliton resolution for such solutions.","To our knowledge, this provides the first rigorous classification of bubble tree dynamics within symmetry.","We introduce a new approach based on the energy method that does not rely on maximum principle.","The key ingredient of the proof is a monotonicity estimate near any bubble tree configurations, which in turn requires a delicate construction of modified multi-bubble profiles also."],"url":"http://arxiv.org/abs/2404.04247v1","category":"math.AP"}
{"created":"2024-04-05 17:51:58","title":"Evaluating Adversarial Robustness: A Comparison Of FGSM, Carlini-Wagner Attacks, And The Role of Distillation as Defense Mechanism","abstract":"This technical report delves into an in-depth exploration of adversarial attacks specifically targeted at Deep Neural Networks (DNNs) utilized for image classification. The study also investigates defense mechanisms aimed at bolstering the robustness of machine learning models. The research focuses on comprehending the ramifications of two prominent attack methodologies: the Fast Gradient Sign Method (FGSM) and the Carlini-Wagner (CW) approach. These attacks are examined concerning three pre-trained image classifiers: Resnext50_32x4d, DenseNet-201, and VGG-19, utilizing the Tiny-ImageNet dataset. Furthermore, the study proposes the robustness of defensive distillation as a defense mechanism to counter FGSM and CW attacks. This defense mechanism is evaluated using the CIFAR-10 dataset, where CNN models, specifically resnet101 and Resnext50_32x4d, serve as the teacher and student models, respectively. The proposed defensive distillation model exhibits effectiveness in thwarting attacks such as FGSM. However, it is noted to remain susceptible to more sophisticated techniques like the CW attack. The document presents a meticulous validation of the proposed scheme. It provides detailed and comprehensive results, elucidating the efficacy and limitations of the defense mechanisms employed. Through rigorous experimentation and analysis, the study offers insights into the dynamics of adversarial attacks on DNNs, as well as the effectiveness of defensive strategies in mitigating their impact.","sentences":["This technical report delves into an in-depth exploration of adversarial attacks specifically targeted at Deep Neural Networks (DNNs) utilized for image classification.","The study also investigates defense mechanisms aimed at bolstering the robustness of machine learning models.","The research focuses on comprehending the ramifications of two prominent attack methodologies: the Fast Gradient Sign Method (FGSM) and the Carlini-Wagner (CW) approach.","These attacks are examined concerning three pre-trained image classifiers: Resnext50_32x4d, DenseNet-201, and VGG-19, utilizing the Tiny-ImageNet dataset.","Furthermore, the study proposes the robustness of defensive distillation as a defense mechanism to counter FGSM and CW attacks.","This defense mechanism is evaluated using the CIFAR-10 dataset, where CNN models, specifically resnet101 and Resnext50_32x4d, serve as the teacher and student models, respectively.","The proposed defensive distillation model exhibits effectiveness in thwarting attacks such as FGSM.","However, it is noted to remain susceptible to more sophisticated techniques like the CW attack.","The document presents a meticulous validation of the proposed scheme.","It provides detailed and comprehensive results, elucidating the efficacy and limitations of the defense mechanisms employed.","Through rigorous experimentation and analysis, the study offers insights into the dynamics of adversarial attacks on DNNs, as well as the effectiveness of defensive strategies in mitigating their impact."],"url":"http://arxiv.org/abs/2404.04245v1","category":"cs.CR"}
{"created":"2024-04-05 17:46:38","title":"DiffOp-net: A Differential Operator-based Fully Convolutional Network for Unsupervised Deformable Image Registration","abstract":"Existing unsupervised deformable image registration methods usually rely on metrics applied to the gradients of predicted displacement or velocity fields as a regularization term to ensure transformation smoothness, which potentially limits registration accuracy. In this study, we propose a novel approach to enhance unsupervised deformable image registration by introducing a new differential operator into the registration framework. This operator, acting on the velocity field and mapping it to a dual space, ensures the smoothness of the velocity field during optimization, facilitating accurate deformable registration. In addition, to tackle the challenge of capturing large deformations inside image pairs, we introduce a Cross-Coordinate Attention module (CCA) and embed it into a proposed Fully Convolutional Networks (FCNs)-based multi-resolution registration architecture. Evaluation experiments are conducted on two magnetic resonance imaging (MRI) datasets. Compared to various state-of-the-art registration approaches, including a traditional algorithm and three representative unsupervised learning-based methods, our method achieves superior accuracies, maintaining desirable diffeomorphic properties, and exhibiting promising registration speed.","sentences":["Existing unsupervised deformable image registration methods usually rely on metrics applied to the gradients of predicted displacement or velocity fields as a regularization term to ensure transformation smoothness, which potentially limits registration accuracy.","In this study, we propose a novel approach to enhance unsupervised deformable image registration by introducing a new differential operator into the registration framework.","This operator, acting on the velocity field and mapping it to a dual space, ensures the smoothness of the velocity field during optimization, facilitating accurate deformable registration.","In addition, to tackle the challenge of capturing large deformations inside image pairs, we introduce a Cross-Coordinate Attention module (CCA) and embed it into a proposed Fully Convolutional Networks (FCNs)-based multi-resolution registration architecture.","Evaluation experiments are conducted on two magnetic resonance imaging (MRI) datasets.","Compared to various state-of-the-art registration approaches, including a traditional algorithm and three representative unsupervised learning-based methods, our method achieves superior accuracies, maintaining desirable diffeomorphic properties, and exhibiting promising registration speed."],"url":"http://arxiv.org/abs/2404.04244v1","category":"cs.CV"}
{"created":"2024-04-05 14:54:10","title":"On the plasma quasi-thermal noise in the outer heliosphere","abstract":"The recent paper by Li et al. on electron quasi-thermal noise in the outer heliosphere is flawed. It assumes the plasma drift speed to be much smaller than the electron thermal speed, even though both quantities are of the same order of magnitude in the outer heliosphere inward of the termination shock, because of the low plasma temperature. In this case, the Langmuir wave dispersion equation and the quasi-thermal noise in the antenna frame are completely changed. Furthermore, these calculations neglect the shot noise, which should produce a large contribution below the plasma frequency with the Voyager antennas in the outer heliosphere.","sentences":["The recent paper by Li et al. on electron quasi-thermal noise in the outer heliosphere is flawed.","It assumes the plasma drift speed to be much smaller than the electron thermal speed, even though both quantities are of the same order of magnitude in the outer heliosphere inward of the termination shock, because of the low plasma temperature.","In this case, the Langmuir wave dispersion equation and the quasi-thermal noise in the antenna frame are completely changed.","Furthermore, these calculations neglect the shot noise, which should produce a large contribution below the plasma frequency with the Voyager antennas in the outer heliosphere."],"url":"http://arxiv.org/abs/2404.04150v1","category":"physics.space-ph"}
{"created":"2024-04-05 14:08:57","title":"The Unreasonable Effectiveness Of Early Discarding After One Epoch In Neural Network Hyperparameter Optimization","abstract":"To reach high performance with deep learning, hyperparameter optimization (HPO) is essential. This process is usually time-consuming due to costly evaluations of neural networks. Early discarding techniques limit the resources granted to unpromising candidates by observing the empirical learning curves and canceling neural network training as soon as the lack of competitiveness of a candidate becomes evident. Despite two decades of research, little is understood about the trade-off between the aggressiveness of discarding and the loss of predictive performance. Our paper studies this trade-off for several commonly used discarding techniques such as successive halving and learning curve extrapolation. Our surprising finding is that these commonly used techniques offer minimal to no added value compared to the simple strategy of discarding after a constant number of epochs of training. The chosen number of epochs depends mostly on the available compute budget. We call this approach i-Epoch (i being the constant number of epochs with which neural networks are trained) and suggest to assess the quality of early discarding techniques by comparing how their Pareto-Front (in consumed training epochs and predictive performance) complement the Pareto-Front of i-Epoch.","sentences":["To reach high performance with deep learning, hyperparameter optimization (HPO) is essential.","This process is usually time-consuming due to costly evaluations of neural networks.","Early discarding techniques limit the resources granted to unpromising candidates by observing the empirical learning curves and canceling neural network training as soon as the lack of competitiveness of a candidate becomes evident.","Despite two decades of research, little is understood about the trade-off between the aggressiveness of discarding and the loss of predictive performance.","Our paper studies this trade-off for several commonly used discarding techniques such as successive halving and learning curve extrapolation.","Our surprising finding is that these commonly used techniques offer minimal to no added value compared to the simple strategy of discarding after a constant number of epochs of training.","The chosen number of epochs depends mostly on the available compute budget.","We call this approach i-Epoch (i being the constant number of epochs with which neural networks are trained) and suggest to assess the quality of early discarding techniques by comparing how their Pareto-Front (in consumed training epochs and predictive performance) complement the Pareto-Front of i-Epoch."],"url":"http://arxiv.org/abs/2404.04111v1","category":"cs.LG"}
{"created":"2024-04-05 13:49:27","title":"You Can Use But Cannot Recognize: Preserving Visual Privacy in Deep Neural Networks","abstract":"Image data have been extensively used in Deep Neural Network (DNN) tasks in various scenarios, e.g., autonomous driving and medical image analysis, which incurs significant privacy concerns. Existing privacy protection techniques are unable to efficiently protect such data. For example, Differential Privacy (DP) that is an emerging technique protects data with strong privacy guarantee cannot effectively protect visual features of exposed image dataset. In this paper, we propose a novel privacy-preserving framework VisualMixer that protects the training data of visual DNN tasks by pixel shuffling, while not injecting any noises. VisualMixer utilizes a new privacy metric called Visual Feature Entropy (VFE) to effectively quantify the visual features of an image from both biological and machine vision aspects. In VisualMixer, we devise a task-agnostic image obfuscation method to protect the visual privacy of data for DNN training and inference. For each image, it determines regions for pixel shuffling in the image and the sizes of these regions according to the desired VFE. It shuffles pixels both in the spatial domain and in the chromatic channel space in the regions without injecting noises so that it can prevent visual features from being discerned and recognized, while incurring negligible accuracy loss. Extensive experiments on real-world datasets demonstrate that VisualMixer can effectively preserve the visual privacy with negligible accuracy loss, i.e., at average 2.35 percentage points of model accuracy loss, and almost no performance degradation on model training.","sentences":["Image data have been extensively used in Deep Neural Network (DNN) tasks in various scenarios, e.g., autonomous driving and medical image analysis, which incurs significant privacy concerns.","Existing privacy protection techniques are unable to efficiently protect such data.","For example, Differential Privacy (DP) that is an emerging technique protects data with strong privacy guarantee cannot effectively protect visual features of exposed image dataset.","In this paper, we propose a novel privacy-preserving framework VisualMixer that protects the training data of visual DNN tasks by pixel shuffling, while not injecting any noises.","VisualMixer utilizes a new privacy metric called Visual Feature Entropy (VFE) to effectively quantify the visual features of an image from both biological and machine vision aspects.","In VisualMixer, we devise a task-agnostic image obfuscation method to protect the visual privacy of data for DNN training and inference.","For each image, it determines regions for pixel shuffling in the image and the sizes of these regions according to the desired VFE.","It shuffles pixels both in the spatial domain and in the chromatic channel space in the regions without injecting noises so that it can prevent visual features from being discerned and recognized, while incurring negligible accuracy loss.","Extensive experiments on real-world datasets demonstrate that VisualMixer can effectively preserve the visual privacy with negligible accuracy loss, i.e., at average 2.35 percentage points of model accuracy loss, and almost no performance degradation on model training."],"url":"http://arxiv.org/abs/2404.04098v1","category":"cs.CR"}
{"created":"2024-04-05 13:02:50","title":"Newton's method for nonlinear mappings into vector bundles","abstract":"We consider Newton's method for finding zeros of mappings from a manifold $\\mathcal{X}$ into a vector bundle $\\mathcal{E}$. In this setting a connection on $\\mathcal{E}$ is required to render the Newton equation well defined, and a retraction on $\\mathcal{X}$ is needed to compute a Newton update. We discuss local convergence in terms of suitable differentiability concepts, using a Banach space variant of a Riemannian distance. We also carry over an affine covariant damping strategy to our setting. Finally, we discuss two simple applications of our approach, namely, finding fixed points of vector fields and stationary points of functionals.","sentences":["We consider Newton's method for finding zeros of mappings from a manifold $\\mathcal{X}$ into a vector bundle $\\mathcal{E}$. In this setting a connection on $\\mathcal{E}$ is required to render the Newton equation well defined, and a retraction on $\\mathcal{X}$ is needed to compute a Newton update.","We discuss local convergence in terms of suitable differentiability concepts, using a Banach space variant of a Riemannian distance.","We also carry over an affine covariant damping strategy to our setting.","Finally, we discuss two simple applications of our approach, namely, finding fixed points of vector fields and stationary points of functionals."],"url":"http://arxiv.org/abs/2404.04073v1","category":"math.DG"}
{"created":"2024-04-05 11:52:11","title":"Study of mass outflow rates from magnetized advective accretion disk around rotating black holes","abstract":"We develop and discuss a model formalism to study the properties of mass outflows that are emerged out from a relativistic, magnetized, viscous, advective accretion flow around a rotating black hole. In doing so, we consider the toroidal component as the dominant magnetic fields and synchrotron process is the dominant cooling mechanism inside the accretion disk. With this, we self-consistently solve the coupled accretion-ejection governing equations in the steady state and obtain the shock-induced global inflow-outflow solutions in terms of the inflow parameters, namely plasma-$\\beta$ ($=p_{\\rm gas}/p_{\\rm mag}$, $p_{\\rm gas}$ and $p_{\\rm mag}$ being gas and magnetic pressures), accretion rates ($\\dot m$) and viscosity ($\\alpha_{\\rm B}$), respectively. Using these solutions, we compute the mass outflow rate ($R_{\\dot m}$, the ratio of outflow to inflow mass flux) and find that mass loss from the magnetized accretion disk continues to take place for wide range of inflow parameters and black hole spin ($a_{\\rm k}$). We also observe that $R_{\\dot m}$ strongly depends on plasma-$\\beta$, $\\dot m$, $\\alpha_{\\rm B}$ and $a_{\\rm k}$, and it increases as the magnetic activity inside the accretion disk is increased. Further, we compute the maximum mass outflow rate ($R^{\\rm max}_{\\dot m}$) by freely varying the inflow parameters and find that for magnetic pressure dominated disk, $R^{\\rm max}_{\\dot m} \\sim 24\\%$ ($\\sim 30\\%$) for $a_{\\rm k}=0.0$ ($0.99$). Finally, while discussing the implication of our model formalism, we compute the maximum jet kinetic power using $R^{\\rm max}_{\\dot m}$ which appears to be in close agreement with the observed jet kinetic power of several black hole sources.","sentences":["We develop and discuss a model formalism to study the properties of mass outflows that are emerged out from a relativistic, magnetized, viscous, advective accretion flow around a rotating black hole.","In doing so, we consider the toroidal component as the dominant magnetic fields and synchrotron process is the dominant cooling mechanism inside the accretion disk.","With this, we self-consistently solve the coupled accretion-ejection governing equations in the steady state and obtain the shock-induced global inflow-outflow solutions in terms of the inflow parameters, namely plasma-$\\beta$ ($=p_{\\rm gas}/p_{\\rm mag}$, $p_{\\rm gas}$ and $p_{\\rm mag}$ being gas and magnetic pressures), accretion rates ($\\dot m$) and viscosity ($\\alpha_{\\rm B}$), respectively.","Using these solutions, we compute the mass outflow rate ($R_{\\dot m}$, the ratio of outflow to inflow mass flux) and find that mass loss from the magnetized accretion disk continues to take place for wide range of inflow parameters and black hole spin ($a_{\\rm k}$).","We also observe that $R_{\\dot m}$ strongly depends on plasma-$\\beta$, $\\dot m$, $\\alpha_{\\rm B}$ and $a_{\\rm k}$, and it increases as the magnetic activity inside the accretion disk is increased.","Further, we compute the maximum mass outflow rate ($R^{\\rm max}_{\\dot m}$) by freely varying the inflow parameters and find that for magnetic pressure dominated disk, $R^{\\rm max}_{\\dot m} \\sim 24\\%$ ($\\sim 30\\%$) for $a_{\\rm k}=0.0$ ($0.99$).","Finally, while discussing the implication of our model formalism, we compute the maximum jet kinetic power using $R^{\\rm max}_{\\dot m}$ which appears to be in close agreement with the observed jet kinetic power of several black hole sources."],"url":"http://arxiv.org/abs/2404.04043v1","category":"astro-ph.HE"}
{"created":"2024-04-05 11:03:55","title":"Unified equations of state for cold nonaccreting neutron stars with Brussels-Montreal functionals. V. Improved parametrization of the nucleon density distributions","abstract":"We previously studied the inner crust and the pasta mantle of a neutron star within the 4th-order extended Thomas-Fermi (ETF) approach with consistent proton shell corrections added perturbatively via the Strutinsky integral (SI) theorem together with the contribution due to pairing. To speed up the computations and avoid numerical problems, we adopted parametrized nucleon density distributions. However, the errors incurred by the choice of the parametrization are expected to become more significant as the mean baryon number density is increased, especially in the pasta mantle where the differences in the energy per nucleon of the different phases are very small, typically a few keV. To improve the description of these exotic structures, we discuss the important features that a nuclear profile should fulfill and introduce two new parametrizations. Performing calculations using the BSk24 functional, we find that these parametrizations lead to lower ETF energy solutions for all pasta phases than the parametrization we adopted before and more accurately reproduce the exact equilibrium nucleon density distributions obtained from unconstrained variational calculations. Within the ETFSI method, all parametrizations predict the same composition in the region with quasi-spherical clusters. However, the two new parametrizations lead to a different mantle structure at mean baryon densities above about 0.07 fm^-3, at which point lasagna is energetically favored. Interestingly, spherical clusters reappear in the pasta region. The inverted pasta phases such as bucatini and Swiss cheese are still found in the densest region above the core in all cases.","sentences":["We previously studied the inner crust and the pasta mantle of a neutron star within the 4th-order extended Thomas-Fermi (ETF) approach with consistent proton shell corrections added perturbatively via the Strutinsky integral (SI) theorem together with the contribution due to pairing.","To speed up the computations and avoid numerical problems, we adopted parametrized nucleon density distributions.","However, the errors incurred by the choice of the parametrization are expected to become more significant as the mean baryon number density is increased, especially in the pasta mantle where the differences in the energy per nucleon of the different phases are very small, typically a few keV.","To improve the description of these exotic structures, we discuss the important features that a nuclear profile should fulfill and introduce two new parametrizations.","Performing calculations using the BSk24 functional, we find that these parametrizations lead to lower ETF energy solutions for all pasta phases than the parametrization we adopted before and more accurately reproduce the exact equilibrium nucleon density distributions obtained from unconstrained variational calculations.","Within the ETFSI method, all parametrizations predict the same composition in the region with quasi-spherical clusters.","However, the two new parametrizations lead to a different mantle structure at mean baryon densities above about 0.07 fm^-3, at which point lasagna is energetically favored.","Interestingly, spherical clusters reappear in the pasta region.","The inverted pasta phases such as bucatini and Swiss cheese are still found in the densest region above the core in all cases."],"url":"http://arxiv.org/abs/2404.04020v1","category":"astro-ph.HE"}
{"created":"2024-04-05 10:30:38","title":"Neural-Symbolic VideoQA: Learning Compositional Spatio-Temporal Reasoning for Real-world Video Question Answering","abstract":"Compositional spatio-temporal reasoning poses a significant challenge in the field of video question answering (VideoQA). Existing approaches struggle to establish effective symbolic reasoning structures, which are crucial for answering compositional spatio-temporal questions. To address this challenge, we propose a neural-symbolic framework called Neural-Symbolic VideoQA (NS-VideoQA), specifically designed for real-world VideoQA tasks. The uniqueness and superiority of NS-VideoQA are two-fold: 1) It proposes a Scene Parser Network (SPN) to transform static-dynamic video scenes into Symbolic Representation (SR), structuralizing persons, objects, relations, and action chronologies. 2) A Symbolic Reasoning Machine (SRM) is designed for top-down question decompositions and bottom-up compositional reasonings. Specifically, a polymorphic program executor is constructed for internally consistent reasoning from SR to the final answer. As a result, Our NS-VideoQA not only improves the compositional spatio-temporal reasoning in real-world VideoQA task, but also enables step-by-step error analysis by tracing the intermediate results. Experimental evaluations on the AGQA Decomp benchmark demonstrate the effectiveness of the proposed NS-VideoQA framework. Empirical studies further confirm that NS-VideoQA exhibits internal consistency in answering compositional questions and significantly improves the capability of spatio-temporal and logical inference for VideoQA tasks.","sentences":["Compositional spatio-temporal reasoning poses a significant challenge in the field of video question answering (VideoQA).","Existing approaches struggle to establish effective symbolic reasoning structures, which are crucial for answering compositional spatio-temporal questions.","To address this challenge, we propose a neural-symbolic framework called Neural-Symbolic VideoQA (NS-VideoQA), specifically designed for real-world VideoQA tasks.","The uniqueness and superiority of NS-VideoQA are two-fold: 1) It proposes a Scene Parser Network (SPN) to transform static-dynamic video scenes into Symbolic Representation (SR), structuralizing persons, objects, relations, and action chronologies.","2) A Symbolic Reasoning Machine (SRM) is designed for top-down question decompositions and bottom-up compositional reasonings.","Specifically, a polymorphic program executor is constructed for internally consistent reasoning from SR to the final answer.","As a result, Our NS-VideoQA not only improves the compositional spatio-temporal reasoning in real-world VideoQA task, but also enables step-by-step error analysis by tracing the intermediate results.","Experimental evaluations on the AGQA Decomp benchmark demonstrate the effectiveness of the proposed NS-VideoQA framework.","Empirical studies further confirm that NS-VideoQA exhibits internal consistency in answering compositional questions and significantly improves the capability of spatio-temporal and logical inference for VideoQA tasks."],"url":"http://arxiv.org/abs/2404.04007v1","category":"cs.CV"}
{"created":"2024-04-05 10:30:26","title":"From Theory to Comprehension: A Comparative Study of Differential Privacy and $k$-Anonymity","abstract":"The notion of $\\varepsilon$-differential privacy is a widely used concept of providing quantifiable privacy to individuals. However, it is unclear how to explain the level of privacy protection provided by a differential privacy mechanism with a set $\\varepsilon$. In this study, we focus on users' comprehension of the privacy protection provided by a differential privacy mechanism. To do so, we study three variants of explaining the privacy protection provided by differential privacy: (1) the original mathematical definition; (2) $\\varepsilon$ translated into a specific privacy risk; and (3) an explanation using the randomized response technique. We compare users' comprehension of privacy protection employing these explanatory models with their comprehension of privacy protection of $k$-anonymity as baseline comprehensibility. Our findings suggest that participants' comprehension of differential privacy protection is enhanced by the privacy risk model and the randomized response-based model. Moreover, our results confirm our intuition that privacy protection provided by $k$-anonymity is more comprehensible.","sentences":["The notion of $\\varepsilon$-differential privacy is a widely used concept of providing quantifiable privacy to individuals.","However, it is unclear how to explain the level of privacy protection provided by a differential privacy mechanism with a set $\\varepsilon$. In this study, we focus on users' comprehension of the privacy protection provided by a differential privacy mechanism.","To do so, we study three variants of explaining the privacy protection provided by differential privacy: (1) the original mathematical definition; (2) $\\varepsilon$ translated into a specific privacy risk; and (3) an explanation using the randomized response technique.","We compare users' comprehension of privacy protection employing these explanatory models with their comprehension of privacy protection of $k$-anonymity as baseline comprehensibility.","Our findings suggest that participants' comprehension of differential privacy protection is enhanced by the privacy risk model and the randomized response-based model.","Moreover, our results confirm our intuition that privacy protection provided by $k$-anonymity is more comprehensible."],"url":"http://arxiv.org/abs/2404.04006v1","category":"cs.CR"}
{"created":"2024-04-05 08:55:35","title":"A mean correction for improved phase-averaging accuracy in oscillatory, multiscale, differential equations","abstract":"This paper introduces a new algorithm to improve the accuracy of numerical phase-averaging in oscillatory, multiscale, differential equations. Phase-averaging is a technique that applies averaging to a mapped variable to remove highly oscillatory linear terms from the differential equation. This retains the main contribution of fast oscillations on the low frequencies without needing to resolve the rapid oscillations themselves. However, this comes at the cost of an averaging error, which we aim to offset with a modified mapping. The new mapping includes a mean correction which encodes an average measure of the nonlinear interactions. This mapping was introduced in Tao (2019) for weak nonlinearity and relied on classical time averaging. Our algorithm extends this work to the case where 1) the nonlinearity is not weak but the linear oscillations are fast and 2) finite averaging windows are applied via a smooth kernel, which has the advantage of retaining low frequencies whilst still eliminating the fastest oscillations. We show that the new algorithm reduces phase errors in the mapped variable for the swinging spring ODE. We also demonstrate accuracy improvements compared to standard phase-averaging in numerical experiments with the one-dimensional Rotating Shallow Water Equations, a useful test case for weather and climate applications. As the mean correction term can be computed in parallel, this new mapping has potential as a more accurate, yet still computationally cheap, coarse propagator for the oscillatory parareal method.","sentences":["This paper introduces a new algorithm to improve the accuracy of numerical phase-averaging in oscillatory, multiscale, differential equations.","Phase-averaging is a technique that applies averaging to a mapped variable to remove highly oscillatory linear terms from the differential equation.","This retains the main contribution of fast oscillations on the low frequencies without needing to resolve the rapid oscillations themselves.","However, this comes at the cost of an averaging error, which we aim to offset with a modified mapping.","The new mapping includes a mean correction which encodes an average measure of the nonlinear interactions.","This mapping was introduced in Tao (2019) for weak nonlinearity and relied on classical time averaging.","Our algorithm extends this work to the case where 1) the nonlinearity is not weak but the linear oscillations are fast and 2) finite averaging windows are applied via a smooth kernel, which has the advantage of retaining low frequencies whilst still eliminating the fastest oscillations.","We show that the new algorithm reduces phase errors in the mapped variable for the swinging spring ODE.","We also demonstrate accuracy improvements compared to standard phase-averaging in numerical experiments with the one-dimensional Rotating Shallow Water Equations, a useful test case for weather and climate applications.","As the mean correction term can be computed in parallel, this new mapping has potential as a more accurate, yet still computationally cheap, coarse propagator for the oscillatory parareal method."],"url":"http://arxiv.org/abs/2404.03964v1","category":"math.NA"}
{"created":"2024-04-05 17:25:17","title":"Image-Text Co-Decomposition for Text-Supervised Semantic Segmentation","abstract":"This paper addresses text-supervised semantic segmentation, aiming to learn a model capable of segmenting arbitrary visual concepts within images by using only image-text pairs without dense annotations. Existing methods have demonstrated that contrastive learning on image-text pairs effectively aligns visual segments with the meanings of texts. We notice that there is a discrepancy between text alignment and semantic segmentation: A text often consists of multiple semantic concepts, whereas semantic segmentation strives to create semantically homogeneous segments. To address this issue, we propose a novel framework, Image-Text Co-Decomposition (CoDe), where the paired image and text are jointly decomposed into a set of image regions and a set of word segments, respectively, and contrastive learning is developed to enforce region-word alignment. To work with a vision-language model, we present a prompt learning mechanism that derives an extra representation to highlight an image segment or a word segment of interest, with which more effective features can be extracted from that segment. Comprehensive experimental results demonstrate that our method performs favorably against existing text-supervised semantic segmentation methods on six benchmark datasets.","sentences":["This paper addresses text-supervised semantic segmentation, aiming to learn a model capable of segmenting arbitrary visual concepts within images by using only image-text pairs without dense annotations.","Existing methods have demonstrated that contrastive learning on image-text pairs effectively aligns visual segments with the meanings of texts.","We notice that there is a discrepancy between text alignment and semantic segmentation: A text often consists of multiple semantic concepts, whereas semantic segmentation strives to create semantically homogeneous segments.","To address this issue, we propose a novel framework, Image-Text Co-Decomposition (CoDe), where the paired image and text are jointly decomposed into a set of image regions and a set of word segments, respectively, and contrastive learning is developed to enforce region-word alignment.","To work with a vision-language model, we present a prompt learning mechanism that derives an extra representation to highlight an image segment or a word segment of interest, with which more effective features can be extracted from that segment.","Comprehensive experimental results demonstrate that our method performs favorably against existing text-supervised semantic segmentation methods on six benchmark datasets."],"url":"http://arxiv.org/abs/2404.04231v1","category":"cs.CV"}
{"created":"2024-04-05 17:10:33","title":"How Lexical is Bilingual Lexicon Induction?","abstract":"In contemporary machine learning approaches to bilingual lexicon induction (BLI), a model learns a mapping between the embedding spaces of a language pair. Recently, retrieve-and-rank approach to BLI has achieved state of the art results on the task. However, the problem remains challenging in low-resource settings, due to the paucity of data. The task is complicated by factors such as lexical variation across languages. We argue that the incorporation of additional lexical information into the recent retrieve-and-rank approach should improve lexicon induction. We demonstrate the efficacy of our proposed approach on XLING, improving over the previous state of the art by an average of 2\\% across all language pairs.","sentences":["In contemporary machine learning approaches to bilingual lexicon induction (BLI), a model learns a mapping between the embedding spaces of a language pair.","Recently, retrieve-and-rank approach to BLI has achieved state of the art results on the task.","However, the problem remains challenging in low-resource settings, due to the paucity of data.","The task is complicated by factors such as lexical variation across languages.","We argue that the incorporation of additional lexical information into the recent retrieve-and-rank approach should improve lexicon induction.","We demonstrate the efficacy of our proposed approach on XLING, improving over the previous state of the art by an average of 2\\% across all language pairs."],"url":"http://arxiv.org/abs/2404.04221v1","category":"cs.CL"}
{"created":"2024-04-05 16:14:54","title":"Machine-Learning-Enhanced Quantum Optical Storage in Solids","abstract":"Quantum memory devices with high storage efficiency and bandwidth are essential elements for future quantum networks. Solid-state quantum memories can provide broadband storage, but they primarily suffer from low storage efficiency. We use passive optimization and machine learning techniques to demonstrate nearly a 6-fold enhancement in quantum memory efficiency. In this regime, we demonstrate coherent and single-photon-level storage with a high signal-to-noise ratio. The optimization technique presented here can be applied to most solid-state quantum memories to significantly improve the storage efficiency without compromising the memory bandwidth.","sentences":["Quantum memory devices with high storage efficiency and bandwidth are essential elements for future quantum networks.","Solid-state quantum memories can provide broadband storage, but they primarily suffer from low storage efficiency.","We use passive optimization and machine learning techniques to demonstrate nearly a 6-fold enhancement in quantum memory efficiency.","In this regime, we demonstrate coherent and single-photon-level storage with a high signal-to-noise ratio.","The optimization technique presented here can be applied to most solid-state quantum memories to significantly improve the storage efficiency without compromising the memory bandwidth."],"url":"http://arxiv.org/abs/2404.04200v1","category":"quant-ph"}
{"created":"2024-04-05 14:13:55","title":"BEAR: A Unified Framework for Evaluating Relational Knowledge in Causal and Masked Language Models","abstract":"Knowledge probing assesses to which degree a language model (LM) has successfully learned relational knowledge during pre-training. Probing is an inexpensive way to compare LMs of different sizes and training configurations. However, previous approaches rely on the objective function used in pre-training LMs and are thus applicable only to masked or causal LMs. As a result, comparing different types of LMs becomes impossible. To address this, we propose an approach that uses an LM's inherent ability to estimate the log-likelihood of any given textual statement. We carefully design an evaluation dataset of 7,731 instances (40,916 in a larger variant) from which we produce alternative statements for each relational fact, one of which is correct. We then evaluate whether an LM correctly assigns the highest log-likelihood to the correct statement. Our experimental evaluation of 22 common LMs shows that our proposed framework, BEAR, can effectively probe for knowledge across different LM types. We release the BEAR datasets and an open-source framework that implements the probing approach to the research community to facilitate the evaluation and development of LMs.","sentences":["Knowledge probing assesses to which degree a language model (LM) has successfully learned relational knowledge during pre-training.","Probing is an inexpensive way to compare LMs of different sizes and training configurations.","However, previous approaches rely on the objective function used in pre-training LMs and are thus applicable only to masked or causal LMs.","As a result, comparing different types of LMs becomes impossible.","To address this, we propose an approach that uses an LM's inherent ability to estimate the log-likelihood of any given textual statement.","We carefully design an evaluation dataset of 7,731 instances (40,916 in a larger variant) from which we produce alternative statements for each relational fact, one of which is correct.","We then evaluate whether an LM correctly assigns the highest log-likelihood to the correct statement.","Our experimental evaluation of 22 common LMs shows that our proposed framework, BEAR, can effectively probe for knowledge across different LM types.","We release the BEAR datasets and an open-source framework that implements the probing approach to the research community to facilitate the evaluation and development of LMs."],"url":"http://arxiv.org/abs/2404.04113v1","category":"cs.CL"}
{"created":"2024-04-05 12:58:07","title":"Label Propagation for Zero-shot Classification with Vision-Language Models","abstract":"Vision-Language Models (VLMs) have demonstrated impressive performance on zero-shot classification, i.e. classification when provided merely with a list of class names. In this paper, we tackle the case of zero-shot classification in the presence of unlabeled data. We leverage the graph structure of the unlabeled data and introduce ZLaP, a method based on label propagation (LP) that utilizes geodesic distances for classification. We tailor LP to graphs containing both text and image features and further propose an efficient method for performing inductive inference based on a dual solution and a sparsification step. We perform extensive experiments to evaluate the effectiveness of our method on 14 common datasets and show that ZLaP outperforms the latest related works. Code: https://github.com/vladan-stojnic/ZLaP","sentences":["Vision-Language Models (VLMs) have demonstrated impressive performance on zero-shot classification, i.e. classification when provided merely with a list of class names.","In this paper, we tackle the case of zero-shot classification in the presence of unlabeled data.","We leverage the graph structure of the unlabeled data and introduce ZLaP, a method based on label propagation (LP) that utilizes geodesic distances for classification.","We tailor LP to graphs containing both text and image features and further propose an efficient method for performing inductive inference based on a dual solution and a sparsification step.","We perform extensive experiments to evaluate the effectiveness of our method on 14 common datasets and show that ZLaP outperforms the latest related works.","Code: https://github.com/vladan-stojnic/ZLaP"],"url":"http://arxiv.org/abs/2404.04072v1","category":"cs.CV"}
{"created":"2024-04-05 09:50:00","title":"Model Selection with Model Zoo via Graph Learning","abstract":"Pre-trained deep learning (DL) models are increasingly accessible in public repositories, i.e., model zoos. Given a new prediction task, finding the best model to fine-tune can be computationally intensive and costly, especially when the number of pre-trained models is large. Selecting the right pre-trained models is crucial, yet complicated by the diversity of models from various model families (like ResNet, Vit, Swin) and the hidden relationships between models and datasets. Existing methods, which utilize basic information from models and datasets to compute scores indicating model performance on target datasets, overlook the intrinsic relationships, limiting their effectiveness in model selection. In this study, we introduce TransferGraph, a novel framework that reformulates model selection as a graph learning problem. TransferGraph constructs a graph using extensive metadata extracted from models and datasets, while capturing their inherent relationships. Through comprehensive experiments across 16 real datasets, both images and texts, we demonstrate TransferGraph's effectiveness in capturing essential model-dataset relationships, yielding up to a 32% improvement in correlation between predicted performance and the actual fine-tuning results compared to the state-of-the-art methods.","sentences":["Pre-trained deep learning (DL) models are increasingly accessible in public repositories, i.e., model zoos.","Given a new prediction task, finding the best model to fine-tune can be computationally intensive and costly, especially when the number of pre-trained models is large.","Selecting the right pre-trained models is crucial, yet complicated by the diversity of models from various model families (like ResNet, Vit, Swin) and the hidden relationships between models and datasets.","Existing methods, which utilize basic information from models and datasets to compute scores indicating model performance on target datasets, overlook the intrinsic relationships, limiting their effectiveness in model selection.","In this study, we introduce TransferGraph, a novel framework that reformulates model selection as a graph learning problem.","TransferGraph constructs a graph using extensive metadata extracted from models and datasets, while capturing their inherent relationships.","Through comprehensive experiments across 16 real datasets, both images and texts, we demonstrate TransferGraph's effectiveness in capturing essential model-dataset relationships, yielding up to a 32% improvement in correlation between predicted performance and the actual fine-tuning results compared to the state-of-the-art methods."],"url":"http://arxiv.org/abs/2404.03988v1","category":"cs.LG"}
{"created":"2024-04-05 09:14:52","title":"Game-theoretic Distributed Learning Approach for Heterogeneous-cost Task Allocation with Budget Constraints","abstract":"This paper investigates heterogeneous-cost task allocation with budget constraints (HCTAB), wherein heterogeneity is manifested through the varying capabilities and costs associated with different agents for task execution. Different from the centralized optimization-based method, the HCTAB problem is solved using a fully distributed framework, and a coalition formation game is introduced to provide a theoretical guarantee for this distributed framework. To solve the coalition formation game, a convergence-guaranteed log-linear learning algorithm based on heterogeneous cost is proposed. This algorithm incorporates two improvement strategies, namely, a cooperative exchange strategy and a heterogeneous-cost log-linear learning strategy. These strategies are specifically designed to be compatible with the heterogeneous cost and budget constraints characteristic of the HCTAB problem. Through ablation experiments, we demonstrate the effectiveness of these two improvements. Finally, numerical results show that the proposed algorithm outperforms existing task allocation algorithms and learning algorithms in terms of solving the HCTAB problem.","sentences":["This paper investigates heterogeneous-cost task allocation with budget constraints (HCTAB), wherein heterogeneity is manifested through the varying capabilities and costs associated with different agents for task execution.","Different from the centralized optimization-based method, the HCTAB problem is solved using a fully distributed framework, and a coalition formation game is introduced to provide a theoretical guarantee for this distributed framework.","To solve the coalition formation game, a convergence-guaranteed log-linear learning algorithm based on heterogeneous cost is proposed.","This algorithm incorporates two improvement strategies, namely, a cooperative exchange strategy and a heterogeneous-cost log-linear learning strategy.","These strategies are specifically designed to be compatible with the heterogeneous cost and budget constraints characteristic of the HCTAB problem.","Through ablation experiments, we demonstrate the effectiveness of these two improvements.","Finally, numerical results show that the proposed algorithm outperforms existing task allocation algorithms and learning algorithms in terms of solving the HCTAB problem."],"url":"http://arxiv.org/abs/2404.03974v1","category":"cs.GT"}
{"created":"2024-04-05 09:05:37","title":"Transformers for molecular property prediction: Lessons learned from the past five years","abstract":"Molecular Property Prediction (MPP) is vital for drug discovery, crop protection, and environmental science. Over the last decades, diverse computational techniques have been developed, from using simple physical and chemical properties and molecular fingerprints in statistical models and classical machine learning to advanced deep learning approaches. In this review, we aim to distill insights from current research on employing transformer models for MPP. We analyze the currently available models and explore key questions that arise when training and fine-tuning a transformer model for MPP. These questions encompass the choice and scale of the pre-training data, optimal architecture selections, and promising pre-training objectives. Our analysis highlights areas not yet covered in current research, inviting further exploration to enhance the field's understanding. Additionally, we address the challenges in comparing different models, emphasizing the need for standardized data splitting and robust statistical analysis.","sentences":["Molecular Property Prediction (MPP) is vital for drug discovery, crop protection, and environmental science.","Over the last decades, diverse computational techniques have been developed, from using simple physical and chemical properties and molecular fingerprints in statistical models and classical machine learning to advanced deep learning approaches.","In this review, we aim to distill insights from current research on employing transformer models for MPP.","We analyze the currently available models and explore key questions that arise when training and fine-tuning a transformer model for MPP.","These questions encompass the choice and scale of the pre-training data, optimal architecture selections, and promising pre-training objectives.","Our analysis highlights areas not yet covered in current research, inviting further exploration to enhance the field's understanding.","Additionally, we address the challenges in comparing different models, emphasizing the need for standardized data splitting and robust statistical analysis."],"url":"http://arxiv.org/abs/2404.03969v1","category":"cs.LG"}
{"created":"2024-04-05 17:31:40","title":"Polyhedral Analysis of Quadratic Optimization Problems with Stieltjes Matrices and Indicators","abstract":"In this paper, we consider convex quadratic optimization problems with indicators on the continuous variables. In particular, we assume that the Hessian of the quadratic term is a Stieltjes matrix, which naturally appears in sparse graphical inference problems and others. We describe an explicit convex formulation for the problem by studying the Stieltjes polyhedron arising as part of an extended formulation and exploiting the supermodularity of a set function defined on its extreme points. Our computational results confirm that the proposed convex relaxation provides an exact optimal solution and may be an effective alternative, especially for instances with large integrality gaps that are challenging with the standard approaches.","sentences":["In this paper, we consider convex quadratic optimization problems with indicators on the continuous variables.","In particular, we assume that the Hessian of the quadratic term is a Stieltjes matrix, which naturally appears in sparse graphical inference problems and others.","We describe an explicit convex formulation for the problem by studying the Stieltjes polyhedron arising as part of an extended formulation and exploiting the supermodularity of a set function defined on its extreme points.","Our computational results confirm that the proposed convex relaxation provides an exact optimal solution and may be an effective alternative, especially for instances with large integrality gaps that are challenging with the standard approaches."],"url":"http://arxiv.org/abs/2404.04236v1","category":"math.OC"}
{"created":"2024-04-05 17:29:29","title":"Train timetabling with rolling stock assignment, short-turning and skip-stop strategy for a bidirectional metro line","abstract":"Metro train operations is becoming more challenging due to overcrowding and unpredictable irregular passenger demand. To avoid passenger dissatisfaction, metro operators employ various operational strategies to increase the number of train services using limited number of trains. This paper integrates metro timetabling with several operational strategies to improve passenger services with limited number of trains. We propose three optimization models for timetable planning during both peak and off-peak hours: The first model aims to minimize operational costs, the second aims to minimize passenger waiting time, and the third is a multi-objective optimization model that considers both objectives simultaneously. These models integrate operational strategies such as rolling-stock assignment, short-turning, and skip-stop strategies to increase the number of services with limited trains on a bidirectional metro line. The paper also provides detailed calculations for train services, running times, and station dwell times. The proposed models are then implemented on a simplified Santiago metro line 1.","sentences":["Metro train operations is becoming more challenging due to overcrowding and unpredictable irregular passenger demand.","To avoid passenger dissatisfaction, metro operators employ various operational strategies to increase the number of train services using limited number of trains.","This paper integrates metro timetabling with several operational strategies to improve passenger services with limited number of trains.","We propose three optimization models for timetable planning during both peak and off-peak hours: The first model aims to minimize operational costs, the second aims to minimize passenger waiting time, and the third is a multi-objective optimization model that considers both objectives simultaneously.","These models integrate operational strategies such as rolling-stock assignment, short-turning, and skip-stop strategies to increase the number of services with limited trains on a bidirectional metro line.","The paper also provides detailed calculations for train services, running times, and station dwell times.","The proposed models are then implemented on a simplified Santiago metro line 1."],"url":"http://arxiv.org/abs/2404.04233v1","category":"math.OC"}
{"created":"2024-04-05 17:04:17","title":"Simplifying explicit subtyping coercions in a polymorphic calculus with effects","abstract":"Algebraic effect handlers are becoming increasingly popular way of structuring and reasoning about effectful computations, and their performance is often a concern. One of the proposed approaches towards efficient compilation is tracking effect information through explicit subtyping coercions. However, in the presence of polymorphism, these coercions are compiled to additional arguments of compiled functions, incurring significant overhead.   In this paper, we present a polymorphic effectful calculus, identify simplification phases needed to reduce the number of unnecessary constraints, and prove they preserve the semantics. In addition, we implement the simplification algorithm in the Eff language, and evaluate its performance on a number of benchmarks. Though we do not prove optimality of presented simplifications, the results show that the algorithm eliminates all the coercions, resulting in a code as efficient as manually monomorphised one.","sentences":["Algebraic effect handlers are becoming increasingly popular way of structuring and reasoning about effectful computations, and their performance is often a concern.","One of the proposed approaches towards efficient compilation is tracking effect information through explicit subtyping coercions.","However, in the presence of polymorphism, these coercions are compiled to additional arguments of compiled functions, incurring significant overhead.   ","In this paper, we present a polymorphic effectful calculus, identify simplification phases needed to reduce the number of unnecessary constraints, and prove they preserve the semantics.","In addition, we implement the simplification algorithm in the Eff language, and evaluate its performance on a number of benchmarks.","Though we do not prove optimality of presented simplifications, the results show that the algorithm eliminates all the coercions, resulting in a code as efficient as manually monomorphised one."],"url":"http://arxiv.org/abs/2404.04218v1","category":"cs.PL"}
{"created":"2024-04-05 16:03:04","title":"The link between $1$-norm approximation and effective Positivstellensatze for the hypercube","abstract":"The Schm\\\"udgen's Positivstellensatz gives a certificate to verify positivity of a strictly positive polynomial $f$ on a compact, basic, semi-algebraic set $\\mathbf{K} \\subset \\mathbb{R}^n$. A Positivstellensatz of this type is called effective if one may bound the degrees of the polynomials appearing in the certificate in terms of properties of $f$. If $\\mathbf{K} = [-1,1]^n$ and $0 < f_\\min := \\min_{x \\in \\mathbf{K}} f(x)$, then the degrees of the polynomials appearing in the certificate may be bounded by $O\\left(\\sqrt{\\frac{f_\\max - f_\\min}{f_\\min}}\\right)$, where $f_\\max := \\max_{x \\in \\mathbf{K}} f(x)$, as was recently shown by Laurent and Slot [Optimization Letters 17:515-530, 2023]. The big-O notation suppresses dependence on $n$ and the degree $d$ of $f$. In this paper we show a similar result, but with a better dependence on $n$ and $d$. In particular, our bounds depend on the $1$-norm of the coefficients of $f$, that may readily be calculated.","sentences":["The Schm\\\"udgen's Positivstellensatz gives a certificate to verify positivity of a strictly positive polynomial $f$ on a compact, basic, semi-algebraic set $\\mathbf{K} \\subset \\mathbb{R}^n$.","A Positivstellensatz of this type is called effective if one may bound the degrees of the polynomials appearing in the certificate in terms of properties of $f$. If $\\mathbf{K} =","[-1,1]^n$ and $0 < f_\\min := \\min_{x \\in \\mathbf{K}} f(x)$, then the degrees of the polynomials appearing in the certificate may be bounded by $O\\left(\\sqrt{\\frac{f_\\max - f_\\min}{f_\\min}}\\right)$, where $f_\\max := \\max_{x \\in \\mathbf{K}} f(x)$, as was recently shown by Laurent and Slot [Optimization Letters 17:515-530, 2023].","The big-O notation suppresses dependence on $n$ and the degree $d$ of $f$. In this paper we show a similar result, but with a better dependence on $n$ and $d$. In particular, our bounds depend on the $1$-norm of the coefficients of $f$, that may readily be calculated."],"url":"http://arxiv.org/abs/2404.04190v1","category":"math.OC"}
{"created":"2024-04-05 15:45:35","title":"Review on Quantum Walk Computing: Theory, Implementation, and Application","abstract":"Classical random walk formalism shows a significant role across a wide range of applications. As its quantum counterpart, the quantum walk is proposed as an important theoretical model for quantum computing. By exploiting the quantum effects such as superposition, interference and entanglement, quantum walks and their variety have been extensively studied for achieving beyond classical computing power, and they have been broadly used in designing quantum algorithms in fields ranging from algebraic and optimization problems, graph and network analysis, to quantum Hamiltonian and biochemical process simulations, and even further quantum walk models have proven their capabilities for universal quantum computation. Compared to the conventional quantum circuit models, quantum walks show a feasible path for implementing application-specific quantum computing in particularly the noisy intermediate-scale quantum era. Recently remarkable progress has been achieved in implementing a wide variety of quantum walks and quantum walk applications, demonstrating the great potential of quantum walks. In this review, we provide a thorough summary of quantum walks and quantum walk computing, including aspects of quantum walk theories and characteristics, advances in their physical implementations and the flourishingly developed quantum walk computing applications. We also discuss the challenges facing quantum walk computing, toward realizing a practical quantum computer in the near future.","sentences":["Classical random walk formalism shows a significant role across a wide range of applications.","As its quantum counterpart, the quantum walk is proposed as an important theoretical model for quantum computing.","By exploiting the quantum effects such as superposition, interference and entanglement, quantum walks and their variety have been extensively studied for achieving beyond classical computing power, and they have been broadly used in designing quantum algorithms in fields ranging from algebraic and optimization problems, graph and network analysis, to quantum Hamiltonian and biochemical process simulations, and even further quantum walk models have proven their capabilities for universal quantum computation.","Compared to the conventional quantum circuit models, quantum walks show a feasible path for implementing application-specific quantum computing in particularly the noisy intermediate-scale quantum era.","Recently remarkable progress has been achieved in implementing a wide variety of quantum walks and quantum walk applications, demonstrating the great potential of quantum walks.","In this review, we provide a thorough summary of quantum walks and quantum walk computing, including aspects of quantum walk theories and characteristics, advances in their physical implementations and the flourishingly developed quantum walk computing applications.","We also discuss the challenges facing quantum walk computing, toward realizing a practical quantum computer in the near future."],"url":"http://arxiv.org/abs/2404.04178v1","category":"quant-ph"}
{"created":"2024-04-05 13:51:26","title":"ChoreoVis: Planning and Assessing Formations in Dance Choreographies","abstract":"Sports visualization has developed into an active research field over the last decades. Many approaches focus on analyzing movement data recorded from unstructured situations, such as soccer. For the analysis of choreographed activities like formation dancing, however, the goal differs, as dancers follow specific formations in coordinated movement trajectories. To date, little work exists on how visual analytics methods can support such choreographed performances. To fill this gap, we introduce a new visual approach for planning and assessing dance choreographies. In terms of planning choreographies, we contribute a web application with interactive authoring tools and views for the dancers' positions and orientations, movement trajectories, poses, dance floor utilization, and movement distances. For assessing dancers' real-world movement trajectories, extracted by manual bounding box annotations, we developed a timeline showing aggregated trajectory deviations and a dance floor view for detailed trajectory comparison. Our approach was developed and evaluated in collaboration with dance instructors, showing that introducing visual analytics into this domain promises improvements in training efficiency for the future.","sentences":["Sports visualization has developed into an active research field over the last decades.","Many approaches focus on analyzing movement data recorded from unstructured situations, such as soccer.","For the analysis of choreographed activities like formation dancing, however, the goal differs, as dancers follow specific formations in coordinated movement trajectories.","To date, little work exists on how visual analytics methods can support such choreographed performances.","To fill this gap, we introduce a new visual approach for planning and assessing dance choreographies.","In terms of planning choreographies, we contribute a web application with interactive authoring tools and views for the dancers' positions and orientations, movement trajectories, poses, dance floor utilization, and movement distances.","For assessing dancers' real-world movement trajectories, extracted by manual bounding box annotations, we developed a timeline showing aggregated trajectory deviations and a dance floor view for detailed trajectory comparison.","Our approach was developed and evaluated in collaboration with dance instructors, showing that introducing visual analytics into this domain promises improvements in training efficiency for the future."],"url":"http://arxiv.org/abs/2404.04100v1","category":"cs.HC"}
{"created":"2024-04-05 12:04:05","title":"Revealing the Boundary between Quantum Mechanics and Classical Model by EPR-Steering Inequality","abstract":"In quantum information, the Werner state is a benchmark to test the boundary between quantum mechanics and classical models. There have been three well-known critical values for the two-qubit Werner state, i.e., $V_{\\rm c}^{\\rm E}=1/3$ characterizing the boundary between entanglement and separable model, $V_{\\rm c}^{\\rm B}\\approx 0.6595$ characterizing the boundary between Bell's nonlocality and the local-hidden-variable (LHV) model, while $V_{\\rm c}^{\\rm S}=1/2$ characterizing the boundary between Einstein-Podolsky- Rosen (EPR) steering and the local-hidden-state (LHS) model. So far, the problem of $V_{\\rm c}^{\\rm E}=1/3$ has been completely solved by an inequality involving in the positive-partial-transpose criterion, while how to reveal the other two critical values by the inequality approach are still open. In this work, we focus on EPR steering, which is a form of quantum nonlocality intermediate between entanglement and Bell's nonlocality. By proposing the optimal $N$-setting linear EPR-steering inequalities, we have successfully obtained the desired value $V_{\\rm c}^{\\rm S}=1/2$ for the two-qubit Werner state, thus resolving the long-standing problem.","sentences":["In quantum information, the Werner state is a benchmark to test the boundary between quantum mechanics and classical models.","There have been three well-known critical values for the two-qubit Werner state, i.e., $V_{\\rm c}^{\\rm E}=1/3$ characterizing the boundary between entanglement and separable model, $V_{\\rm c}^{\\rm B}\\approx 0.6595$ characterizing the boundary between Bell's nonlocality and the local-hidden-variable (LHV) model, while $V_{\\rm c}^{\\rm S}=1/2$ characterizing the boundary between Einstein-Podolsky- Rosen (EPR) steering and the local-hidden-state (LHS) model.","So far, the problem of $V_{\\rm c}^{\\rm E}=1/3$ has been completely solved by an inequality involving in the positive-partial-transpose criterion, while how to reveal the other two critical values by the inequality approach are still open.","In this work, we focus on EPR steering, which is a form of quantum nonlocality intermediate between entanglement and Bell's nonlocality.","By proposing the optimal $N$-setting linear EPR-steering inequalities, we have successfully obtained the desired value $V_{\\rm c}^{\\rm S}=1/2$ for the two-qubit Werner state, thus resolving the long-standing problem."],"url":"http://arxiv.org/abs/2404.04048v1","category":"quant-ph"}
{"created":"2024-04-05 17:30:02","title":"Probing the Circumstellar Environment of highly luminous type IIn SN ASASSN-14il","abstract":"We present long-term photometric and spectroscopic studies of Circumstellar Material (CSM)-Ejecta interacting supernova (SN) ASASSN-14il in the galaxy PGC 3093694. The SN reaches a peak $r$-band magnitude of $\\sim$ $-20.3 \\pm 0.2$ mag rivaling SN 2006tf and SN 2010jl. The multiband and the pseudo-bolometric lightcurve show a plateau lasting $\\sim 50$ days. Semi-analytical CSM interaction models can match the high luminosity and decline rates of the lightcurves but fail to faithfully represent the plateau region and the bumps in the lightcurves. The spectral evolution resembles the typical SNe IIn dominated by CSM interaction, showing blue-continuum and narrow Balmer lines. The lines are dominated by electron scattering at early epochs. The signatures of the underlying ejecta are visible as the broad component in the H$\\alpha$ profile from as early as day 50, hinting at asymmetry in the CSM. A narrow component is persistent throughout the evolution. The SN shows remarkable photometric and spectroscopic similarity with SN 2015da. However, the different polarization in ASASSN-14il compared to SN 2015da suggests an alternative viewing angle. The late-time blueshift in the H$\\alpha$ profiles supports dust formation in the post-shock CSM or ejecta. The mass-loss rate of 2-7 M$_{\\odot} \\mathrm{yr}^{-1}$ suggests a Luminous Blue Variable (LBV) progenitor in an eruptive phase for ASASSN-14il.","sentences":["We present long-term photometric and spectroscopic studies of Circumstellar Material (CSM)-Ejecta interacting supernova (SN) ASASSN-14il in the galaxy PGC 3093694.","The SN reaches a peak $r$-band magnitude of $\\sim$ $-20.3 \\pm 0.2$ mag rivaling SN 2006tf and SN 2010jl.","The multiband and the pseudo-bolometric lightcurve show a plateau lasting $\\sim 50$ days.","Semi-analytical CSM interaction models can match the high luminosity and decline rates of the lightcurves but fail to faithfully represent the plateau region and the bumps in the lightcurves.","The spectral evolution resembles the typical SNe IIn dominated by CSM interaction, showing blue-continuum and narrow Balmer lines.","The lines are dominated by electron scattering at early epochs.","The signatures of the underlying ejecta are visible as the broad component in the H$\\alpha$ profile from as early as day 50, hinting at asymmetry in the CSM.","A narrow component is persistent throughout the evolution.","The SN shows remarkable photometric and spectroscopic similarity with SN 2015da.","However, the different polarization in ASASSN-14il compared to SN 2015da suggests an alternative viewing angle.","The late-time blueshift in the H$\\alpha$ profiles supports dust formation in the post-shock CSM or ejecta.","The mass-loss rate of 2-7 M$_{\\odot} \\mathrm{yr}^{-1}$ suggests a Luminous Blue Variable (LBV) progenitor in an eruptive phase for ASASSN-14il."],"url":"http://arxiv.org/abs/2404.04235v1","category":"astro-ph.HE"}
{"created":"2024-04-05 16:54:59","title":"Lagrangian Particle Tracking at Large Reynolds Numbers","abstract":"Particle tracking in turbulent flows is fundamental to the study of the transport of tracers, inertial particles or even active objects in space and time, i.e. the Lagrangian frame of reference. It provides experimental tests of theoretical predictions (e.g. for the statistics of fluid accelerations and particle dispersion) and helps to understand important natural processes where particle inertia is important (e.g. cloud microphysics). While the spatial (Eulerian) properties of turbulent flows have been studied for high, atmospheric Reynolds numbers ($R_\\lambda > 10^4$), the profound difficulties in accurately tracking particles in turbulent flows have limited the Reynolds numbers in the Lagrangian reference frame to the Taylor scale Reynolds numbers $R_\\lambda \\lesssim 10^3$. Here we describe a setup that allowed Lagrangian particle tracking at $R_\\lambda$ between 100 and 6000 in the Max Planck Variable Density Turbulence Tunnel (VDTT). We describe the imaging setup within the pressurised facility, the laser illumination, the particles and the particle dispersion mechanism. We verify that the KOBO Cellulobeads D-10 particles are suitable tracers. They carry negligible charge and their Stokes number is small over the full range of experimental conditions. We present typical data from the experiment and discuss the challenges and constraints of the setup.","sentences":["Particle tracking in turbulent flows is fundamental to the study of the transport of tracers, inertial particles or even active objects in space and time, i.e. the Lagrangian frame of reference.","It provides experimental tests of theoretical predictions (e.g. for the statistics of fluid accelerations and particle dispersion) and helps to understand important natural processes where particle inertia is important (e.g. cloud microphysics).","While the spatial (Eulerian) properties of turbulent flows have been studied for high, atmospheric Reynolds numbers ($R_\\lambda > 10^4$), the profound difficulties in accurately tracking particles in turbulent flows have limited the Reynolds numbers in the Lagrangian reference frame to the Taylor scale Reynolds numbers $R_\\lambda \\lesssim 10^3$.","Here we describe a setup that allowed Lagrangian particle tracking at $R_\\lambda$ between 100 and 6000 in the Max Planck Variable Density Turbulence Tunnel (VDTT).","We describe the imaging setup within the pressurised facility, the laser illumination, the particles and the particle dispersion mechanism.","We verify that the KOBO Cellulobeads D-10 particles are suitable tracers.","They carry negligible charge and their Stokes number is small over the full range of experimental conditions.","We present typical data from the experiment and discuss the challenges and constraints of the setup."],"url":"http://arxiv.org/abs/2404.04215v1","category":"physics.flu-dyn"}
{"created":"2024-04-05 16:40:04","title":"Exploring orbital angular momentum and spin-orbit correlation for gluons at the Electron-Ion Collider","abstract":"In our previous work [Phys. Rev. Lett. 128, 182002 (2022)], we introduced a pioneering observable aimed at experimentally detecting the orbital angular momentum (OAM) of gluons. Our focus was on the longitudinal double spin asymmetry observed in exclusive dijet production during electron-proton scattering. We demonstrated the sensitivity of the $\\cos \\phi$ angular correlation between the scattered electron and proton as a probe for gluon OAM at small-$x$ and its intricate interplay with gluon helicity. This current work provides a comprehensive exposition, diving further into the aforementioned calculation with added elaboration and in-depth analysis. We reveal that, in addition to the gluon OAM, one also gains access to the spin-orbit correlation of gluons. We supplement our work with a detailed numerical analysis of our observables for the kinematics of the Electron-Ion Collider. In addition to dijet production, we also consider the recently proposed semi-inclusive diffractive deep inelastic scattering process which potentially offers experimental advantages over dijet measurements. Finally, we investigate quark-channel contributions to these processes and find an unexpected breakdown of collinear factorization.","sentences":["In our previous work [Phys. Rev. Lett.","128, 182002 (2022)], we introduced a pioneering observable aimed at experimentally detecting the orbital angular momentum (OAM) of gluons.","Our focus was on the longitudinal double spin asymmetry observed in exclusive dijet production during electron-proton scattering.","We demonstrated the sensitivity of the $\\cos \\phi$ angular correlation between the scattered electron and proton as a probe for gluon OAM at small-$x$ and its intricate interplay with gluon helicity.","This current work provides a comprehensive exposition, diving further into the aforementioned calculation with added elaboration and in-depth analysis.","We reveal that, in addition to the gluon OAM, one also gains access to the spin-orbit correlation of gluons.","We supplement our work with a detailed numerical analysis of our observables for the kinematics of the Electron-Ion Collider.","In addition to dijet production, we also consider the recently proposed semi-inclusive diffractive deep inelastic scattering process which potentially offers experimental advantages over dijet measurements.","Finally, we investigate quark-channel contributions to these processes and find an unexpected breakdown of collinear factorization."],"url":"http://arxiv.org/abs/2404.04209v1","category":"hep-ph"}
{"created":"2024-04-05 16:39:58","title":"Spin-orbit entanglement in the Color Glass Condensate","abstract":"We compute the spin-orbit correlations of quarks and gluons at small-$x$ and show that the helicity and the orbital angular momentum of individual partons are strongly anti-aligned even in unpolarized or spinless hadrons and nuclei. Combined with the fact that gluons in the Color Glass Condensate are linearly polarized, our finding indicates that the helicity and the orbital angular momentum of single gluons are maximally entangled in a quantum mechanical sense.","sentences":["We compute the spin-orbit correlations of quarks and gluons at small-$x$ and show that the helicity and the orbital angular momentum of individual partons are strongly anti-aligned even in unpolarized or spinless hadrons and nuclei.","Combined with the fact that gluons in the Color Glass Condensate are linearly polarized, our finding indicates that the helicity and the orbital angular momentum of single gluons are maximally entangled in a quantum mechanical sense."],"url":"http://arxiv.org/abs/2404.04208v1","category":"hep-ph"}
{"created":"2024-04-05 15:12:08","title":"The structural stability of tungsten nanoparticles","abstract":"Motivated by contradicting reports in the literature, we have investigated the structural stability of tungsten nanoparticles using density functional theory calculations. The comparison of BCC, FCC, A15, disordered, and icosahedral configurations unequivocally shows that BCC is the energetically most stable structure when the number of atoms is greater than 40. A disordered structure is more stable for smaller sizes. This result conflicts with an earlier theoretical study on transition metal nanoparticles, based on a semi-empirical modeling of nanoparticles energetics [D. Tom{\\'a}nek et al., Phys. Rev. B \\textbf{28}, 665 (1983)]. Examining this latter work in the light of our results suggests that an erroneous description of clusters geometry is the source of the discrepancy. Finally, we improve the accuracy of the semi-empirical model proposed in this work, which will be useful to calculate nanoparticle energies for larger sizes.","sentences":["Motivated by contradicting reports in the literature, we have investigated the structural stability of tungsten nanoparticles using density functional theory calculations.","The comparison of BCC, FCC, A15, disordered, and icosahedral configurations unequivocally shows that BCC is the energetically most stable structure when the number of atoms is greater than 40.","A disordered structure is more stable for smaller sizes.","This result conflicts with an earlier theoretical study on transition metal nanoparticles, based on a semi-empirical modeling of nanoparticles energetics [D. Tom{\\'a}nek et al., Phys. Rev. B \\textbf{28}, 665 (1983)].","Examining this latter work in the light of our results suggests that an erroneous description of clusters geometry is the source of the discrepancy.","Finally, we improve the accuracy of the semi-empirical model proposed in this work, which will be useful to calculate nanoparticle energies for larger sizes."],"url":"http://arxiv.org/abs/2404.04161v1","category":"cond-mat.mtrl-sci"}
{"created":"2024-04-05 15:00:46","title":"Evaluation of the performance of the event reconstruction algorithms in the JSNS$^2$ experiment using a $^{252}$Cf calibration source","abstract":"JSNS$^2$ searches for short baseline neutrino oscillations with a baseline of 24~meters and a target of 17~tonnes of the Gd-loaded liquid scintillator. The correct algorithm on the event reconstruction of events, which determines the position and energy of neutrino interactions in the detector, are essential for the physics analysis of the data from the experiment. Therefore, the performance of the event reconstruction is carefully checked with calibrations using $^{252}$Cf source. This manuscript describes the methodology and the performance of the event reconstruction.","sentences":["JSNS$^2$ searches for short baseline neutrino oscillations with a baseline of 24~meters and a target of 17~tonnes of the Gd-loaded liquid scintillator.","The correct algorithm on the event reconstruction of events, which determines the position and energy of neutrino interactions in the detector, are essential for the physics analysis of the data from the experiment.","Therefore, the performance of the event reconstruction is carefully checked with calibrations using $^{252}$Cf source.","This manuscript describes the methodology and the performance of the event reconstruction."],"url":"http://arxiv.org/abs/2404.04153v1","category":"hep-ex"}
{"created":"2024-04-05 14:55:47","title":"Coherent Perfect Absorption of Arbitrary Wavefronts at an Exceptional Point","abstract":"A Coherent Perfect Absorber (CPA) exploits the interferometric nature of light to deposit all of a light field's incident energy into an otherwise weakly absorbing sample. The downside of this concept is that the necessary destructive interference in CPAs gets easily destroyed both by spectrally or spatially detuning the incoming light field. Each of these two limitations has recently been overcome by insights from exceptional-point physics and by using a degenerate cavity, respectively. Here, we show how these two concepts can be combined into a new type of cavity design, which allows broadband exceptional-point absorption of arbitrary wavefronts. We present two possible implementations of such a Massively Degenerate Exceptional-Point absorber and compare analytical results with numerical simulations.","sentences":["A Coherent Perfect Absorber (CPA) exploits the interferometric nature of light to deposit all of a light field's incident energy into an otherwise weakly absorbing sample.","The downside of this concept is that the necessary destructive interference in CPAs gets easily destroyed both by spectrally or spatially detuning the incoming light field.","Each of these two limitations has recently been overcome by insights from exceptional-point physics and by using a degenerate cavity, respectively.","Here, we show how these two concepts can be combined into a new type of cavity design, which allows broadband exceptional-point absorption of arbitrary wavefronts.","We present two possible implementations of such a Massively Degenerate Exceptional-Point absorber and compare analytical results with numerical simulations."],"url":"http://arxiv.org/abs/2404.04151v1","category":"physics.optics"}
{"created":"2024-04-05 14:46:42","title":"Theory of ultrathin ferroelectrics: the case of CsGeBr$_3$","abstract":"Ferroelectricity has recently been demonstrated in germanium-based inorganic halide perovskites. We use atomistic first-principles-based simulations to study ultra-thin CsGeBr$_3$ films with thicknesses of 4-18 nm and develop a theory for ferroelectric ultrathin films. The theory introduces (i) a local order parameter, the local polarization, which allows the identification of phase transitions into both monodomain and polydomain phases, and (ii) a dipole pattern classifier, which allows efficient and reliable identification of unique dipole patterns. Application of the theory to both halides CsGeBr$_3$ and CsGeI$_3$, as well as oxide BiFeO$_3$ ultrathin ferroelectrics, which undergo paraelectric cubic to ferroelectric rhombohedral phase transition in bulk, reveal two distinct scenarios for ultrathin films. In the first one, the films transition into a monodomain phase, which is allowed below a critical value of the residual depolarizing field. Above this critical value, the second scenario occurs, and the film undergoes a phase transition into a nanodomain phase. The two scenarios are associated with the opposite response of Curie temperature to thickness reduction. As the film's thickness decreases, the transition temperature into the monodomain phase increases while the transition temperature into the nanodomain phase decreases. The surface effects are responsible for the Curie temperature enhancement, while the stripe domain pattern is the origin of the transition temperature suppression. Application of dipole pattern classifier reveals a rich variety of nanodomain phases in halide films: nano-stripes, labyrinths, zig-zags, pillars, and lego-domains. Our work could lead to both a deeper understanding of nanoscale ferroelectrics and discoveries of unusual nanoscale dipole patterns.","sentences":["Ferroelectricity has recently been demonstrated in germanium-based inorganic halide perovskites.","We use atomistic first-principles-based simulations to study ultra-thin CsGeBr$_3$ films with thicknesses of 4-18 nm and develop a theory for ferroelectric ultrathin films.","The theory introduces (i) a local order parameter, the local polarization, which allows the identification of phase transitions into both monodomain and polydomain phases, and (ii) a dipole pattern classifier, which allows efficient and reliable identification of unique dipole patterns.","Application of the theory to both halides CsGeBr$_3$ and CsGeI$_3$, as well as oxide BiFeO$_3$ ultrathin ferroelectrics, which undergo paraelectric cubic to ferroelectric rhombohedral phase transition in bulk, reveal two distinct scenarios for ultrathin films.","In the first one, the films transition into a monodomain phase, which is allowed below a critical value of the residual depolarizing field.","Above this critical value, the second scenario occurs, and the film undergoes a phase transition into a nanodomain phase.","The two scenarios are associated with the opposite response of Curie temperature to thickness reduction.","As the film's thickness decreases, the transition temperature into the monodomain phase increases while the transition temperature into the nanodomain phase decreases.","The surface effects are responsible for the Curie temperature enhancement, while the stripe domain pattern is the origin of the transition temperature suppression.","Application of dipole pattern classifier reveals a rich variety of nanodomain phases in halide films: nano-stripes, labyrinths, zig-zags, pillars, and lego-domains.","Our work could lead to both a deeper understanding of nanoscale ferroelectrics and discoveries of unusual nanoscale dipole patterns."],"url":"http://arxiv.org/abs/2404.04144v1","category":"cond-mat.mtrl-sci"}
{"created":"2024-04-05 14:37:21","title":"Flickering pulsations in bright X-ray pulsars: the evidence of gravitationally lensed and eclipsed accretion column","abstract":"It is expected that extreme mass accretion rate onto strongly magnetised neutron star results in appearance of accretion columns above stellar surface. For a distant observer, rotation of a star results in periodic variations of X-ray flux. Because the mass accretion rate fluctuates around the average value, the pulse profiles are not stable and demonstrate fluctuations as well. In the case of bright X-ray pulsars, however, pulse fluctuations are not solely attributed to variations in the mass accretion rate. They are also influenced by the variable height of the columns, which is dependent on the mass accretion rate. This study delves into the process of pulse profile formation in bright X-ray pulsars, taking into account stochastic fluctuations in the mass accretion rate, the corresponding variations in accretion column geometry and gravitational bending. Our analysis reveals that potential eclipses of accretion columns by a neutron star during their spin period should manifest specific features in pulse profile variability. Applying a novel pulse profile analysis technique, we successfully detect these features in the bright X-ray transient V0332+53 at luminosities $\\gtrsim 2\\times 10^{38}\\,{\\rm erg\\,s^{-1}}$. This detection serves as compelling evidence for the eclipse of an accretion column by a neutron star. Detection of the eclipse places constraints on the relation between neutron star mass, radius and accretion column height. Specifically, we can establish an upper limit on the accretion column height, which is crucial for refining theoretical models of extreme accretion.","sentences":["It is expected that extreme mass accretion rate onto strongly magnetised neutron star results in appearance of accretion columns above stellar surface.","For a distant observer, rotation of a star results in periodic variations of X-ray flux.","Because the mass accretion rate fluctuates around the average value, the pulse profiles are not stable and demonstrate fluctuations as well.","In the case of bright X-ray pulsars, however, pulse fluctuations are not solely attributed to variations in the mass accretion rate.","They are also influenced by the variable height of the columns, which is dependent on the mass accretion rate.","This study delves into the process of pulse profile formation in bright X-ray pulsars, taking into account stochastic fluctuations in the mass accretion rate, the corresponding variations in accretion column geometry and gravitational bending.","Our analysis reveals that potential eclipses of accretion columns by a neutron star during their spin period should manifest specific features in pulse profile variability.","Applying a novel pulse profile analysis technique, we successfully detect these features in the bright X-ray transient V0332+53 at luminosities $\\gtrsim 2\\times 10^{38}\\,{\\rm","erg\\,s^{-1}}$. This detection serves as compelling evidence for the eclipse of an accretion column by a neutron star.","Detection of the eclipse places constraints on the relation between neutron star mass, radius and accretion column height.","Specifically, we can establish an upper limit on the accretion column height, which is crucial for refining theoretical models of extreme accretion."],"url":"http://arxiv.org/abs/2404.04137v1","category":"astro-ph.HE"}
{"created":"2024-04-05 14:34:54","title":"Explorations in Precision Holography and Higher-derivative Supergravity","abstract":"This thesis explores topics related to the study of quantum gravity, with a focus on precision holography and higher-derivative supergravity. First, we study subleading corrections to the free energy of a particular 3D N=3 Chern-Simons-matter theory found by Gaiotto and Tomasiello, which is given by a matrix model after supersymmetric localization. This theory is dual to massive IIA supergravity on AdS4, and consequently, the structure of subleading corrections to the field theory naturally elucidates the higher-derivative corrections to the gravity dual. We extract the first order of corrections to the free energy using resolvent methods, and our results imply that particular terms in the supergravity action should vanish on-shell. Next, we consider the unreasonable effectiveness of five-dimensional minimal gauged supergravity. There are three independent supersymmetric four-derivative terms that one can add to the action; nevertheless, after going on-shell (or, equivalently, after a field redefinition that pushes the off-shell discrepancies to six-derivative order), there is a unique supersymmetric invariant. Third, we consider the effect of higher-derivative corrections in holographic renormalization group flows across dimensions. In particular, we construct a local holographic c-function out of metric functions and show its monotonicity via the Null Energy Condition. We also construct a c-function from the entanglement entropy for flows with a CFT2 IR fixed point, and we show that such flows are monotonic. Finally, we consider consistent truncations of four-derivative heterotic supergravity. In particular, we show that reducing both on a torus $T^n$ or on $S^3$ and truncating the vector multiplets is indeed a consistent truncation at the four-derivative level. Moreover, we find examples of two-derivative consistent truncations which fail to extend to four-derivative ones.","sentences":["This thesis explores topics related to the study of quantum gravity, with a focus on precision holography and higher-derivative supergravity.","First, we study subleading corrections to the free energy of a particular 3D N=3","Chern-Simons-matter theory found by Gaiotto and Tomasiello, which is given by a matrix model after supersymmetric localization.","This theory is dual to massive IIA supergravity on AdS4, and consequently, the structure of subleading corrections to the field theory naturally elucidates the higher-derivative corrections to the gravity dual.","We extract the first order of corrections to the free energy using resolvent methods, and our results imply that particular terms in the supergravity action should vanish on-shell.","Next, we consider the unreasonable effectiveness of five-dimensional minimal gauged supergravity.","There are three independent supersymmetric four-derivative terms that one can add to the action; nevertheless, after going on-shell (or, equivalently, after a field redefinition that pushes the off-shell discrepancies to six-derivative order), there is a unique supersymmetric invariant.","Third, we consider the effect of higher-derivative corrections in holographic renormalization group flows across dimensions.","In particular, we construct a local holographic c-function out of metric functions and show its monotonicity via the Null Energy Condition.","We also construct a c-function from the entanglement entropy for flows with a CFT2 IR fixed point, and we show that such flows are monotonic.","Finally, we consider consistent truncations of four-derivative heterotic supergravity.","In particular, we show that reducing both on a torus $T^n$ or on $S^3$ and truncating the vector multiplets is indeed a consistent truncation at the four-derivative level.","Moreover, we find examples of two-derivative consistent truncations which fail to extend to four-derivative ones."],"url":"http://arxiv.org/abs/2404.04134v1","category":"hep-th"}
{"created":"2024-04-05 14:14:38","title":"Significance of the refraction effect on the $p$-$d$ elementary process in the ($p$,$pd$) reaction","abstract":"The proton-induced deuteron knockout reaction, ($p$,$pd$), is one of the interests in the studies for probing the deuteron-like $p$-$n$ correlation in nuclei. According to a recent study of the inclusive deuteron-induced reaction, $(d,d'x)$, the refraction effect of the deuteron has a significant effect on the elementary process, nucleon-deuteron ($N$-$d$) binary scattering inside a nucleus, of the reaction. In the paper, it is shown that proper treatment of the local $N$-$d$ relative momentum in the elementary process is crucial in $(d,d'x)$ reactions at $100$ MeV and below. In the present work, we investigate the deuteron refraction effect in the exclusive ($p$,$pd$) reactions. We also discuss the incident energy dependence of the refraction effect. The refraction effect on the $p$-$d$ elementary process is taken into account by the local semiclassical approximation to the distorted waves. The results are compared with those obtained with the asymptotic momentum approximation, which is standardly applied to the distorted wave impulse approximation framework. %The $(p,pd)$ cross sections at 101.3 MeV and 250 MeV are studied to see the incident energy dependence of the refraction effect. It is shown that the refraction effect drastically changes the energy sharing distribution of the $^{16}$O($p$,$pd$)$^{14}$N reaction at 101.3 MeV and gives a better agreement with experimental data. In contrast, it is confirmed that the effect is negligibly small at 250 MeV. We have clarified that the deuteron refraction effect is significant in the $^{16}$O($p$,$pd$)$^{14}$N reaction at 101.3 MeV and the experimental data are well reproduced. The refraction effect plays a significant role in both the shape and magnitude of the ($p$,$pd$) cross section, while the effect is negligible at 250 MeV.","sentences":["The proton-induced deuteron knockout reaction, ($p$,$pd$), is one of the interests in the studies for probing the deuteron-like $p$-$n$ correlation in nuclei.","According to a recent study of the inclusive deuteron-induced reaction, $(d,d'x)$, the refraction effect of the deuteron has a significant effect on the elementary process, nucleon-deuteron ($N$-$d$) binary scattering inside a nucleus, of the reaction.","In the paper, it is shown that proper treatment of the local $N$-$d$ relative momentum in the elementary process is crucial in $(d,d'x)$ reactions at $100$ MeV and below.","In the present work, we investigate the deuteron refraction effect in the exclusive ($p$,$pd$) reactions.","We also discuss the incident energy dependence of the refraction effect.","The refraction effect on the $p$-$d$ elementary process is taken into account by the local semiclassical approximation to the distorted waves.","The results are compared with those obtained with the asymptotic momentum approximation, which is standardly applied to the distorted wave impulse approximation framework.","%The $(p,pd)$ cross sections at 101.3 MeV and 250 MeV are studied to see the incident energy dependence of the refraction effect.","It is shown that the refraction effect drastically changes the energy sharing distribution of the $^{16}$O($p$,$pd$)$^{14}$N reaction at 101.3 MeV and gives a better agreement with experimental data.","In contrast, it is confirmed that the effect is negligibly small at 250 MeV.","We have clarified that the deuteron refraction effect is significant in the $^{16}$O($p$,$pd$)$^{14}$N reaction at 101.3 MeV and the experimental data are well reproduced.","The refraction effect plays a significant role in both the shape and magnitude of the ($p$,$pd$) cross section, while the effect is negligible at 250 MeV."],"url":"http://arxiv.org/abs/2404.04115v1","category":"nucl-th"}
{"created":"2024-04-05 14:12:19","title":"Resonant Raman signatures of exciton polarons in a transition metal oxide: BiVO$_4$","abstract":"In this work we investigate the delocalized excitons and excitons trapped by a polaron formation in \\BVO{} by means of resonant Raman spectroscopy. We record Raman spectra with 16 laser lines between 1.9 and \\SI{2.6}{\\eV} and analyze intensity variations of the Raman peaks for different vibrational modes. The resonant Raman cross sections of the \\Ag{} modes contain two types of resonances. The first high-energy resonance near \\SI{2.45}{\\eV} belongs to a transition between delocalized states; it is close to absorption edge measured at \\SI{2.3}{\\eV} and exhibits a characteristic \\SI{50}{\\meV} anisotropy between polarization parallel and perpendicular to the $c$ axis. The high energy Raman resonance occurs inside the gap at \\SI{1.94}{\\eV} for all crystallographic directions.   The in-gap resonance can involve a localized transition. We attribute it to an exciton-polaron, formed by a small localized electron polaron of Holstein type and delocalized holes. It manifests in the vibrations of vanadium and oxygen atoms where polaron localization occurs and the resonance energy matches theoretical predictions. The vibrational modes couple to the polaron with different efficiency determined from resonant Raman profiles.","sentences":["In this work we investigate the delocalized excitons and excitons trapped by a polaron formation in \\BVO{} by means of resonant Raman spectroscopy.","We record Raman spectra with 16 laser lines between 1.9 and \\SI{2.6}{\\eV} and analyze intensity variations of the Raman peaks for different vibrational modes.","The resonant Raman cross sections of the \\Ag{} modes contain two types of resonances.","The first high-energy resonance near \\SI{2.45}{\\eV} belongs to a transition between delocalized states; it is close to absorption edge measured at \\SI{2.3}{\\eV} and exhibits a characteristic \\SI{50}{\\meV} anisotropy between polarization parallel and perpendicular to the $c$ axis.","The high energy Raman resonance occurs inside the gap at \\SI{1.94}{\\eV} for all crystallographic directions.   ","The in-gap resonance can involve a localized transition.","We attribute it to an exciton-polaron, formed by a small localized electron polaron of Holstein type and delocalized holes.","It manifests in the vibrations of vanadium and oxygen atoms where polaron localization occurs and the resonance energy matches theoretical predictions.","The vibrational modes couple to the polaron with different efficiency determined from resonant Raman profiles."],"url":"http://arxiv.org/abs/2404.04112v1","category":"cond-mat.mtrl-sci"}
{"created":"2024-04-05 12:23:23","title":"Higher-Order Analysis of Three-Dimensional Anisotropy in Imbalanced Alfv\u00e9nic Turbulence","abstract":"We analyze in-situ observations of imbalanced solar wind turbulence to evaluate MHD turbulence models grounded in \"Critical Balance\" (CB) and \"Scale-Dependent Dynamic Alignment\" (SDDA). At energy injection scales, both outgoing and ingoing modes exhibit a weak cascade; a simultaneous tightening of SDDA is noted. Outgoing modes persist in a weak cascade across the inertial range, while ingoing modes shift to a strong cascade at $\\lambda \\approx 3 \\times 10^{4} d_i$, with associated spectral scalings deviating from expected behavior due to \"anomalous coherence\" effects. The inertial range comprises two distinct sub-inertial segments. Beyond $\\lambda \\gtrsim 100 d_i$, eddies adopt a field-aligned tube topology, with SDDA signatures mainly evident in high amplitude fluctuations. The scaling exponents $\\zeta_{n}$ of the $n$-th order conditional structure functions, orthogonal to both the local mean field and fluctuation direction, align with the analytical models of Chandran et al. 2015 and Mallet et al. 2017, indicating \"multifractal\" statistics and strong intermittency; however, scaling in parallel and displacement components is more concave than predicted, possibly influenced by expansion effects. Below $\\lambda \\approx 100 d_i$, eddies become increasingly anisotropic, evolving into thin current sheet-like structures. Concurrently, $\\zeta_{n}$ scales linearly with order, marking a shift towards \"monofractal\" statistics. At $\\lambda \\approx 8 d_i$, the increase in aspect ratio halts, and the eddies become quasi-isotropic. This change may signal tearing instability, leading to reconnection, or result from energy redirection into the ion-cyclotron wave spectrum, aligning with the \"helicity barrier\". Our analysis utilizes 5-point structure functions, proving more effective than the traditional 2-point method in capturing steep scaling behaviors at smaller scales.","sentences":["We analyze in-situ observations of imbalanced solar wind turbulence to evaluate MHD turbulence models grounded in \"Critical Balance\" (CB) and \"Scale-Dependent Dynamic Alignment\" (SDDA).","At energy injection scales, both outgoing and ingoing modes exhibit a weak cascade; a simultaneous tightening of SDDA is noted.","Outgoing modes persist in a weak cascade across the inertial range, while ingoing modes shift to a strong cascade at $\\lambda \\approx 3 \\times 10^{4} d_i$, with associated spectral scalings deviating from expected behavior due to \"anomalous coherence\" effects.","The inertial range comprises two distinct sub-inertial segments.","Beyond $\\lambda \\gtrsim 100 d_i$, eddies adopt a field-aligned tube topology, with SDDA signatures mainly evident in high amplitude fluctuations.","The scaling exponents $\\zeta_{n}$ of the $n$-th order conditional structure functions, orthogonal to both the local mean field and fluctuation direction, align with the analytical models of Chandran et al. 2015 and Mallet et al. 2017, indicating \"multifractal\" statistics and strong intermittency; however, scaling in parallel and displacement components is more concave than predicted, possibly influenced by expansion effects.","Below $\\lambda \\approx 100 d_i$, eddies become increasingly anisotropic, evolving into thin current sheet-like structures.","Concurrently, $\\zeta_{n}$ scales linearly with order, marking a shift towards \"monofractal\" statistics.","At $\\lambda \\approx 8 d_i$, the increase in aspect ratio halts, and the eddies become quasi-isotropic.","This change may signal tearing instability, leading to reconnection, or result from energy redirection into the ion-cyclotron wave spectrum, aligning with the \"helicity barrier\".","Our analysis utilizes 5-point structure functions, proving more effective than the traditional 2-point method in capturing steep scaling behaviors at smaller scales."],"url":"http://arxiv.org/abs/2404.04055v1","category":"physics.space-ph"}
{"created":"2024-04-05 09:41:35","title":"Implicit automata in \u03bb-calculi III: affine planar string-to-string functions","abstract":"We prove a characterization of first-order string-to-string transduction via $\\lambda$-terms typed in non-commutative affine logic that compute with Church encoding, extending the analogous known characterization of star-free languages. We show that every first-order transduction can be computed by a $\\lambda$-term using a known Krohn-Rhodes-style decomposition lemma. The converse direction is given by compiling $\\lambda$-terms into two-way reversible planar transducers. The soundness of this translation involves showing that the transition functions of those transducers live in a monoidal closed category of diagrams in which we can interpret purely affine $\\lambda$-terms. One challenge is that the unit of the tensor of the category in question is not a terminal object. As a result, our interpretation does not identify $\\beta$-equivalent terms, but it does turn $\\beta$-reductions into inequalities in a poset-enrichment of the category of diagrams.","sentences":["We prove a characterization of first-order string-to-string transduction via $\\lambda$-terms typed in non-commutative affine logic that compute with Church encoding, extending the analogous known characterization of star-free languages.","We show that every first-order transduction can be computed by a $\\lambda$-term using a known Krohn-Rhodes-style decomposition lemma.","The converse direction is given by compiling $\\lambda$-terms into two-way reversible planar transducers.","The soundness of this translation involves showing that the transition functions of those transducers live in a monoidal closed category of diagrams in which we can interpret purely affine $\\lambda$-terms.","One challenge is that the unit of the tensor of the category in question is not a terminal object.","As a result, our interpretation does not identify $\\beta$-equivalent terms, but it does turn $\\beta$-reductions into inequalities in a poset-enrichment of the category of diagrams."],"url":"http://arxiv.org/abs/2404.03985v1","category":"cs.LO"}
{"created":"2024-04-05 08:53:59","title":"Composite Dark Matter with Forbidden Annihilation","abstract":"A dark matter model based on QCD-like $SU(N_c)$ gauge theory with electroweakly interacting dark quarks is discussed. Assuming the dark quark mass $m$ is smaller than the dynamical scale $\\Lambda_d \\sim 4\\pi f_d$, the main component of the dark matter is the lightest $G$-parity odd dark pion associated with chiral symmetry breaking in the dark sector. We show that nonzero dark quark mass induces the universal mass contribution to both $G$-parity odd and even pions, and their masses tend to be degenerate. As a result, dark pion annihilation into heavier $G$-parity even dark pion also affects the dark matter relic abundance. Thus, our setup naturally accommodates forbidden dark matter scenario and realizes heavy dark matter whose mass is ${\\cal O}(1$-$100)~{\\rm TeV}$, which is different from conventional electroweakly interacting dark matter such as minimal dark matter. We also discuss CP-violation from $\\theta$-term in the dark gauge sector and find that the predicted size of electron electric dipole moment can be as large as $\\sim 10^{-32}~e~{\\rm cm}$.","sentences":["A dark matter model based on QCD-like $SU(N_c)$ gauge theory with electroweakly interacting dark quarks is discussed.","Assuming the dark quark mass $m$ is smaller than the dynamical scale $\\Lambda_d \\sim 4\\pi f_d$, the main component of the dark matter is the lightest $G$-parity odd dark pion associated with chiral symmetry breaking in the dark sector.","We show that nonzero dark quark mass induces the universal mass contribution to both $G$-parity odd and even pions, and their masses tend to be degenerate.","As a result, dark pion annihilation into heavier $G$-parity even dark pion also affects the dark matter relic abundance.","Thus, our setup naturally accommodates forbidden dark matter scenario and realizes heavy dark matter whose mass is ${\\cal O}(1$-$100)~{\\rm TeV}$, which is different from conventional electroweakly interacting dark matter such as minimal dark matter.","We also discuss CP-violation from $\\theta$-term in the dark gauge sector and find that the predicted size of electron electric dipole moment can be as large as $\\sim 10^{-32}~e~{\\rm cm}$."],"url":"http://arxiv.org/abs/2404.03963v1","category":"hep-ph"}
