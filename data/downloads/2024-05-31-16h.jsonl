{"created":"2024-05-29 17:59:20","title":"LLMs Meet Multimodal Generation and Editing: A Survey","abstract":"With the recent advancement in large language models (LLMs), there is a growing interest in combining LLMs with multimodal learning. Previous surveys of multimodal large language models (MLLMs) mainly focus on understanding. This survey elaborates on multimodal generation across different domains, including image, video, 3D, and audio, where we highlight the notable advancements with milestone works in these fields. Specifically, we exhaustively investigate the key technical components behind methods and multimodal datasets utilized in these studies. Moreover, we dig into tool-augmented multimodal agents that can use existing generative models for human-computer interaction. Lastly, we also comprehensively discuss the advancement in AI safety and investigate emerging applications as well as future prospects. Our work provides a systematic and insightful overview of multimodal generation, which is expected to advance the development of Artificial Intelligence for Generative Content (AIGC) and world models. A curated list of all related papers can be found at https://github.com/YingqingHe/Awesome-LLMs-meet-Multimodal-Generation","sentences":["With the recent advancement in large language models (LLMs), there is a growing interest in combining LLMs with multimodal learning.","Previous surveys of multimodal large language models (MLLMs) mainly focus on understanding.","This survey elaborates on multimodal generation across different domains, including image, video, 3D, and audio, where we highlight the notable advancements with milestone works in these fields.","Specifically, we exhaustively investigate the key technical components behind methods and multimodal datasets utilized in these studies.","Moreover, we dig into tool-augmented multimodal agents that can use existing generative models for human-computer interaction.","Lastly, we also comprehensively discuss the advancement in AI safety and investigate emerging applications as well as future prospects.","Our work provides a systematic and insightful overview of multimodal generation, which is expected to advance the development of Artificial Intelligence for Generative Content (AIGC) and world models.","A curated list of all related papers can be found at https://github.com/YingqingHe/Awesome-LLMs-meet-Multimodal-Generation"],"url":"http://arxiv.org/abs/2405.19334v1","category":"cs.AI"}
{"created":"2024-05-29 17:57:30","title":"Normative Modules: A Generative Agent Architecture for Learning Norms that Supports Multi-Agent Cooperation","abstract":"Generative agents, which implement behaviors using a large language model (LLM) to interpret and evaluate an environment, has demonstrated the capacity to solve complex tasks across many social and technological domains. However, when these agents interact with other agents and humans in presence of social structures such as existing norms, fostering cooperation between them is a fundamental challenge. In this paper, we develop the framework of a 'Normative Module': an architecture designed to enhance cooperation by enabling agents to recognize and adapt to the normative infrastructure of a given environment. We focus on the equilibrium selection aspect of the cooperation problem and inform our agent design based on the existence of classification institutions that implement correlated equilibrium to provide effective resolution of the equilibrium selection problem. Specifically, the normative module enables agents to learn through peer interactions which of multiple candidate institutions in the environment, does a group treat as authoritative. By enabling normative competence in this sense, agents gain ability to coordinate their sanctioning behaviour; coordinated sanctioning behaviour in turn shapes primary behaviour within a social environment, leading to higher average welfare. We design a new environment that supports institutions and evaluate the proposed framework based on two key criteria derived from agent interactions with peers and institutions: (i) the agent's ability to disregard non-authoritative institutions and (ii) the agent's ability to identify authoritative institutions among several options. We show that these capabilities allow the agent to achieve more stable cooperative outcomes compared to baseline agents without the normative module, paving the way for research in a new avenue of designing environments and agents that account for normative infrastructure.","sentences":["Generative agents, which implement behaviors using a large language model (LLM) to interpret and evaluate an environment, has demonstrated the capacity to solve complex tasks across many social and technological domains.","However, when these agents interact with other agents and humans in presence of social structures such as existing norms, fostering cooperation between them is a fundamental challenge.","In this paper, we develop the framework of a 'Normative Module': an architecture designed to enhance cooperation by enabling agents to recognize and adapt to the normative infrastructure of a given environment.","We focus on the equilibrium selection aspect of the cooperation problem and inform our agent design based on the existence of classification institutions that implement correlated equilibrium to provide effective resolution of the equilibrium selection problem.","Specifically, the normative module enables agents to learn through peer interactions which of multiple candidate institutions in the environment, does a group treat as authoritative.","By enabling normative competence in this sense, agents gain ability to coordinate their sanctioning behaviour; coordinated sanctioning behaviour in turn shapes primary behaviour within a social environment, leading to higher average welfare.","We design a new environment that supports institutions and evaluate the proposed framework based on two key criteria derived from agent interactions with peers and institutions: (i) the agent's ability to disregard non-authoritative institutions and (ii) the agent's ability to identify authoritative institutions among several options.","We show that these capabilities allow the agent to achieve more stable cooperative outcomes compared to baseline agents without the normative module, paving the way for research in a new avenue of designing environments and agents that account for normative infrastructure."],"url":"http://arxiv.org/abs/2405.19328v1","category":"cs.MA"}
{"created":"2024-05-29 17:43:13","title":"Adaptive Generalized Neyman Allocation: Local Asymptotic Minimax Optimal Best Arm Identification","abstract":"This study investigates a local asymptotic minimax optimal strategy for fixed-budget best arm identification (BAI). We propose the Adaptive Generalized Neyman Allocation (AGNA) strategy and show that its worst-case upper bound of the probability of misidentifying the best arm aligns with the worst-case lower bound under the small-gap regime, where the gap between the expected outcomes of the best and suboptimal arms is small. Our strategy corresponds to a generalization of the Neyman allocation for two-armed bandits (Neyman, 1934; Kaufmann et al., 2016) and a refinement of existing strategies such as the ones proposed by Glynn & Juneja (2004) and Shin et al. (2018). Compared to Komiyama et al. (2022), which proposes a minimax rate-optimal strategy, our proposed strategy has a tighter upper bound that exactly matches the lower bound, including the constant terms, by restricting the class of distributions to the class of small-gap distributions. Our result contributes to the longstanding open issue about the existence of asymptotically optimal strategies in fixed-budget BAI, by presenting the local asymptotic minimax optimal strategy.","sentences":["This study investigates a local asymptotic minimax optimal strategy for fixed-budget best arm identification (BAI).","We propose the Adaptive Generalized Neyman Allocation (AGNA) strategy and show that its worst-case upper bound of the probability of misidentifying the best arm aligns with the worst-case lower bound under the small-gap regime, where the gap between the expected outcomes of the best and suboptimal arms is small.","Our strategy corresponds to a generalization of the Neyman allocation for two-armed bandits (Neyman, 1934; Kaufmann et al., 2016) and a refinement of existing strategies such as the ones proposed by Glynn & Juneja (2004) and Shin et al.","(2018).","Compared to Komiyama et al. (2022), which proposes a minimax rate-optimal strategy, our proposed strategy has a tighter upper bound that exactly matches the lower bound, including the constant terms, by restricting the class of distributions to the class of small-gap distributions.","Our result contributes to the longstanding open issue about the existence of asymptotically optimal strategies in fixed-budget BAI, by presenting the local asymptotic minimax optimal strategy."],"url":"http://arxiv.org/abs/2405.19317v1","category":"cs.LG"}
{"created":"2024-05-29 17:39:42","title":"Matryoshka Query Transformer for Large Vision-Language Models","abstract":"Large Vision-Language Models (LVLMs) typically encode an image into a fixed number of visual tokens (e.g., 576) and process these tokens with a language model. Despite their strong performance, LVLMs face challenges in adapting to varying computational constraints. This raises the question: can we achieve flexibility in the number of visual tokens to suit different tasks and computational resources? We answer this with an emphatic yes. Inspired by Matryoshka Representation Learning, we introduce the Matryoshka Query Transformer (MQT), capable of encoding an image into m visual tokens during inference, where m can be any number up to a predefined maximum. This is achieved by employing a query transformer with M latent query tokens to compress the visual embeddings. During each training step, we randomly select m <= M latent query tokens and train the model using only these first m tokens, discarding the rest. Combining MQT with LLaVA, we train a single model once, and flexibly and drastically reduce the number of inference-time visual tokens while maintaining similar or better performance compared to training independent models for each number of tokens. Our model, MQT-LLAVA, matches LLaVA-1.5 performance across 11 benchmarks using a maximum of 256 tokens instead of LLaVA's fixed 576. Reducing to 16 tokens (8x less TFLOPs) only sacrifices the performance by 2.4 points on MMBench. On certain tasks such as ScienceQA and MMMU, we can even go down to only 2 visual tokens with performance drops of just 3% and 6% each. Our exploration of the trade-off between the accuracy and computational cost brought about by the number of visual tokens facilitates future research to achieve the best of both worlds.","sentences":["Large Vision-Language Models (LVLMs) typically encode an image into a fixed number of visual tokens (e.g., 576) and process these tokens with a language model.","Despite their strong performance, LVLMs face challenges in adapting to varying computational constraints.","This raises the question: can we achieve flexibility in the number of visual tokens to suit different tasks and computational resources?","We answer this with an emphatic yes.","Inspired by Matryoshka Representation Learning, we introduce the Matryoshka Query Transformer (MQT), capable of encoding an image into m visual tokens during inference, where m can be any number up to a predefined maximum.","This is achieved by employing a query transformer with M latent query tokens to compress the visual embeddings.","During each training step, we randomly select m <= M latent query tokens and train the model using only these first m tokens, discarding the rest.","Combining MQT with LLaVA, we train a single model once, and flexibly and drastically reduce the number of inference-time visual tokens while maintaining similar or better performance compared to training independent models for each number of tokens.","Our model, MQT-LLAVA, matches LLaVA-1.5 performance across 11 benchmarks using a maximum of 256 tokens instead of LLaVA's fixed 576.","Reducing to 16 tokens (8x less TFLOPs) only sacrifices the performance by 2.4 points on MMBench.","On certain tasks such as ScienceQA and MMMU, we can even go down to only 2 visual tokens with performance drops of just 3% and 6% each.","Our exploration of the trade-off between the accuracy and computational cost brought about by the number of visual tokens facilitates future research to achieve the best of both worlds."],"url":"http://arxiv.org/abs/2405.19315v1","category":"cs.CV"}
{"created":"2024-05-29 17:26:09","title":"Adaptive Image Quality Assessment via Teaching Large Multimodal Model to Compare","abstract":"While recent advancements in large multimodal models (LMMs) have significantly improved their abilities in image quality assessment (IQA) relying on absolute quality rating, how to transfer reliable relative quality comparison outputs to continuous perceptual quality scores remains largely unexplored. To address this gap, we introduce Compare2Score-an all-around LMM-based no-reference IQA (NR-IQA) model, which is capable of producing qualitatively comparative responses and effectively translating these discrete comparative levels into a continuous quality score. Specifically, during training, we present to generate scaled-up comparative instructions by comparing images from the same IQA dataset, allowing for more flexible integration of diverse IQA datasets. Utilizing the established large-scale training corpus, we develop a human-like visual quality comparator. During inference, moving beyond binary choices, we propose a soft comparison method that calculates the likelihood of the test image being preferred over multiple predefined anchor images. The quality score is further optimized by maximum a posteriori estimation with the resulting probability matrix. Extensive experiments on nine IQA datasets validate that the Compare2Score effectively bridges text-defined comparative levels during training with converted single image quality score for inference, surpassing state-of-the-art IQA models across diverse scenarios. Moreover, we verify that the probability-matrix-based inference conversion not only improves the rating accuracy of Compare2Score but also zero-shot general-purpose LMMs, suggesting its intrinsic effectiveness.","sentences":["While recent advancements in large multimodal models (LMMs) have significantly improved their abilities in image quality assessment (IQA) relying on absolute quality rating, how to transfer reliable relative quality comparison outputs to continuous perceptual quality scores remains largely unexplored.","To address this gap, we introduce Compare2Score-an all-around LMM-based no-reference IQA (NR-IQA) model, which is capable of producing qualitatively comparative responses and effectively translating these discrete comparative levels into a continuous quality score.","Specifically, during training, we present to generate scaled-up comparative instructions by comparing images from the same IQA dataset, allowing for more flexible integration of diverse IQA datasets.","Utilizing the established large-scale training corpus, we develop a human-like visual quality comparator.","During inference, moving beyond binary choices, we propose a soft comparison method that calculates the likelihood of the test image being preferred over multiple predefined anchor images.","The quality score is further optimized by maximum a posteriori estimation with the resulting probability matrix.","Extensive experiments on nine IQA datasets validate that the Compare2Score effectively bridges text-defined comparative levels during training with converted single image quality score for inference, surpassing state-of-the-art IQA models across diverse scenarios.","Moreover, we verify that the probability-matrix-based inference conversion not only improves the rating accuracy of Compare2Score but also zero-shot general-purpose LMMs, suggesting its intrinsic effectiveness."],"url":"http://arxiv.org/abs/2405.19298v1","category":"cs.CV"}
{"created":"2024-05-29 17:19:04","title":"Integrating Multi-scale Contextualized Information for Byte-based Neural Machine Translation","abstract":"Subword tokenization is a common method for vocabulary building in Neural Machine Translation (NMT) models. However, increasingly complex tasks have revealed its disadvantages. First, a vocabulary cannot be modified once it is learned, making it hard to adapt to new words. Second, in multilingual translation, the imbalance in data volumes across different languages spreads to the vocabulary, exacerbating translations involving low-resource languages. While byte-based tokenization addresses these issues, byte-based models struggle with the low information density inherent in UTF-8 byte sequences. Previous works enhance token semantics through local contextualization but fail to select an appropriate contextualizing scope based on the input. Consequently, we propose the Multi-Scale Contextualization (MSC) method, which learns contextualized information of varying scales across different hidden state dimensions. It then leverages the attention module to dynamically integrate the multi-scale contextualized information. Experiments show that MSC significantly outperforms subword-based and other byte-based methods in both multilingual and out-of-domain scenarios. Code can be found in https://github.com/ictnlp/Multiscale-Contextualization.","sentences":["Subword tokenization is a common method for vocabulary building in Neural Machine Translation (NMT) models.","However, increasingly complex tasks have revealed its disadvantages.","First, a vocabulary cannot be modified once it is learned, making it hard to adapt to new words.","Second, in multilingual translation, the imbalance in data volumes across different languages spreads to the vocabulary, exacerbating translations involving low-resource languages.","While byte-based tokenization addresses these issues, byte-based models struggle with the low information density inherent in UTF-8 byte sequences.","Previous works enhance token semantics through local contextualization but fail to select an appropriate contextualizing scope based on the input.","Consequently, we propose the Multi-Scale Contextualization (MSC) method, which learns contextualized information of varying scales across different hidden state dimensions.","It then leverages the attention module to dynamically integrate the multi-scale contextualized information.","Experiments show that MSC significantly outperforms subword-based and other byte-based methods in both multilingual and out-of-domain scenarios.","Code can be found in https://github.com/ictnlp/Multiscale-Contextualization."],"url":"http://arxiv.org/abs/2405.19290v1","category":"cs.CL"}
{"created":"2024-05-29 16:59:38","title":"PediatricsGPT: Large Language Models as Chinese Medical Assistants for Pediatric Applications","abstract":"Developing intelligent pediatric consultation systems offers promising prospects for improving diagnostic efficiency, especially in China, where healthcare resources are scarce. Despite recent advances in Large Language Models (LLMs) for Chinese medicine, their performance is sub-optimal in pediatric applications due to inadequate instruction data and vulnerable training procedures. To address the above issues, this paper builds PedCorpus, a high-quality dataset of over 300,000 multi-task instructions from pediatric textbooks, guidelines, and knowledge graph resources to fulfil diverse diagnostic demands. Upon well-designed PedCorpus, we propose PediatricsGPT, the first Chinese pediatric LLM assistant built on a systematic and robust training pipeline. In the continuous pre-training phase, we introduce a hybrid instruction pre-training mechanism to mitigate the internal-injected knowledge inconsistency of LLMs for medical domain adaptation. Immediately, the full-parameter Supervised Fine-Tuning (SFT) is utilized to incorporate the general medical knowledge schema into the models. After that, we devise a direct following preference optimization to enhance the generation of pediatrician-like humanistic responses. In the parameter-efficient secondary SFT phase, a mixture of universal-specific experts strategy is presented to resolve the competency conflict between medical generalist and pediatric expertise mastery. Extensive results based on the metrics, GPT-4, and doctor evaluations on distinct doctor downstream tasks show that PediatricsGPT consistently outperforms previous Chinese medical LLMs. Our model and dataset will be open-source for community development.","sentences":["Developing intelligent pediatric consultation systems offers promising prospects for improving diagnostic efficiency, especially in China, where healthcare resources are scarce.","Despite recent advances in Large Language Models (LLMs) for Chinese medicine, their performance is sub-optimal in pediatric applications due to inadequate instruction data and vulnerable training procedures.","To address the above issues, this paper builds PedCorpus, a high-quality dataset of over 300,000 multi-task instructions from pediatric textbooks, guidelines, and knowledge graph resources to fulfil diverse diagnostic demands.","Upon well-designed PedCorpus, we propose PediatricsGPT, the first Chinese pediatric LLM assistant built on a systematic and robust training pipeline.","In the continuous pre-training phase, we introduce a hybrid instruction pre-training mechanism to mitigate the internal-injected knowledge inconsistency of LLMs for medical domain adaptation.","Immediately, the full-parameter Supervised Fine-Tuning (SFT) is utilized to incorporate the general medical knowledge schema into the models.","After that, we devise a direct following preference optimization to enhance the generation of pediatrician-like humanistic responses.","In the parameter-efficient secondary SFT phase, a mixture of universal-specific experts strategy is presented to resolve the competency conflict between medical generalist and pediatric expertise mastery.","Extensive results based on the metrics, GPT-4, and doctor evaluations on distinct doctor downstream tasks show that PediatricsGPT consistently outperforms previous Chinese medical LLMs.","Our model and dataset will be open-source for community development."],"url":"http://arxiv.org/abs/2405.19266v1","category":"cs.CL"}
{"created":"2024-05-29 16:41:42","title":"Weak Generative Sampler to Efficiently Sample Invariant Distribution of Stochastic Differential Equation","abstract":"Sampling invariant distributions from an Ito diffusion process presents a significant challenge in stochastic simulation. Traditional numerical solvers for stochastic differential equations require both a fine step size and a lengthy simulation period, resulting in both biased and correlated samples. Current deep learning-based method solves the stationary Fokker--Planck equation to determine the invariant probability density function in form of deep neural networks, but they generally do not directly address the problem of sampling from the computed density function. In this work, we introduce a framework that employs a weak generative sampler (WGS) to directly generate independent and identically distributed (iid) samples induced by a transformation map derived from the stationary Fokker--Planck equation. Our proposed loss function is based on the weak form of the Fokker--Planck equation, integrating normalizing flows to characterize the invariant distribution and facilitate sample generation from the base distribution. Our randomized test function circumvents the need for mini-max optimization in the traditional weak formulation. Distinct from conventional generative models, our method neither necessitates the computationally intensive calculation of the Jacobian determinant nor the invertibility of the transformation map. A crucial component of our framework is the adaptively chosen family of test functions in the form of Gaussian kernel functions with centres selected from the generated data samples. Experimental results on several benchmark examples demonstrate the effectiveness of our method, which offers both low computational costs and excellent capability in exploring multiple metastable states.","sentences":["Sampling invariant distributions from an Ito diffusion process presents a significant challenge in stochastic simulation.","Traditional numerical solvers for stochastic differential equations require both a fine step size and a lengthy simulation period, resulting in both biased and correlated samples.","Current deep learning-based method solves the stationary Fokker--Planck equation to determine the invariant probability density function in form of deep neural networks, but they generally do not directly address the problem of sampling from the computed density function.","In this work, we introduce a framework that employs a weak generative sampler (WGS) to directly generate independent and identically distributed (iid) samples induced by a transformation map derived from the stationary Fokker--Planck equation.","Our proposed loss function is based on the weak form of the Fokker--Planck equation, integrating normalizing flows to characterize the invariant distribution and facilitate sample generation from the base distribution.","Our randomized test function circumvents the need for mini-max optimization in the traditional weak formulation.","Distinct from conventional generative models, our method neither necessitates the computationally intensive calculation of the Jacobian determinant nor the invertibility of the transformation map.","A crucial component of our framework is the adaptively chosen family of test functions in the form of Gaussian kernel functions with centres selected from the generated data samples.","Experimental results on several benchmark examples demonstrate the effectiveness of our method, which offers both low computational costs and excellent capability in exploring multiple metastable states."],"url":"http://arxiv.org/abs/2405.19256v1","category":"cs.LG"}
{"created":"2024-05-29 16:31:55","title":"Uniform Inviscid Damping and Inviscid Limit of the 2D Navier-Stokes equation with Navier Boundary Conditions","abstract":"We consider the 2D, incompressible Navier-Stokes equations near the Couette flow, $\\omega^{(NS)} = 1 + \\epsilon \\omega$, set on the channel $\\mathbb{T} \\times [-1, 1]$, supplemented with Navier boundary conditions on the perturbation, $\\omega|_{y = \\pm 1} = 0$. We are simultaneously interested in two asymptotic regimes that are classical in hydrodynamic stability: the long time, $t \\rightarrow \\infty$, stability of background shear flows, and the inviscid limit, $\\nu \\rightarrow 0$ in the presence of boundaries. Given small ($\\epsilon \\ll 1$, but independent of $\\nu$) Gevrey 2- datum, $\\omega_0^{(\\nu)}(x, y)$, that is supported away from the boundaries $y = \\pm 1$, we prove the following results: \\begin{align*} & \\|\\omega^{(\\nu)}(t) - \\frac{1}{2\\pi}\\int \\omega^{(\\nu)}(t) dx \\|_{L^2} \\lesssim \\epsilon e^{-\\delta \\nu^{1/3} t}, & \\text{(Enhanced Dissipation)} \\\\ & \\langle t \\rangle \\|u_1^{(\\nu)}(t) - \\frac{1}{2\\pi} \\int u_1^{(\\nu)}(t) dx\\|_{L^2} + \\langle t \\rangle^2 \\|u_2^{(\\nu)}(t)\\|_{L^2} \\lesssim \\epsilon e^{-\\delta \\nu^{1/3} t}, & \\text{(Inviscid Damping)} \\\\ &\\| \\omega^{(\\nu)} - \\omega^{(0)} \\|_{L^\\infty} \\lesssim \\epsilon \\nu t^{3+\\eta}, \\quad\\quad t \\lesssim \\nu^{-1/(3+\\eta)} & \\text{(Long-time Inviscid Limit)} \\end{align*} This is the first nonlinear asymptotic stability result of its type, which combines three important physical phenomena at the nonlinear level: inviscid damping, enhanced dissipation, and long-time inviscid limit in the presence of boundaries. The techniques we develop represent a major departure from prior works on nonlinear inviscid damping as physical space techniques necessarily play a central role. In this paper, we focus on the primary nonlinear result, while tools for handling the linearized parabolic and elliptic equations are developed in our separate, companion work.","sentences":["We consider the 2D, incompressible Navier-Stokes equations near the Couette flow, $\\omega^{(NS)} = 1 + \\epsilon \\omega$, set on the channel $\\mathbb{T} \\times","[-1, 1]$, supplemented with Navier boundary conditions on the perturbation, $\\omega|_{y = \\pm 1} = 0$.","We are simultaneously interested in two asymptotic regimes that are classical in hydrodynamic stability: the long time, $t \\rightarrow \\infty$, stability of background shear flows, and the inviscid limit, $\\nu \\rightarrow 0$ in the presence of boundaries.","Given small ($\\epsilon \\ll 1$, but independent of $\\nu$)","Gevrey 2- datum, $\\omega_0^{(\\nu)}(x, y)$, that is supported away from the boundaries $y = \\pm 1$, we prove the following results: \\begin{align*} & \\|\\omega^{(\\nu)}(t) - \\frac{1}{2\\pi}\\int \\omega^{(\\nu)}(t) dx \\|_{L^2} \\lesssim \\epsilon e^{-\\delta \\nu^{1/3} t}, & \\text{(Enhanced Dissipation)} \\\\ & \\langle t \\rangle \\|u_1^{(\\nu)}(t) - \\frac{1}{2\\pi} \\int u_1^{(\\nu)}(t) dx\\|_{L^2} +","\\langle t \\rangle^2 \\|u_2^{(\\nu)}(t)\\|_{L^2} \\lesssim \\epsilon e^{-\\delta \\nu^{1/3} t}, & \\text{(Inviscid Damping)} \\\\ &\\| \\omega^{(\\nu)} - \\omega^{(0)} \\|_{L^\\infty} \\lesssim \\epsilon \\nu t^{3+\\eta}, \\quad\\quad t \\lesssim \\nu^{-1/(3+\\eta)} & \\text{(Long-time Inviscid Limit)} \\end{align*} This is the first nonlinear asymptotic stability result of its type, which combines three important physical phenomena at the nonlinear level: inviscid damping, enhanced dissipation, and long-time inviscid limit in the presence of boundaries.","The techniques we develop represent a major departure from prior works on nonlinear inviscid damping as physical space techniques necessarily play a central role.","In this paper, we focus on the primary nonlinear result, while tools for handling the linearized parabolic and elliptic equations are developed in our separate, companion work."],"url":"http://arxiv.org/abs/2405.19249v1","category":"math.AP"}
{"created":"2024-05-29 16:26:57","title":"Efficient Optimal Control of Open Quantum Systems","abstract":"The optimal control problem for open quantum systems can be formulated as a time-dependent Lindbladian that is parameterized by a number of time-dependent control variables. Given an observable and an initial state, the goal is to tune the control variables so that the expected value of some observable with respect to the final state is maximized. In this paper, we present algorithms for solving this optimal control problem efficiently, i.e., having a poly-logarithmic dependency on the system dimension, which is exponentially faster than best-known classical algorithms. Our algorithms are hybrid, consisting of both quantum and classical components. The quantum procedure simulates time-dependent Lindblad evolution that drives the initial state to the final state, and it also provides access to the gradients of the objective function via quantum gradient estimation. The classical procedure uses the gradient information to update the control variables.   At the technical level, we provide the first (to the best of our knowledge) simulation algorithm for time-dependent Lindbladians with an $\\ell_1$-norm dependence. As an alternative, we also present a simulation algorithm in the interaction picture to improve the algorithm for the cases where the time-independent component of a Lindbladian dominates the time-dependent part. On the classical side, we heavily adapt the state-of-the-art classical optimization analysis to interface with the quantum part of our algorithms. Both the quantum simulation techniques and the classical optimization analyses might be of independent interest.","sentences":["The optimal control problem for open quantum systems can be formulated as a time-dependent Lindbladian that is parameterized by a number of time-dependent control variables.","Given an observable and an initial state, the goal is to tune the control variables so that the expected value of some observable with respect to the final state is maximized.","In this paper, we present algorithms for solving this optimal control problem efficiently, i.e., having a poly-logarithmic dependency on the system dimension, which is exponentially faster than best-known classical algorithms.","Our algorithms are hybrid, consisting of both quantum and classical components.","The quantum procedure simulates time-dependent Lindblad evolution that drives the initial state to the final state, and it also provides access to the gradients of the objective function via quantum gradient estimation.","The classical procedure uses the gradient information to update the control variables.   ","At the technical level, we provide the first (to the best of our knowledge) simulation algorithm for time-dependent Lindbladians with an $\\ell_1$-norm dependence.","As an alternative, we also present a simulation algorithm in the interaction picture to improve the algorithm for the cases where the time-independent component of a Lindbladian dominates the time-dependent part.","On the classical side, we heavily adapt the state-of-the-art classical optimization analysis to interface with the quantum part of our algorithms.","Both the quantum simulation techniques and the classical optimization analyses might be of independent interest."],"url":"http://arxiv.org/abs/2405.19245v1","category":"quant-ph"}
{"created":"2024-05-29 16:17:19","title":"Exploring the impact of traffic signal control and connected and automated vehicles on intersections safety: A deep reinforcement learning approach","abstract":"In transportation networks, intersections pose significant risks of collisions due to conflicting movements of vehicles approaching from different directions. To address this issue, various tools can exert influence on traffic safety both directly and indirectly. This study focuses on investigating the impact of adaptive signal control and connected and automated vehicles (CAVs) on intersection safety using a deep reinforcement learning approach. The objective is to assess the individual and combined effects of CAVs and adaptive traffic signal control on traffic safety, considering rear-end and crossing conflicts. The study employs a Deep Q Network (DQN) to regulate traffic signals and driving behaviors of both CAVs and Human Drive Vehicles (HDVs), and uses Time To Collision (TTC) metric to evaluate safety. The findings demonstrate a significant reduction in rear-end and crossing conflicts through the combined implementation of CAVs and DQNs-based traffic signal control. Additionally, the long-term positive effects of CAVs on safety are similar to the short-term effects of combined CAVs and DQNs-based traffic signal control. Overall, the study emphasizes the potential benefits of integrating CAVs and adaptive traffic signal control approaches in order to enhance traffic safety. The findings of this study could provide valuable insights for city officials and transportation authorities in developing effective strategies to improve safety at signalized intersections.","sentences":["In transportation networks, intersections pose significant risks of collisions due to conflicting movements of vehicles approaching from different directions.","To address this issue, various tools can exert influence on traffic safety both directly and indirectly.","This study focuses on investigating the impact of adaptive signal control and connected and automated vehicles (CAVs) on intersection safety using a deep reinforcement learning approach.","The objective is to assess the individual and combined effects of CAVs and adaptive traffic signal control on traffic safety, considering rear-end and crossing conflicts.","The study employs a Deep Q Network (DQN) to regulate traffic signals and driving behaviors of both CAVs and Human Drive Vehicles (HDVs), and uses Time To Collision (TTC) metric to evaluate safety.","The findings demonstrate a significant reduction in rear-end and crossing conflicts through the combined implementation of CAVs and DQNs-based traffic signal control.","Additionally, the long-term positive effects of CAVs on safety are similar to the short-term effects of combined CAVs and DQNs-based traffic signal control.","Overall, the study emphasizes the potential benefits of integrating CAVs and adaptive traffic signal control approaches in order to enhance traffic safety.","The findings of this study could provide valuable insights for city officials and transportation authorities in developing effective strategies to improve safety at signalized intersections."],"url":"http://arxiv.org/abs/2405.19236v1","category":"cs.AI"}
{"created":"2024-05-29 16:13:43","title":"Pseudo-Gevrey Smoothing for the Passive Scalar Equations near Couette","abstract":"In this article, we study the regularity theory for two linear equations that are important in fluid dynamics: the passive scalar equation for (time-varying) shear flows close to Couette in $\\mathbb T \\times [-1,1]$ with vanishing diffusivity $\\nu \\to 0$ and the Poisson equation with right-hand side behaving in similar function spaces to such a passive scalar. The primary motivation for this work is to develop some of the main technical tools required for our treatment of the (nonlinear) 2D Navier-Stokes equations, carried out in our companion work. Both equations are studied with homogeneous Dirichlet conditions (the analogue of a Navier slip-type boundary condition) and the initial condition is taken to be compactly supported away from the walls. We develop smoothing estimates with the following three features:   [1] Uniform-in-$\\nu$ regularity is with respect to $\\partial_x$ and a time-dependent adapted vector-field $\\Gamma$ which approximately commutes with the passive scalar equation (as opposed to `flat' derivatives), and a scaled gradient $\\sqrt{\\nu} \\nabla$;   [2] $(\\partial_x, \\Gamma)$-regularity estimates are performed in Gevrey spaces with regularity that depends on the spatial coordinate, $y$ (what we refer to as `pseudo-Gevrey');   [3] The regularity of these pseudo-Gevrey spaces degenerates to finite regularity near the center of the channel and hence standard Gevrey product rules and other amenable properties do not hold.   Nonlinear analysis in such a delicate functional setting is one of the key ingredients to our companion paper, \\cite{BHIW24a}, which proves the full nonlinear asymptotic stability of the Couette flow with slip boundary conditions. The present article introduces new estimates for the associated linear problems in these degenerate pseudo-Gevrey spaces, which is of independent interest.","sentences":["In this article, we study the regularity theory for two linear equations that are important in fluid dynamics: the passive scalar equation for (time-varying) shear flows close to Couette in $\\mathbb T \\times","[-1,1]$ with vanishing diffusivity $\\nu \\to 0$ and the Poisson equation with right-hand side behaving in similar function spaces to such a passive scalar.","The primary motivation for this work is to develop some of the main technical tools required for our treatment of the (nonlinear) 2D Navier-Stokes equations, carried out in our companion work.","Both equations are studied with homogeneous Dirichlet conditions (the analogue of a Navier slip-type boundary condition) and the initial condition is taken to be compactly supported away from the walls.","We develop smoothing estimates with the following three features:   ","[1] Uniform-in-$\\nu$ regularity is with respect to $\\partial_x$ and a time-dependent adapted vector-field $\\Gamma$ which approximately commutes with the passive scalar equation (as opposed to `flat' derivatives), and a scaled gradient $\\sqrt{\\nu} \\nabla$;   [2] $(\\partial_x, \\Gamma)$-regularity estimates are performed in Gevrey spaces with regularity that depends on the spatial coordinate, $y$ (what we refer to as `pseudo-Gevrey');   ","[3] The regularity of these pseudo-Gevrey spaces degenerates to finite regularity near the center of the channel and hence standard Gevrey product rules and other amenable properties do not hold.   ","Nonlinear analysis in such a delicate functional setting is one of the key ingredients to our companion paper, \\cite{BHIW24a}, which proves the full nonlinear asymptotic stability of the Couette flow with slip boundary conditions.","The present article introduces new estimates for the associated linear problems in these degenerate pseudo-Gevrey spaces, which is of independent interest."],"url":"http://arxiv.org/abs/2405.19233v1","category":"math.AP"}
{"created":"2024-05-29 16:12:14","title":"DiPPeST: Diffusion-based Path Planner for Synthesizing Trajectories Applied on Quadruped Robots","abstract":"We present DiPPeST, a novel image and goal conditioned diffusion-based trajectory generator for quadrupedal robot path planning. DiPPeST is a zero-shot adaptation of our previously introduced diffusion-based 2D global trajectory generator (DiPPeR). The introduced system incorporates a novel strategy for local real-time path refinements, that is reactive to camera input, without requiring any further training, image processing, or environment interpretation techniques. DiPPeST achieves 92% success rate in obstacle avoidance for nominal environments and an average of 88% success rate when tested in environments that are up to 3.5 times more complex in pixel variation than DiPPeR. A visual-servoing framework is developed to allow for real-world execution, tested on the quadruped robot, achieving 80% success rate in different environments and showcasing improved behavior than complex state-of-the-art local planners, in narrow environments.","sentences":["We present DiPPeST, a novel image and goal conditioned diffusion-based trajectory generator for quadrupedal robot path planning.","DiPPeST is a zero-shot adaptation of our previously introduced diffusion-based 2D global trajectory generator (DiPPeR).","The introduced system incorporates a novel strategy for local real-time path refinements, that is reactive to camera input, without requiring any further training, image processing, or environment interpretation techniques.","DiPPeST achieves 92% success rate in obstacle avoidance for nominal environments and an average of 88% success rate when tested in environments that are up to 3.5 times more complex in pixel variation than DiPPeR.","A visual-servoing framework is developed to allow for real-world execution, tested on the quadruped robot, achieving 80% success rate in different environments and showcasing improved behavior than complex state-of-the-art local planners, in narrow environments."],"url":"http://arxiv.org/abs/2405.19232v1","category":"cs.RO"}
{"created":"2024-05-29 16:08:15","title":"Covariate Shift Corrected Conditional Randomization Test","abstract":"Conditional independence tests are crucial across various disciplines in determining the independence of an outcome variable $Y$ from a treatment variable $X$, conditioning on a set of confounders $Z$. The Conditional Randomization Test (CRT) offers a powerful framework for such testing by assuming known distributions of $X \\mid Z$; it controls the Type-I error exactly, allowing for the use of flexible, black-box test statistics. In practice, testing for conditional independence often involves using data from a source population to draw conclusions about a target population. This can be challenging due to covariate shift -- differences in the distribution of $X$, $Z$, and surrogate variables, which can affect the conditional distribution of $Y \\mid X, Z$ -- rendering traditional CRT approaches invalid. To address this issue, we propose a novel Covariate Shift Corrected Pearson Chi-squared Conditional Randomization (csPCR) test. This test adapts to covariate shifts by integrating importance weights and employing the control variates method to reduce variance in the test statistics and thus enhance power. Theoretically, we establish that the csPCR test controls the Type-I error asymptotically. Empirically, through simulation studies, we demonstrate that our method not only maintains control over Type-I errors but also exhibits superior power, confirming its efficacy and practical utility in real-world scenarios where covariate shifts are prevalent. Finally, we apply our methodology to a real-world dataset to assess the impact of a COVID-19 treatment on the 90-day mortality rate among patients.","sentences":["Conditional independence tests are crucial across various disciplines in determining the independence of an outcome variable $Y$ from a treatment variable $X$, conditioning on a set of confounders $Z$. The Conditional Randomization Test (CRT) offers a powerful framework for such testing by assuming known distributions of $X \\mid Z$; it controls the Type-I error exactly, allowing for the use of flexible, black-box test statistics.","In practice, testing for conditional independence often involves using data from a source population to draw conclusions about a target population.","This can be challenging due to covariate shift -- differences in the distribution of $X$, $Z$, and surrogate variables, which can affect the conditional distribution of $Y \\mid X, Z$ -- rendering traditional CRT approaches invalid.","To address this issue, we propose a novel Covariate Shift Corrected Pearson Chi-squared Conditional Randomization (csPCR) test.","This test adapts to covariate shifts by integrating importance weights and employing the control variates method to reduce variance in the test statistics and thus enhance power.","Theoretically, we establish that the csPCR test controls the Type-I error asymptotically.","Empirically, through simulation studies, we demonstrate that our method not only maintains control over Type-I errors but also exhibits superior power, confirming its efficacy and practical utility in real-world scenarios where covariate shifts are prevalent.","Finally, we apply our methodology to a real-world dataset to assess the impact of a COVID-19 treatment on the 90-day mortality rate among patients."],"url":"http://arxiv.org/abs/2405.19231v1","category":"stat.ME"}
{"created":"2024-05-29 16:06:21","title":"ContextBLIP: Doubly Contextual Alignment for Contrastive Image Retrieval from Linguistically Complex Descriptions","abstract":"Image retrieval from contextual descriptions (IRCD) aims to identify an image within a set of minimally contrastive candidates based on linguistically complex text. Despite the success of VLMs, they still significantly lag behind human performance in IRCD. The main challenges lie in aligning key contextual cues in two modalities, where these subtle cues are concealed in tiny areas of multiple contrastive images and within the complex linguistics of textual descriptions. This motivates us to propose ContextBLIP, a simple yet effective method that relies on a doubly contextual alignment scheme for challenging IRCD. Specifically, 1) our model comprises a multi-scale adapter, a matching loss, and a text-guided masking loss. The adapter learns to capture fine-grained visual cues. The two losses enable iterative supervision for the adapter, gradually highlighting the focal patches of a single image to the key textual cues. We term such a way as intra-contextual alignment. 2) Then, ContextBLIP further employs an inter-context encoder to learn dependencies among candidates, facilitating alignment between the text to multiple images. We term this step as inter-contextual alignment. Consequently, the nuanced cues concealed in each modality can be effectively aligned. Experiments on two benchmarks show the superiority of our method. We observe that ContextBLIP can yield comparable results with GPT-4V, despite involving about 7,500 times fewer parameters.","sentences":["Image retrieval from contextual descriptions (IRCD) aims to identify an image within a set of minimally contrastive candidates based on linguistically complex text.","Despite the success of VLMs, they still significantly lag behind human performance in IRCD.","The main challenges lie in aligning key contextual cues in two modalities, where these subtle cues are concealed in tiny areas of multiple contrastive images and within the complex linguistics of textual descriptions.","This motivates us to propose ContextBLIP, a simple yet effective method that relies on a doubly contextual alignment scheme for challenging IRCD.","Specifically, 1) our model comprises a multi-scale adapter, a matching loss, and a text-guided masking loss.","The adapter learns to capture fine-grained visual cues.","The two losses enable iterative supervision for the adapter, gradually highlighting the focal patches of a single image to the key textual cues.","We term such a way as intra-contextual alignment.","2) Then, ContextBLIP further employs an inter-context encoder to learn dependencies among candidates, facilitating alignment between the text to multiple images.","We term this step as inter-contextual alignment.","Consequently, the nuanced cues concealed in each modality can be effectively aligned.","Experiments on two benchmarks show the superiority of our method.","We observe that ContextBLIP can yield comparable results with GPT-4V, despite involving about 7,500 times fewer parameters."],"url":"http://arxiv.org/abs/2405.19226v1","category":"cs.CV"}
{"created":"2024-05-29 16:01:15","title":"Domain adaptation in small-scale and heterogeneous biological datasets","abstract":"Machine learning techniques are steadily becoming more important in modern biology, and are used to build predictive models, discover patterns, and investigate biological problems. However, models trained on one dataset are often not generalizable to other datasets from different cohorts or laboratories, due to differences in the statistical properties of these datasets. These could stem from technical differences, such as the measurement technique used, or from relevant biological differences between the populations studied. Domain adaptation, a type of transfer learning, can alleviate this problem by aligning the statistical distributions of features and samples among different datasets so that similar models can be applied across them. However, a majority of state-of-the-art domain adaptation methods are designed to work with large-scale data, mostly text and images, while biological datasets often suffer from small sample sizes, and possess complexities such as heterogeneity of the feature space. This Review aims to synthetically discuss domain adaptation methods in the context of small-scale and highly heterogeneous biological data. We describe the benefits and challenges of domain adaptation in biological research and critically discuss some of its objectives, strengths, and weaknesses through key representative methodologies. We argue for the incorporation of domain adaptation techniques to the computational biologist's toolkit, with further development of customized approaches.","sentences":["Machine learning techniques are steadily becoming more important in modern biology, and are used to build predictive models, discover patterns, and investigate biological problems.","However, models trained on one dataset are often not generalizable to other datasets from different cohorts or laboratories, due to differences in the statistical properties of these datasets.","These could stem from technical differences, such as the measurement technique used, or from relevant biological differences between the populations studied.","Domain adaptation, a type of transfer learning, can alleviate this problem by aligning the statistical distributions of features and samples among different datasets so that similar models can be applied across them.","However, a majority of state-of-the-art domain adaptation methods are designed to work with large-scale data, mostly text and images, while biological datasets often suffer from small sample sizes, and possess complexities such as heterogeneity of the feature space.","This Review aims to synthetically discuss domain adaptation methods in the context of small-scale and highly heterogeneous biological data.","We describe the benefits and challenges of domain adaptation in biological research and critically discuss some of its objectives, strengths, and weaknesses through key representative methodologies.","We argue for the incorporation of domain adaptation techniques to the computational biologist's toolkit, with further development of customized approaches."],"url":"http://arxiv.org/abs/2405.19221v1","category":"q-bio.QM"}
{"created":"2024-05-29 15:56:36","title":"Compactly supported anomalous weak solutions for 2D Euler equations with vorticity in Hardy spaces","abstract":"In a previous work (arXiv:2306.05948), we constructed by convex integration examples of energy dissipating solutions to the 2D Euler equations on $\\mathbb{R}^2$ with vorticity in the real Hardy space $H^p(\\mathbb{R}^2)$. In the present paper, we develop tools that significantly improve that result in two ways: Firstly, we achieve vorticities in $H^p(\\mathbb{R}^2)$ in the optimal range $p\\in (0,1)$ compared to $(2/3,1)$ in our previous work. Secondly, the solutions constructed here possess compact support and in particular preserve linear and angular momenta.","sentences":["In a previous work (arXiv:2306.05948), we constructed by convex integration examples of energy dissipating solutions to the 2D Euler equations on $\\mathbb{R}^2$ with vorticity in the real Hardy space $H^p(\\mathbb{R}^2)$. In the present paper, we develop tools that significantly improve that result in two ways: Firstly, we achieve vorticities in $H^p(\\mathbb{R}^2)$ in the optimal range $p\\in (0,1)$ compared to $(2/3,1)$ in our previous work.","Secondly, the solutions constructed here possess compact support and in particular preserve linear and angular momenta."],"url":"http://arxiv.org/abs/2405.19214v1","category":"math.AP"}
{"created":"2024-05-29 15:49:09","title":"VideoTree: Adaptive Tree-based Video Representation for LLM Reasoning on Long Videos","abstract":"Video-language understanding tasks have focused on short video clips, often struggling with long-form video understanding tasks. Recently, many long video-language understanding approaches have leveraged the reasoning capabilities of Large Language Models (LLMs) to perform long video QA, transforming videos into densely sampled frame captions, and asking LLMs to respond to text queries over captions. However, the frames used for captioning are often redundant and contain irrelevant information, making dense sampling inefficient, and ignoring the fact that video QA requires varying levels of granularity, with some video segments being highly relevant to the question (needing more fine-grained detail) while others being less relevant. Thus, these LLM-based approaches are prone to missing information and operate on large numbers of irrelevant captions, lowering both performance and efficiency. To address these issues, we introduce VideoTree, a query-adaptive and hierarchical framework for long-video understanding with LLMs. VideoTree dynamically extracts query-related information from a video and builds a tree-based representation for LLM reasoning. First, VideoTree adaptively selects frames for captioning by iteratively clustering frames based on their visual features and scoring clusters using their relevance to the query. Second, it organizes visual clusters into a query-adaptive and hierarchical tree structure; the tree encodes varying levels of granularity, with higher resolution on relevant segments. Finally, VideoTree produces an answer by traversing the tree's keyframes and passing their captions to an LLM answerer. Our method improves both reasoning accuracy and efficiency compared to existing methods: VideoTree achieves a 7.0%, 2.2%, and 2.7% accuracy gain over baselines on the EgoSchema, NExT-QA, and IntentQA benchmarks, respectively, while reducing inference time by 40%.","sentences":["Video-language understanding tasks have focused on short video clips, often struggling with long-form video understanding tasks.","Recently, many long video-language understanding approaches have leveraged the reasoning capabilities of Large Language Models (LLMs) to perform long video QA, transforming videos into densely sampled frame captions, and asking LLMs to respond to text queries over captions.","However, the frames used for captioning are often redundant and contain irrelevant information, making dense sampling inefficient, and ignoring the fact that video QA requires varying levels of granularity, with some video segments being highly relevant to the question (needing more fine-grained detail) while others being less relevant.","Thus, these LLM-based approaches are prone to missing information and operate on large numbers of irrelevant captions, lowering both performance and efficiency.","To address these issues, we introduce VideoTree, a query-adaptive and hierarchical framework for long-video understanding with LLMs.","VideoTree dynamically extracts query-related information from a video and builds a tree-based representation for LLM reasoning.","First, VideoTree adaptively selects frames for captioning by iteratively clustering frames based on their visual features and scoring clusters using their relevance to the query.","Second, it organizes visual clusters into a query-adaptive and hierarchical tree structure; the tree encodes varying levels of granularity, with higher resolution on relevant segments.","Finally, VideoTree produces an answer by traversing the tree's keyframes and passing their captions to an LLM answerer.","Our method improves both reasoning accuracy and efficiency compared to existing methods: VideoTree achieves a 7.0%, 2.2%, and 2.7% accuracy gain over baselines on the EgoSchema, NExT-QA, and IntentQA benchmarks, respectively, while reducing inference time by 40%."],"url":"http://arxiv.org/abs/2405.19209v1","category":"cs.CV"}
{"created":"2024-05-29 15:44:51","title":"Contrastive-Adversarial and Diffusion: Exploring pre-training and fine-tuning strategies for sulcal identification","abstract":"In the last decade, computer vision has witnessed the establishment of various training and learning approaches. Techniques like adversarial learning, contrastive learning, diffusion denoising learning, and ordinary reconstruction learning have become standard, representing state-of-the-art methods extensively employed for fully training or pre-training networks across various vision tasks. The exploration of fine-tuning approaches has emerged as a current focal point, addressing the need for efficient model tuning with reduced GPU memory usage and time costs while enhancing overall performance, as exemplified by methodologies like low-rank adaptation (LoRA). Key questions arise: which pre-training technique yields optimal results - adversarial, contrastive, reconstruction, or diffusion denoising? How does the performance of these approaches vary as the complexity of fine-tuning is adjusted? This study aims to elucidate the advantages of pre-training techniques and fine-tuning strategies to enhance the learning process of neural networks in independent identical distribution (IID) cohorts. We underscore the significance of fine-tuning by examining various cases, including full tuning, decoder tuning, top-level tuning, and fine-tuning of linear parameters using LoRA. Systematic summaries of model performance and efficiency are presented, leveraging metrics such as accuracy, time cost, and memory efficiency. To empirically demonstrate our findings, we focus on a multi-task segmentation-classification challenge involving the paracingulate sulcus (PCS) using different 3D Convolutional Neural Network (CNN) architectures by using the TOP-OSLO cohort comprising 596 subjects.","sentences":["In the last decade, computer vision has witnessed the establishment of various training and learning approaches.","Techniques like adversarial learning, contrastive learning, diffusion denoising learning, and ordinary reconstruction learning have become standard, representing state-of-the-art methods extensively employed for fully training or pre-training networks across various vision tasks.","The exploration of fine-tuning approaches has emerged as a current focal point, addressing the need for efficient model tuning with reduced GPU memory usage and time costs while enhancing overall performance, as exemplified by methodologies like low-rank adaptation (LoRA).","Key questions arise: which pre-training technique yields optimal results - adversarial, contrastive, reconstruction, or diffusion denoising?","How does the performance of these approaches vary as the complexity of fine-tuning is adjusted?","This study aims to elucidate the advantages of pre-training techniques and fine-tuning strategies to enhance the learning process of neural networks in independent identical distribution (IID) cohorts.","We underscore the significance of fine-tuning by examining various cases, including full tuning, decoder tuning, top-level tuning, and fine-tuning of linear parameters using LoRA.","Systematic summaries of model performance and efficiency are presented, leveraging metrics such as accuracy, time cost, and memory efficiency.","To empirically demonstrate our findings, we focus on a multi-task segmentation-classification challenge involving the paracingulate sulcus (PCS) using different 3D Convolutional Neural Network (CNN) architectures by using the TOP-OSLO cohort comprising 596 subjects."],"url":"http://arxiv.org/abs/2405.19204v1","category":"eess.IV"}
{"created":"2024-05-29 15:14:28","title":"Greedy Kernel Methods for Approximating Breakthrough Curves for Reactive Flow from 3D Porous Geometry Data","abstract":"We address the challenging application of 3D pore scale reactive flow under varying geometry parameters. The task is to predict time-dependent integral quantities, i.e., breakthrough curves, from the given geometries. As the 3D reactive flow simulation is highly complex and computationally expensive, we are interested in data-based surrogates that can give a rapid prediction of the target quantities of interest. This setting is an example of an application with scarce data, i.e., only having available few data samples, while the input and output dimensions are high. In this scarce data setting, standard machine learning methods are likely to ail. Therefore, we resort to greedy kernel approximation schemes that have shown to be efficient meshless approximation techniques for multivariate functions. We demonstrate that such methods can efficiently be used in the high-dimensional input/output case under scarce data. Especially, we show that the vectorial kernel orthogonal greedy approximation (VKOGA) procedure with a data-adapted two-layer kernel yields excellent predictors for learning from 3D geometry voxel data via both morphological descriptors or principal component analysis.","sentences":["We address the challenging application of 3D pore scale reactive flow under varying geometry parameters.","The task is to predict time-dependent integral quantities, i.e., breakthrough curves, from the given geometries.","As the 3D reactive flow simulation is highly complex and computationally expensive, we are interested in data-based surrogates that can give a rapid prediction of the target quantities of interest.","This setting is an example of an application with scarce data, i.e., only having available few data samples, while the input and output dimensions are high.","In this scarce data setting, standard machine learning methods are likely to ail.","Therefore, we resort to greedy kernel approximation schemes that have shown to be efficient meshless approximation techniques for multivariate functions.","We demonstrate that such methods can efficiently be used in the high-dimensional input/output case under scarce data.","Especially, we show that the vectorial kernel orthogonal greedy approximation (VKOGA) procedure with a data-adapted two-layer kernel yields excellent predictors for learning from 3D geometry voxel data via both morphological descriptors or principal component analysis."],"url":"http://arxiv.org/abs/2405.19170v1","category":"math.NA"}
{"created":"2024-05-29 14:40:24","title":"A quantum implementation of high-order power method for estimating geometric entanglement of pure states","abstract":"Entanglement is one of the fundamental properties of a quantum state and is a crucial differentiator between classical and quantum computation. There are many ways to define entanglement and its measure, depending on the problem or application under consideration. Each of these measures may be computed or approximated by multiple methods. However, hardly any of these methods can be run on near-term quantum hardware. This work presents a quantum adaptation of the iterative higher-order power method for estimating the geometric measure of entanglement of multi-qubit pure states using rank-1 tensor approximation. This method is executable on current (hybrid) quantum hardware and does not depend on quantum memory. We study the effect of noise on the algorithm using a simple theoretical model based on the standard depolarising channel. This model allows us to post hoc mitigate the effects of noise on the results of the computation.","sentences":["Entanglement is one of the fundamental properties of a quantum state and is a crucial differentiator between classical and quantum computation.","There are many ways to define entanglement and its measure, depending on the problem or application under consideration.","Each of these measures may be computed or approximated by multiple methods.","However, hardly any of these methods can be run on near-term quantum hardware.","This work presents a quantum adaptation of the iterative higher-order power method for estimating the geometric measure of entanglement of multi-qubit pure states using rank-1 tensor approximation.","This method is executable on current (hybrid) quantum hardware and does not depend on quantum memory.","We study the effect of noise on the algorithm using a simple theoretical model based on the standard depolarising channel.","This model allows us to post hoc mitigate the effects of noise on the results of the computation."],"url":"http://arxiv.org/abs/2405.19134v1","category":"quant-ph"}
{"created":"2024-05-29 14:37:48","title":"Learning Interpretable Scheduling Algorithms for Data Processing Clusters","abstract":"Workloads in data processing clusters are often represented in the form of DAG (Directed Acyclic Graph) jobs. Scheduling DAG jobs is challenging. Simple heuristic scheduling algorithms are often adopted in practice in production data centres. There is much room for scheduling performance optimisation for cost saving. Recently, reinforcement learning approaches (like decima) have been attempted to optimise DAG job scheduling and demonstrate clear performance gain in comparison to traditional algorithms. However, reinforcement learning (RL) approaches face their own problems in real-world deployment. In particular, their black-box decision making processes and generalizability in unseen workloads may add a non-trivial burden to the cluster administrators. Moreover, adapting RL models on unseen workloads often requires significant amount of training data, which leaves edge cases run in a sub-optimal mode. To fill the gap, we propose a new method to distill a simple scheduling policy based on observations of the behaviours of a complex deep learning model. The simple model not only provides interpretability of scheduling decisions, but also adaptive to edge cases easily through tuning. We show that our method achieves high fidelity to the decisions made by deep learning models and outperforms these models when additional heuristics are taken into account.","sentences":["Workloads in data processing clusters are often represented in the form of DAG (Directed Acyclic Graph) jobs.","Scheduling DAG jobs is challenging.","Simple heuristic scheduling algorithms are often adopted in practice in production data centres.","There is much room for scheduling performance optimisation for cost saving.","Recently, reinforcement learning approaches (like decima) have been attempted to optimise DAG job scheduling and demonstrate clear performance gain in comparison to traditional algorithms.","However, reinforcement learning (RL) approaches face their own problems in real-world deployment.","In particular, their black-box decision making processes and generalizability in unseen workloads may add a non-trivial burden to the cluster administrators.","Moreover, adapting RL models on unseen workloads often requires significant amount of training data, which leaves edge cases run in a sub-optimal mode.","To fill the gap, we propose a new method to distill a simple scheduling policy based on observations of the behaviours of a complex deep learning model.","The simple model not only provides interpretability of scheduling decisions, but also adaptive to edge cases easily through tuning.","We show that our method achieves high fidelity to the decisions made by deep learning models and outperforms these models when additional heuristics are taken into account."],"url":"http://arxiv.org/abs/2405.19131v1","category":"cs.DC"}
{"created":"2024-05-29 14:31:39","title":"Early Detection of Critical Urban Events using Mobile Phone Network Data","abstract":"Network Signalling Data (NSD) have the potential to provide continuous spatio-temporal information about the presence, mobility, and usage patterns of cell phone services by individuals. Such information is invaluable for monitoring large urban areas and supporting the implementation of decision-making services. When analyzed in real time, NSD can enable the early detection of critical urban events, including fires, large accidents, stampedes, terrorist attacks, and sports and leisure gatherings, especially if these events significantly impact mobile phone network activity in the affected areas. This paper presents empirical evidence that advanced NSD can detect anomalies in mobile traffic service consumption, attributable to critical urban events, with fine spatial and temporal resolutions. We introduce two methodologies for real-time anomaly detection from multivariate time series extracted from large-scale NSD, utilizing a range of algorithms adapted from the state-of-the-art in unsupervised machine learning techniques for anomaly detection. Our research includes a comprehensive quantitative evaluation of these algorithms on a large-scale dataset of NSD service consumption for the Paris region. The evaluation uses an original dataset of documented critical or unusual urban events. This dataset has been built as a ground truth basis for assessing the algorithms performance. The obtained results demonstrate that our framework can detect unusual events almost instantaneously and locate the affected areas with high precision, largely outperforming random classifiers. This efficiency and effectiveness underline the potential of NSD-based anomaly detection in significantly enhancing emergency response strategies and urban planning.","sentences":["Network Signalling Data (NSD) have the potential to provide continuous spatio-temporal information about the presence, mobility, and usage patterns of cell phone services by individuals.","Such information is invaluable for monitoring large urban areas and supporting the implementation of decision-making services.","When analyzed in real time, NSD can enable the early detection of critical urban events, including fires, large accidents, stampedes, terrorist attacks, and sports and leisure gatherings, especially if these events significantly impact mobile phone network activity in the affected areas.","This paper presents empirical evidence that advanced NSD can detect anomalies in mobile traffic service consumption, attributable to critical urban events, with fine spatial and temporal resolutions.","We introduce two methodologies for real-time anomaly detection from multivariate time series extracted from large-scale NSD, utilizing a range of algorithms adapted from the state-of-the-art in unsupervised machine learning techniques for anomaly detection.","Our research includes a comprehensive quantitative evaluation of these algorithms on a large-scale dataset of NSD service consumption for the Paris region.","The evaluation uses an original dataset of documented critical or unusual urban events.","This dataset has been built as a ground truth basis for assessing the algorithms performance.","The obtained results demonstrate that our framework can detect unusual events almost instantaneously and locate the affected areas with high precision, largely outperforming random classifiers.","This efficiency and effectiveness underline the potential of NSD-based anomaly detection in significantly enhancing emergency response strategies and urban planning."],"url":"http://arxiv.org/abs/2405.19125v1","category":"cs.CY"}
{"created":"2024-05-29 14:28:17","title":"Apparent horizon tracking in supercritical solutions of the Einstein-scalar field equations in spherical symmetry in affine-null coordinates","abstract":"Choptuik's critical phenomena in general relativity is revisited in the affine-null metric formulation of Einstein's equations for a massless scalar field in spherical symmetry. Numerical solutions are obtained by evolution of initial data using pseudo-spectral methods. The underlying system consists of differential equations along the outgoing null rays which can be solved in sequential form. A new two-parameter family of initial data is presented for which these equations can be integrated analytically. Specific choices of the initial data parameters correspond to either an asymptotically flat null cone, a black hole event horizon or the singular interior of a black hole. Our main focus is on the interior features of a black hole, for which the affine-null system is especially well adapted. We present both analytic and numerical results describing the geometric properties of the apparent horizon and final singularity. Using a re-gridding technique for the affine parameter, numerical evolution of initially asymptotically flat supercritical data can be continued inside the event horizon and track the apparent horizon up to the formation of the final singularity.","sentences":["Choptuik's critical phenomena in general relativity is revisited in the affine-null metric formulation of Einstein's equations for a massless scalar field in spherical symmetry.","Numerical solutions are obtained by evolution of initial data using pseudo-spectral methods.","The underlying system consists of differential equations along the outgoing null rays which can be solved in sequential form.","A new two-parameter family of initial data is presented for which these equations can be integrated analytically.","Specific choices of the initial data parameters correspond to either an asymptotically flat null cone, a black hole event horizon or the singular interior of a black hole.","Our main focus is on the interior features of a black hole, for which the affine-null system is especially well adapted.","We present both analytic and numerical results describing the geometric properties of the apparent horizon and final singularity.","Using a re-gridding technique for the affine parameter, numerical evolution of initially asymptotically flat supercritical data can be continued inside the event horizon and track the apparent horizon up to the formation of the final singularity."],"url":"http://arxiv.org/abs/2405.19122v1","category":"gr-qc"}
{"created":"2024-05-29 14:24:35","title":"MHD simulations of the space weather in Proxima b: Habitability conditions and radio emission","abstract":"The habitability of exoplanets hosted by M-dwarf stars dramatically depends on their space weather. We present 3D magneto-hydrodynamic simulations to characterise the magneto-plasma environment and thus the habitability of the Earth-like planet Proxima b when it is subject to both calm and extreme (CME-like) space weather conditions. We study the role of the stellar wind and planetary magnetic field, and determine the radio emission arising from the interaction between the stellar wind of Proxima and the magnetosphere of its planet Proxima b. We find that if Prox b has a magnetic field similar to that of the Earth ($B_{\\rm p} = B_\\oplus \\approx 0.32$ G) or larger, the magnetopause standoff distance is large enough to shield the surface from the stellar wind for essentially any planetary tilt but the most extreme values (close to $90^{\\circ} $), under a calm space weather. Even if Proxima b is subject to more extreme space weather conditions, the planet is well shielded by an Earth-like magnetosphere ($B_{\\rm p} \\approx B_\\oplus$; $ \\approx 23.5^{\\circ}$), or if it has tilt smaller than that of the Earth. For calm space weather conditions, the radio emission caused by the day-side reconnection regions can be as high as 7$\\times10^{19}$ erg s$^{-1}$ in the super-Alfv\\'enic regime, and is on average almost an order of magnitude larger than the radio emission in the sub-Alfv\\'enic cases, due to the much larger contribution of the bow shock. We also find that the energy dissipation at the bow shock is independent of the angle between the planet's magnetic dipole and the incident stellar wind flow. If Prox b is subject to extreme space weather conditions, the radio emission is more than two orders of magnitude larger than under calm space weather conditions. This result yields expectations for a direct detection--from Earth--in radio of giant planets in close-in orbits.","sentences":["The habitability of exoplanets hosted by M-dwarf stars dramatically depends on their space weather.","We present 3D magneto-hydrodynamic simulations to characterise the magneto-plasma environment and thus the habitability of the Earth-like planet Proxima b when it is subject to both calm and extreme (CME-like) space weather conditions.","We study the role of the stellar wind and planetary magnetic field, and determine the radio emission arising from the interaction between the stellar wind of Proxima and the magnetosphere of its planet Proxima b.","We find that if Prox b has a magnetic field similar to that of the Earth ($B_{\\rm p} =","B_\\oplus","\\approx 0.32$ G) or larger, the magnetopause standoff distance is large enough to shield the surface from the stellar wind for essentially any planetary tilt but the most extreme values (close to $90^{\\circ} $), under a calm space weather.","Even if Proxima b is subject to more extreme space weather conditions, the planet is well shielded by an Earth-like magnetosphere ($B_{\\rm p} \\approx B_\\oplus$; $ \\approx 23.5^{\\circ}$), or if it has tilt smaller than that of the Earth.","For calm space weather conditions, the radio emission caused by the day-side reconnection regions can be as high as 7$\\times10^{19}$ erg s$^{-1}$ in the super-Alfv\\'enic regime, and is on average almost an order of magnitude larger than the radio emission in the sub-Alfv\\'enic cases, due to the much larger contribution of the bow shock.","We also find that the energy dissipation at the bow shock is independent of the angle between the planet's magnetic dipole and the incident stellar wind flow.","If Prox b is subject to extreme space weather conditions, the radio emission is more than two orders of magnitude larger than under calm space weather conditions.","This result yields expectations for a direct detection--from Earth--in radio of giant planets in close-in orbits."],"url":"http://arxiv.org/abs/2405.19116v1","category":"astro-ph.EP"}
{"created":"2024-05-29 14:07:44","title":"Voice Jailbreak Attacks Against GPT-4o","abstract":"Recently, the concept of artificial assistants has evolved from science fiction into real-world applications. GPT-4o, the newest multimodal large language model (MLLM) across audio, vision, and text, has further blurred the line between fiction and reality by enabling more natural human-computer interactions. However, the advent of GPT-4o's voice mode may also introduce a new attack surface. In this paper, we present the first systematic measurement of jailbreak attacks against the voice mode of GPT-4o. We show that GPT-4o demonstrates good resistance to forbidden questions and text jailbreak prompts when directly transferring them to voice mode. This resistance is primarily due to GPT-4o's internal safeguards and the difficulty of adapting text jailbreak prompts to voice mode. Inspired by GPT-4o's human-like behaviors, we propose VoiceJailbreak, a novel voice jailbreak attack that humanizes GPT-4o and attempts to persuade it through fictional storytelling (setting, character, and plot). VoiceJailbreak is capable of generating simple, audible, yet effective jailbreak prompts, which significantly increases the average attack success rate (ASR) from 0.033 to 0.778 in six forbidden scenarios. We also conduct extensive experiments to explore the impacts of interaction steps, key elements of fictional writing, and different languages on VoiceJailbreak's effectiveness and further enhance the attack performance with advanced fictional writing techniques. We hope our study can assist the research community in building more secure and well-regulated MLLMs.","sentences":["Recently, the concept of artificial assistants has evolved from science fiction into real-world applications.","GPT-4o, the newest multimodal large language model (MLLM) across audio, vision, and text, has further blurred the line between fiction and reality by enabling more natural human-computer interactions.","However, the advent of GPT-4o's voice mode may also introduce a new attack surface.","In this paper, we present the first systematic measurement of jailbreak attacks against the voice mode of GPT-4o.","We show that GPT-4o demonstrates good resistance to forbidden questions and text jailbreak prompts when directly transferring them to voice mode.","This resistance is primarily due to GPT-4o's internal safeguards and the difficulty of adapting text jailbreak prompts to voice mode.","Inspired by GPT-4o's human-like behaviors, we propose VoiceJailbreak, a novel voice jailbreak attack that humanizes GPT-4o and attempts to persuade it through fictional storytelling (setting, character, and plot).","VoiceJailbreak is capable of generating simple, audible, yet effective jailbreak prompts, which significantly increases the average attack success rate (ASR) from 0.033 to 0.778 in six forbidden scenarios.","We also conduct extensive experiments to explore the impacts of interaction steps, key elements of fictional writing, and different languages on VoiceJailbreak's effectiveness and further enhance the attack performance with advanced fictional writing techniques.","We hope our study can assist the research community in building more secure and well-regulated MLLMs."],"url":"http://arxiv.org/abs/2405.19103v1","category":"cs.CR"}
{"created":"2024-05-29 14:05:16","title":"Efficient Black-box Adversarial Attacks via Bayesian Optimization Guided by a Function Prior","abstract":"This paper studies the challenging black-box adversarial attack that aims to generate adversarial examples against a black-box model by only using output feedback of the model to input queries. Some previous methods improve the query efficiency by incorporating the gradient of a surrogate white-box model into query-based attacks due to the adversarial transferability. However, the localized gradient is not informative enough, making these methods still query-intensive. In this paper, we propose a Prior-guided Bayesian Optimization (P-BO) algorithm that leverages the surrogate model as a global function prior in black-box adversarial attacks. As the surrogate model contains rich prior information of the black-box one, P-BO models the attack objective with a Gaussian process whose mean function is initialized as the surrogate model's loss. Our theoretical analysis on the regret bound indicates that the performance of P-BO may be affected by a bad prior. Therefore, we further propose an adaptive integration strategy to automatically adjust a coefficient on the function prior by minimizing the regret bound. Extensive experiments on image classifiers and large vision-language models demonstrate the superiority of the proposed algorithm in reducing queries and improving attack success rates compared with the state-of-the-art black-box attacks. Code is available at https://github.com/yibo-miao/PBO-Attack.","sentences":["This paper studies the challenging black-box adversarial attack that aims to generate adversarial examples against a black-box model by only using output feedback of the model to input queries.","Some previous methods improve the query efficiency by incorporating the gradient of a surrogate white-box model into query-based attacks due to the adversarial transferability.","However, the localized gradient is not informative enough, making these methods still query-intensive.","In this paper, we propose a Prior-guided Bayesian Optimization (P-BO) algorithm that leverages the surrogate model as a global function prior in black-box adversarial attacks.","As the surrogate model contains rich prior information of the black-box one, P-BO models the attack objective with a Gaussian process whose mean function is initialized as the surrogate model's loss.","Our theoretical analysis on the regret bound indicates that the performance of P-BO may be affected by a bad prior.","Therefore, we further propose an adaptive integration strategy to automatically adjust a coefficient on the function prior by minimizing the regret bound.","Extensive experiments on image classifiers and large vision-language models demonstrate the superiority of the proposed algorithm in reducing queries and improving attack success rates compared with the state-of-the-art black-box attacks.","Code is available at https://github.com/yibo-miao/PBO-Attack."],"url":"http://arxiv.org/abs/2405.19098v1","category":"cs.LG"}
{"created":"2024-05-29 13:49:44","title":"MEMoE: Enhancing Model Editing with Mixture of Experts Adaptors","abstract":"Model editing aims to efficiently alter the behavior of Large Language Models (LLMs) within a desired scope, while ensuring no adverse impact on other inputs. Recent years have witnessed various model editing methods been proposed. However, these methods either exhibit poor overall performance or struggle to strike a balance between generalization and locality. We propose MOMoE, a model editing adapter utilizing a Mixture of Experts (MoE) architecture with a knowledge anchor routing strategy. MOMoE updates knowledge using a bypass MoE structure, keeping the original parameters unchanged to preserve the general ability of LLMs. And, the knowledge anchor routing ensures that inputs requiring similar knowledge are routed to the same expert, thereby enhancing the generalization of the updated knowledge. Experimental results show the superiority of our approach over both batch editing and sequential batch editing tasks, exhibiting exceptional overall performance alongside outstanding balance between generalization and locality. Our code will be available.","sentences":["Model editing aims to efficiently alter the behavior of Large Language Models (LLMs) within a desired scope, while ensuring no adverse impact on other inputs.","Recent years have witnessed various model editing methods been proposed.","However, these methods either exhibit poor overall performance or struggle to strike a balance between generalization and locality.","We propose MOMoE, a model editing adapter utilizing a Mixture of Experts (MoE) architecture with a knowledge anchor routing strategy.","MOMoE updates knowledge using a bypass MoE structure, keeping the original parameters unchanged to preserve the general ability of LLMs.","And, the knowledge anchor routing ensures that inputs requiring similar knowledge are routed to the same expert, thereby enhancing the generalization of the updated knowledge.","Experimental results show the superiority of our approach over both batch editing and sequential batch editing tasks, exhibiting exceptional overall performance alongside outstanding balance between generalization and locality.","Our code will be available."],"url":"http://arxiv.org/abs/2405.19086v1","category":"cs.CL"}
{"created":"2024-05-29 13:47:32","title":"Patch-enhanced Mask Encoder Prompt Image Generation","abstract":"Artificial Intelligence Generated Content(AIGC), known for its superior visual results, represents a promising mitigation method for high-cost advertising applications. Numerous approaches have been developed to manipulate generated content under different conditions. However, a crucial limitation lies in the accurate description of products in advertising applications. Applying previous methods directly may lead to considerable distortion and deformation of advertised products, primarily due to oversimplified content control conditions. Hence, in this work, we propose a patch-enhanced mask encoder approach to ensure accurate product descriptions while preserving diverse backgrounds. Our approach consists of three components Patch Flexible Visibility, Mask Encoder Prompt Adapter and an image Foundation Model. Patch Flexible Visibility is used for generating a more reasonable background image. Mask Encoder Prompt Adapter enables region-controlled fusion. We also conduct an analysis of the structure and operational mechanisms of the Generation Module. Experimental results show our method can achieve the highest visual results and FID scores compared with other methods.","sentences":["Artificial Intelligence Generated Content(AIGC), known for its superior visual results, represents a promising mitigation method for high-cost advertising applications.","Numerous approaches have been developed to manipulate generated content under different conditions.","However, a crucial limitation lies in the accurate description of products in advertising applications.","Applying previous methods directly may lead to considerable distortion and deformation of advertised products, primarily due to oversimplified content control conditions.","Hence, in this work, we propose a patch-enhanced mask encoder approach to ensure accurate product descriptions while preserving diverse backgrounds.","Our approach consists of three components Patch Flexible Visibility, Mask Encoder Prompt Adapter and an image Foundation Model.","Patch Flexible Visibility is used for generating a more reasonable background image.","Mask Encoder Prompt Adapter enables region-controlled fusion.","We also conduct an analysis of the structure and operational mechanisms of the Generation Module.","Experimental results show our method can achieve the highest visual results and FID scores compared with other methods."],"url":"http://arxiv.org/abs/2405.19085v1","category":"cs.AI"}
{"created":"2024-05-29 13:36:36","title":"OMPO: A Unified Framework for RL under Policy and Dynamics Shifts","abstract":"Training reinforcement learning policies using environment interaction data collected from varying policies or dynamics presents a fundamental challenge. Existing works often overlook the distribution discrepancies induced by policy or dynamics shifts, or rely on specialized algorithms with task priors, thus often resulting in suboptimal policy performances and high learning variances. In this paper, we identify a unified strategy for online RL policy learning under diverse settings of policy and dynamics shifts: transition occupancy matching. In light of this, we introduce a surrogate policy learning objective by considering the transition occupancy discrepancies and then cast it into a tractable min-max optimization problem through dual reformulation. Our method, dubbed Occupancy-Matching Policy Optimization (OMPO), features a specialized actor-critic structure equipped with a distribution discriminator and a small-size local buffer. We conduct extensive experiments based on the OpenAI Gym, Meta-World, and Panda Robots environments, encompassing policy shifts under stationary and nonstationary dynamics, as well as domain adaption. The results demonstrate that OMPO outperforms the specialized baselines from different categories in all settings. We also find that OMPO exhibits particularly strong performance when combined with domain randomization, highlighting its potential in RL-based robotics applications","sentences":["Training reinforcement learning policies using environment interaction data collected from varying policies or dynamics presents a fundamental challenge.","Existing works often overlook the distribution discrepancies induced by policy or dynamics shifts, or rely on specialized algorithms with task priors, thus often resulting in suboptimal policy performances and high learning variances.","In this paper, we identify a unified strategy for online RL policy learning under diverse settings of policy and dynamics shifts: transition occupancy matching.","In light of this, we introduce a surrogate policy learning objective by considering the transition occupancy discrepancies and then cast it into a tractable min-max optimization problem through dual reformulation.","Our method, dubbed Occupancy-Matching Policy Optimization (OMPO), features a specialized actor-critic structure equipped with a distribution discriminator and a small-size local buffer.","We conduct extensive experiments based on the OpenAI Gym, Meta-World, and Panda Robots environments, encompassing policy shifts under stationary and nonstationary dynamics, as well as domain adaption.","The results demonstrate that OMPO outperforms the specialized baselines from different categories in all settings.","We also find that OMPO exhibits particularly strong performance when combined with domain randomization, highlighting its potential in RL-based robotics applications"],"url":"http://arxiv.org/abs/2405.19080v1","category":"cs.LG"}
{"created":"2024-05-29 13:25:30","title":"Computational bounds on randomized algorithms for online bin stretching","abstract":"A frequently studied performance measure in online optimization is competitive analysis. It corresponds to the worst-case ratio, over all possible inputs of an algorithm, between the performance of the algorithm and the optimal offline performance. However, this analysis may be too pessimistic to give valuable insight on a problem. Several workarounds exist, such as randomized algorithms. This paper aims to propose computational methods to construct randomized algorithms and to bound their performance on the classical online bin stretching problem. A game theory method is adapted to construct lower bounds on the performance of randomized online algorithms via linear programming. Another computational method is then proposed to construct randomized algorithms which perform better than the best deterministic algorithms known. Finally, another lower bound method for a restricted class of randomized algorithm for this problem is proposed.","sentences":["A frequently studied performance measure in online optimization is competitive analysis.","It corresponds to the worst-case ratio, over all possible inputs of an algorithm, between the performance of the algorithm and the optimal offline performance.","However, this analysis may be too pessimistic to give valuable insight on a problem.","Several workarounds exist, such as randomized algorithms.","This paper aims to propose computational methods to construct randomized algorithms and to bound their performance on the classical online bin stretching problem.","A game theory method is adapted to construct lower bounds on the performance of randomized online algorithms via linear programming.","Another computational method is then proposed to construct randomized algorithms which perform better than the best deterministic algorithms known.","Finally, another lower bound method for a restricted class of randomized algorithm for this problem is proposed."],"url":"http://arxiv.org/abs/2405.19071v1","category":"math.OC"}
{"created":"2024-05-29 13:20:50","title":"Implementing arbitrary multi-mode continuous-variable quantum gates with fixed non-Gaussian states and adaptive linear optics","abstract":"Non-Gaussian quantum gates are essential components for optical quantum information processing. However, the efficient implementation of practically important multi-mode higher-order non-Gaussian gates has not been comprehensively studied. We propose a measurement-based method to directly implement general, multi-mode, and higher-order non-Gaussian gates using only fixed non-Gaussian ancillary states and adaptive linear optics. Compared to existing methods, our method allows for a more resource-efficient and experimentally feasible implementation of multi-mode gates that are important for various applications in optical quantum technology, such as the two-mode cubic quantum non-demolition gate or the three-mode continuous-variable Toffoli gate, and their higher-order extensions. Our results will expedite the progress toward fault-tolerant universal quantum computing with light.","sentences":["Non-Gaussian quantum gates are essential components for optical quantum information processing.","However, the efficient implementation of practically important multi-mode higher-order non-Gaussian gates has not been comprehensively studied.","We propose a measurement-based method to directly implement general, multi-mode, and higher-order non-Gaussian gates using only fixed non-Gaussian ancillary states and adaptive linear optics.","Compared to existing methods, our method allows for a more resource-efficient and experimentally feasible implementation of multi-mode gates that are important for various applications in optical quantum technology, such as the two-mode cubic quantum non-demolition gate or the three-mode continuous-variable Toffoli gate, and their higher-order extensions.","Our results will expedite the progress toward fault-tolerant universal quantum computing with light."],"url":"http://arxiv.org/abs/2405.19067v1","category":"quant-ph"}
{"created":"2024-05-29 13:08:50","title":"Fracture metamaterials with on-demand crack paths enabled by bending","abstract":"In many scenarios -- when we bite food or during a crash -- fracture is inevitable. Finding solutions to steer fracture to mitigate its impact or turn it into a purposeful functionality, is therefore crucial. Strategies using composites, changes in chemical composition or crystal orientation, have proven to be very efficient, but the crack path control remains limited and has not been achieved in load-bearing structures. Here, we introduce fracture metamaterials consisting of slender elements whose bending enables large elastic deformation as fracture propagates. This interplay between bending and fracture enables tunable energy dissipation and the design of on-demand crack paths of arbitrary complexity. To this end, we use topology optimisation to create unit cells with anisotropic fracture energy, which we then tile up to realize fracture metamaterials with uniform density that we 3D-print. The thin ligaments that constitute the unit cells confer them a strikingly distinct response in tension and shear, and we show that by controlling the orientation and layout of the unit cells the sequential progress of the crack can be controlled, making the fracture path arbitrarily tortuous. This tortuosity increases the energy dissipation of the metamaterial without changing its stiffness. Using bespoke arrangements of unit cells, metamaterials can have on-demand fracture paths of arbitrary complexity. Our findings bring a new perspective on inelastic deformations in mechanical metamaterials, with potential applications in areas as diverse as the food industry, structural design, and for shock and impact damping.","sentences":["In many scenarios -- when we bite food or during a crash -- fracture is inevitable.","Finding solutions to steer fracture to mitigate its impact or turn it into a purposeful functionality, is therefore crucial.","Strategies using composites, changes in chemical composition or crystal orientation, have proven to be very efficient, but the crack path control remains limited and has not been achieved in load-bearing structures.","Here, we introduce fracture metamaterials consisting of slender elements whose bending enables large elastic deformation as fracture propagates.","This interplay between bending and fracture enables tunable energy dissipation and the design of on-demand crack paths of arbitrary complexity.","To this end, we use topology optimisation to create unit cells with anisotropic fracture energy, which we then tile up to realize fracture metamaterials with uniform density that we 3D-print.","The thin ligaments that constitute the unit cells confer them a strikingly distinct response in tension and shear, and we show that by controlling the orientation and layout of the unit cells the sequential progress of the crack can be controlled, making the fracture path arbitrarily tortuous.","This tortuosity increases the energy dissipation of the metamaterial without changing its stiffness.","Using bespoke arrangements of unit cells, metamaterials can have on-demand fracture paths of arbitrary complexity.","Our findings bring a new perspective on inelastic deformations in mechanical metamaterials, with potential applications in areas as diverse as the food industry, structural design, and for shock and impact damping."],"url":"http://arxiv.org/abs/2405.19061v1","category":"cond-mat.soft"}
{"created":"2024-05-29 13:06:10","title":"New perspectives on the optimal placement of detectors for suicide bombers using metaheuristics","abstract":"We consider an operational model of suicide bombing attacks -- an increasingly prevalent form of terrorism -- against specific targets, and the use of protective countermeasures based on the deployment of detectors over the area under threat. These detectors have to be carefully located in order to minimize the expected number of casualties or the economic damage suffered, resulting in a hard optimization problem for which different metaheuristics have been proposed. Rather than assuming random decisions by the attacker, the problem is approached by considering different models of the latter, whereby he takes informed decisions on which objective must be targeted and through which path it has to be reached based on knowledge on the importance or value of the objectives or on the defensive strategy of the defender (a scenario that can be regarded as an adversarial game). We consider four different algorithms, namely a greedy heuristic, a hill climber, tabu search and an evolutionary algorithm, and study their performance on a broad collection of problem instances trying to resemble different realistic settings such as a coastal area, a modern urban area, and the historic core of an old town. It is shown that the adversarial scenario is harder for all techniques, and that the evolutionary algorithm seems to adapt better to the complexity of the resulting search landscape.","sentences":["We consider an operational model of suicide bombing attacks -- an increasingly prevalent form of terrorism -- against specific targets, and the use of protective countermeasures based on the deployment of detectors over the area under threat.","These detectors have to be carefully located in order to minimize the expected number of casualties or the economic damage suffered, resulting in a hard optimization problem for which different metaheuristics have been proposed.","Rather than assuming random decisions by the attacker, the problem is approached by considering different models of the latter, whereby he takes informed decisions on which objective must be targeted and through which path it has to be reached based on knowledge on the importance or value of the objectives or on the defensive strategy of the defender (a scenario that can be regarded as an adversarial game).","We consider four different algorithms, namely a greedy heuristic, a hill climber, tabu search and an evolutionary algorithm, and study their performance on a broad collection of problem instances trying to resemble different realistic settings such as a coastal area, a modern urban area, and the historic core of an old town.","It is shown that the adversarial scenario is harder for all techniques, and that the evolutionary algorithm seems to adapt better to the complexity of the resulting search landscape."],"url":"http://arxiv.org/abs/2405.19060v1","category":"cs.NE"}
{"created":"2024-05-29 12:44:41","title":"Statistical Context Detection for Deep Lifelong Reinforcement Learning","abstract":"Context detection involves labeling segments of an online stream of data as belonging to different tasks. Task labels are used in lifelong learning algorithms to perform consolidation or other procedures that prevent catastrophic forgetting. Inferring task labels from online experiences remains a challenging problem. Most approaches assume finite and low-dimension observation spaces or a preliminary training phase during which task labels are learned. Moreover, changes in the transition or reward functions can be detected only in combination with a policy, and therefore are more difficult to detect than changes in the input distribution. This paper presents an approach to learning both policies and labels in an online deep reinforcement learning setting. The key idea is to use distance metrics, obtained via optimal transport methods, i.e., Wasserstein distance, on suitable latent action-reward spaces to measure distances between sets of data points from past and current streams. Such distances can then be used for statistical tests based on an adapted Kolmogorov-Smirnov calculation to assign labels to sequences of experiences. A rollback procedure is introduced to learn multiple policies by ensuring that only the appropriate data is used to train the corresponding policy. The combination of task detection and policy deployment allows for the optimization of lifelong reinforcement learning agents without an oracle that provides task labels. The approach is tested using two benchmarks and the results show promising performance when compared with related context detection algorithms. The results suggest that optimal transport statistical methods provide an explainable and justifiable procedure for online context detection and reward optimization in lifelong reinforcement learning.","sentences":["Context detection involves labeling segments of an online stream of data as belonging to different tasks.","Task labels are used in lifelong learning algorithms to perform consolidation or other procedures that prevent catastrophic forgetting.","Inferring task labels from online experiences remains a challenging problem.","Most approaches assume finite and low-dimension observation spaces or a preliminary training phase during which task labels are learned.","Moreover, changes in the transition or reward functions can be detected only in combination with a policy, and therefore are more difficult to detect than changes in the input distribution.","This paper presents an approach to learning both policies and labels in an online deep reinforcement learning setting.","The key idea is to use distance metrics, obtained via optimal transport methods, i.e., Wasserstein distance, on suitable latent action-reward spaces to measure distances between sets of data points from past and current streams.","Such distances can then be used for statistical tests based on an adapted Kolmogorov-Smirnov calculation to assign labels to sequences of experiences.","A rollback procedure is introduced to learn multiple policies by ensuring that only the appropriate data is used to train the corresponding policy.","The combination of task detection and policy deployment allows for the optimization of lifelong reinforcement learning agents without an oracle that provides task labels.","The approach is tested using two benchmarks and the results show promising performance when compared with related context detection algorithms.","The results suggest that optimal transport statistical methods provide an explainable and justifiable procedure for online context detection and reward optimization in lifelong reinforcement learning."],"url":"http://arxiv.org/abs/2405.19047v1","category":"cs.LG"}
{"created":"2024-05-29 12:43:39","title":"Continual Collaborative Distillation for Recommender System","abstract":"Knowledge distillation (KD) has emerged as a promising technique for addressing the computational challenges associated with deploying large-scale recommender systems. KD transfers the knowledge of a massive teacher system to a compact student model, to reduce the huge computational burdens for inference while retaining high accuracy. The existing KD studies primarily focus on one-time distillation in static environments, leaving a substantial gap in their applicability to real-world scenarios dealing with continuously incoming users, items, and their interactions. In this work, we delve into a systematic approach to operating the teacher-student KD in a non-stationary data stream. Our goal is to enable efficient deployment through a compact student, which preserves the high performance of the massive teacher, while effectively adapting to continuously incoming data. We propose Continual Collaborative Distillation (CCD) framework, where both the teacher and the student continually and collaboratively evolve along the data stream. CCD facilitates the student in effectively adapting to new data, while also enabling the teacher to fully leverage accumulated knowledge. We validate the effectiveness of CCD through extensive quantitative, ablative, and exploratory experiments on two real-world datasets. We expect this research direction to contribute to narrowing the gap between existing KD studies and practical applications, thereby enhancing the applicability of KD in real-world systems.","sentences":["Knowledge distillation (KD) has emerged as a promising technique for addressing the computational challenges associated with deploying large-scale recommender systems.","KD transfers the knowledge of a massive teacher system to a compact student model, to reduce the huge computational burdens for inference while retaining high accuracy.","The existing KD studies primarily focus on one-time distillation in static environments, leaving a substantial gap in their applicability to real-world scenarios dealing with continuously incoming users, items, and their interactions.","In this work, we delve into a systematic approach to operating the teacher-student KD in a non-stationary data stream.","Our goal is to enable efficient deployment through a compact student, which preserves the high performance of the massive teacher, while effectively adapting to continuously incoming data.","We propose Continual Collaborative Distillation (CCD) framework, where both the teacher and the student continually and collaboratively evolve along the data stream.","CCD facilitates the student in effectively adapting to new data, while also enabling the teacher to fully leverage accumulated knowledge.","We validate the effectiveness of CCD through extensive quantitative, ablative, and exploratory experiments on two real-world datasets.","We expect this research direction to contribute to narrowing the gap between existing KD studies and practical applications, thereby enhancing the applicability of KD in real-world systems."],"url":"http://arxiv.org/abs/2405.19046v1","category":"cs.IR"}
{"created":"2024-05-29 12:38:01","title":"On adaptive stochastic extended iterative methods for solving least squares","abstract":"In this paper, we propose a novel adaptive stochastic extended iterative method, which can be viewed as an improved extension of the randomized extended Kaczmarz (REK) method, for finding the unique minimum Euclidean norm least-squares solution of a given linear system. In particular, we introduce three equivalent stochastic reformulations of the linear least-squares problem: stochastic unconstrained and constrained optimization problems, and the stochastic multiobjective optimization problem. We then alternately employ the adaptive variants of the stochastic heavy ball momentum (SHBM) method, which utilize iterative information to update the parameters, to solve the stochastic reformulations. We prove that our method converges linearly in expectation, addressing an open problem in the literature related to designing theoretically supported adaptive SHBM methods. Numerical experiments show that our adaptive stochastic extended iterative method has strong advantages over the non-adaptive one.","sentences":["In this paper, we propose a novel adaptive stochastic extended iterative method, which can be viewed as an improved extension of the randomized extended Kaczmarz (REK) method, for finding the unique minimum Euclidean norm least-squares solution of a given linear system.","In particular, we introduce three equivalent stochastic reformulations of the linear least-squares problem: stochastic unconstrained and constrained optimization problems, and the stochastic multiobjective optimization problem.","We then alternately employ the adaptive variants of the stochastic heavy ball momentum (SHBM) method, which utilize iterative information to update the parameters, to solve the stochastic reformulations.","We prove that our method converges linearly in expectation, addressing an open problem in the literature related to designing theoretically supported adaptive SHBM methods.","Numerical experiments show that our adaptive stochastic extended iterative method has strong advantages over the non-adaptive one."],"url":"http://arxiv.org/abs/2405.19044v1","category":"math.NA"}
{"created":"2024-05-29 12:32:08","title":"BLSP-KD: Bootstrapping Language-Speech Pre-training via Knowledge Distillation","abstract":"Recent end-to-end approaches have shown promise in extending large language models (LLMs) to speech inputs, but face limitations in directly assessing and optimizing alignment quality and fail to achieve fine-grained alignment due to speech-text length mismatch. We introduce BLSP-KD, a novel approach for Bootstrapping Language-Speech Pretraining via Knowledge Distillation, which addresses these limitations through two key techniques. First, it optimizes speech-text alignment by minimizing the divergence between the LLM's next-token prediction distributions for speech and text inputs using knowledge distillation. Second, it employs a continuous-integrate-andfire strategy to segment speech into tokens that correspond one-to-one with text tokens, enabling fine-grained alignment. We also introduce Partial LoRA (PLoRA), a new adaptation method supporting LLM finetuning for speech inputs under knowledge distillation. Quantitative evaluation shows that BLSP-KD outperforms previous end-to-end baselines and cascaded systems with comparable scale of parameters, facilitating general instruction-following capabilities for LLMs with speech inputs. This approach provides new possibilities for extending LLMs to spoken language interactions.","sentences":["Recent end-to-end approaches have shown promise in extending large language models (LLMs) to speech inputs, but face limitations in directly assessing and optimizing alignment quality and fail to achieve fine-grained alignment due to speech-text length mismatch.","We introduce BLSP-KD, a novel approach for Bootstrapping Language-Speech Pretraining via Knowledge Distillation, which addresses these limitations through two key techniques.","First, it optimizes speech-text alignment by minimizing the divergence between the LLM's next-token prediction distributions for speech and text inputs using knowledge distillation.","Second, it employs a continuous-integrate-andfire strategy to segment speech into tokens that correspond one-to-one with text tokens, enabling fine-grained alignment.","We also introduce Partial LoRA (PLoRA), a new adaptation method supporting LLM finetuning for speech inputs under knowledge distillation.","Quantitative evaluation shows that BLSP-KD outperforms previous end-to-end baselines and cascaded systems with comparable scale of parameters, facilitating general instruction-following capabilities for LLMs with speech inputs.","This approach provides new possibilities for extending LLMs to spoken language interactions."],"url":"http://arxiv.org/abs/2405.19041v1","category":"cs.CL"}
{"created":"2024-05-29 11:57:04","title":"Adaptive posterior concentration rates for sparse high-dimensional linear regression with random design and unknown error variance","abstract":"This paper investigates sparse high-dimensional linear regression, particularly examining the properties of the posterior under conditions of random design and unknown error variance. We provide consistency results for the posterior and analyze its concentration rates, demonstrating adaptiveness to the unknown sparsity level of the regression coefficient vector. Furthermore, we extend our investigation to establish concentration outcomes for parameter estimation using specific distance measures. These findings are in line with recent discoveries in frequentist studies. Additionally, by employing techniques to address model misspecification through a fractional posterior, we broaden our analysis through oracle inequalities to encompass the critical aspect of model misspecification for the regular posterior. Our novel findings are demonstrated using two different types of sparsity priors: a shrinkage prior and a spike-and-slab prior.","sentences":["This paper investigates sparse high-dimensional linear regression, particularly examining the properties of the posterior under conditions of random design and unknown error variance.","We provide consistency results for the posterior and analyze its concentration rates, demonstrating adaptiveness to the unknown sparsity level of the regression coefficient vector.","Furthermore, we extend our investigation to establish concentration outcomes for parameter estimation using specific distance measures.","These findings are in line with recent discoveries in frequentist studies.","Additionally, by employing techniques to address model misspecification through a fractional posterior, we broaden our analysis through oracle inequalities to encompass the critical aspect of model misspecification for the regular posterior.","Our novel findings are demonstrated using two different types of sparsity priors: a shrinkage prior and a spike-and-slab prior."],"url":"http://arxiv.org/abs/2405.19016v1","category":"math.ST"}
{"created":"2024-05-29 11:53:07","title":"Trust the Model Where It Trusts Itself -- Model-Based Actor-Critic with Uncertainty-Aware Rollout Adaption","abstract":"Dyna-style model-based reinforcement learning (MBRL) combines model-free agents with predictive transition models through model-based rollouts. This combination raises a critical question: 'When to trust your model?'; i.e., which rollout length results in the model providing useful data? Janner et al. (2019) address this question by gradually increasing rollout lengths throughout the training. While theoretically tempting, uniform model accuracy is a fallacy that collapses at the latest when extrapolating. Instead, we propose asking the question 'Where to trust your model?'. Using inherent model uncertainty to consider local accuracy, we obtain the Model-Based Actor-Critic with Uncertainty-Aware Rollout Adaption (MACURA) algorithm. We propose an easy-to-tune rollout mechanism and demonstrate substantial improvements in data efficiency and performance compared to state-of-the-art deep MBRL methods on the MuJoCo benchmark.","sentences":["Dyna-style model-based reinforcement learning (MBRL) combines model-free agents with predictive transition models through model-based rollouts.","This combination raises a critical question: 'When to trust your model?'; i.e., which rollout length results in the model providing useful data?","Janner et al. (2019) address this question by gradually increasing rollout lengths throughout the training.","While theoretically tempting, uniform model accuracy is a fallacy that collapses at the latest when extrapolating.","Instead, we propose asking the question 'Where to trust your model?'.","Using inherent model uncertainty to consider local accuracy, we obtain the Model-Based Actor-Critic with Uncertainty-Aware Rollout Adaption (MACURA) algorithm.","We propose an easy-to-tune rollout mechanism and demonstrate substantial improvements in data efficiency and performance compared to state-of-the-art deep MBRL methods on the MuJoCo benchmark."],"url":"http://arxiv.org/abs/2405.19014v1","category":"cs.LG"}
{"created":"2024-05-29 11:52:53","title":"On Dissipativity of Cross-Entropy Loss in Training ResNets","abstract":"The training of ResNets and neural ODEs can be formulated and analyzed from the perspective of optimal control. This paper proposes a dissipative formulation of the training of ResNets and neural ODEs for classification problems by including a variant of the cross-entropy as a regularization in the stage cost. Based on the dissipative formulation of the training, we prove that the trained ResNet exhibit the turnpike phenomenon. We then illustrate that the training exhibits the turnpike phenomenon by training on the two spirals and MNIST datasets. This can be used to find very shallow networks suitable for a given classification task.","sentences":["The training of ResNets and neural ODEs can be formulated and analyzed from the perspective of optimal control.","This paper proposes a dissipative formulation of the training of ResNets and neural ODEs for classification problems by including a variant of the cross-entropy as a regularization in the stage cost.","Based on the dissipative formulation of the training, we prove that the trained ResNet exhibit the turnpike phenomenon.","We then illustrate that the training exhibits the turnpike phenomenon by training on the two spirals and MNIST datasets.","This can be used to find very shallow networks suitable for a given classification task."],"url":"http://arxiv.org/abs/2405.19013v1","category":"cs.LG"}
{"created":"2024-05-29 11:51:33","title":"Implicit Neural Image Field for Biological Microscopy Image Compression","abstract":"The rapid pace of innovation in biological microscopy imaging has led to large images, putting pressure on data storage and impeding efficient sharing, management, and visualization. This necessitates the development of efficient compression solutions. Traditional CODEC methods struggle to adapt to the diverse bioimaging data and often suffer from sub-optimal compression. In this study, we propose an adaptive compression workflow based on Implicit Neural Representation (INR). This approach permits application-specific compression objectives, capable of compressing images of any shape and arbitrary pixel-wise decompression. We demonstrated on a wide range of microscopy images from real applications that our workflow not only achieved high, controllable compression ratios (e.g., 512x) but also preserved detailed information critical for downstream analysis.","sentences":["The rapid pace of innovation in biological microscopy imaging has led to large images, putting pressure on data storage and impeding efficient sharing, management, and visualization.","This necessitates the development of efficient compression solutions.","Traditional CODEC methods struggle to adapt to the diverse bioimaging data and often suffer from sub-optimal compression.","In this study, we propose an adaptive compression workflow based on Implicit Neural Representation (INR).","This approach permits application-specific compression objectives, capable of compressing images of any shape and arbitrary pixel-wise decompression.","We demonstrated on a wide range of microscopy images from real applications that our workflow not only achieved high, controllable compression ratios (e.g., 512x) but also preserved detailed information critical for downstream analysis."],"url":"http://arxiv.org/abs/2405.19012v1","category":"cs.AI"}
{"created":"2024-05-29 11:42:02","title":"Auto-selected Knowledge Adapters for Lifelong Person Re-identification","abstract":"Lifelong Person Re-Identification (LReID) extends traditional ReID by requiring systems to continually learn from non-overlapping datasets across different times and locations, adapting to new identities while preserving knowledge of previous ones. Existing approaches, either rehearsal-free or rehearsal-based, still suffer from the problem of catastrophic forgetting since they try to cram diverse knowledge into one fixed model. To overcome this limitation, we introduce a novel framework AdalReID, that adopts knowledge adapters and a parameter-free auto-selection mechanism for lifelong learning. Concretely, we incrementally build distinct adapters to learn domain-specific knowledge at each step, which can effectively learn and preserve knowledge across different datasets. Meanwhile, the proposed auto-selection strategy adaptively calculates the knowledge similarity between the input set and the adapters. On the one hand, the appropriate adapters are selected for the inputs to process ReID, and on the other hand, the knowledge interaction and fusion between adapters are enhanced to improve the generalization ability of the model. Extensive experiments are conducted to demonstrate the superiority of our AdalReID, which significantly outperforms SOTAs by about 10$\\sim$20\\% mAP on both seen and unseen domains.","sentences":["Lifelong Person Re-Identification (LReID) extends traditional ReID by requiring systems to continually learn from non-overlapping datasets across different times and locations, adapting to new identities while preserving knowledge of previous ones.","Existing approaches, either rehearsal-free or rehearsal-based, still suffer from the problem of catastrophic forgetting since they try to cram diverse knowledge into one fixed model.","To overcome this limitation, we introduce a novel framework AdalReID, that adopts knowledge adapters and a parameter-free auto-selection mechanism for lifelong learning.","Concretely, we incrementally build distinct adapters to learn domain-specific knowledge at each step, which can effectively learn and preserve knowledge across different datasets.","Meanwhile, the proposed auto-selection strategy adaptively calculates the knowledge similarity between the input set and the adapters.","On the one hand, the appropriate adapters are selected for the inputs to process ReID, and on the other hand, the knowledge interaction and fusion between adapters are enhanced to improve the generalization ability of the model.","Extensive experiments are conducted to demonstrate the superiority of our AdalReID, which significantly outperforms SOTAs by about 10$\\sim$20\\% mAP on both seen and unseen domains."],"url":"http://arxiv.org/abs/2405.19005v2","category":"cs.CV"}
{"created":"2024-05-29 11:28:06","title":"FedMAP: Unlocking Potential in Personalized Federated Learning through Bi-Level MAP Optimization","abstract":"Federated Learning (FL) enables collaborative training of machine learning models on decentralized data while preserving data privacy. However, data across clients often differs significantly due to class imbalance, feature distribution skew, sample size imbalance, and other phenomena. Leveraging information from these not identically distributed (non-IID) datasets poses substantial challenges. FL methods based on a single global model cannot effectively capture the variations in client data and underperform in non-IID settings. Consequently, Personalized FL (PFL) approaches that adapt to each client's data distribution but leverage other clients' data are essential but currently underexplored. We propose a novel Bayesian PFL framework using bi-level optimization to tackle the data heterogeneity challenges. Our proposed framework utilizes the global model as a prior distribution within a Maximum A Posteriori (MAP) estimation of personalized client models. This approach facilitates PFL by integrating shared knowledge from the prior, thereby enhancing local model performance, generalization ability, and communication efficiency. We extensively evaluated our bi-level optimization approach on real-world and synthetic datasets, demonstrating significant improvements in model accuracy compared to existing methods while reducing communication overhead. This study contributes to PFL by establishing a solid theoretical foundation for the proposed method and offering a robust, ready-to-use framework that effectively addresses the challenges posed by non-IID data in FL.","sentences":["Federated Learning (FL) enables collaborative training of machine learning models on decentralized data while preserving data privacy.","However, data across clients often differs significantly due to class imbalance, feature distribution skew, sample size imbalance, and other phenomena.","Leveraging information from these not identically distributed (non-IID) datasets poses substantial challenges.","FL methods based on a single global model cannot effectively capture the variations in client data and underperform in non-IID settings.","Consequently, Personalized FL (PFL) approaches that adapt to each client's data distribution but leverage other clients' data are essential but currently underexplored.","We propose a novel Bayesian PFL framework using bi-level optimization to tackle the data heterogeneity challenges.","Our proposed framework utilizes the global model as a prior distribution within a Maximum A Posteriori (MAP) estimation of personalized client models.","This approach facilitates PFL by integrating shared knowledge from the prior, thereby enhancing local model performance, generalization ability, and communication efficiency.","We extensively evaluated our bi-level optimization approach on real-world and synthetic datasets, demonstrating significant improvements in model accuracy compared to existing methods while reducing communication overhead.","This study contributes to PFL by establishing a solid theoretical foundation for the proposed method and offering a robust, ready-to-use framework that effectively addresses the challenges posed by non-IID data in FL."],"url":"http://arxiv.org/abs/2405.19000v1","category":"cs.LG"}
{"created":"2024-05-29 11:11:07","title":"EasyAnimate: A High-Performance Long Video Generation Method based on Transformer Architecture","abstract":"This paper presents EasyAnimate, an advanced method for video generation that leverages the power of transformer architecture for high-performance outcomes. We have expanded the DiT framework originally designed for 2D image synthesis to accommodate the complexities of 3D video generation by incorporating a motion module block. It is used to capture temporal dynamics, thereby ensuring the production of consistent frames and seamless motion transitions. The motion module can be adapted to various DiT baseline methods to generate video with different styles. It can also generate videos with different frame rates and resolutions during both training and inference phases, suitable for both images and videos. Moreover, we introduce slice VAE, a novel approach to condense the temporal axis, facilitating the generation of long duration videos. Currently, EasyAnimate exhibits the proficiency to generate videos with 144 frames. We provide a holistic ecosystem for video production based on DiT, encompassing aspects such as data pre-processing, VAE training, DiT models training (both the baseline model and LoRA model), and end-to-end video inference. Code is available at: https://github.com/aigc-apps/EasyAnimate. We are continuously working to enhance the performance of our method.","sentences":["This paper presents EasyAnimate, an advanced method for video generation that leverages the power of transformer architecture for high-performance outcomes.","We have expanded the DiT framework originally designed for 2D image synthesis to accommodate the complexities of 3D video generation by incorporating a motion module block.","It is used to capture temporal dynamics, thereby ensuring the production of consistent frames and seamless motion transitions.","The motion module can be adapted to various DiT baseline methods to generate video with different styles.","It can also generate videos with different frame rates and resolutions during both training and inference phases, suitable for both images and videos.","Moreover, we introduce slice VAE, a novel approach to condense the temporal axis, facilitating the generation of long duration videos.","Currently, EasyAnimate exhibits the proficiency to generate videos with 144 frames.","We provide a holistic ecosystem for video production based on DiT, encompassing aspects such as data pre-processing, VAE training, DiT models training (both the baseline model and LoRA model), and end-to-end video inference.","Code is available at: https://github.com/aigc-apps/EasyAnimate.","We are continuously working to enhance the performance of our method."],"url":"http://arxiv.org/abs/2405.18991v1","category":"cs.CV"}
{"created":"2024-05-29 10:34:44","title":"Federated Learning with Bilateral Curation for Partially Class-Disjoint Data","abstract":"Partially class-disjoint data (PCDD), a common yet under-explored data formation where each client contributes a part of classes (instead of all classes) of samples, severely challenges the performance of federated algorithms. Without full classes, the local objective will contradict the global objective, yielding the angle collapse problem for locally missing classes and the space waste problem for locally existing classes. As far as we know, none of the existing methods can intrinsically mitigate PCDD challenges to achieve holistic improvement in the bilateral views (both global view and local view) of federated learning. To address this dilemma, we are inspired by the strong generalization of simplex Equiangular Tight Frame~(ETF) on the imbalanced data, and propose a novel approach called FedGELA where the classifier is globally fixed as a simplex ETF while locally adapted to the personal distributions. Globally, FedGELA provides fair and equal discrimination for all classes and avoids inaccurate updates of the classifier, while locally it utilizes the space of locally missing classes for locally existing classes. We conduct extensive experiments on a range of datasets to demonstrate that our FedGELA achieves promising performance~(averaged improvement of 3.9% to FedAvg and 1.5% to best baselines) and provide both local and global convergence guarantees. Source code is available at:https://github.com/MediaBrain-SJTU/FedGELA.git.","sentences":["Partially class-disjoint data (PCDD), a common yet under-explored data formation where each client contributes a part of classes (instead of all classes) of samples, severely challenges the performance of federated algorithms.","Without full classes, the local objective will contradict the global objective, yielding the angle collapse problem for locally missing classes and the space waste problem for locally existing classes.","As far as we know, none of the existing methods can intrinsically mitigate PCDD challenges to achieve holistic improvement in the bilateral views (both global view and local view) of federated learning.","To address this dilemma, we are inspired by the strong generalization of simplex Equiangular Tight Frame~(ETF) on the imbalanced data, and propose a novel approach called FedGELA where the classifier is globally fixed as a simplex ETF while locally adapted to the personal distributions.","Globally, FedGELA provides fair and equal discrimination for all classes and avoids inaccurate updates of the classifier, while locally it utilizes the space of locally missing classes for locally existing classes.","We conduct extensive experiments on a range of datasets to demonstrate that our FedGELA achieves promising performance~(averaged improvement of 3.9% to FedAvg and 1.5% to best baselines) and provide both local and global convergence guarantees.","Source code is available at:https://github.com/MediaBrain-SJTU/FedGELA.git."],"url":"http://arxiv.org/abs/2405.18972v1","category":"cs.LG"}
{"created":"2024-05-29 10:31:53","title":"Mitigate Position Bias with Coupled Ranking Bias on CTR Prediction","abstract":"Position bias, i.e., users' preference of an item is affected by its placing position, is well studied in the recommender system literature. However, most existing methods ignore the widely coupled ranking bias, which is also related to the placing position of the item. Using both synthetic and industrial datasets, we first show how this widely coexisted ranking bias deteriorates the performance of the existing position bias estimation methods. To mitigate the position bias with the presence of the ranking bias, we propose a novel position bias estimation method, namely gradient interpolation, which fuses two estimation methods using a fusing weight. We further propose an adaptive method to automatically determine the optimal fusing weight. Extensive experiments on both synthetic and industrial datasets demonstrate the superior performance of the proposed methods.","sentences":["Position bias, i.e., users' preference of an item is affected by its placing position, is well studied in the recommender system literature.","However, most existing methods ignore the widely coupled ranking bias, which is also related to the placing position of the item.","Using both synthetic and industrial datasets, we first show how this widely coexisted ranking bias deteriorates the performance of the existing position bias estimation methods.","To mitigate the position bias with the presence of the ranking bias, we propose a novel position bias estimation method, namely gradient interpolation, which fuses two estimation methods using a fusing weight.","We further propose an adaptive method to automatically determine the optimal fusing weight.","Extensive experiments on both synthetic and industrial datasets demonstrate the superior performance of the proposed methods."],"url":"http://arxiv.org/abs/2405.18971v1","category":"cs.IR"}
{"created":"2024-05-29 09:56:00","title":"Predicting Many Properties of Crystals by a Single Deep Learning Model","abstract":"The use of machine learning methods for predicting the properties of crystalline materials encounters significant challenges, primarily related to input encoding, output versatility, and interpretability. Here, we introduce CrystalBERT, an adaptable transformer-based framework with novel structure that integrates space group, elemental, and unit cell information. The method's adaptability lies not only in its ability to seamlessly combine diverse features but also in its capability to accurately predict a wide range of physically important properties, including topological properties, superconducting transition temperatures, dielectric constants, and more. CrystalBERT also provides insightful physical interpretations regarding the features that most significantly influence the target properties. Our findings indicate that space group and elemental information are more important for predicting topological and superconducting properties, in contrast to some properties that primarily depend on the unit cell information. This underscores the intricate nature of topological and superconducting properties. By incorporating all these features, we achieve a high accuracy of 91% in topological classification, surpassing prior studies and identifying previously misclassified topological materials, further demonstrating the effectiveness of our model.","sentences":["The use of machine learning methods for predicting the properties of crystalline materials encounters significant challenges, primarily related to input encoding, output versatility, and interpretability.","Here, we introduce CrystalBERT, an adaptable transformer-based framework with novel structure that integrates space group, elemental, and unit cell information.","The method's adaptability lies not only in its ability to seamlessly combine diverse features but also in its capability to accurately predict a wide range of physically important properties, including topological properties, superconducting transition temperatures, dielectric constants, and more.","CrystalBERT also provides insightful physical interpretations regarding the features that most significantly influence the target properties.","Our findings indicate that space group and elemental information are more important for predicting topological and superconducting properties, in contrast to some properties that primarily depend on the unit cell information.","This underscores the intricate nature of topological and superconducting properties.","By incorporating all these features, we achieve a high accuracy of 91% in topological classification, surpassing prior studies and identifying previously misclassified topological materials, further demonstrating the effectiveness of our model."],"url":"http://arxiv.org/abs/2405.18944v1","category":"cond-mat.mtrl-sci"}
{"created":"2024-05-29 09:13:30","title":"Exploring Human-in-the-Loop Test-Time Adaptation by Synergizing Active Learning and Model Selection","abstract":"Existing test-time adaptation (TTA) approaches often adapt models with the unlabeled testing data stream. A recent attempt relaxed the assumption by introducing limited human annotation, referred to as Human-In-the-Loop Test-Time Adaptation (HILTTA) in this study. The focus of existing HILTTA lies on selecting the most informative samples to label, a.k.a. active learning. In this work, we are motivated by a pitfall of TTA, i.e. sensitive to hyper-parameters, and propose to approach HILTTA by synergizing active learning and model selection. Specifically, we first select samples for human annotation (active learning) and then use the labeled data to select optimal hyper-parameters (model selection). A sample selection strategy is tailored for choosing samples by considering the balance between active learning and model selection purposes. We demonstrate on 4 TTA datasets that the proposed HILTTA approach is compatible with off-the-shelf TTA methods which outperform the state-of-the-art HILTTA methods and stream-based active learning methods. Importantly, our proposed method can always prevent choosing the worst hyper-parameters on all off-the-shelf TTA methods. The source code will be released upon publication.","sentences":["Existing test-time adaptation (TTA) approaches often adapt models with the unlabeled testing data stream.","A recent attempt relaxed the assumption by introducing limited human annotation, referred to as Human-In-the-Loop Test-Time Adaptation (HILTTA) in this study.","The focus of existing HILTTA lies on selecting the most informative samples to label, a.k.a. active learning.","In this work, we are motivated by a pitfall of TTA, i.e. sensitive to hyper-parameters, and propose to approach HILTTA by synergizing active learning and model selection.","Specifically, we first select samples for human annotation (active learning) and then use the labeled data to select optimal hyper-parameters (model selection).","A sample selection strategy is tailored for choosing samples by considering the balance between active learning and model selection purposes.","We demonstrate on 4 TTA datasets that the proposed HILTTA approach is compatible with off-the-shelf TTA methods which outperform the state-of-the-art HILTTA methods and stream-based active learning methods.","Importantly, our proposed method can always prevent choosing the worst hyper-parameters on all off-the-shelf TTA methods.","The source code will be released upon publication."],"url":"http://arxiv.org/abs/2405.18911v1","category":"cs.CV"}
{"created":"2024-05-29 09:09:00","title":"Language Generation with Strictly Proper Scoring Rules","abstract":"Language generation based on maximum likelihood estimation (MLE) has become the fundamental approach for text generation. Maximum likelihood estimation is typically performed by minimizing the log-likelihood loss, also known as the logarithmic score in statistical decision theory. The logarithmic score is strictly proper in the sense that it encourages honest forecasts, where the expected score is maximized only when the model reports true probabilities. Although many strictly proper scoring rules exist, the logarithmic score is the only local scoring rule among them that depends exclusively on the probability of the observed sample, making it capable of handling the exponentially large sample space of natural text. In this work, we propose a straightforward strategy for adapting scoring rules to language generation, allowing for language modeling with any non-local scoring rules. Leveraging this strategy, we train language generation models using two classic strictly proper scoring rules, the Brier score and the Spherical score, as alternatives to the logarithmic score. Experimental results indicate that simply substituting the loss function, without adjusting other hyperparameters, can yield substantial improvements in model's generation capabilities. Moreover, these improvements can scale up to large language models (LLMs) such as LLaMA-7B and LLaMA-13B. Source code: \\url{https://github.com/shaochenze/ScoringRulesLM}.","sentences":["Language generation based on maximum likelihood estimation (MLE) has become the fundamental approach for text generation.","Maximum likelihood estimation is typically performed by minimizing the log-likelihood loss, also known as the logarithmic score in statistical decision theory.","The logarithmic score is strictly proper in the sense that it encourages honest forecasts, where the expected score is maximized only when the model reports true probabilities.","Although many strictly proper scoring rules exist, the logarithmic score is the only local scoring rule among them that depends exclusively on the probability of the observed sample, making it capable of handling the exponentially large sample space of natural text.","In this work, we propose a straightforward strategy for adapting scoring rules to language generation, allowing for language modeling with any non-local scoring rules.","Leveraging this strategy, we train language generation models using two classic strictly proper scoring rules, the Brier score and the Spherical score, as alternatives to the logarithmic score.","Experimental results indicate that simply substituting the loss function, without adjusting other hyperparameters, can yield substantial improvements in model's generation capabilities.","Moreover, these improvements can scale up to large language models (LLMs) such as LLaMA-7B and LLaMA-13B. Source code: \\url{https://github.com/shaochenze/ScoringRulesLM}."],"url":"http://arxiv.org/abs/2405.18906v1","category":"cs.CL"}
{"created":"2024-05-29 08:57:23","title":"MLAE: Masked LoRA Experts for Parameter-Efficient Fine-Tuning","abstract":"In response to the challenges posed by the extensive parameter updates required for full fine-tuning of large-scale pre-trained models, parameter-efficient fine-tuning (PEFT) methods, exemplified by Low-Rank Adaptation (LoRA), have emerged. LoRA simplifies the fine-tuning process but may still struggle with a certain level of redundancy in low-rank matrices and limited effectiveness from merely increasing their rank. To address these issues, a natural idea is to enhance the independence and diversity of the learning process for the low-rank matrices. Therefore, we propose Masked LoRA Experts (MLAE), an innovative approach that applies the concept of masking to PEFT. Our method incorporates a cellular decomposition strategy that transforms a low-rank matrix into independent rank-1 submatrices, or ``experts'', thus enhancing independence. Additionally, we introduce a binary mask matrix that selectively activates these experts during training to promote more diverse and anisotropic learning, based on expert-level dropout strategies. Our investigations reveal that this selective activation not only enhances performance but also fosters a more diverse acquisition of knowledge with a marked decrease in parameter similarity among MLAE, significantly boosting the quality of the model while barely increasing the parameter count. Remarkably, MLAE achieves new SOTA performance with an average accuracy score of 78.8% on the VTAB-1k benchmark and 90.9% on the FGVC benchmark, demonstrating superior performance. Our code is available at https://github.com/jie040109/MLAE.","sentences":["In response to the challenges posed by the extensive parameter updates required for full fine-tuning of large-scale pre-trained models, parameter-efficient fine-tuning (PEFT) methods, exemplified by Low-Rank Adaptation (LoRA), have emerged.","LoRA simplifies the fine-tuning process but may still struggle with a certain level of redundancy in low-rank matrices and limited effectiveness from merely increasing their rank.","To address these issues, a natural idea is to enhance the independence and diversity of the learning process for the low-rank matrices.","Therefore, we propose Masked LoRA Experts (MLAE), an innovative approach that applies the concept of masking to PEFT.","Our method incorporates a cellular decomposition strategy that transforms a low-rank matrix into independent rank-1 submatrices, or ``experts'', thus enhancing independence.","Additionally, we introduce a binary mask matrix that selectively activates these experts during training to promote more diverse and anisotropic learning, based on expert-level dropout strategies.","Our investigations reveal that this selective activation not only enhances performance but also fosters a more diverse acquisition of knowledge with a marked decrease in parameter similarity among MLAE, significantly boosting the quality of the model while barely increasing the parameter count.","Remarkably, MLAE achieves new SOTA performance with an average accuracy score of 78.8% on the VTAB-1k benchmark and 90.9% on the FGVC benchmark, demonstrating superior performance.","Our code is available at https://github.com/jie040109/MLAE."],"url":"http://arxiv.org/abs/2405.18897v1","category":"cs.CV"}
{"created":"2024-05-29 08:42:30","title":"Compressing Large Language Models using Low Rank and Low Precision Decomposition","abstract":"The prohibitive sizes of Large Language Models (LLMs) today make it difficult to deploy them on memory-constrained edge devices. This work introduces $\\rm CALDERA$ -- a new post-training LLM compression algorithm that harnesses the inherent low-rank structure of a weight matrix $\\mathbf{W}$ by approximating it via a low-rank, low-precision decomposition as $\\mathbf{W} \\approx \\mathbf{Q} + \\mathbf{L}\\mathbf{R}$. Here, $\\mathbf{L}$ and $\\mathbf{R}$ are low rank factors, and the entries of $\\mathbf{Q}$, $\\mathbf{L}$ and $\\mathbf{R}$ are quantized. The model is compressed by substituting each layer with its $\\mathbf{Q} + \\mathbf{L}\\mathbf{R}$ decomposition, and the zero-shot performance of the compressed model is evaluated. Additionally, $\\mathbf{L}$ and $\\mathbf{R}$ are readily amenable to low-rank adaptation, consequently enhancing the zero-shot performance. $\\rm CALDERA$ obtains this decomposition by formulating it as an optimization problem $\\min_{\\mathbf{Q},\\mathbf{L},\\mathbf{R}}\\lVert(\\mathbf{Q} + \\mathbf{L}\\mathbf{R} - \\mathbf{W})\\mathbf{X}^\\top\\rVert_{\\rm F}^2$, where $\\mathbf{X}$ is the calibration data, and $\\mathbf{Q}, \\mathbf{L}, \\mathbf{R}$ are constrained to be representable using low-precision formats. Theoretical upper bounds on the approximation error of $\\rm CALDERA$ are established using a rank-constrained regression framework, and the tradeoff between compression ratio and model performance is studied by analyzing the impact of target rank and quantization bit budget. Results illustrate that compressing LlaMa-$2$ $7$B/$70$B and LlaMa-$3$ $8$B models obtained using $\\rm CALDERA$ outperforms existing post-training LLM compression techniques in the regime of less than $2.5$ bits per parameter. The implementation is available at: \\href{https://github.com/pilancilab/caldera}{https://github.com/pilancilab/caldera}.","sentences":["The prohibitive sizes of Large Language Models (LLMs) today make it difficult to deploy them on memory-constrained edge devices.","This work introduces $\\rm CALDERA$ -- a new post-training LLM compression algorithm that harnesses the inherent low-rank structure of a weight matrix $\\mathbf{W}$ by approximating it via a low-rank, low-precision decomposition as $\\mathbf{W} \\approx \\mathbf{Q} + \\mathbf{L}\\mathbf{R}$. Here, $\\mathbf{L}$ and $\\mathbf{R}$ are low rank factors, and the entries of $\\mathbf{Q}$, $\\mathbf{L}$ and $\\mathbf{R}$ are quantized.","The model is compressed by substituting each layer with its $\\mathbf{Q} + \\mathbf{L}\\mathbf{R}$ decomposition, and the zero-shot performance of the compressed model is evaluated.","Additionally, $\\mathbf{L}$ and $\\mathbf{R}$ are readily amenable to low-rank adaptation, consequently enhancing the zero-shot performance.","$\\rm CALDERA$ obtains this decomposition by formulating it as an optimization problem $\\min_{\\mathbf{Q},\\mathbf{L},\\mathbf{R}}\\lVert(\\mathbf{Q} + \\mathbf{L}\\mathbf{R} - \\mathbf{W})\\mathbf{X}^\\top\\rVert_{\\rm F}^2$, where $\\mathbf{X}$ is the calibration data, and $\\mathbf{Q}, \\mathbf{L}, \\mathbf{R}$ are constrained to be representable using low-precision formats.","Theoretical upper bounds on the approximation error of $\\rm CALDERA$ are established using a rank-constrained regression framework, and the tradeoff between compression ratio and model performance is studied by analyzing the impact of target rank and quantization bit budget.","Results illustrate that compressing LlaMa-$2$ $7$B/$70$B and LlaMa-$3$ $8$B models obtained using $\\rm CALDERA$ outperforms existing post-training LLM compression techniques in the regime of less than $2.5$ bits per parameter.","The implementation is available at: \\href{https://github.com/pilancilab/caldera}{https://github.com/pilancilab/caldera}."],"url":"http://arxiv.org/abs/2405.18886v1","category":"cs.LG"}
{"created":"2024-05-29 08:39:31","title":"EventZoom: A Progressive Approach to Event-Based Data Augmentation for Enhanced Neuromorphic Vision","abstract":"Event data captured by Dynamic Vision Sensors (DVS) offers a unique approach to visual processing that differs from traditional video capture, showcasing its efficiency in dynamic and real-time scenarios. Despite advantages such as high temporal resolution and low energy consumption, the application of event data faces challenges due to limited dataset size and diversity. To address this, we developed EventZoom -- a data augmentation strategy specifically designed for event data. EventZoom employs a progressive temporal strategy that intelligently blends time and space to enhance the diversity and complexity of the data while maintaining its authenticity. This method aims to improve the quality of data for model training and enhance the adaptability and robustness of algorithms in handling complex dynamic scenes. We have experimentally validated EventZoom across various supervised learning frameworks, including supervised, semi-supervised, and unsupervised learning. Our results demonstrate that EventZoom consistently outperforms other data augmentation methods, confirming its effectiveness and applicability as a powerful event-based data augmentation tool in diverse learning settings.","sentences":["Event data captured by Dynamic Vision Sensors (DVS) offers a unique approach to visual processing that differs from traditional video capture, showcasing its efficiency in dynamic and real-time scenarios.","Despite advantages such as high temporal resolution and low energy consumption, the application of event data faces challenges due to limited dataset size and diversity.","To address this, we developed EventZoom -- a data augmentation strategy specifically designed for event data.","EventZoom employs a progressive temporal strategy that intelligently blends time and space to enhance the diversity and complexity of the data while maintaining its authenticity.","This method aims to improve the quality of data for model training and enhance the adaptability and robustness of algorithms in handling complex dynamic scenes.","We have experimentally validated EventZoom across various supervised learning frameworks, including supervised, semi-supervised, and unsupervised learning.","Our results demonstrate that EventZoom consistently outperforms other data augmentation methods, confirming its effectiveness and applicability as a powerful event-based data augmentation tool in diverse learning settings."],"url":"http://arxiv.org/abs/2405.18880v1","category":"cs.CV"}
{"created":"2024-05-29 08:10:29","title":"Inference under covariate-adaptive randomization with many strata","abstract":"Covariate-adaptive randomization is widely employed to balance baseline covariates in interventional studies such as clinical trials and experiments in development economics. Recent years have witnessed substantial progress in inference under covariate-adaptive randomization with a fixed number of strata. However, concerns have been raised about the impact of a large number of strata on its design and analysis, which is a common scenario in practice, such as in multicenter randomized clinical trials. In this paper, we propose a general framework for inference under covariate-adaptive randomization, which extends the seminal works of Bugni et al. (2018, 2019) by allowing for a diverging number of strata. Furthermore, we introduce a novel weighted regression adjustment that ensures efficiency improvement. On top of establishing the asymptotic theory, practical algorithms for handling situations involving an extremely large number of strata are also developed. Moreover, by linking design balance and inference robustness, we highlight the advantages of stratified block randomization, which enforces better covariate balance within strata compared to simple randomization. This paper offers a comprehensive landscape of inference under covariate-adaptive randomization, spanning from fixed to diverging to extremely large numbers of strata.","sentences":["Covariate-adaptive randomization is widely employed to balance baseline covariates in interventional studies such as clinical trials and experiments in development economics.","Recent years have witnessed substantial progress in inference under covariate-adaptive randomization with a fixed number of strata.","However, concerns have been raised about the impact of a large number of strata on its design and analysis, which is a common scenario in practice, such as in multicenter randomized clinical trials.","In this paper, we propose a general framework for inference under covariate-adaptive randomization, which extends the seminal works of Bugni et al.","(2018, 2019) by allowing for a diverging number of strata.","Furthermore, we introduce a novel weighted regression adjustment that ensures efficiency improvement.","On top of establishing the asymptotic theory, practical algorithms for handling situations involving an extremely large number of strata are also developed.","Moreover, by linking design balance and inference robustness, we highlight the advantages of stratified block randomization, which enforces better covariate balance within strata compared to simple randomization.","This paper offers a comprehensive landscape of inference under covariate-adaptive randomization, spanning from fixed to diverging to extremely large numbers of strata."],"url":"http://arxiv.org/abs/2405.18856v1","category":"stat.ME"}
{"created":"2024-05-29 08:01:18","title":"Approximation of the steady state for piecewise stable Ornstein-Uhlenbeck processes arising in queueing networks","abstract":"We shall use the Euler-Maruyama (EM) scheme with decreasing step size $\\Lambda=(\\eta_n)_{n\\in \\mathbb{N}}$ to approximate the steady state for piecewise $\\alpha$-stable Ornstein-Uhlenbeck processes arising in queue networks. These processes do not have an explicit dissipation. We prove the EM scheme converges to the steady state with a rate $\\eta^{1/\\alpha}_n$ in Wasserstein-1 distance. In addition, we utilize the Sinkhorn--Knopp algorithm to compute the Wasserstein-1 distance and conduct the simulations for several examples.","sentences":["We shall use the Euler-Maruyama (EM) scheme with decreasing step size $\\Lambda=(\\eta_n)_{n\\in \\mathbb{N}}$ to approximate the steady state for piecewise $\\alpha$-stable Ornstein-Uhlenbeck processes arising in queue networks.","These processes do not have an explicit dissipation.","We prove the EM scheme converges to the steady state with a rate $\\eta^{1/\\alpha}_n$ in Wasserstein-1 distance.","In addition, we utilize the Sinkhorn--Knopp algorithm to compute the Wasserstein-1 distance and conduct the simulations for several examples."],"url":"http://arxiv.org/abs/2405.18851v1","category":"math.PR"}
{"created":"2024-05-29 07:50:47","title":"Data-driven Machinery Fault Detection: A Comprehensive Review","abstract":"In this era of advanced manufacturing, it's now more crucial than ever to diagnose machine faults as early as possible to guarantee their safe and efficient operation. With the massive surge in industrial big data and advancement in sensing and computational technologies, data-driven Machinery Fault Diagnosis (MFD) solutions based on machine/deep learning approaches have been used ubiquitously in manufacturing. Timely and accurately identifying faulty machine signals is vital in industrial applications for which many relevant solutions have been proposed and are reviewed in many articles. Despite the availability of numerous solutions and reviews on MFD, existing works often lack several aspects. Most of the available literature has limited applicability in a wide range of manufacturing settings due to their concentration on a particular type of equipment or method of analysis. Additionally, discussions regarding the challenges associated with implementing data-driven approaches, such as dealing with noisy data, selecting appropriate features, and adapting models to accommodate new or unforeseen faults, are often superficial or completely overlooked. Thus, this survey provides a comprehensive review of the articles using different types of machine learning approaches for the detection and diagnosis of various types of machinery faults, highlights their strengths and limitations, provides a review of the methods used for condition-based analyses, comprehensively discusses the available machinery fault datasets, introduces future researchers to the possible challenges they have to encounter while using these approaches for MFD and recommends the probable solutions to mitigate those problems. The future research prospects are also pointed out for a better understanding of the field. We believe this article will help researchers and contribute to the further development of the field.","sentences":["In this era of advanced manufacturing, it's now more crucial than ever to diagnose machine faults as early as possible to guarantee their safe and efficient operation.","With the massive surge in industrial big data and advancement in sensing and computational technologies, data-driven Machinery Fault Diagnosis (MFD) solutions based on machine/deep learning approaches have been used ubiquitously in manufacturing.","Timely and accurately identifying faulty machine signals is vital in industrial applications for which many relevant solutions have been proposed and are reviewed in many articles.","Despite the availability of numerous solutions and reviews on MFD, existing works often lack several aspects.","Most of the available literature has limited applicability in a wide range of manufacturing settings due to their concentration on a particular type of equipment or method of analysis.","Additionally, discussions regarding the challenges associated with implementing data-driven approaches, such as dealing with noisy data, selecting appropriate features, and adapting models to accommodate new or unforeseen faults, are often superficial or completely overlooked.","Thus, this survey provides a comprehensive review of the articles using different types of machine learning approaches for the detection and diagnosis of various types of machinery faults, highlights their strengths and limitations, provides a review of the methods used for condition-based analyses, comprehensively discusses the available machinery fault datasets, introduces future researchers to the possible challenges they have to encounter while using these approaches for MFD and recommends the probable solutions to mitigate those problems.","The future research prospects are also pointed out for a better understanding of the field.","We believe this article will help researchers and contribute to the further development of the field."],"url":"http://arxiv.org/abs/2405.18843v1","category":"cs.AI"}
{"created":"2024-05-29 06:47:34","title":"Tilde: Teleoperation for Dexterous In-Hand Manipulation Learning with a DeltaHand","abstract":"Dexterous robotic manipulation remains a challenging domain due to its strict demands for precision and robustness on both hardware and software. While dexterous robotic hands have demonstrated remarkable capabilities in complex tasks, efficiently learning adaptive control policies for hands still presents a significant hurdle given the high dimensionalities of hands and tasks. To bridge this gap, we propose Tilde, an imitation learning-based in-hand manipulation system on a dexterous DeltaHand. It leverages 1) a low-cost, configurable, simple-to-control, soft dexterous robotic hand, DeltaHand, 2) a user-friendly, precise, real-time teleoperation interface, TeleHand, and 3) an efficient and generalizable imitation learning approach with diffusion policies. Our proposed TeleHand has a kinematic twin design to the DeltaHand that enables precise one-to-one joint control of the DeltaHand during teleoperation. This facilitates efficient high-quality data collection of human demonstrations in the real world. To evaluate the effectiveness of our system, we demonstrate the fully autonomous closed-loop deployment of diffusion policies learned from demonstrations across seven dexterous manipulation tasks with an average 90% success rate.","sentences":["Dexterous robotic manipulation remains a challenging domain due to its strict demands for precision and robustness on both hardware and software.","While dexterous robotic hands have demonstrated remarkable capabilities in complex tasks, efficiently learning adaptive control policies for hands still presents a significant hurdle given the high dimensionalities of hands and tasks.","To bridge this gap, we propose Tilde, an imitation learning-based in-hand manipulation system on a dexterous DeltaHand.","It leverages 1) a low-cost, configurable, simple-to-control, soft dexterous robotic hand, DeltaHand, 2) a user-friendly, precise, real-time teleoperation interface, TeleHand, and 3) an efficient and generalizable imitation learning approach with diffusion policies.","Our proposed TeleHand has a kinematic twin design to the DeltaHand that enables precise one-to-one joint control of the DeltaHand during teleoperation.","This facilitates efficient high-quality data collection of human demonstrations in the real world.","To evaluate the effectiveness of our system, we demonstrate the fully autonomous closed-loop deployment of diffusion policies learned from demonstrations across seven dexterous manipulation tasks with an average 90% success rate."],"url":"http://arxiv.org/abs/2405.18804v1","category":"cs.RO"}
{"created":"2024-05-29 06:18:09","title":"Adaptive Discretization-based Non-Episodic Reinforcement Learning in Metric Spaces","abstract":"We study non-episodic Reinforcement Learning for Lipschitz MDPs in which state-action space is a metric space, and the transition kernel and rewards are Lipschitz functions. We develop computationally efficient UCB-based algorithm, $\\textit{ZoRL-}\\epsilon$ that adaptively discretizes the state-action space and show that their regret as compared with $\\epsilon$-optimal policy is bounded as $\\mathcal{O}(\\epsilon^{-(2 d_\\mathcal{S} + d^\\epsilon_z + 1)}\\log{(T)})$, where $d^\\epsilon_z$ is the $\\epsilon$-zooming dimension. In contrast, if one uses the vanilla $\\textit{UCRL-}2$ on a fixed discretization of the MDP, the regret w.r.t. a $\\epsilon$-optimal policy scales as $\\mathcal{O}(\\epsilon^{-(2 d_\\mathcal{S} + d + 1)}\\log{(T)})$ so that the adaptivity gains are huge when $d^\\epsilon_z \\ll d$. Note that the absolute regret of any 'uniformly good' algorithm for a large family of continuous MDPs asymptotically scales as at least $\\Omega(\\log{(T)})$. Though adaptive discretization has been shown to yield $\\mathcal{\\tilde{O}}(H^{2.5}K^\\frac{d_z + 1}{d_z + 2})$ regret in episodic RL, an attempt to extend this to the non-episodic case by employing constant duration episodes whose duration increases with $T$, is futile since $d_z \\to d$ as $T \\to \\infty$. The current work shows how to obtain adaptivity gains for non-episodic RL. The theoretical results are supported by simulations on two systems where the performance of $\\textit{ZoRL-}\\epsilon$ is compared with that of '$\\textit{UCRL-C}$,' the fixed discretization-based extension of $\\textit{UCRL-}2$ for systems with continuous state-action spaces.","sentences":["We study non-episodic Reinforcement Learning for Lipschitz MDPs in which state-action space is a metric space, and the transition kernel and rewards are Lipschitz functions.","We develop computationally efficient UCB-based algorithm, $\\textit{ZoRL-}\\epsilon$ that adaptively discretizes the state-action space and show that their regret as compared with $\\epsilon$-optimal policy is bounded as $\\mathcal{O}(\\epsilon^{-(2 d_\\mathcal{S} + d^\\epsilon_z + 1)}\\log{(T)})$, where $d^\\epsilon_z$ is the $\\epsilon$-zooming dimension.","In contrast, if one uses the vanilla $\\textit{UCRL-}2$ on a fixed discretization of the MDP, the regret w.r.t.","a $\\epsilon$-optimal policy scales as $\\mathcal{O}(\\epsilon^{-(2 d_\\mathcal{S}","+ d + 1)}\\log{(T)})$ so that the adaptivity gains are huge when $d^\\epsilon_z \\ll d$.","Note that the absolute regret of any 'uniformly good' algorithm for a large family of continuous MDPs asymptotically scales as","at least $\\Omega(\\log{(T)})$. Though adaptive discretization has been shown to yield $\\mathcal{\\tilde{O}}(H^{2.5}K^\\frac{d_z + 1}{d_z + 2})$ regret in episodic RL, an attempt to extend this to the non-episodic case by employing constant duration episodes whose duration increases with $T$, is futile since $d_z \\to d$ as $T \\to \\infty$. The current work shows how to obtain adaptivity gains for non-episodic RL.","The theoretical results are supported by simulations on two systems where the performance of $\\textit{ZoRL-}\\epsilon$ is compared with that of '$\\textit{UCRL-C}$,' the fixed discretization-based extension of $\\textit{UCRL-}2$ for systems with continuous state-action spaces."],"url":"http://arxiv.org/abs/2405.18793v1","category":"cs.LG"}
{"created":"2024-05-29 05:59:15","title":"A Fast and Adaptable Algorithm for Optimal Multi-Qubit Pathfinding in Quantum Circuit Compilation","abstract":"Quantum computing has the potential to significantly enhance our ability to simulate and solve complex, classically intractable problems across various fields of research and industry. However, we are currently in the noisy intermediate-scale quantum (NISQ) era, where devices are relatively small and suffer from substantial noise levels, prohibiting large-scale computations. To achieve any quantum advantage in this regime and beyond, it is crucial to minimise the impact of noise from qubit decoherence and two-qubit gates. A direct approach is to improve the optimisation of quantum circuit compilation processes that map circuits onto physical devices, thereby reducing noisy gates and circuit execution times. This work focuses on multi-qubit pathfinding as a critical subroutine within the quantum circuit compilation mapping problem. We introduce an algorithm, modelled using binary integer linear programming, that navigates qubits on quantum hardware optimally with respect to circuit SWAP-gate depth, while also optimising for accumulated gate errors and can be flexibly adapted to various problem modifications. This multi-qubit pathfinding algorithm incorporates considerations for gate-error penalties, SWAP movement constraints, and configurable arrangements of source and target qubit locations and qubit teams. We have benchmarked the algorithm across a variety of quantum hardware layouts, assessing properties such as computational runtimes, solution SWAP depths, and accumulated SWAP-gate error rates. The results demonstrate the algorithm's practical runtimes on current quantum devices and compare its effectiveness across different hardware configurations, providing insights for future quantum hardware design.","sentences":["Quantum computing has the potential to significantly enhance our ability to simulate and solve complex, classically intractable problems across various fields of research and industry.","However, we are currently in the noisy intermediate-scale quantum (NISQ) era, where devices are relatively small and suffer from substantial noise levels, prohibiting large-scale computations.","To achieve any quantum advantage in this regime and beyond, it is crucial to minimise the impact of noise from qubit decoherence and two-qubit gates.","A direct approach is to improve the optimisation of quantum circuit compilation processes that map circuits onto physical devices, thereby reducing noisy gates and circuit execution times.","This work focuses on multi-qubit pathfinding as a critical subroutine within the quantum circuit compilation mapping problem.","We introduce an algorithm, modelled using binary integer linear programming, that navigates qubits on quantum hardware optimally with respect to circuit SWAP-gate depth, while also optimising for accumulated gate errors and can be flexibly adapted to various problem modifications.","This multi-qubit pathfinding algorithm incorporates considerations for gate-error penalties, SWAP movement constraints, and configurable arrangements of source and target qubit locations and qubit teams.","We have benchmarked the algorithm across a variety of quantum hardware layouts, assessing properties such as computational runtimes, solution SWAP depths, and accumulated SWAP-gate error rates.","The results demonstrate the algorithm's practical runtimes on current quantum devices and compare its effectiveness across different hardware configurations, providing insights for future quantum hardware design."],"url":"http://arxiv.org/abs/2405.18785v1","category":"quant-ph"}
{"created":"2024-05-29 05:56:44","title":"Global optimization in variational quantum algorithms via dynamic tunneling method","abstract":"We present a global optimization routine for the variational quantum algorithms, which utilizes the dynamic tunneling flow. Originally designed to leverage information gathered by a gradient-based optimizer around local minima, we adapt the conventional dynamic tunneling flow to exploit the distance measure of quantum states, resolving issues of extrinsic degeneracy arising from the parametrization of quantum states. Our global optimization algorithm is applied to the variational quantum eigensolver for the transverse-field Ising model to demonstrate the performance of our routine while comparing it with the conventional dynamic tunneling method, which is based on the Euclidean distance measure on the parameter space.","sentences":["We present a global optimization routine for the variational quantum algorithms, which utilizes the dynamic tunneling flow.","Originally designed to leverage information gathered by a gradient-based optimizer around local minima, we adapt the conventional dynamic tunneling flow to exploit the distance measure of quantum states, resolving issues of extrinsic degeneracy arising from the parametrization of quantum states.","Our global optimization algorithm is applied to the variational quantum eigensolver for the transverse-field Ising model to demonstrate the performance of our routine while comparing it with the conventional dynamic tunneling method, which is based on the Euclidean distance measure on the parameter space."],"url":"http://arxiv.org/abs/2405.18783v1","category":"quant-ph"}
{"created":"2024-05-29 05:36:03","title":"SPABA: A Single-Loop and Probabilistic Stochastic Bilevel Algorithm Achieving Optimal Sample Complexity","abstract":"While stochastic bilevel optimization methods have been extensively studied for addressing large-scale nested optimization problems in machine learning, it remains an open question whether the optimal complexity bounds for solving bilevel optimization are the same as those in single-level optimization. Our main result resolves this question: SPABA, an adaptation of the PAGE method for nonconvex optimization in (Li et al., 2021) to the bilevel setting, can achieve optimal sample complexity in both the finite-sum and expectation settings. We show the optimality of SPABA by proving that there is no gap in complexity analysis between stochastic bilevel and single-level optimization when implementing PAGE. Notably, as indicated by the results of (Dagr\\'eou et al., 2022), there might exist a gap in complexity analysis when implementing other stochastic gradient estimators, like SGD and SAGA. In addition to SPABA, we propose several other single-loop stochastic bilevel algorithms, that either match or improve the state-of-the-art sample complexity results, leveraging our convergence rate and complexity analysis. Numerical experiments demonstrate the superior practical performance of the proposed methods.","sentences":["While stochastic bilevel optimization methods have been extensively studied for addressing large-scale nested optimization problems in machine learning, it remains an open question whether the optimal complexity bounds for solving bilevel optimization are the same as those in single-level optimization.","Our main result resolves this question: SPABA, an adaptation of the PAGE method for nonconvex optimization in (Li et al., 2021) to the bilevel setting, can achieve optimal sample complexity in both the finite-sum and expectation settings.","We show the optimality of SPABA by proving that there is no gap in complexity analysis between stochastic bilevel and single-level optimization when implementing PAGE.","Notably, as indicated by the results of (Dagr\\'eou et al., 2022), there might exist a gap in complexity analysis when implementing other stochastic gradient estimators, like SGD and SAGA.","In addition to SPABA, we propose several other single-loop stochastic bilevel algorithms, that either match or improve the state-of-the-art sample complexity results, leveraging our convergence rate and complexity analysis.","Numerical experiments demonstrate the superior practical performance of the proposed methods."],"url":"http://arxiv.org/abs/2405.18777v1","category":"math.OC"}
{"created":"2024-05-29 05:26:25","title":"LLaMA-Reg: Using LLaMA 2 for Unsupervised Medical Image Registration","abstract":"Medical image registration is an essential topic in medical image analysis. In this paper, we propose a method for medical image registration using a pretrained large language model. We find that using the pretrained large language model to encode deep features of the medical images in the registration model can effectively improve image registration accuracy, indicating the great potential of the large language model in medical image registration tasks. We use dual encoders to perform deep feature extraction on image pairs and then input the features into the pretrained large language model. To adapt the large language model to our registration task, the weights of the large language model are frozen in the registration model, and an adapter is utilized to fine-tune the large language model, which aims at (a) mapping the visual tokens to the language space before the large language model computing, (b) project the modeled language tokens output from the large language model to the visual space. Our method combines output features from the fine-tuned large language model with the features output from each encoder layer to gradually generate the deformation fields required for registration in the decoder. To demonstrate the effectiveness of the large prediction model in registration tasks, we conducted experiments on knee and brain MRI and achieved state-of-the-art results.","sentences":["Medical image registration is an essential topic in medical image analysis.","In this paper, we propose a method for medical image registration using a pretrained large language model.","We find that using the pretrained large language model to encode deep features of the medical images in the registration model can effectively improve image registration accuracy, indicating the great potential of the large language model in medical image registration tasks.","We use dual encoders to perform deep feature extraction on image pairs and then input the features into the pretrained large language model.","To adapt the large language model to our registration task, the weights of the large language model are frozen in the registration model, and an adapter is utilized to fine-tune the large language model, which aims at (a) mapping the visual tokens to the language space before the large language model computing, (b) project the modeled language tokens output from the large language model to the visual space.","Our method combines output features from the fine-tuned large language model with the features output from each encoder layer to gradually generate the deformation fields required for registration in the decoder.","To demonstrate the effectiveness of the large prediction model in registration tasks, we conducted experiments on knee and brain MRI and achieved state-of-the-art results."],"url":"http://arxiv.org/abs/2405.18774v1","category":"cs.CV"}
{"created":"2024-05-29 05:10:25","title":"RNAFlow: RNA Structure & Sequence Design via Inverse Folding-Based Flow Matching","abstract":"The growing significance of RNA engineering in diverse biological applications has spurred interest in developing AI methods for structure-based RNA design. While diffusion models have excelled in protein design, adapting them for RNA presents new challenges due to RNA's conformational flexibility and the computational cost of fine-tuning large structure prediction models. To this end, we propose RNAFlow, a flow matching model for protein-conditioned RNA sequence-structure design. Its denoising network integrates an RNA inverse folding model and a pre-trained RosettaFold2NA network for generation of RNA sequences and structures. The integration of inverse folding in the structure denoising process allows us to simplify training by fixing the structure prediction network. We further enhance the inverse folding model by conditioning it on inferred conformational ensembles to model dynamic RNA conformations. Evaluation on protein-conditioned RNA structure and sequence generation tasks demonstrates RNAFlow's advantage over existing RNA design methods.","sentences":["The growing significance of RNA engineering in diverse biological applications has spurred interest in developing AI methods for structure-based RNA design.","While diffusion models have excelled in protein design, adapting them for RNA presents new challenges due to RNA's conformational flexibility and the computational cost of fine-tuning large structure prediction models.","To this end, we propose RNAFlow, a flow matching model for protein-conditioned RNA sequence-structure design.","Its denoising network integrates an RNA inverse folding model and a pre-trained RosettaFold2NA network for generation of RNA sequences and structures.","The integration of inverse folding in the structure denoising process allows us to simplify training by fixing the structure prediction network.","We further enhance the inverse folding model by conditioning it on inferred conformational ensembles to model dynamic RNA conformations.","Evaluation on protein-conditioned RNA structure and sequence generation tasks demonstrates RNAFlow's advantage over existing RNA design methods."],"url":"http://arxiv.org/abs/2405.18768v1","category":"q-bio.BM"}
{"created":"2024-05-29 05:00:50","title":"FDQN: A Flexible Deep Q-Network Framework for Game Automation","abstract":"In reinforcement learning, it is often difficult to automate high-dimensional, rapid decision-making in dynamic environments, especially when domains require real-time online interaction and adaptive strategies such as web-based games. This work proposes a state-of-the-art Flexible Deep Q-Network (FDQN) framework that can address this challenge with a selfadaptive approach that is processing high-dimensional sensory data in realtime using a CNN and dynamically adapting the model architecture to varying action spaces of different gaming environments and outperforming previous baseline models in various Atari games and the Chrome Dino game as baselines. Using the epsilon-greedy policy, it effectively balances the new learning and exploitation for improved performance, and it has been designed with a modular structure that it can be easily adapted to other HTML-based games without touching the core part of the framework. It is demonstrated that the FDQN framework can successfully solve a well-defined task in a laboratory condition, but more importantly it also discusses potential applications to more challenging real-world cases and serve as the starting point for future further exploration into automated game play and beyond.","sentences":["In reinforcement learning, it is often difficult to automate high-dimensional, rapid decision-making in dynamic environments, especially when domains require real-time online interaction and adaptive strategies such as web-based games.","This work proposes a state-of-the-art Flexible Deep Q-Network (FDQN) framework that can address this challenge with a selfadaptive approach that is processing high-dimensional sensory data in realtime using a CNN and dynamically adapting the model architecture to varying action spaces of different gaming environments and outperforming previous baseline models in various Atari games and the Chrome Dino game as baselines.","Using the epsilon-greedy policy, it effectively balances the new learning and exploitation for improved performance, and it has been designed with a modular structure that it can be easily adapted to other HTML-based games without touching the core part of the framework.","It is demonstrated that the FDQN framework can successfully solve a well-defined task in a laboratory condition, but more importantly it also discusses potential applications to more challenging real-world cases and serve as the starting point for future further exploration into automated game play and beyond."],"url":"http://arxiv.org/abs/2405.18761v1","category":"cs.LG"}
{"created":"2024-05-29 04:48:11","title":"Provable Contrastive Continual Learning","abstract":"Continual learning requires learning incremental tasks with dynamic data distributions. So far, it has been observed that employing a combination of contrastive loss and distillation loss for training in continual learning yields strong performance. To the best of our knowledge, however, this contrastive continual learning framework lacks convincing theoretical explanations. In this work, we fill this gap by establishing theoretical performance guarantees, which reveal how the performance of the model is bounded by training losses of previous tasks in the contrastive continual learning framework. Our theoretical explanations further support the idea that pre-training can benefit continual learning. Inspired by our theoretical analysis of these guarantees, we propose a novel contrastive continual learning algorithm called CILA, which uses adaptive distillation coefficients for different tasks. These distillation coefficients are easily computed by the ratio between average distillation losses and average contrastive losses from previous tasks. Our method shows great improvement on standard benchmarks and achieves new state-of-the-art performance.","sentences":["Continual learning requires learning incremental tasks with dynamic data distributions.","So far, it has been observed that employing a combination of contrastive loss and distillation loss for training in continual learning yields strong performance.","To the best of our knowledge, however, this contrastive continual learning framework lacks convincing theoretical explanations.","In this work, we fill this gap by establishing theoretical performance guarantees, which reveal how the performance of the model is bounded by training losses of previous tasks in the contrastive continual learning framework.","Our theoretical explanations further support the idea that pre-training can benefit continual learning.","Inspired by our theoretical analysis of these guarantees, we propose a novel contrastive continual learning algorithm called CILA, which uses adaptive distillation coefficients for different tasks.","These distillation coefficients are easily computed by the ratio between average distillation losses and average contrastive losses from previous tasks.","Our method shows great improvement on standard benchmarks and achieves new state-of-the-art performance."],"url":"http://arxiv.org/abs/2405.18756v1","category":"cs.LG"}
{"created":"2024-05-29 03:53:52","title":"FlocOff: Data Heterogeneity Resilient Federated Learning with Communication-Efficient Edge Offloading","abstract":"Federated Learning (FL) has emerged as a fundamental learning paradigm to harness massive data scattered at geo-distributed edge devices in a privacy-preserving way. Given the heterogeneous deployment of edge devices, however, their data are usually Non-IID, introducing significant challenges to FL including degraded training accuracy, intensive communication costs, and high computing complexity. Towards that, traditional approaches typically utilize adaptive mechanisms, which may suffer from scalability issues, increased computational overhead, and limited adaptability to diverse edge environments. To address that, this paper instead leverages the observation that the computation offloading involves inherent functionalities such as node matching and service correlation to achieve data reshaping and proposes Federated learning based on computing Offloading (FlocOff) framework, to address data heterogeneity and resource-constrained challenges. Specifically, FlocOff formulates the FL process with Non-IID data in edge scenarios and derives rigorous analysis on the impact of imbalanced data distribution. Based on this, FlocOff decouples the optimization in two steps, namely : (1) Minimizes the Kullback-Leibler (KL) divergence via Computation Offloading scheduling (MKL-CO); (2) Minimizes the Communication Cost through Resource Allocation (MCC-RA). Extensive experimental results demonstrate that the proposed FlocOff effectively improves model convergence and accuracy by 14.3\\%-32.7\\% while reducing data heterogeneity under various data distributions.","sentences":["Federated Learning (FL) has emerged as a fundamental learning paradigm to harness massive data scattered at geo-distributed edge devices in a privacy-preserving way.","Given the heterogeneous deployment of edge devices, however, their data are usually Non-IID, introducing significant challenges to FL including degraded training accuracy, intensive communication costs, and high computing complexity.","Towards that, traditional approaches typically utilize adaptive mechanisms, which may suffer from scalability issues, increased computational overhead, and limited adaptability to diverse edge environments.","To address that, this paper instead leverages the observation that the computation offloading involves inherent functionalities such as node matching and service correlation to achieve data reshaping and proposes Federated learning based on computing Offloading (FlocOff) framework, to address data heterogeneity and resource-constrained challenges.","Specifically, FlocOff formulates the FL process with Non-IID data in edge scenarios and derives rigorous analysis on the impact of imbalanced data distribution.","Based on this, FlocOff decouples the optimization in two steps, namely : (1) Minimizes the Kullback-Leibler (KL) divergence via Computation Offloading scheduling (MKL-CO); (2) Minimizes the Communication Cost through Resource Allocation (MCC-RA).","Extensive experimental results demonstrate that the proposed FlocOff effectively improves model convergence and accuracy by 14.3\\%-32.7\\% while reducing data heterogeneity under various data distributions."],"url":"http://arxiv.org/abs/2405.18739v1","category":"cs.NI"}
{"created":"2024-05-29 03:19:59","title":"Preferred-Action-Optimized Diffusion Policies for Offline Reinforcement Learning","abstract":"Offline reinforcement learning (RL) aims to learn optimal policies from previously collected datasets. Recently, due to their powerful representational capabilities, diffusion models have shown significant potential as policy models for offline RL issues. However, previous offline RL algorithms based on diffusion policies generally adopt weighted regression to improve the policy. This approach optimizes the policy only using the collected actions and is sensitive to Q-values, which limits the potential for further performance enhancement. To this end, we propose a novel preferred-action-optimized diffusion policy for offline RL. In particular, an expressive conditional diffusion model is utilized to represent the diverse distribution of a behavior policy. Meanwhile, based on the diffusion model, preferred actions within the same behavior distribution are automatically generated through the critic function. Moreover, an anti-noise preference optimization is designed to achieve policy improvement by using the preferred actions, which can adapt to noise-preferred actions for stable training. Extensive experiments demonstrate that the proposed method provides competitive or superior performance compared to previous state-of-the-art offline RL methods, particularly in sparse reward tasks such as Kitchen and AntMaze. Additionally, we empirically prove the effectiveness of anti-noise preference optimization.","sentences":["Offline reinforcement learning (RL) aims to learn optimal policies from previously collected datasets.","Recently, due to their powerful representational capabilities, diffusion models have shown significant potential as policy models for offline RL issues.","However, previous offline RL algorithms based on diffusion policies generally adopt weighted regression to improve the policy.","This approach optimizes the policy only using the collected actions and is sensitive to Q-values, which limits the potential for further performance enhancement.","To this end, we propose a novel preferred-action-optimized diffusion policy for offline RL.","In particular, an expressive conditional diffusion model is utilized to represent the diverse distribution of a behavior policy.","Meanwhile, based on the diffusion model, preferred actions within the same behavior distribution are automatically generated through the critic function.","Moreover, an anti-noise preference optimization is designed to achieve policy improvement by using the preferred actions, which can adapt to noise-preferred actions for stable training.","Extensive experiments demonstrate that the proposed method provides competitive or superior performance compared to previous state-of-the-art offline RL methods, particularly in sparse reward tasks such as Kitchen and AntMaze.","Additionally, we empirically prove the effectiveness of anti-noise preference optimization."],"url":"http://arxiv.org/abs/2405.18729v1","category":"cs.LG"}
{"created":"2024-05-29 03:17:16","title":"CtrlA: Adaptive Retrieval-Augmented Generation via Probe-Guided Control","abstract":"Retrieval-augmented generation (RAG) has emerged as a promising solution for mitigating hallucinations of large language models (LLMs) with retrieved external knowledge. Adaptive RAG enhances this approach by dynamically assessing the retrieval necessity, aiming to balance external and internal knowledge usage. However, existing adaptive RAG methods primarily realize retrieval on demand by relying on superficially verbalize-based or probability-based feedback of LLMs, or directly fine-tuning LLMs via carefully crafted datasets, resulting in unreliable retrieval necessity decisions, heavy extra costs, and sub-optimal response generation. We present the first attempts to delve into the internal states of LLMs to mitigate such issues by introducing an effective probe-guided adaptive RAG framework, termed CtrlA. Specifically, CtrlA employs an honesty probe to regulate the LLM's behavior by manipulating its representations for increased honesty, and a confidence probe to monitor the internal states of LLM and assess confidence levels, determining the retrieval necessity during generation. Experiments show that CtrlA is superior to existing adaptive RAG methods on a diverse set of tasks, the honesty control can effectively make LLMs more honest and confidence monitoring is proven to be a promising indicator of retrieval trigger. Our codes are available at https://github.com/HSLiu-Initial/CtrlA.git.","sentences":["Retrieval-augmented generation (RAG) has emerged as a promising solution for mitigating hallucinations of large language models (LLMs) with retrieved external knowledge.","Adaptive RAG enhances this approach by dynamically assessing the retrieval necessity, aiming to balance external and internal knowledge usage.","However, existing adaptive RAG methods primarily realize retrieval on demand by relying on superficially verbalize-based or probability-based feedback of LLMs, or directly fine-tuning LLMs via carefully crafted datasets, resulting in unreliable retrieval necessity decisions, heavy extra costs, and sub-optimal response generation.","We present the first attempts to delve into the internal states of LLMs to mitigate such issues by introducing an effective probe-guided adaptive RAG framework, termed CtrlA.","Specifically, CtrlA employs an honesty probe to regulate the LLM's behavior by manipulating its representations for increased honesty, and a confidence probe to monitor the internal states of LLM and assess confidence levels, determining the retrieval necessity during generation.","Experiments show that CtrlA is superior to existing adaptive RAG methods on a diverse set of tasks, the honesty control can effectively make LLMs more honest and confidence monitoring is proven to be a promising indicator of retrieval trigger.","Our codes are available at https://github.com/HSLiu-Initial/CtrlA.git."],"url":"http://arxiv.org/abs/2405.18727v1","category":"cs.CL"}
{"created":"2024-05-29 03:10:21","title":"Adapting Differential Molecular Representation with Hierarchical Prompts for Multi-label Property Prediction","abstract":"Accurate prediction of molecular properties is critical in the field of drug discovery. However, existing methods do not fully consider the fact that molecules in the real world usually possess multiple property labels, and complex high-order relationships may exist among these labels. Therefore, molecular representation learning models should generate differential molecular representations that consider multi-granularity correlation information among tasks. To this end, our research introduces a Hierarchical Prompted Molecular Representation Learning Framework (HiPM), which enhances the differential expression of tasks in molecular representations through task-aware prompts, and utilizes shared information among labels to mitigate negative transfer between different tasks. HiPM primarily consists of two core components: the Molecular Representation Encoder (MRE) and the Task-Aware Prompter (TAP). The MRE employs a hierarchical message-passing network architecture to capture molecular features at both the atomic and motif levels, while the TAP uses agglomerative hierarchical clustering to build a prompt tree that reflects the affinity and distinctiveness of tasks, enabling the model to effectively handle the complexity of multi-label property predictions. Extensive experiments demonstrate that HiPM achieves state-of-the-art performance across various multi-label datasets, offering a new perspective on multi-label molecular representation learning.","sentences":["Accurate prediction of molecular properties is critical in the field of drug discovery.","However, existing methods do not fully consider the fact that molecules in the real world usually possess multiple property labels, and complex high-order relationships may exist among these labels.","Therefore, molecular representation learning models should generate differential molecular representations that consider multi-granularity correlation information among tasks.","To this end, our research introduces a Hierarchical Prompted Molecular Representation Learning Framework (HiPM), which enhances the differential expression of tasks in molecular representations through task-aware prompts, and utilizes shared information among labels to mitigate negative transfer between different tasks.","HiPM primarily consists of two core components: the Molecular Representation Encoder (MRE) and the Task-Aware Prompter (TAP).","The MRE employs a hierarchical message-passing network architecture to capture molecular features at both the atomic and motif levels, while the TAP uses agglomerative hierarchical clustering to build a prompt tree that reflects the affinity and distinctiveness of tasks, enabling the model to effectively handle the complexity of multi-label property predictions.","Extensive experiments demonstrate that HiPM achieves state-of-the-art performance across various multi-label datasets, offering a new perspective on multi-label molecular representation learning."],"url":"http://arxiv.org/abs/2405.18724v1","category":"q-bio.QM"}
{"created":"2024-05-29 03:05:59","title":"Adaptive and Efficient Learning with Blockwise Missing and Semi-Supervised Data","abstract":"Data fusion is an important way to realize powerful and generalizable analyses across multiple sources. However, different capability of data collection across the sources has become a prominent issue in practice. This could result in the blockwise missingness (BM) of covariates troublesome for integration. Meanwhile, the high cost of obtaining gold-standard labels can cause the missingness of response on a large proportion of samples, known as the semi-supervised (SS) problem. In this paper, we consider a challenging scenario confronting both the BM and SS issues, and propose a novel Data-adaptive projecting Estimation approach for data FUsion in the SEmi-supervised setting (DEFUSE). Starting with a complete-data-only estimator, it involves two successive projection steps to reduce its variance without incurring bias. Compared to existing approaches, DEFUSE achieves a two-fold improvement. First, it leverages the BM labeled sample more efficiently through a novel data-adaptive projection approach robust to model misspecification on the missing covariates, leading to better variance reduction. Second, our method further incorporates the large unlabeled sample to enhance the estimation efficiency through imputation and projection. Compared to the previous SS setting with complete covariates, our work reveals a more essential role of the unlabeled sample in the BM setting. These advantages are justified in asymptotic and simulation studies. We also apply DEFUSE for the risk modeling and inference of heart diseases with the MIMIC-III electronic medical record (EMR) data.","sentences":["Data fusion is an important way to realize powerful and generalizable analyses across multiple sources.","However, different capability of data collection across the sources has become a prominent issue in practice.","This could result in the blockwise missingness (BM) of covariates troublesome for integration.","Meanwhile, the high cost of obtaining gold-standard labels can cause the missingness of response on a large proportion of samples, known as the semi-supervised (SS) problem.","In this paper, we consider a challenging scenario confronting both the BM and SS issues, and propose a novel Data-adaptive projecting Estimation approach for data FUsion in the SEmi-supervised setting (DEFUSE).","Starting with a complete-data-only estimator, it involves two successive projection steps to reduce its variance without incurring bias.","Compared to existing approaches, DEFUSE achieves a two-fold improvement.","First, it leverages the BM labeled sample more efficiently through a novel data-adaptive projection approach robust to model misspecification on the missing covariates, leading to better variance reduction.","Second, our method further incorporates the large unlabeled sample to enhance the estimation efficiency through imputation and projection.","Compared to the previous SS setting with complete covariates, our work reveals a more essential role of the unlabeled sample in the BM setting.","These advantages are justified in asymptotic and simulation studies.","We also apply DEFUSE for the risk modeling and inference of heart diseases with the MIMIC-III electronic medical record (EMR) data."],"url":"http://arxiv.org/abs/2405.18722v1","category":"stat.ME"}
{"created":"2024-05-29 02:35:23","title":"Cognitive Evolutionary Learning to Select Feature Interactions for Recommender Systems","abstract":"Feature interaction selection is a fundamental problem in commercial recommender systems. Most approaches equally enumerate all features and interactions by the same pre-defined operation under expert guidance. Their recommendation is unsatisfactory sometimes due to the following issues: (1)~They cannot ensure the learning abilities of models because their architectures are poorly adaptable to tasks and data; (2)~Useless features and interactions can bring unnecessary noise and complicate the training process. In this paper, we aim to adaptively evolve the model to select appropriate operations, features, and interactions under task guidance. Inspired by the evolution and functioning of natural organisms, we propose a novel \\textsl{Cognitive EvoLutionary Learning (CELL)} framework, where cognitive ability refers to a property of organisms that allows them to react and survive in diverse environments. It consists of three stages, i.e., DNA search, genome search, and model functioning. Specifically, if we regard the relationship between models and tasks as the relationship between organisms and natural environments, interactions of feature pairs can be analogous to double-stranded DNA, of which relevant features and interactions can be analogous to genomes. Along this line, we diagnose the fitness of the model on operations, features, and interactions to simulate the survival rates of organisms for natural selection. We show that CELL can adaptively evolve into different models for different tasks and data, which enables practitioners to access off-the-shelf models. Extensive experiments on four real-world datasets demonstrate that CELL significantly outperforms state-of-the-art baselines. Also, we conduct synthetic experiments to ascertain that CELL can consistently discover the pre-defined interaction patterns for feature pairs.","sentences":["Feature interaction selection is a fundamental problem in commercial recommender systems.","Most approaches equally enumerate all features and interactions by the same pre-defined operation under expert guidance.","Their recommendation is unsatisfactory sometimes due to the following issues: (1)~They cannot ensure the learning abilities of models because their architectures are poorly adaptable to tasks and data; (2)~Useless features and interactions can bring unnecessary noise and complicate the training process.","In this paper, we aim to adaptively evolve the model to select appropriate operations, features, and interactions under task guidance.","Inspired by the evolution and functioning of natural organisms, we propose a novel \\textsl{Cognitive EvoLutionary Learning (CELL)} framework, where cognitive ability refers to a property of organisms that allows them to react and survive in diverse environments.","It consists of three stages, i.e., DNA search, genome search, and model functioning.","Specifically, if we regard the relationship between models and tasks as the relationship between organisms and natural environments, interactions of feature pairs can be analogous to double-stranded DNA, of which relevant features and interactions can be analogous to genomes.","Along this line, we diagnose the fitness of the model on operations, features, and interactions to simulate the survival rates of organisms for natural selection.","We show that CELL can adaptively evolve into different models for different tasks and data, which enables practitioners to access off-the-shelf models.","Extensive experiments on four real-world datasets demonstrate that CELL significantly outperforms state-of-the-art baselines.","Also, we conduct synthetic experiments to ascertain that CELL can consistently discover the pre-defined interaction patterns for feature pairs."],"url":"http://arxiv.org/abs/2405.18708v1","category":"cs.AI"}
{"created":"2024-05-29 02:34:38","title":"Adaptive and Parallel Split Federated Learning in Vehicular Edge Computing","abstract":"Vehicular edge intelligence (VEI) is a promising paradigm for enabling future intelligent transportation systems by accommodating artificial intelligence (AI) at the vehicular edge computing (VEC) system. Federated learning (FL) stands as one of the fundamental technologies facilitating collaborative model training locally and aggregation, while safeguarding the privacy of vehicle data in VEI. However, traditional FL faces challenges in adapting to vehicle heterogeneity, training large models on resource-constrained vehicles, and remaining susceptible to model weight privacy leakage. Meanwhile, split learning (SL) is proposed as a promising collaborative learning framework which can mitigate the risk of model wights leakage, and release the training workload on vehicles. SL sequentially trains a model between a vehicle and an edge cloud (EC) by dividing the entire model into a vehicle-side model and an EC-side model at a given cut layer. In this work, we combine the advantages of SL and FL to develop an Adaptive Split Federated Learning scheme for Vehicular Edge Computing (ASFV). The ASFV scheme adaptively splits the model and parallelizes the training process, taking into account mobile vehicle selection and resource allocation. Our extensive simulations, conducted on non-independent and identically distributed data, demonstrate that the proposed ASFV solution significantly reduces training latency compared to existing benchmarks, while adapting to network dynamics and vehicles' mobility.","sentences":["Vehicular edge intelligence (VEI) is a promising paradigm for enabling future intelligent transportation systems by accommodating artificial intelligence (AI) at the vehicular edge computing (VEC) system.","Federated learning (FL) stands as one of the fundamental technologies facilitating collaborative model training locally and aggregation, while safeguarding the privacy of vehicle data in VEI.","However, traditional FL faces challenges in adapting to vehicle heterogeneity, training large models on resource-constrained vehicles, and remaining susceptible to model weight privacy leakage.","Meanwhile, split learning (SL) is proposed as a promising collaborative learning framework which can mitigate the risk of model wights leakage, and release the training workload on vehicles.","SL sequentially trains a model between a vehicle and an edge cloud (EC) by dividing the entire model into a vehicle-side model and an EC-side model at a given cut layer.","In this work, we combine the advantages of SL and FL to develop an Adaptive Split Federated Learning scheme for Vehicular Edge Computing (ASFV).","The ASFV scheme adaptively splits the model and parallelizes the training process, taking into account mobile vehicle selection and resource allocation.","Our extensive simulations, conducted on non-independent and identically distributed data, demonstrate that the proposed ASFV solution significantly reduces training latency compared to existing benchmarks, while adapting to network dynamics and vehicles' mobility."],"url":"http://arxiv.org/abs/2405.18707v1","category":"cs.LG"}
{"created":"2024-05-29 01:07:38","title":"A random-key GRASP for combinatorial optimization","abstract":"This paper proposes a problem-independent GRASP metaheuristic using the random-key optimizer (RKO) paradigm. GRASP (greedy randomized adaptive search procedure) is a metaheuristic for combinatorial optimization that repeatedly applies a semi-greedy construction procedure followed by a local search procedure. The best solution found over all iterations is returned as the solution of the GRASP. Continuous GRASP (C-GRASP) is an extension of GRASP for continuous optimization in the unit hypercube. A random-key optimizer (RKO) uses a vector of random keys to encode a solution to a combinatorial optimization problem. It uses a decoder to evaluate a solution encoded by the vector of random keys. A random-key GRASP is a C-GRASP where points in the unit hypercube are evaluated employing a decoder. We describe random key GRASP consisting of a problem-independent component and a problem-dependent decoder. As a proof of concept, the random-key GRASP is tested on five NP-hard combinatorial optimization problems: traveling salesman problem, tree of hubs location problem, Steiner triple covering problem, node capacitated graph partitioning problem, and job sequencing and tool switching problem.","sentences":["This paper proposes a problem-independent GRASP metaheuristic using the random-key optimizer (RKO) paradigm.","GRASP (greedy randomized adaptive search procedure) is a metaheuristic for combinatorial optimization that repeatedly applies a semi-greedy construction procedure followed by a local search procedure.","The best solution found over all iterations is returned as the solution of the GRASP.","Continuous GRASP (C-GRASP) is an extension of GRASP for continuous optimization in the unit hypercube.","A random-key optimizer (RKO) uses a vector of random keys to encode a solution to a combinatorial optimization problem.","It uses a decoder to evaluate a solution encoded by the vector of random keys.","A random-key GRASP is a C-GRASP where points in the unit hypercube are evaluated employing a decoder.","We describe random key GRASP consisting of a problem-independent component and a problem-dependent decoder.","As a proof of concept, the random-key GRASP is tested on five NP-hard combinatorial optimization problems: traveling salesman problem, tree of hubs location problem, Steiner triple covering problem, node capacitated graph partitioning problem, and job sequencing and tool switching problem."],"url":"http://arxiv.org/abs/2405.18681v2","category":"cs.NE"}
{"created":"2024-05-29 00:25:07","title":"Adapting Differentially Private Synthetic Data to Relational Databases","abstract":"Existing differentially private (DP) synthetic data generation mechanisms typically assume a single-source table. In practice, data is often distributed across multiple tables with relationships across tables. In this paper, we introduce the first-of-its-kind algorithm that can be combined with any existing DP mechanisms to generate synthetic relational databases. Our algorithm iteratively refines the relationship between individual synthetic tables to minimize their approximation errors in terms of low-order marginal distributions while maintaining referential integrity. Finally, we provide both DP and theoretical utility guarantees for our algorithm.","sentences":["Existing differentially private (DP) synthetic data generation mechanisms typically assume a single-source table.","In practice, data is often distributed across multiple tables with relationships across tables.","In this paper, we introduce the first-of-its-kind algorithm that can be combined with any existing DP mechanisms to generate synthetic relational databases.","Our algorithm iteratively refines the relationship between individual synthetic tables to minimize their approximation errors in terms of low-order marginal distributions while maintaining referential integrity.","Finally, we provide both DP and theoretical utility guarantees for our algorithm."],"url":"http://arxiv.org/abs/2405.18670v1","category":"cs.LG"}
{"created":"2024-05-28 23:54:01","title":"Weak (non)conservation and stochastic dynamics of angular momentum","abstract":"Angular momentum conservation influences equilibrium statistical mechanics, leading to a generalized microcanonical density for an isolated system and a generalized Gibbs density for a weakly coupled system. We study the stochastic decay of angular momentum due to weakly imperfect rotational symmetry of the external potential that confines the isolated many-particle system. We present a mesoscopic description of the system, deriving Langevin and Fokker-Planck equations, which are consistent with equilibrium statistical mechanics when rotational symmetry is maintained. When the symmetry is weakly violated, we formulate a coarse-grained stochastic differential equation governing the decay of total angular momentum over time. To validate our analytical predictions, we conduct numerical simulations of the microcanonical ensemble, an isolated system undergoing thermalization due to weak two-body interactions. Our coarse-grained Langevin equation accurately characterizes both the decay of the angular momentum and its fluctuations in a steady state. Furthermore, we estimate the parameters of our mesoscopic model directly from simulations, providing insights into the dissipative phenomenological coefficients, such as friction. More generally, this study contributes to a deeper understanding of the behavior of the integrals of motion when the corresponding symmetry is weakly violated.","sentences":["Angular momentum conservation influences equilibrium statistical mechanics, leading to a generalized microcanonical density for an isolated system and a generalized Gibbs density for a weakly coupled system.","We study the stochastic decay of angular momentum due to weakly imperfect rotational symmetry of the external potential that confines the isolated many-particle system.","We present a mesoscopic description of the system, deriving Langevin and Fokker-Planck equations, which are consistent with equilibrium statistical mechanics when rotational symmetry is maintained.","When the symmetry is weakly violated, we formulate a coarse-grained stochastic differential equation governing the decay of total angular momentum over time.","To validate our analytical predictions, we conduct numerical simulations of the microcanonical ensemble, an isolated system undergoing thermalization due to weak two-body interactions.","Our coarse-grained Langevin equation accurately characterizes both the decay of the angular momentum and its fluctuations in a steady state.","Furthermore, we estimate the parameters of our mesoscopic model directly from simulations, providing insights into the dissipative phenomenological coefficients, such as friction.","More generally, this study contributes to a deeper understanding of the behavior of the integrals of motion when the corresponding symmetry is weakly violated."],"url":"http://arxiv.org/abs/2405.18660v1","category":"cond-mat.stat-mech"}
{"created":"2024-05-28 23:49:52","title":"D-CoRP: Differentiable Connectivity Refinement for Functional Brain Networks","abstract":"Brain network is an important tool for understanding the brain, offering insights for scientific research and clinical diagnosis. Existing models for brain networks typically primarily focus on brain regions or overlook the complexity of brain connectivities. MRI-derived brain network data is commonly susceptible to connectivity noise, underscoring the necessity of incorporating connectivities into the modeling of brain networks. To address this gap, we introduce a differentiable module for refining brain connectivity. We develop the multivariate optimization based on information bottleneck theory to address the complexity of the brain network and filter noisy or redundant connections. Also, our method functions as a flexible plugin that is adaptable to most graph neural networks. Our extensive experimental results show that the proposed method can significantly improve the performance of various baseline models and outperform other state-of-the-art methods, indicating the effectiveness and generalizability of the proposed method in refining brain network connectivity. The code will be released for public availability.","sentences":["Brain network is an important tool for understanding the brain, offering insights for scientific research and clinical diagnosis.","Existing models for brain networks typically primarily focus on brain regions or overlook the complexity of brain connectivities.","MRI-derived brain network data is commonly susceptible to connectivity noise, underscoring the necessity of incorporating connectivities into the modeling of brain networks.","To address this gap, we introduce a differentiable module for refining brain connectivity.","We develop the multivariate optimization based on information bottleneck theory to address the complexity of the brain network and filter noisy or redundant connections.","Also, our method functions as a flexible plugin that is adaptable to most graph neural networks.","Our extensive experimental results show that the proposed method can significantly improve the performance of various baseline models and outperform other state-of-the-art methods, indicating the effectiveness and generalizability of the proposed method in refining brain network connectivity.","The code will be released for public availability."],"url":"http://arxiv.org/abs/2405.18658v1","category":"q-bio.NC"}
{"created":"2024-05-28 23:32:46","title":"Recent Advances of Foundation Language Models-based Continual Learning: A Survey","abstract":"Recently, foundation language models (LMs) have marked significant achievements in the domains of natural language processing (NLP) and computer vision (CV). Unlike traditional neural network models, foundation LMs obtain a great ability for transfer learning by acquiring rich commonsense knowledge through pre-training on extensive unsupervised datasets with a vast number of parameters. However, they still can not emulate human-like continuous learning due to catastrophic forgetting. Consequently, various continual learning (CL)-based methodologies have been developed to refine LMs, enabling them to adapt to new tasks without forgetting previous knowledge. However, a systematic taxonomy of existing approaches and a comparison of their performance are still lacking, which is the gap that our survey aims to fill. We delve into a comprehensive review, summarization, and classification of the existing literature on CL-based approaches applied to foundation language models, such as pre-trained language models (PLMs), large language models (LLMs) and vision-language models (VLMs). We divide these studies into offline CL and online CL, which consist of traditional methods, parameter-efficient-based methods, instruction tuning-based methods and continual pre-training methods. Offline CL encompasses domain-incremental learning, task-incremental learning, and class-incremental learning, while online CL is subdivided into hard task boundary and blurry task boundary settings. Additionally, we outline the typical datasets and metrics employed in CL research and provide a detailed analysis of the challenges and future work for LMs-based continual learning.","sentences":["Recently, foundation language models (LMs) have marked significant achievements in the domains of natural language processing (NLP) and computer vision (CV).","Unlike traditional neural network models, foundation LMs obtain a great ability for transfer learning by acquiring rich commonsense knowledge through pre-training on extensive unsupervised datasets with a vast number of parameters.","However, they still can not emulate human-like continuous learning due to catastrophic forgetting.","Consequently, various continual learning (CL)-based methodologies have been developed to refine LMs, enabling them to adapt to new tasks without forgetting previous knowledge.","However, a systematic taxonomy of existing approaches and a comparison of their performance are still lacking, which is the gap that our survey aims to fill.","We delve into a comprehensive review, summarization, and classification of the existing literature on CL-based approaches applied to foundation language models, such as pre-trained language models (PLMs), large language models (LLMs) and vision-language models (VLMs).","We divide these studies into offline CL and online CL, which consist of traditional methods, parameter-efficient-based methods, instruction tuning-based methods and continual pre-training methods.","Offline CL encompasses domain-incremental learning, task-incremental learning, and class-incremental learning, while online CL is subdivided into hard task boundary and blurry task boundary settings.","Additionally, we outline the typical datasets and metrics employed in CL research and provide a detailed analysis of the challenges and future work for LMs-based continual learning."],"url":"http://arxiv.org/abs/2405.18653v1","category":"cs.CL"}
{"created":"2024-05-28 23:22:18","title":"Approximating Human Models During Argumentation-based Dialogues","abstract":"Explainable AI Planning (XAIP) aims to develop AI agents that can effectively explain their decisions and actions to human users, fostering trust and facilitating human-AI collaboration. A key challenge in XAIP is model reconciliation, which seeks to align the mental models of AI agents and humans. While existing approaches often assume a known and deterministic human model, this simplification may not capture the complexities and uncertainties of real-world interactions. In this paper, we propose a novel framework that enables AI agents to learn and update a probabilistic human model through argumentation-based dialogues. Our approach incorporates trust-based and certainty-based update mechanisms, allowing the agent to refine its understanding of the human's mental state based on the human's expressed trust in the agent's arguments and certainty in their own arguments. We employ a probability weighting function inspired by prospect theory to capture the relationship between trust and perceived probability, and use a Bayesian approach to update the agent's probability distribution over possible human models. We conduct a human-subject study to empirically evaluate the effectiveness of our approach in an argumentation scenario, demonstrating its ability to capture the dynamics of human belief formation and adaptation.","sentences":["Explainable AI Planning (XAIP) aims to develop AI agents that can effectively explain their decisions and actions to human users, fostering trust and facilitating human-AI collaboration.","A key challenge in XAIP is model reconciliation, which seeks to align the mental models of AI agents and humans.","While existing approaches often assume a known and deterministic human model, this simplification may not capture the complexities and uncertainties of real-world interactions.","In this paper, we propose a novel framework that enables AI agents to learn and update a probabilistic human model through argumentation-based dialogues.","Our approach incorporates trust-based and certainty-based update mechanisms, allowing the agent to refine its understanding of the human's mental state based on the human's expressed trust in the agent's arguments and certainty in their own arguments.","We employ a probability weighting function inspired by prospect theory to capture the relationship between trust and perceived probability, and use a Bayesian approach to update the agent's probability distribution over possible human models.","We conduct a human-subject study to empirically evaluate the effectiveness of our approach in an argumentation scenario, demonstrating its ability to capture the dynamics of human belief formation and adaptation."],"url":"http://arxiv.org/abs/2405.18650v1","category":"cs.AI"}
{"created":"2024-05-28 22:32:17","title":"Battery Degradation Heuristics for Predictive Energy Management in Shipboard Power Systems","abstract":"The presence of Pulse Power Loads (PPLs) in the Notional Shipboard Power System (SPS) presents a challenge in the form of meeting their high ramp rate requirements. Considering the ramp rate limitations on the generators, this might hinder the power flow in the grid. Failure to meet the ramp rate requirements might cause instability. Aggregating generators with energy storage elements usually addresses the ramp requirements while ensuring the power demand is achieved. This paper proposes an energy management strategy that adaptively splits the power demand between the generators and the batteries while simultaneously considering the battery degradation and the generator's efficient operation. Since it is challenging to incorporate the battery degradation model directly into the optimization problem due to its complex structure and the degradation time scale which is not practical for real-time implementation, two reasonable heuristics in terms of minimizing the absolute battery power and minimizing the battery state of charge are proposed and compared to manage the battery degradation. A model predictive energy management strategy is then developed to coordinate the power split considering the generator efficiency and minimizing the battery degradation based on the two heuristic approaches. The designed strategy is tested via a simulation of a lumped notional shipboard power system. The results show the impact of the battery degradation heuristics for energy management strategy in mitigating battery degradation and its health management.","sentences":["The presence of Pulse Power Loads (PPLs) in the Notional Shipboard Power System (SPS) presents a challenge in the form of meeting their high ramp rate requirements.","Considering the ramp rate limitations on the generators, this might hinder the power flow in the grid.","Failure to meet the ramp rate requirements might cause instability.","Aggregating generators with energy storage elements usually addresses the ramp requirements while ensuring the power demand is achieved.","This paper proposes an energy management strategy that adaptively splits the power demand between the generators and the batteries while simultaneously considering the battery degradation and the generator's efficient operation.","Since it is challenging to incorporate the battery degradation model directly into the optimization problem due to its complex structure and the degradation time scale which is not practical for real-time implementation, two reasonable heuristics in terms of minimizing the absolute battery power and minimizing the battery state of charge are proposed and compared to manage the battery degradation.","A model predictive energy management strategy is then developed to coordinate the power split considering the generator efficiency and minimizing the battery degradation based on the two heuristic approaches.","The designed strategy is tested via a simulation of a lumped notional shipboard power system.","The results show the impact of the battery degradation heuristics for energy management strategy in mitigating battery degradation and its health management."],"url":"http://arxiv.org/abs/2405.18633v1","category":"math.OC"}
{"created":"2024-05-28 22:19:30","title":"Hardware-Aware Parallel Prompt Decoding for Memory-Efficient Acceleration of LLM Inference","abstract":"The auto-regressive decoding of Large Language Models (LLMs) results in significant overheads in their hardware performance. While recent research has investigated various speculative decoding techniques for multi-token generation, these efforts have primarily focused on improving processing speed such as throughput. Crucially, they often neglect other metrics essential for real-life deployments, such as memory consumption and training cost. To overcome these limitations, we propose a novel parallel prompt decoding that requires only $0.0002$% trainable parameters, enabling efficient training on a single A100-40GB GPU in just 16 hours. Inspired by the human natural language generation process, $PPD$ approximates outputs generated at future timesteps in parallel by using multiple prompt tokens. This approach partially recovers the missing conditional dependency information necessary for multi-token generation, resulting in up to a 28% higher acceptance rate for long-range predictions. Furthermore, we present a hardware-aware dynamic sparse tree technique that adaptively optimizes this decoding scheme to fully leverage the computational capacities on different GPUs. Through extensive experiments across LLMs ranging from MobileLlama to Vicuna-13B on a wide range of benchmarks, our approach demonstrates up to 2.49$\\times$ speedup and maintains a minimal runtime memory overhead of just $0.0004$%. More importantly, our parallel prompt decoding can serve as an orthogonal optimization for synergistic integration with existing speculative decoding, showing up to $1.22\\times$ further speed improvement. Our code is available at https://github.com/hmarkc/parallel-prompt-decoding.","sentences":["The auto-regressive decoding of Large Language Models (LLMs) results in significant overheads in their hardware performance.","While recent research has investigated various speculative decoding techniques for multi-token generation, these efforts have primarily focused on improving processing speed such as throughput.","Crucially, they often neglect other metrics essential for real-life deployments, such as memory consumption and training cost.","To overcome these limitations, we propose a novel parallel prompt decoding that requires only $0.0002$% trainable parameters, enabling efficient training on a single A100-40GB GPU in just 16 hours.","Inspired by the human natural language generation process, $PPD$ approximates outputs generated at future timesteps in parallel by using multiple prompt tokens.","This approach partially recovers the missing conditional dependency information necessary for multi-token generation, resulting in up to a 28% higher acceptance rate for long-range predictions.","Furthermore, we present a hardware-aware dynamic sparse tree technique that adaptively optimizes this decoding scheme to fully leverage the computational capacities on different GPUs.","Through extensive experiments across LLMs ranging from MobileLlama to Vicuna-13B on a wide range of benchmarks, our approach demonstrates up to 2.49$\\times$ speedup and maintains a minimal runtime memory overhead of just $0.0004$%.","More importantly, our parallel prompt decoding can serve as an orthogonal optimization for synergistic integration with existing speculative decoding, showing up to $1.22\\times$ further speed improvement.","Our code is available at https://github.com/hmarkc/parallel-prompt-decoding."],"url":"http://arxiv.org/abs/2405.18628v1","category":"cs.LG"}
{"created":"2024-05-28 22:17:57","title":"Causal Contextual Bandits with Adaptive Context","abstract":"We study a variant of causal contextual bandits where the context is chosen based on an initial intervention chosen by the learner. At the beginning of each round, the learner selects an initial action, depending on which a stochastic context is revealed by the environment. Following this, the learner then selects a final action and receives a reward. Given $T$ rounds of interactions with the environment, the objective of the learner is to learn a policy (of selecting the initial and the final action) with maximum expected reward. In this paper we study the specific situation where every action corresponds to intervening on a node in some known causal graph. We extend prior work from the deterministic context setting to obtain simple regret minimization guarantees. This is achieved through an instance-dependent causal parameter, $\\lambda$, which characterizes our upper bound. Furthermore, we prove that our simple regret is essentially tight for a large class of instances. A key feature of our work is that we use convex optimization to address the bandit exploration problem. We also conduct experiments to validate our theoretical results, and release our code at our project GitHub repository: https://github.com/adaptiveContextualCausalBandits/aCCB.","sentences":["We study a variant of causal contextual bandits where the context is chosen based on an initial intervention chosen by the learner.","At the beginning of each round, the learner selects an initial action, depending on which a stochastic context is revealed by the environment.","Following this, the learner then selects a final action and receives a reward.","Given $T$ rounds of interactions with the environment, the objective of the learner is to learn a policy (of selecting the initial and the final action) with maximum expected reward.","In this paper we study the specific situation where every action corresponds to intervening on a node in some known causal graph.","We extend prior work from the deterministic context setting to obtain simple regret minimization guarantees.","This is achieved through an instance-dependent causal parameter, $\\lambda$, which characterizes our upper bound.","Furthermore, we prove that our simple regret is essentially tight for a large class of instances.","A key feature of our work is that we use convex optimization to address the bandit exploration problem.","We also conduct experiments to validate our theoretical results, and release our code at our project GitHub repository: https://github.com/adaptiveContextualCausalBandits/aCCB."],"url":"http://arxiv.org/abs/2405.18626v1","category":"cs.LG"}
{"created":"2024-05-28 22:01:50","title":"Multi-Armed Bandits with Network Interference","abstract":"Online experimentation with interference is a common challenge in modern applications such as e-commerce and adaptive clinical trials in medicine. For example, in online marketplaces, the revenue of a good depends on discounts applied to competing goods. Statistical inference with interference is widely studied in the offline setting, but far less is known about how to adaptively assign treatments to minimize regret. We address this gap by studying a multi-armed bandit (MAB) problem where a learner (e-commerce platform) sequentially assigns one of possible $\\mathcal{A}$ actions (discounts) to $N$ units (goods) over $T$ rounds to minimize regret (maximize revenue). Unlike traditional MAB problems, the reward of each unit depends on the treatments assigned to other units, i.e., there is interference across the underlying network of units. With $\\mathcal{A}$ actions and $N$ units, minimizing regret is combinatorially difficult since the action space grows as $\\mathcal{A}^N$. To overcome this issue, we study a sparse network interference model, where the reward of a unit is only affected by the treatments assigned to $s$ neighboring units. We use tools from discrete Fourier analysis to develop a sparse linear representation of the unit-specific reward $r_n: [\\mathcal{A}]^N \\rightarrow \\mathbb{R} $, and propose simple, linear regression-based algorithms to minimize regret. Importantly, our algorithms achieve provably low regret both when the learner observes the interference neighborhood for all units and when it is unknown. This significantly generalizes other works on this topic which impose strict conditions on the strength of interference on a known network, and also compare regret to a markedly weaker optimal action. Empirically, we corroborate our theoretical findings via numerical simulations.","sentences":["Online experimentation with interference is a common challenge in modern applications such as e-commerce and adaptive clinical trials in medicine.","For example, in online marketplaces, the revenue of a good depends on discounts applied to competing goods.","Statistical inference with interference is widely studied in the offline setting, but far less is known about how to adaptively assign treatments to minimize regret.","We address this gap by studying a multi-armed bandit (MAB) problem where a learner (e-commerce platform) sequentially assigns one of possible $\\mathcal{A}$ actions (discounts) to $N$ units (goods) over $T$ rounds to minimize regret (maximize revenue).","Unlike traditional MAB problems, the reward of each unit depends on the treatments assigned to other units, i.e., there is interference across the underlying network of units.","With $\\mathcal{A}$ actions and $N$ units, minimizing regret is combinatorially difficult since the action space grows as $\\mathcal{A}^N$. To overcome this issue, we study a sparse network interference model, where the reward of a unit is only affected by the treatments assigned to $s$ neighboring units.","We use tools from discrete Fourier analysis to develop a sparse linear representation of the unit-specific reward $r_n:","[\\mathcal{A}]^N \\rightarrow \\mathbb{R} $, and propose simple, linear regression-based algorithms to minimize regret.","Importantly, our algorithms achieve provably low regret both when the learner observes the interference neighborhood for all units and when it is unknown.","This significantly generalizes other works on this topic which impose strict conditions on the strength of interference on a known network, and also compare regret to a markedly weaker optimal action.","Empirically, we corroborate our theoretical findings via numerical simulations."],"url":"http://arxiv.org/abs/2405.18621v1","category":"cs.LG"}
{"created":"2024-05-28 21:58:09","title":"Stability of the Rao-Nakra sandwich beam with a dissipation of fractional derivative type: theoretical and numerical study","abstract":"This paper is devoted to the solution and stability of a one-dimensional model depicting Rao--Nakra sandwich beams, incorporating damping terms characterized by fractional derivative types within the domain, specifically a generalized Caputo derivative with exponential weight. To address existence, uniqueness, stability, and numerical results, fractional derivatives are substituted by diffusion equations relative to a new independent variable, $\\xi$, resulting in an augmented model with a dissipative semigroup operator. Polynomial decay of energy is achieved, with a decay rate depending on the fractional derivative parameters. Both the polynomial decay and its dependency on the parameters of the generalized Caputo derivative are numerically validated. To this end, an energy-conserving finite difference numerical scheme is employed.","sentences":["This paper is devoted to the solution and stability of a one-dimensional model depicting Rao--Nakra sandwich beams, incorporating damping terms characterized by fractional derivative types within the domain, specifically a generalized Caputo derivative with exponential weight.","To address existence, uniqueness, stability, and numerical results, fractional derivatives are substituted by diffusion equations relative to a new independent variable, $\\xi$, resulting in an augmented model with a dissipative semigroup operator.","Polynomial decay of energy is achieved, with a decay rate depending on the fractional derivative parameters.","Both the polynomial decay and its dependency on the parameters of the generalized Caputo derivative are numerically validated.","To this end, an energy-conserving finite difference numerical scheme is employed."],"url":"http://arxiv.org/abs/2405.18619v1","category":"math.NA"}
{"created":"2024-05-28 21:40:00","title":"DTR-Bench: An in silico Environment and Benchmark Platform for Reinforcement Learning Based Dynamic Treatment Regime","abstract":"Reinforcement learning (RL) has garnered increasing recognition for its potential to optimise dynamic treatment regimes (DTRs) in personalised medicine, particularly for drug dosage prescriptions and medication recommendations. However, a significant challenge persists: the absence of a unified framework for simulating diverse healthcare scenarios and a comprehensive analysis to benchmark the effectiveness of RL algorithms within these contexts. To address this gap, we introduce \\textit{DTR-Bench}, a benchmarking platform comprising four distinct simulation environments tailored to common DTR applications, including cancer chemotherapy, radiotherapy, glucose management in diabetes, and sepsis treatment. We evaluate various state-of-the-art RL algorithms across these settings, particularly highlighting their performance amidst real-world challenges such as pharmacokinetic/pharmacodynamic (PK/PD) variability, noise, and missing data. Our experiments reveal varying degrees of performance degradation among RL algorithms in the presence of noise and patient variability, with some algorithms failing to converge. Additionally, we observe that using temporal observation representations does not consistently lead to improved performance in DTR settings. Our findings underscore the necessity of developing robust, adaptive RL algorithms capable of effectively managing these complexities to enhance patient-specific healthcare. We have open-sourced our benchmark and code at https://github.com/GilesLuo/DTR-Bench.","sentences":["Reinforcement learning (RL) has garnered increasing recognition for its potential to optimise dynamic treatment regimes (DTRs) in personalised medicine, particularly for drug dosage prescriptions and medication recommendations.","However, a significant challenge persists: the absence of a unified framework for simulating diverse healthcare scenarios and a comprehensive analysis to benchmark the effectiveness of RL algorithms within these contexts.","To address this gap, we introduce \\textit{DTR-Bench}, a benchmarking platform comprising four distinct simulation environments tailored to common DTR applications, including cancer chemotherapy, radiotherapy, glucose management in diabetes, and sepsis treatment.","We evaluate various state-of-the-art RL algorithms across these settings, particularly highlighting their performance amidst real-world challenges such as pharmacokinetic/pharmacodynamic (PK/PD) variability, noise, and missing data.","Our experiments reveal varying degrees of performance degradation among RL algorithms in the presence of noise and patient variability, with some algorithms failing to converge.","Additionally, we observe that using temporal observation representations does not consistently lead to improved performance in DTR settings.","Our findings underscore the necessity of developing robust, adaptive RL algorithms capable of effectively managing these complexities to enhance patient-specific healthcare.","We have open-sourced our benchmark and code at https://github.com/GilesLuo/DTR-Bench."],"url":"http://arxiv.org/abs/2405.18610v1","category":"cs.LG"}
{"created":"2024-05-28 21:32:11","title":"OpenConvoy: Universal Platform for Real-World Testing of Cooperative Driving Systems","abstract":"Cooperative driving, enabled by communication between automated vehicle systems, promises significant benefits to fuel efficiency, road capacity, and safety over single-vehicle driver assistance systems such as adaptive cruise control (ACC). However, the responsible development and implementation of these algorithms poses substantial challenges due to the need for extensive real-world testing. We address this issue and introduce OpenConvoy, an open and extensible framework designed for the implementation and assessment of cooperative driving policies on physical connected and autonomous vehicles (CAVs). We demonstrate the capabilities of OpenConvoy through a series of experiments on a convoy of multi-scale vehicles controlled by Platooning to show the stability of our system across vehicle configurations and its ability to effectively measure convoy cohesion across driving scenarios including varying degrees of communication loss.","sentences":["Cooperative driving, enabled by communication between automated vehicle systems, promises significant benefits to fuel efficiency, road capacity, and safety over single-vehicle driver assistance systems such as adaptive cruise control (ACC).","However, the responsible development and implementation of these algorithms poses substantial challenges due to the need for extensive real-world testing.","We address this issue and introduce OpenConvoy, an open and extensible framework designed for the implementation and assessment of cooperative driving policies on physical connected and autonomous vehicles (CAVs).","We demonstrate the capabilities of OpenConvoy through a series of experiments on a convoy of multi-scale vehicles controlled by Platooning to show the stability of our system across vehicle configurations and its ability to effectively measure convoy cohesion across driving scenarios including varying degrees of communication loss."],"url":"http://arxiv.org/abs/2405.18600v1","category":"cs.RO"}
{"created":"2024-05-28 21:07:53","title":"Emergence and long-term maintenance of modularity in spiking neural networks with plasticity","abstract":"In the last three decades the field of brain connectivity has uncovered that cortical regions, interconnected via white-matter fibers, form a modular and hierarchical network. This type of organization, which has also been recognised at the microscopic level in the form of interconnected neural assemblies, is typically believed to support the coexistence of segregation (specialization) and integration (binding) of information. A prominent remaining question is to understand how the brain could possibly become such a complex network. Here, we give a first step into answering this question and propose that adaptation to various inputs could be the key driving mechanism for the formation of structural assemblies at different scales. To illustrate that, we develop a model of (QIF) spiking neurons, subjected to stimuli targetting distributed populations. The model follows several biologically plausible constraints: (i) it contains both excitatory and inhibitory neurons with two classes of plasticity: Hebbian and anti-Hebbian STDP, (ii) dynamics are not frozen after the entrainment is finished but the network is allowed to continue firing spontaneously, and (iii) plasticity remains always active, also after the learning phase. We find that only the combination of Hebbian and anti-Hebbian inhibitory plasticity allows the formation of stable modular organization in the network. Besides, given that the model continues ``alive'' after the learning, the network settles into an asynchronous irregular firing state displaying spontaneous memory recalls which, as we show, turn crucial for the long-term consolidation of the learned memories.","sentences":["In the last three decades the field of brain connectivity has uncovered that cortical regions, interconnected via white-matter fibers, form a modular and hierarchical network.","This type of organization, which has also been recognised at the microscopic level in the form of interconnected neural assemblies, is typically believed to support the coexistence of segregation (specialization) and integration (binding) of information.","A prominent remaining question is to understand how the brain could possibly become such a complex network.","Here, we give a first step into answering this question and propose that adaptation to various inputs could be the key driving mechanism for the formation of structural assemblies at different scales.","To illustrate that, we develop a model of (QIF) spiking neurons, subjected to stimuli targetting distributed populations.","The model follows several biologically plausible constraints: (i) it contains both excitatory and inhibitory neurons with two classes of plasticity: Hebbian and anti-Hebbian STDP, (ii) dynamics are not frozen after the entrainment is finished but the network is allowed to continue firing spontaneously, and (iii) plasticity remains always active, also after the learning phase.","We find that only the combination of Hebbian and anti-Hebbian inhibitory plasticity allows the formation of stable modular organization in the network.","Besides, given that the model continues ``alive'' after the learning, the network settles into an asynchronous irregular firing state displaying spontaneous memory recalls which, as we show, turn crucial for the long-term consolidation of the learned memories."],"url":"http://arxiv.org/abs/2405.18587v1","category":"q-bio.NC"}
{"created":"2024-05-28 20:53:26","title":"Smooth connectivity in real algebraic varieties","abstract":"A standard question in real algebraic geometry is to compute the number of connected components of a real algebraic variety in affine space. By adapting an approach for determining connectivity in complements of real hypersurfaces by Hong, Rohal, Safey El Din, and Schost, algorithms are presented for computing the number of connected components, the Euler characteristic, and deciding the connectivity between two points for a smooth manifold arising as the complement of a real hypersurface of a real algebraic variety. When taking such real hypersurface to be the set of singular points, this yields an approach for determining smooth connectivity in a real algebraic variety. The method is based upon gradient ascent/descent paths on the real algebraic variety and several examples are included to demonstrate the approach.","sentences":["A standard question in real algebraic geometry is to compute the number of connected components of a real algebraic variety in affine space.","By adapting an approach for determining connectivity in complements of real hypersurfaces by Hong, Rohal, Safey El Din, and Schost, algorithms are presented for computing the number of connected components, the Euler characteristic, and deciding the connectivity between two points for a smooth manifold arising as the complement of a real hypersurface of a real algebraic variety.","When taking such real hypersurface to be the set of singular points, this yields an approach for determining smooth connectivity in a real algebraic variety.","The method is based upon gradient ascent/descent paths on the real algebraic variety and several examples are included to demonstrate the approach."],"url":"http://arxiv.org/abs/2405.18578v1","category":"math.AG"}
{"created":"2024-05-28 20:28:07","title":"Its Not a Modality Gap: Characterizing and Addressing the Contrastive Gap","abstract":"Multi-modal contrastive models such as CLIP achieve state-of-the-art performance in zero-shot classification by embedding input images and texts on a joint representational space. Recently, a modality gap has been reported in two-encoder contrastive models like CLIP, meaning that the image and text embeddings reside in disjoint areas of the latent space. Previous studies suggest that this gap exists due to 1) the cone effect, 2) mismatched pairs in the dataset, and 3) insufficient training. We show that, even when accounting for all these factors, and even when using the same modality, the contrastive loss actually creates a gap during training. As a result, We propose that the modality gap is inherent to the two-encoder contrastive loss and rename it the contrastive gap. We present evidence that attributes this contrastive gap to low uniformity in CLIP space, resulting in embeddings that occupy only a small portion of the latent space. To close the gap, we adapt the uniformity and alignment properties of unimodal contrastive loss to the multi-modal setting and show that simply adding these terms to the CLIP loss distributes the embeddings more uniformly in the representational space, closing the gap. In our experiments, we show that the modified representational space achieves better performance than default CLIP loss in downstream tasks such as zero-shot image classification and multi-modal arithmetic.","sentences":["Multi-modal contrastive models such as CLIP achieve state-of-the-art performance in zero-shot classification by embedding input images and texts on a joint representational space.","Recently, a modality gap has been reported in two-encoder contrastive models like CLIP, meaning that the image and text embeddings reside in disjoint areas of the latent space.","Previous studies suggest that this gap exists due to 1) the cone effect, 2) mismatched pairs in the dataset, and 3) insufficient training.","We show that, even when accounting for all these factors, and even when using the same modality, the contrastive loss actually creates a gap during training.","As a result, We propose that the modality gap is inherent to the two-encoder contrastive loss and rename it the contrastive gap.","We present evidence that attributes this contrastive gap to low uniformity in CLIP space, resulting in embeddings that occupy only a small portion of the latent space.","To close the gap, we adapt the uniformity and alignment properties of unimodal contrastive loss to the multi-modal setting and show that simply adding these terms to the CLIP loss distributes the embeddings more uniformly in the representational space, closing the gap.","In our experiments, we show that the modified representational space achieves better performance than default CLIP loss in downstream tasks such as zero-shot image classification and multi-modal arithmetic."],"url":"http://arxiv.org/abs/2405.18570v1","category":"cs.CV"}
{"created":"2024-05-28 20:24:51","title":"Locally different models in a checkerboard pattern with mesh adaptation and error control for multiple quantities of interest","abstract":"In this work, we apply multi-goal oriented error estimation to the finite element method. In particular, we use the dual weighted residual method and apply it to a model problem. This model problem consist of locally different coercive partial differential equations in a checkerboard pattern, where the solution is continuous across the interface. In addition to the error estimation, the error can be localized using a partition of unity technique. The resulting adaptive algorithm is substantiated with a numerical example.","sentences":["In this work, we apply multi-goal oriented error estimation to the finite element method.","In particular, we use the dual weighted residual method and apply it to a model problem.","This model problem consist of locally different coercive partial differential equations in a checkerboard pattern, where the solution is continuous across the interface.","In addition to the error estimation, the error can be localized using a partition of unity technique.","The resulting adaptive algorithm is substantiated with a numerical example."],"url":"http://arxiv.org/abs/2405.18567v1","category":"math.NA"}
{"created":"2024-05-28 20:13:44","title":"Covariance Operator Estimation via Adaptive Thresholding","abstract":"This paper studies sparse covariance operator estimation for nonstationary Gaussian processes with sharply varying marginal variance and small correlation lengthscale. We introduce a covariance operator estimator that adaptively thresholds the sample covariance function using an estimate of the variance components. Building on recent results from empirical process theory, we derive an operator norm bound on the estimation error in terms of the sparsity level of the covariance and the expected supremum of the normalized process. Our theory and numerical simulations demonstrate the advantage of adaptive threshold estimators over universal threshold and sample covariance estimators in nonstationary settings.","sentences":["This paper studies sparse covariance operator estimation for nonstationary Gaussian processes with sharply varying marginal variance and small correlation lengthscale.","We introduce a covariance operator estimator that adaptively thresholds the sample covariance function using an estimate of the variance components.","Building on recent results from empirical process theory, we derive an operator norm bound on the estimation error in terms of the sparsity level of the covariance and the expected supremum of the normalized process.","Our theory and numerical simulations demonstrate the advantage of adaptive threshold estimators over universal threshold and sample covariance estimators in nonstationary settings."],"url":"http://arxiv.org/abs/2405.18562v1","category":"math.ST"}
{"created":"2024-05-28 19:54:46","title":"The FAIIR Tool: A Conversational AI Agent Assistant for Youth Mental Health Service Provision","abstract":"World's healthcare systems and mental health agencies face both a growing demand for youth mental health services, alongside a simultaneous challenge of limited resources. Given these constraints, this work presents our experience in the creation and evaluation of the FAIIR (Frontline Assistant: Issue Identification and Recommendation) tool, an ensemble of domain-adapted and fine-tuned transformer models, leveraging natural language processing to identify issues that youth may be experiencing. We explore the technical development, performance, and validation processes leveraged for the FAIIR tool in application to situations of frontline crisis response via Kids Help Phone. Frontline Crisis Responders assign an issue tag from a defined list following each conversation. Assisting with the identification of issues of relevance helps reduce the burden on CRs, ensuring that appropriate resources can be provided and that active rescues and mandatory reporting can take place in critical situations requiring immediate de-escalation.","sentences":["World's healthcare systems and mental health agencies face both a growing demand for youth mental health services, alongside a simultaneous challenge of limited resources.","Given these constraints, this work presents our experience in the creation and evaluation of the FAIIR (Frontline Assistant: Issue Identification and Recommendation) tool, an ensemble of domain-adapted and fine-tuned transformer models, leveraging natural language processing to identify issues that youth may be experiencing.","We explore the technical development, performance, and validation processes leveraged for the FAIIR tool in application to situations of frontline crisis response via Kids Help Phone.","Frontline Crisis Responders assign an issue tag from a defined list following each conversation.","Assisting with the identification of issues of relevance helps reduce the burden on CRs, ensuring that appropriate resources can be provided and that active rescues and mandatory reporting can take place in critical situations requiring immediate de-escalation."],"url":"http://arxiv.org/abs/2405.18553v1","category":"cs.AI"}
{"created":"2024-05-28 19:16:59","title":"Low-Rank Few-Shot Adaptation of Vision-Language Models","abstract":"Recent progress in the few-shot adaptation of Vision-Language Models (VLMs) has further pushed their generalization capabilities, at the expense of just a few labeled samples within the target downstream task. However, this promising, already quite abundant few-shot literature has focused principally on prompt learning and, to a lesser extent, on adapters, overlooking the recent advances in Parameter-Efficient Fine-Tuning (PEFT). Furthermore, existing few-shot learning methods for VLMs often rely on heavy training procedures and/or carefully chosen, task-specific hyper-parameters, which might impede their applicability. In response, we introduce Low-Rank Adaptation (LoRA) in few-shot learning for VLMs, and show its potential on 11 datasets, in comparison to current state-of-the-art prompt- and adapter-based approaches. Surprisingly, our simple CLIP-LoRA method exhibits substantial improvements, while reducing the training times and keeping the same hyper-parameters in all the target tasks, i.e., across all the datasets and numbers of shots. Certainly, our surprising results do not dismiss the potential of prompt-learning and adapter-based research. However, we believe that our strong baseline could be used to evaluate progress in these emergent subjects in few-shot VLMs.","sentences":["Recent progress in the few-shot adaptation of Vision-Language Models (VLMs) has further pushed their generalization capabilities, at the expense of just a few labeled samples within the target downstream task.","However, this promising, already quite abundant few-shot literature has focused principally on prompt learning and, to a lesser extent, on adapters, overlooking the recent advances in Parameter-Efficient Fine-Tuning (PEFT).","Furthermore, existing few-shot learning methods for VLMs often rely on heavy training procedures and/or carefully chosen, task-specific hyper-parameters, which might impede their applicability.","In response, we introduce Low-Rank Adaptation (LoRA) in few-shot learning for VLMs, and show its potential on 11 datasets, in comparison to current state-of-the-art prompt- and adapter-based approaches.","Surprisingly, our simple CLIP-LoRA method exhibits substantial improvements, while reducing the training times and keeping the same hyper-parameters in all the target tasks, i.e., across all the datasets and numbers of shots.","Certainly, our surprising results do not dismiss the potential of prompt-learning and adapter-based research.","However, we believe that our strong baseline could be used to evaluate progress in these emergent subjects in few-shot VLMs."],"url":"http://arxiv.org/abs/2405.18541v1","category":"cs.CV"}
{"created":"2024-05-28 18:49:17","title":"Task-Driven Uncertainty Quantification in Inverse Problems via Conformal Prediction","abstract":"In imaging inverse problems, one seeks to recover an image from missing/corrupted measurements. Because such problems are ill-posed, there is great motivation to quantify the uncertainty induced by the measurement-and-recovery process. Motivated by applications where the recovered image is used for a downstream task, such as soft-output classification, we propose a task-centered approach to uncertainty quantification. In particular, we use conformal prediction to construct an interval that is guaranteed to contain the task output from the true image up to a user-specified probability, and we use the width of that interval to quantify the uncertainty contributed by measurement-and-recovery. For posterior-sampling-based image recovery, we construct locally adaptive prediction intervals. Furthermore, we propose to collect measurements over multiple rounds, stopping as soon as the task uncertainty falls below an acceptable level. We demonstrate our methodology on accelerated magnetic resonance imaging (MRI).","sentences":["In imaging inverse problems, one seeks to recover an image from missing/corrupted measurements.","Because such problems are ill-posed, there is great motivation to quantify the uncertainty induced by the measurement-and-recovery process.","Motivated by applications where the recovered image is used for a downstream task, such as soft-output classification, we propose a task-centered approach to uncertainty quantification.","In particular, we use conformal prediction to construct an interval that is guaranteed to contain the task output from the true image up to a user-specified probability, and we use the width of that interval to quantify the uncertainty contributed by measurement-and-recovery.","For posterior-sampling-based image recovery, we construct locally adaptive prediction intervals.","Furthermore, we propose to collect measurements over multiple rounds, stopping as soon as the task uncertainty falls below an acceptable level.","We demonstrate our methodology on accelerated magnetic resonance imaging (MRI)."],"url":"http://arxiv.org/abs/2405.18527v1","category":"cs.CV"}
{"created":"2024-05-28 18:38:46","title":"Offline-Boosted Actor-Critic: Adaptively Blending Optimal Historical Behaviors in Deep Off-Policy RL","abstract":"Off-policy reinforcement learning (RL) has achieved notable success in tackling many complex real-world tasks, by leveraging previously collected data for policy learning. However, most existing off-policy RL algorithms fail to maximally exploit the information in the replay buffer, limiting sample efficiency and policy performance. In this work, we discover that concurrently training an offline RL policy based on the shared online replay buffer can sometimes outperform the original online learning policy, though the occurrence of such performance gains remains uncertain. This motivates a new possibility of harnessing the emergent outperforming offline optimal policy to improve online policy learning. Based on this insight, we present Offline-Boosted Actor-Critic (OBAC), a model-free online RL framework that elegantly identifies the outperforming offline policy through value comparison, and uses it as an adaptive constraint to guarantee stronger policy learning performance. Our experiments demonstrate that OBAC outperforms other popular model-free RL baselines and rivals advanced model-based RL methods in terms of sample efficiency and asymptotic performance across 53 tasks spanning 6 task suites.","sentences":["Off-policy reinforcement learning (RL) has achieved notable success in tackling many complex real-world tasks, by leveraging previously collected data for policy learning.","However, most existing off-policy RL algorithms fail to maximally exploit the information in the replay buffer, limiting sample efficiency and policy performance.","In this work, we discover that concurrently training an offline RL policy based on the shared online replay buffer can sometimes outperform the original online learning policy, though the occurrence of such performance gains remains uncertain.","This motivates a new possibility of harnessing the emergent outperforming offline optimal policy to improve online policy learning.","Based on this insight, we present Offline-Boosted Actor-Critic (OBAC), a model-free online RL framework that elegantly identifies the outperforming offline policy through value comparison, and uses it as an adaptive constraint to guarantee stronger policy learning performance.","Our experiments demonstrate that OBAC outperforms other popular model-free RL baselines and rivals advanced model-based RL methods in terms of sample efficiency and asymptotic performance across 53 tasks spanning 6 task suites."],"url":"http://arxiv.org/abs/2405.18520v1","category":"cs.LG"}
{"created":"2024-05-28 18:18:06","title":"Symmetry-protection Zeno phase transition in monitored lattice gauge theories","abstract":"Quantum measurements profoundly influence system dynamics. They lead to complex nonequilibrium phenomena like the quantum Zeno effect, and they can be used for mitigating errors in quantum simulations.   Such an ability is particularly valuable for lattice gauge theories (LGTs), which require the challenging preservation of an extensive number of local conservation laws.   While it is known that tailored quantum measurements can soften violations of gauge symmetry, the nature of this protection, and in particular the possibility of a threshold behavior, is still unexplored.   Here, we demonstrate the existence of a sharp transition, triggered by the measurement rate, between a protected gauge-theory regime resistant to simulation errors and an irregular regime.   Our results are based on the paradigmatic example of a 1+1d $\\mathbb{Z}_2$ LGT. We study in detail the protection through projective measurements of ancillary qubits coupled to the local symmetry generators, and compare this approach with analog (weak) measurement protocols.   We show that, while the resulting ensemble averages in the continuous-time limit share the same Liouvillian dynamics, different physical implementations of the stochastic gauge protection protocol yield trajectory unravelings with vastly different statistics.   Additionally, we design an on-chip feedback mechanism that corrects bit-flip errors and significantly enhances the discrete-time scheme. Our results shed light on the dissipative criticality of strongly-interacting, highly-constrained quantum systems, and they offer valuable insights into error mitigation and correction of gauge-theory quantum simulations.","sentences":["Quantum measurements profoundly influence system dynamics.","They lead to complex nonequilibrium phenomena like the quantum Zeno effect, and they can be used for mitigating errors in quantum simulations.   ","Such an ability is particularly valuable for lattice gauge theories (LGTs), which require the challenging preservation of an extensive number of local conservation laws.   ","While it is known that tailored quantum measurements can soften violations of gauge symmetry, the nature of this protection, and in particular the possibility of a threshold behavior, is still unexplored.   ","Here, we demonstrate the existence of a sharp transition, triggered by the measurement rate, between a protected gauge-theory regime resistant to simulation errors and an irregular regime.   ","Our results are based on the paradigmatic example of a 1+1d $\\mathbb{Z}_2$ LGT.","We study in detail the protection through projective measurements of ancillary qubits coupled to the local symmetry generators, and compare this approach with analog (weak) measurement protocols.   ","We show that, while the resulting ensemble averages in the continuous-time limit share the same Liouvillian dynamics, different physical implementations of the stochastic gauge protection protocol yield trajectory unravelings with vastly different statistics.   ","Additionally, we design an on-chip feedback mechanism that corrects bit-flip errors and significantly enhances the discrete-time scheme.","Our results shed light on the dissipative criticality of strongly-interacting, highly-constrained quantum systems, and they offer valuable insights into error mitigation and correction of gauge-theory quantum simulations."],"url":"http://arxiv.org/abs/2405.18504v1","category":"quant-ph"}
{"created":"2024-05-28 18:09:22","title":"The Unified Balance Theory of Second-Moment Exponential Scaling Optimizers in Visual Tasks","abstract":"We have identified a potential method for unifying first-order optimizers through the use of variable Second-Moment Exponential Scaling(SMES). We begin with back propagation, addressing classic phenomena such as gradient vanishing and explosion, as well as issues related to dataset sparsity, and introduce the theory of balance in optimization. Through this theory, we suggest that SGD and adaptive optimizers can be unified under a broader inference, employing variable moving exponential scaling to achieve a balanced approach within a generalized formula for first-order optimizers. We conducted tests on some classic datasets and networks to confirm the impact of different balance coefficients on the overall training process.","sentences":["We have identified a potential method for unifying first-order optimizers through the use of variable Second-Moment Exponential Scaling(SMES).","We begin with back propagation, addressing classic phenomena such as gradient vanishing and explosion, as well as issues related to dataset sparsity, and introduce the theory of balance in optimization.","Through this theory, we suggest that SGD and adaptive optimizers can be unified under a broader inference, employing variable moving exponential scaling to achieve a balanced approach within a generalized formula for first-order optimizers.","We conducted tests on some classic datasets and networks to confirm the impact of different balance coefficients on the overall training process."],"url":"http://arxiv.org/abs/2405.18498v1","category":"cs.LG"}
{"created":"2024-05-29 17:58:09","title":"NPGA: Neural Parametric Gaussian Avatars","abstract":"The creation of high-fidelity, digital versions of human heads is an important stepping stone in the process of further integrating virtual components into our everyday lives. Constructing such avatars is a challenging research problem, due to a high demand for photo-realism and real-time rendering performance. In this work, we propose Neural Parametric Gaussian Avatars (NPGA), a data-driven approach to create high-fidelity, controllable avatars from multi-view video recordings. We build our method around 3D Gaussian Splatting for its highly efficient rendering and to inherit the topological flexibility of point clouds. In contrast to previous work, we condition our avatars' dynamics on the rich expression space of neural parametric head models (NPHM), instead of mesh-based 3DMMs. To this end, we distill the backward deformation field of our underlying NPHM into forward deformations which are compatible with rasterization-based rendering. All remaining fine-scale, expression-dependent details are learned from the multi-view videos. To increase the representational capacity of our avatars, we augment the canonical Gaussian point cloud using per-primitive latent features which govern its dynamic behavior. To regularize this increased dynamic expressivity, we propose Laplacian terms on the latent features and predicted dynamics. We evaluate our method on the public NeRSemble dataset, demonstrating that NPGA significantly outperforms the previous state-of-the-art avatars on the self-reenactment task by 2.6 PSNR. Furthermore, we demonstrate accurate animation capabilities from real-world monocular videos.","sentences":["The creation of high-fidelity, digital versions of human heads is an important stepping stone in the process of further integrating virtual components into our everyday lives.","Constructing such avatars is a challenging research problem, due to a high demand for photo-realism and real-time rendering performance.","In this work, we propose Neural Parametric Gaussian Avatars (NPGA), a data-driven approach to create high-fidelity, controllable avatars from multi-view video recordings.","We build our method around 3D Gaussian Splatting for its highly efficient rendering and to inherit the topological flexibility of point clouds.","In contrast to previous work, we condition our avatars' dynamics on the rich expression space of neural parametric head models (NPHM), instead of mesh-based 3DMMs.","To this end, we distill the backward deformation field of our underlying NPHM into forward deformations which are compatible with rasterization-based rendering.","All remaining fine-scale, expression-dependent details are learned from the multi-view videos.","To increase the representational capacity of our avatars, we augment the canonical Gaussian point cloud using per-primitive latent features which govern its dynamic behavior.","To regularize this increased dynamic expressivity, we propose Laplacian terms on the latent features and predicted dynamics.","We evaluate our method on the public NeRSemble dataset, demonstrating that NPGA significantly outperforms the previous state-of-the-art avatars on the self-reenactment task by 2.6 PSNR.","Furthermore, we demonstrate accurate animation capabilities from real-world monocular videos."],"url":"http://arxiv.org/abs/2405.19331v1","category":"cs.CV"}
{"created":"2024-05-29 17:44:22","title":"Cosmology Based on Finsler and Finsler-like Metric Structure of Gravitational Field","abstract":"In this article, we review some aspects of gravitational field and cosmology based on Finsler and Finsler-like generalized metric structures. The geometrical framework of these spaces allows further investigation of locally-anisotropic phenomena related to the gravitational field and cosmological considerations, e.g the extracted geodesics, deflection of light, Finsler-Einstein gravitational field equations , the Friedmann equations and the Raychaudhuri equations include extra anisotropic terms that in the Riemannian framework of General Relativity (GR) are not interpreted. This approach gives us the opportunity to extend the research with more degrees of freedom on the tangent bundle of a spacetime manifold. In the above mentioned generalizations omitting the extra anisotropic terms we recover the framework of GR. In addition, we study the gravitational Magnus effect in a generalized metric framework.   Based on this approach, we describe further properties of Finsler-Randers (FR) and Schwarzschild Finsler Randers (SFR) cosmological models which are useful for the description and evolution of the universe.","sentences":["In this article, we review some aspects of gravitational field and cosmology based on Finsler and Finsler-like generalized metric structures.","The geometrical framework of these spaces allows further investigation of locally-anisotropic phenomena related to the gravitational field and cosmological considerations, e.g the extracted geodesics, deflection of light, Finsler-Einstein gravitational field equations , the Friedmann equations and the Raychaudhuri equations include extra anisotropic terms that in the Riemannian framework of General Relativity (GR) are not interpreted.","This approach gives us the opportunity to extend the research with more degrees of freedom on the tangent bundle of a spacetime manifold.","In the above mentioned generalizations omitting the extra anisotropic terms we recover the framework of GR.","In addition, we study the gravitational Magnus effect in a generalized metric framework.   ","Based on this approach, we describe further properties of Finsler-Randers (FR) and Schwarzschild Finsler Randers (SFR) cosmological models which are useful for the description and evolution of the universe."],"url":"http://arxiv.org/abs/2405.19318v1","category":"gr-qc"}
{"created":"2024-05-29 17:33:34","title":"SDPRLayers: Certifiable Backpropagation Through Polynomial Optimization Problems in Robotics","abstract":"Differentiable optimization is a powerful new paradigm capable of reconciling model-based and learning-based approaches in robotics. However, the majority of robotics optimization problems are non-convex and current differentiable optimization techniques are therefore prone to convergence to local minima. When this occurs, the gradients provided by these existing solvers can be wildly inaccurate and will ultimately corrupt the training process. On the other hand, any non-convex robotics problems can be framed as polynomial optimization problems and, in turn, admit convex relaxations that can be used to recover a global solution via so-called certifiably correct methods. We present SDPRLayers, an approach that leverages these methods as well as state-of-the-art convex implicit differentiation techniques to provide certifiably correct gradients throughout the training process. We introduce this approach and showcase theoretical results that provide conditions under which correctness of the gradients is guaranteed. We demonstrate our approach on two simple-but-demonstrative simulated examples, which expose the potential pitfalls of existing, state-of-the-art, differentiable optimization methods. We apply our method in a real-world application: we train a deep neural network to detect image keypoints for robot localization in challenging lighting conditions. An open-source, PyTorch implementation of SDPRLayers will be made available upon paper acceptance.","sentences":["Differentiable optimization is a powerful new paradigm capable of reconciling model-based and learning-based approaches in robotics.","However, the majority of robotics optimization problems are non-convex and current differentiable optimization techniques are therefore prone to convergence to local minima.","When this occurs, the gradients provided by these existing solvers can be wildly inaccurate and will ultimately corrupt the training process.","On the other hand, any non-convex robotics problems can be framed as polynomial optimization problems and, in turn, admit convex relaxations that can be used to recover a global solution via so-called certifiably correct methods.","We present SDPRLayers, an approach that leverages these methods as well as state-of-the-art convex implicit differentiation techniques to provide certifiably correct gradients throughout the training process.","We introduce this approach and showcase theoretical results that provide conditions under which correctness of the gradients is guaranteed.","We demonstrate our approach on two simple-but-demonstrative simulated examples, which expose the potential pitfalls of existing, state-of-the-art, differentiable optimization methods.","We apply our method in a real-world application: we train a deep neural network to detect image keypoints for robot localization in challenging lighting conditions.","An open-source, PyTorch implementation of SDPRLayers will be made available upon paper acceptance."],"url":"http://arxiv.org/abs/2405.19309v1","category":"cs.RO"}
{"created":"2024-05-29 17:30:06","title":"Uniform-in-time estimates on the size of chaos for interacting Brownian particles","abstract":"We consider a system of classical Brownian particles interacting via a smooth long-range potential in the mean-field regime, and we analyze the propagation of chaos in form of sharp, uniform-in-time estimates on many-particle correlation functions. Our results cover both the kinetic Langevin setting and the corresponding overdamped Brownian dynamics. The approach is mainly based on so-called Lions expansions, which we combine with new diagrammatic tools to capture many-particle cancellations, as well as with fine ergodic estimates on the linearized mean-field equation, and with discrete stochastic calculus with respect to initial data. In the process, we derive some new ergodic estimates for the linearized Vlasov-Fokker-Planck kinetic equation that are of independent interest. Our analysis also leads to uniform-in-time concentration estimates and to a uniform-in-time quantitative central limit theorem for the empirical measure associated with the particle dynamics.","sentences":["We consider a system of classical Brownian particles interacting via a smooth long-range potential in the mean-field regime, and we analyze the propagation of chaos in form of sharp, uniform-in-time estimates on many-particle correlation functions.","Our results cover both the kinetic Langevin setting and the corresponding overdamped Brownian dynamics.","The approach is mainly based on so-called Lions expansions, which we combine with new diagrammatic tools to capture many-particle cancellations, as well as with fine ergodic estimates on the linearized mean-field equation, and with discrete stochastic calculus with respect to initial data.","In the process, we derive some new ergodic estimates for the linearized Vlasov-Fokker-Planck kinetic equation that are of independent interest.","Our analysis also leads to uniform-in-time concentration estimates and to a uniform-in-time quantitative central limit theorem for the empirical measure associated with the particle dynamics."],"url":"http://arxiv.org/abs/2405.19306v1","category":"math.AP"}
{"created":"2024-05-29 17:29:54","title":"Set Descriptive Complexity of Solvable Functions","abstract":"In a recent article, we introduced and studied a precise class of dynamical systems called solvable systems. These systems present a dynamic ruled by discontinuous ordinary differential equations with solvable right-hand terms and unique evolution. They correspond to a class of systems for which a transfinite method exist to compute the solution. We also presented several examples including a nontrivial one whose solution yields, at an integer time, a real encoding of the halting set for Turing machines; therefore showcasing that the behavior of solvable systems might describe ordinal Turing computations. In the current article, we study in more depth solvable systems, using tools from descriptive set theory. By establishing a correspondence with the class of well-founded trees, we construct a coanalytic ranking over the set of solvable functions and discuss its relation with other existing rankings for differentiable functions, in particular with the Kechris-Woodin, Denjoy and Zalcwasser ranking. We prove that our ranking is unbounded below the first uncountable ordinal.","sentences":["In a recent article, we introduced and studied a precise class of dynamical systems called solvable systems.","These systems present a dynamic ruled by discontinuous ordinary differential equations with solvable right-hand terms and unique evolution.","They correspond to a class of systems for which a transfinite method exist to compute the solution.","We also presented several examples including a nontrivial one whose solution yields, at an integer time, a real encoding of the halting set for Turing machines; therefore showcasing that the behavior of solvable systems might describe ordinal Turing computations.","In the current article, we study in more depth solvable systems, using tools from descriptive set theory.","By establishing a correspondence with the class of well-founded trees, we construct a coanalytic ranking over the set of solvable functions and discuss its relation with other existing rankings for differentiable functions, in particular with the Kechris-Woodin, Denjoy and Zalcwasser ranking.","We prove that our ranking is unbounded below the first uncountable ordinal."],"url":"http://arxiv.org/abs/2405.19304v1","category":"cs.CC"}
{"created":"2024-05-29 17:24:25","title":"Neural Isometries: Taming Transformations for Equivariant ML","abstract":"Real-world geometry and 3D vision tasks are replete with challenging symmetries that defy tractable analytical expression. In this paper, we introduce Neural Isometries, an autoencoder framework which learns to map the observation space to a general-purpose latent space wherein encodings are related by isometries whenever their corresponding observations are geometrically related in world space. Specifically, we regularize the latent space such that maps between encodings preserve a learned inner product and commute with a learned functional operator, in the same manner as rigid-body transformations commute with the Laplacian. This approach forms an effective backbone for self-supervised representation learning, and we demonstrate that a simple off-the-shelf equivariant network operating in the pre-trained latent space can achieve results on par with meticulously-engineered, handcrafted networks designed to handle complex, nonlinear symmetries. Furthermore, isometric maps capture information about the respective transformations in world space, and we show that this allows us to regress camera poses directly from the coefficients of the maps between encodings of adjacent views of a scene.","sentences":["Real-world geometry and 3D vision tasks are replete with challenging symmetries that defy tractable analytical expression.","In this paper, we introduce Neural Isometries, an autoencoder framework which learns to map the observation space to a general-purpose latent space wherein encodings are related by isometries whenever their corresponding observations are geometrically related in world space.","Specifically, we regularize the latent space such that maps between encodings preserve a learned inner product and commute with a learned functional operator, in the same manner as rigid-body transformations commute with the Laplacian.","This approach forms an effective backbone for self-supervised representation learning, and we demonstrate that a simple off-the-shelf equivariant network operating in the pre-trained latent space can achieve results on par with meticulously-engineered, handcrafted networks designed to handle complex, nonlinear symmetries.","Furthermore, isometric maps capture information about the respective transformations in world space, and we show that this allows us to regress camera poses directly from the coefficients of the maps between encodings of adjacent views of a scene."],"url":"http://arxiv.org/abs/2405.19296v1","category":"cs.CV"}
{"created":"2024-05-29 17:23:51","title":"3D Neural Edge Reconstruction","abstract":"Real-world objects and environments are predominantly composed of edge features, including straight lines and curves. Such edges are crucial elements for various applications, such as CAD modeling, surface meshing, lane mapping, etc. However, existing traditional methods only prioritize lines over curves for simplicity in geometric modeling. To this end, we introduce EMAP, a new method for learning 3D edge representations with a focus on both lines and curves. Our method implicitly encodes 3D edge distance and direction in Unsigned Distance Functions (UDF) from multi-view edge maps. On top of this neural representation, we propose an edge extraction algorithm that robustly abstracts parametric 3D edges from the inferred edge points and their directions. Comprehensive evaluations demonstrate that our method achieves better 3D edge reconstruction on multiple challenging datasets. We further show that our learned UDF field enhances neural surface reconstruction by capturing more details.","sentences":["Real-world objects and environments are predominantly composed of edge features, including straight lines and curves.","Such edges are crucial elements for various applications, such as CAD modeling, surface meshing, lane mapping, etc.","However, existing traditional methods only prioritize lines over curves for simplicity in geometric modeling.","To this end, we introduce EMAP, a new method for learning 3D edge representations with a focus on both lines and curves.","Our method implicitly encodes 3D edge distance and direction in Unsigned Distance Functions (UDF) from multi-view edge maps.","On top of this neural representation, we propose an edge extraction algorithm that robustly abstracts parametric 3D edges from the inferred edge points and their directions.","Comprehensive evaluations demonstrate that our method achieves better 3D edge reconstruction on multiple challenging datasets.","We further show that our learned UDF field enhances neural surface reconstruction by capturing more details."],"url":"http://arxiv.org/abs/2405.19295v1","category":"cs.CV"}
{"created":"2024-05-29 17:18:51","title":"Genuine topological Anderson insulator from impurity induced chirality reversal","abstract":"We investigate a model of Dirac fermions with Haldane type mass impurities which open a global topological gap even in the dilute limit. Surprisingly, we find that the chirality of this mass term, i.e., the sign of the Chern number, can be reversed by tuning the magnitude of the single-impurity scattering. Consequently, the disorder induces a phase disconnected from the clean topological phase, i.e., a genuine topological Anderson insulator. In seeming contradiction to the expectation that mass disorder is an irrelevant perturbation to the clean integer quantum Hall transition, the tri-critical point separating these two Chern insulating phases and a thermal metal phase is located at zero impurity density and connected to the appearance of a zero energy bound state in the continuum corresponding to a divergent Haldane mass impurity. Our conclusions based on the T-matrix expansion are substantiated by large scale Chebyshev-Polynomial-Green-Function numerics. We discuss possible experimental platforms.","sentences":["We investigate a model of Dirac fermions with Haldane type mass impurities which open a global topological gap even in the dilute limit.","Surprisingly, we find that the chirality of this mass term, i.e., the sign of the Chern number, can be reversed by tuning the magnitude of the single-impurity scattering.","Consequently, the disorder induces a phase disconnected from the clean topological phase, i.e., a genuine topological Anderson insulator.","In seeming contradiction to the expectation that mass disorder is an irrelevant perturbation to the clean integer quantum Hall transition, the tri-critical point separating these two Chern insulating phases and a thermal metal phase is located at zero impurity density and connected to the appearance of a zero energy bound state in the continuum corresponding to a divergent Haldane mass impurity.","Our conclusions based on the T-matrix expansion are substantiated by large scale Chebyshev-Polynomial-Green-Function numerics.","We discuss possible experimental platforms."],"url":"http://arxiv.org/abs/2405.19289v1","category":"cond-mat.mes-hall"}
{"created":"2024-05-29 17:12:10","title":"Parametric satellites and connected-sums in the space of Legendrian embeddings","abstract":"This article introduces two new constructions at the higher homotopy level in the space of Legendrian embeddings in $(\\mathbb{R}^3, \\xi_{\\operatorname{std}})$. We first introduce the parametric Legendrian satellite construction, showing that the satellite operation works for parametric families of Legendrian embeddings. This yields new invariants at the higher-order homotopy level.   We then introduce the parametric connected-sum construction. This operation takes as inputs two $n$-spheres based at Legendrian embeddings $K_1$ and $K_2$, respectively, and produces a new $n$-sphere based at $K_1\\# K_2$. As a main application we construct new infinite families of loops of Legendrian embeddings with non-trivial LCH monodromy invariant.","sentences":["This article introduces two new constructions at the higher homotopy level in the space of Legendrian embeddings in $(\\mathbb{R}^3, \\xi_{\\operatorname{std}})$. We first introduce the parametric Legendrian satellite construction, showing that the satellite operation works for parametric families of Legendrian embeddings.","This yields new invariants at the higher-order homotopy level.   ","We then introduce the parametric connected-sum construction.","This operation takes as inputs two $n$-spheres based at Legendrian embeddings $K_1$ and $K_2$, respectively, and produces a new $n$-sphere based at $K_1\\# K_2$.","As a main application we construct new infinite families of loops of Legendrian embeddings with non-trivial LCH monodromy invariant."],"url":"http://arxiv.org/abs/2405.19280v1","category":"math.SG"}
{"created":"2024-05-29 17:11:28","title":"Understanding and Minimising Outlier Features in Neural Network Training","abstract":"Outlier Features (OF) are neurons whose activation magnitudes significantly exceed the average over a neural network's (NN) width. They are well known to emerge during standard transformer training and have the undesirable effect of hindering quantisation in afflicted models. Despite their practical importance, little is known behind why OFs emerge during training, nor how one can minimise them.   Our work focuses on the above questions, first identifying several quantitative metrics, such as the kurtosis over neuron activation norms, to measure OFs. With these metrics, we study how architectural and optimisation choices influence OFs, and provide practical insights to minimise OFs during training. As highlights, we emphasise the importance of controlling signal propagation throughout training, and propose the Outlier Protected transformer block, which removes standard Pre-Norm layers to mitigate OFs, without loss of convergence speed or training stability. Overall, our findings shed new light on our understanding of, our ability to prevent, and the complexity of this important facet in NN training dynamics.","sentences":["Outlier Features (OF) are neurons whose activation magnitudes significantly exceed the average over a neural network's (NN) width.","They are well known to emerge during standard transformer training and have the undesirable effect of hindering quantisation in afflicted models.","Despite their practical importance, little is known behind why OFs emerge during training, nor how one can minimise them.   ","Our work focuses on the above questions, first identifying several quantitative metrics, such as the kurtosis over neuron activation norms, to measure OFs.","With these metrics, we study how architectural and optimisation choices influence OFs, and provide practical insights to minimise OFs during training.","As highlights, we emphasise the importance of controlling signal propagation throughout training, and propose the Outlier Protected transformer block, which removes standard Pre-Norm layers to mitigate OFs, without loss of convergence speed or training stability.","Overall, our findings shed new light on our understanding of, our ability to prevent, and the complexity of this important facet in NN training dynamics."],"url":"http://arxiv.org/abs/2405.19279v1","category":"cs.LG"}
{"created":"2024-05-29 17:07:33","title":"Deep Latent Variable Modeling of Physiological Signals","abstract":"A deep latent variable model is a powerful method for capturing complex distributions. These models assume that underlying structures, but unobserved, are present within the data. In this dissertation, we explore high-dimensional problems related to physiological monitoring using latent variable models. First, we present a novel deep state-space model to generate electrical waveforms of the heart using optically obtained signals as inputs. This can bring about clinical diagnoses of heart disease via simple assessment through wearable devices. Second, we present a brain signal modeling scheme that combines the strengths of probabilistic graphical models and deep adversarial learning. The structured representations can provide interpretability and encode inductive biases to reduce the data complexity of neural oscillations. The efficacy of the learned representations is further studied in epilepsy seizure detection formulated as an unsupervised learning problem. Third, we propose a framework for the joint modeling of physiological measures and behavior. Existing methods to combine multiple sources of brain data provided are limited. Direct analysis of the relationship between different types of physiological measures usually does not involve behavioral data. Our method can identify the unique and shared contributions of brain regions to behavior and can be used to discover new functions of brain regions. The success of these innovative computational methods would allow the translation of biomarker findings across species and provide insight into neurocognitive analysis in numerous biological studies and clinical diagnoses, as well as emerging consumer applications.","sentences":["A deep latent variable model is a powerful method for capturing complex distributions.","These models assume that underlying structures, but unobserved, are present within the data.","In this dissertation, we explore high-dimensional problems related to physiological monitoring using latent variable models.","First, we present a novel deep state-space model to generate electrical waveforms of the heart using optically obtained signals as inputs.","This can bring about clinical diagnoses of heart disease via simple assessment through wearable devices.","Second, we present a brain signal modeling scheme that combines the strengths of probabilistic graphical models and deep adversarial learning.","The structured representations can provide interpretability and encode inductive biases to reduce the data complexity of neural oscillations.","The efficacy of the learned representations is further studied in epilepsy seizure detection formulated as an unsupervised learning problem.","Third, we propose a framework for the joint modeling of physiological measures and behavior.","Existing methods to combine multiple sources of brain data provided are limited.","Direct analysis of the relationship between different types of physiological measures usually does not involve behavioral data.","Our method can identify the unique and shared contributions of brain regions to behavior and can be used to discover new functions of brain regions.","The success of these innovative computational methods would allow the translation of biomarker findings across species and provide insight into neurocognitive analysis in numerous biological studies and clinical diagnoses, as well as emerging consumer applications."],"url":"http://arxiv.org/abs/2405.19277v2","category":"cs.LG"}
{"created":"2024-05-29 17:07:24","title":"A Recipe for Charge Density Prediction","abstract":"In density functional theory, charge density is the core attribute of atomic systems from which all chemical properties can be derived. Machine learning methods are promising in significantly accelerating charge density prediction, yet existing approaches either lack accuracy or scalability. We propose a recipe that can achieve both. In particular, we identify three key ingredients: (1) representing the charge density with atomic and virtual orbitals (spherical fields centered at atom/virtual coordinates); (2) using expressive and learnable orbital basis sets (basis function for the spherical fields); and (3) using high-capacity equivariant neural network architecture. Our method achieves state-of-the-art accuracy while being more than an order of magnitude faster than existing methods. Furthermore, our method enables flexible efficiency-accuracy trade-offs by adjusting the model/basis sizes.","sentences":["In density functional theory, charge density is the core attribute of atomic systems from which all chemical properties can be derived.","Machine learning methods are promising in significantly accelerating charge density prediction, yet existing approaches either lack accuracy or scalability.","We propose a recipe that can achieve both.","In particular, we identify three key ingredients: (1) representing the charge density with atomic and virtual orbitals (spherical fields centered at atom/virtual coordinates); (2) using expressive and learnable orbital basis sets (basis function for the spherical fields); and (3) using high-capacity equivariant neural network architecture.","Our method achieves state-of-the-art accuracy while being more than an order of magnitude faster than existing methods.","Furthermore, our method enables flexible efficiency-accuracy trade-offs by adjusting the model/basis sizes."],"url":"http://arxiv.org/abs/2405.19276v1","category":"physics.comp-ph"}
{"created":"2024-05-29 17:03:31","title":"Mitigating Disparate Impact of Differential Privacy in Federated Learning through Robust Clustering","abstract":"Federated Learning (FL) is a decentralized machine learning (ML) approach that keeps data localized and often incorporates Differential Privacy (DP) to enhance privacy guarantees. Similar to previous work on DP in ML, we observed that differentially private federated learning (DPFL) introduces performance disparities, particularly affecting minority groups. Recent work has attempted to address performance fairness in vanilla FL through clustering, but this method remains sensitive and prone to errors, which are further exacerbated by the DP noise in DPFL. To fill this gap, in this paper, we propose a novel clustered DPFL algorithm designed to effectively identify clients' clusters in highly heterogeneous settings while maintaining high accuracy with DP guarantees. To this end, we propose to cluster clients based on both their model updates and training loss values. Our proposed approach also addresses the server's uncertainties in clustering clients' model updates by employing larger batch sizes along with Gaussian Mixture Model (GMM) to alleviate the impact of noise and potential clustering errors, especially in privacy-sensitive scenarios. We provide theoretical analysis of the effectiveness of our proposed approach. We also extensively evaluate our approach across diverse data distributions and privacy budgets and show its effectiveness in mitigating the disparate impact of DP in FL settings with a small computational cost.","sentences":["Federated Learning (FL) is a decentralized machine learning (ML) approach that keeps data localized and often incorporates Differential Privacy (DP) to enhance privacy guarantees.","Similar to previous work on DP in ML, we observed that differentially private federated learning (DPFL) introduces performance disparities, particularly affecting minority groups.","Recent work has attempted to address performance fairness in vanilla FL through clustering, but this method remains sensitive and prone to errors, which are further exacerbated by the DP noise in DPFL.","To fill this gap, in this paper, we propose a novel clustered DPFL algorithm designed to effectively identify clients' clusters in highly heterogeneous settings while maintaining high accuracy with DP guarantees.","To this end, we propose to cluster clients based on both their model updates and training loss values.","Our proposed approach also addresses the server's uncertainties in clustering clients' model updates by employing larger batch sizes along with Gaussian Mixture Model (GMM) to alleviate the impact of noise and potential clustering errors, especially in privacy-sensitive scenarios.","We provide theoretical analysis of the effectiveness of our proposed approach.","We also extensively evaluate our approach across diverse data distributions and privacy budgets and show its effectiveness in mitigating the disparate impact of DP in FL settings with a small computational cost."],"url":"http://arxiv.org/abs/2405.19272v1","category":"cs.LG"}
{"created":"2024-05-29 16:44:09","title":"Hybrid-Parallel: Achieving High Performance and Energy Efficient Distributed Inference on Robots","abstract":"The rapid advancements in machine learning techniques have led to significant achievements in various real-world robotic tasks. These tasks heavily rely on fast and energy-efficient inference of deep neural network (DNN) models when deployed on robots. To enhance inference performance, distributed inference has emerged as a promising approach, parallelizing inference across multiple powerful GPU devices in modern data centers using techniques such as data parallelism, tensor parallelism, and pipeline parallelism. However, when deployed on real-world robots, existing parallel methods fail to provide low inference latency and meet the energy requirements due to the limited bandwidth of robotic IoT. We present Hybrid-Parallel, a high-performance distributed inference system optimized for robotic IoT. Hybrid-Parallel employs a fine-grained approach to parallelize inference at the granularity of local operators within DNN layers (i.e., operators that can be computed independently with the partial input, such as the convolution kernel in the convolution layer). By doing so, Hybrid-Parallel enables different operators of different layers to be computed and transmitted concurrently, and overlap the computation and transmission phases within the same inference task. The evaluation demonstrate that Hybrid-Parallel reduces inference time by 14.9% ~41.1% and energy consumption per inference by up to 35.3% compared to the state-of-the-art baselines.","sentences":["The rapid advancements in machine learning techniques have led to significant achievements in various real-world robotic tasks.","These tasks heavily rely on fast and energy-efficient inference of deep neural network (DNN) models when deployed on robots.","To enhance inference performance, distributed inference has emerged as a promising approach, parallelizing inference across multiple powerful GPU devices in modern data centers using techniques such as data parallelism, tensor parallelism, and pipeline parallelism.","However, when deployed on real-world robots, existing parallel methods fail to provide low inference latency and meet the energy requirements due to the limited bandwidth of robotic IoT. We present Hybrid-Parallel, a high-performance distributed inference system optimized for robotic IoT. Hybrid-Parallel employs a fine-grained approach to parallelize inference at the granularity of local operators within DNN layers (i.e., operators that can be computed independently with the partial input, such as the convolution kernel in the convolution layer).","By doing so, Hybrid-Parallel enables different operators of different layers to be computed and transmitted concurrently, and overlap the computation and transmission phases within the same inference task.","The evaluation demonstrate that Hybrid-Parallel reduces inference time by 14.9% ~41.1% and energy consumption per inference by up to 35.3% compared to the state-of-the-art baselines."],"url":"http://arxiv.org/abs/2405.19257v1","category":"cs.RO"}
{"created":"2024-05-29 16:39:01","title":"Causal Fermion Systems as an Effective Collapse Theory","abstract":"It is shown that, in the non-relativistic limit, causal fermion systems give rise to an effective collapse theory. The nonlinear and stochastic correction terms to the Schr\\\"odinger equation are derived from the causal action principle. The dynamics of the statistical operator is described by a deterministic equation of Kossakowski-Lindblad form. Moreover, the quantum state undergoes a dynamical collapse compatible with Born's rule. The effective model has similarities with the continuous spontaneous localization model, but differs from it by a conservation law for the probability integral as well as a non-locality in time on a microscopic length scale $\\ell_{\\min}$.","sentences":["It is shown that, in the non-relativistic limit, causal fermion systems give rise to an effective collapse theory.","The nonlinear and stochastic correction terms to the Schr\\\"odinger equation are derived from the causal action principle.","The dynamics of the statistical operator is described by a deterministic equation of Kossakowski-Lindblad form.","Moreover, the quantum state undergoes a dynamical collapse compatible with Born's rule.","The effective model has similarities with the continuous spontaneous localization model, but differs from it by a conservation law for the probability integral as well as a non-locality in time on a microscopic length scale $\\ell_{\\min}$."],"url":"http://arxiv.org/abs/2405.19254v1","category":"math-ph"}
{"created":"2024-05-29 16:34:54","title":"Dark matter admixed neutron stars with a realistic nuclear equation of state from chiral nuclear interactions","abstract":"We study the effects of dark matter on the structural properties of neutron stars. In particular we investigate how the presence of a dark matter component influences the mass-radius relation, the value of the maximum mass of a neutron star and others stellar properties. To model ordinary matter we use a state-of-the-art equation of state of $\\beta$-stable nuclear matter obtained using the Brueckner-Hartree-Fock quantum many-body approach starting from two-body and three-body nuclear interactions derived from chiral effective field theory. The dark matter component of the star is modeled as a non-self-annihilating system of spin $1/2$ fermions and its equation of state as an ideal relativistic Fermi gas. The equilibrium configurations of these dark matter admixed neutron stars (DANS) are calculated by solving a generalization of the Tolman-Oppenheimer-Volkoff equations to the case where the system consists of two perfect fluids interacting solely through gravity. We find that, depending on the dark matter particle mass $m_\\chi$, one can have somehow opposite effects on the stellar properties. In the case $m_\\chi = 1\\, \\mathrm{GeV}$, the stellar gravitational maximum mass $M_{max}$ decreases, whereas in the case $m_\\chi = 0.1\\, \\mathrm{GeV}$, $M_{max}$ increases with respect to the maximum mass of ordinary neutron stars. We also show that the presence of dark matter has indirect sizeable effect on the proton fraction in the ordinary matter fluid and, in the case $m_\\chi = 1\\, \\mathrm{GeV}$, results in a decrease of the threshold gravitational mass $M_{tot}^{durca}$ for having direct URCA processes and fast stellar cooling. Finally we study the stability of dark matter admixed neutron stars with respect to radial perturbations.","sentences":["We study the effects of dark matter on the structural properties of neutron stars.","In particular we investigate how the presence of a dark matter component influences the mass-radius relation, the value of the maximum mass of a neutron star and others stellar properties.","To model ordinary matter we use a state-of-the-art equation of state of $\\beta$-stable nuclear matter obtained using the Brueckner-Hartree-Fock quantum many-body approach starting from two-body and three-body nuclear interactions derived from chiral effective field theory.","The dark matter component of the star is modeled as a non-self-annihilating system of spin $1/2$ fermions and its equation of state as an ideal relativistic Fermi gas.","The equilibrium configurations of these dark matter admixed neutron stars (DANS) are calculated by solving a generalization of the Tolman-Oppenheimer-Volkoff equations to the case where the system consists of two perfect fluids interacting solely through gravity.","We find that, depending on the dark matter particle mass $m_\\chi$, one can have somehow opposite effects on the stellar properties.","In the case $m_\\chi = 1\\, \\mathrm{GeV}$, the stellar gravitational maximum mass $M_{max}$ decreases, whereas in the case $m_\\chi = 0.1\\, \\mathrm{GeV}$, $M_{max}$ increases with respect to the maximum mass of ordinary neutron stars.","We also show that the presence of dark matter has indirect sizeable effect on the proton fraction in the ordinary matter fluid and, in the case $m_\\chi = 1\\, \\mathrm{GeV}$, results in a decrease of the threshold gravitational mass $M_{tot}^{durca}$ for having direct URCA processes and fast stellar cooling.","Finally we study the stability of dark matter admixed neutron stars with respect to radial perturbations."],"url":"http://arxiv.org/abs/2405.19251v1","category":"astro-ph.HE"}
{"created":"2024-05-29 16:21:43","title":"On geometric invariants of singular plane curves","abstract":"Given a germ of a smooth plane curve $(\\{f(x,y)=0\\},0)\\subset (\\mathbb K^2,0), \\mathbb K=\\mathbb R, \\mathbb C$, with an isolated singularity, we define two invariants $I_f$ and $V_f\\in \\mathbb N\\cup\\{\\infty\\}$ which count the number of inflections and vertices (suitably interpreted in the complex case) concentrated at the singular point; the first is an affine invariant and the second is invariant under similarities of $\\mathbb R^2$, and their analogue for $\\mathbb C^2$. We show that for almost all representations of $f$, in the sense that their complement is of infinite codimension, these invariants are finite. Indeed when the curve has no smooth components they are always finite and bounded and we can be much more explicit about the values they can attain; the set of possible values is of course an analytic invariant of $f$. We illustrate our results by computing these invariants for Arnold's $\\mathcal K$-simple singularities as well as singularities that have ${\\mathcal A}$-simple parametrisations. We also obtain a relationship between these invariants, the Milnor number of $f$ and the contact of the curve germ with its osculating circle.","sentences":["Given a germ of a smooth plane curve $(\\{f(x,y)=0\\},0)\\subset (\\mathbb K^2,0), \\mathbb K=\\mathbb R, \\mathbb C$, with an isolated singularity, we define two invariants $I_f$ and $V_f\\in \\mathbb N\\cup\\{\\infty\\}$ which count the number of inflections and vertices (suitably interpreted in the complex case) concentrated at the singular point; the first is an affine invariant and the second is invariant under similarities of $\\mathbb R^2$, and their analogue for $\\mathbb C^2$. We show that for almost all representations of $f$, in the sense that their complement is of infinite codimension, these invariants are finite.","Indeed when the curve has no smooth components they are always finite and bounded and we can be much more explicit about the values they can attain; the set of possible values is of course an analytic invariant of $f$. We illustrate our results by computing these invariants for Arnold's $\\mathcal K$-simple singularities as well as singularities that have ${\\mathcal A}$-simple parametrisations.","We also obtain a relationship between these invariants, the Milnor number of $f$ and the contact of the curve germ with its osculating circle."],"url":"http://arxiv.org/abs/2405.19239v1","category":"math.DG"}
{"created":"2024-05-29 16:13:54","title":"Forward-Backward Knowledge Distillation for Continual Clustering","abstract":"Unsupervised Continual Learning (UCL) is a burgeoning field in machine learning, focusing on enabling neural networks to sequentially learn tasks without explicit label information. Catastrophic Forgetting (CF), where models forget previously learned tasks upon learning new ones, poses a significant challenge in continual learning, especially in UCL, where labeled information of data is not accessible. CF mitigation strategies, such as knowledge distillation and replay buffers, often face memory inefficiency and privacy issues. Although current research in UCL has endeavored to refine data representations and address CF in streaming data contexts, there is a noticeable lack of algorithms specifically designed for unsupervised clustering. To fill this gap, in this paper, we introduce the concept of Unsupervised Continual Clustering (UCC). We propose Forward-Backward Knowledge Distillation for unsupervised Continual Clustering (FBCC) to counteract CF within the context of UCC. FBCC employs a single continual learner (the ``teacher'') with a cluster projector, along with multiple student models, to address the CF issue. The proposed method consists of two phases: Forward Knowledge Distillation, where the teacher learns new clusters while retaining knowledge from previous tasks with guidance from specialized student models, and Backward Knowledge Distillation, where a student model mimics the teacher's behavior to retain task-specific knowledge, aiding the teacher in subsequent tasks. FBCC marks a pioneering approach to UCC, demonstrating enhanced performance and memory efficiency in clustering across various tasks, outperforming the application of clustering algorithms to the latent space of state-of-the-art UCL algorithms.","sentences":["Unsupervised Continual Learning (UCL) is a burgeoning field in machine learning, focusing on enabling neural networks to sequentially learn tasks without explicit label information.","Catastrophic Forgetting (CF), where models forget previously learned tasks upon learning new ones, poses a significant challenge in continual learning, especially in UCL, where labeled information of data is not accessible.","CF mitigation strategies, such as knowledge distillation and replay buffers, often face memory inefficiency and privacy issues.","Although current research in UCL has endeavored to refine data representations and address CF in streaming data contexts, there is a noticeable lack of algorithms specifically designed for unsupervised clustering.","To fill this gap, in this paper, we introduce the concept of Unsupervised Continual Clustering (UCC).","We propose Forward-Backward Knowledge Distillation for unsupervised Continual Clustering (FBCC) to counteract CF within the context of UCC.","FBCC employs a single continual learner (the ``teacher'') with a cluster projector, along with multiple student models, to address the CF issue.","The proposed method consists of two phases: Forward Knowledge Distillation, where the teacher learns new clusters while retaining knowledge from previous tasks with guidance from specialized student models, and Backward Knowledge Distillation, where a student model mimics the teacher's behavior to retain task-specific knowledge, aiding the teacher in subsequent tasks.","FBCC marks a pioneering approach to UCC, demonstrating enhanced performance and memory efficiency in clustering across various tasks, outperforming the application of clustering algorithms to the latent space of state-of-the-art UCL algorithms."],"url":"http://arxiv.org/abs/2405.19234v1","category":"cs.LG"}
{"created":"2024-05-29 16:07:39","title":"Valid Conformal Prediction for Dynamic GNNs","abstract":"Graph neural networks (GNNs) are powerful black-box models which have shown impressive empirical performance. However, without any form of uncertainty quantification, it can be difficult to trust such models in high-risk scenarios. Conformal prediction aims to address this problem, however, an assumption of exchangeability is required for its validity which has limited its applicability to static graphs and transductive regimes. We propose to use unfolding, which allows any existing static GNN to output a dynamic graph embedding with exchangeability properties. Using this, we extend the validity of conformal prediction to dynamic GNNs in both transductive and semi-inductive regimes. We provide a theoretical guarantee of valid conformal prediction in these cases and demonstrate the empirical validity, as well as the performance gains, of unfolded GNNs against standard GNN architectures on both simulated and real datasets.","sentences":["Graph neural networks (GNNs) are powerful black-box models which have shown impressive empirical performance.","However, without any form of uncertainty quantification, it can be difficult to trust such models in high-risk scenarios.","Conformal prediction aims to address this problem, however, an assumption of exchangeability is required for its validity which has limited its applicability to static graphs and transductive regimes.","We propose to use unfolding, which allows any existing static GNN to output a dynamic graph embedding with exchangeability properties.","Using this, we extend the validity of conformal prediction to dynamic GNNs in both transductive and semi-inductive regimes.","We provide a theoretical guarantee of valid conformal prediction in these cases and demonstrate the empirical validity, as well as the performance gains, of unfolded GNNs against standard GNN architectures on both simulated and real datasets."],"url":"http://arxiv.org/abs/2405.19230v1","category":"stat.ML"}
{"created":"2024-05-29 17:59:07","title":"Self-Exploring Language Models: Active Preference Elicitation for Online Alignment","abstract":"Preference optimization, particularly through Reinforcement Learning from Human Feedback (RLHF), has achieved significant success in aligning Large Language Models (LLMs) to adhere to human intentions. Unlike offline alignment with a fixed dataset, online feedback collection from humans or AI on model generations typically leads to more capable reward models and better-aligned LLMs through an iterative process. However, achieving a globally accurate reward model requires systematic exploration to generate diverse responses that span the vast space of natural language. Random sampling from standard reward-maximizing LLMs alone is insufficient to fulfill this requirement. To address this issue, we propose a bilevel objective optimistically biased towards potentially high-reward responses to actively explore out-of-distribution regions. By solving the inner-level problem with the reparameterized reward function, the resulting algorithm, named Self-Exploring Language Models (SELM), eliminates the need for a separate RM and iteratively updates the LLM with a straightforward objective. Compared to Direct Preference Optimization (DPO), the SELM objective reduces indiscriminate favor of unseen extrapolations and enhances exploration efficiency. Our experimental results demonstrate that when finetuned on Zephyr-7B-SFT and Llama-3-8B-Instruct models, SELM significantly boosts the performance on instruction-following benchmarks such as MT-Bench and AlpacaEval 2.0, as well as various standard academic benchmarks in different settings. Our code and models are available at https://github.com/shenao-zhang/SELM.","sentences":["Preference optimization, particularly through Reinforcement Learning from Human Feedback (RLHF), has achieved significant success in aligning Large Language Models (LLMs) to adhere to human intentions.","Unlike offline alignment with a fixed dataset, online feedback collection from humans or AI on model generations typically leads to more capable reward models and better-aligned LLMs through an iterative process.","However, achieving a globally accurate reward model requires systematic exploration to generate diverse responses that span the vast space of natural language.","Random sampling from standard reward-maximizing LLMs alone is insufficient to fulfill this requirement.","To address this issue, we propose a bilevel objective optimistically biased towards potentially high-reward responses to actively explore out-of-distribution regions.","By solving the inner-level problem with the reparameterized reward function, the resulting algorithm, named Self-Exploring Language Models (SELM), eliminates the need for a separate RM and iteratively updates the LLM with a straightforward objective.","Compared to Direct Preference Optimization (DPO), the SELM objective reduces indiscriminate favor of unseen extrapolations and enhances exploration efficiency.","Our experimental results demonstrate that when finetuned on Zephyr-7B-SFT and Llama-3-8B-Instruct models, SELM significantly boosts the performance on instruction-following benchmarks such as MT-Bench and AlpacaEval 2.0, as well as various standard academic benchmarks in different settings.","Our code and models are available at https://github.com/shenao-zhang/SELM."],"url":"http://arxiv.org/abs/2405.19332v1","category":"cs.LG"}
{"created":"2024-05-29 17:57:16","title":"MAP-Neo: Highly Capable and Transparent Bilingual Large Language Model Series","abstract":"Large Language Models (LLMs) have made great strides in recent years to achieve unprecedented performance across different tasks. However, due to commercial interest, the most competitive models like GPT, Gemini, and Claude have been gated behind proprietary interfaces without disclosing the training details. Recently, many institutions have open-sourced several strong LLMs like LLaMA-3, comparable to existing closed-source LLMs. However, only the model's weights are provided with most details (e.g., intermediate checkpoints, pre-training corpus, and training code, etc.) being undisclosed. To improve the transparency of LLMs, the research community has formed to open-source truly open LLMs (e.g., Pythia, Amber, OLMo), where more details (e.g., pre-training corpus and training code) are being provided. These models have greatly advanced the scientific study of these large models including their strengths, weaknesses, biases and risks. However, we observe that the existing truly open LLMs on reasoning, knowledge, and coding tasks are still inferior to existing state-of-the-art LLMs with similar model sizes. To this end, we open-source MAP-Neo, a highly capable and transparent bilingual language model with 7B parameters trained from scratch on 4.5T high-quality tokens. Our MAP-Neo is the first fully open-sourced bilingual LLM with comparable performance compared to existing state-of-the-art LLMs. Moreover, we open-source all details to reproduce our MAP-Neo, where the cleaned pre-training corpus, data cleaning pipeline, checkpoints, and well-optimized training/evaluation framework are provided. Finally, we hope our MAP-Neo will enhance and strengthen the open research community and inspire more innovations and creativities to facilitate the further improvements of LLMs.","sentences":["Large Language Models (LLMs) have made great strides in recent years to achieve unprecedented performance across different tasks.","However, due to commercial interest, the most competitive models like GPT, Gemini, and Claude have been gated behind proprietary interfaces without disclosing the training details.","Recently, many institutions have open-sourced several strong LLMs like LLaMA-3, comparable to existing closed-source LLMs.","However, only the model's weights are provided with most details (e.g., intermediate checkpoints, pre-training corpus, and training code, etc.)","being undisclosed.","To improve the transparency of LLMs, the research community has formed to open-source truly open LLMs (e.g., Pythia, Amber, OLMo), where more details (e.g., pre-training corpus and training code) are being provided.","These models have greatly advanced the scientific study of these large models including their strengths, weaknesses, biases and risks.","However, we observe that the existing truly open LLMs on reasoning, knowledge, and coding tasks are still inferior to existing state-of-the-art LLMs with similar model sizes.","To this end, we open-source MAP-Neo, a highly capable and transparent bilingual language model with 7B parameters trained from scratch on 4.5T high-quality tokens.","Our MAP-Neo is the first fully open-sourced bilingual LLM with comparable performance compared to existing state-of-the-art LLMs.","Moreover, we open-source all details to reproduce our MAP-Neo, where the cleaned pre-training corpus, data cleaning pipeline, checkpoints, and well-optimized training/evaluation framework are provided.","Finally, we hope our MAP-Neo will enhance and strengthen the open research community and inspire more innovations and creativities to facilitate the further improvements of LLMs."],"url":"http://arxiv.org/abs/2405.19327v2","category":"cs.CL"}
{"created":"2024-05-29 17:52:22","title":"DGD: Dynamic 3D Gaussians Distillation","abstract":"We tackle the task of learning dynamic 3D semantic radiance fields given a single monocular video as input. Our learned semantic radiance field captures per-point semantics as well as color and geometric properties for a dynamic 3D scene, enabling the generation of novel views and their corresponding semantics. This enables the segmentation and tracking of a diverse set of 3D semantic entities, specified using a simple and intuitive interface that includes a user click or a text prompt. To this end, we present DGD, a unified 3D representation for both the appearance and semantics of a dynamic 3D scene, building upon the recently proposed dynamic 3D Gaussians representation. Our representation is optimized over time with both color and semantic information. Key to our method is the joint optimization of the appearance and semantic attributes, which jointly affect the geometric properties of the scene. We evaluate our approach in its ability to enable dense semantic 3D object tracking and demonstrate high-quality results that are fast to render, for a diverse set of scenes. Our project webpage is available on https://isaaclabe.github.io/DGD-Website/","sentences":["We tackle the task of learning dynamic 3D semantic radiance fields given a single monocular video as input.","Our learned semantic radiance field captures per-point semantics as well as color and geometric properties for a dynamic 3D scene, enabling the generation of novel views and their corresponding semantics.","This enables the segmentation and tracking of a diverse set of 3D semantic entities, specified using a simple and intuitive interface that includes a user click or a text prompt.","To this end, we present DGD, a unified 3D representation for both the appearance and semantics of a dynamic 3D scene, building upon the recently proposed dynamic 3D Gaussians representation.","Our representation is optimized over time with both color and semantic information.","Key to our method is the joint optimization of the appearance and semantic attributes, which jointly affect the geometric properties of the scene.","We evaluate our approach in its ability to enable dense semantic 3D object tracking and demonstrate high-quality results that are fast to render, for a diverse set of scenes.","Our project webpage is available on https://isaaclabe.github.io/DGD-Website/"],"url":"http://arxiv.org/abs/2405.19321v1","category":"cs.CV"}
{"created":"2024-05-29 17:51:42","title":"Value-Incentivized Preference Optimization: A Unified Approach to Online and Offline RLHF","abstract":"Reinforcement learning from human feedback (RLHF) has demonstrated great promise in aligning large language models (LLMs) with human preference. Depending on the availability of preference data, both online and offline RLHF are active areas of investigation. A key bottleneck is understanding how to incorporate uncertainty estimation in the reward function learned from the preference data for RLHF, regardless of how the preference data is collected. While the principles of optimism or pessimism under uncertainty are well-established in standard reinforcement learning (RL), a practically-implementable and theoretically-grounded form amenable to large language models is not yet available, as standard techniques for constructing confidence intervals become intractable under arbitrary policy parameterizations.   In this paper, we introduce a unified approach to online and offline RLHF -- value-incentivized preference optimization (VPO) -- which regularizes the maximum-likelihood estimate of the reward function with the corresponding value function, modulated by a $\\textit{sign}$ to indicate whether the optimism or pessimism is chosen. VPO also directly optimizes the policy with implicit reward modeling, and therefore shares a simpler RLHF pipeline similar to direct preference optimization. Theoretical guarantees of VPO are provided for both online and offline settings, matching the rates of their standard RL counterparts. Moreover, experiments on text summarization and dialog verify the practicality and effectiveness of VPO.","sentences":["Reinforcement learning from human feedback (RLHF) has demonstrated great promise in aligning large language models (LLMs) with human preference.","Depending on the availability of preference data, both online and offline RLHF are active areas of investigation.","A key bottleneck is understanding how to incorporate uncertainty estimation in the reward function learned from the preference data for RLHF, regardless of how the preference data is collected.","While the principles of optimism or pessimism under uncertainty are well-established in standard reinforcement learning (RL), a practically-implementable and theoretically-grounded form amenable to large language models is not yet available, as standard techniques for constructing confidence intervals become intractable under arbitrary policy parameterizations.   ","In this paper, we introduce a unified approach to online and offline RLHF -- value-incentivized preference optimization (VPO) -- which regularizes the maximum-likelihood estimate of the reward function with the corresponding value function, modulated by a $\\textit{sign}$ to indicate whether the optimism or pessimism is chosen.","VPO also directly optimizes the policy with implicit reward modeling, and therefore shares a simpler RLHF pipeline similar to direct preference optimization.","Theoretical guarantees of VPO are provided for both online and offline settings, matching the rates of their standard RL counterparts.","Moreover, experiments on text summarization and dialog verify the practicality and effectiveness of VPO."],"url":"http://arxiv.org/abs/2405.19320v1","category":"cs.LG"}
{"created":"2024-05-29 17:39:48","title":"Robust Preference Optimization through Reward Model Distillation","abstract":"Language model (LM) post-training (or alignment) involves maximizing a reward function that is derived from preference annotations. Direct Preference Optimization (DPO) is a popular offline alignment method that trains a policy directly on preference data without the need to train a reward model or apply reinforcement learning. However, typical preference datasets have only a single, or at most a few, annotation per preference pair, which causes DPO to overconfidently assign rewards that trend towards infinite magnitude. This frequently leads to degenerate policies, sometimes causing even the probabilities of the preferred generations to go to zero. In this work, we analyze this phenomenon and propose distillation to get a better proxy for the true preference distribution over generation pairs: we train the LM to produce probabilities that match the distribution induced by a reward model trained on the preference data. Moreover, to account for uncertainty in the reward model we are distilling from, we optimize against a family of reward models that, as a whole, is likely to include at least one reasonable proxy for the preference distribution. Our results show that distilling from such a family of reward models leads to improved robustness to distribution shift in preference annotations, while preserving the simple supervised nature of DPO.","sentences":["Language model (LM) post-training (or alignment) involves maximizing a reward function that is derived from preference annotations.","Direct Preference Optimization (DPO) is a popular offline alignment method that trains a policy directly on preference data without the need to train a reward model or apply reinforcement learning.","However, typical preference datasets have only a single, or at most a few, annotation per preference pair, which causes DPO to overconfidently assign rewards that trend towards infinite magnitude.","This frequently leads to degenerate policies, sometimes causing even the probabilities of the preferred generations to go to zero.","In this work, we analyze this phenomenon and propose distillation to get a better proxy for the true preference distribution over generation pairs: we train the LM to produce probabilities that match the distribution induced by a reward model trained on the preference data.","Moreover, to account for uncertainty in the reward model we are distilling from, we optimize against a family of reward models that, as a whole, is likely to include at least one reasonable proxy for the preference distribution.","Our results show that distilling from such a family of reward models leads to improved robustness to distribution shift in preference annotations, while preserving the simple supervised nature of DPO."],"url":"http://arxiv.org/abs/2405.19316v1","category":"cs.LG"}
{"created":"2024-05-29 17:27:50","title":"Multi-qubit circuit synthesis and Hermitian lattices","abstract":"We present new optimal and heuristic algorithms for exact synthesis of multi-qubit unitaries and isometries. For example, our algorithms find Clifford and T circuits for unitaries with entries in $\\mathbb{Z}[i,1/\\sqrt{2}]$. The optimal algorithms are the A* search instantiated with a new data structure for graph vertices and new consistent heuristic functions. We also prove that for some gate sets, best-first search synthesis relying on the same heuristic is efficient. For example, for two-qubit Clifford and T circuits, our best-first search runtime is proportional to the T-count of the unitary. Our algorithms rely on Hermite and Smith Normal Forms of matrices with entries in a ring of integers of a number field, and we leverage the theory of and algorithms for Hermitian lattices over number fields to prove efficiency. These new techniques are of independent interest for future work on multi-qubit exact circuit synthesis and related questions.","sentences":["We present new optimal and heuristic algorithms for exact synthesis of multi-qubit unitaries and isometries.","For example, our algorithms find Clifford and T circuits for unitaries with entries in $\\mathbb{Z}[i,1/\\sqrt{2}]$. The optimal algorithms are the A* search instantiated with a new data structure for graph vertices and new consistent heuristic functions.","We also prove that for some gate sets, best-first search synthesis relying on the same heuristic is efficient.","For example, for two-qubit Clifford and T circuits, our best-first search runtime is proportional to the T-count of the unitary.","Our algorithms rely on Hermite and Smith Normal Forms of matrices with entries in a ring of integers of a number field, and we leverage the theory of and algorithms for Hermitian lattices over number fields to prove efficiency.","These new techniques are of independent interest for future work on multi-qubit exact circuit synthesis and related questions."],"url":"http://arxiv.org/abs/2405.19302v1","category":"quant-ph"}
{"created":"2024-05-29 17:27:30","title":"Safe and Efficient Estimation for Robotics through the Optimal Use of Resources","abstract":"In order to operate in and interact with the physical world, robots need to have estimates of the current and future state of the environment. We thus equip robots with sensors and build models and algorithms that, given some measurements, produce estimates of the current or future states. Environments can be unpredictable and sensors are not perfect. Therefore, it is important to both use all information available, and to do so optimally: making sure that we get the best possible answer from the amount of information we have. However, in prevalent research, uncommon sensors, such as sound or radio-frequency signals, are commonly ignored for state estimation; and the most popular solvers employed to produce state estimates are only of local nature, meaning they may produce suboptimal estimates for the typically non-convex estimation problems. My research aims to use resources more optimally, by building on 1) multi-modality: using ubiquitous RF transceivers and microphones to support state estimation, 2) building certifiably optimal solvers and 3) learning and improving adequate models from data.","sentences":["In order to operate in and interact with the physical world, robots need to have estimates of the current and future state of the environment.","We thus equip robots with sensors and build models and algorithms that, given some measurements, produce estimates of the current or future states.","Environments can be unpredictable and sensors are not perfect.","Therefore, it is important to both use all information available, and to do so optimally: making sure that we get the best possible answer from the amount of information we have.","However, in prevalent research, uncommon sensors, such as sound or radio-frequency signals, are commonly ignored for state estimation; and the most popular solvers employed to produce state estimates are only of local nature, meaning they may produce suboptimal estimates for the typically non-convex estimation problems.","My research aims to use resources more optimally, by building on 1) multi-modality: using ubiquitous RF transceivers and microphones to support state estimation, 2) building certifiably optimal solvers and 3) learning and improving adequate models from data."],"url":"http://arxiv.org/abs/2405.19301v1","category":"cs.RO"}
{"created":"2024-05-29 17:23:05","title":"GPU-accelerated Higher Representations of Wilson Fermions with HiRep","abstract":"We are improving one of the available lattice software packages HiRep by adding GPU acceleration supporting highly-optimized simulations on both NVIDIA and AMD GPUs. HiRep allows lattice simulations of theories with fermions in higher representations and a variable number of colors in the gauge group. The development is accompanied by an overall software quality improvement in the build system, testing, and documentation, adding features for both CPUs and GPUs. The software is available under https://github.com/claudiopica/HiRep","sentences":["We are improving one of the available lattice software packages HiRep by adding GPU acceleration supporting highly-optimized simulations on both NVIDIA and AMD GPUs.","HiRep allows lattice simulations of theories with fermions in higher representations and a variable number of colors in the gauge group.","The development is accompanied by an overall software quality improvement in the build system, testing, and documentation, adding features for both CPUs and GPUs.","The software is available under https://github.com/claudiopica/HiRep"],"url":"http://arxiv.org/abs/2405.19294v1","category":"hep-lat"}
{"created":"2024-05-29 17:21:25","title":"Act Natural! Projecting Autonomous System Trajectories Into Naturalistic Behavior Sets","abstract":"Autonomous agents operating around human actors must consider how their behaviors might affect those humans, even when not directly interacting with them. To this end, it is often beneficial to be predictable and appear naturalistic. Existing methods to address this problem use human actor intent modeling or imitation learning techniques, but these approaches rarely capture all possible motivations for human behavior or require significant amounts of data. In contrast, we propose a technique for modeling naturalistic behavior as a set of convex hulls computed over a relatively small dataset of human behavior. Given this set, we design an optimization-based filter which projects arbitrary trajectories into it to make them more naturalistic for autonomous agents to execute while also satisfying dynamics constraints. We demonstrate our methods on real-world human driving data from the inD intersection dataset (Bock et al., 2020).","sentences":["Autonomous agents operating around human actors must consider how their behaviors might affect those humans, even when not directly interacting with them.","To this end, it is often beneficial to be predictable and appear naturalistic.","Existing methods to address this problem use human actor intent modeling or imitation learning techniques, but these approaches rarely capture all possible motivations for human behavior or require significant amounts of data.","In contrast, we propose a technique for modeling naturalistic behavior as a set of convex hulls computed over a relatively small dataset of human behavior.","Given this set, we design an optimization-based filter which projects arbitrary trajectories into it to make them more naturalistic for autonomous agents to execute while also satisfying dynamics constraints.","We demonstrate our methods on real-world human driving data from the inD intersection dataset (Bock et al., 2020)."],"url":"http://arxiv.org/abs/2405.19292v1","category":"cs.MA"}
