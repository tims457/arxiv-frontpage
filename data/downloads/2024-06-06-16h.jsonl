{"created":"2024-06-04 17:59:36","title":"Learning to grok: Emergence of in-context learning and skill composition in modular arithmetic tasks","abstract":"Large language models can solve tasks that were not present in the training set. This capability is believed to be due to in-context learning and skill composition. In this work, we study the emergence of in-context learning and skill composition in a collection of modular arithmetic tasks. Specifically, we consider a finite collection of linear modular functions $z = a \\, x + b \\, y \\;\\mathrm{mod}\\; p$ labeled by the vector $(a, b) \\in \\mathbb{Z}_p^2$. We use some of these tasks for pre-training and the rest for out-of-distribution testing. We empirically show that a GPT-style transformer exhibits a transition from in-distribution to out-of-distribution generalization as the number of pre-training tasks increases. We find that the smallest model capable of out-of-distribution generalization requires two transformer blocks, while for deeper models, the out-of-distribution generalization phase is \\emph{transient}, necessitating early stopping. Finally, we perform an interpretability study of the pre-trained models, revealing the highly structured representations in both phases; and discuss the learnt algorithm.","sentences":["Large language models can solve tasks that were not present in the training set.","This capability is believed to be due to in-context learning and skill composition.","In this work, we study the emergence of in-context learning and skill composition in a collection of modular arithmetic tasks.","Specifically, we consider a finite collection of linear modular functions $z = a \\, x + b \\, y \\;\\mathrm{mod}\\;","p$ labeled by the vector $(a, b) \\in \\mathbb{Z}_p^2$. We use some of these tasks for pre-training and the rest for out-of-distribution testing.","We empirically show that a GPT-style transformer exhibits a transition from in-distribution to out-of-distribution generalization as the number of pre-training tasks increases.","We find that the smallest model capable of out-of-distribution generalization requires two transformer blocks, while for deeper models, the out-of-distribution generalization phase is \\emph{transient}, necessitating early stopping.","Finally, we perform an interpretability study of the pre-trained models, revealing the highly structured representations in both phases; and discuss the learnt algorithm."],"url":"http://arxiv.org/abs/2406.02550v1","category":"cs.LG"}
{"created":"2024-06-04 17:58:18","title":"To Believe or Not to Believe Your LLM","abstract":"We explore uncertainty quantification in large language models (LLMs), with the goal to identify when uncertainty in responses given a query is large. We simultaneously consider both epistemic and aleatoric uncertainties, where the former comes from the lack of knowledge about the ground truth (such as about facts or the language), and the latter comes from irreducible randomness (such as multiple possible answers). In particular, we derive an information-theoretic metric that allows to reliably detect when only epistemic uncertainty is large, in which case the output of the model is unreliable. This condition can be computed based solely on the output of the model obtained simply by some special iterative prompting based on the previous responses. Such quantification, for instance, allows to detect hallucinations (cases when epistemic uncertainty is high) in both single- and multi-answer responses. This is in contrast to many standard uncertainty quantification strategies (such as thresholding the log-likelihood of a response) where hallucinations in the multi-answer case cannot be detected. We conduct a series of experiments which demonstrate the advantage of our formulation. Further, our investigations shed some light on how the probabilities assigned to a given output by an LLM can be amplified by iterative prompting, which might be of independent interest.","sentences":["We explore uncertainty quantification in large language models (LLMs), with the goal to identify when uncertainty in responses given a query is large.","We simultaneously consider both epistemic and aleatoric uncertainties, where the former comes from the lack of knowledge about the ground truth (such as about facts or the language), and the latter comes from irreducible randomness (such as multiple possible answers).","In particular, we derive an information-theoretic metric that allows to reliably detect when only epistemic uncertainty is large, in which case the output of the model is unreliable.","This condition can be computed based solely on the output of the model obtained simply by some special iterative prompting based on the previous responses.","Such quantification, for instance, allows to detect hallucinations (cases when epistemic uncertainty is high) in both single- and multi-answer responses.","This is in contrast to many standard uncertainty quantification strategies (such as thresholding the log-likelihood of a response) where hallucinations in the multi-answer case cannot be detected.","We conduct a series of experiments which demonstrate the advantage of our formulation.","Further, our investigations shed some light on how the probabilities assigned to a given output by an LLM can be amplified by iterative prompting, which might be of independent interest."],"url":"http://arxiv.org/abs/2406.02543v1","category":"cs.LG"}
{"created":"2024-06-04 17:56:28","title":"Parrot: Multilingual Visual Instruction Tuning","abstract":"The rapid development of Multimodal Large Language Models (MLLMs) like GPT-4V has marked a significant step towards artificial general intelligence. Existing methods mainly focus on aligning vision encoders with LLMs through supervised fine-tuning (SFT) to endow LLMs with multimodal abilities, making MLLMs' inherent ability to react to multiple languages progressively deteriorate as the training process evolves. We empirically find that the imbalanced SFT datasets, primarily composed of English-centric image-text pairs, lead to significantly reduced performance in non-English languages. This is due to the failure of aligning the vision encoder and LLM with multilingual tokens during the SFT process. In this paper, we introduce Parrot, a novel method that utilizes textual guidance to drive visual token alignment at the language level. Parrot makes the visual tokens condition on diverse language inputs and uses Mixture-of-Experts (MoE) to promote the alignment of multilingual tokens. Specifically, to enhance non-English visual tokens alignment, we compute the cross-attention using the initial visual features and textual embeddings, the result of which is then fed into the MoE router to select the most relevant experts. The selected experts subsequently convert the initial visual tokens into language-specific visual tokens. Moreover, considering the current lack of benchmarks for evaluating multilingual capabilities within the field, we collect and make available a Massive Multilingual Multimodal Benchmark which includes 6 languages, 15 categories, and 12,000 questions, named as MMMB. Our method not only demonstrates state-of-the-art performance on multilingual MMBench and MMMB, but also excels across a broad range of multimodal tasks. Both the source code and the training dataset of Parrot will be made publicly available.","sentences":["The rapid development of Multimodal Large Language Models (MLLMs) like GPT-4V has marked a significant step towards artificial general intelligence.","Existing methods mainly focus on aligning vision encoders with LLMs through supervised fine-tuning (SFT) to endow LLMs with multimodal abilities, making MLLMs' inherent ability to react to multiple languages progressively deteriorate as the training process evolves.","We empirically find that the imbalanced SFT datasets, primarily composed of English-centric image-text pairs, lead to significantly reduced performance in non-English languages.","This is due to the failure of aligning the vision encoder and LLM with multilingual tokens during the SFT process.","In this paper, we introduce Parrot, a novel method that utilizes textual guidance to drive visual token alignment at the language level.","Parrot makes the visual tokens condition on diverse language inputs and uses Mixture-of-Experts (MoE) to promote the alignment of multilingual tokens.","Specifically, to enhance non-English visual tokens alignment, we compute the cross-attention using the initial visual features and textual embeddings, the result of which is then fed into the MoE router to select the most relevant experts.","The selected experts subsequently convert the initial visual tokens into language-specific visual tokens.","Moreover, considering the current lack of benchmarks for evaluating multilingual capabilities within the field, we collect and make available a Massive Multilingual Multimodal Benchmark which includes 6 languages, 15 categories, and 12,000 questions, named as MMMB.","Our method not only demonstrates state-of-the-art performance on multilingual MMBench and MMMB, but also excels across a broad range of multimodal tasks.","Both the source code and the training dataset of Parrot will be made publicly available."],"url":"http://arxiv.org/abs/2406.02539v1","category":"cs.CV"}
{"created":"2024-06-04 17:55:22","title":"Enhancing 2D Representation Learning with a 3D Prior","abstract":"Learning robust and effective representations of visual data is a fundamental task in computer vision. Traditionally, this is achieved by training models with labeled data which can be expensive to obtain. Self-supervised learning attempts to circumvent the requirement for labeled data by learning representations from raw unlabeled visual data alone. However, unlike humans who obtain rich 3D information from their binocular vision and through motion, the majority of current self-supervised methods are tasked with learning from monocular 2D image collections. This is noteworthy as it has been demonstrated that shape-centric visual processing is more robust compared to texture-biased automated methods. Inspired by this, we propose a new approach for strengthening existing self-supervised methods by explicitly enforcing a strong 3D structural prior directly into the model during training. Through experiments, across a range of datasets, we demonstrate that our 3D aware representations are more robust compared to conventional self-supervised baselines.","sentences":["Learning robust and effective representations of visual data is a fundamental task in computer vision.","Traditionally, this is achieved by training models with labeled data which can be expensive to obtain.","Self-supervised learning attempts to circumvent the requirement for labeled data by learning representations from raw unlabeled visual data alone.","However, unlike humans who obtain rich 3D information from their binocular vision and through motion, the majority of current self-supervised methods are tasked with learning from monocular 2D image collections.","This is noteworthy as it has been demonstrated that shape-centric visual processing is more robust compared to texture-biased automated methods.","Inspired by this, we propose a new approach for strengthening existing self-supervised methods by explicitly enforcing a strong 3D structural prior directly into the model during training.","Through experiments, across a range of datasets, we demonstrate that our 3D aware representations are more robust compared to conventional self-supervised baselines."],"url":"http://arxiv.org/abs/2406.02535v1","category":"cs.CV"}
{"created":"2024-06-04 17:54:44","title":"Enhancing predictive imaging biomarker discovery through treatment effect analysis","abstract":"Identifying predictive biomarkers, which forecast individual treatment effectiveness, is crucial for personalized medicine and informs decision-making across diverse disciplines. These biomarkers are extracted from pre-treatment data, often within randomized controlled trials, and have to be distinguished from prognostic biomarkers, which are independent of treatment assignment. Our study focuses on the discovery of predictive imaging biomarkers, aiming to leverage pre-treatment images to unveil new causal relationships. Previous approaches relied on labor-intensive handcrafted or manually derived features, which may introduce biases. In response, we present a new task of discovering predictive imaging biomarkers directly from the pre-treatment images to learn relevant image features. We propose an evaluation protocol for this task to assess a model's ability to identify predictive imaging biomarkers and differentiate them from prognostic ones. It employs statistical testing and a comprehensive analysis of image feature attribution. We explore the suitability of deep learning models originally designed for estimating the conditional average treatment effect (CATE) for this task, which previously have been primarily assessed for the precision of CATE estimation, overlooking the evaluation of imaging biomarker discovery. Our proof-of-concept analysis demonstrates promising results in discovering and validating predictive imaging biomarkers from synthetic outcomes and real-world image datasets.","sentences":["Identifying predictive biomarkers, which forecast individual treatment effectiveness, is crucial for personalized medicine and informs decision-making across diverse disciplines.","These biomarkers are extracted from pre-treatment data, often within randomized controlled trials, and have to be distinguished from prognostic biomarkers, which are independent of treatment assignment.","Our study focuses on the discovery of predictive imaging biomarkers, aiming to leverage pre-treatment images to unveil new causal relationships.","Previous approaches relied on labor-intensive handcrafted or manually derived features, which may introduce biases.","In response, we present a new task of discovering predictive imaging biomarkers directly from the pre-treatment images to learn relevant image features.","We propose an evaluation protocol for this task to assess a model's ability to identify predictive imaging biomarkers and differentiate them from prognostic ones.","It employs statistical testing and a comprehensive analysis of image feature attribution.","We explore the suitability of deep learning models originally designed for estimating the conditional average treatment effect (CATE) for this task, which previously have been primarily assessed for the precision of CATE estimation, overlooking the evaluation of imaging biomarker discovery.","Our proof-of-concept analysis demonstrates promising results in discovering and validating predictive imaging biomarkers from synthetic outcomes and real-world image datasets."],"url":"http://arxiv.org/abs/2406.02534v1","category":"eess.IV"}
{"created":"2024-06-04 17:54:20","title":"SatSplatYOLO: 3D Gaussian Splatting-based Virtual Object Detection Ensembles for Satellite Feature Recognition","abstract":"On-orbit servicing (OOS), inspection of spacecraft, and active debris removal (ADR). Such missions require precise rendezvous and proximity operations in the vicinity of non-cooperative, possibly unknown, resident space objects. Safety concerns with manned missions and lag times with ground-based control necessitate complete autonomy. In this article, we present an approach for mapping geometries and high-confidence detection of components of unknown, non-cooperative satellites on orbit. We implement accelerated 3D Gaussian splatting to learn a 3D representation of the satellite, render virtual views of the target, and ensemble the YOLOv5 object detector over the virtual views, resulting in reliable, accurate, and precise satellite component detections. The full pipeline capable of running on-board and stand to enable downstream machine intelligence tasks necessary for autonomous guidance, navigation, and control tasks.","sentences":["On-orbit servicing (OOS), inspection of spacecraft, and active debris removal (ADR).","Such missions require precise rendezvous and proximity operations in the vicinity of non-cooperative, possibly unknown, resident space objects.","Safety concerns with manned missions and lag times with ground-based control necessitate complete autonomy.","In this article, we present an approach for mapping geometries and high-confidence detection of components of unknown, non-cooperative satellites on orbit.","We implement accelerated 3D Gaussian splatting to learn a 3D representation of the satellite, render virtual views of the target, and ensemble the YOLOv5 object detector over the virtual views, resulting in reliable, accurate, and precise satellite component detections.","The full pipeline capable of running on-board and stand to enable downstream machine intelligence tasks necessary for autonomous guidance, navigation, and control tasks."],"url":"http://arxiv.org/abs/2406.02533v1","category":"cs.CV"}
{"created":"2024-06-04 17:51:08","title":"ReLUs Are Sufficient for Learning Implicit Neural Representations","abstract":"Motivated by the growing theoretical understanding of neural networks that employ the Rectified Linear Unit (ReLU) as their activation function, we revisit the use of ReLU activation functions for learning implicit neural representations (INRs). Inspired by second order B-spline wavelets, we incorporate a set of simple constraints to the ReLU neurons in each layer of a deep neural network (DNN) to remedy the spectral bias. This in turn enables its use for various INR tasks. Empirically, we demonstrate that, contrary to popular belief, one can learn state-of-the-art INRs based on a DNN composed of only ReLU neurons. Next, by leveraging recent theoretical works which characterize the kinds of functions ReLU neural networks learn, we provide a way to quantify the regularity of the learned function. This offers a principled approach to selecting the hyperparameters in INR architectures. We substantiate our claims through experiments in signal representation, super resolution, and computed tomography, demonstrating the versatility and effectiveness of our method. The code for all experiments can be found at https://github.com/joeshenouda/relu-inrs.","sentences":["Motivated by the growing theoretical understanding of neural networks that employ the Rectified Linear Unit (ReLU) as their activation function, we revisit the use of ReLU activation functions for learning implicit neural representations (INRs).","Inspired by second order B-spline wavelets, we incorporate a set of simple constraints to the ReLU neurons in each layer of a deep neural network (DNN) to remedy the spectral bias.","This in turn enables its use for various INR tasks.","Empirically, we demonstrate that, contrary to popular belief, one can learn state-of-the-art INRs based on a DNN composed of only ReLU neurons.","Next, by leveraging recent theoretical works which characterize the kinds of functions ReLU neural networks learn, we provide a way to quantify the regularity of the learned function.","This offers a principled approach to selecting the hyperparameters in INR architectures.","We substantiate our claims through experiments in signal representation, super resolution, and computed tomography, demonstrating the versatility and effectiveness of our method.","The code for all experiments can be found at https://github.com/joeshenouda/relu-inrs."],"url":"http://arxiv.org/abs/2406.02529v1","category":"eess.IV"}
{"created":"2024-06-04 17:41:31","title":"RoboCasa: Large-Scale Simulation of Everyday Tasks for Generalist Robots","abstract":"Recent advancements in Artificial Intelligence (AI) have largely been propelled by scaling. In Robotics, scaling is hindered by the lack of access to massive robot datasets. We advocate using realistic physical simulation as a means to scale environments, tasks, and datasets for robot learning methods. We present RoboCasa, a large-scale simulation framework for training generalist robots in everyday environments. RoboCasa features realistic and diverse scenes focusing on kitchen environments. We provide thousands of 3D assets across over 150 object categories and dozens of interactable furniture and appliances. We enrich the realism and diversity of our simulation with generative AI tools, such as object assets from text-to-3D models and environment textures from text-to-image models. We design a set of 100 tasks for systematic evaluation, including composite tasks generated by the guidance of large language models. To facilitate learning, we provide high-quality human demonstrations and integrate automated trajectory generation methods to substantially enlarge our datasets with minimal human burden. Our experiments show a clear scaling trend in using synthetically generated robot data for large-scale imitation learning and show great promise in harnessing simulation data in real-world tasks. Videos and open-source code are available at https://robocasa.ai/","sentences":["Recent advancements in Artificial Intelligence (AI) have largely been propelled by scaling.","In Robotics, scaling is hindered by the lack of access to massive robot datasets.","We advocate using realistic physical simulation as a means to scale environments, tasks, and datasets for robot learning methods.","We present RoboCasa, a large-scale simulation framework for training generalist robots in everyday environments.","RoboCasa features realistic and diverse scenes focusing on kitchen environments.","We provide thousands of 3D assets across over 150 object categories and dozens of interactable furniture and appliances.","We enrich the realism and diversity of our simulation with generative AI tools, such as object assets from text-to-3D models and environment textures from text-to-image models.","We design a set of 100 tasks for systematic evaluation, including composite tasks generated by the guidance of large language models.","To facilitate learning, we provide high-quality human demonstrations and integrate automated trajectory generation methods to substantially enlarge our datasets with minimal human burden.","Our experiments show a clear scaling trend in using synthetically generated robot data for large-scale imitation learning and show great promise in harnessing simulation data in real-world tasks.","Videos and open-source code are available at https://robocasa.ai/"],"url":"http://arxiv.org/abs/2406.02523v1","category":"cs.RO"}
{"created":"2024-06-04 17:32:52","title":"V-Express: Conditional Dropout for Progressive Training of Portrait Video Generation","abstract":"In the field of portrait video generation, the use of single images to generate portrait videos has become increasingly prevalent. A common approach involves leveraging generative models to enhance adapters for controlled generation. However, control signals (e.g., text, audio, reference image, pose, depth map, etc.) can vary in strength. Among these, weaker conditions often struggle to be effective due to interference from stronger conditions, posing a challenge in balancing these conditions. In our work on portrait video generation, we identified audio signals as particularly weak, often overshadowed by stronger signals such as facial pose and reference image. However, direct training with weak signals often leads to difficulties in convergence. To address this, we propose V-Express, a simple method that balances different control signals through the progressive training and the conditional dropout operation. Our method gradually enables effective control by weak conditions, thereby achieving generation capabilities that simultaneously take into account the facial pose, reference image, and audio. The experimental results demonstrate that our method can effectively generate portrait videos controlled by audio. Furthermore, a potential solution is provided for the simultaneous and effective use of conditions of varying strengths.","sentences":["In the field of portrait video generation, the use of single images to generate portrait videos has become increasingly prevalent.","A common approach involves leveraging generative models to enhance adapters for controlled generation.","However, control signals (e.g., text, audio, reference image, pose, depth map, etc.) can vary in strength.","Among these, weaker conditions often struggle to be effective due to interference from stronger conditions, posing a challenge in balancing these conditions.","In our work on portrait video generation, we identified audio signals as particularly weak, often overshadowed by stronger signals such as facial pose and reference image.","However, direct training with weak signals often leads to difficulties in convergence.","To address this, we propose V-Express, a simple method that balances different control signals through the progressive training and the conditional dropout operation.","Our method gradually enables effective control by weak conditions, thereby achieving generation capabilities that simultaneously take into account the facial pose, reference image, and audio.","The experimental results demonstrate that our method can effectively generate portrait videos controlled by audio.","Furthermore, a potential solution is provided for the simultaneous and effective use of conditions of varying strengths."],"url":"http://arxiv.org/abs/2406.02511v1","category":"cs.CV"}
{"created":"2024-06-04 17:25:59","title":"Guiding a Diffusion Model with a Bad Version of Itself","abstract":"The primary axes of interest in image-generating diffusion models are image quality, the amount of variation in the results, and how well the results align with a given condition, e.g., a class label or a text prompt. The popular classifier-free guidance approach uses an unconditional model to guide a conditional model, leading to simultaneously better prompt alignment and higher-quality images at the cost of reduced variation. These effects seem inherently entangled, and thus hard to control. We make the surprising observation that it is possible to obtain disentangled control over image quality without compromising the amount of variation by guiding generation using a smaller, less-trained version of the model itself rather than an unconditional model. This leads to significant improvements in ImageNet generation, setting record FIDs of 1.01 for 64x64 and 1.25 for 512x512, using publicly available networks. Furthermore, the method is also applicable to unconditional diffusion models, drastically improving their quality.","sentences":["The primary axes of interest in image-generating diffusion models are image quality, the amount of variation in the results, and how well the results align with a given condition, e.g., a class label or a text prompt.","The popular classifier-free guidance approach uses an unconditional model to guide a conditional model, leading to simultaneously better prompt alignment and higher-quality images at the cost of reduced variation.","These effects seem inherently entangled, and thus hard to control.","We make the surprising observation that it is possible to obtain disentangled control over image quality without compromising the amount of variation by guiding generation using a smaller, less-trained version of the model itself rather than an unconditional model.","This leads to significant improvements in ImageNet generation, setting record FIDs of 1.01 for 64x64 and 1.25 for 512x512, using publicly available networks.","Furthermore, the method is also applicable to unconditional diffusion models, drastically improving their quality."],"url":"http://arxiv.org/abs/2406.02507v1","category":"cs.CV"}
{"created":"2024-06-04 17:18:40","title":"Demystifying the Compression of Mixture-of-Experts Through a Unified Framework","abstract":"Scaling large language models has revolutionized the performance across diverse domains, yet the continual growth in model size poses significant challenges for real-world deployment. The Mixture of Experts (MoE) approach addresses this by dynamically selecting and activating only a subset of experts, significantly reducing computational costs while maintaining high performance. However, MoE introduces potential redundancy (e.g., parameters) and extra costs (e.g., communication overhead). Despite numerous compression techniques developed for mitigating the redundancy in dense models, the compression of MoE remains under-explored. We first bridge this gap with a cutting-edge unified framework that not only seamlessly integrates mainstream compression methods but also helps systematically understand MoE compression. This framework approaches compression from two perspectives: Expert Slimming which compresses individual experts and Expert Trimming which removes structured modules. Within this framework, we explore the optimization space unexplored by existing methods,and further introduce aggressive Expert Trimming techniques, i.e., Layer Drop and Block Drop, to eliminate redundancy at larger scales. Based on these insights,we present a comprehensive recipe to guide practitioners in compressing MoE effectively. Extensive experimental results demonstrate the effectiveness of the compression methods under our framework and the proposed recipe, achieving a 6.05x speedup and only 20.0GB memory usage while maintaining over 92% of performance on Mixtral-8x7B.","sentences":["Scaling large language models has revolutionized the performance across diverse domains, yet the continual growth in model size poses significant challenges for real-world deployment.","The Mixture of Experts (MoE) approach addresses this by dynamically selecting and activating only a subset of experts, significantly reducing computational costs while maintaining high performance.","However, MoE introduces potential redundancy (e.g., parameters) and extra costs (e.g., communication overhead).","Despite numerous compression techniques developed for mitigating the redundancy in dense models, the compression of MoE remains under-explored.","We first bridge this gap with a cutting-edge unified framework that not only seamlessly integrates mainstream compression methods but also helps systematically understand MoE compression.","This framework approaches compression from two perspectives: Expert Slimming which compresses individual experts and Expert Trimming which removes structured modules.","Within this framework, we explore the optimization space unexplored by existing methods,and further introduce aggressive Expert Trimming techniques, i.e., Layer Drop and Block Drop, to eliminate redundancy at larger scales.","Based on these insights,we present a comprehensive recipe to guide practitioners in compressing MoE effectively.","Extensive experimental results demonstrate the effectiveness of the compression methods under our framework and the proposed recipe, achieving a 6.05x speedup and only 20.0GB memory usage while maintaining over 92% of performance on Mixtral-8x7B."],"url":"http://arxiv.org/abs/2406.02500v1","category":"cs.LG"}
{"created":"2024-06-04 17:15:25","title":"Dropout MPC: An Ensemble Neural MPC Approach for Systems with Learned Dynamics","abstract":"Neural networks are lately more and more often being used in the context of data-driven control, as an approximate model of the true system dynamics. Model Predictive Control (MPC) adopts this practise leading to neural MPC strategies. This raises a question of whether the trained neural network has converged and generalized in a way that the learned model encapsulates an accurate approximation of the true dynamic model of the system, thus making it a reliable choice for model-based control, especially for disturbed and uncertain systems. To tackle that, we propose Dropout MPC, a novel sampling-based ensemble neural MPC algorithm that employs the Monte-Carlo dropout technique on the learned system model. The closed loop is based on an ensemble of predictive controllers, that are used simultaneously at each time-step for trajectory optimization. Each member of the ensemble influences the control input, based on a weighted voting scheme, thus by employing different realizations of the learned system dynamics, neural control becomes more reliable by design. An additional strength of the method is that it offers by design a way to estimate future uncertainty, leading to cautious control. While the method aims in general at uncertain systems with complex dynamics, where models derived from first principles are hard to infer, to showcase the application we utilize data gathered in the laboratory from a real mobile manipulator and employ the proposed algorithm for the navigation of the robot in simulation.","sentences":["Neural networks are lately more and more often being used in the context of data-driven control, as an approximate model of the true system dynamics.","Model Predictive Control (MPC) adopts this practise leading to neural MPC strategies.","This raises a question of whether the trained neural network has converged and generalized in a way that the learned model encapsulates an accurate approximation of the true dynamic model of the system, thus making it a reliable choice for model-based control, especially for disturbed and uncertain systems.","To tackle that, we propose Dropout MPC, a novel sampling-based ensemble neural MPC algorithm that employs the Monte-Carlo dropout technique on the learned system model.","The closed loop is based on an ensemble of predictive controllers, that are used simultaneously at each time-step for trajectory optimization.","Each member of the ensemble influences the control input, based on a weighted voting scheme, thus by employing different realizations of the learned system dynamics, neural control becomes more reliable by design.","An additional strength of the method is that it offers by design a way to estimate future uncertainty, leading to cautious control.","While the method aims in general at uncertain systems with complex dynamics, where models derived from first principles are hard to infer, to showcase the application we utilize data gathered in the laboratory from a real mobile manipulator and employ the proposed algorithm for the navigation of the robot in simulation."],"url":"http://arxiv.org/abs/2406.02497v1","category":"eess.SY"}
{"created":"2024-06-04 17:14:31","title":"Kolmogorov-Arnold Networks for Time Series: Bridging Predictive Power and Interpretability","abstract":"Kolmogorov-Arnold Networks (KAN) is a groundbreaking model recently proposed by the MIT team, representing a revolutionary approach with the potential to be a game-changer in the field. This innovative concept has rapidly garnered worldwide interest within the AI community. Inspired by the Kolmogorov-Arnold representation theorem, KAN utilizes spline-parametrized univariate functions in place of traditional linear weights, enabling them to dynamically learn activation patterns and significantly enhancing interpretability. In this paper, we explore the application of KAN to time series forecasting and propose two variants: T-KAN and MT-KAN. T-KAN is designed to detect concept drift within time series and can explain the nonlinear relationships between predictions and previous time steps through symbolic regression, making it highly interpretable in dynamically changing environments. MT-KAN, on the other hand, improves predictive performance by effectively uncovering and leveraging the complex relationships among variables in multivariate time series. Experiments validate the effectiveness of these approaches, demonstrating that T-KAN and MT-KAN significantly outperform traditional methods in time series forecasting tasks, not only enhancing predictive accuracy but also improving model interpretability. This research opens new avenues for adaptive forecasting models, highlighting the potential of KAN as a powerful and interpretable tool in predictive analytics.","sentences":["Kolmogorov-Arnold Networks (KAN) is a groundbreaking model recently proposed by the MIT team, representing a revolutionary approach with the potential to be a game-changer in the field.","This innovative concept has rapidly garnered worldwide interest within the AI community.","Inspired by the Kolmogorov-Arnold representation theorem, KAN utilizes spline-parametrized univariate functions in place of traditional linear weights, enabling them to dynamically learn activation patterns and significantly enhancing interpretability.","In this paper, we explore the application of KAN to time series forecasting and propose two variants: T-KAN and MT-KAN.","T-KAN is designed to detect concept drift within time series and can explain the nonlinear relationships between predictions and previous time steps through symbolic regression, making it highly interpretable in dynamically changing environments.","MT-KAN, on the other hand, improves predictive performance by effectively uncovering and leveraging the complex relationships among variables in multivariate time series.","Experiments validate the effectiveness of these approaches, demonstrating that T-KAN and MT-KAN significantly outperform traditional methods in time series forecasting tasks, not only enhancing predictive accuracy but also improving model interpretability.","This research opens new avenues for adaptive forecasting models, highlighting the potential of KAN as a powerful and interpretable tool in predictive analytics."],"url":"http://arxiv.org/abs/2406.02496v1","category":"cs.LG"}
{"created":"2024-06-04 16:51:42","title":"How Do Neural Spoofing Countermeasures Detect Partially Spoofed Audio?","abstract":"Partially manipulating a sentence can greatly change its meaning. Recent work shows that countermeasures (CMs) trained on partially spoofed audio can effectively detect such spoofing. However, the current understanding of the decision-making process of CMs is limited. We utilize Grad-CAM and introduce a quantitative analysis metric to interpret CMs' decisions. We find that CMs prioritize the artifacts of transition regions created when concatenating bona fide and spoofed audio. This focus differs from that of CMs trained on fully spoofed audio, which concentrate on the pattern differences between bona fide and spoofed parts. Our further investigation explains the varying nature of CMs' focus while making correct or incorrect predictions. These insights provide a basis for the design of CM models and the creation of datasets. Moreover, this work lays a foundation of interpretability in the field of partial spoofed audio detection that has not been well explored previously.","sentences":["Partially manipulating a sentence can greatly change its meaning.","Recent work shows that countermeasures (CMs) trained on partially spoofed audio can effectively detect such spoofing.","However, the current understanding of the decision-making process of CMs is limited.","We utilize Grad-CAM and introduce a quantitative analysis metric to interpret CMs' decisions.","We find that CMs prioritize the artifacts of transition regions created when concatenating bona fide and spoofed audio.","This focus differs from that of CMs trained on fully spoofed audio, which concentrate on the pattern differences between bona fide and spoofed parts.","Our further investigation explains the varying nature of CMs' focus while making correct or incorrect predictions.","These insights provide a basis for the design of CM models and the creation of datasets.","Moreover, this work lays a foundation of interpretability in the field of partial spoofed audio detection that has not been well explored previously."],"url":"http://arxiv.org/abs/2406.02483v1","category":"eess.AS"}
{"created":"2024-06-04 16:40:55","title":"Meta-Designing Quantum Experiments with Language Models","abstract":"Artificial Intelligence (AI) has the potential to significantly advance scientific discovery by finding solutions beyond human capabilities. However, these super-human solutions are often unintuitive and require considerable effort to uncover underlying principles, if possible at all. Here, we show how a code-generating language model trained on synthetic data can not only find solutions to specific problems but can create meta-solutions, which solve an entire class of problems in one shot and simultaneously offer insight into the underlying design principles. Specifically, for the design of new quantum physics experiments, our sequence-to-sequence transformer architecture generates interpretable Python code that describes experimental blueprints for a whole class of quantum systems. We discover general and previously unknown design rules for infinitely large classes of quantum states. The ability to automatically generate generalized patterns in readable computer code is a crucial step toward machines that help discover new scientific understanding -- one of the central aims of physics.","sentences":["Artificial Intelligence (AI) has the potential to significantly advance scientific discovery by finding solutions beyond human capabilities.","However, these super-human solutions are often unintuitive and require considerable effort to uncover underlying principles, if possible at all.","Here, we show how a code-generating language model trained on synthetic data can not only find solutions to specific problems but can create meta-solutions, which solve an entire class of problems in one shot and simultaneously offer insight into the underlying design principles.","Specifically, for the design of new quantum physics experiments, our sequence-to-sequence transformer architecture generates interpretable Python code that describes experimental blueprints for a whole class of quantum systems.","We discover general and previously unknown design rules for infinitely large classes of quantum states.","The ability to automatically generate generalized patterns in readable computer code is a crucial step toward machines that help discover new scientific understanding -- one of the central aims of physics."],"url":"http://arxiv.org/abs/2406.02470v1","category":"quant-ph"}
{"created":"2024-06-04 16:34:17","title":"An Empirical Study into Clustering of Unseen Datasets with Self-Supervised Encoders","abstract":"Can pretrained models generalize to new datasets without any retraining? We deploy pretrained image models on datasets they were not trained for, and investigate whether their embeddings form meaningful clusters. Our suite of benchmarking experiments use encoders pretrained solely on ImageNet-1k with either supervised or self-supervised training techniques, deployed on image datasets that were not seen during training, and clustered with conventional clustering algorithms. This evaluation provides new insights into the embeddings of self-supervised models, which prioritize different features to supervised models. Supervised encoders typically offer more utility than SSL encoders within the training domain, and vice-versa far outside of it, however, fine-tuned encoders demonstrate the opposite trend. Clustering provides a way to evaluate the utility of self-supervised learned representations orthogonal to existing methods such as kNN. Additionally, we find the silhouette score when measured in a UMAP-reduced space is highly correlated with clustering performance, and can therefore be used as a proxy for clustering performance on data with no ground truth labels. Our code implementation is available at \\url{https://github.com/scottclowe/zs-ssl-clustering/}.","sentences":["Can pretrained models generalize to new datasets without any retraining?","We deploy pretrained image models on datasets they were not trained for, and investigate whether their embeddings form meaningful clusters.","Our suite of benchmarking experiments use encoders pretrained solely on ImageNet-1k with either supervised or self-supervised training techniques, deployed on image datasets that were not seen during training, and clustered with conventional clustering algorithms.","This evaluation provides new insights into the embeddings of self-supervised models, which prioritize different features to supervised models.","Supervised encoders typically offer more utility than SSL encoders within the training domain, and vice-versa far outside of it, however, fine-tuned encoders demonstrate the opposite trend.","Clustering provides a way to evaluate the utility of self-supervised learned representations orthogonal to existing methods such as kNN.","Additionally, we find the silhouette score when measured in a UMAP-reduced space is highly correlated with clustering performance, and can therefore be used as a proxy for clustering performance on data with no ground truth labels.","Our code implementation is available at \\url{https://github.com/scottclowe/zs-ssl-clustering/}."],"url":"http://arxiv.org/abs/2406.02465v1","category":"cs.LG"}
{"created":"2024-06-04 16:31:43","title":"Meta-Learners for Partially-Identified Treatment Effects Across Multiple Environments","abstract":"Estimating the conditional average treatment effect (CATE) from observational data is relevant for many applications such as personalized medicine. Here, we focus on the widespread setting where the observational data come from multiple environments, such as different hospitals, physicians, or countries. Furthermore, we allow for violations of standard causal assumptions, namely, overlap within the environments and unconfoundedness. To this end, we move away from point identification and focus on partial identification. Specifically, we show that current assumptions from the literature on multiple environments allow us to interpret the environment as an instrumental variable (IV). This allows us to adapt bounds from the IV literature for partial identification of CATE by leveraging treatment assignment mechanisms across environments. Then, we propose different model-agnostic learners (so-called meta-learners) to estimate the bounds that can be used in combination with arbitrary machine learning models. We further demonstrate the effectiveness of our meta-learners across various experiments using both simulated and real-world data. Finally, we discuss the applicability of our meta-learners to partial identification in instrumental variable settings, such as randomized controlled trials with non-compliance.","sentences":["Estimating the conditional average treatment effect (CATE) from observational data is relevant for many applications such as personalized medicine.","Here, we focus on the widespread setting where the observational data come from multiple environments, such as different hospitals, physicians, or countries.","Furthermore, we allow for violations of standard causal assumptions, namely, overlap within the environments and unconfoundedness.","To this end, we move away from point identification and focus on partial identification.","Specifically, we show that current assumptions from the literature on multiple environments allow us to interpret the environment as an instrumental variable (IV).","This allows us to adapt bounds from the IV literature for partial identification of CATE by leveraging treatment assignment mechanisms across environments.","Then, we propose different model-agnostic learners (so-called meta-learners) to estimate the bounds that can be used in combination with arbitrary machine learning models.","We further demonstrate the effectiveness of our meta-learners across various experiments using both simulated and real-world data.","Finally, we discuss the applicability of our meta-learners to partial identification in instrumental variable settings, such as randomized controlled trials with non-compliance."],"url":"http://arxiv.org/abs/2406.02464v1","category":"cs.LG"}
{"created":"2024-06-04 16:31:19","title":"Click Without Compromise: Online Advertising Measurement via Per User Differential Privacy","abstract":"Online advertising is a cornerstone of the Internet ecosystem, with advertising measurement playing a crucial role in optimizing efficiency. Ad measurement entails attributing desired behaviors, such as purchases, to ad exposures across various platforms, necessitating the collection of user activities across these platforms. As this practice faces increasing restrictions due to rising privacy concerns, safeguarding user privacy in this context is imperative. Our work is the first to formulate the real-world challenge of advertising measurement systems with real-time reporting of streaming data in advertising campaigns. We introduce Ads-BPC, a novel user-level differential privacy protection scheme for advertising measurement results. This approach optimizes global noise power and results in a non-identically distributed noise distribution that preserves differential privacy while enhancing measurement accuracy. Through experiments on both real-world advertising campaigns and synthetic datasets, Ads-BPC achieves a 25% to 50% increase in accuracy over existing streaming DP mechanisms applied to advertising measurement. This highlights our method's effectiveness in achieving superior accuracy alongside a formal privacy guarantee, thereby advancing the state-of-the-art in privacy-preserving advertising measurement.","sentences":["Online advertising is a cornerstone of the Internet ecosystem, with advertising measurement playing a crucial role in optimizing efficiency.","Ad measurement entails attributing desired behaviors, such as purchases, to ad exposures across various platforms, necessitating the collection of user activities across these platforms.","As this practice faces increasing restrictions due to rising privacy concerns, safeguarding user privacy in this context is imperative.","Our work is the first to formulate the real-world challenge of advertising measurement systems with real-time reporting of streaming data in advertising campaigns.","We introduce Ads-BPC, a novel user-level differential privacy protection scheme for advertising measurement results.","This approach optimizes global noise power and results in a non-identically distributed noise distribution that preserves differential privacy while enhancing measurement accuracy.","Through experiments on both real-world advertising campaigns and synthetic datasets, Ads-BPC achieves a 25% to 50% increase in accuracy over existing streaming DP mechanisms applied to advertising measurement.","This highlights our method's effectiveness in achieving superior accuracy alongside a formal privacy guarantee, thereby advancing the state-of-the-art in privacy-preserving advertising measurement."],"url":"http://arxiv.org/abs/2406.02463v1","category":"cs.CR"}
{"created":"2024-06-04 16:30:37","title":"Learning Image Priors through Patch-based Diffusion Models for Solving Inverse Problems","abstract":"Diffusion models can learn strong image priors from underlying data distribution and use them to solve inverse problems, but the training process is computationally expensive and requires lots of data. Such bottlenecks prevent most existing works from being feasible for high-dimensional and high-resolution data such as 3D images. This paper proposes a method to learn an efficient data prior for the entire image by training diffusion models only on patches of images. Specifically, we propose a patch-based position-aware diffusion inverse solver, called PaDIS, where we obtain the score function of the whole image through scores of patches and their positional encoding and utilize this as the prior for solving inverse problems. First of all, we show that this diffusion model achieves an improved memory efficiency and data efficiency while still maintaining the capability to generate entire images via positional encoding. Additionally, the proposed PaDIS model is highly flexible and can be plugged in with different diffusion inverse solvers (DIS). We demonstrate that the proposed PaDIS approach enables solving various inverse problems in both natural and medical image domains, including CT reconstruction, deblurring, and superresolution, given only patch-based priors. Notably, PaDIS outperforms previous DIS methods trained on entire image priors in the case of limited training data, demonstrating the data efficiency of our proposed approach by learning patch-based prior.","sentences":["Diffusion models can learn strong image priors from underlying data distribution and use them to solve inverse problems, but the training process is computationally expensive and requires lots of data.","Such bottlenecks prevent most existing works from being feasible for high-dimensional and high-resolution data such as 3D images.","This paper proposes a method to learn an efficient data prior for the entire image by training diffusion models only on patches of images.","Specifically, we propose a patch-based position-aware diffusion inverse solver, called PaDIS, where we obtain the score function of the whole image through scores of patches and their positional encoding and utilize this as the prior for solving inverse problems.","First of all, we show that this diffusion model achieves an improved memory efficiency and data efficiency while still maintaining the capability to generate entire images via positional encoding.","Additionally, the proposed PaDIS model is highly flexible and can be plugged in with different diffusion inverse solvers (DIS).","We demonstrate that the proposed PaDIS approach enables solving various inverse problems in both natural and medical image domains, including CT reconstruction, deblurring, and superresolution, given only patch-based priors.","Notably, PaDIS outperforms previous DIS methods trained on entire image priors in the case of limited training data, demonstrating the data efficiency of our proposed approach by learning patch-based prior."],"url":"http://arxiv.org/abs/2406.02462v1","category":"cs.CV"}
{"created":"2024-06-04 16:21:14","title":"Offline Bayesian Aleatoric and Epistemic Uncertainty Quantification and Posterior Value Optimisation in Finite-State MDPs","abstract":"We address the challenge of quantifying Bayesian uncertainty and incorporating it in offline use cases of finite-state Markov Decision Processes (MDPs) with unknown dynamics. Our approach provides a principled method to disentangle epistemic and aleatoric uncertainty, and a novel technique to find policies that optimise Bayesian posterior expected value without relying on strong assumptions about the MDP's posterior distribution. First, we utilise standard Bayesian reinforcement learning methods to capture the posterior uncertainty in MDP parameters based on available data. We then analytically compute the first two moments of the return distribution across posterior samples and apply the law of total variance to disentangle aleatoric and epistemic uncertainties. To find policies that maximise posterior expected value, we leverage the closed-form expression for value as a function of policy. This allows us to propose a stochastic gradient-based approach for solving the problem. We illustrate the uncertainty quantification and Bayesian posterior value optimisation performance of our agent in simple, interpretable gridworlds and validate it through ground-truth evaluations on synthetic MDPs. Finally, we highlight the real-world impact and computational scalability of our method by applying it to the AI Clinician problem, which recommends treatment for patients in intensive care units and has emerged as a key use case of finite-state MDPs with offline data. We discuss the challenges that arise with Bayesian modelling of larger scale MDPs while demonstrating the potential to apply our methods rooted in Bayesian decision theory into the real world. We make our code available at https://github.com/filippovaldettaro/finite-state-mdps .","sentences":["We address the challenge of quantifying Bayesian uncertainty and incorporating it in offline use cases of finite-state Markov Decision Processes (MDPs) with unknown dynamics.","Our approach provides a principled method to disentangle epistemic and aleatoric uncertainty, and a novel technique to find policies that optimise Bayesian posterior expected value without relying on strong assumptions about the MDP's posterior distribution.","First, we utilise standard Bayesian reinforcement learning methods to capture the posterior uncertainty in MDP parameters based on available data.","We then analytically compute the first two moments of the return distribution across posterior samples and apply the law of total variance to disentangle aleatoric and epistemic uncertainties.","To find policies that maximise posterior expected value, we leverage the closed-form expression for value as a function of policy.","This allows us to propose a stochastic gradient-based approach for solving the problem.","We illustrate the uncertainty quantification and Bayesian posterior value optimisation performance of our agent in simple, interpretable gridworlds and validate it through ground-truth evaluations on synthetic MDPs.","Finally, we highlight the real-world impact and computational scalability of our method by applying it to the AI Clinician problem, which recommends treatment for patients in intensive care units and has emerged as a key use case of finite-state MDPs with offline data.","We discuss the challenges that arise with Bayesian modelling of larger scale MDPs while demonstrating the potential to apply our methods rooted in Bayesian decision theory into the real world.","We make our code available at https://github.com/filippovaldettaro/finite-state-mdps ."],"url":"http://arxiv.org/abs/2406.02456v1","category":"cs.LG"}
{"created":"2024-06-04 16:14:55","title":"A Generalized Apprenticeship Learning Framework for Modeling Heterogeneous Student Pedagogical Strategies","abstract":"A key challenge in e-learning environments like Intelligent Tutoring Systems (ITSs) is to induce effective pedagogical policies efficiently. While Deep Reinforcement Learning (DRL) often suffers from sample inefficiency and reward function design difficulty, Apprenticeship Learning(AL) algorithms can overcome them. However, most AL algorithms can not handle heterogeneity as they assume all demonstrations are generated with a homogeneous policy driven by a single reward function. Still, some AL algorithms which consider heterogeneity, often can not generalize to large continuous state space and only work with discrete states. In this paper, we propose an expectation-maximization(EM)-EDM, a general AL framework to induce effective pedagogical policies from given optimal or near-optimal demonstrations, which are assumed to be driven by heterogeneous reward functions. We compare the effectiveness of the policies induced by our proposed EM-EDM against four AL-based baselines and two policies induced by DRL on two different but related tasks that involve pedagogical action prediction. Our overall results showed that, for both tasks, EM-EDM outperforms the four AL baselines across all performance metrics and the two DRL baselines. This suggests that EM-EDM can effectively model complex student pedagogical decision-making processes through the ability to manage a large, continuous state space and adapt to handle diverse and heterogeneous reward functions with very few given demonstrations.","sentences":["A key challenge in e-learning environments like Intelligent Tutoring Systems (ITSs) is to induce effective pedagogical policies efficiently.","While Deep Reinforcement Learning (DRL) often suffers from sample inefficiency and reward function design difficulty, Apprenticeship Learning(AL) algorithms can overcome them.","However, most AL algorithms can not handle heterogeneity as they assume all demonstrations are generated with a homogeneous policy driven by a single reward function.","Still, some AL algorithms which consider heterogeneity, often can not generalize to large continuous state space and only work with discrete states.","In this paper, we propose an expectation-maximization(EM)-EDM, a general AL framework to induce effective pedagogical policies from given optimal or near-optimal demonstrations, which are assumed to be driven by heterogeneous reward functions.","We compare the effectiveness of the policies induced by our proposed EM-EDM against four AL-based baselines and two policies induced by DRL on two different but related tasks that involve pedagogical action prediction.","Our overall results showed that, for both tasks, EM-EDM outperforms the four AL baselines across all performance metrics and the two DRL baselines.","This suggests that EM-EDM can effectively model complex student pedagogical decision-making processes through the ability to manage a large, continuous state space and adapt to handle diverse and heterogeneous reward functions with very few given demonstrations."],"url":"http://arxiv.org/abs/2406.02450v1","category":"cs.LG"}
{"created":"2024-06-04 16:14:00","title":"Representations as Language: An Information-Theoretic Framework for Interpretability","abstract":"Large scale neural models show impressive performance across a wide array of linguistic tasks. Despite this they remain, largely, black-boxes - inducing vector-representations of their input that prove difficult to interpret. This limits our ability to understand what they learn, and when the learn it, or describe what kinds of representations generalise well out of distribution. To address this we introduce a novel approach to interpretability that looks at the mapping a model learns from sentences to representations as a kind of language in its own right. In doing so we introduce a set of information-theoretic measures that quantify how structured a model's representations are with respect to its input, and when during training that structure arises. Our measures are fast to compute, grounded in linguistic theory, and can predict which models will generalise best based on their representations. We use these measures to describe two distinct phases of training a transformer: an initial phase of in-distribution learning which reduces task loss, then a second stage where representations becoming robust to noise. Generalisation performance begins to increase during this second phase, drawing a link between generalisation and robustness to noise. Finally we look at how model size affects the structure of the representational space, showing that larger models ultimately compress their representations more than their smaller counterparts.","sentences":["Large scale neural models show impressive performance across a wide array of linguistic tasks.","Despite this they remain, largely, black-boxes - inducing vector-representations of their input that prove difficult to interpret.","This limits our ability to understand what they learn, and when the learn it, or describe what kinds of representations generalise well out of distribution.","To address this we introduce a novel approach to interpretability that looks at the mapping a model learns from sentences to representations as a kind of language in its own right.","In doing so we introduce a set of information-theoretic measures that quantify how structured a model's representations are with respect to its input, and when during training that structure arises.","Our measures are fast to compute, grounded in linguistic theory, and can predict which models will generalise best based on their representations.","We use these measures to describe two distinct phases of training a transformer: an initial phase of in-distribution learning which reduces task loss, then a second stage where representations becoming robust to noise.","Generalisation performance begins to increase during this second phase, drawing a link between generalisation and robustness to noise.","Finally we look at how model size affects the structure of the representational space, showing that larger models ultimately compress their representations more than their smaller counterparts."],"url":"http://arxiv.org/abs/2406.02449v1","category":"cs.CL"}
{"created":"2024-06-04 16:06:51","title":"Explainable Deep Learning Analysis for Raga Identification in Indian Art Music","abstract":"The task of Raga Identification is a very popular research problem in Music Information Retrieval. Few studies that have explored this task employed various approaches, such as signal processing, Machine Learning (ML) methods, and more recently Deep Learning (DL) based methods. However, a key question remains unanswered in all of these works: do these ML/DL methods learn and interpret Ragas in a manner similar to human experts? Besides, a significant roadblock in this research is the unavailability of ample supply of rich, labeled datasets, which drives these ML/DL based methods. In this paper, we introduce \"Prasarbharti Indian Music\" version-1 (PIM-v1), a novel dataset comprising of 191 hours of meticulously labeled Hindustani Classical Music (HCM) recordings, which is the largest labeled dataset for HCM recordings to the best of our knowledge. Our approach involves conducting ablation studies to find the benchmark classification model for Automatic Raga Identification (ARI) using PIM-v1 dataset. We achieve a chunk-wise f1-score of 0.89 for a subset of 12 Raga classes. Subsequently, we employ model explainability techniques to evaluate the classifier's predictions, aiming to ascertain whether they align with human understanding of Ragas or are driven by arbitrary patterns. We validate the correctness of model's predictions by comparing the explanations given by two ExAI models with human expert annotations. Following this, we analyze explanations for individual test examples to understand the role of regions highlighted by explanations in correct or incorrect predictions made by the model.","sentences":["The task of Raga Identification is a very popular research problem in Music Information Retrieval.","Few studies that have explored this task employed various approaches, such as signal processing, Machine Learning (ML) methods, and more recently Deep Learning (DL) based methods.","However, a key question remains unanswered in all of these works: do these ML/DL methods learn and interpret Ragas in a manner similar to human experts?","Besides, a significant roadblock in this research is the unavailability of ample supply of rich, labeled datasets, which drives these ML/DL based methods.","In this paper, we introduce \"Prasarbharti Indian Music\" version-1 (PIM-v1), a novel dataset comprising of 191 hours of meticulously labeled Hindustani Classical Music (HCM) recordings, which is the largest labeled dataset for HCM recordings to the best of our knowledge.","Our approach involves conducting ablation studies to find the benchmark classification model for Automatic Raga Identification (ARI) using PIM-v1 dataset.","We achieve a chunk-wise f1-score of 0.89 for a subset of 12 Raga classes.","Subsequently, we employ model explainability techniques to evaluate the classifier's predictions, aiming to ascertain whether they align with human understanding of Ragas or are driven by arbitrary patterns.","We validate the correctness of model's predictions by comparing the explanations given by two ExAI models with human expert annotations.","Following this, we analyze explanations for individual test examples to understand the role of regions highlighted by explanations in correct or incorrect predictions made by the model."],"url":"http://arxiv.org/abs/2406.02443v1","category":"eess.AS"}
{"created":"2024-06-04 16:01:26","title":"The Multi-Commodity Flow Problem with Outsourcing Decisions","abstract":"We address a new prize-collecting problem of routing commodities in a given network with hub and non-hub nodes, in which the service of the non-hub nodes will be outsourced to third-party carriers. The problem is modeled as a Stackelberg game: there is a major firm (leader) that decides to serve a subset of commodities. The leader aims to outsource first and third legs of transportation services to smaller carriers (who act as followers) by allocating at most one carrier to each non-hub node. The carriers try to maximize their own profits, which are influenced by the leader's offers. The goal of the leader is to determine the optimal outsourcing fees, along with the allocation of carriers to the non-hub nodes, so that the profit from the routed commodities is maximized. The optimal response of the followers must be taken into account, as the followers might refuse to serve some legs in case they are negative or do not maximize their profit. We also study two alternative settings: one in which the outsourcing fees are fixed, and the other one in which the carriers accept any offer, as long as the resulting profit is non-negative. We prove that the set of possible outsourcing fees can be discretized and formulate the problem as a single-level mixed-integer nonlinear program. For all considered problem variants, we prove NP-hardness and propose and computationally investigate several MIP formulations. We study the computational scalability of these MIP formulations and analyze solutions obtained by varying the reservation prices of the carriers. Finally, by comparing the introduced problem variants, we derive some interesting managerial insights.","sentences":["We address a new prize-collecting problem of routing commodities in a given network with hub and non-hub nodes, in which the service of the non-hub nodes will be outsourced to third-party carriers.","The problem is modeled as a Stackelberg game: there is a major firm (leader) that decides to serve a subset of commodities.","The leader aims to outsource first and third legs of transportation services to smaller carriers (who act as followers) by allocating at most one carrier to each non-hub node.","The carriers try to maximize their own profits, which are influenced by the leader's offers.","The goal of the leader is to determine the optimal outsourcing fees, along with the allocation of carriers to the non-hub nodes, so that the profit from the routed commodities is maximized.","The optimal response of the followers must be taken into account, as the followers might refuse to serve some legs in case they are negative or do not maximize their profit.","We also study two alternative settings: one in which the outsourcing fees are fixed, and the other one in which the carriers accept any offer, as long as the resulting profit is non-negative.","We prove that the set of possible outsourcing fees can be discretized and formulate the problem as a single-level mixed-integer nonlinear program.","For all considered problem variants, we prove NP-hardness and propose and computationally investigate several MIP formulations.","We study the computational scalability of these MIP formulations and analyze solutions obtained by varying the reservation prices of the carriers.","Finally, by comparing the introduced problem variants, we derive some interesting managerial insights."],"url":"http://arxiv.org/abs/2406.02439v1","category":"math.OC"}
{"created":"2024-06-04 16:00:18","title":"CtrSVDD: A Benchmark Dataset and Baseline Analysis for Controlled Singing Voice Deepfake Detection","abstract":"Recent singing voice synthesis and conversion advancements necessitate robust singing voice deepfake detection (SVDD) models. Current SVDD datasets face challenges due to limited controllability, diversity in deepfake methods, and licensing restrictions. Addressing these gaps, we introduce CtrSVDD, a large-scale, diverse collection of bonafide and deepfake singing vocals. These vocals are synthesized using state-of-the-art methods from publicly accessible singing voice datasets. CtrSVDD includes 47.64 hours of bonafide and 260.34 hours of deepfake singing vocals, spanning 14 deepfake methods and involving 164 singer identities. We also present a baseline system with flexible front-end features, evaluated against a structured train/dev/eval split. The experiments show the importance of feature selection and highlight a need for generalization towards deepfake methods that deviate further from training distribution. The CtrSVDD dataset and baselines are publicly accessible.","sentences":["Recent singing voice synthesis and conversion advancements necessitate robust singing voice deepfake detection (SVDD) models.","Current SVDD datasets face challenges due to limited controllability, diversity in deepfake methods, and licensing restrictions.","Addressing these gaps, we introduce CtrSVDD, a large-scale, diverse collection of bonafide and deepfake singing vocals.","These vocals are synthesized using state-of-the-art methods from publicly accessible singing voice datasets.","CtrSVDD includes 47.64 hours of bonafide and 260.34 hours of deepfake singing vocals, spanning 14 deepfake methods and involving 164 singer identities.","We also present a baseline system with flexible front-end features, evaluated against a structured train/dev/eval split.","The experiments show the importance of feature selection and highlight a need for generalization towards deepfake methods that deviate further from training distribution.","The CtrSVDD dataset and baselines are publicly accessible."],"url":"http://arxiv.org/abs/2406.02438v1","category":"eess.AS"}
{"created":"2024-06-04 15:59:36","title":"Algorithmic Collusion in Dynamic Pricing with Deep Reinforcement Learning","abstract":"Nowadays, a significant share of the Business-to-Consumer sector is based on online platforms like Amazon and Alibaba and uses Artificial Intelligence for pricing strategies. This has sparked debate on whether pricing algorithms may tacitly collude to set supra-competitive prices without being explicitly designed to do so. Our study addresses these concerns by examining the risk of collusion when Reinforcement Learning algorithms are used to decide on pricing strategies in competitive markets. Prior research in this field focused on Tabular Q-learning (TQL) and led to opposing views on whether learning-based algorithms can lead to supra-competitive prices. Our work contributes to this ongoing discussion by providing a more nuanced numerical study that goes beyond TQL by additionally capturing off- and on-policy Deep Reinforcement Learning (DRL) algorithms. We study multiple Bertrand oligopoly variants and show that algorithmic collusion depends on the algorithm used. In our experiments, TQL exhibits higher collusion and price dispersion phenomena compared to DRL algorithms. We show that the severity of collusion depends not only on the algorithm used but also on the characteristics of the market environment. We further find that Proximal Policy Optimization appears to be less sensitive to collusive outcomes compared to other state-of-the-art DRL algorithms.","sentences":["Nowadays, a significant share of the Business-to-Consumer sector is based on online platforms like Amazon and Alibaba and uses Artificial Intelligence for pricing strategies.","This has sparked debate on whether pricing algorithms may tacitly collude to set supra-competitive prices without being explicitly designed to do so.","Our study addresses these concerns by examining the risk of collusion when Reinforcement Learning algorithms are used to decide on pricing strategies in competitive markets.","Prior research in this field focused on Tabular Q-learning (TQL) and led to opposing views on whether learning-based algorithms can lead to supra-competitive prices.","Our work contributes to this ongoing discussion by providing a more nuanced numerical study that goes beyond TQL by additionally capturing off- and on-policy Deep Reinforcement Learning (DRL) algorithms.","We study multiple Bertrand oligopoly variants and show that algorithmic collusion depends on the algorithm used.","In our experiments, TQL exhibits higher collusion and price dispersion phenomena compared to DRL algorithms.","We show that the severity of collusion depends not only on the algorithm used but also on the characteristics of the market environment.","We further find that Proximal Policy Optimization appears to be less sensitive to collusive outcomes compared to other state-of-the-art DRL algorithms."],"url":"http://arxiv.org/abs/2406.02437v1","category":"econ.GN"}
{"created":"2024-06-04 15:44:25","title":"CoNav: A Benchmark for Human-Centered Collaborative Navigation","abstract":"Human-robot collaboration, in which the robot intelligently assists the human with the upcoming task, is an appealing objective. To achieve this goal, the agent needs to be equipped with a fundamental collaborative navigation ability, where the agent should reason human intention by observing human activities and then navigate to the human's intended destination in advance of the human. However, this vital ability has not been well studied in previous literature. To fill this gap, we propose a collaborative navigation (CoNav) benchmark. Our CoNav tackles the critical challenge of constructing a 3D navigation environment with realistic and diverse human activities. To achieve this, we design a novel LLM-based humanoid animation generation framework, which is conditioned on both text descriptions and environmental context. The generated humanoid trajectory obeys the environmental context and can be easily integrated into popular simulators. We empirically find that the existing navigation methods struggle in CoNav task since they neglect the perception of human intention. To solve this problem, we propose an intention-aware agent for reasoning both long-term and short-term human intention. The agent predicts navigation action based on the predicted intention and panoramic observation. The emergent agent behavior including observing humans, avoiding human collision, and navigation reveals the efficiency of the proposed datasets and agents.","sentences":["Human-robot collaboration, in which the robot intelligently assists the human with the upcoming task, is an appealing objective.","To achieve this goal, the agent needs to be equipped with a fundamental collaborative navigation ability, where the agent should reason human intention by observing human activities and then navigate to the human's intended destination in advance of the human.","However, this vital ability has not been well studied in previous literature.","To fill this gap, we propose a collaborative navigation (CoNav) benchmark.","Our CoNav tackles the critical challenge of constructing a 3D navigation environment with realistic and diverse human activities.","To achieve this, we design a novel LLM-based humanoid animation generation framework, which is conditioned on both text descriptions and environmental context.","The generated humanoid trajectory obeys the environmental context and can be easily integrated into popular simulators.","We empirically find that the existing navigation methods struggle in CoNav task since they neglect the perception of human intention.","To solve this problem, we propose an intention-aware agent for reasoning both long-term and short-term human intention.","The agent predicts navigation action based on the predicted intention and panoramic observation.","The emergent agent behavior including observing humans, avoiding human collision, and navigation reveals the efficiency of the proposed datasets and agents."],"url":"http://arxiv.org/abs/2406.02425v1","category":"cs.CV"}
{"created":"2024-06-04 15:17:37","title":"WE-GS: An In-the-wild Efficient 3D Gaussian Representation for Unconstrained Photo Collections","abstract":"Novel View Synthesis (NVS) from unconstrained photo collections is challenging in computer graphics. Recently, 3D Gaussian Splatting (3DGS) has shown promise for photorealistic and real-time NVS of static scenes. Building on 3DGS, we propose an efficient point-based differentiable rendering framework for scene reconstruction from photo collections. Our key innovation is a residual-based spherical harmonic coefficients transfer module that adapts 3DGS to varying lighting conditions and photometric post-processing. This lightweight module can be pre-computed and ensures efficient gradient propagation from rendered images to 3D Gaussian attributes. Additionally, we observe that the appearance encoder and the transient mask predictor, the two most critical parts of NVS from unconstrained photo collections, can be mutually beneficial. We introduce a plug-and-play lightweight spatial attention module to simultaneously predict transient occluders and latent appearance representation for each image. After training and preprocessing, our method aligns with the standard 3DGS format and rendering pipeline, facilitating seamlessly integration into various 3DGS applications. Extensive experiments on diverse datasets show our approach outperforms existing approaches on the rendering quality of novel view and appearance synthesis with high converge and rendering speed.","sentences":["Novel View Synthesis (NVS) from unconstrained photo collections is challenging in computer graphics.","Recently, 3D Gaussian Splatting (3DGS) has shown promise for photorealistic and real-time NVS of static scenes.","Building on 3DGS, we propose an efficient point-based differentiable rendering framework for scene reconstruction from photo collections.","Our key innovation is a residual-based spherical harmonic coefficients transfer module that adapts 3DGS to varying lighting conditions and photometric post-processing.","This lightweight module can be pre-computed and ensures efficient gradient propagation from rendered images to 3D Gaussian attributes.","Additionally, we observe that the appearance encoder and the transient mask predictor, the two most critical parts of NVS from unconstrained photo collections, can be mutually beneficial.","We introduce a plug-and-play lightweight spatial attention module to simultaneously predict transient occluders and latent appearance representation for each image.","After training and preprocessing, our method aligns with the standard 3DGS format and rendering pipeline, facilitating seamlessly integration into various 3DGS applications.","Extensive experiments on diverse datasets show our approach outperforms existing approaches on the rendering quality of novel view and appearance synthesis with high converge and rendering speed."],"url":"http://arxiv.org/abs/2406.02407v1","category":"cs.CV"}
{"created":"2024-06-04 15:11:27","title":"The Scandinavian Embedding Benchmarks: Comprehensive Assessment of Multilingual and Monolingual Text Embedding","abstract":"The evaluation of English text embeddings has transitioned from evaluating a handful of datasets to broad coverage across many tasks through benchmarks such as MTEB. However, this is not the case for multilingual text embeddings due to a lack of available benchmarks. To address this problem, we introduce the Scandinavian Embedding Benchmark (SEB). SEB is a comprehensive framework that enables text embedding evaluation for Scandinavian languages across 24 tasks, 10 subtasks, and 4 task categories. Building on SEB, we evaluate more than 26 models, uncovering significant performance disparities between public and commercial solutions not previously captured by MTEB. We open-source SEB and integrate it with MTEB, thus bridging the text embedding evaluation gap for Scandinavian languages.","sentences":["The evaluation of English text embeddings has transitioned from evaluating a handful of datasets to broad coverage across many tasks through benchmarks such as MTEB.","However, this is not the case for multilingual text embeddings due to a lack of available benchmarks.","To address this problem, we introduce the Scandinavian Embedding Benchmark (SEB).","SEB is a comprehensive framework that enables text embedding evaluation for Scandinavian languages across 24 tasks, 10 subtasks, and 4 task categories.","Building on SEB, we evaluate more than 26 models, uncovering significant performance disparities between public and commercial solutions not previously captured by MTEB.","We open-source SEB and integrate it with MTEB, thus bridging the text embedding evaluation gap for Scandinavian languages."],"url":"http://arxiv.org/abs/2406.02396v1","category":"cs.CL"}
{"created":"2024-06-04 15:08:56","title":"Multiple Choice Questions and Large Languages Models: A Case Study with Fictional Medical Data","abstract":"Large Language Models (LLMs) like ChatGPT demonstrate significant potential in the medical field, often evaluated using multiple-choice questions (MCQs) similar to those found on the USMLE. Despite their prevalence in medical education, MCQs have limitations that might be exacerbated when assessing LLMs. To evaluate the effectiveness of MCQs in assessing the performance of LLMs, we developed a fictional medical benchmark focused on a non-existent gland, the Glianorex. This approach allowed us to isolate the knowledge of the LLM from its test-taking abilities. We used GPT-4 to generate a comprehensive textbook on the Glianorex in both English and French and developed corresponding multiple-choice questions in both languages. We evaluated various open-source, proprietary, and domain-specific LLMs using these questions in a zero-shot setting. The models achieved average scores around 67%, with minor performance differences between larger and smaller models. Performance was slightly higher in English than in French. Fine-tuned medical models showed some improvement over their base versions in English but not in French. The uniformly high performance across models suggests that traditional MCQ-based benchmarks may not accurately measure LLMs' clinical knowledge and reasoning abilities, instead highlighting their pattern recognition skills. This study underscores the need for more robust evaluation methods to better assess the true capabilities of LLMs in medical contexts.","sentences":["Large Language Models (LLMs) like ChatGPT demonstrate significant potential in the medical field, often evaluated using multiple-choice questions (MCQs) similar to those found on the USMLE.","Despite their prevalence in medical education, MCQs have limitations that might be exacerbated when assessing LLMs.","To evaluate the effectiveness of MCQs in assessing the performance of LLMs, we developed a fictional medical benchmark focused on a non-existent gland, the Glianorex.","This approach allowed us to isolate the knowledge of the LLM from its test-taking abilities.","We used GPT-4 to generate a comprehensive textbook on the Glianorex in both English and French and developed corresponding multiple-choice questions in both languages.","We evaluated various open-source, proprietary, and domain-specific LLMs using these questions in a zero-shot setting.","The models achieved average scores around 67%, with minor performance differences between larger and smaller models.","Performance was slightly higher in English than in French.","Fine-tuned medical models showed some improvement over their base versions in English but not in French.","The uniformly high performance across models suggests that traditional MCQ-based benchmarks may not accurately measure LLMs' clinical knowledge and reasoning abilities, instead highlighting their pattern recognition skills.","This study underscores the need for more robust evaluation methods to better assess the true capabilities of LLMs in medical contexts."],"url":"http://arxiv.org/abs/2406.02394v1","category":"cs.CL"}
{"created":"2024-06-04 14:59:38","title":"Learning to Edit Visual Programs with Self-Supervision","abstract":"We design a system that learns how to edit visual programs. Our edit network consumes a complete input program and a visual target. From this input, we task our network with predicting a local edit operation that could be applied to the input program to improve its similarity to the target. In order to apply this scheme for domains that lack program annotations, we develop a self-supervised learning approach that integrates this edit network into a bootstrapped finetuning loop along with a network that predicts entire programs in one-shot. Our joint finetuning scheme, when coupled with an inference procedure that initializes a population from the one-shot model and evolves members of this population with the edit network, helps to infer more accurate visual programs. Over multiple domains, we experimentally compare our method against the alternative of using only the one-shot model, and find that even under equal search-time budgets, our editing-based paradigm provides significant advantages.","sentences":["We design a system that learns how to edit visual programs.","Our edit network consumes a complete input program and a visual target.","From this input, we task our network with predicting a local edit operation that could be applied to the input program to improve its similarity to the target.","In order to apply this scheme for domains that lack program annotations, we develop a self-supervised learning approach that integrates this edit network into a bootstrapped finetuning loop along with a network that predicts entire programs in one-shot.","Our joint finetuning scheme, when coupled with an inference procedure that initializes a population from the one-shot model and evolves members of this population with the edit network, helps to infer more accurate visual programs.","Over multiple domains, we experimentally compare our method against the alternative of using only the one-shot model, and find that even under equal search-time budgets, our editing-based paradigm provides significant advantages."],"url":"http://arxiv.org/abs/2406.02383v1","category":"cs.CV"}
{"created":"2024-06-04 14:58:10","title":"Kirigami: large convolutional kernels improve deep learning-based RNA secondary structure prediction","abstract":"We introduce a novel fully convolutional neural network (FCN) architecture for predicting the secondary structure of ribonucleic acid (RNA) molecules. Interpreting RNA structures as weighted graphs, we employ deep learning to estimate the probability of base pairing between nucleotide residues. Unique to our model are its massive 11-pixel kernels, which we argue provide a distinct advantage for FCNs on the specialized domain of RNA secondary structures. On a widely adopted, standardized test set comprised of 1,305 molecules, the accuracy of our method exceeds that of current state-of-the-art (SOTA) secondary structure prediction software, achieving a Matthews Correlation Coefficient (MCC) over 11-40% higher than that of other leading methods on overall structures and 58-400% higher on pseudoknots specifically.","sentences":["We introduce a novel fully convolutional neural network (FCN) architecture for predicting the secondary structure of ribonucleic acid (RNA) molecules.","Interpreting RNA structures as weighted graphs, we employ deep learning to estimate the probability of base pairing between nucleotide residues.","Unique to our model are its massive 11-pixel kernels, which we argue provide a distinct advantage for FCNs on the specialized domain of RNA secondary structures.","On a widely adopted, standardized test set comprised of 1,305 molecules, the accuracy of our method exceeds that of current state-of-the-art (SOTA) secondary structure prediction software, achieving a Matthews Correlation Coefficient (MCC) over 11-40% higher than that of other leading methods on overall structures and 58-400% higher on pseudoknots specifically."],"url":"http://arxiv.org/abs/2406.02381v1","category":"q-bio.BM"}
{"created":"2024-06-04 14:57:56","title":"EUFCC-340K: A Faceted Hierarchical Dataset for Metadata Annotation in GLAM Collections","abstract":"In this paper, we address the challenges of automatic metadata annotation in the domain of Galleries, Libraries, Archives, and Museums (GLAMs) by introducing a novel dataset, EUFCC340K, collected from the Europeana portal. Comprising over 340,000 images, the EUFCC340K dataset is organized across multiple facets: Materials, Object Types, Disciplines, and Subjects, following a hierarchical structure based on the Art & Architecture Thesaurus (AAT). We developed several baseline models, incorporating multiple heads on a ConvNeXT backbone for multi-label image tagging on these facets, and fine-tuning a CLIP model with our image text pairs. Our experiments to evaluate model robustness and generalization capabilities in two different test scenarios demonstrate the utility of the dataset in improving multi-label classification tools that have the potential to alleviate cataloging tasks in the cultural heritage sector.","sentences":["In this paper, we address the challenges of automatic metadata annotation in the domain of Galleries, Libraries, Archives, and Museums (GLAMs) by introducing a novel dataset, EUFCC340K, collected from the Europeana portal.","Comprising over 340,000 images, the EUFCC340K dataset is organized across multiple facets: Materials, Object Types, Disciplines, and Subjects, following a hierarchical structure based on the Art & Architecture Thesaurus (AAT).","We developed several baseline models, incorporating multiple heads on a ConvNeXT backbone for multi-label image tagging on these facets, and fine-tuning a CLIP model with our image text pairs.","Our experiments to evaluate model robustness and generalization capabilities in two different test scenarios demonstrate the utility of the dataset in improving multi-label classification tools that have the potential to alleviate cataloging tasks in the cultural heritage sector."],"url":"http://arxiv.org/abs/2406.02380v1","category":"cs.CV"}
{"created":"2024-06-04 14:55:14","title":"XRec: Large Language Models for Explainable Recommendation","abstract":"Recommender systems help users navigate information overload by providing personalized recommendations aligned with their preferences. Collaborative Filtering (CF) is a widely adopted approach, but while advanced techniques like graph neural networks (GNNs) and self-supervised learning (SSL) have enhanced CF models for better user representations, they often lack the ability to provide explanations for the recommended items. Explainable recommendations aim to address this gap by offering transparency and insights into the recommendation decision-making process, enhancing users' understanding. This work leverages the language capabilities of Large Language Models (LLMs) to push the boundaries of explainable recommender systems. We introduce a model-agnostic framework called XRec, which enables LLMs to provide comprehensive explanations for user behaviors in recommender systems. By integrating collaborative signals and designing a lightweight collaborative adaptor, the framework empowers LLMs to understand complex patterns in user-item interactions and gain a deeper understanding of user preferences. Our extensive experiments demonstrate the effectiveness of XRec, showcasing its ability to generate comprehensive and meaningful explanations that outperform baseline approaches in explainable recommender systems. We open-source our model implementation at https://github.com/HKUDS/XRec.","sentences":["Recommender systems help users navigate information overload by providing personalized recommendations aligned with their preferences.","Collaborative Filtering (CF) is a widely adopted approach, but while advanced techniques like graph neural networks (GNNs) and self-supervised learning (SSL) have enhanced CF models for better user representations, they often lack the ability to provide explanations for the recommended items.","Explainable recommendations aim to address this gap by offering transparency and insights into the recommendation decision-making process, enhancing users' understanding.","This work leverages the language capabilities of Large Language Models (LLMs) to push the boundaries of explainable recommender systems.","We introduce a model-agnostic framework called XRec, which enables LLMs to provide comprehensive explanations for user behaviors in recommender systems.","By integrating collaborative signals and designing a lightweight collaborative adaptor, the framework empowers LLMs to understand complex patterns in user-item interactions and gain a deeper understanding of user preferences.","Our extensive experiments demonstrate the effectiveness of XRec, showcasing its ability to generate comprehensive and meaningful explanations that outperform baseline approaches in explainable recommender systems.","We open-source our model implementation at https://github.com/HKUDS/XRec."],"url":"http://arxiv.org/abs/2406.02377v1","category":"cs.IR"}
{"created":"2024-06-04 14:45:47","title":"Finding NeMo: Localizing Neurons Responsible For Memorization in Diffusion Models","abstract":"Diffusion models (DMs) produce very detailed and high-quality images. Their power results from extensive training on large amounts of data, usually scraped from the internet without proper attribution or consent from content creators. Unfortunately, this practice raises privacy and intellectual property concerns, as DMs can memorize and later reproduce their potentially sensitive or copyrighted training images at inference time. Prior efforts prevent this issue by either changing the input to the diffusion process, thereby preventing the DM from generating memorized samples during inference, or removing the memorized data from training altogether. While those are viable solutions when the DM is developed and deployed in a secure and constantly monitored environment, they hold the risk of adversaries circumventing the safeguards and are not effective when the DM itself is publicly released. To solve the problem, we introduce NeMo, the first method to localize memorization of individual data samples down to the level of neurons in DMs' cross-attention layers. Through our experiments, we make the intriguing finding that in many cases, single neurons are responsible for memorizing particular training samples. By deactivating these memorization neurons, we can avoid the replication of training data at inference time, increase the diversity in the generated outputs, and mitigate the leakage of private and copyrighted data. In this way, our NeMo contributes to a more responsible deployment of DMs.","sentences":["Diffusion models (DMs) produce very detailed and high-quality images.","Their power results from extensive training on large amounts of data, usually scraped from the internet without proper attribution or consent from content creators.","Unfortunately, this practice raises privacy and intellectual property concerns, as DMs can memorize and later reproduce their potentially sensitive or copyrighted training images at inference time.","Prior efforts prevent this issue by either changing the input to the diffusion process, thereby preventing the DM from generating memorized samples during inference, or removing the memorized data from training altogether.","While those are viable solutions when the DM is developed and deployed in a secure and constantly monitored environment, they hold the risk of adversaries circumventing the safeguards and are not effective when the DM itself is publicly released.","To solve the problem, we introduce NeMo, the first method to localize memorization of individual data samples down to the level of neurons in DMs' cross-attention layers.","Through our experiments, we make the intriguing finding that in many cases, single neurons are responsible for memorizing particular training samples.","By deactivating these memorization neurons, we can avoid the replication of training data at inference time, increase the diversity in the generated outputs, and mitigate the leakage of private and copyrighted data.","In this way, our NeMo contributes to a more responsible deployment of DMs."],"url":"http://arxiv.org/abs/2406.02366v1","category":"cs.LG"}
{"created":"2024-06-04 14:39:51","title":"Temporal Graph Rewiring with Expander Graphs","abstract":"Evolving relations in real-world networks are often modelled by temporal graphs. Graph rewiring techniques have been utilised on Graph Neural Networks (GNNs) to improve expressiveness and increase model performance. In this work, we propose Temporal Graph Rewiring (TGR), the first approach for graph rewiring on temporal graphs. TGR enables communication between temporally distant nodes in a continuous time dynamic graph by utilising expander graph propagation to construct a message passing highway for message passing between distant nodes. Expander graphs are suitable candidates for rewiring as they help overcome the oversquashing problem often observed in GNNs. On the public tgbl-wiki benchmark, we show that TGR improves the performance of a widely used TGN model by a significant margin. Our code repository is accessible at https://github.com/kpetrovicc/TGR.git .","sentences":["Evolving relations in real-world networks are often modelled by temporal graphs.","Graph rewiring techniques have been utilised on Graph Neural Networks (GNNs) to improve expressiveness and increase model performance.","In this work, we propose Temporal Graph Rewiring (TGR), the first approach for graph rewiring on temporal graphs.","TGR enables communication between temporally distant nodes in a continuous time dynamic graph by utilising expander graph propagation to construct a message passing highway for message passing between distant nodes.","Expander graphs are suitable candidates for rewiring as they help overcome the oversquashing problem often observed in GNNs.","On the public tgbl-wiki benchmark, we show that TGR improves the performance of a widely used TGN model by a significant margin.","Our code repository is accessible at https://github.com/kpetrovicc/TGR.git ."],"url":"http://arxiv.org/abs/2406.02362v2","category":"cs.LG"}
{"created":"2024-06-04 14:35:27","title":"The complexity of approximate (coarse) correlated equilibrium for incomplete information games","abstract":"We study the iteration complexity of decentralized learning of approximate correlated equilibria in incomplete information games.   On the negative side, we prove that in $\\mathit{extensive}$-$\\mathit{form}$ $\\mathit{games}$, assuming $\\mathsf{PPAD} \\not\\subset \\mathsf{TIME}(n^{\\mathsf{polylog}(n)})$, any polynomial-time learning algorithms must take at least $2^{\\log_2^{1-o(1)}(|\\mathcal{I}|)}$ iterations to converge to the set of $\\epsilon$-approximate correlated equilibrium, where $|\\mathcal{I}|$ is the number of nodes in the game and $\\epsilon > 0$ is an absolute constant. This nearly matches, up to the $o(1)$ term, the algorithms of [PR'24, DDFG'24] for learning $\\epsilon$-approximate correlated equilibrium, and resolves an open question of Anagnostides, Kalavasis, Sandholm, and Zampetakis [AKSZ'24]. Our lower bound holds even for the easier solution concept of $\\epsilon$-approximate $\\mathit{coarse}$ correlated equilibrium   On the positive side, we give uncoupled dynamics that reach $\\epsilon$-approximate correlated equilibria of a $\\mathit{Bayesian}$ $\\mathit{game}$ in polylogarithmic iterations, without any dependence of the number of types. This demonstrates a separation between Bayesian games and extensive-form games.","sentences":["We study the iteration complexity of decentralized learning of approximate correlated equilibria in incomplete information games.   ","On the negative side, we prove that in $\\mathit{extensive}$-$\\mathit{form}$ $\\mathit{games}$, assuming $\\mathsf{PPAD} \\not\\subset \\mathsf{TIME}(n^{\\mathsf{polylog}(n)})$, any polynomial-time learning algorithms must take at least $2^{\\log_2^{1-o(1)}(|\\mathcal{I}|)}$ iterations to converge to the set of $\\epsilon$-approximate correlated equilibrium, where $|\\mathcal{I}|$ is the number of nodes in the game and $\\epsilon > 0$ is an absolute constant.","This nearly matches, up to the $o(1)$ term, the algorithms of [PR'24, DDFG'24] for learning $\\epsilon$-approximate correlated equilibrium, and resolves an open question of Anagnostides, Kalavasis, Sandholm, and","Zampetakis","[AKSZ'24].","Our lower bound holds even for the easier solution concept of $\\epsilon$-approximate $\\mathit{coarse}$ correlated equilibrium   On the positive side, we give uncoupled dynamics that reach $\\epsilon$-approximate correlated equilibria of a $\\mathit{Bayesian}$ $\\mathit{game}$ in polylogarithmic iterations, without any dependence of the number of types.","This demonstrates a separation between Bayesian games and extensive-form games."],"url":"http://arxiv.org/abs/2406.02357v1","category":"cs.GT"}
{"created":"2024-06-04 14:34:39","title":"Language Models Do Hard Arithmetic Tasks Easily and Hardly Do Easy Arithmetic Tasks","abstract":"The ability (and inability) of large language models (LLMs) to perform arithmetic tasks has been the subject of much theoretical and practical debate. We show that LLMs are frequently able to correctly and confidently predict the first digit of n-digit by m-digit multiplication tasks without using chain of thought reasoning, despite these tasks require compounding operations to solve. Simultaneously, LLMs in practice often fail to correctly or confidently predict the last digit of an n-digit by m-digit multiplication, a task equivalent to 1-digit by 1-digit multiplication which can be easily learned or memorized. We show that the latter task can be solved more robustly when the LLM is conditioned on all of the correct higher-order digits, which on average increases the confidence of the correct last digit on 5-digit by 5-digit multiplication tasks using Llama 2-13B by over 230% (0.13 to 0.43) and Mistral-7B by 150% (0.22 to 0.55).","sentences":["The ability (and inability) of large language models (LLMs) to perform arithmetic tasks has been the subject of much theoretical and practical debate.","We show that LLMs are frequently able to correctly and confidently predict the first digit of n-digit by m-digit multiplication tasks without using chain of thought reasoning, despite these tasks require compounding operations to solve.","Simultaneously, LLMs in practice often fail to correctly or confidently predict the last digit of an n-digit by m-digit multiplication, a task equivalent to 1-digit by 1-digit multiplication which can be easily learned or memorized.","We show that the latter task can be solved more robustly when the LLM is conditioned on all of the correct higher-order digits, which on average increases the confidence of the correct last digit on 5-digit by 5-digit multiplication tasks using Llama 2-13B by over 230% (0.13 to 0.43) and Mistral-7B by 150% (0.22 to 0.55)."],"url":"http://arxiv.org/abs/2406.02356v1","category":"cs.LG"}
{"created":"2024-06-04 14:34:13","title":"FedDr+: Stabilizing Dot-regression with Global Feature Distillation for Federated Learning","abstract":"Federated Learning (FL) has emerged as a pivotal framework for the development of effective global models (global FL) or personalized models (personalized FL) across clients with heterogeneous, non-iid data distribution. A key challenge in FL is client drift, where data heterogeneity impedes the aggregation of scattered knowledge. Recent studies have tackled the client drift issue by identifying significant divergence in the last classifier layer. To mitigate this divergence, strategies such as freezing the classifier weights and aligning the feature extractor accordingly have proven effective. Although the local alignment between classifier and feature extractor has been studied as a crucial factor in FL, we observe that it may lead the model to overemphasize the observed classes within each client. Thus, our objectives are twofold: (1) enhancing local alignment while (2) preserving the representation of unseen class samples. This approach aims to effectively integrate knowledge from individual clients, thereby improving performance for both global and personalized FL. To achieve this, we introduce a novel algorithm named FedDr+, which empowers local model alignment using dot-regression loss. FedDr+ freezes the classifier as a simplex ETF to align the features and improves aggregated global models by employing a feature distillation mechanism to retain information about unseen/missing classes. Consequently, we provide empirical evidence demonstrating that our algorithm surpasses existing methods that use a frozen classifier to boost alignment across the diverse distribution.","sentences":["Federated Learning (FL) has emerged as a pivotal framework for the development of effective global models (global FL) or personalized models (personalized FL) across clients with heterogeneous, non-iid data distribution.","A key challenge in FL is client drift, where data heterogeneity impedes the aggregation of scattered knowledge.","Recent studies have tackled the client drift issue by identifying significant divergence in the last classifier layer.","To mitigate this divergence, strategies such as freezing the classifier weights and aligning the feature extractor accordingly have proven effective.","Although the local alignment between classifier and feature extractor has been studied as a crucial factor in FL, we observe that it may lead the model to overemphasize the observed classes within each client.","Thus, our objectives are twofold: (1) enhancing local alignment while (2) preserving the representation of unseen class samples.","This approach aims to effectively integrate knowledge from individual clients, thereby improving performance for both global and personalized FL.","To achieve this, we introduce a novel algorithm named FedDr+, which empowers local model alignment using dot-regression loss.","FedDr+ freezes the classifier as a simplex ETF to align the features and improves aggregated global models by employing a feature distillation mechanism to retain information about unseen/missing classes.","Consequently, we provide empirical evidence demonstrating that our algorithm surpasses existing methods that use a frozen classifier to boost alignment across the diverse distribution."],"url":"http://arxiv.org/abs/2406.02355v1","category":"cs.CV"}
{"created":"2024-06-04 14:33:23","title":"Label-wise Aleatoric and Epistemic Uncertainty Quantification","abstract":"We present a novel approach to uncertainty quantification in classification tasks based on label-wise decomposition of uncertainty measures. This label-wise perspective allows uncertainty to be quantified at the individual class level, thereby improving cost-sensitive decision-making and helping understand the sources of uncertainty. Furthermore, it allows to define total, aleatoric, and epistemic uncertainty on the basis of non-categorical measures such as variance, going beyond common entropy-based measures. In particular, variance-based measures address some of the limitations associated with established methods that have recently been discussed in the literature. We show that our proposed measures adhere to a number of desirable properties. Through empirical evaluation on a variety of benchmark data sets -- including applications in the medical domain where accurate uncertainty quantification is crucial -- we establish the effectiveness of label-wise uncertainty quantification.","sentences":["We present a novel approach to uncertainty quantification in classification tasks based on label-wise decomposition of uncertainty measures.","This label-wise perspective allows uncertainty to be quantified at the individual class level, thereby improving cost-sensitive decision-making and helping understand the sources of uncertainty.","Furthermore, it allows to define total, aleatoric, and epistemic uncertainty on the basis of non-categorical measures such as variance, going beyond common entropy-based measures.","In particular, variance-based measures address some of the limitations associated with established methods that have recently been discussed in the literature.","We show that our proposed measures adhere to a number of desirable properties.","Through empirical evaluation on a variety of benchmark data sets -- including applications in the medical domain where accurate uncertainty quantification is crucial -- we establish the effectiveness of label-wise uncertainty quantification."],"url":"http://arxiv.org/abs/2406.02354v1","category":"cs.LG"}
{"created":"2024-06-04 14:24:53","title":"LlamaCare: A Large Medical Language Model for Enhancing Healthcare Knowledge Sharing","abstract":"Large language models (LLMs) have shown amazing capabilities in knowledge memorization and the present. However, when it comes to domain-specific knowledge and downstream tasks like medical, general LLMs are often unable to give precise answers. In addition, when people want LLMs to answer classification questions, they usually go through instruction tuning first. However, LLMs do not always give a direct index of the categorization after instruction tuning. In this paper, we proposed LlamaCare, a fine-tuned medical language model, and Extended Classification Integration(ECI), a module to handle classification problems of LLMs. Our contributions are : (i) We fine-tuned a large language model of medical knowledge with very low carbon emissions and achieved similar performance with ChatGPT by a 24G GPU. (ii) We solved the problem of redundant categorical answers and improved the performance of LLMs by proposing a new module called Extended Classification Integration. (iii) We released our processed data for one-shot and few-shot training for some benchmarks such as PubMedQA and USMLE 1-3 step. Our method achieves a close performance comparable to some state-of-the-art models with the same quantity of parameters on benchmarks, while being more environmentally friendly by using less GPU computation time. Our models, codes, and datasets can be found at \\url{https://github.com/Stephen-SMJ/LLamaCare}.","sentences":["Large language models (LLMs) have shown amazing capabilities in knowledge memorization and the present.","However, when it comes to domain-specific knowledge and downstream tasks like medical, general LLMs are often unable to give precise answers.","In addition, when people want LLMs to answer classification questions, they usually go through instruction tuning first.","However, LLMs do not always give a direct index of the categorization after instruction tuning.","In this paper, we proposed LlamaCare, a fine-tuned medical language model, and Extended Classification Integration(ECI), a module to handle classification problems of LLMs.","Our contributions are : (i) We fine-tuned a large language model of medical knowledge with very low carbon emissions and achieved similar performance with ChatGPT by a 24G GPU.","(ii) We solved the problem of redundant categorical answers and improved the performance of LLMs by proposing a new module called Extended Classification Integration.","(iii) We released our processed data for one-shot and few-shot training for some benchmarks such as PubMedQA and USMLE 1-3 step.","Our method achieves a close performance comparable to some state-of-the-art models with the same quantity of parameters on benchmarks, while being more environmentally friendly by using less GPU computation time.","Our models, codes, and datasets can be found at \\url{https://github.com/Stephen-SMJ/LLamaCare}."],"url":"http://arxiv.org/abs/2406.02350v2","category":"cs.CL"}
{"created":"2024-06-04 14:24:35","title":"CADE: Cosine Annealing Differential Evolution for Spiking Neural Network","abstract":"Spiking neural networks (SNNs) have gained prominence for their potential in neuromorphic computing and energy-efficient artificial intelligence, yet optimizing them remains a formidable challenge for gradient-based methods due to their discrete, spike-based computation. This paper attempts to tackle the challenges by introducing Cosine Annealing Differential Evolution (CADE), designed to modulate the mutation factor (F) and crossover rate (CR) of differential evolution (DE) for the SNN model, i.e., Spiking Element Wise (SEW) ResNet. Extensive empirical evaluations were conducted to analyze CADE. CADE showed a balance in exploring and exploiting the search space, resulting in accelerated convergence and improved accuracy compared to existing gradient-based and DE-based methods. Moreover, an initialization method based on a transfer learning setting was developed, pretraining on a source dataset (i.e., CIFAR-10) and fine-tuning the target dataset (i.e., CIFAR-100), to improve population diversity. It was found to further enhance CADE for SNN. Remarkably, CADE elevates the performance of the highest accuracy SEW model by an additional 0.52 percentage points, underscoring its effectiveness in fine-tuning and enhancing SNNs. These findings emphasize the pivotal role of a scheduler for F and CR adjustment, especially for DE-based SNN. Source Code on Github: https://github.com/Tank-Jiang/CADE4SNN.","sentences":["Spiking neural networks (SNNs) have gained prominence for their potential in neuromorphic computing and energy-efficient artificial intelligence, yet optimizing them remains a formidable challenge for gradient-based methods due to their discrete, spike-based computation.","This paper attempts to tackle the challenges by introducing Cosine Annealing Differential Evolution (CADE), designed to modulate the mutation factor (F) and crossover rate (CR) of differential evolution (DE) for the SNN model, i.e., Spiking Element Wise (SEW) ResNet.","Extensive empirical evaluations were conducted to analyze CADE.","CADE showed a balance in exploring and exploiting the search space, resulting in accelerated convergence and improved accuracy compared to existing gradient-based and DE-based methods.","Moreover, an initialization method based on a transfer learning setting was developed, pretraining on a source dataset (i.e., CIFAR-10) and fine-tuning the target dataset (i.e., CIFAR-100), to improve population diversity.","It was found to further enhance CADE for SNN.","Remarkably, CADE elevates the performance of the highest accuracy SEW model by an additional 0.52 percentage points, underscoring its effectiveness in fine-tuning and enhancing SNNs.","These findings emphasize the pivotal role of a scheduler for F and CR adjustment, especially for DE-based SNN.","Source Code on Github: https://github.com/Tank-Jiang/CADE4SNN."],"url":"http://arxiv.org/abs/2406.02349v1","category":"cs.NE"}
{"created":"2024-06-04 17:41:23","title":"Superconducting magic-angle twisted trilayer graphene hosts competing magnetic order and moir\u00e9 inhomogeneities","abstract":"The microscopic mechanism of superconductivity in the magic-angle twisted graphene family, including magic-angle twisted trilayer graphene (MATTG), is poorly understood. Properties of MATTG, like Pauli limit violation, suggest unconventional superconductivity. Theoretical studies propose proximal magnetic states in the phase diagram, but direct experimental evidence is lacking. We show direct evidence for an in-plane magnetic order proximal to the superconducting state using two complementary electrical transport measurements. First, we probe the superconducting phase by using statistically significant switching events from superconducting to the dissipative state of MATTG. The system behaves like a network of Josephson junctions due to lattice relaxation-induced moir\\'e inhomogeneity in the system. We observe non-monotonic and hysteretic responses in the switching distributions as a function of temperature and in-plane magnetic field. Second, in normal regions doped slightly away from the superconducting regime, we observe hysteresis in magnetoresistance with an in-plane magnetic field; showing evidence for in-plane magnetic order that vanishes $\\sim$900 mK. Additionally, we show a broadened Berezinskii-Kosterlitz-Thouless transition due to relaxation-induced moir\\'e inhomogeneity. We find superfluid stiffness $J_{\\mathrm{s}}$$\\sim$0.15 K with strong temperature dependence. Theoretically, the magnetic and superconducting order arising from the magnetic order's fluctuations have been proposed - we show direct evidence for both. Our observation that the hysteretic magnetoresistance is sensitive to the in-plane field may constrain possible intervalley-coherent magnetic orders and the resulting superconductivity that arises from its fluctuations.","sentences":["The microscopic mechanism of superconductivity in the magic-angle twisted graphene family, including magic-angle twisted trilayer graphene (MATTG), is poorly understood.","Properties of MATTG, like Pauli limit violation, suggest unconventional superconductivity.","Theoretical studies propose proximal magnetic states in the phase diagram, but direct experimental evidence is lacking.","We show direct evidence for an in-plane magnetic order proximal to the superconducting state using two complementary electrical transport measurements.","First, we probe the superconducting phase by using statistically significant switching events from superconducting to the dissipative state of MATTG.","The system behaves like a network of Josephson junctions due to lattice relaxation-induced moir\\'e inhomogeneity in the system.","We observe non-monotonic and hysteretic responses in the switching distributions as a function of temperature and in-plane magnetic field.","Second, in normal regions doped slightly away from the superconducting regime, we observe hysteresis in magnetoresistance with an in-plane magnetic field; showing evidence for in-plane magnetic order that vanishes $\\sim$900 mK. Additionally, we show a broadened Berezinskii-Kosterlitz-Thouless transition due to relaxation-induced moir\\'e inhomogeneity.","We find superfluid stiffness $J_{\\mathrm{s}}$$\\sim$0.15 K with strong temperature dependence.","Theoretically, the magnetic and superconducting order arising from the magnetic order's fluctuations have been proposed - we show direct evidence for both.","Our observation that the hysteretic magnetoresistance is sensitive to the in-plane field may constrain possible intervalley-coherent magnetic orders and the resulting superconductivity that arises from its fluctuations."],"url":"http://arxiv.org/abs/2406.02521v1","category":"cond-mat.mes-hall"}
{"created":"2024-06-04 17:39:31","title":"DDGS-CT: Direction-Disentangled Gaussian Splatting for Realistic Volume Rendering","abstract":"Digitally reconstructed radiographs (DRRs) are simulated 2D X-ray images generated from 3D CT volumes, widely used in preoperative settings but limited in intraoperative applications due to computational bottlenecks, especially for accurate but heavy physics-based Monte Carlo methods. While analytical DRR renderers offer greater efficiency, they overlook anisotropic X-ray image formation phenomena, such as Compton scattering. We present a novel approach that marries realistic physics-inspired X-ray simulation with efficient, differentiable DRR generation using 3D Gaussian splatting (3DGS). Our direction-disentangled 3DGS (DDGS) method separates the radiosity contribution into isotropic and direction-dependent components, approximating complex anisotropic interactions without intricate runtime simulations. Additionally, we adapt the 3DGS initialization to account for tomography data properties, enhancing accuracy and efficiency. Our method outperforms state-of-the-art techniques in image accuracy. Furthermore, our DDGS shows promise for intraoperative applications and inverse problems such as pose registration, delivering superior registration accuracy and runtime performance compared to analytical DRR methods.","sentences":["Digitally reconstructed radiographs (DRRs) are simulated 2D X-ray images generated from 3D CT volumes, widely used in preoperative settings but limited in intraoperative applications due to computational bottlenecks, especially for accurate but heavy physics-based Monte Carlo methods.","While analytical DRR renderers offer greater efficiency, they overlook anisotropic X-ray image formation phenomena, such as Compton scattering.","We present a novel approach that marries realistic physics-inspired X-ray simulation with efficient, differentiable DRR generation using 3D Gaussian splatting (3DGS).","Our direction-disentangled 3DGS (DDGS) method separates the radiosity contribution into isotropic and direction-dependent components, approximating complex anisotropic interactions without intricate runtime simulations.","Additionally, we adapt the 3DGS initialization to account for tomography data properties, enhancing accuracy and efficiency.","Our method outperforms state-of-the-art techniques in image accuracy.","Furthermore, our DDGS shows promise for intraoperative applications and inverse problems such as pose registration, delivering superior registration accuracy and runtime performance compared to analytical DRR methods."],"url":"http://arxiv.org/abs/2406.02518v1","category":"cs.CV"}
{"created":"2024-06-04 16:54:28","title":"Stable-Pose: Leveraging Transformers for Pose-Guided Text-to-Image Generation","abstract":"Controllable text-to-image (T2I) diffusion models have shown impressive performance in generating high-quality visual content through the incorporation of various conditions. Current methods, however, exhibit limited performance when guided by skeleton human poses, especially in complex pose conditions such as side or rear perspectives of human figures. To address this issue, we present Stable-Pose, a novel adapter model that introduces a coarse-to-fine attention masking strategy into a vision Transformer (ViT) to gain accurate pose guidance for T2I models. Stable-Pose is designed to adeptly handle pose conditions within pre-trained Stable Diffusion, providing a refined and efficient way of aligning pose representation during image synthesis. We leverage the query-key self-attention mechanism of ViTs to explore the interconnections among different anatomical parts in human pose skeletons. Masked pose images are used to smoothly refine the attention maps based on target pose-related features in a hierarchical manner, transitioning from coarse to fine levels. Additionally, our loss function is formulated to allocate increased emphasis to the pose region, thereby augmenting the model's precision in capturing intricate pose details. We assessed the performance of Stable-Pose across five public datasets under a wide range of indoor and outdoor human pose scenarios. Stable-Pose achieved an AP score of 57.1 in the LAION-Human dataset, marking around 13% improvement over the established technique ControlNet. The project link and code is available at https://github.com/ai-med/StablePose.","sentences":["Controllable text-to-image (T2I) diffusion models have shown impressive performance in generating high-quality visual content through the incorporation of various conditions.","Current methods, however, exhibit limited performance when guided by skeleton human poses, especially in complex pose conditions such as side or rear perspectives of human figures.","To address this issue, we present Stable-Pose, a novel adapter model that introduces a coarse-to-fine attention masking strategy into a vision Transformer (ViT) to gain accurate pose guidance for T2I models.","Stable-Pose is designed to adeptly handle pose conditions within pre-trained Stable Diffusion, providing a refined and efficient way of aligning pose representation during image synthesis.","We leverage the query-key self-attention mechanism of ViTs to explore the interconnections among different anatomical parts in human pose skeletons.","Masked pose images are used to smoothly refine the attention maps based on target pose-related features in a hierarchical manner, transitioning from coarse to fine levels.","Additionally, our loss function is formulated to allocate increased emphasis to the pose region, thereby augmenting the model's precision in capturing intricate pose details.","We assessed the performance of Stable-Pose across five public datasets under a wide range of indoor and outdoor human pose scenarios.","Stable-Pose achieved an AP score of 57.1 in the LAION-Human dataset, marking around 13% improvement over the established technique ControlNet.","The project link and code is available at https://github.com/ai-med/StablePose."],"url":"http://arxiv.org/abs/2406.02485v1","category":"cs.CV"}
{"created":"2024-06-04 16:38:57","title":"Landscape-Aware Growing: The Power of a Little LAG","abstract":"Recently, there has been increasing interest in efficient pretraining paradigms for training Transformer-based models. Several recent approaches use smaller models to initialize larger models in order to save computation (e.g., stacking and fusion). In this work, we study the fundamental question of how to select the best growing strategy from a given pool of growing strategies. Prior works have extensively focused on loss- and/or function-preserving behavior at initialization or simply performance at the end of training. Instead, we identify that behavior at initialization can be misleading as a predictor of final performance and present an alternative perspective based on early training dynamics, which we call \"landscape-aware growing (LAG)\". We perform extensive analysis of correlation of the final performance with performance in the initial steps of training and find early and more accurate predictions of the optimal growing strategy (i.e., with only a small \"lag\" after initialization). This perspective also motivates an adaptive strategy for gradual stacking.","sentences":["Recently, there has been increasing interest in efficient pretraining paradigms for training Transformer-based models.","Several recent approaches use smaller models to initialize larger models in order to save computation (e.g., stacking and fusion).","In this work, we study the fundamental question of how to select the best growing strategy from a given pool of growing strategies.","Prior works have extensively focused on loss- and/or function-preserving behavior at initialization or simply performance at the end of training.","Instead, we identify that behavior at initialization can be misleading as a predictor of final performance and present an alternative perspective based on early training dynamics, which we call \"landscape-aware growing (LAG)\".","We perform extensive analysis of correlation of the final performance with performance in the initial steps of training and find early and more accurate predictions of the optimal growing strategy (i.e., with only a small \"lag\" after initialization).","This perspective also motivates an adaptive strategy for gradual stacking."],"url":"http://arxiv.org/abs/2406.02469v1","category":"cs.LG"}
{"created":"2024-06-04 16:07:26","title":"Noise-adapted qudit codes for amplitude-damping noise","abstract":"Quantum error correction (QEC) plays a critical role in preventing information loss in quantum systems and provides a framework for reliable quantum computation. Identifying quantum codes with nice code parameters for physically motivated noise models remains an interesting challenge. Going beyond qubit codes, here we propose a class of qudit error correcting codes tailored to protect against amplitude-damping noise. Specifically, we construct a class of four-qudit codes that satisfies the error correction conditions for all single-qudit and a few two-qudit damping errors up to the leading order in the damping parameter $\\gamma$. We devise a protocol to extract syndromes that identify this set of errors unambiguously, leading to a noise-adapted recovery scheme that achieves a fidelity loss of $\\cO(\\gamma^{2})$. For the $d=2$ case, our QEC scheme is identical to the known example of the $4$-qubit code and the associated syndrome-based recovery.   We also assess the performance of our class of codes using the Petz recovery map and note some interesting deviations from the qubit case.","sentences":["Quantum error correction (QEC) plays a critical role in preventing information loss in quantum systems and provides a framework for reliable quantum computation.","Identifying quantum codes with nice code parameters for physically motivated noise models remains an interesting challenge.","Going beyond qubit codes, here we propose a class of qudit error correcting codes tailored to protect against amplitude-damping noise.","Specifically, we construct a class of four-qudit codes that satisfies the error correction conditions for all single-qudit and a few two-qudit damping errors up to the leading order in the damping parameter $\\gamma$.","We devise a protocol to extract syndromes that identify this set of errors unambiguously, leading to a noise-adapted recovery scheme that achieves a fidelity loss of $\\cO(\\gamma^{2})$. For the $d=2$ case, our QEC scheme is identical to the known example of the $4$-qubit code and the associated syndrome-based recovery.   ","We also assess the performance of our class of codes using the Petz recovery map and note some interesting deviations from the qubit case."],"url":"http://arxiv.org/abs/2406.02444v1","category":"quant-ph"}
{"created":"2024-06-04 16:03:23","title":"Ultra-thin transistors and circuits for conformable electronics","abstract":"Adapting electronics to perfectly conform to non-planar and rough surfaces, such as human skin, is a very challenging task which, if solved, could open up new applications in fields of high economic and scientific interest ranging from health to robotics, wearable electronics, human-machine interface and Internet of Things. The key to success lies in defining a technology that can lead to the fabrication of ultra-thin devices while exploiting materials that are ultimately thin, with high mechanical flexibility and excellent electrical properties. Here, we report a hybrid approach for the definition of high-performance, ultra-thin and conformable electronic devices and circuits, based on the integration of ultimately thin semiconducting transition metal dichalcogenides (TMDC), i.e., MoS2, with organic gate dielectric material, i.e., polyvinyl formal (PVF) combined with the ink-jet printing of conductive PEDOT:PSS ink for electrodes definition. Through this cost-effective, fully bottom-up and solution-based approach, transistors and simple digital and analogue circuits are fabricated by a sequential stacking of ultrathin (nanometer) layers on a few micron thick polyimide substrate, which guarantees the high flexibility mandatory for the targeted applications.","sentences":["Adapting electronics to perfectly conform to non-planar and rough surfaces, such as human skin, is a very challenging task which, if solved, could open up new applications in fields of high economic and scientific interest ranging from health to robotics, wearable electronics, human-machine interface and Internet of Things.","The key to success lies in defining a technology that can lead to the fabrication of ultra-thin devices while exploiting materials that are ultimately thin, with high mechanical flexibility and excellent electrical properties.","Here, we report a hybrid approach for the definition of high-performance, ultra-thin and conformable electronic devices and circuits, based on the integration of ultimately thin semiconducting transition metal dichalcogenides (TMDC), i.e., MoS2, with organic gate dielectric material, i.e., polyvinyl formal (PVF) combined with the ink-jet printing of conductive PEDOT:","PSS ink for electrodes definition.","Through this cost-effective, fully bottom-up and solution-based approach, transistors and simple digital and analogue circuits are fabricated by a sequential stacking of ultrathin (nanometer) layers on a few micron thick polyimide substrate, which guarantees the high flexibility mandatory for the targeted applications."],"url":"http://arxiv.org/abs/2406.02442v1","category":"physics.app-ph"}
{"created":"2024-06-04 15:58:14","title":"Out-of-Distribution Runtime Adaptation with Conformalized Neural Network Ensembles","abstract":"We present a method to integrate real-time out-of-distribution (OOD) detection for neural network trajectory predictors, and to adapt the control strategy of a robot (e.g., a self-driving car or drone) to preserve safety while operating in OOD regimes. Specifically, we use a neural network ensemble to predict the trajectory for a dynamic obstacle (such as a pedestrian), and use the maximum singular value of the empirical covariance among the ensemble as a signal for OOD detection. We calibrate this signal with a small fraction of held-out training data using the methodology of conformal prediction, to derive an OOD detector with probabilistic guarantees on the false-positive rate of the detector, given a user-specified confidence level. During in-distribution operation, we use an MPC controller to avoid collisions with the obstacle based on the trajectory predicted by the neural network ensemble. When OOD conditions are detected, we switch to a reachability-based controller to guarantee safety under the worst-case actions of the obstacle. We verify our method in extensive autonomous driving simulations in a pedestrian crossing scenario, showing that our OOD detector obtains the desired accuracy rate within a theoretically-predicted range. We also demonstrate the effectiveness of our method with real pedestrian data. We show improved safety and less conservatism in comparison with two state-of-the-art methods that also use conformal prediction, but without OOD adaptation.","sentences":["We present a method to integrate real-time out-of-distribution (OOD) detection for neural network trajectory predictors, and to adapt the control strategy of a robot (e.g., a self-driving car or drone) to preserve safety while operating in OOD regimes.","Specifically, we use a neural network ensemble to predict the trajectory for a dynamic obstacle (such as a pedestrian), and use the maximum singular value of the empirical covariance among the ensemble as a signal for OOD detection.","We calibrate this signal with a small fraction of held-out training data using the methodology of conformal prediction, to derive an OOD detector with probabilistic guarantees on the false-positive rate of the detector, given a user-specified confidence level.","During in-distribution operation, we use an MPC controller to avoid collisions with the obstacle based on the trajectory predicted by the neural network ensemble.","When OOD conditions are detected, we switch to a reachability-based controller to guarantee safety under the worst-case actions of the obstacle.","We verify our method in extensive autonomous driving simulations in a pedestrian crossing scenario, showing that our OOD detector obtains the desired accuracy rate within a theoretically-predicted range.","We also demonstrate the effectiveness of our method with real pedestrian data.","We show improved safety and less conservatism in comparison with two state-of-the-art methods that also use conformal prediction, but without OOD adaptation."],"url":"http://arxiv.org/abs/2406.02436v1","category":"cs.RO"}
{"created":"2024-06-04 15:47:03","title":"Harnessing Neural Unit Dynamics for Effective and Scalable Class-Incremental Learning","abstract":"Class-incremental learning (CIL) aims to train a model to learn new classes from non-stationary data streams without forgetting old ones. In this paper, we propose a new kind of connectionist model by tailoring neural unit dynamics that adapt the behavior of neural networks for CIL. In each training session, it introduces a supervisory mechanism to guide network expansion whose growth size is compactly commensurate with the intrinsic complexity of a newly arriving task. This constructs a near-minimal network while allowing the model to expand its capacity when cannot sufficiently hold new classes. At inference time, it automatically reactivates the required neural units to retrieve knowledge and leaves the remaining inactivated to prevent interference. We name our model AutoActivator, which is effective and scalable. To gain insights into the neural unit dynamics, we theoretically analyze the model's convergence property via a universal approximation theorem on learning sequential mappings, which is under-explored in the CIL community. Experiments show that our method achieves strong CIL performance in rehearsal-free and minimal-expansion settings with different backbones.","sentences":["Class-incremental learning (CIL) aims to train a model to learn new classes from non-stationary data streams without forgetting old ones.","In this paper, we propose a new kind of connectionist model by tailoring neural unit dynamics that adapt the behavior of neural networks for CIL.","In each training session, it introduces a supervisory mechanism to guide network expansion whose growth size is compactly commensurate with the intrinsic complexity of a newly arriving task.","This constructs a near-minimal network while allowing the model to expand its capacity when cannot sufficiently hold new classes.","At inference time, it automatically reactivates the required neural units to retrieve knowledge and leaves the remaining inactivated to prevent interference.","We name our model AutoActivator, which is effective and scalable.","To gain insights into the neural unit dynamics, we theoretically analyze the model's convergence property via a universal approximation theorem on learning sequential mappings, which is under-explored in the CIL community.","Experiments show that our method achieves strong CIL performance in rehearsal-free and minimal-expansion settings with different backbones."],"url":"http://arxiv.org/abs/2406.02428v1","category":"cs.LG"}
{"created":"2024-06-04 15:16:39","title":"Emergence of Newtonian Deterministic Causality from Stochastic Motions in Continuous Space and Time","abstract":"Since Newton's time, deterministic causality has been considered a crucial prerequisite in any fundamental theory in physics. In contrast, the present work investigates stochastic dynamical models for motion in one spatial dimension, in which Newtonian mechanics becomes an emergent property: We present a coherent theory in which a Hamilton-Jacobi equation (HJE) emerges in a description of the evolution of entropy $-\\phi(x,t)=\\epsilon \\log$(Probability) of a system under observation and in the limit of large information extent $\\epsilon^{-1}$ in homogeneous space and time. The variable $\\phi$ represents a non-random high-order statistical concept that is distinct from probability itself as $\\epsilon=0$; the HJE embodies an emergent law of deterministic causality in continuous space and time with an Imaginary Scale symmetry $(t,x,\\phi)\\leftrightarrow (it,ix,i\\phi)$. $\\phi(x,t)$ exhibits a nonlinear wave phenomenon with a mathematical singularity in finite time, overcoming which we introduce viscosity $\\epsilon(\\partial^2\\phi/\\partial x^2)$ and wave $i\\epsilon(\\partial^2 \\phi/\\partial x^2)$ perturbations, articulating dissipation and conservation, which break the Imaginary Scale symmetry: They lead to the Brownian motion and Schr\\\"{o}dinger's equation of motion, respectively. Last but not least, Lagrange's action in classical mechanics acquires an entropic interpretation and Hamilton's principle is established.","sentences":["Since Newton's time, deterministic causality has been considered a crucial prerequisite in any fundamental theory in physics.","In contrast, the present work investigates stochastic dynamical models for motion in one spatial dimension, in which Newtonian mechanics becomes an emergent property: We present a coherent theory in which a Hamilton-Jacobi equation (HJE) emerges in a description of the evolution of entropy $-\\phi(x,t)=\\epsilon \\log$(Probability) of a system under observation and in the limit of large information extent $\\epsilon^{-1}$ in homogeneous space and time.","The variable $\\phi$ represents a non-random high-order statistical concept that is distinct from probability itself as $\\epsilon=0$; the HJE embodies an emergent law of deterministic causality in continuous space and time with an Imaginary Scale symmetry $(t,x,\\phi)\\leftrightarrow (it,ix,i\\phi)$. $\\phi(x,t)$ exhibits a nonlinear wave phenomenon with a mathematical singularity in finite time, overcoming which we introduce viscosity $\\epsilon(\\partial^2\\phi/\\partial x^2)$ and wave $i\\epsilon(\\partial^2 \\phi/\\partial x^2)$","perturbations, articulating dissipation and conservation, which break the Imaginary Scale symmetry: They lead to the Brownian motion and Schr\\\"{o}dinger's equation of motion, respectively.","Last but not least, Lagrange's action in classical mechanics acquires an entropic interpretation and Hamilton's principle is established."],"url":"http://arxiv.org/abs/2406.02405v1","category":"cond-mat.stat-mech"}
{"created":"2024-06-04 15:14:10","title":"Online Fair Allocation of Perishable Resources","abstract":"We consider a practically motivated variant of the canonical online fair allocation problem: a decision-maker has a budget of perishable resources to allocate over a fixed number of rounds. Each round sees a random number of arrivals, and the decision-maker must commit to an allocation for these individuals before moving on to the next round. The goal is to construct a sequence of allocations that is envy-free and efficient. Our work makes two important contributions toward this problem: we first derive strong lower bounds on the optimal envy-efficiency trade-off that demonstrate that a decision-maker is fundamentally limited in what she can hope to achieve relative to the no-perishing setting; we then design an algorithm achieving these lower bounds which takes as input $(i)$ a prediction of the perishing order, and $(ii)$ a desired bound on envy. Given the remaining budget in each period, the algorithm uses forecasts of future demand and perishing to adaptively choose one of two carefully constructed guardrail quantities. We demonstrate our algorithm's strong numerical performance - and state-of-the-art, perishing-agnostic algorithms' inefficacy - on simulations calibrated to a real-world dataset.","sentences":["We consider a practically motivated variant of the canonical online fair allocation problem: a decision-maker has a budget of perishable resources to allocate over a fixed number of rounds.","Each round sees a random number of arrivals, and the decision-maker must commit to an allocation for these individuals before moving on to the next round.","The goal is to construct a sequence of allocations that is envy-free and efficient.","Our work makes two important contributions toward this problem: we first derive strong lower bounds on the optimal envy-efficiency trade-off that demonstrate that a decision-maker is fundamentally limited in what she can hope to achieve relative to the no-perishing setting; we then design an algorithm achieving these lower bounds which takes as input $(i)$ a prediction of the perishing order, and $(ii)$ a desired bound on envy.","Given the remaining budget in each period, the algorithm uses forecasts of future demand and perishing to adaptively choose one of two carefully constructed guardrail quantities.","We demonstrate our algorithm's strong numerical performance - and state-of-the-art, perishing-agnostic algorithms' inefficacy - on simulations calibrated to a real-world dataset."],"url":"http://arxiv.org/abs/2406.02402v1","category":"math.OC"}
{"created":"2024-06-04 15:00:49","title":"Low-Rank Adaption on Transformer-based Oriented Object Detector for Satellite Onboard Processing of Remote Sensing Images","abstract":"Deep learning models in satellite onboard enable real-time interpretation of remote sensing images, reducing the need for data transmission to the ground and conserving communication resources. As satellite numbers and observation frequencies increase, the demand for satellite onboard real-time image interpretation grows, highlighting the expanding importance and development of this technology. However, updating the extensive parameters of models deployed on the satellites for spaceborne object detection model is challenging due to the limitations of uplink bandwidth in wireless satellite communications. To address this issue, this paper proposes a method based on parameter-efficient fine-tuning technology with low-rank adaptation (LoRA) module. It involves training low-rank matrix parameters and integrating them with the original model's weight matrix through multiplication and summation, thereby fine-tuning the model parameters to adapt to new data distributions with minimal weight updates. The proposed method combines parameter-efficient fine-tuning with full fine-tuning in the parameter update strategy of the oriented object detection algorithm architecture. This strategy enables model performance improvements close to full fine-tuning effects with minimal parameter updates. In addition, low rank approximation is conducted to pick an optimal rank value for LoRA matrices. Extensive experiments verify the effectiveness of the proposed method. By fine-tuning and updating only 12.4$\\%$ of the model's total parameters, it is able to achieve 97$\\%$ to 100$\\%$ of the performance of full fine-tuning models. Additionally, the reduced number of trainable parameters accelerates model training iterations and enhances the generalization and robustness of the oriented object detection model. The source code is available at: \\url{https://github.com/fudanxu/LoRA-Det}.","sentences":["Deep learning models in satellite onboard enable real-time interpretation of remote sensing images, reducing the need for data transmission to the ground and conserving communication resources.","As satellite numbers and observation frequencies increase, the demand for satellite onboard real-time image interpretation grows, highlighting the expanding importance and development of this technology.","However, updating the extensive parameters of models deployed on the satellites for spaceborne object detection model is challenging due to the limitations of uplink bandwidth in wireless satellite communications.","To address this issue, this paper proposes a method based on parameter-efficient fine-tuning technology with low-rank adaptation (LoRA) module.","It involves training low-rank matrix parameters and integrating them with the original model's weight matrix through multiplication and summation, thereby fine-tuning the model parameters to adapt to new data distributions with minimal weight updates.","The proposed method combines parameter-efficient fine-tuning with full fine-tuning in the parameter update strategy of the oriented object detection algorithm architecture.","This strategy enables model performance improvements close to full fine-tuning effects with minimal parameter updates.","In addition, low rank approximation is conducted to pick an optimal rank value for LoRA matrices.","Extensive experiments verify the effectiveness of the proposed method.","By fine-tuning and updating only 12.4$\\%$ of the model's total parameters, it is able to achieve 97$\\%$ to 100$\\%$ of the performance of full fine-tuning models.","Additionally, the reduced number of trainable parameters accelerates model training iterations and enhances the generalization and robustness of the oriented object detection model.","The source code is available at: \\url{https://github.com/fudanxu/LoRA-Det}."],"url":"http://arxiv.org/abs/2406.02385v1","category":"cs.CV"}
{"created":"2024-06-04 14:59:52","title":"Second-order optimality conditions for the sparse optimal control of nonviscous Cahn-Hilliard systems","abstract":"In this paper we study the optimal control of an initial-boundary value problem for the classical nonviscous Cahn-Hilliard system with zero Neumann boundary conditions. Phase field systems of this type govern the evolution of diffusive phase transition processes with conserved order parameter. For such systems, optimal control problems have been studied in the past. We focus here on the situation when the cost functional of the optimal control problem contains a sparsity-enhancing nondifferentiable term like the L1-norm. For such cases, we establish first-order necessary and second-order sufficient optimality conditions for locally optimal controls, where in the approach to second-order sufficient conditions we employ a technique introduced by E. Casas, C. Ryll and F. Tr\\\"oltzsch in the paper [SIAM J. Control Optim. 53 (2015), 2168-2202]. The main novelty of this paper is that this method, which has recently been successfully applied to systems of viscous Cahn-Hilliard type, can be adapted also to the classical nonviscous case. Since in the case without viscosity the solutions to the state and adjoint systems turn out to be considerably less regular than in the viscous case, numerous additional technical difficulties have to be overcome, and additional conditions have to be imposed. In particular, we have to restrict ourselves to the case when the nonlinearity driving the phase separation is regular, while in the presence of a viscosity term also nonlinearities of logarithmic type turn could be admitted. In addition, the implicit function theorem, which was employed to establish the needed differentiability properties of the control-to-state operator in the viscous case, does not apply in our situation and has to be substituted by other arguments.","sentences":["In this paper we study the optimal control of an initial-boundary value problem for the classical nonviscous Cahn-Hilliard system with zero Neumann boundary conditions.","Phase field systems of this type govern the evolution of diffusive phase transition processes with conserved order parameter.","For such systems, optimal control problems have been studied in the past.","We focus here on the situation when the cost functional of the optimal control problem contains a sparsity-enhancing nondifferentiable term like the L1-norm.","For such cases, we establish first-order necessary and second-order sufficient optimality conditions for locally optimal controls, where in the approach to second-order sufficient conditions we employ a technique introduced by E. Casas, C. Ryll and F. Tr\\\"oltzsch in the paper [SIAM J. Control Optim.","53 (2015), 2168-2202].","The main novelty of this paper is that this method, which has recently been successfully applied to systems of viscous Cahn-Hilliard type, can be adapted also to the classical nonviscous case.","Since in the case without viscosity the solutions to the state and adjoint systems turn out to be considerably less regular than in the viscous case, numerous additional technical difficulties have to be overcome, and additional conditions have to be imposed.","In particular, we have to restrict ourselves to the case when the nonlinearity driving the phase separation is regular, while in the presence of a viscosity term also nonlinearities of logarithmic type turn could be admitted.","In addition, the implicit function theorem, which was employed to establish the needed differentiability properties of the control-to-state operator in the viscous case, does not apply in our situation and has to be substituted by other arguments."],"url":"http://arxiv.org/abs/2406.02384v1","category":"math.OC"}
{"created":"2024-06-04 14:57:21","title":"Entanglement accelerates quantum simulation","abstract":"Quantum entanglement is an essential feature of many-body systems that impacts both quantum information processing and fundamental physics. The growth of entanglement is a major challenge for classical simulation methods. In this work, we investigate the relationship between quantum entanglement and quantum simulation, showing that product-formula approximations can perform better for entangled systems. We establish a tighter upper bound for algorithmic error in terms of entanglement entropy and develop an adaptive simulation algorithm incorporating measurement gadgets to estimate the algorithmic error. This shows that entanglement is not only an obstacle to classical simulation, but also a feature that can accelerate quantum algorithms.","sentences":["Quantum entanglement is an essential feature of many-body systems that impacts both quantum information processing and fundamental physics.","The growth of entanglement is a major challenge for classical simulation methods.","In this work, we investigate the relationship between quantum entanglement and quantum simulation, showing that product-formula approximations can perform better for entangled systems.","We establish a tighter upper bound for algorithmic error in terms of entanglement entropy and develop an adaptive simulation algorithm incorporating measurement gadgets to estimate the algorithmic error.","This shows that entanglement is not only an obstacle to classical simulation, but also a feature that can accelerate quantum algorithms."],"url":"http://arxiv.org/abs/2406.02379v1","category":"quant-ph"}
{"created":"2024-06-04 14:28:36","title":"System-Aware Neural ODE Processes for Few-Shot Bayesian Optimization","abstract":"We consider the problem of optimizing initial conditions and timing in dynamical systems governed by unknown ordinary differential equations (ODEs), where evaluating different initial conditions is costly and there are constraints on observation times. To identify the optimal conditions within several trials, we introduce a few-shot Bayesian Optimization (BO) framework based on the system's prior information. At the core of our approach is the System-Aware Neural ODE Processes (SANODEP), an extension of Neural ODE Processes (NODEP) designed to meta-learn ODE systems from multiple trajectories using a novel context embedding block. Additionally, we propose a multi-scenario loss function specifically for optimization purposes. Our two-stage BO framework effectively incorporates search space constraints, enabling efficient optimization of both initial conditions and observation timings. We conduct extensive experiments showcasing SANODEP's potential for few-shot BO. We also explore SANODEP's adaptability to varying levels of prior information, highlighting the trade-off between prior flexibility and model fitting accuracy.","sentences":["We consider the problem of optimizing initial conditions and timing in dynamical systems governed by unknown ordinary differential equations (ODEs), where evaluating different initial conditions is costly and there are constraints on observation times.","To identify the optimal conditions within several trials, we introduce a few-shot Bayesian Optimization (BO) framework based on the system's prior information.","At the core of our approach is the System-Aware Neural ODE Processes (SANODEP), an extension of Neural ODE Processes (NODEP) designed to meta-learn ODE systems from multiple trajectories using a novel context embedding block.","Additionally, we propose a multi-scenario loss function specifically for optimization purposes.","Our two-stage BO framework effectively incorporates search space constraints, enabling efficient optimization of both initial conditions and observation timings.","We conduct extensive experiments showcasing SANODEP's potential for few-shot BO.","We also explore SANODEP's adaptability to varying levels of prior information, highlighting the trade-off between prior flexibility and model fitting accuracy."],"url":"http://arxiv.org/abs/2406.02352v1","category":"cs.LG"}
{"created":"2024-06-04 14:24:30","title":"AMOSL: Adaptive Modality-wise Structure Learning in Multi-view Graph Neural Networks For Enhanced Unified Representation","abstract":"While Multi-view Graph Neural Networks (MVGNNs) excel at leveraging diverse modalities for learning object representation, existing methods assume identical local topology structures across modalities that overlook real-world discrepancies. This leads MVGNNs straggles in modality fusion and representations denoising. To address these issues, we propose adaptive modality-wise structure learning (AMoSL). AMoSL captures node correspondences between modalities via optimal transport, and jointly learning with graph embedding. To enable efficient end-to-end training, we employ an efficient solution for the resulting complex bilevel optimization problem. Furthermore, AMoSL adapts to downstream tasks through unsupervised learning on inter-modality distances. The effectiveness of AMoSL is demonstrated by its ability to train more accurate graph classifiers on six benchmark datasets.","sentences":["While Multi-view Graph Neural Networks (MVGNNs) excel at leveraging diverse modalities for learning object representation, existing methods assume identical local topology structures across modalities that overlook real-world discrepancies.","This leads MVGNNs straggles in modality fusion and representations denoising.","To address these issues, we propose adaptive modality-wise structure learning (AMoSL).","AMoSL captures node correspondences between modalities via optimal transport, and jointly learning with graph embedding.","To enable efficient end-to-end training, we employ an efficient solution for the resulting complex bilevel optimization problem.","Furthermore, AMoSL adapts to downstream tasks through unsupervised learning on inter-modality distances.","The effectiveness of AMoSL is demonstrated by its ability to train more accurate graph classifiers on six benchmark datasets."],"url":"http://arxiv.org/abs/2406.02348v1","category":"cs.LG"}
{"created":"2024-06-04 14:23:27","title":"Flash Diffusion: Accelerating Any Conditional Diffusion Model for Few Steps Image Generation","abstract":"In this paper, we propose an efficient, fast, and versatile distillation method to accelerate the generation of pre-trained diffusion models: Flash Diffusion. The method reaches state-of-the-art performances in terms of FID and CLIP-Score for few steps image generation on the COCO2014 and COCO2017 datasets, while requiring only several GPU hours of training and fewer trainable parameters than existing methods. In addition to its efficiency, the versatility of the method is also exposed across several tasks such as text-to-image, inpainting, face-swapping, super-resolution and using different backbones such as UNet-based denoisers (SD1.5, SDXL) or DiT (Pixart-$\\alpha$), as well as adapters. In all cases, the method allowed to reduce drastically the number of sampling steps while maintaining very high-quality image generation. The official implementation is available at https://github.com/gojasper/flash-diffusion.","sentences":["In this paper, we propose an efficient, fast, and versatile distillation method to accelerate the generation of pre-trained diffusion models: Flash Diffusion.","The method reaches state-of-the-art performances in terms of FID and CLIP-Score for few steps image generation on the COCO2014 and COCO2017 datasets, while requiring only several GPU hours of training and fewer trainable parameters than existing methods.","In addition to its efficiency, the versatility of the method is also exposed across several tasks such as text-to-image, inpainting, face-swapping, super-resolution and using different backbones such as UNet-based denoisers (SD1.5, SDXL) or DiT (Pixart-$\\alpha$), as well as adapters.","In all cases, the method allowed to reduce drastically the number of sampling steps while maintaining very high-quality image generation.","The official implementation is available at https://github.com/gojasper/flash-diffusion."],"url":"http://arxiv.org/abs/2406.02347v1","category":"cs.CV"}
{"created":"2024-06-04 14:08:19","title":"Laplacian Renormalization Group: An introduction to heterogeneous coarse-graining","abstract":"The renormalization group (RG) constitutes a fundamental framework in modern theoretical physics. It allows the study of many systems showing states with large-scale correlations and their classification in a relatively small set of universality classes. RG is the most powerful tool for investigating organizational scales within dynamic systems. However, the application of RG techniques to complex networks has presented significant challenges, primarily due to the intricate interplay of correlations on multiple scales. Existing approaches have relied on hypotheses involving hidden geometries and based on embedding complex networks into hidden metric spaces. Here, we present a practical overview of the recently introduced Laplacian Renormalization Group for heterogeneous networks. First, we present a brief overview that justifies the use of the Laplacian as a natural extension for well-known field theories to analyze spatial disorder. We then draw an analogy to traditional real-space renormalization group procedures, explaining how the LRG generalizes the concept of \"Kadanoff supernodes\" as block nodes that span multiple scales. These supernodes help mitigate the effects of cross-scale correlations due to small-world properties. Additionally, we rigorously define the LRG procedure in momentum space in the spirit of Wilson RG. Finally, we show different analyses for the evolution of network properties along the LRG flow following structural changes when the network is properly reduced.","sentences":["The renormalization group (RG) constitutes a fundamental framework in modern theoretical physics.","It allows the study of many systems showing states with large-scale correlations and their classification in a relatively small set of universality classes.","RG is the most powerful tool for investigating organizational scales within dynamic systems.","However, the application of RG techniques to complex networks has presented significant challenges, primarily due to the intricate interplay of correlations on multiple scales.","Existing approaches have relied on hypotheses involving hidden geometries and based on embedding complex networks into hidden metric spaces.","Here, we present a practical overview of the recently introduced Laplacian Renormalization Group for heterogeneous networks.","First, we present a brief overview that justifies the use of the Laplacian as a natural extension for well-known field theories to analyze spatial disorder.","We then draw an analogy to traditional real-space renormalization group procedures, explaining how the LRG generalizes the concept of \"Kadanoff supernodes\" as block nodes that span multiple scales.","These supernodes help mitigate the effects of cross-scale correlations due to small-world properties.","Additionally, we rigorously define the LRG procedure in momentum space in the spirit of Wilson RG.","Finally, we show different analyses for the evolution of network properties along the LRG flow following structural changes when the network is properly reduced."],"url":"http://arxiv.org/abs/2406.02337v1","category":"cond-mat.stat-mech"}
{"created":"2024-06-04 14:06:15","title":"Polynomial-Augmented Neural Networks (PANNs) with Weak Orthogonality Constraints for Enhanced Function and PDE Approximation","abstract":"We present polynomial-augmented neural networks (PANNs), a novel machine learning architecture that combines deep neural networks (DNNs) with a polynomial approximant. PANNs combine the strengths of DNNs (flexibility and efficiency in higher-dimensional approximation) with those of polynomial approximation (rapid convergence rates for smooth functions). To aid in both stable training and enhanced accuracy over a variety of problems, we present (1) a family of orthogonality constraints that impose mutual orthogonality between the polynomial and the DNN within a PANN; (2) a simple basis pruning approach to combat the curse of dimensionality introduced by the polynomial component; and (3) an adaptation of a polynomial preconditioning strategy to both DNNs and polynomials. We test the resulting architecture for its polynomial reproduction properties, ability to approximate both smooth functions and functions of limited smoothness, and as a method for the solution of partial differential equations (PDEs). Through these experiments, we demonstrate that PANNs offer superior approximation properties to DNNs for both regression and the numerical solution of PDEs, while also offering enhanced accuracy over both polynomial and DNN-based regression (each) when regressing functions with limited smoothness.","sentences":["We present polynomial-augmented neural networks (PANNs), a novel machine learning architecture that combines deep neural networks (DNNs) with a polynomial approximant.","PANNs combine the strengths of DNNs (flexibility and efficiency in higher-dimensional approximation) with those of polynomial approximation (rapid convergence rates for smooth functions).","To aid in both stable training and enhanced accuracy over a variety of problems, we present (1) a family of orthogonality constraints that impose mutual orthogonality between the polynomial and the DNN within a PANN; (2) a simple basis pruning approach to combat the curse of dimensionality introduced by the polynomial component; and (3) an adaptation of a polynomial preconditioning strategy to both DNNs and polynomials.","We test the resulting architecture for its polynomial reproduction properties, ability to approximate both smooth functions and functions of limited smoothness, and as a method for the solution of partial differential equations (PDEs).","Through these experiments, we demonstrate that PANNs offer superior approximation properties to DNNs for both regression and the numerical solution of PDEs, while also offering enhanced accuracy over both polynomial and DNN-based regression (each) when regressing functions with limited smoothness."],"url":"http://arxiv.org/abs/2406.02336v1","category":"cs.LG"}
{"created":"2024-06-04 13:57:26","title":"Jet formation model from accretion disks of electron-ion-photon gas","abstract":"The problem of Astrophysical Jet formation from relativistic accretion disks through the establishment of relativistic disk-powerful jet equilibrium structure is studied applying the Beltrami-Bernoulli equilibrium approach of Shatashvili & Yoshida 2011; Arshilava et al. 2019. Accretion disk is weakly magnetized consisting of fully ionized relativistic electron-ion plasma and photon gas strongly coupled to electrons due to Thompson Scattering. %hence, making the behavior of photon gas similar to that of \"a charged fluid\". Analysis is based on the generalized Shakura-Sunyaev $\\alpha $-turbulent dissipation model for local viscosity (being the main source of accretion), in which the contributions from both the photon and ion gases are taken into account. Ignoring the self-gravitation in the disk we constructed the analytical self-similar solutions for the equilibrium relativistic disk-jet structure characteristic parameters in the field of gravitating central compact object for the force-free condition. It is shown, that the magnetic field energy in the Jet is several orders greater compared to that of accretion disk, while jet-outflow is locally Super-Alfv\\'enic with local {\\it Plasma-beta} $< 1$ near the jet-axis. The derived solutions can be used to analyze the astrophysical jets observed in binary systems during the star formation process linking the jet properties with the parameters of relativistic accretion disks of electron-ion-photon gas.","sentences":["The problem of Astrophysical Jet formation from relativistic accretion disks through the establishment of relativistic disk-powerful jet equilibrium structure is studied applying the Beltrami-Bernoulli equilibrium approach of Shatashvili & Yoshida 2011; Arshilava et al. 2019.","Accretion disk is weakly magnetized consisting of fully ionized relativistic electron-ion plasma and photon gas strongly coupled to electrons due to Thompson Scattering.","%hence, making the behavior of photon gas similar to that of \"a charged fluid\".","Analysis is based on the generalized Shakura-Sunyaev $\\alpha $-turbulent dissipation model for local viscosity (being the main source of accretion), in which the contributions from both the photon and ion gases are taken into account.","Ignoring the self-gravitation in the disk we constructed the analytical self-similar solutions for the equilibrium relativistic disk-jet structure characteristic parameters in the field of gravitating central compact object for the force-free condition.","It is shown, that the magnetic field energy in the Jet is several orders greater compared to that of accretion disk, while jet-outflow is locally Super-Alfv\\'enic with local {\\it Plasma-beta} $< 1$ near the jet-axis.","The derived solutions can be used to analyze the astrophysical jets observed in binary systems during the star formation process linking the jet properties with the parameters of relativistic accretion disks of electron-ion-photon gas."],"url":"http://arxiv.org/abs/2406.02326v1","category":"astro-ph.HE"}
{"created":"2024-06-04 13:52:24","title":"A Bayesian nonlinear stationary model with multiple frequencies for business cycle analysis","abstract":"We design a novel, nonlinear single-source-of-error model for analysis of multiple business cycles. The model's specification is intended to capture key empirical characteristics of business cycle data by allowing for simultaneous cycles of different types and lengths, as well as time-variable amplitude and phase shift. The model is shown to feature relevant theoretical properties, including stationarity and pseudo-cyclical autocovariance function, and enables a decomposition of overall cyclic fluctuations into separate frequency-specific components. We develop a Bayesian framework for estimation and inference in the model, along with an MCMC procedure for posterior sampling, combining the Gibbs sampler and the Metropolis-Hastings algorithm, suitably adapted to address encountered numerical issues. Empirical results obtained from the model applied to the Polish GDP growth rates imply co-existence of two types of economic fluctuations: the investment and inventory cycles, and support the stochastic variability of the amplitude and phase shift, also capturing some business cycle asymmetries. Finally, the Bayesian framework enables a fully probabilistic inference on the business cycle clocks and dating, which seems the most relevant approach in view of economic uncertainties.","sentences":["We design a novel, nonlinear single-source-of-error model for analysis of multiple business cycles.","The model's specification is intended to capture key empirical characteristics of business cycle data by allowing for simultaneous cycles of different types and lengths, as well as time-variable amplitude and phase shift.","The model is shown to feature relevant theoretical properties, including stationarity and pseudo-cyclical autocovariance function, and enables a decomposition of overall cyclic fluctuations into separate frequency-specific components.","We develop a Bayesian framework for estimation and inference in the model, along with an MCMC procedure for posterior sampling, combining the Gibbs sampler and the Metropolis-Hastings algorithm, suitably adapted to address encountered numerical issues.","Empirical results obtained from the model applied to the Polish GDP growth rates imply co-existence of two types of economic fluctuations: the investment and inventory cycles, and support the stochastic variability of the amplitude and phase shift, also capturing some business cycle asymmetries.","Finally, the Bayesian framework enables a fully probabilistic inference on the business cycle clocks and dating, which seems the most relevant approach in view of economic uncertainties."],"url":"http://arxiv.org/abs/2406.02321v1","category":"stat.ME"}
{"created":"2024-06-04 13:51:12","title":"Compositional dynamic modelling for causal prediction in multivariate time series","abstract":"Theoretical developments in sequential Bayesian analysis of multivariate dynamic models underlie new methodology for causal prediction. This extends the utility of existing models with computationally efficient methodology, enabling routine exploration of Bayesian counterfactual analyses with multiple selected time series as synthetic controls. Methodological contributions also define the concept of outcome adaptive modelling to monitor and inferentially respond to changes in experimental time series following interventions designed to explore causal effects. The benefits of sequential analyses with time-varying parameter models for causal investigations are inherited in this broader setting. A case study in commercial causal analysis-- involving retail revenue outcomes related to marketing interventions-- highlights the methodological advances.","sentences":["Theoretical developments in sequential Bayesian analysis of multivariate dynamic models underlie new methodology for causal prediction.","This extends the utility of existing models with computationally efficient methodology, enabling routine exploration of Bayesian counterfactual analyses with multiple selected time series as synthetic controls.","Methodological contributions also define the concept of outcome adaptive modelling to monitor and inferentially respond to changes in experimental time series following interventions designed to explore causal effects.","The benefits of sequential analyses with time-varying parameter models for causal investigations are inherited in this broader setting.","A case study in commercial causal analysis-- involving retail revenue outcomes related to marketing interventions-- highlights the methodological advances."],"url":"http://arxiv.org/abs/2406.02320v1","category":"stat.ME"}
{"created":"2024-06-04 13:51:08","title":"PeFAD: A Parameter-Efficient Federated Framework for Time Series Anomaly Detection","abstract":"With the proliferation of mobile sensing techniques, huge amounts of time series data are generated and accumulated in various domains, fueling plenty of real-world applications. In this setting, time series anomaly detection is practically important. It endeavors to identify deviant samples from the normal sample distribution in time series. Existing approaches generally assume that all the time series is available at a central location. However, we are witnessing the decentralized collection of time series due to the deployment of various edge devices. To bridge the gap between the decentralized time series data and the centralized anomaly detection algorithms, we propose a Parameter-efficient Federated Anomaly Detection framework named PeFAD with the increasing privacy concerns. PeFAD for the first time employs the pre-trained language model (PLM) as the body of the client's local model, which can benefit from its cross-modality knowledge transfer capability. To reduce the communication overhead and local model adaptation cost, we propose a parameter-efficient federated training module such that clients only need to fine-tune small-scale parameters and transmit them to the server for update. PeFAD utilizes a novel anomaly-driven mask selection strategy to mitigate the impact of neglected anomalies during training. A knowledge distillation operation on a synthetic privacy-preserving dataset that is shared by all the clients is also proposed to address the data heterogeneity issue across clients. We conduct extensive evaluations on four real datasets, where PeFAD outperforms existing state-of-the-art baselines by up to 28.74\\%.","sentences":["With the proliferation of mobile sensing techniques, huge amounts of time series data are generated and accumulated in various domains, fueling plenty of real-world applications.","In this setting, time series anomaly detection is practically important.","It endeavors to identify deviant samples from the normal sample distribution in time series.","Existing approaches generally assume that all the time series is available at a central location.","However, we are witnessing the decentralized collection of time series due to the deployment of various edge devices.","To bridge the gap between the decentralized time series data and the centralized anomaly detection algorithms, we propose a Parameter-efficient Federated Anomaly Detection framework named PeFAD with the increasing privacy concerns.","PeFAD for the first time employs the pre-trained language model (PLM) as the body of the client's local model, which can benefit from its cross-modality knowledge transfer capability.","To reduce the communication overhead and local model adaptation cost, we propose a parameter-efficient federated training module such that clients only need to fine-tune small-scale parameters and transmit them to the server for update.","PeFAD utilizes a novel anomaly-driven mask selection strategy to mitigate the impact of neglected anomalies during training.","A knowledge distillation operation on a synthetic privacy-preserving dataset that is shared by all the clients is also proposed to address the data heterogeneity issue across clients.","We conduct extensive evaluations on four real datasets, where PeFAD outperforms existing state-of-the-art baselines by up to 28.74\\%."],"url":"http://arxiv.org/abs/2406.02318v1","category":"cs.LG"}
{"created":"2024-06-04 13:44:39","title":"An Independence-promoting Loss for Music Generation with Language Models","abstract":"Music generation schemes using language modeling rely on a vocabulary of audio tokens, generally provided as codes in a discrete latent space learnt by an auto-encoder. Multi-stage quantizers are often employed to produce these tokens, therefore the decoding strategy used for token prediction must be adapted to account for multiple codebooks: either it should model the joint distribution over all codebooks, or fit the product of the codebook marginal distributions. Modelling the joint distribution requires a costly increase in the number of auto-regressive steps, while fitting the product of the marginals yields an inexact model unless the codebooks are mutually independent. In this work, we introduce an independence-promoting loss to regularize the auto-encoder used as the tokenizer in language models for music generation. The proposed loss is a proxy for mutual information based on the maximum mean discrepancy principle, applied in reproducible kernel Hilbert spaces. Our criterion is simple to implement and train, and it is generalizable to other multi-stream codecs. We show that it reduces the statistical dependence between codebooks during auto-encoding. This leads to an increase in the generated music quality when modelling the product of the marginal distributions, while generating audio much faster than the joint distribution model.","sentences":["Music generation schemes using language modeling rely on a vocabulary of audio tokens, generally provided as codes in a discrete latent space learnt by an auto-encoder.","Multi-stage quantizers are often employed to produce these tokens, therefore the decoding strategy used for token prediction must be adapted to account for multiple codebooks: either it should model the joint distribution over all codebooks, or fit the product of the codebook marginal distributions.","Modelling the joint distribution requires a costly increase in the number of auto-regressive steps, while fitting the product of the marginals yields an inexact model unless the codebooks are mutually independent.","In this work, we introduce an independence-promoting loss to regularize the auto-encoder used as the tokenizer in language models for music generation.","The proposed loss is a proxy for mutual information based on the maximum mean discrepancy principle, applied in reproducible kernel Hilbert spaces.","Our criterion is simple to implement and train, and it is generalizable to other multi-stream codecs.","We show that it reduces the statistical dependence between codebooks during auto-encoding.","This leads to an increase in the generated music quality when modelling the product of the marginal distributions, while generating audio much faster than the joint distribution model."],"url":"http://arxiv.org/abs/2406.02315v1","category":"cs.SD"}
{"created":"2024-06-04 13:31:57","title":"Towards AI-Assisted Sustainable Adaptive Video Streaming Systems: Tutorial and Survey","abstract":"Improvements in networking technologies and the steadily increasing numbers of users, as well as the shift from traditional broadcasting to streaming content over the Internet, have made video applications (e.g., live and Video-on-Demand (VoD)) predominant sources of traffic. Recent advances in Artificial Intelligence (AI) and its widespread application in various academic and industrial fields have focused on designing and implementing a variety of video compression and content delivery techniques to improve user Quality of Experience (QoE). However, providing high QoE services results in more energy consumption and carbon footprint across the service delivery path, extending from the end user's device through the network and service infrastructure (e.g., cloud providers). Despite the importance of energy efficiency in video streaming, there is a lack of comprehensive surveys covering state-of-the-art AI techniques and their applications throughout the video streaming lifecycle. Existing surveys typically focus on specific parts, such as video encoding, delivery networks, playback, or quality assessment, without providing a holistic view of the entire lifecycle and its impact on energy consumption and QoE. Motivated by this research gap, this survey provides a comprehensive overview of the video streaming lifecycle, content delivery, energy and Video Quality Assessment (VQA) metrics and models, and AI techniques employed in video streaming. In addition, it conducts an in-depth state-of-the-art analysis focused on AI-driven approaches to enhance the energy efficiency of end-to-end aspects of video streaming systems (i.e., encoding, delivery network, playback, and VQA approaches). Finally, it discusses prospective research directions for developing AI-assisted energy-aware video streaming systems.","sentences":["Improvements in networking technologies and the steadily increasing numbers of users, as well as the shift from traditional broadcasting to streaming content over the Internet, have made video applications (e.g., live and Video-on-Demand (VoD)) predominant sources of traffic.","Recent advances in Artificial Intelligence (AI) and its widespread application in various academic and industrial fields have focused on designing and implementing a variety of video compression and content delivery techniques to improve user Quality of Experience (QoE).","However, providing high QoE services results in more energy consumption and carbon footprint across the service delivery path, extending from the end user's device through the network and service infrastructure (e.g., cloud providers).","Despite the importance of energy efficiency in video streaming, there is a lack of comprehensive surveys covering state-of-the-art AI techniques and their applications throughout the video streaming lifecycle.","Existing surveys typically focus on specific parts, such as video encoding, delivery networks, playback, or quality assessment, without providing a holistic view of the entire lifecycle and its impact on energy consumption and QoE. Motivated by this research gap, this survey provides a comprehensive overview of the video streaming lifecycle, content delivery, energy and Video Quality Assessment (VQA) metrics and models, and AI techniques employed in video streaming.","In addition, it conducts an in-depth state-of-the-art analysis focused on AI-driven approaches to enhance the energy efficiency of end-to-end aspects of video streaming systems (i.e., encoding, delivery network, playback, and VQA approaches).","Finally, it discusses prospective research directions for developing AI-assisted energy-aware video streaming systems."],"url":"http://arxiv.org/abs/2406.02302v1","category":"cs.MM"}
{"created":"2024-06-04 13:11:01","title":"An Axiomatic Approach to Loss Aggregation and an Adapted Aggregating Algorithm","abstract":"Supervised learning has gone beyond the expected risk minimization framework. Central to most of these developments is the introduction of more general aggregation functions for losses incurred by the learner. In this paper, we turn towards online learning under expert advice. Via easily justified assumptions we characterize a set of reasonable loss aggregation functions as quasi-sums. Based upon this insight, we suggest a variant of the Aggregating Algorithm tailored to these more general aggregation functions. This variant inherits most of the nice theoretical properties of the AA, such as recovery of Bayes' updating and a time-independent bound on quasi-sum regret. Finally, we argue that generalized aggregations express the attitude of the learner towards losses.","sentences":["Supervised learning has gone beyond the expected risk minimization framework.","Central to most of these developments is the introduction of more general aggregation functions for losses incurred by the learner.","In this paper, we turn towards online learning under expert advice.","Via easily justified assumptions we characterize a set of reasonable loss aggregation functions as quasi-sums.","Based upon this insight, we suggest a variant of the Aggregating Algorithm tailored to these more general aggregation functions.","This variant inherits most of the nice theoretical properties of the AA, such as recovery of Bayes' updating and a time-independent bound on quasi-sum regret.","Finally, we argue that generalized aggregations express the attitude of the learner towards losses."],"url":"http://arxiv.org/abs/2406.02292v1","category":"cs.LG"}
{"created":"2024-06-04 13:09:12","title":"A deep-learning-based MAC for integrating channel access, rate adaptation and channel switch","abstract":"With increasing density and heterogeneity in unlicensed wireless networks, traditional MAC protocols, such as carrier-sense multiple access with collision avoidance (CSMA/CA) in Wi-Fi networks, are experiencing performance degradation. This is manifested in increased collisions and extended backoff times, leading to diminished spectrum efficiency and protocol coordination. Addressing these issues, this paper proposes a deep-learning-based MAC paradigm, dubbed DL-MAC, which leverages spectrum sensing data readily available from energy detection modules in wireless devices to achieve the MAC functionalities of channel access, rate adaptation and channel switch. First, we utilize DL-MAC to realize a joint design of channel access and rate adaptation. Subsequently, we integrate the capability of channel switch into DL-MAC, enhancing its functionality from single-channel to multi-channel operation. Specifically, the DL-MAC protocol incorporates a deep neural network (DNN) for channel selection and a recurrent neural network (RNN) for the joint design of channel access and rate adaptation. We conducted real-world data collection within the 2.4 GHz frequency band to validate the effectiveness of DL-MAC, and our experiments reveal that DL-MAC exhibits superior performance over traditional algorithms in both single and multi-channel environments and also outperforms single-function approaches in terms of overall performance. Additionally, the performance of DL-MAC remains robust, unaffected by channel switch overhead within the evaluated range.","sentences":["With increasing density and heterogeneity in unlicensed wireless networks, traditional MAC protocols, such as carrier-sense multiple access with collision avoidance (CSMA/CA) in Wi-Fi networks, are experiencing performance degradation.","This is manifested in increased collisions and extended backoff times, leading to diminished spectrum efficiency and protocol coordination.","Addressing these issues, this paper proposes a deep-learning-based MAC paradigm, dubbed DL-MAC, which leverages spectrum sensing data readily available from energy detection modules in wireless devices to achieve the MAC functionalities of channel access, rate adaptation and channel switch.","First, we utilize DL-MAC to realize a joint design of channel access and rate adaptation.","Subsequently, we integrate the capability of channel switch into DL-MAC, enhancing its functionality from single-channel to multi-channel operation.","Specifically, the DL-MAC protocol incorporates a deep neural network (DNN) for channel selection and a recurrent neural network (RNN) for the joint design of channel access and rate adaptation.","We conducted real-world data collection within the 2.4 GHz frequency band to validate the effectiveness of DL-MAC, and our experiments reveal that DL-MAC exhibits superior performance over traditional algorithms in both single and multi-channel environments and also outperforms single-function approaches in terms of overall performance.","Additionally, the performance of DL-MAC remains robust, unaffected by channel switch overhead within the evaluated range."],"url":"http://arxiv.org/abs/2406.02291v1","category":"cs.NI"}
{"created":"2024-06-04 13:05:47","title":"A Study of Optimizations for Fine-tuning Large Language Models","abstract":"Fine-tuning large language models is a popular choice among users trying to adapt them for specific applications. However, fine-tuning these models is a demanding task because the user has to examine several factors, such as resource budget, runtime, model size and context length among others. A specific challenge is that fine-tuning is memory intensive, imposing constraints on the required hardware memory and context length of training data that can be handled. In this work, we share a detailed study on a variety of fine-tuning optimizations across different fine-tuning scenarios. In particular, we assess Gradient Checkpointing, Low Rank Adaptation, DeepSpeed's ZeRO Redundancy Optimizer and Flash Attention. With a focus on memory and runtime, we examine the impact of different optimization combinations on GPU memory usage and execution runtime during fine-tuning phase. We provide recommendation on best default optimization for balancing memory and runtime across diverse model sizes. We share effective strategies for fine-tuning very large models with tens or hundreds of billions of parameters and enabling large context lengths during fine-tuning. Furthermore, we propose the appropriate optimization mixtures for fine-tuning under GPU resource limitations.","sentences":["Fine-tuning large language models is a popular choice among users trying to adapt them for specific applications.","However, fine-tuning these models is a demanding task because the user has to examine several factors, such as resource budget, runtime, model size and context length among others.","A specific challenge is that fine-tuning is memory intensive, imposing constraints on the required hardware memory and context length of training data that can be handled.","In this work, we share a detailed study on a variety of fine-tuning optimizations across different fine-tuning scenarios.","In particular, we assess Gradient Checkpointing, Low Rank Adaptation, DeepSpeed's ZeRO Redundancy Optimizer and Flash Attention.","With a focus on memory and runtime, we examine the impact of different optimization combinations on GPU memory usage and execution runtime during fine-tuning phase.","We provide recommendation on best default optimization for balancing memory and runtime across diverse model sizes.","We share effective strategies for fine-tuning very large models with tens or hundreds of billions of parameters and enabling large context lengths during fine-tuning.","Furthermore, we propose the appropriate optimization mixtures for fine-tuning under GPU resource limitations."],"url":"http://arxiv.org/abs/2406.02290v1","category":"cs.LG"}
{"created":"2024-06-04 12:59:29","title":"How pure can we go with adiabatic state manipulation?","abstract":"Dissipative systems with decoherence free subspaces, a.k.a. dark spaces (DSs), can be used to protect quantum information. At the same time, dissipation is expected to give rise to coherent information degradation outside the DS. Employed to support quantum information platforms, DSs can be adiabatically modified in a way that resembles adiabatic control of coherent systems. Here we study the slow evolution of a purely dissipative system with a spectral gap $\\gamma$, characterized by a strong symmetry, under a cyclic protocol with period $T$. Non-adiabatic corrections to the state evolution give rise to decoherence: the evolution within the instantaneous DS is described by a time-local effective Liouvillian operator that leads to purity degradation over a period, of order $1/\\gamma T$. We obtain a closed form of the latter to order $1/(\\gamma T)^2$. Our analysis underlines speed limitations in quantum information processing in the absence of corrective measures.","sentences":["Dissipative systems with decoherence free subspaces, a.k.a. dark spaces (DSs), can be used to protect quantum information.","At the same time, dissipation is expected to give rise to coherent information degradation outside the DS.","Employed to support quantum information platforms, DSs can be adiabatically modified in a way that resembles adiabatic control of coherent systems.","Here we study the slow evolution of a purely dissipative system with a spectral gap $\\gamma$, characterized by a strong symmetry, under a cyclic protocol with period $T$. Non-adiabatic corrections to the state evolution give rise to decoherence: the evolution within the instantaneous DS is described by a time-local effective Liouvillian operator that leads to purity degradation over a period, of order $1/\\gamma","T$. We obtain a closed form of the latter to order $1/(\\gamma","T)^2$. Our analysis underlines speed limitations in quantum information processing in the absence of corrective measures."],"url":"http://arxiv.org/abs/2406.02286v1","category":"quant-ph"}
{"created":"2024-06-04 12:51:23","title":"Environment-induced Transitions in Many-body Quantum Teleportation","abstract":"Quantum teleportation is a phenomenon arising from entanglement, decisively distinguishing the classical and quantum worlds. The recent success of many-body quantum teleportation is even more surprising: although input information is initially dispersed and encoded into the many-body state in a complex way, the teleportation process can refocus this highly non-local information at the receiver's end. This success manifests intriguing capability of many-body systems in quantum information processing. Current studies indicate that information scrambling, a generic dynamic process in many-body systems, underlies the effectiveness of many-body quantum teleportation. However, this process is known to undergo a novel scrambling-dissipation transition in the presence of environments. How environments affect the quantum information processing capability of many-body systems calls for further investigation. In this work, we study many-body quantum teleportation in the presence of environments. We predict two emergent critical points that hallmark the transitions of the teleportation performance from the quantum regime to the classical regime, and finally to the no-signal regime as the system-environment coupling, quantified by $\\gamma$, increases. In the quantum regime, teleportation can outperform its classical counterparts, while in the classical regime, it can be replaced by a classical channel. Our prediction is based on a generic argument harnessing the relationship between many-body quantum teleportation and information scrambling, corroborated by solvable Brownian Sachdev-Ye-Kitaev models.","sentences":["Quantum teleportation is a phenomenon arising from entanglement, decisively distinguishing the classical and quantum worlds.","The recent success of many-body quantum teleportation is even more surprising: although input information is initially dispersed and encoded into the many-body state in a complex way, the teleportation process can refocus this highly non-local information at the receiver's end.","This success manifests intriguing capability of many-body systems in quantum information processing.","Current studies indicate that information scrambling, a generic dynamic process in many-body systems, underlies the effectiveness of many-body quantum teleportation.","However, this process is known to undergo a novel scrambling-dissipation transition in the presence of environments.","How environments affect the quantum information processing capability of many-body systems calls for further investigation.","In this work, we study many-body quantum teleportation in the presence of environments.","We predict two emergent critical points that hallmark the transitions of the teleportation performance from the quantum regime to the classical regime, and finally to the no-signal regime as the system-environment coupling, quantified by $\\gamma$, increases.","In the quantum regime, teleportation can outperform its classical counterparts, while in the classical regime, it can be replaced by a classical channel.","Our prediction is based on a generic argument harnessing the relationship between many-body quantum teleportation and information scrambling, corroborated by solvable Brownian Sachdev-Ye-Kitaev models."],"url":"http://arxiv.org/abs/2406.02277v1","category":"quant-ph"}
{"created":"2024-06-04 12:29:51","title":"Reinforcement Learning with Lookahead Information","abstract":"We study reinforcement learning (RL) problems in which agents observe the reward or transition realizations at their current state before deciding which action to take. Such observations are available in many applications, including transactions, navigation and more. When the environment is known, previous work shows that this lookahead information can drastically increase the collected reward. However, outside of specific applications, existing approaches for interacting with unknown environments are not well-adapted to these observations. In this work, we close this gap and design provably-efficient learning algorithms able to incorporate lookahead information. To achieve this, we perform planning using the empirical distribution of the reward and transition observations, in contrast to vanilla approaches that only rely on estimated expectations. We prove that our algorithms achieve tight regret versus a baseline that also has access to lookahead information - linearly increasing the amount of collected reward compared to agents that cannot handle lookahead information.","sentences":["We study reinforcement learning (RL) problems in which agents observe the reward or transition realizations at their current state before deciding which action to take.","Such observations are available in many applications, including transactions, navigation and more.","When the environment is known, previous work shows that this lookahead information can drastically increase the collected reward.","However, outside of specific applications, existing approaches for interacting with unknown environments are not well-adapted to these observations.","In this work, we close this gap and design provably-efficient learning algorithms able to incorporate lookahead information.","To achieve this, we perform planning using the empirical distribution of the reward and transition observations, in contrast to vanilla approaches that only rely on estimated expectations.","We prove that our algorithms achieve tight regret versus a baseline that also has access to lookahead information - linearly increasing the amount of collected reward compared to agents that cannot handle lookahead information."],"url":"http://arxiv.org/abs/2406.02258v1","category":"cs.LG"}
{"created":"2024-06-04 11:51:10","title":"Longitudinal Filtering, Sponge Layers, and Equatorial Jet Formation in a General Circulation Model of Gaseous Exoplanets","abstract":"General circulation models are a useful tool in understanding the three dimensional structure of hot Jupiter and sub-Neptune atmospheres; however, understanding the validity of the results from these simulations requires an understanding the artificial dissipation required for numerical stability. In this paper, we investigate the impact of the longitudinal filter and vertical ``sponge'' used in the Met Office's {\\sc Unified Model} when simulating gaseous exoplanets. We demonstrate that excessive dissipation can result in counter-rotating jets and a catastrophic failure to conserve angular momentum. Once the dissipation is reduced to a level where a super-rotating jet forms, however, the jet and thermal structure are relatively insensitive to the dissipation, except in the nightside gyres where temperatures can vary by $\\sim 100\\,\\mathrm{K}$. We do find, however, that flattening the latitudinal profile of the longitudinal filtering alters the results more than a reduction in the strength of the filtering itself. We also show that even in situations where the temperatures are relatively insensitive to the dissipation, the vertical velocities can still vary with the dissipation, potentially impacting physical processes that depend on the local vertical transport.","sentences":["General circulation models are a useful tool in understanding the three dimensional structure of hot Jupiter and sub-Neptune atmospheres; however, understanding the validity of the results from these simulations requires an understanding the artificial dissipation required for numerical stability.","In this paper, we investigate the impact of the longitudinal filter and vertical ``sponge'' used in the Met Office's {\\sc Unified Model} when simulating gaseous exoplanets.","We demonstrate that excessive dissipation can result in counter-rotating jets and a catastrophic failure to conserve angular momentum.","Once the dissipation is reduced to a level where a super-rotating jet forms, however, the jet and thermal structure are relatively insensitive to the dissipation, except in the nightside gyres where temperatures can vary by $\\sim 100\\,\\mathrm{K}$. We do find, however, that flattening the latitudinal profile of the longitudinal filtering alters the results more than a reduction in the strength of the filtering itself.","We also show that even in situations where the temperatures are relatively insensitive to the dissipation, the vertical velocities can still vary with the dissipation, potentially impacting physical processes that depend on the local vertical transport."],"url":"http://arxiv.org/abs/2406.02231v1","category":"astro-ph.EP"}
{"created":"2024-06-04 11:36:09","title":"FedMKT: Federated Mutual Knowledge Transfer for Large and Small Language Models","abstract":"Recent research in federated large language models (LLMs) has primarily focused on enabling clients to fine-tune their locally deployed homogeneous LLMs collaboratively or on transferring knowledge from server-based LLMs to small language models (SLMs) at downstream clients. However, a significant gap remains in the simultaneous mutual enhancement of both the server's LLM and clients' SLMs. To bridge this gap, we propose FedMKT, a parameter-efficient federated mutual knowledge transfer framework for large and small language models. This framework is designed to adaptively transfer knowledge from the server's LLM to clients' SLMs while concurrently enriching the LLM with clients' unique domain insights. We facilitate token alignment using minimum edit distance (MinED) and then selective mutual knowledge transfer between client-side SLMs and a server-side LLM, aiming to collectively enhance their performance. Through extensive experiments across three distinct scenarios, heterogeneous, homogeneous, and one-to-one, we evaluate the effectiveness of FedMKT using various public LLMs and SLMs on a range of NLP text generation tasks. Empirical results demonstrate significant performance improvements in clients' SLMs with the aid of the LLM. Furthermore, the LLM optimized by FedMKT achieves a performance comparable to that achieved through direct fine-tuning based on clients' data, highlighting the effectiveness and adaptability of FedMKT.","sentences":["Recent research in federated large language models (LLMs) has primarily focused on enabling clients to fine-tune their locally deployed homogeneous LLMs collaboratively or on transferring knowledge from server-based LLMs to small language models (SLMs) at downstream clients.","However, a significant gap remains in the simultaneous mutual enhancement of both the server's LLM and clients' SLMs.","To bridge this gap, we propose FedMKT, a parameter-efficient federated mutual knowledge transfer framework for large and small language models.","This framework is designed to adaptively transfer knowledge from the server's LLM to clients' SLMs while concurrently enriching the LLM with clients' unique domain insights.","We facilitate token alignment using minimum edit distance (MinED) and then selective mutual knowledge transfer between client-side SLMs and a server-side LLM, aiming to collectively enhance their performance.","Through extensive experiments across three distinct scenarios, heterogeneous, homogeneous, and one-to-one, we evaluate the effectiveness of FedMKT using various public LLMs and SLMs on a range of NLP text generation tasks.","Empirical results demonstrate significant performance improvements in clients' SLMs with the aid of the LLM.","Furthermore, the LLM optimized by FedMKT achieves a performance comparable to that achieved through direct fine-tuning based on clients' data, highlighting the effectiveness and adaptability of FedMKT."],"url":"http://arxiv.org/abs/2406.02224v1","category":"cs.CL"}
{"created":"2024-06-04 11:14:21","title":"SLTrain: a sparse plus low-rank approach for parameter and memory efficient pretraining","abstract":"Large language models (LLMs) have shown impressive capabilities across various tasks. However, training LLMs from scratch requires significant computational power and extensive memory capacity. Recent studies have explored low-rank structures on weights for efficient fine-tuning in terms of parameters and memory, either through low-rank adaptation or factorization. While effective for fine-tuning, low-rank structures are generally less suitable for pretraining because they restrict parameters to a low-dimensional subspace. In this work, we propose to parameterize the weights as a sum of low-rank and sparse matrices for pretraining, which we call SLTrain. The low-rank component is learned via matrix factorization, while for the sparse component, we employ a simple strategy of uniformly selecting the sparsity support at random and learning only the non-zero entries with the fixed support. While being simple, the random fixed-support sparse learning strategy significantly enhances pretraining when combined with low-rank learning. Our results show that SLTrain adds minimal extra parameters and memory costs compared to pretraining with low-rank parameterization, yet achieves substantially better performance, which is comparable to full-rank training. Remarkably, when combined with quantization and per-layer updates, SLTrain can reduce memory requirements by up to 73% when pretraining the LLaMA 7B model.","sentences":["Large language models (LLMs) have shown impressive capabilities across various tasks.","However, training LLMs from scratch requires significant computational power and extensive memory capacity.","Recent studies have explored low-rank structures on weights for efficient fine-tuning in terms of parameters and memory, either through low-rank adaptation or factorization.","While effective for fine-tuning, low-rank structures are generally less suitable for pretraining because they restrict parameters to a low-dimensional subspace.","In this work, we propose to parameterize the weights as a sum of low-rank and sparse matrices for pretraining, which we call SLTrain.","The low-rank component is learned via matrix factorization, while for the sparse component, we employ a simple strategy of uniformly selecting the sparsity support at random and learning only the non-zero entries with the fixed support.","While being simple, the random fixed-support sparse learning strategy significantly enhances pretraining when combined with low-rank learning.","Our results show that SLTrain adds minimal extra parameters and memory costs compared to pretraining with low-rank parameterization, yet achieves substantially better performance, which is comparable to full-rank training.","Remarkably, when combined with quantization and per-layer updates, SLTrain can reduce memory requirements by up to 73% when pretraining the LLaMA 7B model."],"url":"http://arxiv.org/abs/2406.02214v1","category":"cs.LG"}
{"created":"2024-06-04 11:07:31","title":"An Open and Reconfigurable User Interface to Manage Complex ROS-based Robotic Systems","abstract":"The Robot Operating System (ROS) has significantly gained popularity among robotic engineers and researchers over the past five years, primarily due to its powerful infrastructure for node communication, which enables developers to build modular and large robotic applications. However, ROS presents a steep learning curve and lacks the intuitive usability of vendor-specific robotic Graphical User Interfaces (GUIs). Moreover, its modular and distributed nature complicates the control and monitoring of extensive systems, even for advanced users. To address these challenges, this paper proposes a highly adaptable and reconfigurable web-based GUI for intuitively controlling, monitoring, and configuring complex ROS-based robotic systems. The GUI leverages ROSBridge and roslibjs to ensure seamless communication with ROS systems via topics and services. Designed as a versatile platform, the GUI allows for the selective incorporation of modular features to accommodate diverse robotic systems and applications. An initial set of commonly used features in robotic applications is presented. To demonstrate its reconfigurability, the GUI was customized and tested for four industrial use cases, receiving positive feedback. The project's repository has been made publicly available to support the robotics community and lower the entry barrier for ROS in industrial applications.","sentences":["The Robot Operating System (ROS) has significantly gained popularity among robotic engineers and researchers over the past five years, primarily due to its powerful infrastructure for node communication, which enables developers to build modular and large robotic applications.","However, ROS presents a steep learning curve and lacks the intuitive usability of vendor-specific robotic Graphical User Interfaces (GUIs).","Moreover, its modular and distributed nature complicates the control and monitoring of extensive systems, even for advanced users.","To address these challenges, this paper proposes a highly adaptable and reconfigurable web-based GUI for intuitively controlling, monitoring, and configuring complex ROS-based robotic systems.","The GUI leverages ROSBridge and roslibjs to ensure seamless communication with ROS systems via topics and services.","Designed as a versatile platform, the GUI allows for the selective incorporation of modular features to accommodate diverse robotic systems and applications.","An initial set of commonly used features in robotic applications is presented.","To demonstrate its reconfigurability, the GUI was customized and tested for four industrial use cases, receiving positive feedback.","The project's repository has been made publicly available to support the robotics community and lower the entry barrier for ROS in industrial applications."],"url":"http://arxiv.org/abs/2406.02210v1","category":"cs.RO"}
{"created":"2024-06-04 11:06:13","title":"Why Only Text: Empowering Vision-and-Language Navigation with Multi-modal Prompts","abstract":"Current Vision-and-Language Navigation (VLN) tasks mainly employ textual instructions to guide agents. However, being inherently abstract, the same textual instruction can be associated with different visual signals, causing severe ambiguity and limiting the transfer of prior knowledge in the vision domain from the user to the agent. To fill this gap, we propose Vision-and-Language Navigation with Multi-modal Prompts (VLN-MP), a novel task augmenting traditional VLN by integrating both natural language and images in instructions. VLN-MP not only maintains backward compatibility by effectively handling text-only prompts but also consistently shows advantages with different quantities and relevance of visual prompts. Possible forms of visual prompts include both exact and similar object images, providing adaptability and versatility in diverse navigation scenarios. To evaluate VLN-MP under a unified framework, we implement a new benchmark that offers: (1) a training-free pipeline to transform textual instructions into multi-modal forms with landmark images; (2) diverse datasets with multi-modal instructions for different downstream tasks; (3) a novel module designed to process various image prompts for seamless integration with state-of-the-art VLN models. Extensive experiments on four VLN benchmarks (R2R, RxR, REVERIE, CVDN) show that incorporating visual prompts significantly boosts navigation performance. While maintaining efficiency with text-only prompts, VLN-MP enables agents to navigate in the pre-explore setting and outperform text-based models, showing its broader applicability.","sentences":["Current Vision-and-Language Navigation (VLN) tasks mainly employ textual instructions to guide agents.","However, being inherently abstract, the same textual instruction can be associated with different visual signals, causing severe ambiguity and limiting the transfer of prior knowledge in the vision domain from the user to the agent.","To fill this gap, we propose Vision-and-Language Navigation with Multi-modal Prompts (VLN-MP), a novel task augmenting traditional VLN by integrating both natural language and images in instructions.","VLN-MP not only maintains backward compatibility by effectively handling text-only prompts but also consistently shows advantages with different quantities and relevance of visual prompts.","Possible forms of visual prompts include both exact and similar object images, providing adaptability and versatility in diverse navigation scenarios.","To evaluate VLN-MP under a unified framework, we implement a new benchmark that offers: (1) a training-free pipeline to transform textual instructions into multi-modal forms with landmark images; (2) diverse datasets with multi-modal instructions for different downstream tasks; (3) a novel module designed to process various image prompts for seamless integration with state-of-the-art VLN models.","Extensive experiments on four VLN benchmarks (R2R, RxR, REVERIE, CVDN) show that incorporating visual prompts significantly boosts navigation performance.","While maintaining efficiency with text-only prompts, VLN-MP enables agents to navigate in the pre-explore setting and outperform text-based models, showing its broader applicability."],"url":"http://arxiv.org/abs/2406.02208v1","category":"cs.CV"}
{"created":"2024-06-04 11:02:15","title":"Query-Enhanced Adaptive Semantic Path Reasoning for Inductive Knowledge Graph Completion","abstract":"Conventional Knowledge graph completion (KGC) methods aim to infer missing information in incomplete Knowledge Graphs (KGs) by leveraging existing information, which struggle to perform effectively in scenarios involving emerging entities. Inductive KGC methods can handle the emerging entities and relations in KGs, offering greater dynamic adaptability. While existing inductive KGC methods have achieved some success, they also face challenges, such as susceptibility to noisy structural information during reasoning and difficulty in capturing long-range dependencies in reasoning paths. To address these challenges, this paper proposes the Query-Enhanced Adaptive Semantic Path Reasoning (QASPR) framework, which simultaneously captures both the structural and semantic information of KGs to enhance the inductive KGC task. Specifically, the proposed QASPR employs a query-dependent masking module to adaptively mask noisy structural information while retaining important information closely related to the targets. Additionally, QASPR introduces a global semantic scoring module that evaluates both the individual contributions and the collective impact of nodes along the reasoning path within KGs. The experimental results demonstrate that QASPR achieves state-of-the-art performance.","sentences":["Conventional Knowledge graph completion (KGC) methods aim to infer missing information in incomplete Knowledge Graphs (KGs) by leveraging existing information, which struggle to perform effectively in scenarios involving emerging entities.","Inductive KGC methods can handle the emerging entities and relations in KGs, offering greater dynamic adaptability.","While existing inductive KGC methods have achieved some success, they also face challenges, such as susceptibility to noisy structural information during reasoning and difficulty in capturing long-range dependencies in reasoning paths.","To address these challenges, this paper proposes the Query-Enhanced Adaptive Semantic Path Reasoning (QASPR) framework, which simultaneously captures both the structural and semantic information of KGs to enhance the inductive KGC task.","Specifically, the proposed QASPR employs a query-dependent masking module to adaptively mask noisy structural information while retaining important information closely related to the targets.","Additionally, QASPR introduces a global semantic scoring module that evaluates both the individual contributions and the collective impact of nodes along the reasoning path within KGs.","The experimental results demonstrate that QASPR achieves state-of-the-art performance."],"url":"http://arxiv.org/abs/2406.02205v1","category":"cs.AI"}
{"created":"2024-06-04 10:56:56","title":"Porting the grid-based 3D+3V hybrid-Vlasov kinetic plasma simulation Vlasiator to heterogeneous GPU architectures","abstract":"Vlasiator is a space plasma simulation code which models near-Earth ion-kinetic dynamics in three spatial and three velocity dimensions. It is highly parallelized, modeling the Vlasov equation directly through the distribution function, discretized on a Cartesian grid, instead of the more common particle-in-cell approach. Modeling near-Earth space, plasma properties span several orders of magnitude in temperature, density, and magnetic field strength. In order to fit the required six-dimensional grids in memory, Vlasiator utilizes a sparse block-based velocity mesh, where chunks of velocity space are added or deleted based on the advection requirements of the Vlasov solver. In addition, the spatial mesh is adaptively refined through cell-based octree refinement. In this paper, we describe the design choices of porting Vlasiator to heterogeneous CPU/GPU architectures. We detail the memory management, algorithmic changes, and kernel construction as well as our unified codebase approach, resulting in portability to both NVIDIA and AMD hardware (CUDA and HIP languages, respectively). In particular, we showcase a highly parallel block adjustment approach allowing efficient re-ordering of a sparse velocity mesh. We detail pitfalls we have overcome and lay out a plan for optimization to facilitate future exascale simulations using multi-node GPU supercomputing.","sentences":["Vlasiator is a space plasma simulation code which models near-Earth ion-kinetic dynamics in three spatial and three velocity dimensions.","It is highly parallelized, modeling the Vlasov equation directly through the distribution function, discretized on a Cartesian grid, instead of the more common particle-in-cell approach.","Modeling near-Earth space, plasma properties span several orders of magnitude in temperature, density, and magnetic field strength.","In order to fit the required six-dimensional grids in memory, Vlasiator utilizes a sparse block-based velocity mesh, where chunks of velocity space are added or deleted based on the advection requirements of the Vlasov solver.","In addition, the spatial mesh is adaptively refined through cell-based octree refinement.","In this paper, we describe the design choices of porting Vlasiator to heterogeneous CPU/GPU architectures.","We detail the memory management, algorithmic changes, and kernel construction as well as our unified codebase approach, resulting in portability to both NVIDIA and AMD hardware (CUDA and HIP languages, respectively).","In particular, we showcase a highly parallel block adjustment approach allowing efficient re-ordering of a sparse velocity mesh.","We detail pitfalls we have overcome and lay out a plan for optimization to facilitate future exascale simulations using multi-node GPU supercomputing."],"url":"http://arxiv.org/abs/2406.02201v1","category":"physics.comp-ph"}
{"created":"2024-06-04 10:34:40","title":"Age of Trust (AoT): A Continuous Verification Framework for Wireless Networks","abstract":"Zero Trust is a new security vision for 6G networks that emphasises the philosophy of never trust and always verify. However, there is a fundamental trade-off between the wireless transmission efficiency and the trust level, which is reflected by the verification interval and its adaptation strategy. More importantly, the mathematical framework to characterise the trust level of the adaptive verification strategy is still missing. Inspired by this vision, we propose a concept called age of trust (AoT) to capture the characteristics of the trust level degrading over time, with the definition of the time elapsed since the last verification of the target user's trust plus the initial age, which depends on the trust level evaluated at that verification. The higher the trust level, the lower the initial age. To evaluate the trust level in the long term, the average AoT is used. We then investigate how to find a compromise between average AoT and wireless transmission efficiency with limited resources. In particular, we address the bi-objective optimization (BOO) problem between average AoT and throughput over a single link with arbitrary service process, where the identity of the receiver is constantly verified, and we devise a periodic verification scheme and a Q-learning-based scheme for constant process and random process, respectively. We also tackle the BOO problem in a multiple random access scenario, where a trust-enhanced frame-slotted ALOHA is designed. Finally, the numerical results show that our proposals can achieve a fair compromise between trust level and wireless transmission efficiency, and thus have a wide application prospect in various zero-trust architectures.","sentences":["Zero Trust is a new security vision for 6G networks that emphasises the philosophy of never trust and always verify.","However, there is a fundamental trade-off between the wireless transmission efficiency and the trust level, which is reflected by the verification interval and its adaptation strategy.","More importantly, the mathematical framework to characterise the trust level of the adaptive verification strategy is still missing.","Inspired by this vision, we propose a concept called age of trust (AoT) to capture the characteristics of the trust level degrading over time, with the definition of the time elapsed since the last verification of the target user's trust plus the initial age, which depends on the trust level evaluated at that verification.","The higher the trust level, the lower the initial age.","To evaluate the trust level in the long term, the average AoT is used.","We then investigate how to find a compromise between average AoT and wireless transmission efficiency with limited resources.","In particular, we address the bi-objective optimization (BOO) problem between average AoT and throughput over a single link with arbitrary service process, where the identity of the receiver is constantly verified, and we devise a periodic verification scheme and a Q-learning-based scheme for constant process and random process, respectively.","We also tackle the BOO problem in a multiple random access scenario, where a trust-enhanced frame-slotted ALOHA is designed.","Finally, the numerical results show that our proposals can achieve a fair compromise between trust level and wireless transmission efficiency, and thus have a wide application prospect in various zero-trust architectures."],"url":"http://arxiv.org/abs/2406.02190v1","category":"eess.SY"}
{"created":"2024-06-04 10:00:46","title":"A Multipurpose Interface for Close- and Far-Proximity Control of Mobile Collaborative Robots","abstract":"This letter introduces an innovative visuo-haptic interface to control Mobile Collaborative Robots (MCR). Thanks to a passive detachable mechanism, the interface can be attached/detached from a robot, offering two control modes: local control (attached) and teleoperation (detached). These modes are integrated with a robot whole-body controller and presented in a unified close- and far-proximity control framework for MCR. The earlier introduction of the haptic component in this interface enabled users to execute intricate loco-manipulation tasks via admittance-type control, effectively decoupling task dynamics and enhancing human capabilities. In contrast, this ongoing work proposes a novel design that integrates a visual component. This design utilizes Visual-Inertial Odometry (VIO) for teleoperation, estimating the interface's pose through stereo cameras and an Inertial Measurement Unit (IMU). The estimated pose serves as the reference for the robot's end-effector in teleoperation mode. Hence, the interface offers complete flexibility and adaptability, enabling any user to operate an MCR seamlessly without needing expert knowledge. In this letter, we primarily focus on the new visual feature, and first present a performance evaluation of different VIO-based methods for teleoperation. Next, the interface's usability is analyzed in a home-care application and compared to an alternative designed by a commercial MoCap system. Results show comparable performance in terms of accuracy, completion time, and usability. Nevertheless, the proposed interface is low-cost, poses minimal wearability constraints, and can be used anywhere and anytime without needing external devices or additional equipment, offering a versatile and accessible solution for teleoperation.","sentences":["This letter introduces an innovative visuo-haptic interface to control Mobile Collaborative Robots (MCR).","Thanks to a passive detachable mechanism, the interface can be attached/detached from a robot, offering two control modes: local control (attached) and teleoperation (detached).","These modes are integrated with a robot whole-body controller and presented in a unified close- and far-proximity control framework for MCR.","The earlier introduction of the haptic component in this interface enabled users to execute intricate loco-manipulation tasks via admittance-type control, effectively decoupling task dynamics and enhancing human capabilities.","In contrast, this ongoing work proposes a novel design that integrates a visual component.","This design utilizes Visual-Inertial Odometry (VIO) for teleoperation, estimating the interface's pose through stereo cameras and an Inertial Measurement Unit (IMU).","The estimated pose serves as the reference for the robot's end-effector in teleoperation mode.","Hence, the interface offers complete flexibility and adaptability, enabling any user to operate an MCR seamlessly without needing expert knowledge.","In this letter, we primarily focus on the new visual feature, and first present a performance evaluation of different VIO-based methods for teleoperation.","Next, the interface's usability is analyzed in a home-care application and compared to an alternative designed by a commercial MoCap system.","Results show comparable performance in terms of accuracy, completion time, and usability.","Nevertheless, the proposed interface is low-cost, poses minimal wearability constraints, and can be used anywhere and anytime without needing external devices or additional equipment, offering a versatile and accessible solution for teleoperation."],"url":"http://arxiv.org/abs/2406.02171v1","category":"cs.RO"}
{"created":"2024-06-04 09:35:47","title":"Synergetic Event Understanding: A Collaborative Approach to Cross-Document Event Coreference Resolution with Large Language Models","abstract":"Cross-document event coreference resolution (CDECR) involves clustering event mentions across multiple documents that refer to the same real-world events. Existing approaches utilize fine-tuning of small language models (SLMs) like BERT to address the compatibility among the contexts of event mentions. However, due to the complexity and diversity of contexts, these models are prone to learning simple co-occurrences. Recently, large language models (LLMs) like ChatGPT have demonstrated impressive contextual understanding, yet they encounter challenges in adapting to specific information extraction (IE) tasks. In this paper, we propose a collaborative approach for CDECR, leveraging the capabilities of both a universally capable LLM and a task-specific SLM. The collaborative strategy begins with the LLM accurately and comprehensively summarizing events through prompting. Then, the SLM refines its learning of event representations based on these insights during fine-tuning. Experimental results demonstrate that our approach surpasses the performance of both the large and small language models individually, forming a complementary advantage. Across various datasets, our approach achieves state-of-the-art performance, underscoring its effectiveness in diverse scenarios.","sentences":["Cross-document event coreference resolution (CDECR) involves clustering event mentions across multiple documents that refer to the same real-world events.","Existing approaches utilize fine-tuning of small language models (SLMs) like BERT to address the compatibility among the contexts of event mentions.","However, due to the complexity and diversity of contexts, these models are prone to learning simple co-occurrences.","Recently, large language models (LLMs) like ChatGPT have demonstrated impressive contextual understanding, yet they encounter challenges in adapting to specific information extraction (IE) tasks.","In this paper, we propose a collaborative approach for CDECR, leveraging the capabilities of both a universally capable LLM and a task-specific SLM.","The collaborative strategy begins with the LLM accurately and comprehensively summarizing events through prompting.","Then, the SLM refines its learning of event representations based on these insights during fine-tuning.","Experimental results demonstrate that our approach surpasses the performance of both the large and small language models individually, forming a complementary advantage.","Across various datasets, our approach achieves state-of-the-art performance, underscoring its effectiveness in diverse scenarios."],"url":"http://arxiv.org/abs/2406.02148v1","category":"cs.CL"}
{"created":"2024-06-04 09:32:08","title":"The continuity equation in the Heisenberg-periodic case: a representation formula and an application to Mean Field Games","abstract":"We provide a representation of the weak solution of the continuity equation on the Heisenberg group $\\mathbb H^1$ with periodic data (the periodicity is suitably adapted to the group law). This solution is the push forward of a measure concentrated on the flux associated with the drift of the continuity equation. Furthermore, we shall use this interpretation for proving that weak solutions to first order Mean Field Games on $\\mathbb H^1$ are also mild solutions.","sentences":["We provide a representation of the weak solution of the continuity equation on the Heisenberg group $\\mathbb H^1$ with periodic data (the periodicity is suitably adapted to the group law).","This solution is the push forward of a measure concentrated on the flux associated with the drift of the continuity equation.","Furthermore, we shall use this interpretation for proving that weak solutions to first order Mean Field Games on $\\mathbb H^1$ are also mild solutions."],"url":"http://arxiv.org/abs/2406.02145v1","category":"math.AP"}
{"created":"2024-06-04 09:18:20","title":"CondTSF: One-line Plugin of Dataset Condensation for Time Series Forecasting","abstract":"Dataset condensation is a newborn technique that generates a small dataset that can be used in training deep neural networks to lower training costs. The objective of dataset condensation is to ensure that the model trained with the synthetic dataset can perform comparably to the model trained with full datasets. However, existing methods predominantly concentrate on classification tasks, posing challenges in their adaptation to time series forecasting (TS-forecasting). This challenge arises from disparities in the evaluation of synthetic data. In classification, the synthetic data is considered well-distilled if the model trained with the full dataset and the model trained with the synthetic dataset yield identical labels for the same input, regardless of variations in output logits distribution. Conversely, in TS-forecasting, the effectiveness of synthetic data distillation is determined by the distance between predictions of the two models. The synthetic data is deemed well-distilled only when all data points within the predictions are similar. Consequently, TS-forecasting has a more rigorous evaluation methodology compared to classification. To mitigate this gap, we theoretically analyze the optimization objective of dataset condensation for TS-forecasting and propose a new one-line plugin of dataset condensation designated as Dataset Condensation for Time Series Forecasting (CondTSF) based on our analysis. Plugging CondTSF into previous dataset condensation methods facilitates a reduction in the distance between the predictions of the model trained with the full dataset and the model trained with the synthetic dataset, thereby enhancing performance. We conduct extensive experiments on eight commonly used time series datasets. CondTSF consistently improves the performance of all previous dataset condensation methods across all datasets, particularly at low condensing ratios.","sentences":["Dataset condensation is a newborn technique that generates a small dataset that can be used in training deep neural networks to lower training costs.","The objective of dataset condensation is to ensure that the model trained with the synthetic dataset can perform comparably to the model trained with full datasets.","However, existing methods predominantly concentrate on classification tasks, posing challenges in their adaptation to time series forecasting (TS-forecasting).","This challenge arises from disparities in the evaluation of synthetic data.","In classification, the synthetic data is considered well-distilled if the model trained with the full dataset and the model trained with the synthetic dataset yield identical labels for the same input, regardless of variations in output logits distribution.","Conversely, in TS-forecasting, the effectiveness of synthetic data distillation is determined by the distance between predictions of the two models.","The synthetic data is deemed well-distilled only when all data points within the predictions are similar.","Consequently, TS-forecasting has a more rigorous evaluation methodology compared to classification.","To mitigate this gap, we theoretically analyze the optimization objective of dataset condensation for TS-forecasting and propose a new one-line plugin of dataset condensation designated as Dataset Condensation for Time Series Forecasting (CondTSF) based on our analysis.","Plugging CondTSF into previous dataset condensation methods facilitates a reduction in the distance between the predictions of the model trained with the full dataset and the model trained with the synthetic dataset, thereby enhancing performance.","We conduct extensive experiments on eight commonly used time series datasets.","CondTSF consistently improves the performance of all previous dataset condensation methods across all datasets, particularly at low condensing ratios."],"url":"http://arxiv.org/abs/2406.02131v2","category":"cs.LG"}
{"created":"2024-06-04 09:09:54","title":"Measuring the Dispersion of Discrete Distributions","abstract":"Measuring dispersion is among the most fundamental and ubiquitous concepts in statistics, both in applied and theoretical contexts. In order to ensure that dispersion measures like the standard deviation indeed capture the dispersion of any given distribution, they are by definition required to preserve a stochastic order of dispersion. The most basic order that functions as a foundation underneath the concept of dispersion measures is the so-called dispersive order. However, that order is incompatible with almost all discrete distributions, including all lattice distributions and most empirical distributions. Thus, there is no guarantee that popular measures properly capture the dispersion of these distributions.   In this paper, discrete adaptations of the dispersive order are derived and analyzed. Their derivation is directly informed by key properties of the dispersive order in order to obtain a foundation for the measurement of discrete dispersion that is as similar as possible to the continuous setting. Two slightly different orders are obtained that both have numerous properties that the original dispersive order also has. Their behaviour on well-known families of lattice distribution is generally as expected if the parameter differences are large enough. Most popular dispersion measures preserve both discrete dispersive orders, which rigorously ensures that they are also meaningful in discrete settings. However, the interquantile range preserves neither discrete order, yielding that it should not be used to measure the dispersion of discrete distributions.","sentences":["Measuring dispersion is among the most fundamental and ubiquitous concepts in statistics, both in applied and theoretical contexts.","In order to ensure that dispersion measures like the standard deviation indeed capture the dispersion of any given distribution, they are by definition required to preserve a stochastic order of dispersion.","The most basic order that functions as a foundation underneath the concept of dispersion measures is the so-called dispersive order.","However, that order is incompatible with almost all discrete distributions, including all lattice distributions and most empirical distributions.","Thus, there is no guarantee that popular measures properly capture the dispersion of these distributions.   ","In this paper, discrete adaptations of the dispersive order are derived and analyzed.","Their derivation is directly informed by key properties of the dispersive order in order to obtain a foundation for the measurement of discrete dispersion that is as similar as possible to the continuous setting.","Two slightly different orders are obtained that both have numerous properties that the original dispersive order also has.","Their behaviour on well-known families of lattice distribution is generally as expected if the parameter differences are large enough.","Most popular dispersion measures preserve both discrete dispersive orders, which rigorously ensures that they are also meaningful in discrete settings.","However, the interquantile range preserves neither discrete order, yielding that it should not be used to measure the dispersion of discrete distributions."],"url":"http://arxiv.org/abs/2406.02124v1","category":"stat.ME"}
{"created":"2024-06-04 09:02:22","title":"Diver: Large Language Model Decoding with Span-Level Mutual Information Verification","abstract":"Large language models (LLMs) have shown impressive capabilities in adapting to various tasks when provided with task-specific instructions. However, LLMs using standard decoding strategies often struggle with deviations from the inputs. Intuitively, compliant LLM outputs should reflect the information present in the input, which can be measured by point-wise mutual information (PMI) scores. Therefore, we propose Diver, a novel approach that enhances LLM Decoding through span-level PMI verification. During inference, Diver first identifies divergence steps that may lead to multiple candidate spans. Subsequently, it calculates the PMI scores by assessing the log-likelihood gains of the input if the candidate spans are generated. Finally, the optimal span is selected based on the PMI re-ranked output distributions. We evaluate our method across various downstream tasks, and empirical results demonstrate that Diver significantly outperforms existing decoding methods in both performance and versatility.","sentences":["Large language models (LLMs) have shown impressive capabilities in adapting to various tasks when provided with task-specific instructions.","However, LLMs using standard decoding strategies often struggle with deviations from the inputs.","Intuitively, compliant LLM outputs should reflect the information present in the input, which can be measured by point-wise mutual information (PMI) scores.","Therefore, we propose Diver, a novel approach that enhances LLM Decoding through span-level PMI verification.","During inference, Diver first identifies divergence steps that may lead to multiple candidate spans.","Subsequently, it calculates the PMI scores by assessing the log-likelihood gains of the input if the candidate spans are generated.","Finally, the optimal span is selected based on the PMI re-ranked output distributions.","We evaluate our method across various downstream tasks, and empirical results demonstrate that Diver significantly outperforms existing decoding methods in both performance and versatility."],"url":"http://arxiv.org/abs/2406.02120v1","category":"cs.CL"}
{"created":"2024-06-04 08:36:39","title":"UniOQA: A Unified Framework for Knowledge Graph Question Answering with Large Language Models","abstract":"OwnThink stands as the most extensive Chinese open-domain knowledge graph introduced in recent times. Despite prior attempts in question answering over OwnThink (OQA), existing studies have faced limitations in model representation capabilities, posing challenges in further enhancing overall accuracy in question answering. In this paper, we introduce UniOQA, a unified framework that integrates two complementary parallel workflows. Unlike conventional approaches, UniOQA harnesses large language models (LLMs) for precise question answering and incorporates a direct-answer-prediction process as a cost-effective complement. Initially, to bolster representation capacity, we fine-tune an LLM to translate questions into the Cypher query language (CQL), tackling issues associated with restricted semantic understanding and hallucinations. Subsequently, we introduce the Entity and Relation Replacement algorithm to ensure the executability of the generated CQL. Concurrently, to augment overall accuracy in question answering, we further adapt the Retrieval-Augmented Generation (RAG) process to the knowledge graph. Ultimately, we optimize answer accuracy through a dynamic decision algorithm. Experimental findings illustrate that UniOQA notably advances SpCQL Logical Accuracy to 21.2% and Execution Accuracy to 54.9%, achieving the new state-of-the-art results on this benchmark. Through ablation experiments, we delve into the superior representation capacity of UniOQA and quantify its performance breakthrough.","sentences":["OwnThink stands as the most extensive Chinese open-domain knowledge graph introduced in recent times.","Despite prior attempts in question answering over OwnThink (OQA), existing studies have faced limitations in model representation capabilities, posing challenges in further enhancing overall accuracy in question answering.","In this paper, we introduce UniOQA, a unified framework that integrates two complementary parallel workflows.","Unlike conventional approaches, UniOQA harnesses large language models (LLMs) for precise question answering and incorporates a direct-answer-prediction process as a cost-effective complement.","Initially, to bolster representation capacity, we fine-tune an LLM to translate questions into the Cypher query language (CQL), tackling issues associated with restricted semantic understanding and hallucinations.","Subsequently, we introduce the Entity and Relation Replacement algorithm to ensure the executability of the generated CQL.","Concurrently, to augment overall accuracy in question answering, we further adapt the Retrieval-Augmented Generation (RAG) process to the knowledge graph.","Ultimately, we optimize answer accuracy through a dynamic decision algorithm.","Experimental findings illustrate that UniOQA notably advances SpCQL Logical Accuracy to 21.2% and Execution Accuracy to 54.9%, achieving the new state-of-the-art results on this benchmark.","Through ablation experiments, we delve into the superior representation capacity of UniOQA and quantify its performance breakthrough."],"url":"http://arxiv.org/abs/2406.02110v1","category":"cs.CL"}
{"created":"2024-06-04 08:33:56","title":"Kernel vs. Kernel: Exploring How the Data Structure Affects Neural Collapse","abstract":"Recently, a vast amount of literature has focused on the \"Neural Collapse\" (NC) phenomenon, which emerges when training neural network (NN) classifiers beyond the zero training error point. The core component of NC is the decrease in the within class variability of the network's deepest features, dubbed as NC1. The theoretical works that study NC are typically based on simplified unconstrained features models (UFMs) that mask any effect of the data on the extent of collapse. In this paper, we provide a kernel-based analysis that does not suffer from this limitation. First, given a kernel function, we establish expressions for the traces of the within- and between-class covariance matrices of the samples' features (and consequently an NC1 metric). Then, we turn to focus on kernels associated with shallow NNs. First, we consider the NN Gaussian Process kernel (NNGP), associated with the network at initialization, and the complement Neural Tangent Kernel (NTK), associated with its training in the \"lazy regime\". Interestingly, we show that the NTK does not represent more collapsed features than the NNGP for prototypical data models. As NC emerges from training, we then consider an alternative to NTK: the recently proposed adaptive kernel, which generalizes NNGP to model the feature mapping learned from the training data. Contrasting our NC1 analysis for these two kernels enables gaining insights into the effect of data distribution on the extent of collapse, which are empirically aligned with the behavior observed with practical training of NNs.","sentences":["Recently, a vast amount of literature has focused on the \"Neural Collapse\" (NC) phenomenon, which emerges when training neural network (NN) classifiers beyond the zero training error point.","The core component of NC is the decrease in the within class variability of the network's deepest features, dubbed as NC1.","The theoretical works that study NC are typically based on simplified unconstrained features models (UFMs) that mask any effect of the data on the extent of collapse.","In this paper, we provide a kernel-based analysis that does not suffer from this limitation.","First, given a kernel function, we establish expressions for the traces of the within- and between-class covariance matrices of the samples' features (and consequently an NC1 metric).","Then, we turn to focus on kernels associated with shallow NNs.","First, we consider the NN Gaussian Process kernel (NNGP), associated with the network at initialization, and the complement Neural Tangent Kernel (NTK), associated with its training in the \"lazy regime\".","Interestingly, we show that the NTK does not represent more collapsed features than the NNGP for prototypical data models.","As NC emerges from training, we then consider an alternative to NTK: the recently proposed adaptive kernel, which generalizes NNGP to model the feature mapping learned from the training data.","Contrasting our NC1 analysis for these two kernels enables gaining insights into the effect of data distribution on the extent of collapse, which are empirically aligned with the behavior observed with practical training of NNs."],"url":"http://arxiv.org/abs/2406.02105v1","category":"cs.LG"}
{"created":"2024-06-04 08:17:47","title":"How Western, Educated, Industrialized, Rich, and Democratic is Social Computing Research?","abstract":"Much of the research in social computing analyzes data from social media platforms, which may inherently carry biases. An overlooked source of such bias is the over-representation of WEIRD (Western, Educated, Industrialized, Rich, and Democratic) populations, which might not accurately mirror the global demographic diversity. We evaluated the dependence on WEIRD populations in research presented at the AAAI ICWSM conference; the only venue whose proceedings are fully dedicated to social computing research. We did so by analyzing 494 papers published from 2018 to 2022, which included full research papers, dataset papers and posters. After filtering out papers that analyze synthetic datasets or those lacking clear country of origin, we were left with 420 papers from which 188 participants in a crowdsourcing study with full manual validation extracted data for the WEIRD scores computation. This data was then used to adapt existing WEIRD metrics to be applicable for social media data. We found that 37% of these papers focused solely on data from Western countries. This percentage is significantly less than the percentages observed in research from CHI (76%) and FAccT (84%) conferences, suggesting a greater diversity of dataset origins within ICWSM. However, the studies at ICWSM still predominantly examine populations from countries that are more Educated, Industrialized, and Rich in comparison to those in FAccT, with a special note on the 'Democratic' variable reflecting political freedoms and rights. This points out the utility of social media data in shedding light on findings from countries with restricted political freedoms. Based on these insights, we recommend extensions of current \"paper checklists\" to include considerations about the WEIRD bias and call for the community to broaden research inclusivity by encouraging the use of diverse datasets from underrepresented regions.","sentences":["Much of the research in social computing analyzes data from social media platforms, which may inherently carry biases.","An overlooked source of such bias is the over-representation of WEIRD (Western, Educated, Industrialized, Rich, and Democratic) populations, which might not accurately mirror the global demographic diversity.","We evaluated the dependence on WEIRD populations in research presented at the AAAI ICWSM conference; the only venue whose proceedings are fully dedicated to social computing research.","We did so by analyzing 494 papers published from 2018 to 2022, which included full research papers, dataset papers and posters.","After filtering out papers that analyze synthetic datasets or those lacking clear country of origin, we were left with 420 papers from which 188 participants in a crowdsourcing study with full manual validation extracted data for the WEIRD scores computation.","This data was then used to adapt existing WEIRD metrics to be applicable for social media data.","We found that 37% of these papers focused solely on data from Western countries.","This percentage is significantly less than the percentages observed in research from CHI (76%) and FAccT (84%) conferences, suggesting a greater diversity of dataset origins within ICWSM.","However, the studies at ICWSM still predominantly examine populations from countries that are more Educated, Industrialized, and Rich in comparison to those in FAccT, with a special note on the 'Democratic' variable reflecting political freedoms and rights.","This points out the utility of social media data in shedding light on findings from countries with restricted political freedoms.","Based on these insights, we recommend extensions of current \"paper checklists\" to include considerations about the WEIRD bias and call for the community to broaden research inclusivity by encouraging the use of diverse datasets from underrepresented regions."],"url":"http://arxiv.org/abs/2406.02090v1","category":"cs.HC"}
{"created":"2024-06-04 07:44:18","title":"Towards Railways Remote Driving: Analysis of Video Streaming Latency and Adaptive Rate Control","abstract":"Remote driving aims to improve transport systems by promoting efficiency, sustainability, and accessibility. In the railway sector, remote driving makes it possible to increase flexibility, as the driver no longer has to be in the cab. However, this brings several challenges, as it has to provide at least the same level of safety obtained when the driver is in the cab. To achieve it, wireless networks and video streaming technologies gain importance as they should provide real-time track visualization and obstacle detection capabilities to the remote driver. Low latency camera capture, onboard media processing devices, and streaming protocols adapted for wireless links are the necessary enablers to be developed and integrated into the railway infrastructure. This paper compares video streaming protocols such as Real-Time Streaming Protocol (RTSP) and Web Real-Time Communication (WebRTC), as they are the main alternatives based on Real-time Transport Protocol (RTP) protocol to enable low latency. As latency is the main performance metric, this paper also provides a solution to calculate the End-to-End video streaming latency analytically. Finally, the paper proposes a rate control algorithm to adapt the video stream depending on the network capacity. The objective is to keep the latency as low as possible while avoiding any visual artifacts. The proposed solutions are tested in different setups and scenarios to prove their effectiveness before the planned field testing.","sentences":["Remote driving aims to improve transport systems by promoting efficiency, sustainability, and accessibility.","In the railway sector, remote driving makes it possible to increase flexibility, as the driver no longer has to be in the cab.","However, this brings several challenges, as it has to provide at least the same level of safety obtained when the driver is in the cab.","To achieve it, wireless networks and video streaming technologies gain importance as they should provide real-time track visualization and obstacle detection capabilities to the remote driver.","Low latency camera capture, onboard media processing devices, and streaming protocols adapted for wireless links are the necessary enablers to be developed and integrated into the railway infrastructure.","This paper compares video streaming protocols such as Real-Time Streaming Protocol (RTSP) and Web Real-Time Communication (WebRTC), as they are the main alternatives based on Real-time Transport Protocol (RTP) protocol to enable low latency.","As latency is the main performance metric, this paper also provides a solution to calculate the End-to-End video streaming latency analytically.","Finally, the paper proposes a rate control algorithm to adapt the video stream depending on the network capacity.","The objective is to keep the latency as low as possible while avoiding any visual artifacts.","The proposed solutions are tested in different setups and scenarios to prove their effectiveness before the planned field testing."],"url":"http://arxiv.org/abs/2406.02062v1","category":"cs.NI"}
{"created":"2024-06-04 07:41:15","title":"Tabular and Deep Learning for the Whittle Index","abstract":"The Whittle index policy is a heuristic that has shown remarkably good performance (with guaranteed asymptotic optimality) when applied to the class of problems known as Restless Multi-Armed Bandit Problems (RMABPs). In this paper we present QWI and QWINN, two reinforcement learning algorithms, respectively tabular and deep, to learn the Whittle index for the total discounted criterion. The key feature is the use of two time-scales, a faster one to update the state-action Q -values, and a relatively slower one to update the Whittle indices. In our main theoretical result we show that QWI, which is a tabular implementation, converges to the real Whittle indices. We then present QWINN, an adaptation of QWI algorithm using neural networks to compute the Q -values on the faster time-scale, which is able to extrapolate information from one state to another and scales naturally to large state-space environments. For QWINN, we show that all local minima of the Bellman error are locally stable equilibria, which is the first result of its kind for DQN-based schemes. Numerical computations show that QWI and QWINN converge faster than the standard Q -learning algorithm, neural-network based approximate Q-learning and other state of the art algorithms.","sentences":["The Whittle index policy is a heuristic that has shown remarkably good performance (with guaranteed asymptotic optimality) when applied to the class of problems known as Restless Multi-Armed Bandit Problems (RMABPs).","In this paper we present QWI and QWINN, two reinforcement learning algorithms, respectively tabular and deep, to learn the Whittle index for the total discounted criterion.","The key feature is the use of two time-scales, a faster one to update the state-action Q -values, and a relatively slower one to update the Whittle indices.","In our main theoretical result we show that QWI, which is a tabular implementation, converges to the real Whittle indices.","We then present QWINN, an adaptation of QWI algorithm using neural networks to compute the Q -values on the faster time-scale, which is able to extrapolate information from one state to another and scales naturally to large state-space environments.","For QWINN, we show that all local minima of the Bellman error are locally stable equilibria, which is the first result of its kind for DQN-based schemes.","Numerical computations show that QWI and QWINN converge faster than the standard Q -learning algorithm, neural-network based approximate Q-learning and other state of the art algorithms."],"url":"http://arxiv.org/abs/2406.02057v1","category":"cs.AI"}
{"created":"2024-06-04 07:30:27","title":"Causal Effect Identification in LiNGAM Models with Latent Confounders","abstract":"We study the generic identifiability of causal effects in linear non-Gaussian acyclic models (LiNGAM) with latent variables. We consider the problem in two main settings: When the causal graph is known a priori, and when it is unknown. In both settings, we provide a complete graphical characterization of the identifiable direct or total causal effects among observed variables. Moreover, we propose efficient algorithms to certify the graphical conditions. Finally, we propose an adaptation of the reconstruction independent component analysis (RICA) algorithm that estimates the causal effects from the observational data given the causal graph. Experimental results show the effectiveness of the proposed method in estimating the causal effects.","sentences":["We study the generic identifiability of causal effects in linear non-Gaussian acyclic models (LiNGAM) with latent variables.","We consider the problem in two main settings: When the causal graph is known a priori, and when it is unknown.","In both settings, we provide a complete graphical characterization of the identifiable direct or total causal effects among observed variables.","Moreover, we propose efficient algorithms to certify the graphical conditions.","Finally, we propose an adaptation of the reconstruction independent component analysis (RICA) algorithm that estimates the causal effects from the observational data given the causal graph.","Experimental results show the effectiveness of the proposed method in estimating the causal effects."],"url":"http://arxiv.org/abs/2406.02049v1","category":"stat.ML"}
{"created":"2024-06-04 07:24:51","title":"DFA-GNN: Forward Learning of Graph Neural Networks by Direct Feedback Alignment","abstract":"Graph neural networks are recognized for their strong performance across various applications, with the backpropagation algorithm playing a central role in the development of most GNN models. However, despite its effectiveness, BP has limitations that challenge its biological plausibility and affect the efficiency, scalability and parallelism of training neural networks for graph-based tasks. While several non-BP training algorithms, such as the direct feedback alignment, have been successfully applied to fully-connected and convolutional network components for handling Euclidean data, directly adapting these non-BP frameworks to manage non-Euclidean graph data in GNN models presents significant challenges. These challenges primarily arise from the violation of the i.i.d. assumption in graph data and the difficulty in accessing prediction errors for all samples (nodes) within the graph. To overcome these obstacles, in this paper we propose DFA-GNN, a novel forward learning framework tailored for GNNs with a case study of semi-supervised learning. The proposed method breaks the limitations of BP by using a dedicated forward training mechanism. Specifically, DFA-GNN extends the principles of DFA to adapt to graph data and unique architecture of GNNs, which incorporates the information of graph topology into the feedback links to accommodate the non-Euclidean characteristics of graph data. Additionally, for semi-supervised graph learning tasks, we developed a pseudo error generator that spreads residual errors from training data to create a pseudo error for each unlabeled node. These pseudo errors are then utilized to train GNNs using DFA. Extensive experiments on 10 public benchmarks reveal that our learning framework outperforms not only previous non-BP methods but also the standard BP methods, and it exhibits excellent robustness against various types of noise and attacks.","sentences":["Graph neural networks are recognized for their strong performance across various applications, with the backpropagation algorithm playing a central role in the development of most GNN models.","However, despite its effectiveness, BP has limitations that challenge its biological plausibility and affect the efficiency, scalability and parallelism of training neural networks for graph-based tasks.","While several non-BP training algorithms, such as the direct feedback alignment, have been successfully applied to fully-connected and convolutional network components for handling Euclidean data, directly adapting these non-BP frameworks to manage non-Euclidean graph data in GNN models presents significant challenges.","These challenges primarily arise from the violation of the i.i.d. assumption in graph data and the difficulty in accessing prediction errors for all samples (nodes) within the graph.","To overcome these obstacles, in this paper we propose DFA-GNN, a novel forward learning framework tailored for GNNs with a case study of semi-supervised learning.","The proposed method breaks the limitations of BP by using a dedicated forward training mechanism.","Specifically, DFA-GNN extends the principles of DFA to adapt to graph data and unique architecture of GNNs, which incorporates the information of graph topology into the feedback links to accommodate the non-Euclidean characteristics of graph data.","Additionally, for semi-supervised graph learning tasks, we developed a pseudo error generator that spreads residual errors from training data to create a pseudo error for each unlabeled node.","These pseudo errors are then utilized to train GNNs using DFA.","Extensive experiments on 10 public benchmarks reveal that our learning framework outperforms not only previous non-BP methods but also the standard BP methods, and it exhibits excellent robustness against various types of noise and attacks."],"url":"http://arxiv.org/abs/2406.02040v1","category":"cs.LG"}
{"created":"2024-06-04 06:56:41","title":"Adaptive and Optimal Second-order Optimistic Methods for Minimax Optimization","abstract":"We propose adaptive, line search-free second-order methods with optimal rate of convergence for solving convex-concave min-max problems. By means of an adaptive step size, our algorithms feature a simple update rule that requires solving only one linear system per iteration, eliminating the need for line search or backtracking mechanisms. Specifically, we base our algorithms on the optimistic method and appropriately combine it with second-order information. Moreover, distinct from common adaptive schemes, we define the step size recursively as a function of the gradient norm and the prediction error in the optimistic update. We first analyze a variant where the step size requires knowledge of the Lipschitz constant of the Hessian. Under the additional assumption of Lipschitz continuous gradients, we further design a parameter-free version by tracking the Hessian Lipschitz constant locally and ensuring the iterates remain bounded. We also evaluate the practical performance of our algorithm by comparing it to existing second-order algorithms for minimax optimization.","sentences":["We propose adaptive, line search-free second-order methods with optimal rate of convergence for solving convex-concave min-max problems.","By means of an adaptive step size, our algorithms feature a simple update rule that requires solving only one linear system per iteration, eliminating the need for line search or backtracking mechanisms.","Specifically, we base our algorithms on the optimistic method and appropriately combine it with second-order information.","Moreover, distinct from common adaptive schemes, we define the step size recursively as a function of the gradient norm and the prediction error in the optimistic update.","We first analyze a variant where the step size requires knowledge of the Lipschitz constant of the Hessian.","Under the additional assumption of Lipschitz continuous gradients, we further design a parameter-free version by tracking the Hessian Lipschitz constant locally and ensuring the iterates remain bounded.","We also evaluate the practical performance of our algorithm by comparing it to existing second-order algorithms for minimax optimization."],"url":"http://arxiv.org/abs/2406.02016v1","category":"math.OC"}
{"created":"2024-06-04 06:53:32","title":"Understanding Auditory Evoked Brain Signal via Physics-informed Embedding Network with Multi-Task Transformer","abstract":"In the fields of brain-computer interaction and cognitive neuroscience, effective decoding of auditory signals from task-based functional magnetic resonance imaging (fMRI) is key to understanding how the brain processes complex auditory information. Although existing methods have enhanced decoding capabilities, limitations remain in information utilization and model representation. To overcome these challenges, we propose an innovative multi-task learning model, Physics-informed Embedding Network with Multi-Task Transformer (PEMT-Net), which enhances decoding performance through physics-informed embedding and deep learning techniques. PEMT-Net consists of two principal components: feature augmentation and classification. For feature augmentation, we propose a novel approach by creating neural embedding graphs via node embedding, utilizing random walks to simulate the physical diffusion of neural information. This method captures both local and non-local information overflow and proposes a position encoding based on relative physical coordinates. In the classification segment, we propose adaptive embedding fusion to maximally capture linear and non-linear characteristics. Furthermore, we propose an innovative parameter-sharing mechanism to optimize the retention and learning of extracted features. Experiments on a specific dataset demonstrate PEMT-Net's significant performance in multi-task auditory signal decoding, surpassing existing methods and offering new insights into the brain's mechanisms for processing complex auditory information.","sentences":["In the fields of brain-computer interaction and cognitive neuroscience, effective decoding of auditory signals from task-based functional magnetic resonance imaging (fMRI) is key to understanding how the brain processes complex auditory information.","Although existing methods have enhanced decoding capabilities, limitations remain in information utilization and model representation.","To overcome these challenges, we propose an innovative multi-task learning model, Physics-informed Embedding Network with Multi-Task Transformer (PEMT-Net), which enhances decoding performance through physics-informed embedding and deep learning techniques.","PEMT-Net consists of two principal components: feature augmentation and classification.","For feature augmentation, we propose a novel approach by creating neural embedding graphs via node embedding, utilizing random walks to simulate the physical diffusion of neural information.","This method captures both local and non-local information overflow and proposes a position encoding based on relative physical coordinates.","In the classification segment, we propose adaptive embedding fusion to maximally capture linear and non-linear characteristics.","Furthermore, we propose an innovative parameter-sharing mechanism to optimize the retention and learning of extracted features.","Experiments on a specific dataset demonstrate PEMT-Net's significant performance in multi-task auditory signal decoding, surpassing existing methods and offering new insights into the brain's mechanisms for processing complex auditory information."],"url":"http://arxiv.org/abs/2406.02014v1","category":"q-bio.NC"}
{"created":"2024-06-04 06:34:33","title":"Efficiently Train ASR Models that Memorize Less and Perform Better with Per-core Clipping","abstract":"Gradient clipping plays a vital role in training large-scale automatic speech recognition (ASR) models. It is typically applied to minibatch gradients to prevent gradient explosion, and to the individual sample gradients to mitigate unintended memorization. This work systematically investigates the impact of a specific granularity of gradient clipping, namely per-core clip-ping (PCC), across training a wide range of ASR models. We empirically demonstrate that PCC can effectively mitigate unintended memorization in ASR models. Surprisingly, we find that PCC positively influences ASR performance metrics, leading to improved convergence rates and reduced word error rates. To avoid tuning the additional hyperparameter introduced by PCC, we further propose a novel variant, adaptive per-core clipping (APCC), for streamlined optimization. Our findings highlight the multifaceted benefits of PCC as a strategy for robust, privacy-forward ASR model training.","sentences":["Gradient clipping plays a vital role in training large-scale automatic speech recognition (ASR) models.","It is typically applied to minibatch gradients to prevent gradient explosion, and to the individual sample gradients to mitigate unintended memorization.","This work systematically investigates the impact of a specific granularity of gradient clipping, namely per-core clip-ping (PCC), across training a wide range of ASR models.","We empirically demonstrate that PCC can effectively mitigate unintended memorization in ASR models.","Surprisingly, we find that PCC positively influences ASR performance metrics, leading to improved convergence rates and reduced word error rates.","To avoid tuning the additional hyperparameter introduced by PCC, we further propose a novel variant, adaptive per-core clipping (APCC), for streamlined optimization.","Our findings highlight the multifaceted benefits of PCC as a strategy for robust, privacy-forward ASR model training."],"url":"http://arxiv.org/abs/2406.02004v1","category":"cs.CR"}
{"created":"2024-06-04 06:07:24","title":"Dealing with All-stage Missing Modality: Towards A Universal Model with Robust Reconstruction and Personalization","abstract":"Addressing missing modalities presents a critical challenge in multimodal learning. Current approaches focus on developing models that can handle modality-incomplete inputs during inference, assuming that the full set of modalities are available for all the data during training. This reliance on full-modality data for training limits the use of abundant modality-incomplete samples that are often encountered in practical settings. In this paper, we propose a robust universal model with modality reconstruction and model personalization, which can effectively tackle the missing modality at both training and testing stages. Our method leverages a multimodal masked autoencoder to reconstruct the missing modality and masked patches simultaneously, incorporating an innovative distribution approximation mechanism to fully utilize both modality-complete and modality-incomplete data. The reconstructed modalities then contributes to our designed data-model co-distillation scheme to guide the model learning in the presence of missing modalities. Moreover, we propose a CLIP-driven hyper-network to personalize partial model parameters, enabling the model to adapt to each distinct missing modality scenario. Our method has been extensively validated on two brain tumor segmentation benchmarks. Experimental results demonstrate the promising performance of our method, which consistently exceeds previous state-of-the-art approaches under the all-stage missing modality settings with different missing ratios. Code will be available.","sentences":["Addressing missing modalities presents a critical challenge in multimodal learning.","Current approaches focus on developing models that can handle modality-incomplete inputs during inference, assuming that the full set of modalities are available for all the data during training.","This reliance on full-modality data for training limits the use of abundant modality-incomplete samples that are often encountered in practical settings.","In this paper, we propose a robust universal model with modality reconstruction and model personalization, which can effectively tackle the missing modality at both training and testing stages.","Our method leverages a multimodal masked autoencoder to reconstruct the missing modality and masked patches simultaneously, incorporating an innovative distribution approximation mechanism to fully utilize both modality-complete and modality-incomplete data.","The reconstructed modalities then contributes to our designed data-model co-distillation scheme to guide the model learning in the presence of missing modalities.","Moreover, we propose a CLIP-driven hyper-network to personalize partial model parameters, enabling the model to adapt to each distinct missing modality scenario.","Our method has been extensively validated on two brain tumor segmentation benchmarks.","Experimental results demonstrate the promising performance of our method, which consistently exceeds previous state-of-the-art approaches under the all-stage missing modality settings with different missing ratios.","Code will be available."],"url":"http://arxiv.org/abs/2406.01987v1","category":"cs.CV"}
{"created":"2024-06-04 05:18:11","title":"Adaptive Relaxation based Non-Conservative Chance Constrained Stochastic MPC for Battery Scheduling Under Forecast Uncertainties","abstract":"Chance constrained stochastic model predictive controllers (CC-SMPC) trade off full constraint satisfaction for economical plant performance under uncertainty. Previous CC-SMPC works are over-conservative in constraint violations leading to worse economic performance. Other past works require a-priori information about the uncertainty set, limiting their application to real-world systems. This paper considers a discrete linear time invariant system with hard constraints on inputs and chance constraints on states, with unknown uncertainty distribution, statistics, or samples. This work proposes a novel adaptive online update rule to relax the state constraints based on the time-average of past constraint violations, for the SMPC to achieve reduced conservativeness in closed-loop. Under an ideal control policy assumption, it is proven that the time-average of constraint violations converges to the maximum allowed violation probability. The time-average of constraint violations is also proven to asymptotically converge even without the simplifying assumptions. The proposed method is applied to the optimal battery energy storage system (BESS) dispatch in a grid connected microgrid with PV generation and load demand with chance constraints on BESS state-of-charge (SOC). Realistic simulations show the superior electricity cost saving potential of the proposed method as compared to the traditional MPC (with hard constraints on BESS SOC), by satisfying the chance constraints non-conservatively in closed-loop, thereby effectively trading off increased cost savings with minimal adverse effects on BESS lifetime.","sentences":["Chance constrained stochastic model predictive controllers (CC-SMPC) trade off full constraint satisfaction for economical plant performance under uncertainty.","Previous CC-SMPC works are over-conservative in constraint violations leading to worse economic performance.","Other past works require a-priori information about the uncertainty set, limiting their application to real-world systems.","This paper considers a discrete linear time invariant system with hard constraints on inputs and chance constraints on states, with unknown uncertainty distribution, statistics, or samples.","This work proposes a novel adaptive online update rule to relax the state constraints based on the time-average of past constraint violations, for the SMPC to achieve reduced conservativeness in closed-loop.","Under an ideal control policy assumption, it is proven that the time-average of constraint violations converges to the maximum allowed violation probability.","The time-average of constraint violations is also proven to asymptotically converge even without the simplifying assumptions.","The proposed method is applied to the optimal battery energy storage system (BESS) dispatch in a grid connected microgrid with PV generation and load demand with chance constraints on BESS state-of-charge (SOC).","Realistic simulations show the superior electricity cost saving potential of the proposed method as compared to the traditional MPC (with hard constraints on BESS SOC), by satisfying the chance constraints non-conservatively in closed-loop, thereby effectively trading off increased cost savings with minimal adverse effects on BESS lifetime."],"url":"http://arxiv.org/abs/2406.01973v1","category":"eess.SY"}
{"created":"2024-06-04 04:39:51","title":"Adaptive Variance Reduction for Stochastic Optimization under Weaker Assumptions","abstract":"This paper explores adaptive variance reduction methods for stochastic optimization based on the STORM technique. Existing adaptive extensions of STORM rely on strong assumptions like bounded gradients and bounded function values, or suffer an additional $\\mathcal{O}(\\log T)$ term in the convergence rate. To address these limitations, we introduce a novel adaptive STORM method that achieves an optimal convergence rate of $\\mathcal{O}(T^{-1/3})$ for non-convex functions with our newly designed learning rate strategy. Compared with existing approaches, our method requires weaker assumptions and attains the optimal convergence rate without the additional $\\mathcal{O}(\\log T)$ term. We also extend the proposed technique to stochastic compositional optimization, obtaining the same optimal rate of $\\mathcal{O}(T^{-1/3})$. Furthermore, we investigate the non-convex finite-sum problem and develop another innovative adaptive variance reduction method that achieves an optimal convergence rate of $\\mathcal{O}(n^{1/4} T^{-1/2} )$, where $n$ represents the number of component functions. Numerical experiments across various tasks validate the effectiveness of our method.","sentences":["This paper explores adaptive variance reduction methods for stochastic optimization based on the STORM technique.","Existing adaptive extensions of STORM rely on strong assumptions like bounded gradients and bounded function values, or suffer an additional $\\mathcal{O}(\\log T)$ term in the convergence rate.","To address these limitations, we introduce a novel adaptive STORM method that achieves an optimal convergence rate of $\\mathcal{O}(T^{-1/3})$ for non-convex functions with our newly designed learning rate strategy.","Compared with existing approaches, our method requires weaker assumptions and attains the optimal convergence rate without the additional $\\mathcal{O}(\\log T)$ term.","We also extend the proposed technique to stochastic compositional optimization, obtaining the same optimal rate of $\\mathcal{O}(T^{-1/3})$. Furthermore, we investigate the non-convex finite-sum problem and develop another innovative adaptive variance reduction method that achieves an optimal convergence rate of $\\mathcal{O}(n^{1/4} T^{-1/2} )$, where $n$ represents the number of component functions.","Numerical experiments across various tasks validate the effectiveness of our method."],"url":"http://arxiv.org/abs/2406.01959v1","category":"math.OC"}
{"created":"2024-06-04 04:22:39","title":"On-Demand Routing in LEO Mega-Constellations with Dynamic Laser Inter-Satellite Links","abstract":"Low Earth orbit (LEO) satellite mega constellations are beginning to include laser inter-satellite links (LISLs) to extend the Internet to the most remote locations on Earth. Since the process of establishing these links incurs a setup delay on the order of seconds, a static network topology is generally established well in advance, which is then used for the routing calculations. However, this involves keeping links active even when they are not being used to forward traffic, leading to poor energy efficiency. Motivated by technological advances that are gradually decreasing the LISL setup delays, we foresee scenarios where it will be possible to compute routes and establish dynamic LISLs on demand. This will require considering setup delays as penalties that will affect the end-to-end latency. In this paper, we present a nonlinear optimization model that considers these penalties in the cost function and propose three heuristic algorithms that solve the problem in a tractable way. The algorithms establish different trade-offs in terms of performance and computational complexity. We extensively analyze metrics including average latency, route change rate, outage probability, and jitter in Starlink's Phase I version 2 constellation. The results show the benefit of adaptive routing schemes according to the link setup delay. In particular, more complex schemes can decrease the average end-to-end latency in exchange for an increase in execution time. On the other hand, depending on the maximum tolerated latency, it is possible to use less computationally complex schemes which will be more scalable for the satellite mega constellations of the future.","sentences":["Low Earth orbit (LEO) satellite mega constellations are beginning to include laser inter-satellite links (LISLs) to extend the Internet to the most remote locations on Earth.","Since the process of establishing these links incurs a setup delay on the order of seconds, a static network topology is generally established well in advance, which is then used for the routing calculations.","However, this involves keeping links active even when they are not being used to forward traffic, leading to poor energy efficiency.","Motivated by technological advances that are gradually decreasing the LISL setup delays, we foresee scenarios where it will be possible to compute routes and establish dynamic LISLs on demand.","This will require considering setup delays as penalties that will affect the end-to-end latency.","In this paper, we present a nonlinear optimization model that considers these penalties in the cost function and propose three heuristic algorithms that solve the problem in a tractable way.","The algorithms establish different trade-offs in terms of performance and computational complexity.","We extensively analyze metrics including average latency, route change rate, outage probability, and jitter in Starlink's Phase I version 2 constellation.","The results show the benefit of adaptive routing schemes according to the link setup delay.","In particular, more complex schemes can decrease the average end-to-end latency in exchange for an increase in execution time.","On the other hand, depending on the maximum tolerated latency, it is possible to use less computationally complex schemes which will be more scalable for the satellite mega constellations of the future."],"url":"http://arxiv.org/abs/2406.01953v1","category":"cs.NI"}
{"created":"2024-06-04 03:49:10","title":"SDS++: Online Situation-Aware Drivable Space Estimation for Automated Driving","abstract":"Autonomous Vehicles (AVs) need an accurate and up-to-date representation of the environment for safe navigation. Traditional methods, which often rely on detailed environmental representations constructed offline, struggle in dynamically changing environments or when dealing with outdated maps. Consequently, there is a pressing need for real-time solutions that can integrate diverse data sources and adapt to the current situation. An existing framework that addresses these challenges is SDS (situation-aware drivable space). However, SDS faces several limitations, including its use of a non-standard output representation, its choice of encoding objects as points, restricting representation of more complex geometries like road lanes, and the fact that its methodology has been validated only with simulated or heavily post-processed data. This work builds upon SDS and introduces SDS++, designed to overcome SDS's shortcomings while preserving its benefits. SDS++ has been rigorously validated not only in simulations but also with unrefined vehicle data, and it is integrated with a model predictive control (MPC)-based planner to verify its advantages for the planning task. The results demonstrate that SDS++ significantly enhances trajectory planning capabilities, providing increased robustness against localization noise, and enabling the planning of trajectories that adapt to the current driving context.","sentences":["Autonomous Vehicles (AVs) need an accurate and up-to-date representation of the environment for safe navigation.","Traditional methods, which often rely on detailed environmental representations constructed offline, struggle in dynamically changing environments or when dealing with outdated maps.","Consequently, there is a pressing need for real-time solutions that can integrate diverse data sources and adapt to the current situation.","An existing framework that addresses these challenges is SDS (situation-aware drivable space).","However, SDS faces several limitations, including its use of a non-standard output representation, its choice of encoding objects as points, restricting representation of more complex geometries like road lanes, and the fact that its methodology has been validated only with simulated or heavily post-processed data.","This work builds upon SDS and introduces SDS++, designed to overcome SDS's shortcomings while preserving its benefits.","SDS++ has been rigorously validated not only in simulations but also with unrefined vehicle data, and it is integrated with a model predictive control (MPC)-based planner to verify its advantages for the planning task.","The results demonstrate that SDS++ significantly enhances trajectory planning capabilities, providing increased robustness against localization noise, and enabling the planning of trajectories that adapt to the current driving context."],"url":"http://arxiv.org/abs/2406.01941v1","category":"cs.RO"}
{"created":"2024-06-04 03:00:55","title":"OTTAWA: Optimal TransporT Adaptive Word Aligner for Hallucination and Omission Translation Errors Detection","abstract":"Recently, there has been considerable attention on detecting hallucinations and omissions in Machine Translation (MT) systems. The two dominant approaches to tackle this task involve analyzing the MT system's internal states or relying on the output of external tools, such as sentence similarity or MT quality estimators. In this work, we introduce OTTAWA, a novel Optimal Transport (OT)-based word aligner specifically designed to enhance the detection of hallucinations and omissions in MT systems. Our approach explicitly models the missing alignments by introducing a \"null\" vector, for which we propose a novel one-side constrained OT setting to allow an adaptive null alignment. Our approach yields competitive results compared to state-of-the-art methods across 18 language pairs on the HalOmi benchmark. In addition, it shows promising features, such as the ability to distinguish between both error types and perform word-level detection without accessing the MT system's internal states.","sentences":["Recently, there has been considerable attention on detecting hallucinations and omissions in Machine Translation (MT) systems.","The two dominant approaches to tackle this task involve analyzing the MT system's internal states or relying on the output of external tools, such as sentence similarity or MT quality estimators.","In this work, we introduce OTTAWA, a novel Optimal Transport (OT)-based word aligner specifically designed to enhance the detection of hallucinations and omissions in MT systems.","Our approach explicitly models the missing alignments by introducing a \"null\" vector, for which we propose a novel one-side constrained OT setting to allow an adaptive null alignment.","Our approach yields competitive results compared to state-of-the-art methods across 18 language pairs on the HalOmi benchmark.","In addition, it shows promising features, such as the ability to distinguish between both error types and perform word-level detection without accessing the MT system's internal states."],"url":"http://arxiv.org/abs/2406.01919v1","category":"cs.CL"}
{"created":"2024-06-04 02:57:09","title":"FastLGS: Speeding up Language Embedded Gaussians with Feature Grid Mapping","abstract":"The semantically interactive radiance field has always been an appealing task for its potential to facilitate user-friendly and automated real-world 3D scene understanding applications. However, it is a challenging task to achieve high quality, efficiency and zero-shot ability at the same time with semantics in radiance fields. In this work, we present FastLGS, an approach that supports real-time open-vocabulary query within 3D Gaussian Splatting (3DGS) under high resolution. We propose the semantic feature grid to save multi-view CLIP features which are extracted based on Segment Anything Model (SAM) masks, and map the grids to low dimensional features for semantic field training through 3DGS. Once trained, we can restore pixel-aligned CLIP embeddings through feature grids from rendered features for open-vocabulary queries. Comparisons with other state-of-the-art methods prove that FastLGS can achieve the first place performance concerning both speed and accuracy, where FastLGS is 98x faster than LERF and 4x faster than LangSplat. Meanwhile, experiments show that FastLGS is adaptive and compatible with many downstream tasks, such as 3D segmentation and 3D object inpainting, which can be easily applied to other 3D manipulation systems.","sentences":["The semantically interactive radiance field has always been an appealing task for its potential to facilitate user-friendly and automated real-world 3D scene understanding applications.","However, it is a challenging task to achieve high quality, efficiency and zero-shot ability at the same time with semantics in radiance fields.","In this work, we present FastLGS, an approach that supports real-time open-vocabulary query within 3D Gaussian Splatting (3DGS) under high resolution.","We propose the semantic feature grid to save multi-view CLIP features which are extracted based on Segment Anything Model (SAM) masks, and map the grids to low dimensional features for semantic field training through 3DGS.","Once trained, we can restore pixel-aligned CLIP embeddings through feature grids from rendered features for open-vocabulary queries.","Comparisons with other state-of-the-art methods prove that FastLGS can achieve the first place performance concerning both speed and accuracy, where FastLGS is 98x faster than LERF and 4x faster than LangSplat.","Meanwhile, experiments show that FastLGS is adaptive and compatible with many downstream tasks, such as 3D segmentation and 3D object inpainting, which can be easily applied to other 3D manipulation systems."],"url":"http://arxiv.org/abs/2406.01916v1","category":"cs.CV"}
{"created":"2024-06-04 02:52:26","title":"Enhancing Human-Robot Collaborative Assembly in Manufacturing Systems Using Large Language Models","abstract":"The development of human-robot collaboration has the ability to improve manufacturing system performance by leveraging the unique strengths of both humans and robots. On the shop floor, human operators contribute with their adaptability and flexibility in dynamic situations, while robots provide precision and the ability to perform repetitive tasks. However, the communication gap between human operators and robots limits the collaboration and coordination of human-robot teams in manufacturing systems. Our research presents a human-robot collaborative assembly framework that utilizes a large language model for enhancing communication in manufacturing environments. The framework facilitates human-robot communication by integrating voice commands through natural language for task management. A case study for an assembly task demonstrates the framework's ability to process natural language inputs and address real-time assembly challenges, emphasizing adaptability to language variation and efficiency in error resolution. The results suggest that large language models have the potential to improve human-robot interaction for collaborative manufacturing assembly applications.","sentences":["The development of human-robot collaboration has the ability to improve manufacturing system performance by leveraging the unique strengths of both humans and robots.","On the shop floor, human operators contribute with their adaptability and flexibility in dynamic situations, while robots provide precision and the ability to perform repetitive tasks.","However, the communication gap between human operators and robots limits the collaboration and coordination of human-robot teams in manufacturing systems.","Our research presents a human-robot collaborative assembly framework that utilizes a large language model for enhancing communication in manufacturing environments.","The framework facilitates human-robot communication by integrating voice commands through natural language for task management.","A case study for an assembly task demonstrates the framework's ability to process natural language inputs and address real-time assembly challenges, emphasizing adaptability to language variation and efficiency in error resolution.","The results suggest that large language models have the potential to improve human-robot interaction for collaborative manufacturing assembly applications."],"url":"http://arxiv.org/abs/2406.01915v1","category":"cs.RO"}
{"created":"2024-06-04 02:04:09","title":"Cross-Domain Graph Data Scaling: A Showcase with Diffusion Models","abstract":"Models for natural language and images benefit from data scaling behavior: the more data fed into the model, the better they perform. This 'better with more' phenomenon enables the effectiveness of large-scale pre-training on vast amounts of data. However, current graph pre-training methods struggle to scale up data due to heterogeneity across graphs. To achieve effective data scaling, we aim to develop a general model that is able to capture diverse data patterns of graphs and can be utilized to adaptively help the downstream tasks. To this end, we propose UniAug, a universal graph structure augmentor built on a diffusion model. We first pre-train a discrete diffusion model on thousands of graphs across domains to learn the graph structural patterns. In the downstream phase, we provide adaptive enhancement by conducting graph structure augmentation with the help of the pre-trained diffusion model via guided generation. By leveraging the pre-trained diffusion model for structure augmentation, we consistently achieve performance improvements across various downstream tasks in a plug-and-play manner. To the best of our knowledge, this study represents the first demonstration of a data-scaling graph structure augmentor on graphs across domains.","sentences":["Models for natural language and images benefit from data scaling behavior: the more data fed into the model, the better they perform.","This 'better with more' phenomenon enables the effectiveness of large-scale pre-training on vast amounts of data.","However, current graph pre-training methods struggle to scale up data due to heterogeneity across graphs.","To achieve effective data scaling, we aim to develop a general model that is able to capture diverse data patterns of graphs and can be utilized to adaptively help the downstream tasks.","To this end, we propose UniAug, a universal graph structure augmentor built on a diffusion model.","We first pre-train a discrete diffusion model on thousands of graphs across domains to learn the graph structural patterns.","In the downstream phase, we provide adaptive enhancement by conducting graph structure augmentation with the help of the pre-trained diffusion model via guided generation.","By leveraging the pre-trained diffusion model for structure augmentation, we consistently achieve performance improvements across various downstream tasks in a plug-and-play manner.","To the best of our knowledge, this study represents the first demonstration of a data-scaling graph structure augmentor on graphs across domains."],"url":"http://arxiv.org/abs/2406.01899v1","category":"cs.LG"}
{"created":"2024-06-04 01:57:37","title":"Large Language Model-Enabled Multi-Agent Manufacturing Systems","abstract":"Traditional manufacturing faces challenges adapting to dynamic environments and quickly responding to manufacturing changes. The use of multi-agent systems has improved adaptability and coordination but requires further advancements in rapid human instruction comprehension, operational adaptability, and coordination through natural language integration. Large language models like GPT-3.5 and GPT-4 enhance multi-agent manufacturing systems by enabling agents to communicate in natural language and interpret human instructions for decision-making. This research introduces a novel framework where large language models enhance the capabilities of agents in manufacturing, making them more adaptable, and capable of processing context-specific instructions. A case study demonstrates the practical application of this framework, showing how agents can effectively communicate, understand tasks, and execute manufacturing processes, including precise G-code allocation among agents. The findings highlight the importance of continuous large language model integration into multi-agent manufacturing systems and the development of sophisticated agent communication protocols for a more flexible manufacturing system.","sentences":["Traditional manufacturing faces challenges adapting to dynamic environments and quickly responding to manufacturing changes.","The use of multi-agent systems has improved adaptability and coordination but requires further advancements in rapid human instruction comprehension, operational adaptability, and coordination through natural language integration.","Large language models like GPT-3.5 and GPT-4 enhance multi-agent manufacturing systems by enabling agents to communicate in natural language and interpret human instructions for decision-making.","This research introduces a novel framework where large language models enhance the capabilities of agents in manufacturing, making them more adaptable, and capable of processing context-specific instructions.","A case study demonstrates the practical application of this framework, showing how agents can effectively communicate, understand tasks, and execute manufacturing processes, including precise G-code allocation among agents.","The findings highlight the importance of continuous large language model integration into multi-agent manufacturing systems and the development of sophisticated agent communication protocols for a more flexible manufacturing system."],"url":"http://arxiv.org/abs/2406.01893v1","category":"cs.MA"}
{"created":"2024-06-04 01:31:20","title":"HoneyGPT: Breaking the Trilemma in Terminal Honeypots with Large Language Model","abstract":"Honeypots, as a strategic cyber-deception mechanism designed to emulate authentic interactions and bait unauthorized entities, continue to struggle with balancing flexibility, interaction depth, and deceptive capability despite their evolution over decades. Often they also lack the capability of proactively adapting to an attacker's evolving tactics, which restricts the depth of engagement and subsequent information gathering. Under this context, the emergent capabilities of large language models, in tandem with pioneering prompt-based engineering techniques, offer a transformative shift in the design and deployment of honeypot technologies. In this paper, we introduce HoneyGPT, a pioneering honeypot architecture based on ChatGPT, heralding a new era of intelligent honeypot solutions characterized by their cost-effectiveness, high adaptability, and enhanced interactivity, coupled with a predisposition for proactive attacker engagement. Furthermore, we present a structured prompt engineering framework that augments long-term interaction memory and robust security analytics. This framework, integrating thought of chain tactics attuned to honeypot contexts, enhances interactivity and deception, deepens security analytics, and ensures sustained engagement.   The evaluation of HoneyGPT includes two parts: a baseline comparison based on a collected dataset and a field evaluation in real scenarios for four weeks. The baseline comparison demonstrates HoneyGPT's remarkable ability to strike a balance among flexibility, interaction depth, and deceptive capability. The field evaluation further validates HoneyGPT's efficacy, showing its marked superiority in enticing attackers into more profound interactive engagements and capturing a wider array of novel attack vectors in comparison to existing honeypot technologies.","sentences":["Honeypots, as a strategic cyber-deception mechanism designed to emulate authentic interactions and bait unauthorized entities, continue to struggle with balancing flexibility, interaction depth, and deceptive capability despite their evolution over decades.","Often they also lack the capability of proactively adapting to an attacker's evolving tactics, which restricts the depth of engagement and subsequent information gathering.","Under this context, the emergent capabilities of large language models, in tandem with pioneering prompt-based engineering techniques, offer a transformative shift in the design and deployment of honeypot technologies.","In this paper, we introduce HoneyGPT, a pioneering honeypot architecture based on ChatGPT, heralding a new era of intelligent honeypot solutions characterized by their cost-effectiveness, high adaptability, and enhanced interactivity, coupled with a predisposition for proactive attacker engagement.","Furthermore, we present a structured prompt engineering framework that augments long-term interaction memory and robust security analytics.","This framework, integrating thought of chain tactics attuned to honeypot contexts, enhances interactivity and deception, deepens security analytics, and ensures sustained engagement.   ","The evaluation of HoneyGPT includes two parts: a baseline comparison based on a collected dataset and a field evaluation in real scenarios for four weeks.","The baseline comparison demonstrates HoneyGPT's remarkable ability to strike a balance among flexibility, interaction depth, and deceptive capability.","The field evaluation further validates HoneyGPT's efficacy, showing its marked superiority in enticing attackers into more profound interactive engagements and capturing a wider array of novel attack vectors in comparison to existing honeypot technologies."],"url":"http://arxiv.org/abs/2406.01882v1","category":"cs.CR"}
{"created":"2024-06-04 01:29:55","title":"Activity patterns in ring networks of quadratic integrate-and-fire neurons with synaptic and gap junction coupling","abstract":"We consider a ring network of quadratic integrate-and-fire neurons with nonlocal synaptic and gap junction coupling. The corresponding neural field model supports solutions such as standing and travelling waves, and also lurching waves. We show that many of these solutions satisfy self-consistency equations which can be used to follow them as parameters are varied. We perform numerical bifurcation analysis of the neural field model, concentrating on the effects of varying gap junction coupling strength. Our methods are generally applicable to a wide variety of networks of quadratic integrate-and-fire neurons.","sentences":["We consider a ring network of quadratic integrate-and-fire neurons with nonlocal synaptic and gap junction coupling.","The corresponding neural field model supports solutions such as standing and travelling waves, and also lurching waves.","We show that many of these solutions satisfy self-consistency equations which can be used to follow them as parameters are varied.","We perform numerical bifurcation analysis of the neural field model, concentrating on the effects of varying gap junction coupling strength.","Our methods are generally applicable to a wide variety of networks of quadratic integrate-and-fire neurons."],"url":"http://arxiv.org/abs/2406.01881v1","category":"nlin.AO"}
{"created":"2024-06-03 23:54:48","title":"Non-uniformity is All You Need: Efficient and Timely Encrypted Traffic Classification With ECHO","abstract":"With 95% of Internet traffic now encrypted, an effective approach to classifying this traffic is crucial for network security and management. This paper introduces ECHO -- a novel optimization process for ML/DL-based encrypted traffic classification. ECHO targets both classification time and memory utilization and incorporates two innovative techniques.   The first component, HO (Hyperparameter Optimization of binnings), aims at creating efficient traffic representations. While previous research often uses representations that map packet sizes and packet arrival times to fixed-sized bins, we show that non-uniform binnings are significantly more efficient. These non-uniform binnings are derived by employing a hyperparameter optimization algorithm in the training stage. HO significantly improves accuracy given a required representation size, or, equivalently, achieves comparable accuracy using smaller representations.   Then, we introduce EC (Early Classification of traffic), which enables faster classification using a cascade of classifiers adapted for different exit times, where classification is based on the level of confidence. EC reduces the average classification latency by up to 90\\%. Remarkably, this method not only maintains classification accuracy but also, in certain cases, improves it.   Using three publicly available datasets, we demonstrate that the combined method, Early Classification with Hyperparameter Optimization (ECHO), leads to a significant improvement in classification efficiency.","sentences":["With 95% of Internet traffic now encrypted, an effective approach to classifying this traffic is crucial for network security and management.","This paper introduces ECHO -- a novel optimization process for ML/DL-based encrypted traffic classification.","ECHO targets both classification time and memory utilization and incorporates two innovative techniques.   ","The first component, HO (Hyperparameter Optimization of binnings), aims at creating efficient traffic representations.","While previous research often uses representations that map packet sizes and packet arrival times to fixed-sized bins, we show that non-uniform binnings are significantly more efficient.","These non-uniform binnings are derived by employing a hyperparameter optimization algorithm in the training stage.","HO significantly improves accuracy given a required representation size, or, equivalently, achieves comparable accuracy using smaller representations.   ","Then, we introduce EC (Early Classification of traffic), which enables faster classification using a cascade of classifiers adapted for different exit times, where classification is based on the level of confidence.","EC reduces the average classification latency by up to 90\\%.","Remarkably, this method not only maintains classification accuracy but also, in certain cases, improves it.   ","Using three publicly available datasets, we demonstrate that the combined method, Early Classification with Hyperparameter Optimization (ECHO), leads to a significant improvement in classification efficiency."],"url":"http://arxiv.org/abs/2406.01852v1","category":"cs.NI"}
{"created":"2024-06-03 23:28:05","title":"GraphWeaver: Billion-Scale Cybersecurity Incident Correlation","abstract":"In the dynamic landscape of large enterprise cybersecurity, accurately and efficiently correlating billions of security alerts into comprehensive incidents is a substantial challenge. Traditional correlation techniques often struggle with maintenance, scaling, and adapting to emerging threats and novel sources of telemetry. We introduce GraphWeaver, an industry-scale framework that shifts the traditional incident correlation process to a data-optimized, geo-distributed graph based approach. GraphWeaver introduces a suite of innovations tailored to handle the complexities of correlating billions of shared evidence alerts across hundreds of thousands of enterprises. Key among these innovations are a geo-distributed database and PySpark analytics engine for large-scale data processing, a minimum spanning tree algorithm to optimize correlation storage, integration of security domain knowledge and threat intelligence, and a human-in-the-loop feedback system to continuously refine key correlation processes and parameters. GraphWeaver is integrated into the Microsoft Defender XDR product and deployed worldwide, handling billions of correlations with a 99% accuracy rate, as confirmed by customer feedback and extensive investigations by security experts. This integration has not only maintained high correlation accuracy but reduces traditional correlation storage requirements by 7.4x. We provide an in-depth overview of the key design and operational features of GraphWeaver, setting a precedent as the first cybersecurity company to openly discuss these critical capabilities at this level of depth.","sentences":["In the dynamic landscape of large enterprise cybersecurity, accurately and efficiently correlating billions of security alerts into comprehensive incidents is a substantial challenge.","Traditional correlation techniques often struggle with maintenance, scaling, and adapting to emerging threats and novel sources of telemetry.","We introduce GraphWeaver, an industry-scale framework that shifts the traditional incident correlation process to a data-optimized, geo-distributed graph based approach.","GraphWeaver introduces a suite of innovations tailored to handle the complexities of correlating billions of shared evidence alerts across hundreds of thousands of enterprises.","Key among these innovations are a geo-distributed database and PySpark analytics engine for large-scale data processing, a minimum spanning tree algorithm to optimize correlation storage, integration of security domain knowledge and threat intelligence, and a human-in-the-loop feedback system to continuously refine key correlation processes and parameters.","GraphWeaver is integrated into the Microsoft Defender XDR product and deployed worldwide, handling billions of correlations with a 99% accuracy rate, as confirmed by customer feedback and extensive investigations by security experts.","This integration has not only maintained high correlation accuracy but reduces traditional correlation storage requirements by 7.4x.","We provide an in-depth overview of the key design and operational features of GraphWeaver, setting a precedent as the first cybersecurity company to openly discuss these critical capabilities at this level of depth."],"url":"http://arxiv.org/abs/2406.01842v1","category":"cs.CR"}
{"created":"2024-06-03 22:56:40","title":"FacAID: A Transformer Model for Neuro-Symbolic Facade Reconstruction","abstract":"We introduce a neuro-symbolic transformer-based model that converts flat, segmented facade structures into procedural definitions using a custom-designed split grammar. To facilitate this, we first develop a semi-complex split grammar tailored for architectural facades and then generate a dataset comprising of facades alongside their corresponding procedural representations. This dataset is used to train our transformer model to convert segmented, flat facades into the procedural language of our grammar. During inference, the model applies this learned transformation to new facade segmentations, providing a procedural representation that users can adjust to generate varied facade designs. This method not only automates the conversion of static facade images into dynamic, editable procedural formats but also enhances the design flexibility, allowing for easy modifications and variations by architects and designers. Our approach sets a new standard in facade design by combining the precision of procedural generation with the adaptability of neuro-symbolic learning.","sentences":["We introduce a neuro-symbolic transformer-based model that converts flat, segmented facade structures into procedural definitions using a custom-designed split grammar.","To facilitate this, we first develop a semi-complex split grammar tailored for architectural facades and then generate a dataset comprising of facades alongside their corresponding procedural representations.","This dataset is used to train our transformer model to convert segmented, flat facades into the procedural language of our grammar.","During inference, the model applies this learned transformation to new facade segmentations, providing a procedural representation that users can adjust to generate varied facade designs.","This method not only automates the conversion of static facade images into dynamic, editable procedural formats but also enhances the design flexibility, allowing for easy modifications and variations by architects and designers.","Our approach sets a new standard in facade design by combining the precision of procedural generation with the adaptability of neuro-symbolic learning."],"url":"http://arxiv.org/abs/2406.01829v1","category":"cs.NE"}
{"created":"2024-06-03 22:09:47","title":"A Game-Theoretic Approach to Privacy-Utility Tradeoff in Sharing Genomic Summary Statistics","abstract":"The advent of online genomic data-sharing services has sought to enhance the accessibility of large genomic datasets by allowing queries about genetic variants, such as summary statistics, aiding care providers in distinguishing between spurious genomic variations and those with clinical significance. However, numerous studies have demonstrated that even sharing summary genomic information exposes individual members of such datasets to a significant privacy risk due to membership inference attacks. While several approaches have emerged that reduce privacy risks by adding noise or reducing the amount of information shared, these typically assume non-adaptive attacks that use likelihood ratio test (LRT) statistics. We propose a Bayesian game-theoretic framework for optimal privacy-utility tradeoff in the sharing of genomic summary statistics. Our first contribution is to prove that a very general Bayesian attacker model that anchors our game-theoretic approach is more powerful than the conventional LRT-based threat models in that it induces worse privacy loss for the defender who is modeled as a von Neumann-Morgenstern (vNM) decision-maker. We show this to be true even when the attacker uses a non-informative subjective prior. Next, we present an analytically tractable approach to compare the Bayesian attacks with arbitrary subjective priors and the Neyman-Pearson optimal LRT attacks under the Gaussian mechanism common in differential privacy frameworks. Finally, we propose an approach for approximating Bayes-Nash equilibria of the game using deep neural network generators to implicitly represent player mixed strategies. Our experiments demonstrate that the proposed game-theoretic framework yields both stronger attacks and stronger defense strategies than the state of the art.","sentences":["The advent of online genomic data-sharing services has sought to enhance the accessibility of large genomic datasets by allowing queries about genetic variants, such as summary statistics, aiding care providers in distinguishing between spurious genomic variations and those with clinical significance.","However, numerous studies have demonstrated that even sharing summary genomic information exposes individual members of such datasets to a significant privacy risk due to membership inference attacks.","While several approaches have emerged that reduce privacy risks by adding noise or reducing the amount of information shared, these typically assume non-adaptive attacks that use likelihood ratio test (LRT) statistics.","We propose a Bayesian game-theoretic framework for optimal privacy-utility tradeoff in the sharing of genomic summary statistics.","Our first contribution is to prove that a very general Bayesian attacker model that anchors our game-theoretic approach is more powerful than the conventional LRT-based threat models in that it induces worse privacy loss for the defender who is modeled as a von Neumann-Morgenstern (vNM) decision-maker.","We show this to be true even when the attacker uses a non-informative subjective prior.","Next, we present an analytically tractable approach to compare the Bayesian attacks with arbitrary subjective priors and the Neyman-Pearson optimal LRT attacks under the Gaussian mechanism common in differential privacy frameworks.","Finally, we propose an approach for approximating Bayes-Nash equilibria of the game using deep neural network generators to implicitly represent player mixed strategies.","Our experiments demonstrate that the proposed game-theoretic framework yields both stronger attacks and stronger defense strategies than the state of the art."],"url":"http://arxiv.org/abs/2406.01811v1","category":"cs.CR"}
{"created":"2024-06-03 21:59:21","title":"In-Context Learning of Physical Properties: Few-Shot Adaptation to Out-of-Distribution Molecular Graphs","abstract":"Large language models manifest the ability of few-shot adaptation to a sequence of provided examples. This behavior, known as in-context learning, allows for performing nontrivial machine learning tasks during inference only. In this work, we address the question: can we leverage in-context learning to predict out-of-distribution materials properties? However, this would not be possible for structure property prediction tasks unless an effective method is found to pass atomic-level geometric features to the transformer model. To address this problem, we employ a compound model in which GPT-2 acts on the output of geometry-aware graph neural networks to adapt in-context information. To demonstrate our model's capabilities, we partition the QM9 dataset into sequences of molecules that share a common substructure and use them for in-context learning. This approach significantly improves the performance of the model on out-of-distribution examples, surpassing the one of general graph neural network models.","sentences":["Large language models manifest the ability of few-shot adaptation to a sequence of provided examples.","This behavior, known as in-context learning, allows for performing nontrivial machine learning tasks during inference only.","In this work, we address the question: can we leverage in-context learning to predict out-of-distribution materials properties?","However, this would not be possible for structure property prediction tasks unless an effective method is found to pass atomic-level geometric features to the transformer model.","To address this problem, we employ a compound model in which GPT-2 acts on the output of geometry-aware graph neural networks to adapt in-context information.","To demonstrate our model's capabilities, we partition the QM9 dataset into sequences of molecules that share a common substructure and use them for in-context learning.","This approach significantly improves the performance of the model on out-of-distribution examples, surpassing the one of general graph neural network models."],"url":"http://arxiv.org/abs/2406.01808v1","category":"cs.LG"}
{"created":"2024-06-03 21:50:40","title":"Leader-Follower Density Control of Spatial Dynamics in Large-Scale Multi-Agent Systems","abstract":"We address the problem of controlling the density of a large ensemble of follower agents by acting on group of leader agents that interact with them. We formulate the problem as a system of coupled partial integro-differential equations describing for the dynamics of the leaders' and followers' densities. We define feasibility conditions and propose two control architectures for exponential global stability. The first architecture is a feed-forward scheme for the followers. It adjusts the leaders' density via a feedback loop, which leverages information about leaders and a fixed reference density, to direct followers towards a target distribution. The second, dual feedback strategy employs a reference-governor to dynamically adapt the leaders' reference density based on measurements on both leaders and followers. Initially analyzed in one dimension, our methods are expanded to multi-dimensional applications. Numerical validations and an application in continuification-based control of leader-follower multiagent systems confirm the effectiveness of our approaches.","sentences":["We address the problem of controlling the density of a large ensemble of follower agents by acting on group of leader agents that interact with them.","We formulate the problem as a system of coupled partial integro-differential equations describing for the dynamics of the leaders' and followers' densities.","We define feasibility conditions and propose two control architectures for exponential global stability.","The first architecture is a feed-forward scheme for the followers.","It adjusts the leaders' density via a feedback loop, which leverages information about leaders and a fixed reference density, to direct followers towards a target distribution.","The second, dual feedback strategy employs a reference-governor to dynamically adapt the leaders' reference density based on measurements on both leaders and followers.","Initially analyzed in one dimension, our methods are expanded to multi-dimensional applications.","Numerical validations and an application in continuification-based control of leader-follower multiagent systems confirm the effectiveness of our approaches."],"url":"http://arxiv.org/abs/2406.01804v1","category":"eess.SY"}
{"created":"2024-06-03 21:32:50","title":"The Empirical Impact of Forgetting and Transfer in Continual Visual Odometry","abstract":"As robotics continues to advance, the need for adaptive and continuously-learning embodied agents increases, particularly in the realm of assistance robotics. Quick adaptability and long-term information retention are essential to operate in dynamic environments typical of humans' everyday lives. A lifelong learning paradigm is thus required, but it is scarcely addressed by current robotics literature. This study empirically investigates the impact of catastrophic forgetting and the effectiveness of knowledge transfer in neural networks trained continuously in an embodied setting. We focus on the task of visual odometry, which holds primary importance for embodied agents in enabling their self-localization. We experiment on the simple continual scenario of discrete transitions between indoor locations, akin to a robot navigating different apartments. In this regime, we observe initial satisfactory performance with high transferability between environments, followed by a specialization phase where the model prioritizes current environment-specific knowledge at the expense of generalization. Conventional regularization strategies and increased model capacity prove ineffective in mitigating this phenomenon. Rehearsal is instead mildly beneficial but with the addition of a substantial memory cost. Incorporating action information, as commonly done in embodied settings, facilitates quicker convergence but exacerbates specialization, making the model overly reliant on its motion expectations and less adept at correctly interpreting visual cues. These findings emphasize the open challenges of balancing adaptation and memory retention in lifelong robotics and contribute valuable insights into the application of a lifelong paradigm on embodied agents.","sentences":["As robotics continues to advance, the need for adaptive and continuously-learning embodied agents increases, particularly in the realm of assistance robotics.","Quick adaptability and long-term information retention are essential to operate in dynamic environments typical of humans' everyday lives.","A lifelong learning paradigm is thus required, but it is scarcely addressed by current robotics literature.","This study empirically investigates the impact of catastrophic forgetting and the effectiveness of knowledge transfer in neural networks trained continuously in an embodied setting.","We focus on the task of visual odometry, which holds primary importance for embodied agents in enabling their self-localization.","We experiment on the simple continual scenario of discrete transitions between indoor locations, akin to a robot navigating different apartments.","In this regime, we observe initial satisfactory performance with high transferability between environments, followed by a specialization phase where the model prioritizes current environment-specific knowledge at the expense of generalization.","Conventional regularization strategies and increased model capacity prove ineffective in mitigating this phenomenon.","Rehearsal is instead mildly beneficial but with the addition of a substantial memory cost.","Incorporating action information, as commonly done in embodied settings, facilitates quicker convergence but exacerbates specialization, making the model overly reliant on its motion expectations and less adept at correctly interpreting visual cues.","These findings emphasize the open challenges of balancing adaptation and memory retention in lifelong robotics and contribute valuable insights into the application of a lifelong paradigm on embodied agents."],"url":"http://arxiv.org/abs/2406.01797v1","category":"cs.CV"}
{"created":"2024-06-03 21:14:53","title":"Hybrid-Learning Video Moment Retrieval across Multi-Domain Labels","abstract":"Video moment retrieval (VMR) is to search for a visual temporal moment in an untrimmed raw video by a given text query description (sentence). Existing studies either start from collecting exhaustive frame-wise annotations on the temporal boundary of target moments (fully-supervised), or learn with only the video-level video-text pairing labels (weakly-supervised). The former is poor in generalisation to unknown concepts and/or novel scenes due to restricted dataset scale and diversity under expensive annotation costs; the latter is subject to visual-textual mis-correlations from incomplete labels. In this work, we introduce a new approach called hybrid-learning video moment retrieval to solve the problem by knowledge transfer through adapting the video-text matching relationships learned from a fully-supervised source domain to a weakly-labelled target domain when they do not share a common label space. Our aim is to explore shared universal knowledge between the two domains in order to improve model learning in the weakly-labelled target domain. Specifically, we introduce a multiplE branch Video-text Alignment model (EVA) that performs cross-modal (visual-textual) matching information sharing and multi-modal feature alignment to optimise domain-invariant visual and textual features as well as per-task discriminative joint video-text representations. Experiments show EVA's effectiveness in exploring temporal segment annotations in a source domain to help learn video moment retrieval without temporal labels in a target domain.","sentences":["Video moment retrieval (VMR) is to search for a visual temporal moment in an untrimmed raw video by a given text query description (sentence).","Existing studies either start from collecting exhaustive frame-wise annotations on the temporal boundary of target moments (fully-supervised), or learn with only the video-level video-text pairing labels (weakly-supervised).","The former is poor in generalisation to unknown concepts and/or novel scenes due to restricted dataset scale and diversity under expensive annotation costs; the latter is subject to visual-textual mis-correlations from incomplete labels.","In this work, we introduce a new approach called hybrid-learning video moment retrieval to solve the problem by knowledge transfer through adapting the video-text matching relationships learned from a fully-supervised source domain to a weakly-labelled target domain when they do not share a common label space.","Our aim is to explore shared universal knowledge between the two domains in order to improve model learning in the weakly-labelled target domain.","Specifically, we introduce a multiplE branch Video-text Alignment model (EVA) that performs cross-modal (visual-textual) matching information sharing and multi-modal feature alignment to optimise domain-invariant visual and textual features as well as per-task discriminative joint video-text representations.","Experiments show EVA's effectiveness in exploring temporal segment annotations in a source domain to help learn video moment retrieval without temporal labels in a target domain."],"url":"http://arxiv.org/abs/2406.01791v1","category":"cs.CV"}
{"created":"2024-06-03 20:37:27","title":"OLoRA: Orthonormal Low-Rank Adaptation of Large Language Models","abstract":"The advent of large language models (LLMs) has revolutionized natural language processing, enabling unprecedented capabilities in understanding and generating human-like text. However, the computational cost and convergence times associated with fine-tuning these models remain significant challenges. Low-Rank Adaptation (LoRA) has emerged as a promising method to mitigate these issues by introducing efficient fine-tuning techniques with a reduced number of trainable parameters. In this paper, we present OLoRA, an enhancement to the LoRA method that leverages orthonormal matrix initialization through QR decomposition. OLoRA significantly accelerates the convergence of LLM training while preserving the efficiency benefits of LoRA, such as the number of trainable parameters and GPU memory footprint. Our empirical evaluations demonstrate that OLoRA not only converges faster but also exhibits improved performance compared to standard LoRA across a variety of language modeling tasks. This advancement opens new avenues for more efficient and accessible fine-tuning of LLMs, potentially enabling broader adoption and innovation in natural language applications.","sentences":["The advent of large language models (LLMs) has revolutionized natural language processing, enabling unprecedented capabilities in understanding and generating human-like text.","However, the computational cost and convergence times associated with fine-tuning these models remain significant challenges.","Low-Rank Adaptation (LoRA) has emerged as a promising method to mitigate these issues by introducing efficient fine-tuning techniques with a reduced number of trainable parameters.","In this paper, we present OLoRA, an enhancement to the LoRA method that leverages orthonormal matrix initialization through QR decomposition.","OLoRA significantly accelerates the convergence of LLM training while preserving the efficiency benefits of LoRA, such as the number of trainable parameters and GPU memory footprint.","Our empirical evaluations demonstrate that OLoRA not only converges faster but also exhibits improved performance compared to standard LoRA across a variety of language modeling tasks.","This advancement opens new avenues for more efficient and accessible fine-tuning of LLMs, potentially enabling broader adoption and innovation in natural language applications."],"url":"http://arxiv.org/abs/2406.01775v1","category":"cs.CL"}
{"created":"2024-06-03 19:28:01","title":"3D transcranial Dynamic Ultrasound Localization Microscopy in the mouse brain using a Row-Column Array","abstract":"The role of brain hemodynamics in neurodegenerative diseases cannot be fully assessed using existing imaging technologies. Recently, 2D Dynamic Ultrasound Localization Microscopy (DULM) has allowed for the quantitative mapping of the pulsatile flow at sub-wavelength resolution. However, to obtain accurate velocity estimates, 3D imaging is more adapted, especially for complex vascularized organs like the brain. 3D+t DULM is achievable using matrix array probes, but suffers from limitations in terms of cost, device complexity associated with the high channel count, and operating frequencies. Alternatively, Row Column Arrays (RCA) can reduce the number of elements while maintaining a large field of view and high frame rate. Herein, we demonstrate the feasibility of performing 3D+t blood flow measurements in the mouse brain using an RCA and a DULM sequence with a high spatiotemporal resolution. Transcranial images of anesthetized mice (n=7) were acquired at a volume rate of 750 Hz using 42 tilted plane waves. After microbubbles localization and tracking, super-resolved dynamic density and velocity maps of the 3D brain vascular network were obtained. Cortical vessels were segmented and pulsatility in the arteries was significantly higher than in veins for all mice, in accordance with the literature. Our results demonstrate the feasibility and reproducibility of achieving high spatiotemporal resolution volumes of the mouse brain vasculature with DULM using a RCA.","sentences":["The role of brain hemodynamics in neurodegenerative diseases cannot be fully assessed using existing imaging technologies.","Recently, 2D Dynamic Ultrasound Localization Microscopy (DULM) has allowed for the quantitative mapping of the pulsatile flow at sub-wavelength resolution.","However, to obtain accurate velocity estimates, 3D imaging is more adapted, especially for complex vascularized organs like the brain.","3D+t DULM is achievable using matrix array probes, but suffers from limitations in terms of cost, device complexity associated with the high channel count, and operating frequencies.","Alternatively, Row Column Arrays (RCA) can reduce the number of elements while maintaining a large field of view and high frame rate.","Herein, we demonstrate the feasibility of performing 3D+t blood flow measurements in the mouse brain using an RCA and a DULM sequence with a high spatiotemporal resolution.","Transcranial images of anesthetized mice (n=7) were acquired at a volume rate of 750 Hz using 42 tilted plane waves.","After microbubbles localization and tracking, super-resolved dynamic density and velocity maps of the 3D brain vascular network were obtained.","Cortical vessels were segmented and pulsatility in the arteries was significantly higher than in veins for all mice, in accordance with the literature.","Our results demonstrate the feasibility and reproducibility of achieving high spatiotemporal resolution volumes of the mouse brain vasculature with DULM using a RCA."],"url":"http://arxiv.org/abs/2406.01746v1","category":"physics.med-ph"}
{"created":"2024-06-03 18:45:34","title":"The density conjecture for activated random walk","abstract":"In the late 1990s, Dickman, Mu\\~noz, Vespignani, and Zapperi explained the self-organized criticality observed by Bak, Tang, and Wiesenfeld as an external force pushing a hidden parameter toward the critical value of a traditional absorbing-state phase transition. As evidence, they observed empirically that for various sandpile models the particle density in a finite box under driven-dissipative dynamics converges to the critical density of an infinite-volume version of the model. We give the first proof of this well-known density conjecture in any setting by establishing it for activated random walk in one dimension. We prove that two other natural versions of the model have the same critical value, further establishing activated random walk as a universal model of self-organized criticality.","sentences":["In the late 1990s, Dickman, Mu\\~noz, Vespignani, and Zapperi explained the self-organized criticality observed by Bak, Tang, and Wiesenfeld as an external force pushing a hidden parameter toward the critical value of a traditional absorbing-state phase transition.","As evidence, they observed empirically that for various sandpile models the particle density in a finite box under driven-dissipative dynamics converges to the critical density of an infinite-volume version of the model.","We give the first proof of this well-known density conjecture in any setting by establishing it for activated random walk in one dimension.","We prove that two other natural versions of the model have the same critical value, further establishing activated random walk as a universal model of self-organized criticality."],"url":"http://arxiv.org/abs/2406.01731v1","category":"math.PR"}
{"created":"2024-06-03 18:01:43","title":"Snowflake: A Distributed Streaming Decoder","abstract":"We design Snowflake, a quantum error correction decoder that runs in a streaming fashion and is capable of a simple, local implementation. In doing so we propose a new method for general stream decoding that eliminates the processing overhead due to window overlap in existing windowing methods. As a first study, we test our local implementation of Snowflake on the surface code under circuit-level noise. It recovers roughly 2/3 the accuracy threshold of the Union-Find decoder adapted with a windowing method, with a better mean runtime scaling: subquadratic as opposed to cubic in code distance $d$. We discuss how Snowflake may be implemented on a 2D chip and decode not just quantum memory but lattice surgery-based computation.","sentences":["We design Snowflake, a quantum error correction decoder that runs in a streaming fashion and is capable of a simple, local implementation.","In doing so we propose a new method for general stream decoding that eliminates the processing overhead due to window overlap in existing windowing methods.","As a first study, we test our local implementation of Snowflake on the surface code under circuit-level noise.","It recovers roughly 2/3 the accuracy threshold of the Union-Find decoder adapted with a windowing method, with a better mean runtime scaling: subquadratic as opposed to cubic in code distance $d$.","We discuss how Snowflake may be implemented on a 2D chip and decode not just quantum memory but lattice surgery-based computation."],"url":"http://arxiv.org/abs/2406.01701v1","category":"quant-ph"}
{"created":"2024-06-03 18:00:01","title":"Color Glass Condensate meets High Twist Expansion","abstract":"We establish the correspondence between two well-known frameworks for QCD multiple scattering in nuclear media: the Color Glass Condensate (CGC) and the High-Twist (HT) expansion formalism. We argue that a consistent matching between both frameworks, in their common domain of validity, is achieved by incorporating the sub-eikonal longitudinal momentum phase in the CGC formalism, which mediates the transition between coherent and incoherent scattering. We perform a detailed calculation and analysis of direct photon production in proton-nucleus scattering as a concrete example to establish the matching between HT and CGC up to twist-4, including initial- and final-state interactions, as well as their interferences. The techniques developed in this work can be adapted to other processes in electron-nucleus and proton-nucleus collisions, and they provide a potential avenue for a unified picture of dilute-dense dynamics in nuclear media.","sentences":["We establish the correspondence between two well-known frameworks for QCD multiple scattering in nuclear media: the Color Glass Condensate (CGC) and the High-Twist (HT) expansion formalism.","We argue that a consistent matching between both frameworks, in their common domain of validity, is achieved by incorporating the sub-eikonal longitudinal momentum phase in the CGC formalism, which mediates the transition between coherent and incoherent scattering.","We perform a detailed calculation and analysis of direct photon production in proton-nucleus scattering as a concrete example to establish the matching between HT and CGC up to twist-4, including initial- and final-state interactions, as well as their interferences.","The techniques developed in this work can be adapted to other processes in electron-nucleus and proton-nucleus collisions, and they provide a potential avenue for a unified picture of dilute-dense dynamics in nuclear media."],"url":"http://arxiv.org/abs/2406.01684v1","category":"hep-ph"}
{"created":"2024-06-03 17:59:53","title":"DiffUHaul: A Training-Free Method for Object Dragging in Images","abstract":"Text-to-image diffusion models have proven effective for solving many image editing tasks. However, the seemingly straightforward task of seamlessly relocating objects within a scene remains surprisingly challenging. Existing methods addressing this problem often struggle to function reliably in real-world scenarios due to lacking spatial reasoning. In this work, we propose a training-free method, dubbed DiffUHaul, that harnesses the spatial understanding of a localized text-to-image model, for the object dragging task. Blindly manipulating layout inputs of the localized model tends to cause low editing performance due to the intrinsic entanglement of object representation in the model. To this end, we first apply attention masking in each denoising step to make the generation more disentangled across different objects and adopt the self-attention sharing mechanism to preserve the high-level object appearance. Furthermore, we propose a new diffusion anchoring technique: in the early denoising steps, we interpolate the attention features between source and target images to smoothly fuse new layouts with the original appearance; in the later denoising steps, we pass the localized features from the source images to the interpolated images to retain fine-grained object details. To adapt DiffUHaul to real-image editing, we apply a DDPM self-attention bucketing that can better reconstruct real images with the localized model. Finally, we introduce an automated evaluation pipeline for this task and showcase the efficacy of our method. Our results are reinforced through a user preference study.","sentences":["Text-to-image diffusion models have proven effective for solving many image editing tasks.","However, the seemingly straightforward task of seamlessly relocating objects within a scene remains surprisingly challenging.","Existing methods addressing this problem often struggle to function reliably in real-world scenarios due to lacking spatial reasoning.","In this work, we propose a training-free method, dubbed DiffUHaul, that harnesses the spatial understanding of a localized text-to-image model, for the object dragging task.","Blindly manipulating layout inputs of the localized model tends to cause low editing performance due to the intrinsic entanglement of object representation in the model.","To this end, we first apply attention masking in each denoising step to make the generation more disentangled across different objects and adopt the self-attention sharing mechanism to preserve the high-level object appearance.","Furthermore, we propose a new diffusion anchoring technique: in the early denoising steps, we interpolate the attention features between source and target images to smoothly fuse new layouts with the original appearance; in the later denoising steps, we pass the localized features from the source images to the interpolated images to retain fine-grained object details.","To adapt DiffUHaul to real-image editing, we apply a DDPM self-attention bucketing that can better reconstruct real images with the localized model.","Finally, we introduce an automated evaluation pipeline for this task and showcase the efficacy of our method.","Our results are reinforced through a user preference study."],"url":"http://arxiv.org/abs/2406.01594v1","category":"cs.CV"}
{"created":"2024-06-03 17:59:51","title":"Reconstructing and Simulating Dynamic 3D Objects with Mesh-adsorbed Gaussian Splatting","abstract":"3D reconstruction and simulation, while interrelated, have distinct objectives: reconstruction demands a flexible 3D representation adaptable to diverse scenes, whereas simulation requires a structured representation to model motion principles effectively. This paper introduces the Mesh-adsorbed Gaussian Splatting (MaGS) method to resolve such a dilemma. MaGS constrains 3D Gaussians to hover on the mesh surface, creating a mutual-adsorbed mesh-Gaussian 3D representation that combines the rendering flexibility of 3D Gaussians with the spatial coherence of meshes. Leveraging this representation, we introduce a learnable Relative Deformation Field (RDF) to model the relative displacement between the mesh and 3D Gaussians, extending traditional mesh-driven deformation paradigms that only rely on ARAP prior, thus capturing the motion of each 3D Gaussian more precisely. By joint optimizing meshes, 3D Gaussians, and RDF, MaGS achieves both high rendering accuracy and realistic deformation. Extensive experiments on the D-NeRF and NeRF-DS datasets demonstrate that MaGS can generate competitive results in both reconstruction and simulation.","sentences":["3D reconstruction and simulation, while interrelated, have distinct objectives: reconstruction demands a flexible 3D representation adaptable to diverse scenes, whereas simulation requires a structured representation to model motion principles effectively.","This paper introduces the Mesh-adsorbed Gaussian Splatting (MaGS) method to resolve such a dilemma.","MaGS constrains 3D Gaussians to hover on the mesh surface, creating a mutual-adsorbed mesh-Gaussian 3D representation that combines the rendering flexibility of 3D Gaussians with the spatial coherence of meshes.","Leveraging this representation, we introduce a learnable Relative Deformation Field (RDF) to model the relative displacement between the mesh and 3D Gaussians, extending traditional mesh-driven deformation paradigms that only rely on ARAP prior, thus capturing the motion of each 3D Gaussian more precisely.","By joint optimizing meshes, 3D Gaussians, and RDF, MaGS achieves both high rendering accuracy and realistic deformation.","Extensive experiments on the D-NeRF and NeRF-DS datasets demonstrate that MaGS can generate competitive results in both reconstruction and simulation."],"url":"http://arxiv.org/abs/2406.01593v1","category":"cs.CV"}
{"created":"2024-06-03 17:59:34","title":"DeNVeR: Deformable Neural Vessel Representations for Unsupervised Video Vessel Segmentation","abstract":"This paper presents Deformable Neural Vessel Representations (DeNVeR), an unsupervised approach for vessel segmentation in X-ray videos without annotated ground truth. DeNVeR uses optical flow and layer separation, enhancing segmentation accuracy and adaptability through test-time training. A key component of our research is the introduction of the XACV dataset, the first X-ray angiography coronary video dataset with high-quality, manually labeled segmentation ground truth. Our evaluation demonstrates that DeNVeR outperforms current state-of-the-art methods in vessel segmentation. This paper marks an advance in medical imaging, providing a robust, data-efficient tool for disease diagnosis and treatment planning and setting a new standard for future research in video vessel segmentation. See our project page for video results at https://kirito878.github.io/DeNVeR/.","sentences":["This paper presents Deformable Neural Vessel Representations (DeNVeR), an unsupervised approach for vessel segmentation in X-ray videos without annotated ground truth.","DeNVeR uses optical flow and layer separation, enhancing segmentation accuracy and adaptability through test-time training.","A key component of our research is the introduction of the XACV dataset, the first X-ray angiography coronary video dataset with high-quality, manually labeled segmentation ground truth.","Our evaluation demonstrates that DeNVeR outperforms current state-of-the-art methods in vessel segmentation.","This paper marks an advance in medical imaging, providing a robust, data-efficient tool for disease diagnosis and treatment planning and setting a new standard for future research in video vessel segmentation.","See our project page for video results at https://kirito878.github.io/DeNVeR/."],"url":"http://arxiv.org/abs/2406.01591v1","category":"cs.CV"}
{"created":"2024-06-03 17:58:17","title":"Variational time reversal for free energy estimation in nonequilibrium steady states","abstract":"Studying the structure of systems in nonequilibrium steady states necessitates tools that quantify population shifts and associated deformations of equilibrium free energy landscapes under persistent currents. Within the framework of stochastic thermodynamics, we establish a variant of the Kawasaki--Crooks equality that relates nonequilibrium free energy corrections in driven systems to heat dissipation statistics along time-reversed relaxation trajectories computable with molecular simulation. Using stochastic control theory, we arrive at a variational approach to evaluate the Kawasaki--Crooks equality and use it to estimate distribution functions of order parameters in overdamped Langevin models of active matter, attaining substantial improvement in accuracy over simple perturbative methods.","sentences":["Studying the structure of systems in nonequilibrium steady states necessitates tools that quantify population shifts and associated deformations of equilibrium free energy landscapes under persistent currents.","Within the framework of stochastic thermodynamics, we establish a variant of the Kawasaki--Crooks equality that relates nonequilibrium free energy corrections in driven systems to heat dissipation statistics along time-reversed relaxation trajectories computable with molecular simulation.","Using stochastic control theory, we arrive at a variational approach to evaluate the Kawasaki--Crooks equality and use it to estimate distribution functions of order parameters in overdamped Langevin models of active matter, attaining substantial improvement in accuracy over simple perturbative methods."],"url":"http://arxiv.org/abs/2406.01582v1","category":"cond-mat.stat-mech"}
{"created":"2024-06-03 17:54:58","title":"An Equivalence Between Static and Dynamic Regret Minimization","abstract":"We study the problem of dynamic regret minimization in online convex optimization, in which the objective is to minimize the difference between the cumulative loss of an algorithm and that of an arbitrary sequence of comparators. While the literature on this topic is very rich, a unifying framework for the analysis and design of these algorithms is still missing. In this paper, \\emph{we show that dynamic regret minimization is equivalent to static regret minimization in an extended decision space}. Using this simple observation, we show that there is a frontier of lower bounds trading off penalties due to the variance of the losses and penalties due to variability of the comparator sequence, and provide a framework for achieving any of the guarantees along this frontier. As a result, we prove for the first time that adapting to the squared path-length of an arbitrary sequence of comparators to achieve regret $R_{T}(u_{1},\\dots,u_{T})\\le O(\\sqrt{T\\sum_{t} \\|u_{t}-u_{t+1}\\|^{2}})$ is impossible. However, we prove that it is possible to adapt to a new notion of variability based on the locally-smoothed squared path-length of the comparator sequence, and provide an algorithm guaranteeing dynamic regret of the form $R_{T}(u_{1},\\dots,u_{T})\\le \\tilde O(\\sqrt{T\\sum_{i}\\|\\bar u_{i}-\\bar u_{i+1}\\|^{2}})$. Up to polylogarithmic terms, the new notion of variability is never worse than the classic one involving the path-length.","sentences":["We study the problem of dynamic regret minimization in online convex optimization, in which the objective is to minimize the difference between the cumulative loss of an algorithm and that of an arbitrary sequence of comparators.","While the literature on this topic is very rich, a unifying framework for the analysis and design of these algorithms is still missing.","In this paper, \\emph{we show that dynamic regret minimization is equivalent to static regret minimization in an extended decision space}.","Using this simple observation, we show that there is a frontier of lower bounds trading off penalties due to the variance of the losses and penalties due to variability of the comparator sequence, and provide a framework for achieving any of the guarantees along this frontier.","As a result, we prove for the first time that adapting to the squared path-length of an arbitrary sequence of comparators to achieve regret $R_{T}(u_{1},\\dots,u_{T})\\le O(\\sqrt{T\\sum_{t} \\|u_{t}-u_{t+1}\\|^{2}})$ is impossible.","However, we prove that it is possible to adapt to a new notion of variability based on the locally-smoothed squared path-length of the comparator sequence, and provide an algorithm guaranteeing dynamic regret of the form $R_{T}(u_{1},\\dots,u_{T})\\le","\\tilde O(\\sqrt{T\\sum_{i}\\|\\bar u_{i}-\\bar","u_{i+1}\\|^{2}})$. Up to polylogarithmic terms, the new notion of variability is never worse than the classic one involving the path-length."],"url":"http://arxiv.org/abs/2406.01577v1","category":"cs.LG"}
{"created":"2024-06-03 17:45:41","title":"LoFiT: Localized Fine-tuning on LLM Representations","abstract":"Recent work in interpretability shows that large language models (LLMs) can be adapted for new tasks in a learning-free way: it is possible to intervene on LLM representations to elicit desired behaviors for alignment. For instance, adding certain bias vectors to the outputs of certain attention heads is reported to boost the truthfulness of models. In this work, we show that localized fine-tuning serves as an effective alternative to such representation intervention methods. We introduce a framework called Localized Fine-Tuning on LLM Representations (LoFiT), which identifies a subset of attention heads that are most important for learning a specific task, then trains offset vectors to add to the model's hidden representations at those selected heads. LoFiT localizes to a sparse set of heads (3%) and learns the offset vectors from limited training data, comparable to the settings used for representation intervention. For truthfulness and reasoning tasks, we find that LoFiT's intervention vectors are more effective for LLM adaptation than vectors from representation intervention methods such as Inference-time Intervention. We also find that the localization step is important: selecting a task-specific set of attention heads can lead to higher performance than intervening on heads selected for a different task. Finally, for the tasks we study, LoFiT achieves comparable performance to other parameter-efficient fine-tuning methods such as LoRA, despite modifying 20x-200x fewer parameters than these methods.","sentences":["Recent work in interpretability shows that large language models (LLMs) can be adapted for new tasks in a learning-free way: it is possible to intervene on LLM representations to elicit desired behaviors for alignment.","For instance, adding certain bias vectors to the outputs of certain attention heads is reported to boost the truthfulness of models.","In this work, we show that localized fine-tuning serves as an effective alternative to such representation intervention methods.","We introduce a framework called Localized Fine-Tuning on LLM Representations (LoFiT), which identifies a subset of attention heads that are most important for learning a specific task, then trains offset vectors to add to the model's hidden representations at those selected heads.","LoFiT localizes to a sparse set of heads (3%) and learns the offset vectors from limited training data, comparable to the settings used for representation intervention.","For truthfulness and reasoning tasks, we find that LoFiT's intervention vectors are more effective for LLM adaptation than vectors from representation intervention methods such as Inference-time Intervention.","We also find that the localization step is important: selecting a task-specific set of attention heads can lead to higher performance than intervening on heads selected for a different task.","Finally, for the tasks we study, LoFiT achieves comparable performance to other parameter-efficient fine-tuning methods such as LoRA, despite modifying 20x-200x fewer parameters than these methods."],"url":"http://arxiv.org/abs/2406.01563v1","category":"cs.CL"}
{"created":"2024-06-03 17:38:24","title":"Bayesian compositional regression with flexible microbiome feature aggregation and selection","abstract":"Ongoing advances in microbiome profiling have allowed unprecedented insights into the molecular activities of microbial communities. This has fueled a strong scientific interest in understanding the critical role the microbiome plays in governing human health, by identifying microbial features associated with clinical outcomes of interest. Several aspects of microbiome data limit the applicability of existing variable selection approaches. In particular, microbiome data are high-dimensional, extremely sparse, and compositional. Importantly, many of the observed features, although categorized as different taxa, may play related functional roles. To address these challenges, we propose a novel compositional regression approach that leverages the data-adaptive clustering and variable selection properties of the spiked Dirichlet process to identify taxa that exhibit similar functional roles. Our proposed method, Bayesian Regression with Agglomerated Compositional Effects using a dirichLET process (BRACElet), enables the identification of a sparse set of features with shared impacts on the outcome, facilitating dimension reduction and model interpretation. We demonstrate that BRACElet outperforms existing approaches for microbiome variable selection through simulation studies and an application elucidating the impact of oral microbiome composition on insulin resistance.","sentences":["Ongoing advances in microbiome profiling have allowed unprecedented insights into the molecular activities of microbial communities.","This has fueled a strong scientific interest in understanding the critical role the microbiome plays in governing human health, by identifying microbial features associated with clinical outcomes of interest.","Several aspects of microbiome data limit the applicability of existing variable selection approaches.","In particular, microbiome data are high-dimensional, extremely sparse, and compositional.","Importantly, many of the observed features, although categorized as different taxa, may play related functional roles.","To address these challenges, we propose a novel compositional regression approach that leverages the data-adaptive clustering and variable selection properties of the spiked Dirichlet process to identify taxa that exhibit similar functional roles.","Our proposed method, Bayesian Regression with Agglomerated Compositional Effects using a dirichLET process (BRACElet), enables the identification of a sparse set of features with shared impacts on the outcome, facilitating dimension reduction and model interpretation.","We demonstrate that BRACElet outperforms existing approaches for microbiome variable selection through simulation studies and an application elucidating the impact of oral microbiome composition on insulin resistance."],"url":"http://arxiv.org/abs/2406.01557v1","category":"stat.ME"}
{"created":"2024-06-03 17:36:36","title":"Proxy Denoising for Source-Free Domain Adaptation","abstract":"Source-free Domain Adaptation (SFDA) aims to adapt a pre-trained source model to an unlabeled target domain with no access to the source data. Inspired by the success of pre-trained large vision-language (ViL) models in many other applications, the latest SFDA methods have also validated the benefit of ViL models by leveraging their predictions as pseudo supervision. However, we observe that ViL's predictions could be noisy and inaccurate at an unknown rate, potentially introducing additional negative effects during adaption. To address this thus-far ignored challenge, in this paper, we introduce a novel Proxy Denoising (ProDe) approach. Specifically, we leverage the ViL model as a proxy to facilitate the adaptation process towards the latent domain-invariant space. Critically, we design a proxy denoising mechanism for correcting ViL's predictions. This is grounded on a novel proxy confidence theory by modeling elegantly the domain adaption effect of the proxy's divergence against the domain-invariant space. To capitalize the corrected proxy, we further derive a mutual knowledge distilling regularization. Extensive experiments show that our ProDe significantly outperforms the current state-of-the-art alternatives under both conventional closed-set setting and the more challenging open-set, partial-set and generalized SFDA settings. The code will release soon.","sentences":["Source-free Domain Adaptation (SFDA) aims to adapt a pre-trained source model to an unlabeled target domain with no access to the source data.","Inspired by the success of pre-trained large vision-language (ViL) models in many other applications, the latest SFDA methods have also validated the benefit of ViL models by leveraging their predictions as pseudo supervision.","However, we observe that ViL's predictions could be noisy and inaccurate at an unknown rate, potentially introducing additional negative effects during adaption.","To address this thus-far ignored challenge, in this paper, we introduce a novel Proxy Denoising (ProDe) approach.","Specifically, we leverage the ViL model as a proxy to facilitate the adaptation process towards the latent domain-invariant space.","Critically, we design a proxy denoising mechanism for correcting ViL's predictions.","This is grounded on a novel proxy confidence theory by modeling elegantly the domain adaption effect of the proxy's divergence against the domain-invariant space.","To capitalize the corrected proxy, we further derive a mutual knowledge distilling regularization.","Extensive experiments show that our ProDe significantly outperforms the current state-of-the-art alternatives under both conventional closed-set setting and the more challenging open-set, partial-set and generalized SFDA settings.","The code will release soon."],"url":"http://arxiv.org/abs/2406.01658v1","category":"cs.CV"}
{"created":"2024-06-03 17:34:37","title":"Towards Flexible Interactive Reflection Removal with Human Guidance","abstract":"Single image reflection removal is inherently ambiguous, as both the reflection and transmission components requiring separation may follow natural image statistics. Existing methods attempt to address the issue by using various types of low-level and physics-based cues as sources of reflection signals. However, these cues are not universally applicable, since they are only observable in specific capture scenarios. This leads to a significant performance drop when test images do not align with their assumptions. In this paper, we aim to explore a novel flexible interactive reflection removal approach that leverages various forms of sparse human guidance, such as points and bounding boxes, as auxiliary high-level prior to achieve robust reflection removal. However, incorporating the raw user guidance naively into the existing reflection removal network does not result in performance gains. To this end, we innovatively transform raw user input into a unified form -- reflection masks using an Interactive Segmentation Foundation Model. Such a design absorbs the quintessence of the foundational segmentation model and flexible human guidance, thereby mitigating the challenges of reflection separations. Furthermore, to fully utilize user guidance and reduce user annotation costs, we design a mask-guided reflection removal network, comprising our proposed self-adaptive prompt block. This block adaptively incorporates user guidance as anchors and refines transmission features via cross-attention mechanisms. Extensive results on real-world images validate that our method demonstrates state-of-the-art performance on various datasets with the help of flexible and sparse user guidance. Our code and dataset will be publicly available here https://github.com/ShawnChenn/FlexibleReflectionRemoval.","sentences":["Single image reflection removal is inherently ambiguous, as both the reflection and transmission components requiring separation may follow natural image statistics.","Existing methods attempt to address the issue by using various types of low-level and physics-based cues as sources of reflection signals.","However, these cues are not universally applicable, since they are only observable in specific capture scenarios.","This leads to a significant performance drop when test images do not align with their assumptions.","In this paper, we aim to explore a novel flexible interactive reflection removal approach that leverages various forms of sparse human guidance, such as points and bounding boxes, as auxiliary high-level prior to achieve robust reflection removal.","However, incorporating the raw user guidance naively into the existing reflection removal network does not result in performance gains.","To this end, we innovatively transform raw user input into a unified form -- reflection masks using an Interactive Segmentation Foundation Model.","Such a design absorbs the quintessence of the foundational segmentation model and flexible human guidance, thereby mitigating the challenges of reflection separations.","Furthermore, to fully utilize user guidance and reduce user annotation costs, we design a mask-guided reflection removal network, comprising our proposed self-adaptive prompt block.","This block adaptively incorporates user guidance as anchors and refines transmission features via cross-attention mechanisms.","Extensive results on real-world images validate that our method demonstrates state-of-the-art performance on various datasets with the help of flexible and sparse user guidance.","Our code and dataset will be publicly available here https://github.com/ShawnChenn/FlexibleReflectionRemoval."],"url":"http://arxiv.org/abs/2406.01555v1","category":"cs.CV"}
{"created":"2024-06-03 17:27:40","title":"TinySV: Speaker Verification in TinyML with On-device Learning","abstract":"TinyML is a novel area of machine learning that gained huge momentum in the last few years thanks to the ability to execute machine learning algorithms on tiny devices (such as Internet-of-Things or embedded systems). Interestingly, research in this area focused on the efficient execution of the inference phase of TinyML models on tiny devices, while very few solutions for on-device learning of TinyML models are available in the literature due to the relevant overhead introduced by the learning algorithms.   The aim of this paper is to introduce a new type of adaptive TinyML solution that can be used in tasks, such as the presented \\textit{Tiny Speaker Verification} (TinySV), that require to be tackled with an on-device learning algorithm. Achieving this goal required (i) reducing the memory and computational demand of TinyML learning algorithms, and (ii) designing a TinyML learning algorithm operating with few and possibly unlabelled training data. The proposed TinySV solution relies on a two-layer hierarchical TinyML solution comprising Keyword Spotting and Adaptive Speaker Verification module. We evaluated the effectiveness and efficiency of the proposed TinySV solution on a dataset collected expressly for the task and tested the proposed solution on a real-world IoT device (Infineon PSoC 62S2 Wi-Fi BT Pioneer Kit).","sentences":["TinyML is a novel area of machine learning that gained huge momentum in the last few years thanks to the ability to execute machine learning algorithms on tiny devices (such as Internet-of-Things or embedded systems).","Interestingly, research in this area focused on the efficient execution of the inference phase of TinyML models on tiny devices, while very few solutions for on-device learning of TinyML models are available in the literature due to the relevant overhead introduced by the learning algorithms.   ","The aim of this paper is to introduce a new type of adaptive TinyML solution that can be used in tasks, such as the presented \\textit{Tiny Speaker Verification} (TinySV), that require to be tackled with an on-device learning algorithm.","Achieving this goal required (i) reducing the memory and computational demand of TinyML learning algorithms, and (ii) designing a TinyML learning algorithm operating with few and possibly unlabelled training data.","The proposed TinySV solution relies on a two-layer hierarchical TinyML solution comprising Keyword Spotting and Adaptive Speaker Verification module.","We evaluated the effectiveness and efficiency of the proposed TinySV solution on a dataset collected expressly for the task and tested the proposed solution on a real-world IoT device (Infineon PSoC","62S2","Wi-Fi BT Pioneer Kit)."],"url":"http://arxiv.org/abs/2406.01655v1","category":"cs.SD"}
{"created":"2024-06-03 17:23:00","title":"CO in the Draco Nebula: The Atomic-Molecular Transition","abstract":"This paper presents maps of the J=2-1 transition of CO toward the Draco Nebula Intermediate Velocity Cloud (IVC). The maps cover 8500 square arcmin with a velocity resolution of 0.33 km~s$^{-1}$ and angular resolution of 38\", or 0.11 pc at the cloud distance of 600 pc. The mapped area includes all the emission detected by the {\\it Herschel} satellite with 250 $\\mu$m intensity >5 MJy/sr. Previously published observations of the far-IR emission and the 21 cm line of HI are used to derive the column density distribution of H$_2$ and the abundance ratio CO/H$_2$, as well as the distribution of the molecular fraction of hydrogen, which approaches 90\\% over much of the brighter parts of the nebula. The CO emission is highly clumpy and closely resembles the structures seen in far-IR images. The kinematics of the CO show supersonic motions between clumps but near-thermal to trans-sonic motions within clumps, consistent with model predictions that the scale length for dissipation of supersonic turbulence should be $\\sim0.1$ pc, mediated by kinematic viscosity and/or ambipolar diffusion. Different parts of the nebula show evidence for a spread of molecular formation timescales of a few 10$^5$ years, comparable to the dynamical timescale of the infalling gas. The IVC will likely merge with the Galactic interstellar medium in $\\sim 10^7$ years, and the densest clumps may form an unbound cluster of low-mass stars.","sentences":["This paper presents maps of the J=2-1 transition of CO toward the Draco Nebula Intermediate Velocity Cloud (IVC).","The maps cover 8500 square arcmin with a velocity resolution of 0.33 km~s$^{-1}$ and angular resolution of 38\", or 0.11 pc at the cloud distance of 600 pc.","The mapped area includes all the emission detected by the {\\it Herschel} satellite with 250 $\\mu$m intensity >5 MJy/sr.","Previously published observations of the far-IR emission and the 21 cm line of HI are used to derive the column density distribution of H$_2$ and the abundance ratio CO/H$_2$, as well as the distribution of the molecular fraction of hydrogen, which approaches 90\\% over much of the brighter parts of the nebula.","The CO emission is highly clumpy and closely resembles the structures seen in far-IR images.","The kinematics of the CO show supersonic motions between clumps but near-thermal to trans-sonic motions within clumps, consistent with model predictions that the scale length for dissipation of supersonic turbulence should be $\\sim0.1$ pc, mediated by kinematic viscosity and/or ambipolar diffusion.","Different parts of the nebula show evidence for a spread of molecular formation timescales of a few 10$^5$ years, comparable to the dynamical timescale of the infalling gas.","The IVC will likely merge with the Galactic interstellar medium in $\\sim 10^7$ years, and the densest clumps may form an unbound cluster of low-mass stars."],"url":"http://arxiv.org/abs/2406.01542v1","category":"astro-ph.GA"}
{"created":"2024-06-03 17:19:30","title":"Adaptive discretization algorithms for locally optimal experimental design","abstract":"We develop adaptive discretization algorithms for locally optimal experimental design of nonlinear prediction models. With these algorithms, we refine and improve a pertinent state-of-the-art algorithm in various respects. We establish novel termination, convergence, and convergence rate results for the proposed algorithms. In particular, we prove a sublinear convergence rate result under very general assumptions on the design criterion and, most notably, a linear convergence result under the additional assumption that the design criterion is strongly convex and the design space is finite. Additionally, we prove the finite termination at approximately optimal designs, including upper bounds on the number of iterations until termination. And finally, we illustrate the practical use of the proposed algorithms by means of two application examples from chemical engineering: one with a stationary model and one with a dynamic model.","sentences":["We develop adaptive discretization algorithms for locally optimal experimental design of nonlinear prediction models.","With these algorithms, we refine and improve a pertinent state-of-the-art algorithm in various respects.","We establish novel termination, convergence, and convergence rate results for the proposed algorithms.","In particular, we prove a sublinear convergence rate result under very general assumptions on the design criterion and, most notably, a linear convergence result under the additional assumption that the design criterion is strongly convex and the design space is finite.","Additionally, we prove the finite termination at approximately optimal designs, including upper bounds on the number of iterations until termination.","And finally, we illustrate the practical use of the proposed algorithms by means of two application examples from chemical engineering: one with a stationary model and one with a dynamic model."],"url":"http://arxiv.org/abs/2406.01541v1","category":"math.OC"}
{"created":"2024-06-03 16:51:57","title":"MOSEAC: Streamlined Variable Time Step Reinforcement Learning","abstract":"Traditional reinforcement learning (RL) methods typically employ a fixed control loop, where each cycle corresponds to an action. This rigidity poses challenges in practical applications, as the optimal control frequency is task-dependent. A suboptimal choice can lead to high computational demands and reduced exploration efficiency. Variable Time Step Reinforcement Learning (VTS-RL) addresses these issues by using adaptive frequencies for the control loop, executing actions only when necessary. This approach, rooted in reactive programming principles, reduces computational load and extends the action space by including action durations. However, VTS-RL's implementation is often complicated by the need to tune multiple hyperparameters that govern exploration in the multi-objective action-duration space (i.e., balancing task performance and number of time steps to achieve a goal). To overcome these challenges, we introduce the Multi-Objective Soft Elastic Actor-Critic (MOSEAC) method. This method features an adaptive reward scheme that adjusts hyperparameters based on observed trends in task rewards during training. This scheme reduces the complexity of hyperparameter tuning, requiring a single hyperparameter to guide exploration, thereby simplifying the learning process and lowering deployment costs. We validate the MOSEAC method through simulations in a Newtonian kinematics environment, demonstrating high task and training performance with fewer time steps, ultimately lowering energy consumption. This validation shows that MOSEAC streamlines RL algorithm deployment by automatically tuning the agent control loop frequency using a single parameter. Its principles can be applied to enhance any RL algorithm, making it a versatile solution for various applications.","sentences":["Traditional reinforcement learning (RL) methods typically employ a fixed control loop, where each cycle corresponds to an action.","This rigidity poses challenges in practical applications, as the optimal control frequency is task-dependent.","A suboptimal choice can lead to high computational demands and reduced exploration efficiency.","Variable Time Step Reinforcement Learning (VTS-RL) addresses these issues by using adaptive frequencies for the control loop, executing actions only when necessary.","This approach, rooted in reactive programming principles, reduces computational load and extends the action space by including action durations.","However, VTS-RL's implementation is often complicated by the need to tune multiple hyperparameters that govern exploration in the multi-objective action-duration space (i.e., balancing task performance and number of time steps to achieve a goal).","To overcome these challenges, we introduce the Multi-Objective Soft Elastic Actor-Critic (MOSEAC) method.","This method features an adaptive reward scheme that adjusts hyperparameters based on observed trends in task rewards during training.","This scheme reduces the complexity of hyperparameter tuning, requiring a single hyperparameter to guide exploration, thereby simplifying the learning process and lowering deployment costs.","We validate the MOSEAC method through simulations in a Newtonian kinematics environment, demonstrating high task and training performance with fewer time steps, ultimately lowering energy consumption.","This validation shows that MOSEAC streamlines RL algorithm deployment by automatically tuning the agent control loop frequency using a single parameter.","Its principles can be applied to enhance any RL algorithm, making it a versatile solution for various applications."],"url":"http://arxiv.org/abs/2406.01521v1","category":"cs.LG"}
{"created":"2024-06-03 16:46:18","title":"Decoupled Alignment for Robust Plug-and-Play Adaptation","abstract":"We introduce a low-resource safety enhancement method for aligning large language models (LLMs) without the need for supervised fine-tuning (SFT) or reinforcement learning from human feedback (RLHF). Our main idea is to exploit knowledge distillation to extract the alignment information from existing well-aligned LLMs and integrate it into unaligned LLMs in a plug-and-play fashion. Methodology, we employ delta debugging to identify the critical components of knowledge necessary for effective distillation. On the harmful question dataset, our method significantly enhances the average defense success rate by approximately 14.41%, reaching as high as 51.39%, in 17 unaligned pre-trained LLMs, without compromising performance.","sentences":["We introduce a low-resource safety enhancement method for aligning large language models (LLMs) without the need for supervised fine-tuning (SFT) or reinforcement learning from human feedback (RLHF).","Our main idea is to exploit knowledge distillation to extract the alignment information from existing well-aligned LLMs and integrate it into unaligned LLMs in a plug-and-play fashion.","Methodology, we employ delta debugging to identify the critical components of knowledge necessary for effective distillation.","On the harmful question dataset, our method significantly enhances the average defense success rate by approximately 14.41%, reaching as high as 51.39%, in 17 unaligned pre-trained LLMs, without compromising performance."],"url":"http://arxiv.org/abs/2406.01514v2","category":"cs.CL"}
{"created":"2024-06-03 16:33:54","title":"Reducing phenotype-structured PDE models of cancer evolution to systems of ODEs: a generalised moment dynamics approach","abstract":"Intratumour phenotypic heterogeneity is nowadays understood to play a critical role in disease progression and treatment failure. Accordingly, there has been increasing interest in the development of mathematical models capable of capturing its role in cancer cell adaptation. This can be systematically achieved by means of models comprising phenotype-structured nonlocal partial differential equations, tracking the evolution of the phenotypic density distribution of the cell population, which may be compared to gene and protein expression distributions obtained experimentally. Nevertheless, given the high analytical and computational cost of solving these models, much is to be gained from reducing them to systems of ordinary differential equations for the moments of the distribution. We propose a generalised method of model-reduction, relying on the use of a moment generating function, Taylor series expansion and truncation closure, to reduce a nonlocal reaction-advection-diffusion equation, with general phenotypic drift and proliferation rate functions, to a system of moment equations up to arbitrary order. Our method extends previous results in the literature, which we address via two examples, by removing any \\textit{a priori} assumption on the shape of the distribution, and provides a flexible framework for mathematical modellers to account for the role of phenotypic heterogeneity in cancer adaptive dynamics, in a simpler mathematical framework.","sentences":["Intratumour phenotypic heterogeneity is nowadays understood to play a critical role in disease progression and treatment failure.","Accordingly, there has been increasing interest in the development of mathematical models capable of capturing its role in cancer cell adaptation.","This can be systematically achieved by means of models comprising phenotype-structured nonlocal partial differential equations, tracking the evolution of the phenotypic density distribution of the cell population, which may be compared to gene and protein expression distributions obtained experimentally.","Nevertheless, given the high analytical and computational cost of solving these models, much is to be gained from reducing them to systems of ordinary differential equations for the moments of the distribution.","We propose a generalised method of model-reduction, relying on the use of a moment generating function, Taylor series expansion and truncation closure, to reduce a nonlocal reaction-advection-diffusion equation, with general phenotypic drift and proliferation rate functions, to a system of moment equations up to arbitrary order.","Our method extends previous results in the literature, which we address via two examples, by removing any \\textit{a priori} assumption on the shape of the distribution, and provides a flexible framework for mathematical modellers to account for the role of phenotypic heterogeneity in cancer adaptive dynamics, in a simpler mathematical framework."],"url":"http://arxiv.org/abs/2406.01505v1","category":"q-bio.PE"}
{"created":"2024-06-04 17:39:23","title":"Deterministic Reversible Data Augmentation for Neural Machine Translation","abstract":"Data augmentation is an effective way to diversify corpora in machine translation, but previous methods may introduce semantic inconsistency between original and augmented data because of irreversible operations and random subword sampling procedures. To generate both symbolically diverse and semantically consistent augmentation data, we propose Deterministic Reversible Data Augmentation (DRDA), a simple but effective data augmentation method for neural machine translation. DRDA adopts deterministic segmentations and reversible operations to generate multi-granularity subword representations and pulls them closer together with multi-view techniques. With no extra corpora or model changes required, DRDA outperforms strong baselines on several translation tasks with a clear margin (up to 4.3 BLEU gain over Transformer) and exhibits good robustness in noisy, low-resource, and cross-domain datasets.","sentences":["Data augmentation is an effective way to diversify corpora in machine translation, but previous methods may introduce semantic inconsistency between original and augmented data because of irreversible operations and random subword sampling procedures.","To generate both symbolically diverse and semantically consistent augmentation data, we propose Deterministic Reversible Data Augmentation (DRDA), a simple but effective data augmentation method for neural machine translation.","DRDA adopts deterministic segmentations and reversible operations to generate multi-granularity subword representations and pulls them closer together with multi-view techniques.","With no extra corpora or model changes required, DRDA outperforms strong baselines on several translation tasks with a clear margin (up to 4.3 BLEU gain over Transformer) and exhibits good robustness in noisy, low-resource, and cross-domain datasets."],"url":"http://arxiv.org/abs/2406.02517v1","category":"cs.CL"}
{"created":"2024-06-04 17:39:15","title":"Bottom spectrum of three-dimensional manifolds with scalar curvature lower bound","abstract":"A classical result of Cheng states that the bottom spectrum of complete manifolds of fixed dimension and Ricci curvature lower bound achieves its maximal value on the corresponding hyperbolic space. The paper establishes an analogous result for three-dimensional complete manifolds with scalar curvature lower bound subject to some necessary topological assumptions. The rigidity issue is also addressed and a splitting theorem is obtained for such manifolds with the maximal bottom spectrum.","sentences":["A classical result of Cheng states that the bottom spectrum of complete manifolds of fixed dimension and Ricci curvature lower bound achieves its maximal value on the corresponding hyperbolic space.","The paper establishes an analogous result for three-dimensional complete manifolds with scalar curvature lower bound subject to some necessary topological assumptions.","The rigidity issue is also addressed and a splitting theorem is obtained for such manifolds with the maximal bottom spectrum."],"url":"http://arxiv.org/abs/2406.02516v1","category":"math.DG"}
{"created":"2024-06-04 17:38:24","title":"Uncertainty of Joint Neural Contextual Bandit","abstract":"Contextual bandit learning is increasingly favored in modern large-scale recommendation systems. To better utlize the contextual information and available user or item features, the integration of neural networks have been introduced to enhance contextual bandit learning and has triggered significant interest from both academia and industry. However, a major challenge arises when implementing a disjoint neural contextual bandit solution in large-scale recommendation systems, where each item or user may correspond to a separate bandit arm. The huge number of items to recommend poses a significant hurdle for real world production deployment. This paper focuses on a joint neural contextual bandit solution which serves all recommending items in one single model. The output consists of a predicted reward $\\mu$, an uncertainty $\\sigma$ and a hyper-parameter $\\alpha$ which balances exploitation and exploration, e.g., $\\mu + \\alpha \\sigma$.   The tuning of the parameter $\\alpha$ is typically heuristic and complex in practice due to its stochastic nature. To address this challenge, we provide both theoretical analysis and experimental findings regarding the uncertainty $\\sigma$ of the joint neural contextual bandit model. Our analysis reveals that $\\alpha$ demonstrates an approximate square root relationship with the size of the last hidden layer $F$ and inverse square root relationship with the amount of training data $N$, i.e., $\\sigma \\propto \\sqrt{\\frac{F}{N}}$. The experiments, conducted with real industrial data, align with the theoretical analysis, help understanding model behaviors and assist the hyper-parameter tuning during both offline training and online deployment.","sentences":["Contextual bandit learning is increasingly favored in modern large-scale recommendation systems.","To better utlize the contextual information and available user or item features, the integration of neural networks have been introduced to enhance contextual bandit learning and has triggered significant interest from both academia and industry.","However, a major challenge arises when implementing a disjoint neural contextual bandit solution in large-scale recommendation systems, where each item or user may correspond to a separate bandit arm.","The huge number of items to recommend poses a significant hurdle for real world production deployment.","This paper focuses on a joint neural contextual bandit solution which serves all recommending items in one single model.","The output consists of a predicted reward $\\mu$, an uncertainty $\\sigma$ and a hyper-parameter $\\alpha$ which balances exploitation and exploration, e.g., $\\mu + \\alpha \\sigma$.   The tuning of the parameter $\\alpha$ is typically heuristic and complex in practice due to its stochastic nature.","To address this challenge, we provide both theoretical analysis and experimental findings regarding the uncertainty $\\sigma$ of the joint neural contextual bandit model.","Our analysis reveals that $\\alpha$ demonstrates an approximate square root relationship with the size of the last hidden layer $F$ and inverse square root relationship with the amount of training data $N$,","i.e., $\\sigma \\propto \\sqrt{\\frac{F}{N}}$. The experiments, conducted with real industrial data, align with the theoretical analysis, help understanding model behaviors and assist the hyper-parameter tuning during both offline training and online deployment."],"url":"http://arxiv.org/abs/2406.02515v1","category":"cs.LG"}
{"created":"2024-06-04 17:34:43","title":"Existence, Uniqueness and Asymptotic Dynamics of Nonlinear Schr\u00f6dinger Equations With Quasi-Periodic Initial Data: II. The Derivative NLS","abstract":"This is the second part of a two-paper series studying the nonlinear Schr\\\"odinger equation with quasi-periodic initial data. In this paper, we focus on the quasi-periodic Cauchy problem for the derivative nonlinear Schr\\\"odinger equation. Under the assumption that the Fourier coefficients of the initial data obey an exponential upper bound, we establish local existence of a solution that retains quasi-periodicity in space with a slightly weaker Fourier decay. Moreover, the solution is shown to be unique within this class of quasi-periodic functions. Also, we prove that, for the derivative nonlinear Schr\\\"odinger equation in a weakly nonlinear setting, within the time scale, as the small parameter of nonlinearity tends to zero, the nonlinear solution converges asymptotically to the linear solution in the sense of both sup-norm and analytic Sobolev-norm.   The proof proceeds via a consideration of an associated infinite system of coupled ordinary differential equations for the Fourier coefficients and an explicit combinatorial analysis for the Picard iteration with the help of Feynman diagrams and the power of $\\ast^{[\\cdot]}$ labelling the complex conjugate.","sentences":["This is the second part of a two-paper series studying the nonlinear Schr\\\"odinger equation with quasi-periodic initial data.","In this paper, we focus on the quasi-periodic Cauchy problem for the derivative nonlinear Schr\\\"odinger equation.","Under the assumption that the Fourier coefficients of the initial data obey an exponential upper bound, we establish local existence of a solution that retains quasi-periodicity in space with a slightly weaker Fourier decay.","Moreover, the solution is shown to be unique within this class of quasi-periodic functions.","Also, we prove that, for the derivative nonlinear Schr\\\"odinger equation in a weakly nonlinear setting, within the time scale, as the small parameter of nonlinearity tends to zero, the nonlinear solution converges asymptotically to the linear solution in the sense of both sup-norm and analytic Sobolev-norm.   ","The proof proceeds via a consideration of an associated infinite system of coupled ordinary differential equations for the Fourier coefficients and an explicit combinatorial analysis for the Picard iteration with the help of Feynman diagrams and the power of $\\ast^{[\\cdot]}$ labelling the complex conjugate."],"url":"http://arxiv.org/abs/2406.02512v1","category":"math.AP"}
{"created":"2024-06-04 17:27:07","title":"Radial canonical AdS$_3$ gravity and $T\\bar{T}$","abstract":"We employ an ADM deparametrization strategy to discuss the radial canonical formalism of asymptotically AdS$_3$ gravity. It leads to the identification of a radial 'time' before quantization, which is the volume time, canonically conjugate to York time. Holographically, this allows to interpret the semi-classical path integral of $T\\bar T$ theory as a Schr\\\"odinger wavefunctional satisfying a Schr\\\"odinger evolution equation in volume time, and the $T\\bar T$ operator expectation value in terms of the Hamiltonian that generates volume time translations -- both consistent with cut-off holography. We make use of the canonical perspective to construct the rotating BTZ solution from the Hamilton-Jacobi equation, with a finite cut-off energy spectrum that has a known holographic $T\\bar T$ interpretation, as well as semi-classical Wheeler-DeWitt states for that solution.","sentences":["We employ an ADM deparametrization strategy to discuss the radial canonical formalism of asymptotically AdS$_3$ gravity.","It leads to the identification of a radial 'time' before quantization, which is the volume time, canonically conjugate to York time.","Holographically, this allows to interpret the semi-classical path integral of $T\\bar T$ theory as a Schr\\\"odinger wavefunctional satisfying a Schr\\\"odinger evolution equation in volume time, and the $T\\bar T$ operator expectation value in terms of the Hamiltonian that generates volume time translations -- both consistent with cut-off holography.","We make use of the canonical perspective to construct the rotating BTZ solution from the Hamilton-Jacobi equation, with a finite cut-off energy spectrum that has a known holographic $T\\bar T$ interpretation, as well as semi-classical Wheeler-DeWitt states for that solution."],"url":"http://arxiv.org/abs/2406.02508v1","category":"hep-th"}
{"created":"2024-06-04 17:24:10","title":"Tensor Network Space-Time Spectral Collocation Method for Solving the Nonlinear Convection Diffusion Equation","abstract":"Spectral methods provide highly accurate numerical solutions for partial differential equations, exhibiting exponential convergence with the number of spectral nodes. Traditionally, in addressing time-dependent nonlinear problems, attention has been on low-order finite difference schemes for time discretization and spectral element schemes for spatial variables. However, our recent developments have resulted in the application of spectral methods to both space and time variables, preserving spectral convergence in both domains. Leveraging Tensor Train techniques, our approach tackles the curse of dimensionality inherent in space-time methods. Here, we extend this methodology to the nonlinear time-dependent convection-diffusion equation. Our discretization scheme exhibits a low-rank structure, facilitating translation to tensor-train (TT) format. Nevertheless, controlling the TT-rank across Newton's iterations, needed to deal with the nonlinearity, poses a challenge, leading us to devise the \"Step Truncation TT-Newton\" method. We demonstrate the exponential convergence of our methods through various benchmark examples. Importantly, our scheme offers significantly reduced memory requirement compared to the full-grid scheme.","sentences":["Spectral methods provide highly accurate numerical solutions for partial differential equations, exhibiting exponential convergence with the number of spectral nodes.","Traditionally, in addressing time-dependent nonlinear problems, attention has been on low-order finite difference schemes for time discretization and spectral element schemes for spatial variables.","However, our recent developments have resulted in the application of spectral methods to both space and time variables, preserving spectral convergence in both domains.","Leveraging Tensor Train techniques, our approach tackles the curse of dimensionality inherent in space-time methods.","Here, we extend this methodology to the nonlinear time-dependent convection-diffusion equation.","Our discretization scheme exhibits a low-rank structure, facilitating translation to tensor-train (TT) format.","Nevertheless, controlling the TT-rank across Newton's iterations, needed to deal with the nonlinearity, poses a challenge, leading us to devise the \"Step Truncation TT-Newton\" method.","We demonstrate the exponential convergence of our methods through various benchmark examples.","Importantly, our scheme offers significantly reduced memory requirement compared to the full-grid scheme."],"url":"http://arxiv.org/abs/2406.02505v1","category":"math.NA"}
{"created":"2024-06-04 17:20:42","title":"Singular Subspace Perturbation Bounds via Rectangular Random Matrix Diffusions","abstract":"Given a matrix $A \\in \\mathbb{R}^{m\\times d}$ with singular values $\\sigma_1\\geq \\cdots \\geq \\sigma_d$, and a random matrix $G \\in \\mathbb{R}^{m\\times d}$ with iid $N(0,T)$ entries for some $T>0$, we derive new bounds on the Frobenius distance between subspaces spanned by the top-$k$ (right) singular vectors of $A$ and $A+G$. This problem arises in numerous applications in statistics where a data matrix may be corrupted by Gaussian noise, and in the analysis of the Gaussian mechanism in differential privacy, where Gaussian noise is added to data to preserve private information. We show that, for matrices $A$ where the gaps in the top-$k$ singular values are roughly $\\Omega(\\sigma_k-\\sigma_{k+1})$ the expected Frobenius distance between the subspaces is $\\tilde{O}(\\frac{\\sqrt{d}}{\\sigma_k-\\sigma_{k+1}} \\times \\sqrt{T})$, improving on previous bounds by a factor of $\\frac{\\sqrt{m}}{\\sqrt{d}} \\sqrt{k}$. To obtain our bounds we view the perturbation to the singular vectors as a diffusion process -- the Dyson-Bessel process -- and use tools from stochastic calculus to track the evolution of the subspace spanned by the top-$k$ singular vectors.","sentences":["Given a matrix $A \\in \\mathbb{R}^{m\\times d}$ with singular values $\\sigma_1\\geq \\cdots \\geq \\sigma_d$, and a random matrix $G \\in \\mathbb{R}^{m\\times d}$ with iid $N(0,T)$ entries for some $T>0$, we derive new bounds on the Frobenius distance between subspaces spanned by the top-$k$ (right) singular vectors of $A$ and $A+G$. This problem arises in numerous applications in statistics where a data matrix may be corrupted by Gaussian noise, and in the analysis of the Gaussian mechanism in differential privacy, where Gaussian noise is added to data to preserve private information.","We show that, for matrices $A$ where the gaps in the top-$k$ singular values are roughly $\\Omega(\\sigma_k-\\sigma_{k+1})$ the expected Frobenius distance between the subspaces is $\\tilde{O}(\\frac{\\sqrt{d}}{\\sigma_k-\\sigma_{k+1}} \\times \\sqrt{T})$, improving on previous bounds by a factor of $\\frac{\\sqrt{m}}{\\sqrt{d}} \\sqrt{k}$. To obtain our bounds we view the perturbation to the singular vectors as a diffusion process -- the Dyson-Bessel process -- and use tools from stochastic calculus to track the evolution of the subspace spanned by the top-$k$ singular vectors."],"url":"http://arxiv.org/abs/2406.02502v1","category":"math.ST"}
{"created":"2024-06-04 17:13:10","title":"GenS: Generalizable Neural Surface Reconstruction from Multi-View Images","abstract":"Combining the signed distance function (SDF) and differentiable volume rendering has emerged as a powerful paradigm for surface reconstruction from multi-view images without 3D supervision. However, current methods are impeded by requiring long-time per-scene optimizations and cannot generalize to new scenes. In this paper, we present GenS, an end-to-end generalizable neural surface reconstruction model. Unlike coordinate-based methods that train a separate network for each scene, we construct a generalized multi-scale volume to directly encode all scenes. Compared with existing solutions, our representation is more powerful, which can recover high-frequency details while maintaining global smoothness. Meanwhile, we introduce a multi-scale feature-metric consistency to impose the multi-view consistency in a more discriminative multi-scale feature space, which is robust to the failures of the photometric consistency. And the learnable feature can be self-enhanced to continuously improve the matching accuracy and mitigate aggregation ambiguity. Furthermore, we design a view contrast loss to force the model to be robust to those regions covered by few viewpoints through distilling the geometric prior from dense input to sparse input. Extensive experiments on popular benchmarks show that our model can generalize well to new scenes and outperform existing state-of-the-art methods even those employing ground-truth depth supervision. Code is available at https://github.com/prstrive/GenS.","sentences":["Combining the signed distance function (SDF) and differentiable volume rendering has emerged as a powerful paradigm for surface reconstruction from multi-view images without 3D supervision.","However, current methods are impeded by requiring long-time per-scene optimizations and cannot generalize to new scenes.","In this paper, we present GenS, an end-to-end generalizable neural surface reconstruction model.","Unlike coordinate-based methods that train a separate network for each scene, we construct a generalized multi-scale volume to directly encode all scenes.","Compared with existing solutions, our representation is more powerful, which can recover high-frequency details while maintaining global smoothness.","Meanwhile, we introduce a multi-scale feature-metric consistency to impose the multi-view consistency in a more discriminative multi-scale feature space, which is robust to the failures of the photometric consistency.","And the learnable feature can be self-enhanced to continuously improve the matching accuracy and mitigate aggregation ambiguity.","Furthermore, we design a view contrast loss to force the model to be robust to those regions covered by few viewpoints through distilling the geometric prior from dense input to sparse input.","Extensive experiments on popular benchmarks show that our model can generalize well to new scenes and outperform existing state-of-the-art methods even those employing ground-truth depth supervision.","Code is available at https://github.com/prstrive/GenS."],"url":"http://arxiv.org/abs/2406.02495v1","category":"cs.CV"}
{"created":"2024-06-04 17:04:15","title":"Neural network sampling of Bethe-Heitler process in particle-in-cell codes","abstract":"This study uses neural networks to improve Monte Carlo (MC) implementations of the Bethe-Heitler process in Particle-In-Cell (PIC) codes. We provide a neural network that is as accurate as pre-calculated tables, and requires a hundred times less memory to store. It is trained to predict Bethe-Heitler pair production cross-sections for atomic numbers 1-50 and photon energies between 1 MeV and 10 GeV in the PIC code OSIRIS. We first validate our approach against a theoretical estimate in a simplified context. We later prove that both approaches have similar performance in a typical relativistic laser-plasma interaction scenario. The large memory decrease accessible with neural networks will enable introducing more advanced cross-section models for Bethe-Heitler pair production and other QED mechanisms in the MC modules of PIC codes.","sentences":["This study uses neural networks to improve Monte Carlo (MC) implementations of the Bethe-Heitler process in Particle-In-Cell (PIC) codes.","We provide a neural network that is as accurate as pre-calculated tables, and requires a hundred times less memory to store.","It is trained to predict Bethe-Heitler pair production cross-sections for atomic numbers 1-50 and photon energies between 1 MeV and 10 GeV in the PIC code OSIRIS.","We first validate our approach against a theoretical estimate in a simplified context.","We later prove that both approaches have similar performance in a typical relativistic laser-plasma interaction scenario.","The large memory decrease accessible with neural networks will enable introducing more advanced cross-section models for Bethe-Heitler pair production and other QED mechanisms in the MC modules of PIC codes."],"url":"http://arxiv.org/abs/2406.02491v1","category":"physics.comp-ph"}
{"created":"2024-06-04 17:00:14","title":"Ai-Sampler: Adversarial Learning of Markov kernels with involutive maps","abstract":"Markov chain Monte Carlo methods have become popular in statistics as versatile techniques to sample from complicated probability distributions. In this work, we propose a method to parameterize and train transition kernels of Markov chains to achieve efficient sampling and good mixing. This training procedure minimizes the total variation distance between the stationary distribution of the chain and the empirical distribution of the data. Our approach leverages involutive Metropolis-Hastings kernels constructed from reversible neural networks that ensure detailed balance by construction. We find that reversibility also implies $C_2$-equivariance of the discriminator function which can be used to restrict its function space.","sentences":["Markov chain Monte Carlo methods have become popular in statistics as versatile techniques to sample from complicated probability distributions.","In this work, we propose a method to parameterize and train transition kernels of Markov chains to achieve efficient sampling and good mixing.","This training procedure minimizes the total variation distance between the stationary distribution of the chain and the empirical distribution of the data.","Our approach leverages involutive Metropolis-Hastings kernels constructed from reversible neural networks that ensure detailed balance by construction.","We find that reversibility also implies $C_2$-equivariance of the discriminator function which can be used to restrict its function space."],"url":"http://arxiv.org/abs/2406.02490v1","category":"cs.LG"}
{"created":"2024-06-04 17:00:11","title":"Stability theory over toroidal or Novikov type base and Canonical modifications","abstract":"We set up a generalization of ubiquitous one parameter families in algebraic geometry and its use for stability theories ([Mum65, HL14, AHLH23]) to families over toric varieties, Novikov type rings, or its complex analytic analogues. The language allows us to reformulate degenerations of \"irrational\" direction in various literatures as canonical objects in a unified manner.   Compatibly, we generalize the stable reduction type theorem for $\\Theta$-stratification in [AHLH23] of Langton type to our higher rank setup.","sentences":["We set up a generalization of ubiquitous one parameter families in algebraic geometry and its use for stability theories ([Mum65, HL14, AHLH23]) to families over toric varieties, Novikov type rings, or its complex analytic analogues.","The language allows us to reformulate degenerations of \"irrational\" direction in various literatures as canonical objects in a unified manner.   ","Compatibly, we generalize the stable reduction type theorem for $\\Theta$-stratification in [AHLH23] of Langton type to our higher rank setup."],"url":"http://arxiv.org/abs/2406.02489v1","category":"math.AG"}
{"created":"2024-06-04 16:45:10","title":"Around the codifferential of products of p-forms and generalized interior products","abstract":"Identities pertaining to the de Rham codifferential {\\delta} in differential geometry are scattered in the literature. This article gathers such formulas involving usual differential operators (Lie derivative, Schouten-Nijenhuis bracket, ...), while adding a few new ones using a natural extension of the interior product, to provide a compact handy summary.","sentences":["Identities pertaining to the de Rham codifferential {\\delta} in differential geometry are scattered in the literature.","This article gathers such formulas involving usual differential operators (Lie derivative, Schouten-Nijenhuis bracket, ...), while adding a few new ones using a natural extension of the interior product, to provide a compact handy summary."],"url":"http://arxiv.org/abs/2406.02476v1","category":"math-ph"}
{"created":"2024-06-04 16:44:59","title":"A Lazard-type correspondence and applications to post-Lie rings and skew braces","abstract":"Through a Hopf algebraic approach, we develop a framework for formal differentiation and integration and prove a correspondence theorem that comprises the Lazard correspondence, the Malcev correspondence and the formal integration of complete connected Lie algebras with characteristic 0. We then apply this theory to obtain a correspondence theorem for classes of left nilpotent skew braces on a nilpotent group and left nilpotent post-Lie rings on a nilpotent Lie ring.","sentences":["Through a Hopf algebraic approach, we develop a framework for formal differentiation and integration and prove a correspondence theorem that comprises the Lazard correspondence, the Malcev correspondence and the formal integration of complete connected Lie algebras with characteristic 0.","We then apply this theory to obtain a correspondence theorem for classes of left nilpotent skew braces on a nilpotent group and left nilpotent post-Lie rings on a nilpotent Lie ring."],"url":"http://arxiv.org/abs/2406.02475v1","category":"math.RA"}
{"created":"2024-06-04 16:43:53","title":"An Observation About Weak Solutions of Linear Differential Equations in Hilbert Spaces","abstract":"In this note we propose a definition of weak solution for an abstract Cauchy problem in a Hilbert space, and we discuss existence and uniqueness results.","sentences":["In this note we propose a definition of weak solution for an abstract Cauchy problem in a Hilbert space, and we discuss existence and uniqueness results."],"url":"http://arxiv.org/abs/2406.02474v1","category":"math.AP"}
{"created":"2024-06-04 16:43:29","title":"Dimension of the deformation space of ordinary representations in the cyclotomic limit","abstract":"The weight two ordinary deformations are unobstructed in the cyclotomic limit under certain assumptions. We show that such an ordinary deformation ring over the cyclotomic tower can have arbitrarily large dimension.","sentences":["The weight two ordinary deformations are unobstructed in the cyclotomic limit under certain assumptions.","We show that such an ordinary deformation ring over the cyclotomic tower can have arbitrarily large dimension."],"url":"http://arxiv.org/abs/2406.02473v1","category":"math.NT"}
{"created":"2024-06-04 16:34:41","title":"What no one has seen before: gravitational waveforms from warp drive collapse","abstract":"Despite originating in science fiction, warp drives have a concrete description in general relativity, with Alcubierre first proposing a spacetime metric that supported faster-than-light travel. Whilst there are numerous practical barriers to their implementation in real life, including a requirement for negative energy, computationally, one can simulate their evolution in time given an equation of state describing the matter. In this work, we study the signatures arising from a warp drive \"containment failure\", assuming a stiff equation of state for the fluid. We compute the emitted gravitational-wave signal and track the energy fluxes of the fluid. Apart from its rather speculative application to the search for extraterrestrial life in gravitational-wave detector data, this work is interesting as a study of the dynamical evolution and stability of spacetimes that violate the null energy condition. Our work highlights the importance of exploring strange new spacetimes, to (boldly) simulate what no one has seen before.","sentences":["Despite originating in science fiction, warp drives have a concrete description in general relativity, with Alcubierre first proposing a spacetime metric that supported faster-than-light travel.","Whilst there are numerous practical barriers to their implementation in real life, including a requirement for negative energy, computationally, one can simulate their evolution in time given an equation of state describing the matter.","In this work, we study the signatures arising from a warp drive \"containment failure\", assuming a stiff equation of state for the fluid.","We compute the emitted gravitational-wave signal and track the energy fluxes of the fluid.","Apart from its rather speculative application to the search for extraterrestrial life in gravitational-wave detector data, this work is interesting as a study of the dynamical evolution and stability of spacetimes that violate the null energy condition.","Our work highlights the importance of exploring strange new spacetimes, to (boldly) simulate what no one has seen before."],"url":"http://arxiv.org/abs/2406.02466v1","category":"gr-qc"}
{"created":"2024-06-04 16:25:03","title":"Modified scattering for the three dimensional Maxwell-Dirac system","abstract":"In this work we prove global well-posedness for the massive Maxwell-Dirac system in the Lorenz gauge in $\\mathbb{R}^{1+3}$, for small, sufficiently smooth and decaying initial data, as well as modified scattering for the solutions. Heuristically we exploit the close connection between the massive Maxwell-Dirac and the wave-Klein-Gordon equations, while developing a novel approach which applies directly at the level of the Dirac equations. The modified scattering result follows from a precise description of the asymptotic behavior of the solutions inside the light cone, which we derive via the method of testing with wave packets of Ifrim-Tataru.","sentences":["In this work we prove global well-posedness for the massive Maxwell-Dirac system in the Lorenz gauge in $\\mathbb{R}^{1+3}$, for small, sufficiently smooth and decaying initial data, as well as modified scattering for the solutions.","Heuristically we exploit the close connection between the massive Maxwell-Dirac and the wave-Klein-Gordon equations, while developing a novel approach which applies directly at the level of the Dirac equations.","The modified scattering result follows from a precise description of the asymptotic behavior of the solutions inside the light cone, which we derive via the method of testing with wave packets of Ifrim-Tataru."],"url":"http://arxiv.org/abs/2406.02460v1","category":"math.AP"}
{"created":"2024-06-04 16:21:24","title":"Machine learning Hubbard parameters with equivariant neural networks","abstract":"Density-functional theory with extended Hubbard functionals (DFT+$U$+$V$) provides a robust framework to accurately describe complex materials containing transition-metal or rare-earth elements. It does so by mitigating self-interaction errors inherent to semi-local functionals which are particularly pronounced in systems with partially-filled $d$ and $f$ electronic states. However, achieving accuracy in this approach hinges upon the accurate determination of the on-site $U$ and inter-site $V$ Hubbard parameters. In practice, these are obtained either by semi-empirical tuning, requiring prior knowledge, or, more correctly, by using predictive but expensive first-principles calculations. Here, we present a machine learning model based on equivariant neural networks which uses atomic occupation matrices as descriptors, directly capturing the electronic structure, local chemical environment, and oxidation states of the system at hand. We target here the prediction of Hubbard parameters computed self-consistently with iterative linear-response calculations, as implemented in density-functional perturbation theory (DFPT), and structural relaxations. Remarkably, when trained on data from 11 materials spanning various crystal structures and compositions, our model achieves mean absolute relative errors of 3% and 5% for Hubbard $U$ and $V$ parameters, respectively. By circumventing computationally expensive DFT or DFPT self-consistent protocols, our model significantly expedites the prediction of Hubbard parameters with negligible computational overhead, while approaching the accuracy of DFPT. Moreover, owing to its robust transferability, the model facilitates accelerated materials discovery and design via high-throughput calculations, with relevance for various technological applications.","sentences":["Density-functional theory with extended Hubbard functionals (DFT+$U$+$V$) provides a robust framework to accurately describe complex materials containing transition-metal or rare-earth elements.","It does so by mitigating self-interaction errors inherent to semi-local functionals which are particularly pronounced in systems with partially-filled $d$ and $f$ electronic states.","However, achieving accuracy in this approach hinges upon the accurate determination of the on-site $U$ and inter-site $V$ Hubbard parameters.","In practice, these are obtained either by semi-empirical tuning, requiring prior knowledge, or, more correctly, by using predictive but expensive first-principles calculations.","Here, we present a machine learning model based on equivariant neural networks which uses atomic occupation matrices as descriptors, directly capturing the electronic structure, local chemical environment, and oxidation states of the system at hand.","We target here the prediction of Hubbard parameters computed self-consistently with iterative linear-response calculations, as implemented in density-functional perturbation theory (DFPT), and structural relaxations.","Remarkably, when trained on data from 11 materials spanning various crystal structures and compositions, our model achieves mean absolute relative errors of 3% and 5% for Hubbard $U$ and $V$ parameters, respectively.","By circumventing computationally expensive DFT or DFPT self-consistent protocols, our model significantly expedites the prediction of Hubbard parameters with negligible computational overhead, while approaching the accuracy of DFPT.","Moreover, owing to its robust transferability, the model facilitates accelerated materials discovery and design via high-throughput calculations, with relevance for various technological applications."],"url":"http://arxiv.org/abs/2406.02457v1","category":"cond-mat.mtrl-sci"}
{"created":"2024-06-04 16:16:58","title":"Quantum states from normalizing flows","abstract":"We introduce an architecture for neural quantum states for many-body quantum-mechanical systems, based on normalizing flows. The use of normalizing flows enables efficient uncorrelated sampling of configurations from the probability distribution defined by the wavefunction, mitigating a major cost of using neural states in simulation. We demonstrate the use of this architecture for both ground-state preparation (for self-interacting particles in a harmonic trap) and real-time evolution (for one-dimensional tunneling). Finally, we detail a procedure for obtaining rigorous estimates of the systematic error when using neural states to approximate quantum evolution.","sentences":["We introduce an architecture for neural quantum states for many-body quantum-mechanical systems, based on normalizing flows.","The use of normalizing flows enables efficient uncorrelated sampling of configurations from the probability distribution defined by the wavefunction, mitigating a major cost of using neural states in simulation.","We demonstrate the use of this architecture for both ground-state preparation (for self-interacting particles in a harmonic trap) and real-time evolution (for one-dimensional tunneling).","Finally, we detail a procedure for obtaining rigorous estimates of the systematic error when using neural states to approximate quantum evolution."],"url":"http://arxiv.org/abs/2406.02451v1","category":"quant-ph"}
{"created":"2024-06-04 17:59:57","title":"VHS: High-Resolution Iterative Stereo Matching with Visual Hull Priors","abstract":"We present a stereo-matching method for depth estimation from high-resolution images using visual hulls as priors, and a memory-efficient technique for the correlation computation. Our method uses object masks extracted from supplementary views of the scene to guide the disparity estimation, effectively reducing the search space for matches. This approach is specifically tailored to stereo rigs in volumetric capture systems, where an accurate depth plays a key role in the downstream reconstruction task. To enable training and regression at high resolutions targeted by recent systems, our approach extends a sparse correlation computation into a hybrid sparse-dense scheme suitable for application in leading recurrent network architectures. We evaluate the performance-efficiency trade-off of our method compared to state-of-the-art methods, and demonstrate the efficacy of the visual hull guidance. In addition, we propose a training scheme for a further reduction of memory requirements during optimization, facilitating training on high-resolution data.","sentences":["We present a stereo-matching method for depth estimation from high-resolution images using visual hulls as priors, and a memory-efficient technique for the correlation computation.","Our method uses object masks extracted from supplementary views of the scene to guide the disparity estimation, effectively reducing the search space for matches.","This approach is specifically tailored to stereo rigs in volumetric capture systems, where an accurate depth plays a key role in the downstream reconstruction task.","To enable training and regression at high resolutions targeted by recent systems, our approach extends a sparse correlation computation into a hybrid sparse-dense scheme suitable for application in leading recurrent network architectures.","We evaluate the performance-efficiency trade-off of our method compared to state-of-the-art methods, and demonstrate the efficacy of the visual hull guidance.","In addition, we propose a training scheme for a further reduction of memory requirements during optimization, facilitating training on high-resolution data."],"url":"http://arxiv.org/abs/2406.02552v1","category":"cs.CV"}
{"created":"2024-06-04 17:57:37","title":"Enhancing Temporal Consistency in Video Editing by Reconstructing Videos with 3D Gaussian Splatting","abstract":"Recent advancements in zero-shot video diffusion models have shown promise for text-driven video editing, but challenges remain in achieving high temporal consistency. To address this, we introduce Video-3DGS, a 3D Gaussian Splatting (3DGS)-based video refiner designed to enhance temporal consistency in zero-shot video editors. Our approach utilizes a two-stage 3D Gaussian optimizing process tailored for editing dynamic monocular videos. In the first stage, Video-3DGS employs an improved version of COLMAP, referred to as MC-COLMAP, which processes original videos using a Masked and Clipped approach. For each video clip, MC-COLMAP generates the point clouds for dynamic foreground objects and complex backgrounds. These point clouds are utilized to initialize two sets of 3D Gaussians (Frg-3DGS and Bkg-3DGS) aiming to represent foreground and background views. Both foreground and background views are then merged with a 2D learnable parameter map to reconstruct full views. In the second stage, we leverage the reconstruction ability developed in the first stage to impose the temporal constraints on the video diffusion model. To demonstrate the efficacy of Video-3DGS on both stages, we conduct extensive experiments across two related tasks: Video Reconstruction and Video Editing. Video-3DGS trained with 3k iterations significantly improves video reconstruction quality (+3 PSNR, +7 PSNR increase) and training efficiency (x1.9, x4.5 times faster) over NeRF-based and 3DGS-based state-of-art methods on DAVIS dataset, respectively. Moreover, it enhances video editing by ensuring temporal consistency across 58 dynamic monocular videos.","sentences":["Recent advancements in zero-shot video diffusion models have shown promise for text-driven video editing, but challenges remain in achieving high temporal consistency.","To address this, we introduce Video-3DGS, a 3D Gaussian Splatting (3DGS)-based video refiner designed to enhance temporal consistency in zero-shot video editors.","Our approach utilizes a two-stage 3D Gaussian optimizing process tailored for editing dynamic monocular videos.","In the first stage, Video-3DGS employs an improved version of COLMAP, referred to as MC-COLMAP, which processes original videos using a Masked and Clipped approach.","For each video clip, MC-COLMAP generates the point clouds for dynamic foreground objects and complex backgrounds.","These point clouds are utilized to initialize two sets of 3D Gaussians (Frg-3DGS and Bkg-3DGS) aiming to represent foreground and background views.","Both foreground and background views are then merged with a 2D learnable parameter map to reconstruct full views.","In the second stage, we leverage the reconstruction ability developed in the first stage to impose the temporal constraints on the video diffusion model.","To demonstrate the efficacy of Video-3DGS on both stages, we conduct extensive experiments across two related tasks: Video Reconstruction and Video Editing.","Video-3DGS trained with 3k iterations significantly improves video reconstruction quality (+3 PSNR, +7 PSNR increase) and training efficiency (x1.9, x4.5 times faster) over NeRF-based and 3DGS-based state-of-art methods on DAVIS dataset, respectively.","Moreover, it enhances video editing by ensuring temporal consistency across 58 dynamic monocular videos."],"url":"http://arxiv.org/abs/2406.02541v2","category":"cs.CV"}
{"created":"2024-06-04 17:57:10","title":"ViDiT-Q: Efficient and Accurate Quantization of Diffusion Transformers for Image and Video Generation","abstract":"Diffusion transformers (DiTs) have exhibited remarkable performance in visual generation tasks, such as generating realistic images or videos based on textual instructions. However, larger model sizes and multi-frame processing for video generation lead to increased computational and memory costs, posing challenges for practical deployment on edge devices. Post-Training Quantization (PTQ) is an effective method for reducing memory costs and computational complexity. When quantizing diffusion transformers, we find that applying existing diffusion quantization methods designed for U-Net faces challenges in preserving quality. After analyzing the major challenges for quantizing diffusion transformers, we design an improved quantization scheme: \"ViDiT-Q\": Video and Image Diffusion Transformer Quantization) to address these issues. Furthermore, we identify highly sensitive layers and timesteps hinder quantization for lower bit-widths. To tackle this, we improve ViDiT-Q with a novel metric-decoupled mixed-precision quantization method (ViDiT-Q-MP). We validate the effectiveness of ViDiT-Q across a variety of text-to-image and video models. While baseline quantization methods fail at W8A8 and produce unreadable content at W4A8, ViDiT-Q achieves lossless W8A8 quantization. ViDiTQ-MP achieves W4A8 with negligible visual quality degradation, resulting in a 2.5x memory optimization and a 1.5x latency speedup.","sentences":["Diffusion transformers (DiTs) have exhibited remarkable performance in visual generation tasks, such as generating realistic images or videos based on textual instructions.","However, larger model sizes and multi-frame processing for video generation lead to increased computational and memory costs, posing challenges for practical deployment on edge devices.","Post-Training Quantization (PTQ) is an effective method for reducing memory costs and computational complexity.","When quantizing diffusion transformers, we find that applying existing diffusion quantization methods designed for U-Net faces challenges in preserving quality.","After analyzing the major challenges for quantizing diffusion transformers, we design an improved quantization scheme: \"ViDiT-Q\": Video and Image Diffusion Transformer Quantization) to address these issues.","Furthermore, we identify highly sensitive layers and timesteps hinder quantization for lower bit-widths.","To tackle this, we improve ViDiT-Q with a novel metric-decoupled mixed-precision quantization method (ViDiT-Q-MP).","We validate the effectiveness of ViDiT-Q across a variety of text-to-image and video models.","While baseline quantization methods fail at W8A8 and produce unreadable content at W4A8, ViDiT-Q achieves lossless W8A8 quantization.","ViDiTQ-MP achieves W4A8 with negligible visual quality degradation, resulting in a 2.5x memory optimization and a 1.5x latency speedup."],"url":"http://arxiv.org/abs/2406.02540v1","category":"cs.CV"}
{"created":"2024-06-04 17:50:34","title":"Scalable MatMul-free Language Modeling","abstract":"Matrix multiplication (MatMul) typically dominates the overall computational cost of large language models (LLMs). This cost only grows as LLMs scale to larger embedding dimensions and context lengths. In this work, we show that MatMul operations can be completely eliminated from LLMs while maintaining strong performance at billion-parameter scales. Our experiments show that our proposed MatMul-free models achieve performance on-par with state-of-the-art Transformers that require far more memory during inference at a scale up to at least 2.7B parameters. We investigate the scaling laws and find that the performance gap between our MatMul-free models and full precision Transformers narrows as the model size increases. We also provide a GPU-efficient implementation of this model which reduces memory usage by up to 61% over an unoptimized baseline during training. By utilizing an optimized kernel during inference, our model's memory consumption can be reduced by more than 10x compared to unoptimized models. To properly quantify the efficiency of our architecture, we build a custom hardware solution on an FPGA which exploits lightweight operations beyond what GPUs are capable of. We processed billion-parameter scale models at 13W beyond human readable throughput, moving LLMs closer to brain-like efficiency. This work not only shows how far LLMs can be stripped back while still performing effectively, but also points at the types of operations future accelerators should be optimized for in processing the next generation of lightweight LLMs. Our code implementation is available at \\url{https://github.com/ridgerchu/matmulfreellm}.","sentences":["Matrix multiplication (MatMul) typically dominates the overall computational cost of large language models (LLMs).","This cost only grows as LLMs scale to larger embedding dimensions and context lengths.","In this work, we show that MatMul operations can be completely eliminated from LLMs while maintaining strong performance at billion-parameter scales.","Our experiments show that our proposed MatMul-free models achieve performance on-par with state-of-the-art Transformers that require far more memory during inference at a scale up to at least 2.7B parameters.","We investigate the scaling laws and find that the performance gap between our MatMul-free models and full precision Transformers narrows as the model size increases.","We also provide a GPU-efficient implementation of this model which reduces memory usage by up to 61% over an unoptimized baseline during training.","By utilizing an optimized kernel during inference, our model's memory consumption can be reduced by more than 10x compared to unoptimized models.","To properly quantify the efficiency of our architecture, we build a custom hardware solution on an FPGA which exploits lightweight operations beyond what GPUs are capable of.","We processed billion-parameter scale models at 13W beyond human readable throughput, moving LLMs closer to brain-like efficiency.","This work not only shows how far LLMs can be stripped back while still performing effectively, but also points at the types of operations future accelerators should be optimized for in processing the next generation of lightweight LLMs.","Our code implementation is available at \\url{https://github.com/ridgerchu/matmulfreellm}."],"url":"http://arxiv.org/abs/2406.02528v1","category":"cs.CL"}
{"created":"2024-06-04 17:29:21","title":"Fairness-Optimized Synthetic EHR Generation for Arbitrary Downstream Predictive Tasks","abstract":"Among various aspects of ensuring the responsible design of AI tools for healthcare applications, addressing fairness concerns has been a key focus area. Specifically, given the wide spread of electronic health record (EHR) data and their huge potential to inform a wide range of clinical decision support tasks, improving fairness in this category of health AI tools is of key importance. While such a broad problem (that is, mitigating fairness in EHR-based AI models) has been tackled using various methods, task- and model-agnostic methods are noticeably rare. In this study, we aimed to target this gap by presenting a new pipeline that generates synthetic EHR data, which is not only consistent with (faithful to) the real EHR data but also can reduce the fairness concerns (defined by the end-user) in the downstream tasks, when combined with the real data. We demonstrate the effectiveness of our proposed pipeline across various downstream tasks and two different EHR datasets. Our proposed pipeline can add a widely applicable and complementary tool to the existing toolbox of methods to address fairness in health AI applications such as those modifying the design of a downstream model. The codebase for our project is available at https://github.com/healthylaife/FairSynth","sentences":["Among various aspects of ensuring the responsible design of AI tools for healthcare applications, addressing fairness concerns has been a key focus area.","Specifically, given the wide spread of electronic health record (EHR) data and their huge potential to inform a wide range of clinical decision support tasks, improving fairness in this category of health AI tools is of key importance.","While such a broad problem (that is, mitigating fairness in EHR-based AI models) has been tackled using various methods, task- and model-agnostic methods are noticeably rare.","In this study, we aimed to target this gap by presenting a new pipeline that generates synthetic EHR data, which is not only consistent with (faithful to) the real EHR data but also can reduce the fairness concerns (defined by the end-user) in the downstream tasks, when combined with the real data.","We demonstrate the effectiveness of our proposed pipeline across various downstream tasks and two different EHR datasets.","Our proposed pipeline can add a widely applicable and complementary tool to the existing toolbox of methods to address fairness in health AI applications such as those modifying the design of a downstream model.","The codebase for our project is available at https://github.com/healthylaife/FairSynth"],"url":"http://arxiv.org/abs/2406.02510v1","category":"cs.LG"}
{"created":"2024-06-04 17:22:05","title":"Towards an optimal marked correlation function analysis for the detection of modified gravity","abstract":"Modified gravity (MG) theories have emerged as a promising alternative to explain the late-time acceleration of the Universe. However, the detection of MG in observations of the large-scale structure remains challenging due to the screening mechanisms that obscure any deviations from General Relativity (GR) in high-density regions. The marked two-point correlation function offers a promising approach to potentially detect MG signals. This work investigates novel marks based on large-scale environment estimates but also that exploit the anti-correlation between objects in low- and high-density regions. This is the first time discreteness effects in density-dependent marked correlation functions are investigated in depth. We assess the performance of various marks to distinguish GR from MG by using the ELEPHANT simulations, comprised of realisations of GR as well as $f(R)$ and nDGP gravity. In addition, discreteness effects are studied using the high-density Covmos catalogues. We establish a robust method to correct for shot-noise effects that allows the recovery of the true signal with an accuracy below $5\\%$ over a wide range of scales. We find such correction to be crucial to measure the amplitude of the marked correlation function in an unbiased manner. Furthermore, we demonstrate that marks, anti-correlating objects in low- and high-density regions, are among the most effective in distinguishing between MG and GR. We report differences in the marked correlation function between $f(R)$ with $|f_{R0}|=10^{-6}$ and GR simulations of the order of 3-5$\\sigma$ in real space up to scales of about $80\\, h^{-1} \\, {\\rm Mpc}$. The redshift-space monopole exhibits similar features and performances. The combination of the proposed $\\tanh$-mark with shot-noise correction paves the way towards an optimal approach for the detection of MG in current and future galaxy spectroscopic surveys.","sentences":["Modified gravity (MG) theories have emerged as a promising alternative to explain the late-time acceleration of the Universe.","However, the detection of MG in observations of the large-scale structure remains challenging due to the screening mechanisms that obscure any deviations from General Relativity (GR) in high-density regions.","The marked two-point correlation function offers a promising approach to potentially detect MG signals.","This work investigates novel marks based on large-scale environment estimates but also that exploit the anti-correlation between objects in low- and high-density regions.","This is the first time discreteness effects in density-dependent marked correlation functions are investigated in depth.","We assess the performance of various marks to distinguish GR from MG by using the ELEPHANT simulations, comprised of realisations of GR as well as $f(R)$ and nDGP gravity.","In addition, discreteness effects are studied using the high-density Covmos catalogues.","We establish a robust method to correct for shot-noise effects that allows the recovery of the true signal with an accuracy below $5\\%$ over a wide range of scales.","We find such correction to be crucial to measure the amplitude of the marked correlation function in an unbiased manner.","Furthermore, we demonstrate that marks, anti-correlating objects in low- and high-density regions, are among the most effective in distinguishing between MG and GR.","We report differences in the marked correlation function between $f(R)$ with $|f_{R0}|=10^{-6}$ and GR simulations of the order of 3-5$\\sigma$ in real space up to scales of about $80\\, h^{-1} \\, {\\rm Mpc}$. The redshift-space monopole exhibits similar features and performances.","The combination of the proposed $\\tanh$-mark with shot-noise correction paves the way towards an optimal approach for the detection of MG in current and future galaxy spectroscopic surveys."],"url":"http://arxiv.org/abs/2406.02504v1","category":"astro-ph.CO"}
{"created":"2024-06-04 15:50:42","title":"Coresets for Multiple $\\ell_p$ Regression","abstract":"A coreset of a dataset with $n$ examples and $d$ features is a weighted subset of examples that is sufficient for solving downstream data analytic tasks. Nearly optimal constructions of coresets for least squares and $\\ell_p$ linear regression with a single response are known in prior work. However, for multiple $\\ell_p$ regression where there can be $m$ responses, there are no known constructions with size sublinear in $m$. In this work, we construct coresets of size $\\tilde O(\\varepsilon^{-2}d)$ for $p<2$ and $\\tilde O(\\varepsilon^{-p}d^{p/2})$ for $p>2$ independently of $m$ (i.e., dimension-free) that approximate the multiple $\\ell_p$ regression objective at every point in the domain up to $(1\\pm\\varepsilon)$ relative error. If we only need to preserve the minimizer subject to a subspace constraint, we improve these bounds by an $\\varepsilon$ factor for all $p>1$. All of our bounds are nearly tight.   We give two application of our results. First, we settle the number of uniform samples needed to approximate $\\ell_p$ Euclidean power means up to a $(1+\\varepsilon)$ factor, showing that $\\tilde\\Theta(\\varepsilon^{-2})$ samples for $p = 1$, $\\tilde\\Theta(\\varepsilon^{-1})$ samples for $1 < p < 2$, and $\\tilde\\Theta(\\varepsilon^{1-p})$ samples for $p>2$ is tight, answering a question of Cohen-Addad, Saulpic, and Schwiegelshohn. Second, we show that for $1<p<2$, every matrix has a subset of $\\tilde O(\\varepsilon^{-1}k)$ rows which spans a $(1+\\varepsilon)$-approximately optimal $k$-dimensional subspace for $\\ell_p$ subspace approximation, which is also nearly optimal.","sentences":["A coreset of a dataset with $n$ examples and $d$ features is a weighted subset of examples that is sufficient for solving downstream data analytic tasks.","Nearly optimal constructions of coresets for least squares and $\\ell_p$ linear regression with a single response are known in prior work.","However, for multiple $\\ell_p$ regression where there can be $m$ responses, there are no known constructions with size sublinear in $m$. In this work, we construct coresets of size $\\tilde O(\\varepsilon^{-2}d)$ for $p<2$ and $\\tilde O(\\varepsilon^{-p}d^{p/2})$ for $p>2$ independently of $m$ (i.e., dimension-free) that approximate the multiple $\\ell_p$ regression objective at every point in the domain up to $(1\\pm\\varepsilon)$ relative error.","If we only need to preserve the minimizer subject to a subspace constraint, we improve these bounds by an $\\varepsilon$ factor for all $p>1$. All of our bounds are nearly tight.   ","We give two application of our results.","First, we settle the number of uniform samples needed to approximate $\\ell_p$ Euclidean power means up to a $(1+\\varepsilon)$ factor, showing that $\\tilde\\Theta(\\varepsilon^{-2})$ samples for $p = 1$, $\\tilde\\Theta(\\varepsilon^{-1})$ samples for $1 < p < 2$, and $\\tilde\\Theta(\\varepsilon^{1-p})$ samples for $p>2$ is tight, answering a question of Cohen-Addad, Saulpic, and Schwiegelshohn.","Second, we show that for $1<p<2$, every matrix has a subset of $\\tilde O(\\varepsilon^{-1}k)$ rows which spans a $(1+\\varepsilon)$-approximately optimal $k$-dimensional subspace for $\\ell_p$ subspace approximation, which is also nearly optimal."],"url":"http://arxiv.org/abs/2406.02432v1","category":"cs.DS"}
{"created":"2024-06-04 15:50:35","title":"Reweighted Solutions for Weighted Low Rank Approximation","abstract":"Weighted low rank approximation (WLRA) is an important yet computationally challenging primitive with applications ranging from statistical analysis, model compression, and signal processing. To cope with the NP-hardness of this problem, prior work considers heuristics, bicriteria, or fixed parameter tractable algorithms to solve this problem. In this work, we introduce a new relaxed solution to WLRA which outputs a matrix that is not necessarily low rank, but can be stored using very few parameters and gives provable approximation guarantees when the weight matrix has low rank. Our central idea is to use the weight matrix itself to reweight a low rank solution, which gives an extremely simple algorithm with remarkable empirical performance in applications to model compression and on synthetic datasets. Our algorithm also gives nearly optimal communication complexity bounds for a natural distributed problem associated with this problem, for which we show matching communication lower bounds. Together, our communication complexity bounds show that the rank of the weight matrix provably parameterizes the communication complexity of WLRA. We also obtain the first relative error guarantees for feature selection with a weighted objective.","sentences":["Weighted low rank approximation (WLRA) is an important yet computationally challenging primitive with applications ranging from statistical analysis, model compression, and signal processing.","To cope with the NP-hardness of this problem, prior work considers heuristics, bicriteria, or fixed parameter tractable algorithms to solve this problem.","In this work, we introduce a new relaxed solution to WLRA which outputs a matrix that is not necessarily low rank, but can be stored using very few parameters and gives provable approximation guarantees when the weight matrix has low rank.","Our central idea is to use the weight matrix itself to reweight a low rank solution, which gives an extremely simple algorithm with remarkable empirical performance in applications to model compression and on synthetic datasets.","Our algorithm also gives nearly optimal communication complexity bounds for a natural distributed problem associated with this problem, for which we show matching communication lower bounds.","Together, our communication complexity bounds show that the rank of the weight matrix provably parameterizes the communication complexity of WLRA.","We also obtain the first relative error guarantees for feature selection with a weighted objective."],"url":"http://arxiv.org/abs/2406.02431v1","category":"cs.DS"}
{"created":"2024-06-04 15:46:41","title":"Contextual Optimization under Covariate Shift: A Robust Approach by Intersecting Wasserstein Balls","abstract":"In contextual optimization, a decision-maker observes historical samples of uncertain variables and associated concurrent covariates, without knowing their joint distribution. Given an additional covariate observation, the goal is to choose a decision that minimizes some operational costs. A prevalent issue here is covariate shift, where the marginal distribution of the new covariate differs from historical samples, leading to decision performance variations with nonparametric or parametric estimators. To address this, we propose a distributionally robust approach that uses an ambiguity set by the intersection of two Wasserstein balls, each centered on typical nonparametric or parametric distribution estimators. Computationally, we establish the tractable reformulation of this distributionally robust optimization problem. Statistically, we provide guarantees for our Wasserstein ball intersection approach under covariate shift by analyzing the measure concentration of the estimators. Furthermore, to reduce computational complexity, we employ a surrogate objective that maintains similar generalization guarantees. Through synthetic and empirical case studies on income prediction and portfolio optimization, we demonstrate the strong empirical performance of our proposed models.","sentences":["In contextual optimization, a decision-maker observes historical samples of uncertain variables and associated concurrent covariates, without knowing their joint distribution.","Given an additional covariate observation, the goal is to choose a decision that minimizes some operational costs.","A prevalent issue here is covariate shift, where the marginal distribution of the new covariate differs from historical samples, leading to decision performance variations with nonparametric or parametric estimators.","To address this, we propose a distributionally robust approach that uses an ambiguity set by the intersection of two Wasserstein balls, each centered on typical nonparametric or parametric distribution estimators.","Computationally, we establish the tractable reformulation of this distributionally robust optimization problem.","Statistically, we provide guarantees for our Wasserstein ball intersection approach under covariate shift by analyzing the measure concentration of the estimators.","Furthermore, to reduce computational complexity, we employ a surrogate objective that maintains similar generalization guarantees.","Through synthetic and empirical case studies on income prediction and portfolio optimization, we demonstrate the strong empirical performance of our proposed models."],"url":"http://arxiv.org/abs/2406.02426v1","category":"math.OC"}
{"created":"2024-06-04 15:44:10","title":"Contextual Dynamic Pricing: Algorithms, Optimality, and Local Differential Privacy Constraints","abstract":"We study the contextual dynamic pricing problem where a firm sells products to $T$ sequentially arriving consumers that behave according to an unknown demand model. The firm aims to maximize its revenue, i.e. minimize its regret over a clairvoyant that knows the model in advance. The demand model is a generalized linear model (GLM), allowing for a stochastic feature vector in $\\mathbb R^d$ that encodes product and consumer information. We first show that the optimal regret upper bound is of order $\\sqrt{dT}$, up to a logarithmic factor, improving upon existing upper bounds in the literature by a $\\sqrt{d}$ factor. This sharper rate is materialised by two algorithms: a confidence bound-type (supCB) algorithm and an explore-then-commit (ETC) algorithm. A key insight of our theoretical result is an intrinsic connection between dynamic pricing and the contextual multi-armed bandit problem with many arms based on a careful discretization. We further study contextual dynamic pricing under the local differential privacy (LDP) constraints. In particular, we propose a stochastic gradient descent based ETC algorithm that achieves an optimal regret upper bound of order $d\\sqrt{T}/\\epsilon$, up to a logarithmic factor, where $\\epsilon>0$ is the privacy parameter. The regret upper bounds with and without LDP constraints are accompanied by newly constructed minimax lower bounds, which further characterize the cost of privacy. Extensive numerical experiments and a real data application on online lending are conducted to illustrate the efficiency and practical value of the proposed algorithms in dynamic pricing.","sentences":["We study the contextual dynamic pricing problem where a firm sells products to $T$ sequentially arriving consumers that behave according to an unknown demand model.","The firm aims to maximize its revenue, i.e. minimize its regret over a clairvoyant that knows the model in advance.","The demand model is a generalized linear model (GLM), allowing for a stochastic feature vector in $\\mathbb R^d$ that encodes product and consumer information.","We first show that the optimal regret upper bound is of order $\\sqrt{dT}$, up to a logarithmic factor, improving upon existing upper bounds in the literature by a $\\sqrt{d}$ factor.","This sharper rate is materialised by two algorithms: a confidence bound-type (supCB) algorithm and an explore-then-commit (ETC) algorithm.","A key insight of our theoretical result is an intrinsic connection between dynamic pricing and the contextual multi-armed bandit problem with many arms based on a careful discretization.","We further study contextual dynamic pricing under the local differential privacy (LDP) constraints.","In particular, we propose a stochastic gradient descent based ETC algorithm that achieves an optimal regret upper bound of order $d\\sqrt{T}/\\epsilon$, up to a logarithmic factor, where $\\epsilon>0$ is the privacy parameter.","The regret upper bounds with and without LDP constraints are accompanied by newly constructed minimax lower bounds, which further characterize the cost of privacy.","Extensive numerical experiments and a real data application on online lending are conducted to illustrate the efficiency and practical value of the proposed algorithms in dynamic pricing."],"url":"http://arxiv.org/abs/2406.02424v1","category":"cs.LG"}
{"created":"2024-06-04 15:23:29","title":"Accelerated Variance-Reduced Forward-Reflected Methods for Root-Finding Problems","abstract":"We propose a novel class of Nesterov's stochastic accelerated forward-reflected-based methods with variance reduction to solve root-finding problems under $\\frac{1}{L}$-co-coerciveness. Our algorithm is single-loop and leverages a new family of unbiased variance-reduced estimators specifically designed for root-finding problems. It achieves both $\\mathcal{O}(L^2/k^2)$ and $o(1/k^2)$-last-iterate convergence rates in terms of expected operator squared norm, where $k$ denotes the iteration counter. We instantiate our framework for two prominent estimators: SVRG and SAGA. By an appropriate choice of parameters, both variants attain an oracle complexity of $\\mathcal{O}( n + Ln^{2/3}\\epsilon^{-1})$ to reach an $\\epsilon$-solution, where $n$ represents the number of summands in the finite-sum operator. Furthermore, under $\\mu$-strong quasi-monotonicity, our method achieves a linear convergence rate and an oracle complexity of $\\mathcal{O}(n+ \\kappa n^{2/3}\\log(\\epsilon^{-1}))$, where $\\kappa := \\frac{L}{\\mu}$. We extend our approach to solve a class of finite-sum monotone inclusions, demonstrating that our schemes retain the same theoretical guarantees as in the equation setting. Finally, numerical experiments validate our algorithms and demonstrate their promising performance compared to state-of-the-art methods.","sentences":["We propose a novel class of Nesterov's stochastic accelerated forward-reflected-based methods with variance reduction to solve root-finding problems under $\\frac{1}{L}$-co-coerciveness.","Our algorithm is single-loop and leverages a new family of unbiased variance-reduced estimators specifically designed for root-finding problems.","It achieves both $\\mathcal{O}(L^2/k^2)$ and $o(1/k^2)$-last-iterate convergence rates in terms of expected operator squared norm, where $k$ denotes the iteration counter.","We instantiate our framework for two prominent estimators: SVRG and SAGA.","By an appropriate choice of parameters, both variants attain an oracle complexity of $\\mathcal{O}( n + Ln^{2/3}\\epsilon^{-1})$ to reach an $\\epsilon$-solution, where $n$ represents the number of summands in the finite-sum operator.","Furthermore, under $\\mu$-strong quasi-monotonicity, our method achieves a linear convergence rate and an oracle complexity of $\\mathcal{O}(n+ \\kappa n^{2/3}\\log(\\epsilon^{-1}))$, where $\\kappa := \\frac{L}{\\mu}$.","We extend our approach to solve a class of finite-sum monotone inclusions, demonstrating that our schemes retain the same theoretical guarantees as in the equation setting.","Finally, numerical experiments validate our algorithms and demonstrate their promising performance compared to state-of-the-art methods."],"url":"http://arxiv.org/abs/2406.02413v1","category":"math.OC"}
{"created":"2024-06-04 15:21:37","title":"Decoupling of neural network calibration measures","abstract":"A lot of effort is currently invested in safeguarding autonomous driving systems, which heavily rely on deep neural networks for computer vision. We investigate the coupling of different neural network calibration measures with a special focus on the Area Under the Sparsification Error curve (AUSE) metric. We elaborate on the well-known inconsistency in determining optimal calibration using the Expected Calibration Error (ECE) and we demonstrate similar issues for the AUSE, the Uncertainty Calibration Score (UCS), as well as the Uncertainty Calibration Error (UCE). We conclude that the current methodologies leave a degree of freedom, which prevents a unique model calibration for the homologation of safety-critical functionalities. Furthermore, we propose the AUSE as an indirect measure for the residual uncertainty, which is irreducible for a fixed network architecture and is driven by the stochasticity in the underlying data generation process (aleatoric contribution) as well as the limitation in the hypothesis space (epistemic contribution).","sentences":["A lot of effort is currently invested in safeguarding autonomous driving systems, which heavily rely on deep neural networks for computer vision.","We investigate the coupling of different neural network calibration measures with a special focus on the Area Under the Sparsification Error curve (AUSE) metric.","We elaborate on the well-known inconsistency in determining optimal calibration using the Expected Calibration Error (ECE) and we demonstrate similar issues for the AUSE, the Uncertainty Calibration Score (UCS), as well as the Uncertainty Calibration Error (UCE).","We conclude that the current methodologies leave a degree of freedom, which prevents a unique model calibration for the homologation of safety-critical functionalities.","Furthermore, we propose the AUSE as an indirect measure for the residual uncertainty, which is irreducible for a fixed network architecture and is driven by the stochasticity in the underlying data generation process (aleatoric contribution) as well as the limitation in the hypothesis space (epistemic contribution)."],"url":"http://arxiv.org/abs/2406.02411v1","category":"cs.CV"}
{"created":"2024-06-04 15:19:29","title":"Optimization of Rate-Splitting Multiple Access with Integrated Sensing and Backscatter Communication","abstract":"An integrated sensing and backscatter communication (ISABC) system is introduced herein. This system features a full-duplex (FD) base station (BS) that seamlessly merges sensing with backscatter communication and supports multiple users. Multiple access (MA) for the user is provided by employing rate-splitting multiple access (RSMA). RSMA, unlike other classical orthogonal and non-orthogonal MA schemes, splits messages into common and private streams. With RSMA, the set of common rate forms can be optimized to reduce interference. Optimized formulas are thus derived for communication rates for users, tags, and the BS's sensing rate, with the primary goal of enhancing the transmission efficiency of the BS. The optimization task involves minimizing the BS's overall transmission power by jointly optimizing the BS's beamforming vectors, the tag reflection coefficients, and user common rates. The alternating optimization method is employed to address this challenge. Concrete solutions are provided for the received beamformers, and semi-definite relaxation and slack-optimization techniques are adopted for transmit beamformers and reflection coefficients, respectively. For example, the proposed RSMA-assisted ISABC system achieves a 350% communication rate boost over a nonorthogonal multiple access-assisted ISABC, with only a 24% increase in transmit power, leveraging ten transmit/reception antennas at the BS.","sentences":["An integrated sensing and backscatter communication (ISABC) system is introduced herein.","This system features a full-duplex (FD) base station (BS) that seamlessly merges sensing with backscatter communication and supports multiple users.","Multiple access (MA) for the user is provided by employing rate-splitting multiple access (RSMA).","RSMA, unlike other classical orthogonal and non-orthogonal MA schemes, splits messages into common and private streams.","With RSMA, the set of common rate forms can be optimized to reduce interference.","Optimized formulas are thus derived for communication rates for users, tags, and the BS's sensing rate, with the primary goal of enhancing the transmission efficiency of the BS.","The optimization task involves minimizing the BS's overall transmission power by jointly optimizing the BS's beamforming vectors, the tag reflection coefficients, and user common rates.","The alternating optimization method is employed to address this challenge.","Concrete solutions are provided for the received beamformers, and semi-definite relaxation and slack-optimization techniques are adopted for transmit beamformers and reflection coefficients, respectively.","For example, the proposed RSMA-assisted ISABC system achieves a 350% communication rate boost over a nonorthogonal multiple access-assisted ISABC, with only a 24% increase in transmit power, leveraging ten transmit/reception antennas at the BS."],"url":"http://arxiv.org/abs/2406.02410v1","category":"eess.SP"}
{"created":"2024-06-04 15:17:04","title":"Demonstration of two-dimensional connectivity for a scalable error-corrected ion-trap quantum processor architecture","abstract":"A major hurdle for building a large-scale quantum computer is to scale up the number of qubits while maintaining connectivity between them. In trapped-ion devices, this connectivity can be provided by physically moving subregisters consisting of a few ions across the processor. The topology of the connectivity is given by the layout of the ion trap where one-dimensional and two-dimensional arrangements are possible. Here, we focus on an architecture based on a rectangular two-dimensional lattice, where each lattice site contains a subregister with a linear string of ions. We refer to this architecture as the Quantum Spring Array (QSA). Subregisters placed in neighboring lattice sites can be coupled by bringing the respective ion strings close to each other while avoiding merging them into a single trapping potential. Control of the separation of subregisters along one axis of the lattice, known as the axial direction, uses quasi-static voltages, while the second axis, the radial, requires control of radio frequency signals. In this work, we investigate key elements of the 2D lattice quantum computation architecture along both axes: We show that the coupling rate between neighboring lattice sites increases with the number of ions per site and the motion of the coupled system can be resilient to noise. The coherence of the coupling is assessed, and an entangled state of qubits in separate trapping regions along the radial axis is demonstrated. Moreover, we demonstrate control over radio frequency signals to adjust radial separation between strings, and thus tune their coupling rate. We further map the 2D lattice architecture to code primitives for fault-tolerant quantum error correction, providing a step towards a quantum processor architecture that is optimized for large-scale fault-tolerant operation.","sentences":["A major hurdle for building a large-scale quantum computer is to scale up the number of qubits while maintaining connectivity between them.","In trapped-ion devices, this connectivity can be provided by physically moving subregisters consisting of a few ions across the processor.","The topology of the connectivity is given by the layout of the ion trap where one-dimensional and two-dimensional arrangements are possible.","Here, we focus on an architecture based on a rectangular two-dimensional lattice, where each lattice site contains a subregister with a linear string of ions.","We refer to this architecture as the Quantum Spring Array (QSA).","Subregisters placed in neighboring lattice sites can be coupled by bringing the respective ion strings close to each other while avoiding merging them into a single trapping potential.","Control of the separation of subregisters along one axis of the lattice, known as the axial direction, uses quasi-static voltages, while the second axis, the radial, requires control of radio frequency signals.","In this work, we investigate key elements of the 2D lattice quantum computation architecture along both axes: We show that the coupling rate between neighboring lattice sites increases with the number of ions per site and the motion of the coupled system can be resilient to noise.","The coherence of the coupling is assessed, and an entangled state of qubits in separate trapping regions along the radial axis is demonstrated.","Moreover, we demonstrate control over radio frequency signals to adjust radial separation between strings, and thus tune their coupling rate.","We further map the 2D lattice architecture to code primitives for fault-tolerant quantum error correction, providing a step towards a quantum processor architecture that is optimized for large-scale fault-tolerant operation."],"url":"http://arxiv.org/abs/2406.02406v1","category":"quant-ph"}
{"created":"2024-06-04 15:13:41","title":"Can a Few Decide for Many? The Metric Distortion of Sortition","abstract":"Recent works have studied the design of algorithms for selecting representative sortition panels. However, the most central question remains unaddressed: Do these panels reflect the entire population's opinion? We present a positive answer by adopting the concept of metric distortion from computational social choice, which aims to quantify how much a panel's decision aligns with the ideal decision of the population when preferences and agents lie on a metric space. We show that uniform selection needs only logarithmically many agents in terms of the number of alternatives to achieve almost optimal distortion. We also show that Fair Greedy Capture, a selection algorithm introduced recently by Ebadian & Micha (2024), matches uniform selection's guarantees of almost optimal distortion and also achieves constant ex-post distortion, ensuring a \"best of both worlds\" performance.","sentences":["Recent works have studied the design of algorithms for selecting representative sortition panels.","However, the most central question remains unaddressed: Do these panels reflect the entire population's opinion?","We present a positive answer by adopting the concept of metric distortion from computational social choice, which aims to quantify how much a panel's decision aligns with the ideal decision of the population when preferences and agents lie on a metric space.","We show that uniform selection needs only logarithmically many agents in terms of the number of alternatives to achieve almost optimal distortion.","We also show that Fair Greedy Capture, a selection algorithm introduced recently by Ebadian & Micha (2024), matches uniform selection's guarantees of almost optimal distortion and also achieves constant ex-post distortion, ensuring a \"best of both worlds\" performance."],"url":"http://arxiv.org/abs/2406.02400v1","category":"cs.GT"}
{"created":"2024-06-04 15:01:13","title":"Multifractality in monitored single-particle dynamics","abstract":"We study multifractal properties in time evolution of a single particle subject to repeated measurements. For quantum systems, we consider circuit models consisting of local unitary gates and local projective measurements. For classical systems, we consider models for estimating the trajectory of a particle evolved under local transition processes by partially measuring particle occupations. In both cases, multifractal behaviors appear in the ensemble of wave functions or probability distributions conditioned on measurement outcomes after a sufficiently long time. While the nature of particle transport (diffusive or ballistic) qualitatively affects the multifractal properties, they are even quantitatively robust to the measurement rate or specific protocols. On the other hand, multifractality is generically lost by generalized measurements allowing erroneous outcomes or by postselection of the outcomes with no particle detection. We demonstrate these properties by numerical simulations and also propose several simplified models, which allow us to analytically obtain multifractal properties in the monitored single-particle systems.","sentences":["We study multifractal properties in time evolution of a single particle subject to repeated measurements.","For quantum systems, we consider circuit models consisting of local unitary gates and local projective measurements.","For classical systems, we consider models for estimating the trajectory of a particle evolved under local transition processes by partially measuring particle occupations.","In both cases, multifractal behaviors appear in the ensemble of wave functions or probability distributions conditioned on measurement outcomes after a sufficiently long time.","While the nature of particle transport (diffusive or ballistic) qualitatively affects the multifractal properties, they are even quantitatively robust to the measurement rate or specific protocols.","On the other hand, multifractality is generically lost by generalized measurements allowing erroneous outcomes or by postselection of the outcomes with no particle detection.","We demonstrate these properties by numerical simulations and also propose several simplified models, which allow us to analytically obtain multifractal properties in the monitored single-particle systems."],"url":"http://arxiv.org/abs/2406.02386v1","category":"quant-ph"}
{"created":"2024-06-04 14:43:50","title":"Exploiting Chordal Sparsity for Fast Global Optimality with Application to Localization","abstract":"In recent years, many estimation problems in robotics have been shown to be solvable to global optimality using their semidefinite relaxations. However, the runtime complexity of off-the-shelve semidefinite programming solvers is up to cubic in problem size, which inhibits real-time solutions of problems involving large state dimensions. We show that for a large class of problems, namely those with chordal sparsity, we can reduce the complexity of these solvers to linear in problem size. In particular, we show how to replace the large positive-semidefinite variable by a number of smaller interconnected ones using the well-known chordal decomposition. This formulation also allows for the straightforward application of the alternating direction method of multipliers (ADMM), which can exploit parallelism for increased scalability. We show in simulation that the algorithms provide a significant speed up for two example problems: matrix-weighted and range-only localization.","sentences":["In recent years, many estimation problems in robotics have been shown to be solvable to global optimality using their semidefinite relaxations.","However, the runtime complexity of off-the-shelve semidefinite programming solvers is up to cubic in problem size, which inhibits real-time solutions of problems involving large state dimensions.","We show that for a large class of problems, namely those with chordal sparsity, we can reduce the complexity of these solvers to linear in problem size.","In particular, we show how to replace the large positive-semidefinite variable by a number of smaller interconnected ones using the well-known chordal decomposition.","This formulation also allows for the straightforward application of the alternating direction method of multipliers (ADMM), which can exploit parallelism for increased scalability.","We show in simulation that the algorithms provide a significant speed up for two example problems: matrix-weighted and range-only localization."],"url":"http://arxiv.org/abs/2406.02365v1","category":"cs.RO"}
{"created":"2024-06-04 14:42:09","title":"Learning dynamical models from stochastic trajectories","abstract":"The dynamics of biological systems, from proteins to cells to organisms, is complex and stochastic. To decipher their physical laws, we need to bridge between experimental observations and theoretical modeling. Thanks to progress in microscopy and tracking, there is today an abundance of experimental trajectories reflecting these dynamical laws. Inferring physical models from noisy and imperfect experimental data, however, is challenging. Because there are no inference methods that are robust and efficient, model reconstruction from experimental trajectories is a bottleneck to data-driven biophysics. In this Thesis, I present a set of tools developed to bridge this gap and permit robust and universal inference of stochastic dynamical models from experimental trajectories. These methods are rooted in an information-theoretical framework that quantifies how much can be inferred from trajectories that are short, partial and noisy. They permit the efficient inference of dynamical models for overdamped and underdamped Langevin systems, as well as the inference of entropy production rates. I finally present early applications of these techniques, as well as future research directions.","sentences":["The dynamics of biological systems, from proteins to cells to organisms, is complex and stochastic.","To decipher their physical laws, we need to bridge between experimental observations and theoretical modeling.","Thanks to progress in microscopy and tracking, there is today an abundance of experimental trajectories reflecting these dynamical laws.","Inferring physical models from noisy and imperfect experimental data, however, is challenging.","Because there are no inference methods that are robust and efficient, model reconstruction from experimental trajectories is a bottleneck to data-driven biophysics.","In this Thesis, I present a set of tools developed to bridge this gap and permit robust and universal inference of stochastic dynamical models from experimental trajectories.","These methods are rooted in an information-theoretical framework that quantifies how much can be inferred from trajectories that are short, partial and noisy.","They permit the efficient inference of dynamical models for overdamped and underdamped Langevin systems, as well as the inference of entropy production rates.","I finally present early applications of these techniques, as well as future research directions."],"url":"http://arxiv.org/abs/2406.02363v1","category":"cond-mat.soft"}
{"created":"2024-06-04 14:30:44","title":"A compact stellarator-tokamak hybrid","abstract":"Tokamaks and stellarators are the leading two magnetic confinement devices for producing fusion energy, begging the question of whether the strengths of the two could be merged into a single concept. To meet this challenge, we propose a first-of-its kind optimized stellarator-tokamak hybrid. Compared to a typical tokamak coil set, only a single simple type of stellarator coil has to be added which leads to a compact, volume- and transport-preserving magnetic field, with an added rotational transform that reaches levels thought to enhance stability.","sentences":["Tokamaks and stellarators are the leading two magnetic confinement devices for producing fusion energy, begging the question of whether the strengths of the two could be merged into a single concept.","To meet this challenge, we propose a first-of-its kind optimized stellarator-tokamak hybrid.","Compared to a typical tokamak coil set, only a single simple type of stellarator coil has to be added which leads to a compact, volume- and transport-preserving magnetic field, with an added rotational transform that reaches levels thought to enhance stability."],"url":"http://arxiv.org/abs/2406.02353v1","category":"physics.plasm-ph"}
{"created":"2024-06-04 14:20:10","title":"Incorporating Navigation Context into Inland Vessel Trajectory Prediction: A Gaussian Mixture Model and Transformer Approach","abstract":"Using data sources beyond the Automatic Identification System to represent the context a vessel is navigating in and consequently improve situation awareness is still rare in machine learning approaches to vessel trajectory prediction (VTP). In inland shipping, where vessel movement is constrained within fairways, navigational context information is indispensable. In this contribution targeting inland VTP, Gaussian Mixture Models (GMMs) are applied, on a fused dataset of AIS and discharge measurements, to generate multi-modal distribution curves, capturing typical lateral vessel positioning in the fairway and dislocation speeds along the waterway. By sampling the probability density curves of the GMMs, feature vectors are derived which are used, together with spatio-temporal vessel features and fairway geometries, as input to a VTP transformer model. The incorporation of these distribution features of both the current and forthcoming navigation context improves prediction accuracy. The superiority of the model over a previously proposed transformer model for inland VTP is shown. The novelty lies in the provision of preprocessed, statistics-based features representing the conditioned spatial context, rather than relying on the model to extract relevant features for the VTP task from contextual data. Oversimplification of the complexity of inland navigation patterns by assuming a single typical route or selecting specific clusters prior to model application is avoided by giving the model access to the entire distribution information. The methodology's generalizability is demonstrated through the usage of data of 3 distinct river sections. It can be integrated into an interaction-aware prediction framework, where insights into the positioning of the actual vessel behavior in the overall distribution at the current location and discharge can enhance trajectory prediction accuracy.","sentences":["Using data sources beyond the Automatic Identification System to represent the context a vessel is navigating in and consequently improve situation awareness is still rare in machine learning approaches to vessel trajectory prediction (VTP).","In inland shipping, where vessel movement is constrained within fairways, navigational context information is indispensable.","In this contribution targeting inland VTP, Gaussian Mixture Models (GMMs) are applied, on a fused dataset of AIS and discharge measurements, to generate multi-modal distribution curves, capturing typical lateral vessel positioning in the fairway and dislocation speeds along the waterway.","By sampling the probability density curves of the GMMs, feature vectors are derived which are used, together with spatio-temporal vessel features and fairway geometries, as input to a VTP transformer model.","The incorporation of these distribution features of both the current and forthcoming navigation context improves prediction accuracy.","The superiority of the model over a previously proposed transformer model for inland VTP is shown.","The novelty lies in the provision of preprocessed, statistics-based features representing the conditioned spatial context, rather than relying on the model to extract relevant features for the VTP task from contextual data.","Oversimplification of the complexity of inland navigation patterns by assuming a single typical route or selecting specific clusters prior to model application is avoided by giving the model access to the entire distribution information.","The methodology's generalizability is demonstrated through the usage of data of 3 distinct river sections.","It can be integrated into an interaction-aware prediction framework, where insights into the positioning of the actual vessel behavior in the overall distribution at the current location and discharge can enhance trajectory prediction accuracy."],"url":"http://arxiv.org/abs/2406.02344v2","category":"cs.LG"}
{"created":"2024-06-04 14:19:50","title":"Cluster-Aware Similarity Diffusion for Instance Retrieval","abstract":"Diffusion-based re-ranking is a common method used for retrieving instances by performing similarity propagation in a nearest neighbor graph. However, existing techniques that construct the affinity graph based on pairwise instances can lead to the propagation of misinformation from outliers and other manifolds, resulting in inaccurate results. To overcome this issue, we propose a novel Cluster-Aware Similarity (CAS) diffusion for instance retrieval. The primary concept of CAS is to conduct similarity diffusion within local clusters, which can reduce the influence from other manifolds explicitly. To obtain a symmetrical and smooth similarity matrix, our Bidirectional Similarity Diffusion strategy introduces an inverse constraint term to the optimization objective of local cluster diffusion. Additionally, we have optimized a Neighbor-guided Similarity Smoothing approach to ensure similarity consistency among the local neighbors of each instance. Evaluations in instance retrieval and object re-identification validate the effectiveness of the proposed CAS, our code is publicly available.","sentences":["Diffusion-based re-ranking is a common method used for retrieving instances by performing similarity propagation in a nearest neighbor graph.","However, existing techniques that construct the affinity graph based on pairwise instances can lead to the propagation of misinformation from outliers and other manifolds, resulting in inaccurate results.","To overcome this issue, we propose a novel Cluster-Aware Similarity (CAS) diffusion for instance retrieval.","The primary concept of CAS is to conduct similarity diffusion within local clusters, which can reduce the influence from other manifolds explicitly.","To obtain a symmetrical and smooth similarity matrix, our Bidirectional Similarity Diffusion strategy introduces an inverse constraint term to the optimization objective of local cluster diffusion.","Additionally, we have optimized a Neighbor-guided Similarity Smoothing approach to ensure similarity consistency among the local neighbors of each instance.","Evaluations in instance retrieval and object re-identification validate the effectiveness of the proposed CAS, our code is publicly available."],"url":"http://arxiv.org/abs/2406.02343v1","category":"cs.LG"}
{"created":"2024-06-04 14:18:01","title":"QCDGE database, Quantum Chemistry Database with Ground- and Excited-state Properties of 450 Kilo Molecules","abstract":"Due to rapid advancements in deep learning techniques, the demand for large-volume high-quality databases grows significantly in chemical research. We developed a quantum-chemistry database that includes 443,106 small organic molecules with sizes up to 10 heavy atoms including carbon (C), nitrogen (N), oxygen (O), and fluorine (F). Ground-state geometry optimizations and frequency calculations of all compounds were performed at the B3LYP/6-31G* level with the BJD3 dispersion correction, while the excited-state single-point calculations were conducted at the $\\omega$B97X-D/6-31G* level. Totally twenty seven molecular properties, such as geometric, thermodynamic, electronic and energetic properties, were gathered from these calculations. Meanwhile, we also established a comprehensive protocol for the construction of a high-volume quantum-chemistry database. Our QCDGE (Quantum Chemistry Database with Ground- and Excited-State Properties) database contains a substantial volume of data, exhibits high chemical diversity, and most importantly includes excited-state information. This database, along with its construction protocol, is expected to have a significant impact on the broad applications of machine learning studies across different fields of chemistry, especially in the area of excited-state research.","sentences":["Due to rapid advancements in deep learning techniques, the demand for large-volume high-quality databases grows significantly in chemical research.","We developed a quantum-chemistry database that includes 443,106 small organic molecules with sizes up to 10 heavy atoms including carbon (C), nitrogen (N), oxygen (O), and fluorine (F).","Ground-state geometry optimizations and frequency calculations of all compounds were performed at the B3LYP/6-31G* level with the BJD3 dispersion correction, while the excited-state single-point calculations were conducted at the $\\omega$B97X-D/6-31G* level.","Totally twenty seven molecular properties, such as geometric, thermodynamic, electronic and energetic properties, were gathered from these calculations.","Meanwhile, we also established a comprehensive protocol for the construction of a high-volume quantum-chemistry database.","Our QCDGE (Quantum Chemistry Database with Ground- and Excited-State Properties) database contains a substantial volume of data, exhibits high chemical diversity, and most importantly includes excited-state information.","This database, along with its construction protocol, is expected to have a significant impact on the broad applications of machine learning studies across different fields of chemistry, especially in the area of excited-state research."],"url":"http://arxiv.org/abs/2406.02341v1","category":"physics.chem-ph"}
{"created":"2024-06-04 14:09:36","title":"Linguistic Fingerprint in Transformer Models: How Language Variation Influences Parameter Selection in Irony Detection","abstract":"This paper explores the correlation between linguistic diversity, sentiment analysis and transformer model architectures. We aim to investigate how different English variations impact transformer-based models for irony detection. To conduct our study, we used the EPIC corpus to extract five diverse English variation-specific datasets and applied the KEN pruning algorithm on five different architectures. Our results reveal several similarities between optimal subnetworks, which provide insights into the linguistic variations that share strong resemblances and those that exhibit greater dissimilarities. We discovered that optimal subnetworks across models share at least 60% of their parameters, emphasizing the significance of parameter values in capturing and interpreting linguistic variations. This study highlights the inherent structural similarities between models trained on different variants of the same language and also the critical role of parameter values in capturing these nuances.","sentences":["This paper explores the correlation between linguistic diversity, sentiment analysis and transformer model architectures.","We aim to investigate how different English variations impact transformer-based models for irony detection.","To conduct our study, we used the EPIC corpus to extract five diverse English variation-specific datasets and applied the KEN pruning algorithm on five different architectures.","Our results reveal several similarities between optimal subnetworks, which provide insights into the linguistic variations that share strong resemblances and those that exhibit greater dissimilarities.","We discovered that optimal subnetworks across models share at least 60% of their parameters, emphasizing the significance of parameter values in capturing and interpreting linguistic variations.","This study highlights the inherent structural similarities between models trained on different variants of the same language and also the critical role of parameter values in capturing these nuances."],"url":"http://arxiv.org/abs/2406.02338v1","category":"cs.CL"}
{"created":"2024-06-04 14:01:03","title":"Towards Neural Architecture Search for Transfer Learning in 6G Networks","abstract":"The future 6G network is envisioned to be AI-native, and as such, ML models will be pervasive in support of optimizing performance, reducing energy consumption, and in coping with increasing complexity and heterogeneity. A key challenge is automating the process of finding optimal model architectures satisfying stringent requirements stemming from varying tasks, dynamicity and available resources in the infrastructure and deployment positions. In this paper, we describe and review the state-of-the-art in Neural Architecture Search and Transfer Learning and their applicability in networking. Further, we identify open research challenges and set directions with a specific focus on three main requirements with elements unique to the future network, namely combining NAS and TL, multi-objective search, and tabular data. Finally, we outline and discuss both near-term and long-term work ahead.","sentences":["The future 6G network is envisioned to be AI-native, and as such, ML models will be pervasive in support of optimizing performance, reducing energy consumption, and in coping with increasing complexity and heterogeneity.","A key challenge is automating the process of finding optimal model architectures satisfying stringent requirements stemming from varying tasks, dynamicity and available resources in the infrastructure and deployment positions.","In this paper, we describe and review the state-of-the-art in Neural Architecture Search and Transfer Learning and their applicability in networking.","Further, we identify open research challenges and set directions with a specific focus on three main requirements with elements unique to the future network, namely combining NAS and TL, multi-objective search, and tabular data.","Finally, we outline and discuss both near-term and long-term work ahead."],"url":"http://arxiv.org/abs/2406.02333v1","category":"cs.NI"}
{"created":"2024-06-04 13:45:35","title":"Generative Conditional Distributions by Neural (Entropic) Optimal Transport","abstract":"Learning conditional distributions is challenging because the desired outcome is not a single distribution but multiple distributions that correspond to multiple instances of the covariates. We introduce a novel neural entropic optimal transport method designed to effectively learn generative models of conditional distributions, particularly in scenarios characterized by limited sample sizes. Our method relies on the minimax training of two neural networks: a generative network parametrizing the inverse cumulative distribution functions of the conditional distributions and another network parametrizing the conditional Kantorovich potential. To prevent overfitting, we regularize the objective function by penalizing the Lipschitz constant of the network output. Our experiments on real-world datasets show the effectiveness of our algorithm compared to state-of-the-art conditional distribution learning techniques. Our implementation can be found at https://github.com/nguyenngocbaocmt02/GENTLE.","sentences":["Learning conditional distributions is challenging because the desired outcome is not a single distribution but multiple distributions that correspond to multiple instances of the covariates.","We introduce a novel neural entropic optimal transport method designed to effectively learn generative models of conditional distributions, particularly in scenarios characterized by limited sample sizes.","Our method relies on the minimax training of two neural networks: a generative network parametrizing the inverse cumulative distribution functions of the conditional distributions and another network parametrizing the conditional Kantorovich potential.","To prevent overfitting, we regularize the objective function by penalizing the Lipschitz constant of the network output.","Our experiments on real-world datasets show the effectiveness of our algorithm compared to state-of-the-art conditional distribution learning techniques.","Our implementation can be found at https://github.com/nguyenngocbaocmt02/GENTLE."],"url":"http://arxiv.org/abs/2406.02317v1","category":"cs.LG"}
{"created":"2024-06-04 13:42:42","title":"Neural Thermodynamic Integration: Free Energies from Energy-based Diffusion Models","abstract":"Thermodynamic integration (TI) offers a rigorous method for estimating free-energy differences by integrating over a sequence of interpolating conformational ensembles. However, TI calculations are computationally expensive and typically limited to coupling a small number of degrees of freedom due to the need to sample numerous intermediate ensembles with sufficient conformational-space overlap. In this work, we propose to perform TI along an alchemical pathway represented by a trainable neural network, which we term Neural TI. Critically, we parametrize a time-dependent Hamiltonian interpolating between the interacting and non-interacting systems, and optimize its gradient using a denoising-diffusion objective. The ability of the resulting energy-based diffusion model to sample all intermediate ensembles, allows us to perform TI from a single reference calculation. We apply our method to Lennard-Jones fluids, where we report accurate calculations of the excess chemical potential, demonstrating that Neural TI is capable of coupling hundreds of degrees of freedom at once.","sentences":["Thermodynamic integration (TI) offers a rigorous method for estimating free-energy differences by integrating over a sequence of interpolating conformational ensembles.","However, TI calculations are computationally expensive and typically limited to coupling a small number of degrees of freedom due to the need to sample numerous intermediate ensembles with sufficient conformational-space overlap.","In this work, we propose to perform TI along an alchemical pathway represented by a trainable neural network, which we term Neural TI.","Critically, we parametrize a time-dependent Hamiltonian interpolating between the interacting and non-interacting systems, and optimize its gradient using a denoising-diffusion objective.","The ability of the resulting energy-based diffusion model to sample all intermediate ensembles, allows us to perform TI from a single reference calculation.","We apply our method to Lennard-Jones fluids, where we report accurate calculations of the excess chemical potential, demonstrating that Neural TI is capable of coupling hundreds of degrees of freedom at once."],"url":"http://arxiv.org/abs/2406.02313v1","category":"cond-mat.stat-mech"}
{"created":"2024-06-04 13:42:24","title":"Multimodal Resonance in Strongly Coupled Inductor Arrays","abstract":"Magnetic resonance coupling (MRC) is widely used for wireless power transfer (WPT) applications, but little work has explored how MRC phenomena could be exploited for sensing applications. This paper introduces, validates and evaluates the unique multi-resonant phenomena predicted by circuit theory for over-coupled inductive arrays, and presents eigen-formulae for calculating resonant frequencies and voltage modes within passively excited arrays. Finite-element simulations and experimental results demonstrate the validity of the multi-modal resonant principles for strongly-coupled inductor arrays. The results confirm the distinctive multi-modal resonant frequencies these arrays exhibit, corresponding to the specific magnetic excitation \"modes\" (comparable to vibrational modes in multi-degree-of-freedom systems). The theoretical and finite element models presented offer a framework for designing and optimizing novel inductive sensing arrays, capitalizing on the unique resonant effects of over-coupling and exploiting their potential magnetic field shaping.","sentences":["Magnetic resonance coupling (MRC) is widely used for wireless power transfer (WPT) applications, but little work has explored how MRC phenomena could be exploited for sensing applications.","This paper introduces, validates and evaluates the unique multi-resonant phenomena predicted by circuit theory for over-coupled inductive arrays, and presents eigen-formulae for calculating resonant frequencies and voltage modes within passively excited arrays.","Finite-element simulations and experimental results demonstrate the validity of the multi-modal resonant principles for strongly-coupled inductor arrays.","The results confirm the distinctive multi-modal resonant frequencies these arrays exhibit, corresponding to the specific magnetic excitation \"modes\" (comparable to vibrational modes in multi-degree-of-freedom systems).","The theoretical and finite element models presented offer a framework for designing and optimizing novel inductive sensing arrays, capitalizing on the unique resonant effects of over-coupling and exploiting their potential magnetic field shaping."],"url":"http://arxiv.org/abs/2406.02312v1","category":"eess.SY"}
{"created":"2024-06-04 13:39:58","title":"Gradient-free algorithm for saddle point problems under overparametrization","abstract":"This paper focuses on solving a stochastic saddle point problem (SPP) under an overparameterized regime for the case, when the gradient computation is impractical. As an intermediate step, we generalize Same-sample Stochastic Extra-gradient algorithm (Gorbunov et al., 2022) to a biased oracle and estimate novel convergence rates. As the result of the paper we introduce an algorithm, which uses gradient approximation instead of a gradient oracle. We also conduct an analysis to find the maximum admissible level of adversarial noise and the optimal number of iterations at which our algorithm can guarantee achieving the desired accuracy.","sentences":["This paper focuses on solving a stochastic saddle point problem (SPP) under an overparameterized regime for the case, when the gradient computation is impractical.","As an intermediate step, we generalize Same-sample Stochastic Extra-gradient algorithm (Gorbunov et al., 2022) to a biased oracle and estimate novel convergence rates.","As the result of the paper we introduce an algorithm, which uses gradient approximation instead of a gradient oracle.","We also conduct an analysis to find the maximum admissible level of adversarial noise and the optimal number of iterations at which our algorithm can guarantee achieving the desired accuracy."],"url":"http://arxiv.org/abs/2406.02308v1","category":"math.OC"}
{"created":"2024-06-04 13:18:14","title":"Optimal Stock Portfolio Selection with a Multivariate Hidden Markov Model","abstract":"The underlying market trends that drive stock price fluctuations are often referred to in terms of bull and bear markets. Optimal stock portfolio selection methods need to take into account these market trends; however, the bull and bear market states tend to be unobserved and can only be assigned retrospectively. We fit a linked hidden Markov model (LHMM) to relative stock price changes for S&P 500 stocks from 2011--2016 based on weekly closing values. The LHMM consists of a multivariate state process whose individual components correspond to HMMs for each of the 12 sectors of the S\\&P 500 stocks. The state processes are linked using a Gaussian copula so that the states of the component chains are correlated at any given time point. The LHMM allows us to capture more heterogeneity in the underlying market dynamics for each sector. In this study, stock performances are evaluated in terms of capital gains using the LHMM by utilizing historical stock price data. Based on the fitted LHMM, optimal stock portfolios are constructed to maximize capital gain while balancing reward and risk. Under out-of-sample testing, the annual capital gain for the portfolios for 2016--2017 are calculated. Portfolios constructed using the LHMM are able to generate returns comparable to the S&P 500 index.","sentences":["The underlying market trends that drive stock price fluctuations are often referred to in terms of bull and bear markets.","Optimal stock portfolio selection methods need to take into account these market trends; however, the bull and bear market states tend to be unobserved and can only be assigned retrospectively.","We fit a linked hidden Markov model (LHMM) to relative stock price changes for S&P 500 stocks from 2011--2016 based on weekly closing values.","The LHMM consists of a multivariate state process whose individual components correspond to HMMs for each of the 12 sectors of the S\\&P 500 stocks.","The state processes are linked using a Gaussian copula so that the states of the component chains are correlated at any given time point.","The LHMM allows us to capture more heterogeneity in the underlying market dynamics for each sector.","In this study, stock performances are evaluated in terms of capital gains using the LHMM by utilizing historical stock price data.","Based on the fitted LHMM, optimal stock portfolios are constructed to maximize capital gain while balancing reward and risk.","Under out-of-sample testing, the annual capital gain for the portfolios for 2016--2017 are calculated.","Portfolios constructed using the LHMM are able to generate returns comparable to the S&P 500 index."],"url":"http://arxiv.org/abs/2406.02297v1","category":"stat.ME"}
{"created":"2024-06-04 13:17:24","title":"Learning-Rate-Free Stochastic Optimization over Riemannian Manifolds","abstract":"In recent years, interest in gradient-based optimization over Riemannian manifolds has surged. However, a significant challenge lies in the reliance on hyperparameters, especially the learning rate, which requires meticulous tuning by practitioners to ensure convergence at a suitable rate. In this work, we introduce innovative learning-rate-free algorithms for stochastic optimization over Riemannian manifolds, eliminating the need for hand-tuning and providing a more robust and user-friendly approach. We establish high probability convergence guarantees that are optimal, up to logarithmic factors, compared to the best-known optimally tuned rate in the deterministic setting. Our approach is validated through numerical experiments, demonstrating competitive performance against learning-rate-dependent algorithms.","sentences":["In recent years, interest in gradient-based optimization over Riemannian manifolds has surged.","However, a significant challenge lies in the reliance on hyperparameters, especially the learning rate, which requires meticulous tuning by practitioners to ensure convergence at a suitable rate.","In this work, we introduce innovative learning-rate-free algorithms for stochastic optimization over Riemannian manifolds, eliminating the need for hand-tuning and providing a more robust and user-friendly approach.","We establish high probability convergence guarantees that are optimal, up to logarithmic factors, compared to the best-known optimally tuned rate in the deterministic setting.","Our approach is validated through numerical experiments, demonstrating competitive performance against learning-rate-dependent algorithms."],"url":"http://arxiv.org/abs/2406.02296v1","category":"cs.LG"}
{"created":"2024-06-04 13:16:34","title":"How to Explore with Belief: State Entropy Maximization in POMDPs","abstract":"Recent works have studied *state entropy maximization* in reinforcement learning, in which the agent's objective is to learn a policy inducing high entropy over states visitation (Hazan et al., 2019). They typically assume full observability of the state of the system, so that the entropy of the observations is maximized. In practice, the agent may only get *partial* observations, e.g., a robot perceiving the state of a physical space through proximity sensors and cameras. A significant mismatch between the entropy over observations and true states of the system can arise in those settings. In this paper, we address the problem of entropy maximization over the *true states* with a decision policy conditioned on partial observations *only*. The latter is a generalization of POMDPs, which is intractable in general. We develop a memory and computationally efficient *policy gradient* method to address a first-order relaxation of the objective defined on *belief* states, providing various formal characterizations of approximation gaps, the optimization landscape, and the *hallucination* problem. This paper aims to generalize state entropy maximization to more realistic domains that meet the challenges of applications.","sentences":["Recent works have studied *state entropy maximization* in reinforcement learning, in which the agent's objective is to learn a policy inducing high entropy over states visitation (Hazan et al., 2019).","They typically assume full observability of the state of the system, so that the entropy of the observations is maximized.","In practice, the agent may only get *partial* observations, e.g., a robot perceiving the state of a physical space through proximity sensors and cameras.","A significant mismatch between the entropy over observations and true states of the system can arise in those settings.","In this paper, we address the problem of entropy maximization over the *true states* with a decision policy conditioned on partial observations *only*.","The latter is a generalization of POMDPs, which is intractable in general.","We develop a memory and computationally efficient *policy gradient* method to address a first-order relaxation of the objective defined on *belief* states, providing various formal characterizations of approximation gaps, the optimization landscape, and the *hallucination* problem.","This paper aims to generalize state entropy maximization to more realistic domains that meet the challenges of applications."],"url":"http://arxiv.org/abs/2406.02295v1","category":"cs.LG"}
{"created":"2024-06-04 13:13:29","title":"Composite Quantile Regression With XGBoost Using the Novel Arctan Pinball Loss","abstract":"This paper explores the use of XGBoost for composite quantile regression. XGBoost is a highly popular model renowned for its flexibility, efficiency, and capability to deal with missing data. The optimization uses a second order approximation of the loss function, complicating the use of loss functions with a zero or vanishing second derivative. Quantile regression -- a popular approach to obtain conditional quantiles when point estimates alone are insufficient -- unfortunately uses such a loss function, the pinball loss. Existing workarounds are typically inefficient and can result in severe quantile crossings. In this paper, we present a smooth approximation of the pinball loss, the arctan pinball loss, that is tailored to the needs of XGBoost. Specifically, contrary to other smooth approximations, the arctan pinball loss has a relatively large second derivative, which makes it more suitable to use in the second order approximation. Using this loss function enables the simultaneous prediction of multiple quantiles, which is more efficient and results in far fewer quantile crossings.","sentences":["This paper explores the use of XGBoost for composite quantile regression.","XGBoost is a highly popular model renowned for its flexibility, efficiency, and capability to deal with missing data.","The optimization uses a second order approximation of the loss function, complicating the use of loss functions with a zero or vanishing second derivative.","Quantile regression -- a popular approach to obtain conditional quantiles when point estimates alone are insufficient -- unfortunately uses such a loss function, the pinball loss.","Existing workarounds are typically inefficient and can result in severe quantile crossings.","In this paper, we present a smooth approximation of the pinball loss, the arctan pinball loss, that is tailored to the needs of XGBoost.","Specifically, contrary to other smooth approximations, the arctan pinball loss has a relatively large second derivative, which makes it more suitable to use in the second order approximation.","Using this loss function enables the simultaneous prediction of multiple quantiles, which is more efficient and results in far fewer quantile crossings."],"url":"http://arxiv.org/abs/2406.02293v1","category":"stat.ML"}
{"created":"2024-06-04 13:01:44","title":"OFDM-Based Active STAR-RIS-Aided Integrated Sensing and Communication Systems","abstract":"Simultaneously transmitting and reflecting reconfigurable intelligent surface (STAR-RIS), which consists of numerous passive elements, has recently emerged in wireless communication systems as a promising technology providing 360$^\\circ$ coverage and better performance. In our research, we introduce an active STAR-RIS (ASTARS)-aided integrated sensing and communications (ISAC) system designed to optimize the radar signal-to-noise ratio (SNR), enhancing detection and signal transmission efficiency. The introduction of an ISAC system aims to improve both communication efficiency and sensing capabilities. Also, we employ orthogonal frequency division multiplexing (OFDM) to address the frequency-selective fading problem. Furthermore, we evaluate the radar sensing capabilities by examining the range and velocity, and assess the performance through the mean-squared error (MSE) of their estimations. Our simulation results demonstrate that ASTARS outperforms STAR-RIS in our system configurations, and that the proposed optimization approach further enhances the system performance. Additionally, we confirm that an increase in the subcarrier spacing can reduce the transmission bit error rate (BER) under high-velocity conditions.","sentences":["Simultaneously transmitting and reflecting reconfigurable intelligent surface (STAR-RIS), which consists of numerous passive elements, has recently emerged in wireless communication systems as a promising technology providing 360$^\\circ$ coverage and better performance.","In our research, we introduce an active STAR-RIS (ASTARS)-aided integrated sensing and communications (ISAC) system designed to optimize the radar signal-to-noise ratio (SNR), enhancing detection and signal transmission efficiency.","The introduction of an ISAC system aims to improve both communication efficiency and sensing capabilities.","Also, we employ orthogonal frequency division multiplexing (OFDM) to address the frequency-selective fading problem.","Furthermore, we evaluate the radar sensing capabilities by examining the range and velocity, and assess the performance through the mean-squared error (MSE) of their estimations.","Our simulation results demonstrate that ASTARS outperforms STAR-RIS in our system configurations, and that the proposed optimization approach further enhances the system performance.","Additionally, we confirm that an increase in the subcarrier spacing can reduce the transmission bit error rate (BER) under high-velocity conditions."],"url":"http://arxiv.org/abs/2406.02289v1","category":"eess.SP"}
{"created":"2024-06-04 13:00:22","title":"Optimised ProPainter for Video Diminished Reality Inpainting","abstract":"In this paper, part of the DREAMING Challenge - Diminished Reality for Emerging Applications in Medicine through Inpainting, we introduce a refined video inpainting technique optimised from the ProPainter method to meet the specialised demands of medical imaging, specifically in the context of oral and maxillofacial surgery. Our enhanced algorithm employs the zero-shot ProPainter, featuring optimized parameters and pre-processing, to adeptly manage the complex task of inpainting surgical video sequences, without requiring any training process. It aims to produce temporally coherent and detail-rich reconstructions of occluded regions, facilitating clearer views of operative fields. The efficacy of our approach is evaluated using comprehensive metrics, positioning it as a significant advancement in the application of diminished reality for medical purposes.","sentences":["In this paper, part of the DREAMING Challenge - Diminished Reality for Emerging Applications in Medicine through Inpainting, we introduce a refined video inpainting technique optimised from the ProPainter method to meet the specialised demands of medical imaging, specifically in the context of oral and maxillofacial surgery.","Our enhanced algorithm employs the zero-shot ProPainter, featuring optimized parameters and pre-processing, to adeptly manage the complex task of inpainting surgical video sequences, without requiring any training process.","It aims to produce temporally coherent and detail-rich reconstructions of occluded regions, facilitating clearer views of operative fields.","The efficacy of our approach is evaluated using comprehensive metrics, positioning it as a significant advancement in the application of diminished reality for medical purposes."],"url":"http://arxiv.org/abs/2406.02287v1","category":"cs.CV"}
{"created":"2024-06-04 12:56:10","title":"Test-Time Regret Minimization in Meta Reinforcement Learning","abstract":"Meta reinforcement learning sets a distribution over a set of tasks on which the agent can train at will, then is asked to learn an optimal policy for any test task efficiently. In this paper, we consider a finite set of tasks modeled through Markov decision processes with various dynamics. We assume to have endured a long training phase, from which the set of tasks is perfectly recovered, and we focus on regret minimization against the optimal policy in the unknown test task. Under a separation condition that states the existence of a state-action pair revealing a task against another, Chen et al. (2022) show that $O(M^2 \\log(H))$ regret can be achieved, where $M, H$ are the number of tasks in the set and test episodes, respectively. In our first contribution, we demonstrate that the latter rate is nearly optimal by developing a novel lower bound for test-time regret minimization under separation, showing that a linear dependence with $M$ is unavoidable. Then, we present a family of stronger yet reasonable assumptions beyond separation, which we call strong identifiability, enabling algorithms achieving fast rates $\\log (H)$ and sublinear dependence with $M$ simultaneously. Our paper provides a new understanding of the statistical barriers of test-time regret minimization and when fast rates can be achieved.","sentences":["Meta reinforcement learning sets a distribution over a set of tasks on which the agent can train at will, then is asked to learn an optimal policy for any test task efficiently.","In this paper, we consider a finite set of tasks modeled through Markov decision processes with various dynamics.","We assume to have endured a long training phase, from which the set of tasks is perfectly recovered, and we focus on regret minimization against the optimal policy in the unknown test task.","Under a separation condition that states the existence of a state-action pair revealing a task against another, Chen et al. (2022) show that $O(M^2 \\log(H))$ regret can be achieved, where $M, H$ are the number of tasks in the set and test episodes, respectively.","In our first contribution, we demonstrate that the latter rate is nearly optimal by developing a novel lower bound for test-time regret minimization under separation, showing that a linear dependence with $M$ is unavoidable.","Then, we present a family of stronger yet reasonable assumptions beyond separation, which we call strong identifiability, enabling algorithms achieving fast rates $\\log (H)$ and sublinear dependence with $M$ simultaneously.","Our paper provides a new understanding of the statistical barriers of test-time regret minimization and when fast rates can be achieved."],"url":"http://arxiv.org/abs/2406.02282v1","category":"cs.LG"}
{"created":"2024-06-04 12:49:46","title":"A KL-based Analysis Framework with Applications to Non-Descent Optimization Methods","abstract":"We propose a novel analysis framework for non-descent-type optimization methodologies in nonconvex scenarios based on the Kurdyka-Lojasiewicz property. Our framework allows covering a broad class of algorithms, including those commonly employed in stochastic and distributed optimization. Specifically, it enables the analysis of first-order methods that lack a sufficient descent property and do not require access to full (deterministic) gradient information. We leverage this framework to establish, for the first time, iterate convergence and the corresponding rates for the decentralized gradient method and federated averaging under mild assumptions. Furthermore, based on the new analysis techniques, we show the convergence of the random reshuffling and stochastic gradient descent method without necessitating typical a priori bounded iterates assumptions.","sentences":["We propose a novel analysis framework for non-descent-type optimization methodologies in nonconvex scenarios based on the Kurdyka-Lojasiewicz property.","Our framework allows covering a broad class of algorithms, including those commonly employed in stochastic and distributed optimization.","Specifically, it enables the analysis of first-order methods that lack a sufficient descent property and do not require access to full (deterministic) gradient information.","We leverage this framework to establish, for the first time, iterate convergence and the corresponding rates for the decentralized gradient method and federated averaging under mild assumptions.","Furthermore, based on the new analysis techniques, we show the convergence of the random reshuffling and stochastic gradient descent method without necessitating typical a priori bounded iterates assumptions."],"url":"http://arxiv.org/abs/2406.02273v1","category":"math.OC"}
{"created":"2024-06-04 12:47:39","title":"Steady-State Entanglement Generation via Casimir-Polder Interactions","abstract":"We investigate the generation of steady-state entanglement between two atoms resulting from the fluctuation-mediated Casimir-Polder (CP) interactions near a surface. Starting with an initially separable state of the atoms, we analyze the atom-atom entanglement dynamics for atoms placed at distances in the range of $\\sim25$~nm away from a planar medium, examining the effect of medium properties and geometrical configuration of the atomic dipoles. We show that perfectly conducting and superconducting surfaces yield an optimal steady-state concurrence value of approximately 0.5. Furthermore, although the generated entanglement decreases with medium losses for a metal surface, we identify an optimal distance from the metal surface that assists in the generation of entanglement by the surface. While fluctuation-mediated interactions are typically considered detrimental to the coherence of quantum systems at nanoscales, our results demonstrate a mechanism for leveraging such interactions for entanglement generation.","sentences":["We investigate the generation of steady-state entanglement between two atoms resulting from the fluctuation-mediated Casimir-Polder (CP) interactions near a surface.","Starting with an initially separable state of the atoms, we analyze the atom-atom entanglement dynamics for atoms placed at distances in the range of $\\sim25$~nm away from a planar medium, examining the effect of medium properties and geometrical configuration of the atomic dipoles.","We show that perfectly conducting and superconducting surfaces yield an optimal steady-state concurrence value of approximately 0.5.","Furthermore, although the generated entanglement decreases with medium losses for a metal surface, we identify an optimal distance from the metal surface that assists in the generation of entanglement by the surface.","While fluctuation-mediated interactions are typically considered detrimental to the coherence of quantum systems at nanoscales, our results demonstrate a mechanism for leveraging such interactions for entanglement generation."],"url":"http://arxiv.org/abs/2406.02270v1","category":"quant-ph"}
{"created":"2024-06-04 12:37:11","title":"Image contrast enhancement based on the Schr\u00f6dinger operator spectrum","abstract":"This study proposes a novel image contrast enhancement method based on image projection onto the squared eigenfunctions of the two dimensional Schr\\\"odinger operator. This projection depends on a design parameter \\texorpdfstring{\\(\\gamma\\)}{gamma} which is proposed to control the pixel intensity during image reconstruction. The performance of the proposed method is investigated through its application to color images. The selection of \\texorpdfstring{\\(\\gamma\\)}{gamma} values is performed using k-means, which helps preserve the image spatial adjacency information. Furthermore, multi-objective optimization using the Non dominated Sorting Genetic Algorithm II (NSAG2) algorithm is proposed to select the optimal values of \\texorpdfstring{\\(\\gamma\\)}{gamma} and the semi-classical parameter h from the 2DSCSA. The results demonstrate the effectiveness of the proposed method for enhancing image contrast while preserving the inherent characteristics of the original image, producing the desired enhancement with almost no artifacts.","sentences":["This study proposes a novel image contrast enhancement method based on image projection onto the squared eigenfunctions of the two dimensional Schr\\\"odinger operator.","This projection depends on a design parameter \\texorpdfstring{\\(\\gamma\\)}{gamma} which is proposed to control the pixel intensity during image reconstruction.","The performance of the proposed method is investigated through its application to color images.","The selection of \\texorpdfstring{\\(\\gamma\\)}{gamma} values is performed using k-means, which helps preserve the image spatial adjacency information.","Furthermore, multi-objective optimization using the Non dominated Sorting Genetic Algorithm II (NSAG2) algorithm is proposed to select the optimal values of \\texorpdfstring{\\(\\gamma\\)}{gamma} and the semi-classical parameter h from the 2DSCSA.","The results demonstrate the effectiveness of the proposed method for enhancing image contrast while preserving the inherent characteristics of the original image, producing the desired enhancement with almost no artifacts."],"url":"http://arxiv.org/abs/2406.02264v1","category":"cs.CV"}
{"created":"2024-06-04 12:33:02","title":"A DAFT Based Unified Waveform Design Framework for High-Mobility Communications","abstract":"With the increasing demand for multi-carrier communication in high-mobility scenarios, it is urgent to design new multi-carrier communication waveforms that can resist large delay-Doppler spreads. Various multi-carrier waveforms in the transform domain were proposed for the fast time-varying channels, including orthogonal time frequency space (OTFS), orthogonal chirp division multiplexing (OCDM), and affine frequency division multiplexing (AFDM). Among these, the AFDM is a strong candidate for its low implementation complexity and ability to achieve optimal diversity. This paper unifies the waveforms based on the discrete affine Fourier transform (DAFT) by using the chirp slope factor \"k\" in the time-frequency representation to construct a unified design framework for high-mobility communications. The design framework is employed to verify that the bit error rate performance of the DAFT-based waveform can be enhanced when the signal-to-noise ratio (SNR) is sufficiently high by adjusting the chirp slope factor \"k\".","sentences":["With the increasing demand for multi-carrier communication in high-mobility scenarios, it is urgent to design new multi-carrier communication waveforms that can resist large delay-Doppler spreads.","Various multi-carrier waveforms in the transform domain were proposed for the fast time-varying channels, including orthogonal time frequency space (OTFS), orthogonal chirp division multiplexing (OCDM), and affine frequency division multiplexing (AFDM).","Among these, the AFDM is a strong candidate for its low implementation complexity and ability to achieve optimal diversity.","This paper unifies the waveforms based on the discrete affine Fourier transform (DAFT) by using the chirp slope factor \"k\" in the time-frequency representation to construct a unified design framework for high-mobility communications.","The design framework is employed to verify that the bit error rate performance of the DAFT-based waveform can be enhanced when the signal-to-noise ratio (SNR) is sufficiently high by adjusting the chirp slope factor \"k\"."],"url":"http://arxiv.org/abs/2406.02262v1","category":"eess.SP"}
{"created":"2024-06-04 12:20:54","title":"System Design and Parameter Optimization for Remote Coverage from NOMA-based High-Altitude Platform Stations (HAPS)","abstract":"Stratospheric solar-powered high-altitude platform stations (HAPS) have recently gained immense popularity for their ubiquitous connectivity and resilient operation while providing/catalyzing advanced mobile wireless communication services. They have particularly emerged as promising alternatives for economic coverage of remote areas in the world. This makes them suitable candidates to meet the UN Sustainable Development Goals (SDG-2030) for global connectivity. HAPS can provide line-of-sight (LoS) communications to the ground users in its ultra-wide coverage area. We propose to divide these users into multiple user groups and serve each group with a high-density flexible narrow spot beam, generated by the phased array antennas mounted on HAPS, to achieve high data rates. We carry out the user association and power allocation in a downlink (DL) non-orthogonal multiple access (NOMA) scheme in each user group. To improve the system performance, a sum rate maximization problem is formulated by jointly designing user grouping, user association, beam optimization, and power allocation while guaranteeing the quality-of-service (QoS) for users with limited power budget. We further investigate the outage performance of the users with the proposed approach as compared to the traditional scheme. Our findings reveal the significance of the joint design of communication parameters for enhanced system performance, optimum energy utilization, and resource allocation.","sentences":["Stratospheric solar-powered high-altitude platform stations (HAPS) have recently gained immense popularity for their ubiquitous connectivity and resilient operation while providing/catalyzing advanced mobile wireless communication services.","They have particularly emerged as promising alternatives for economic coverage of remote areas in the world.","This makes them suitable candidates to meet the UN Sustainable Development Goals (SDG-2030) for global connectivity.","HAPS can provide line-of-sight (LoS) communications to the ground users in its ultra-wide coverage area.","We propose to divide these users into multiple user groups and serve each group with a high-density flexible narrow spot beam, generated by the phased array antennas mounted on HAPS, to achieve high data rates.","We carry out the user association and power allocation in a downlink (DL) non-orthogonal multiple access (NOMA) scheme in each user group.","To improve the system performance, a sum rate maximization problem is formulated by jointly designing user grouping, user association, beam optimization, and power allocation while guaranteeing the quality-of-service (QoS) for users with limited power budget.","We further investigate the outage performance of the users with the proposed approach as compared to the traditional scheme.","Our findings reveal the significance of the joint design of communication parameters for enhanced system performance, optimum energy utilization, and resource allocation."],"url":"http://arxiv.org/abs/2406.02254v1","category":"eess.SP"}
