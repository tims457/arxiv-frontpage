{"created":"2024-03-03 01:33:47","title":"Bandit Profit-maximization for Targeted Marketing","abstract":"We study a sequential profit-maximization problem, optimizing for both price and ancillary variables like marketing expenditures. Specifically, we aim to maximize profit over an arbitrary sequence of multiple demand curves, each dependent on a distinct ancillary variable, but sharing the same price. A prototypical example is targeted marketing, where a firm (seller) wishes to sell a product over multiple markets. The firm may invest different marketing expenditures for different markets to optimize customer acquisition, but must maintain the same price across all markets. Moreover, markets may have heterogeneous demand curves, each responding to prices and marketing expenditures differently. The firm's objective is to maximize its gross profit, the total revenue minus marketing costs.   Our results are near-optimal algorithms for this class of problems in an adversarial bandit setting, where demand curves are arbitrary non-adaptive sequences, and the firm observes only noisy evaluations of chosen points on the demand curves. We prove a regret upper bound of $\\widetilde{\\mathcal{O}}\\big(nT^{3/4}\\big)$ and a lower bound of $\\Omega\\big((nT)^{3/4}\\big)$ for monotonic demand curves, and a regret bound of $\\widetilde{\\Theta}\\big(nT^{2/3}\\big)$ for demands curves that are monotonic in price and concave in the ancillary variables.","sentences":["We study a sequential profit-maximization problem, optimizing for both price and ancillary variables like marketing expenditures.","Specifically, we aim to maximize profit over an arbitrary sequence of multiple demand curves, each dependent on a distinct ancillary variable, but sharing the same price.","A prototypical example is targeted marketing, where a firm (seller) wishes to sell a product over multiple markets.","The firm may invest different marketing expenditures for different markets to optimize customer acquisition, but must maintain the same price across all markets.","Moreover, markets may have heterogeneous demand curves, each responding to prices and marketing expenditures differently.","The firm's objective is to maximize its gross profit, the total revenue minus marketing costs.   ","Our results are near-optimal algorithms for this class of problems in an adversarial bandit setting, where demand curves are arbitrary non-adaptive sequences, and the firm observes only noisy evaluations of chosen points on the demand curves.","We prove a regret upper bound of $\\widetilde{\\mathcal{O}}\\big(nT^{3/4}\\big)$ and a lower bound of $\\Omega\\big((nT)^{3/4}\\big)$ for monotonic demand curves, and a regret bound of $\\widetilde{\\Theta}\\big(nT^{2/3}\\big)$ for demands curves that are monotonic in price and concave in the ancillary variables."],"url":"http://arxiv.org/abs/2403.01361v1","category":"cs.LG"}
{"created":"2024-03-03 01:29:49","title":"\"Digitwashing\": The Gap between Words and Deeds in Digital Transformation and Stock Price Crash Risk","abstract":"The contrast between companies' \"fleshy\" promises and the \"skeletal\" performance in digital transformation may lead to a higher risk of stock price crash. This paper selects a sample of Shanghai and Shenzhen A-share listed companies from 2010 to 2021, empirically analyses the specific impact of the gap between words and deeds in digital transformation (GDT) on the stock price crash risk, and explores the possible causes of GDT. We found that GDT significantly increases the stock price crash risk, and this finding is still valid after a series of robustness tests. In a further study, a deeper examination of the causes of GDT reveals that firms' perceptions of economic policy uncertainty significantly increase GDT, and the effect is more pronounced in the sample of loss-making firms. At the same time, the results of the heterogeneity test suggest that investors are more tolerant of state-owned enterprises when they are in the GDT situation. Taken together, we provide a concrete bridge between the two measures of digital transformation - digital text frequency and digital technology share - and offer new insights to enhance capital market stability.","sentences":["The contrast between companies' \"fleshy\" promises and the \"skeletal\" performance in digital transformation may lead to a higher risk of stock price crash.","This paper selects a sample of Shanghai and Shenzhen A-share listed companies from 2010 to 2021, empirically analyses the specific impact of the gap between words and deeds in digital transformation (GDT) on the stock price crash risk, and explores the possible causes of GDT.","We found that GDT significantly increases the stock price crash risk, and this finding is still valid after a series of robustness tests.","In a further study, a deeper examination of the causes of GDT reveals that firms' perceptions of economic policy uncertainty significantly increase GDT, and the effect is more pronounced in the sample of loss-making firms.","At the same time, the results of the heterogeneity test suggest that investors are more tolerant of state-owned enterprises when they are in the GDT situation.","Taken together, we provide a concrete bridge between the two measures of digital transformation - digital text frequency and digital technology share - and offer new insights to enhance capital market stability."],"url":"http://arxiv.org/abs/2403.01360v1","category":"q-fin.ST"}
{"created":"2024-03-03 01:26:12","title":"ModelWriter: Text & Model-Synchronized Document Engineering Platform","abstract":"The ModelWriter platform provides a generic framework for automated traceability analysis. In this paper, we demonstrate how this framework can be used to trace the consistency and completeness of technical documents that consist of a set of System Installation Design Principles used by Airbus to ensure the correctness of aircraft system installation. We show in particular, how the platform allows the integration of two types of reasoning: reasoning about the meaning of text using semantic parsing and description logic theorem proving; and reasoning about document structure using first-order relational logic and finite model finding for traceability analysis.","sentences":["The ModelWriter platform provides a generic framework for automated traceability analysis.","In this paper, we demonstrate how this framework can be used to trace the consistency and completeness of technical documents that consist of a set of System Installation Design Principles used by Airbus to ensure the correctness of aircraft system installation.","We show in particular, how the platform allows the integration of two types of reasoning: reasoning about the meaning of text using semantic parsing and description logic theorem proving; and reasoning about document structure using first-order relational logic and finite model finding for traceability analysis."],"url":"http://arxiv.org/abs/2403.01359v1","category":"cs.SE"}
{"created":"2024-03-03 01:11:50","title":"Inferring potential landscapes: A Schr\u00f6dinger bridge approach to Maximum Caliber","abstract":"Schr\\\"odinger bridges have emerged as an enabling framework for unveiling the stochastic dynamics of systems based on marginal observations at different points in time. The terminology \"bridge'' refers to a probability law that suitably interpolates such marginals. The theory plays a pivotal role in a variety of contemporary developments in machine learning, stochastic control, thermodynamics, and biology, to name a few, impacting disciplines such as single-cell genomics, meteorology, and robotics. In this work, we extend Schr\\\"odinger's paradigm of bridges to account for integral constraints along paths, in a way akin to Maximum Caliber - a Maximum Entropy principle applied in a dynamic context. The Maximum Caliber principle has proven useful to infer the dynamics of complex systems e.g., that model gene circuits and protein folding. We unify these two problems via a maximum likelihood formulation to reconcile stochastic dynamics with ensemble-path data. A variety of data types can be encompassed, ranging from distribution moments to average currents along paths. The framework enables inference of time-varying potential landscapes that drive the process. The resulting forces can be interpreted as the optimal control that drives the system in a way that abides by specified integral constraints. Analogous results are presented in a discrete-time, discrete-space setting and specialized to steady-state dynamics. We finish by illustrating the practical applicability of the framework through paradigmatic examples, such as that of bit erasure or protein folding. In doing so, we highlight the strengths of the proposed framework, namely, the generality of the theory, the ease of computation, and the ability to interpret results in terms of system dynamics. This is in contrast to Maximum-Caliber problems where the focus is typically on updating a probability law on paths.","sentences":["Schr\\\"odinger bridges have emerged as an enabling framework for unveiling the stochastic dynamics of systems based on marginal observations at different points in time.","The terminology \"bridge'' refers to a probability law that suitably interpolates such marginals.","The theory plays a pivotal role in a variety of contemporary developments in machine learning, stochastic control, thermodynamics, and biology, to name a few, impacting disciplines such as single-cell genomics, meteorology, and robotics.","In this work, we extend Schr\\\"odinger's paradigm of bridges to account for integral constraints along paths, in a way akin to Maximum Caliber - a Maximum Entropy principle applied in a dynamic context.","The Maximum Caliber principle has proven useful to infer the dynamics of complex systems e.g., that model gene circuits and protein folding.","We unify these two problems via a maximum likelihood formulation to reconcile stochastic dynamics with ensemble-path data.","A variety of data types can be encompassed, ranging from distribution moments to average currents along paths.","The framework enables inference of time-varying potential landscapes that drive the process.","The resulting forces can be interpreted as the optimal control that drives the system in a way that abides by specified integral constraints.","Analogous results are presented in a discrete-time, discrete-space setting and specialized to steady-state dynamics.","We finish by illustrating the practical applicability of the framework through paradigmatic examples, such as that of bit erasure or protein folding.","In doing so, we highlight the strengths of the proposed framework, namely, the generality of the theory, the ease of computation, and the ability to interpret results in terms of system dynamics.","This is in contrast to Maximum-Caliber problems where the focus is typically on updating a probability law on paths."],"url":"http://arxiv.org/abs/2403.01357v1","category":"cond-mat.stat-mech"}
{"created":"2024-03-03 00:17:13","title":"Spatially parallel decoding for multi-qubit lattice surgery","abstract":"Running quantum algorithms protected by quantum error correction requires a real time, classical decoder. To prevent the accumulation of a backlog, this decoder must process syndromes from the quantum device at a faster rate than they are generated. Most prior work on real time decoding has focused on an isolated logical qubit encoded in the surface code. However, for surface code, quantum programs of utility will require multi-qubit interactions performed via lattice surgery. A large merged patch can arise during lattice surgery -- possibly as large as the entire device. This puts a significant strain on a real time decoder, which must decode errors on this merged patch and maintain the level of fault-tolerance that it achieves on isolated logical qubits.   These requirements are relaxed by using spatially parallel decoding, which can be accomplished by dividing the physical qubits on the device into multiple overlapping groups and assigning a decoder module to each. We refer to this approach as spatially parallel windows. While previous work has explored similar ideas, none have addressed system-specific considerations pertinent to the task or the constraints from using hardware accelerators. In this work, we demonstrate how to configure spatially parallel windows, so that the scheme (1) is compatible with hardware accelerators, (2) supports general lattice surgery operations, (3) maintains the fidelity of the logical qubits, and (4) meets the throughput requirement for real time decoding. Furthermore, our results reveal the importance of optimally choosing the buffer width to achieve a balance between accuracy and throughput -- a decision that should be influenced by the device's physical noise.","sentences":["Running quantum algorithms protected by quantum error correction requires a real time, classical decoder.","To prevent the accumulation of a backlog, this decoder must process syndromes from the quantum device at a faster rate than they are generated.","Most prior work on real time decoding has focused on an isolated logical qubit encoded in the surface code.","However, for surface code, quantum programs of utility will require multi-qubit interactions performed via lattice surgery.","A large merged patch can arise during lattice surgery -- possibly as large as the entire device.","This puts a significant strain on a real time decoder, which must decode errors on this merged patch and maintain the level of fault-tolerance that it achieves on isolated logical qubits.   ","These requirements are relaxed by using spatially parallel decoding, which can be accomplished by dividing the physical qubits on the device into multiple overlapping groups and assigning a decoder module to each.","We refer to this approach as spatially parallel windows.","While previous work has explored similar ideas, none have addressed system-specific considerations pertinent to the task or the constraints from using hardware accelerators.","In this work, we demonstrate how to configure spatially parallel windows, so that the scheme (1) is compatible with hardware accelerators, (2) supports general lattice surgery operations, (3) maintains the fidelity of the logical qubits, and (4) meets the throughput requirement for real time decoding.","Furthermore, our results reveal the importance of optimally choosing the buffer width to achieve a balance between accuracy and throughput -- a decision that should be influenced by the device's physical noise."],"url":"http://arxiv.org/abs/2403.01353v1","category":"quant-ph"}
{"created":"2024-03-03 00:14:12","title":"Improving Uncertainty Sampling with Bell Curve Weight Function","abstract":"Typically, a supervised learning model is trained using passive learning by randomly selecting unlabelled instances to annotate. This approach is effective for learning a model, but can be costly in cases where acquiring labelled instances is expensive. For example, it can be time-consuming to manually identify spam mails (labelled instances) from thousands of emails (unlabelled instances) flooding an inbox during initial data collection. Generally, we answer the above scenario with uncertainty sampling, an active learning method that improves the efficiency of supervised learning by using fewer labelled instances than passive learning. Given an unlabelled data pool, uncertainty sampling queries the labels of instances where the predicted probabilities, p, fall into the uncertainty region, i.e., $p \\approx 0.5$. The newly acquired labels are then added to the existing labelled data pool to learn a new model. Nonetheless, the performance of uncertainty sampling is susceptible to the area of unpredictable responses (AUR) and the nature of the dataset. It is difficult to determine whether to use passive learning or uncertainty sampling without prior knowledge of a new dataset. To address this issue, we propose bell curve sampling, which employs a bell curve weight function to acquire new labels. With the bell curve centred at p=0.5, bell curve sampling selects instances whose predicted values are in the uncertainty area most of the time without neglecting the rest. Simulation results show that, most of the time bell curve sampling outperforms uncertainty sampling and passive learning in datasets of different natures and with AUR.","sentences":["Typically, a supervised learning model is trained using passive learning by randomly selecting unlabelled instances to annotate.","This approach is effective for learning a model, but can be costly in cases where acquiring labelled instances is expensive.","For example, it can be time-consuming to manually identify spam mails (labelled instances) from thousands of emails (unlabelled instances) flooding an inbox during initial data collection.","Generally, we answer the above scenario with uncertainty sampling, an active learning method that improves the efficiency of supervised learning by using fewer labelled instances than passive learning.","Given an unlabelled data pool, uncertainty sampling queries the labels of instances where the predicted probabilities, p, fall into the uncertainty region, i.e., $p \\approx 0.5$. The newly acquired labels are then added to the existing labelled data pool to learn a new model.","Nonetheless, the performance of uncertainty sampling is susceptible to the area of unpredictable responses (AUR) and the nature of the dataset.","It is difficult to determine whether to use passive learning or uncertainty sampling without prior knowledge of a new dataset.","To address this issue, we propose bell curve sampling, which employs a bell curve weight function to acquire new labels.","With the bell curve centred at p=0.5, bell curve sampling selects instances whose predicted values are in the uncertainty area most of the time without neglecting the rest.","Simulation results show that, most of the time bell curve sampling outperforms uncertainty sampling and passive learning in datasets of different natures and with AUR."],"url":"http://arxiv.org/abs/2403.01352v1","category":"cs.LG"}
{"created":"2024-03-03 00:13:26","title":"Efficient FIR filtering with Bit Layer Multiply Accumulator","abstract":"Bit Layer Multiplier Accumulator (BLMAC) is an efficient method to perform dot products without multiplications that exploits the bit level sparsity of the weights. A total of 1,980,000 low, high, band pass and band stop type I FIR filters were generated by systematically sweeping through the cut off frequencies and by varying the number of taps from 55 to 255. After their coefficients were quantized to 16 bits, applying the filter using a BLMAC required, on average, from ~123.3 to ~513.6 additions, depending on the number of taps. A BLMAC dot product machine, specialised for 127 taps FIR filters, was designed for AMD FPGAs. The design footprint is ~110 LUTs, including coefficient and sample storage and is able to apply the filter in ~232 clock cycles on average. This implies a filtering rate of 1.4-3.4 Msamples/s, depending on the FPGA family.","sentences":["Bit Layer Multiplier Accumulator (BLMAC) is an efficient method to perform dot products without multiplications that exploits the bit level sparsity of the weights.","A total of 1,980,000 low, high, band pass and band stop type I FIR filters were generated by systematically sweeping through the cut off frequencies and by varying the number of taps from 55 to 255.","After their coefficients were quantized to 16 bits, applying the filter using a BLMAC required, on average, from ~123.3 to ~513.6 additions, depending on the number of taps.","A BLMAC dot product machine, specialised for 127 taps FIR filters, was designed for AMD FPGAs.","The design footprint is ~110 LUTs, including coefficient and sample storage and is able to apply the filter in ~232 clock cycles on average.","This implies a filtering rate of 1.4-3.4 Msamples/s, depending on the FPGA family."],"url":"http://arxiv.org/abs/2403.01351v1","category":"cs.AR"}
{"created":"2024-03-03 00:01:29","title":"SANGRIA: Stacked Autoencoder Neural Networks with Gradient Boosting for Indoor Localization","abstract":"Indoor localization is a critical task in many embedded applications, such as asset tracking, emergency response, and realtime navigation. In this article, we propose a novel fingerprintingbased framework for indoor localization called SANGRIA that uses stacked autoencoder neural networks with gradient boosted trees. Our approach is designed to overcome the device heterogeneity challenge that can create uncertainty in wireless signal measurements across embedded devices used for localization. We compare SANGRIA to several state-of-the-art frameworks and demonstrate 42.96% lower average localization error across diverse indoor locales and heterogeneous devices.","sentences":["Indoor localization is a critical task in many embedded applications, such as asset tracking, emergency response, and realtime navigation.","In this article, we propose a novel fingerprintingbased framework for indoor localization called SANGRIA that uses stacked autoencoder neural networks with gradient boosted trees.","Our approach is designed to overcome the device heterogeneity challenge that can create uncertainty in wireless signal measurements across embedded devices used for localization.","We compare SANGRIA to several state-of-the-art frameworks and demonstrate 42.96% lower average localization error across diverse indoor locales and heterogeneous devices."],"url":"http://arxiv.org/abs/2403.01348v1","category":"cs.LG"}
{"created":"2024-03-02 23:40:23","title":"ShapeBoost: Boosting Human Shape Estimation with Part-Based Parameterization and Clothing-Preserving Augmentation","abstract":"Accurate human shape recovery from a monocular RGB image is a challenging task because humans come in different shapes and sizes and wear different clothes. In this paper, we propose ShapeBoost, a new human shape recovery framework that achieves pixel-level alignment even for rare body shapes and high accuracy for people wearing different types of clothes. Unlike previous approaches that rely on the use of PCA-based shape coefficients, we adopt a new human shape parameterization that decomposes the human shape into bone lengths and the mean width of each part slice. This part-based parameterization technique achieves a balance between flexibility and validity using a semi-analytical shape reconstruction algorithm. Based on this new parameterization, a clothing-preserving data augmentation module is proposed to generate realistic images with diverse body shapes and accurate annotations. Experimental results show that our method outperforms other state-of-the-art methods in diverse body shape situations as well as in varied clothing situations.","sentences":["Accurate human shape recovery from a monocular RGB image is a challenging task because humans come in different shapes and sizes and wear different clothes.","In this paper, we propose ShapeBoost, a new human shape recovery framework that achieves pixel-level alignment even for rare body shapes and high accuracy for people wearing different types of clothes.","Unlike previous approaches that rely on the use of PCA-based shape coefficients, we adopt a new human shape parameterization that decomposes the human shape into bone lengths and the mean width of each part slice.","This part-based parameterization technique achieves a balance between flexibility and validity using a semi-analytical shape reconstruction algorithm.","Based on this new parameterization, a clothing-preserving data augmentation module is proposed to generate realistic images with diverse body shapes and accurate annotations.","Experimental results show that our method outperforms other state-of-the-art methods in diverse body shape situations as well as in varied clothing situations."],"url":"http://arxiv.org/abs/2403.01345v1","category":"cs.CV"}
{"created":"2024-03-02 23:29:04","title":"Scaling limit of the colored ASEP and stochastic six-vertex models","abstract":"We consider the colored asymmetric simple exclusion process (ASEP) and stochastic six vertex (S6V) model with fully packed initial conditions; the states of these models can be encoded by 2-parameter height functions. We show under Kardar-Parisi-Zhang (KPZ) scaling of time, space, and fluctuations that these height functions converge to the Airy sheet.   Several corollaries follow. For ASEP and the S6V model under the basic coupling, we consider the 4-parameter height function at position $y$ and time $t$, with a step initial condition at position $x$ and time $s<t$. Under KPZ scaling, we deduce its convergence to the directed landscape. We further prove that ASEPs under the basic coupling, with multiple general initial data, converge to KPZ fixed points coupled through the directed landscape. We moreover show that the colored ASEP stationary measures converge to the stationary horizon.   The starting point for our Airy sheet convergence result is an embedding of these colored models into a larger structure -- a color-indexed family of coupled line ensembles with an explicit Gibbs property, i.e., a colored Hall-Littlewood line ensemble. The core of our work then becomes to develop a framework to analyze the edge scaling limit of these ensembles.","sentences":["We consider the colored asymmetric simple exclusion process (ASEP) and stochastic six vertex (S6V) model with fully packed initial conditions; the states of these models can be encoded by 2-parameter height functions.","We show under Kardar-Parisi-Zhang (KPZ) scaling of time, space, and fluctuations that these height functions converge to the Airy sheet.   ","Several corollaries follow.","For ASEP and the S6V model under the basic coupling, we consider the 4-parameter height function at position $y$ and time $t$, with a step initial condition at position $x$ and time $s<t$. Under KPZ scaling, we deduce its convergence to the directed landscape.","We further prove that ASEPs under the basic coupling, with multiple general initial data, converge to KPZ fixed points coupled through the directed landscape.","We moreover show that the colored ASEP stationary measures converge to the stationary horizon.   ","The starting point for our Airy sheet convergence result is an embedding of these colored models into a larger structure -- a color-indexed family of coupled line ensembles with an explicit Gibbs property, i.e., a colored Hall-Littlewood line ensemble.","The core of our work then becomes to develop a framework to analyze the edge scaling limit of these ensembles."],"url":"http://arxiv.org/abs/2403.01341v1","category":"math.PR"}
{"created":"2024-03-02 23:16:52","title":"Normalized solutions of quasilinear Schr\u00f6dinger equations with a general nonlinearity","abstract":"We are concerned with solutions of the following quasilinear Schr\\\"odinger equations \\begin{eqnarray*} -{\\mathrm{div}}\\left(\\varphi^{2}(u) \\nabla u\\right)+\\varphi(u) \\varphi^{\\prime}(u)|\\nabla u|^{2}+\\lambda u=f(u), \\quad x \\in \\mathbb{R}^{N} \\end{eqnarray*} with prescribed mass $$ \\int_{\\mathbb{R}^{N}} u^{2} \\mathrm{d}x=c, $$ where $N\\ge 3, c>0$, $\\lambda \\in \\mathbb{R}$ appears as the Lagrange multiplier and $\\varphi\\in C ^{1}(\\mathbb{R} ,\\mathbb{R}^{+})$. The nonlinearity $f \\in C\\left ( \\mathbb{R}, \\, \\mathbb{R} \\right )$ is allowed to be mass-subcritical, mass-critical and mass-supercritical at origin and infinity. Via a dual approach, the fixed point index and a global branch approach, we establish the existence of normalized solutions to the problem above. The results extend previous results by L. Jeanjean, J. J. Zhang and X.X. Zhong to the quasilinear case.","sentences":["We are concerned with solutions of the following quasilinear Schr\\\"odinger equations \\begin{eqnarray*} -{\\mathrm{div}}\\left(\\varphi^{2}(u) \\nabla u\\right)+\\varphi(u) \\varphi^{\\prime}(u)|\\nabla","u|^{2}+\\lambda u=f(u), \\quad x \\in \\mathbb{R}^{N} \\end{eqnarray*} with prescribed mass $$ \\int_{\\mathbb{R}^{N}} u^{2} \\mathrm{d}x=c, $$ where $N\\ge 3, c>0$, $\\lambda \\in \\mathbb{R}$ appears as the Lagrange multiplier and $\\varphi\\in C ^{1}(\\mathbb{R} ,\\mathbb{R}^{+})$. The nonlinearity $f \\in C\\left ( \\mathbb{R}, \\, \\mathbb{R} \\right )$ is allowed to be mass-subcritical, mass-critical and mass-supercritical at origin and infinity.","Via a dual approach, the fixed point index and a global branch approach, we establish the existence of normalized solutions to the problem above.","The results extend previous results by L. Jeanjean, J. J. Zhang and X.X. Zhong to the quasilinear case."],"url":"http://arxiv.org/abs/2403.01338v1","category":"math.AP"}
{"created":"2024-03-02 22:39:55","title":"Implementation of Linear Parameter Varying System to Investigate the Impact of Varying Flow Rate on the Lithium-ion Batteries Thermal Management System Performance","abstract":"Battery thermal management system is an indispensable part of the electric vehicles working with Lithium-ion batteries. Accordingly, lithium-ion batteries modeling, battery heat generation, and thermal management are the main focus of researchers and car manufacturers. To fulfill the need of manufacturers in the design process, a faster model than time-consuming Computational Fluid Dynamics models (CFD) is required. Reduced Order Models (ROM) address this requirement to maintain the accuracy of CFD models while could be compiled faster. Linear Time Invariant (LTI) reduced order model has been used in the literature; however, due to the limitation of LTI system, considering the constant flow rate for the cooling fluid, a Linear Parameter Varying system with three scheduling parameters was developed in this study. It is shown that LPV system results could fit accurately to CFD results in conditions that LTI system cannot maintain accuracy. Moreover, it is shown that applying varying water flow rates could result in a smoother temperature profile.","sentences":["Battery thermal management system is an indispensable part of the electric vehicles working with Lithium-ion batteries.","Accordingly, lithium-ion batteries modeling, battery heat generation, and thermal management are the main focus of researchers and car manufacturers.","To fulfill the need of manufacturers in the design process, a faster model than time-consuming Computational Fluid Dynamics models (CFD) is required.","Reduced Order Models (ROM) address this requirement to maintain the accuracy of CFD models while could be compiled faster.","Linear Time Invariant (LTI) reduced order model has been used in the literature; however, due to the limitation of LTI system, considering the constant flow rate for the cooling fluid, a Linear Parameter Varying system with three scheduling parameters was developed in this study.","It is shown that LPV system results could fit accurately to CFD results in conditions that LTI system cannot maintain accuracy.","Moreover, it is shown that applying varying water flow rates could result in a smoother temperature profile."],"url":"http://arxiv.org/abs/2403.01334v1","category":"eess.SY"}
{"created":"2024-03-02 22:38:01","title":"Chaining thoughts and LLMs to learn DNA structural biophysics","abstract":"The future development of an AI scientist, a tool that is capable of integrating a variety of experimental data and generating testable hypotheses, holds immense potential. So far, bespoke machine learning models have been created to specialize in singular scientific tasks, but otherwise lack the flexibility of a general purpose model. Here, we show that a general purpose large language model, chatGPT 3.5-turbo, can be fine-tuned to learn the structural biophysics of DNA. We find that both fine-tuning models to return chain-of-thought responses and chaining together models fine-tuned for subtasks have an enhanced ability to analyze and design DNA sequences and their structures.","sentences":["The future development of an AI scientist, a tool that is capable of integrating a variety of experimental data and generating testable hypotheses, holds immense potential.","So far, bespoke machine learning models have been created to specialize in singular scientific tasks, but otherwise lack the flexibility of a general purpose model.","Here, we show that a general purpose large language model, chatGPT 3.5-turbo, can be fine-tuned to learn the structural biophysics of DNA.","We find that both fine-tuning models to return chain-of-thought responses and chaining together models fine-tuned for subtasks have an enhanced ability to analyze and design DNA sequences and their structures."],"url":"http://arxiv.org/abs/2403.01332v1","category":"q-bio.QM"}
{"created":"2024-03-02 22:27:44","title":"Bespoke Non-Stationary Solvers for Fast Sampling of Diffusion and Flow Models","abstract":"This paper introduces Bespoke Non-Stationary (BNS) Solvers, a solver distillation approach to improve sample efficiency of Diffusion and Flow models. BNS solvers are based on a family of non-stationary solvers that provably subsumes existing numerical ODE solvers and consequently demonstrate considerable improvement in sample approximation (PSNR) over these baselines. Compared to model distillation, BNS solvers benefit from a tiny parameter space ($<$200 parameters), fast optimization (two orders of magnitude faster), maintain diversity of samples, and in contrast to previous solver distillation approaches nearly close the gap from standard distillation methods such as Progressive Distillation in the low-medium NFE regime. For example, BNS solver achieves 45 PSNR / 1.76 FID using 16 NFE in class-conditional ImageNet-64. We experimented with BNS solvers for conditional image generation, text-to-image generation, and text-2-audio generation showing significant improvement in sample approximation (PSNR) in all.","sentences":["This paper introduces Bespoke Non-Stationary (BNS) Solvers, a solver distillation approach to improve sample efficiency of Diffusion and Flow models.","BNS solvers are based on a family of non-stationary solvers that provably subsumes existing numerical ODE solvers and consequently demonstrate considerable improvement in sample approximation (PSNR) over these baselines.","Compared to model distillation, BNS solvers benefit from a tiny parameter space ($<$200 parameters), fast optimization (two orders of magnitude faster), maintain diversity of samples, and in contrast to previous solver distillation approaches nearly close the gap from standard distillation methods such as Progressive Distillation in the low-medium NFE regime.","For example, BNS solver achieves 45 PSNR / 1.76 FID using 16 NFE in class-conditional ImageNet-64.","We experimented with BNS solvers for conditional image generation, text-to-image generation, and text-2-audio generation showing significant improvement in sample approximation (PSNR) in all."],"url":"http://arxiv.org/abs/2403.01329v1","category":"cs.LG"}
{"created":"2024-03-02 22:16:47","title":"DNA Family: Boosting Weight-Sharing NAS with Block-Wise Supervisions","abstract":"Neural Architecture Search (NAS), aiming at automatically designing neural architectures by machines, has been considered a key step toward automatic machine learning. One notable NAS branch is the weight-sharing NAS, which significantly improves search efficiency and allows NAS algorithms to run on ordinary computers. Despite receiving high expectations, this category of methods suffers from low search effectiveness. By employing a generalization boundedness tool, we demonstrate that the devil behind this drawback is the untrustworthy architecture rating with the oversized search space of the possible architectures. Addressing this problem, we modularize a large search space into blocks with small search spaces and develop a family of models with the distilling neural architecture (DNA) techniques. These proposed models, namely a DNA family, are capable of resolving multiple dilemmas of the weight-sharing NAS, such as scalability, efficiency, and multi-modal compatibility. Our proposed DNA models can rate all architecture candidates, as opposed to previous works that can only access a sub- search space using heuristic algorithms. Moreover, under a certain computational complexity constraint, our method can seek architectures with different depths and widths. Extensive experimental evaluations show that our models achieve state-of-the-art top-1 accuracy of 78.9% and 83.6% on ImageNet for a mobile convolutional network and a small vision transformer, respectively. Additionally, we provide in-depth empirical analysis and insights into neural architecture ratings. Codes available: \\url{https://github.com/changlin31/DNA}.","sentences":["Neural Architecture Search (NAS), aiming at automatically designing neural architectures by machines, has been considered a key step toward automatic machine learning.","One notable NAS branch is the weight-sharing NAS, which significantly improves search efficiency and allows NAS algorithms to run on ordinary computers.","Despite receiving high expectations, this category of methods suffers from low search effectiveness.","By employing a generalization boundedness tool, we demonstrate that the devil behind this drawback is the untrustworthy architecture rating with the oversized search space of the possible architectures.","Addressing this problem, we modularize a large search space into blocks with small search spaces and develop a family of models with the distilling neural architecture (DNA) techniques.","These proposed models, namely a DNA family, are capable of resolving multiple dilemmas of the weight-sharing NAS, such as scalability, efficiency, and multi-modal compatibility.","Our proposed DNA models can rate all architecture candidates, as opposed to previous works that can only access a sub- search space using heuristic algorithms.","Moreover, under a certain computational complexity constraint, our method can seek architectures with different depths and widths.","Extensive experimental evaluations show that our models achieve state-of-the-art top-1 accuracy of 78.9% and 83.6% on ImageNet for a mobile convolutional network and a small vision transformer, respectively.","Additionally, we provide in-depth empirical analysis and insights into neural architecture ratings.","Codes available: \\url{https://github.com/changlin31/DNA}."],"url":"http://arxiv.org/abs/2403.01326v1","category":"cs.CV"}
{"created":"2024-03-02 22:08:10","title":"NeRF-VPT: Learning Novel View Representations with Neural Radiance Fields via View Prompt Tuning","abstract":"Neural Radiance Fields (NeRF) have garnered remarkable success in novel view synthesis. Nonetheless, the task of generating high-quality images for novel views persists as a critical challenge. While the existing efforts have exhibited commendable progress, capturing intricate details, enhancing textures, and achieving superior Peak Signal-to-Noise Ratio (PSNR) metrics warrant further focused attention and advancement. In this work, we propose NeRF-VPT, an innovative method for novel view synthesis to address these challenges. Our proposed NeRF-VPT employs a cascading view prompt tuning paradigm, wherein RGB information gained from preceding rendering outcomes serves as instructive visual prompts for subsequent rendering stages, with the aspiration that the prior knowledge embedded in the prompts can facilitate the gradual enhancement of rendered image quality. NeRF-VPT only requires sampling RGB data from previous stage renderings as priors at each training stage, without relying on extra guidance or complex techniques. Thus, our NeRF-VPT is plug-and-play and can be readily integrated into existing methods. By conducting comparative analyses of our NeRF-VPT against several NeRF-based approaches on demanding real-scene benchmarks, such as Realistic Synthetic 360, Real Forward-Facing, Replica dataset, and a user-captured dataset, we substantiate that our NeRF-VPT significantly elevates baseline performance and proficiently generates more high-quality novel view images than all the compared state-of-the-art methods. Furthermore, the cascading learning of NeRF-VPT introduces adaptability to scenarios with sparse inputs, resulting in a significant enhancement of accuracy for sparse-view novel view synthesis. The source code and dataset are available at \\url{https://github.com/Freedomcls/NeRF-VPT}.","sentences":["Neural Radiance Fields (NeRF) have garnered remarkable success in novel view synthesis.","Nonetheless, the task of generating high-quality images for novel views persists as a critical challenge.","While the existing efforts have exhibited commendable progress, capturing intricate details, enhancing textures, and achieving superior Peak Signal-to-Noise Ratio (PSNR) metrics warrant further focused attention and advancement.","In this work, we propose NeRF-VPT, an innovative method for novel view synthesis to address these challenges.","Our proposed NeRF-VPT employs a cascading view prompt tuning paradigm, wherein RGB information gained from preceding rendering outcomes serves as instructive visual prompts for subsequent rendering stages, with the aspiration that the prior knowledge embedded in the prompts can facilitate the gradual enhancement of rendered image quality.","NeRF-VPT only requires sampling RGB data from previous stage renderings as priors at each training stage, without relying on extra guidance or complex techniques.","Thus, our NeRF-VPT is plug-and-play and can be readily integrated into existing methods.","By conducting comparative analyses of our NeRF-VPT against several NeRF-based approaches on demanding real-scene benchmarks, such as Realistic Synthetic 360, Real Forward-Facing, Replica dataset, and a user-captured dataset, we substantiate that our NeRF-VPT significantly elevates baseline performance and proficiently generates more high-quality novel view images than all the compared state-of-the-art methods.","Furthermore, the cascading learning of NeRF-VPT introduces adaptability to scenarios with sparse inputs, resulting in a significant enhancement of accuracy for sparse-view novel view synthesis.","The source code and dataset are available at \\url{https://github.com/Freedomcls/NeRF-VPT}."],"url":"http://arxiv.org/abs/2403.01325v1","category":"cs.CV"}
{"created":"2024-03-02 22:01:14","title":"A non-cubic space-filling modular robot","abstract":"Space-filling building blocks of diverse shape permeate nature at all levels of organization, from atoms to honeycombs, and have proven useful in artificial systems, from molecular containers to clay bricks. But, despite the wide variety of space-filling polyhedra known to mathematics, only the cube has been explored in robotics. Thus, here we roboticize a non-cubic space-filling shape: the rhombic dodecahedron. This geometry offers an appealing alternative to cubes as it greatly simplifies rotational motion of one cell about the edge of another, and increases the number of neighbors each cell can communicate with and hold on to. To better understand the challenges and opportunities of these and other space-filling machines, we manufactured 48 rhombic dodecahedral cells and used them to build various superstructures. We report locomotive ability of some of the structures we built, and discuss the dis/advantages of the different designs we tested. We also introduce a strategy for genderless passive docking of cells that generalizes to any polyhedra with radially symmetrical faces. Future work will allow the cells to freely roll/rotate about one another so that they may realize the full potential of their unique shape.","sentences":["Space-filling building blocks of diverse shape permeate nature at all levels of organization, from atoms to honeycombs, and have proven useful in artificial systems, from molecular containers to clay bricks.","But, despite the wide variety of space-filling polyhedra known to mathematics, only the cube has been explored in robotics.","Thus, here we roboticize a non-cubic space-filling shape: the rhombic dodecahedron.","This geometry offers an appealing alternative to cubes as it greatly simplifies rotational motion of one cell about the edge of another, and increases the number of neighbors each cell can communicate with and hold on to.","To better understand the challenges and opportunities of these and other space-filling machines, we manufactured 48 rhombic dodecahedral cells and used them to build various superstructures.","We report locomotive ability of some of the structures we built, and discuss the dis/advantages of the different designs we tested.","We also introduce a strategy for genderless passive docking of cells that generalizes to any polyhedra with radially symmetrical faces.","Future work will allow the cells to freely roll/rotate about one another so that they may realize the full potential of their unique shape."],"url":"http://arxiv.org/abs/2403.01323v1","category":"cs.RO"}
{"created":"2024-03-02 21:54:36","title":"A Communication-Efficient Stochastic Gradient Descent Algorithm for Distributed Nonconvex Optimization","abstract":"This paper studies distributed nonconvex optimization problems with stochastic gradients for a multi-agent system, in which each agent aims to minimize the sum of all agents' cost functions by using local compressed information exchange. We propose a distributed stochastic gradient descent (SGD) algorithm, suitable for a general class of compressors. We show that the proposed algorithm achieves the linear speedup convergence rate $\\mathcal{O}(1/\\sqrt{nT})$ for smooth nonconvex functions, where $T$ and $n$ are the number of iterations and agents, respectively. If the global cost function additionally satisfies the Polyak--{\\L}ojasiewicz condition, the proposed algorithm can linearly converge to a neighborhood of the global optimum, regardless of whether the stochastic gradient is unbiased or not. Numerical experiments are carried out to verify the efficiency of our algorithm.","sentences":["This paper studies distributed nonconvex optimization problems with stochastic gradients for a multi-agent system, in which each agent aims to minimize the sum of all agents' cost functions by using local compressed information exchange.","We propose a distributed stochastic gradient descent (SGD) algorithm, suitable for a general class of compressors.","We show that the proposed algorithm achieves the linear speedup convergence rate $\\mathcal{O}(1/\\sqrt{nT})$ for smooth nonconvex functions, where $T$ and $n$ are the number of iterations and agents, respectively.","If the global cost function additionally satisfies the Polyak--{\\L}ojasiewicz condition, the proposed algorithm can linearly converge to a neighborhood of the global optimum, regardless of whether the stochastic gradient is unbiased or not.","Numerical experiments are carried out to verify the efficiency of our algorithm."],"url":"http://arxiv.org/abs/2403.01322v1","category":"math.OC"}
{"created":"2024-03-02 21:52:44","title":"Influence of Spatial Coherence on Phonon Transmission across Aperiodically Arranged Interfaces","abstract":"In this study, we employ the atomistic wave-packet method to directly simulate coherent phonon transport and scattering dynamics in an aperiodic superlattice structure with aperiodically arranged interfaces. Our investigation reveals that interference dynamics, contingent upon the relative magnitudes of phonon wavelength, spatial coherence length, and average interface spacing, profoundly influence transmission spectra and mode-conversion behavior. Particularly, longer-wavelength phonons possessing larger coherence lengths exhibit more pronounced destructive interference and mode-conversion, leading to generally lower transmission. The insights gained into coherent phonon wave physics from this study can significantly augment the analysis and design of phononic devices.","sentences":["In this study, we employ the atomistic wave-packet method to directly simulate coherent phonon transport and scattering dynamics in an aperiodic superlattice structure with aperiodically arranged interfaces.","Our investigation reveals that interference dynamics, contingent upon the relative magnitudes of phonon wavelength, spatial coherence length, and average interface spacing, profoundly influence transmission spectra and mode-conversion behavior.","Particularly, longer-wavelength phonons possessing larger coherence lengths exhibit more pronounced destructive interference and mode-conversion, leading to generally lower transmission.","The insights gained into coherent phonon wave physics from this study can significantly augment the analysis and design of phononic devices."],"url":"http://arxiv.org/abs/2403.01321v1","category":"cond-mat.mtrl-sci"}
{"created":"2024-03-02 21:42:02","title":"Disconnectivity graphs for visualizing combinatorial optimization problems: challenges of embedding to Ising machines","abstract":"Physics-based Ising machines (IM) have risen to the challenge of solving hard combinatorial optimization problems with higher speed and better energy efficiency. Generally, such dedicated systems employ local search heuristics to traverse energy landscapes in searching for optimal solutions. Extending landscape geometry visualization tools, disconnectivity graphs, we quantify and address some of the major challenges met by IMs in the field of combinatorial optimization. Using efficient sampling methods, we visually capture landscapes of problems having diverse structure and hardness and featuring strong degeneracies, which act as entropic barriers for IMs. Furthermore, we investigate energy barriers, local minima, and configuration space clustering effects caused by locality reduction methods when embedding combinatorial problems to the Ising hardware. For this purpose, we sample disconnectivity graphs of PUBO energy landscapes and their different QUBO mappings accounting for both local minima and saddle regions. We demonstrate that QUBO energy landscape properties lead to the subpar performance of quadratic IMs and suggest directions for their improvement.","sentences":["Physics-based Ising machines (IM) have risen to the challenge of solving hard combinatorial optimization problems with higher speed and better energy efficiency.","Generally, such dedicated systems employ local search heuristics to traverse energy landscapes in searching for optimal solutions.","Extending landscape geometry visualization tools, disconnectivity graphs, we quantify and address some of the major challenges met by IMs in the field of combinatorial optimization.","Using efficient sampling methods, we visually capture landscapes of problems having diverse structure and hardness and featuring strong degeneracies, which act as entropic barriers for IMs.","Furthermore, we investigate energy barriers, local minima, and configuration space clustering effects caused by locality reduction methods when embedding combinatorial problems to the Ising hardware.","For this purpose, we sample disconnectivity graphs of PUBO energy landscapes and their different QUBO mappings accounting for both local minima and saddle regions.","We demonstrate that QUBO energy landscape properties lead to the subpar performance of quadratic IMs and suggest directions for their improvement."],"url":"http://arxiv.org/abs/2403.01320v1","category":"cond-mat.dis-nn"}
{"created":"2024-03-02 21:22:46","title":"Near-optimal Per-Action Regret Bounds for Sleeping Bandits","abstract":"We derive near-optimal per-action regret bounds for sleeping bandits, in which both the sets of available arms and their losses in every round are chosen by an adversary. In a setting with $K$ total arms and at most $A$ available arms in each round over $T$ rounds, the best known upper bound is $O(K\\sqrt{TA\\ln{K}})$, obtained indirectly via minimizing internal sleeping regrets. Compared to the minimax $\\Omega(\\sqrt{TA})$ lower bound, this upper bound contains an extra multiplicative factor of $K\\ln{K}$. We address this gap by directly minimizing the per-action regret using generalized versions of EXP3, EXP3-IX and FTRL with Tsallis entropy, thereby obtaining near-optimal bounds of order $O(\\sqrt{TA\\ln{K}})$ and $O(\\sqrt{T\\sqrt{AK}})$. We extend our results to the setting of bandits with advice from sleeping experts, generalizing EXP4 along the way. This leads to new proofs for a number of existing adaptive and tracking regret bounds for standard non-sleeping bandits. Extending our results to the bandit version of experts that report their confidences leads to new bounds for the confidence regret that depends primarily on the sum of experts' confidences. We prove a lower bound, showing that for any minimax optimal algorithms, there exists an action whose regret is sublinear in $T$ but linear in the number of its active rounds.","sentences":["We derive near-optimal per-action regret bounds for sleeping bandits, in which both the sets of available arms and their losses in every round are chosen by an adversary.","In a setting with $K$ total arms and at most $A$ available arms in each round over $T$ rounds, the best known upper bound is $O(K\\sqrt{TA\\ln{K}})$, obtained indirectly via minimizing internal sleeping regrets.","Compared to the minimax $\\Omega(\\sqrt{TA})$ lower bound, this upper bound contains an extra multiplicative factor of $K\\ln{K}$. We address this gap by directly minimizing the per-action regret using generalized versions of EXP3, EXP3-IX and FTRL with Tsallis entropy, thereby obtaining near-optimal bounds of order $O(\\sqrt{TA\\ln{K}})$ and $O(\\sqrt{T\\sqrt{AK}})$. We extend our results to the setting of bandits with advice from sleeping experts, generalizing EXP4 along the way.","This leads to new proofs for a number of existing adaptive and tracking regret bounds for standard non-sleeping bandits.","Extending our results to the bandit version of experts that report their confidences leads to new bounds for the confidence regret that depends primarily on the sum of experts' confidences.","We prove a lower bound, showing that for any minimax optimal algorithms, there exists an action whose regret is sublinear in $T$ but linear in the number of its active rounds."],"url":"http://arxiv.org/abs/2403.01315v1","category":"cs.LG"}
{"created":"2024-03-02 20:46:56","title":"VNLP: Turkish NLP Package","abstract":"In this work, we present VNLP: the first dedicated, complete, open-source, well-documented, lightweight, production-ready, state-of-the-art Natural Language Processing (NLP) package for the Turkish language. It contains a wide variety of tools, ranging from the simplest tasks, such as sentence splitting and text normalization, to the more advanced ones, such as text and token classification models. Its token classification models are based on \"Context Model\", a novel architecture that is both an encoder and an auto-regressive model. NLP tasks solved by VNLP models include but are not limited to Sentiment Analysis, Named Entity Recognition, Morphological Analysis \\& Disambiguation and Part-of-Speech Tagging. Moreover, it comes with pre-trained word embeddings and corresponding SentencePiece Unigram tokenizers. VNLP has an open-source GitHub repository, ReadtheDocs documentation, PyPi package for convenient installation, Python and command-line API and a demo page to test all the functionality. Consequently, our main contribution is a complete, compact, easy-to-install and easy-to-use NLP package for Turkish.","sentences":["In this work, we present VNLP: the first dedicated, complete, open-source, well-documented, lightweight, production-ready, state-of-the-art Natural Language Processing (NLP) package for the Turkish language.","It contains a wide variety of tools, ranging from the simplest tasks, such as sentence splitting and text normalization, to the more advanced ones, such as text and token classification models.","Its token classification models are based on \"Context Model\", a novel architecture that is both an encoder and an auto-regressive model.","NLP tasks solved by VNLP models include but are not limited to Sentiment Analysis, Named Entity Recognition, Morphological Analysis \\& Disambiguation and Part-of-Speech Tagging.","Moreover, it comes with pre-trained word embeddings and corresponding SentencePiece Unigram tokenizers.","VNLP has an open-source GitHub repository, ReadtheDocs documentation, PyPi package for convenient installation, Python and command-line API and a demo page to test all the functionality.","Consequently, our main contribution is a complete, compact, easy-to-install and easy-to-use NLP package for Turkish."],"url":"http://arxiv.org/abs/2403.01309v1","category":"cs.CL"}
{"created":"2024-03-02 20:40:11","title":"VBART: The Turkish LLM","abstract":"We present VBART, the first Turkish sequence-to-sequence Large Language Models (LLMs) pre-trained on a large corpus from scratch. VBART are compact LLMs based on good ideas leveraged from BART and mBART models and come in two sizes, Large and XLarge. Fine-tuned VBART models surpass the prior state-of-the-art results in abstractive text summarization, title generation, text paraphrasing, question answering and question generation tasks. They allow fine-tuning for future text generation tasks and datasets, carving a new path for Turkish Natural Language Processing (NLP) research. Our work shows that having a pre-trained LLM for Turkish outperforms up to 3x multilingual models, improving existing results and providing efficient models for training and inference. Moreover, we show that our monolingual tokenizer is 7x more efficient than OpenAI's multilingual tokenizer. Last but not least, we introduce a method to enlarge an existing pre-trained LLM and question the relevancy of Chinchilla Scaling Law to sequence-to-sequence masked language models. Our fine-tuned models, tokenizer and cleaned web corpus of 135 GB are publicly available at huggingface.co/vngrs-ai.","sentences":["We present VBART, the first Turkish sequence-to-sequence Large Language Models (LLMs) pre-trained on a large corpus from scratch.","VBART are compact LLMs based on good ideas leveraged from BART and mBART models and come in two sizes, Large and XLarge.","Fine-tuned VBART models surpass the prior state-of-the-art results in abstractive text summarization, title generation, text paraphrasing, question answering and question generation tasks.","They allow fine-tuning for future text generation tasks and datasets, carving a new path for Turkish Natural Language Processing (NLP) research.","Our work shows that having a pre-trained LLM for Turkish outperforms up to 3x multilingual models, improving existing results and providing efficient models for training and inference.","Moreover, we show that our monolingual tokenizer is 7x more efficient than OpenAI's multilingual tokenizer.","Last but not least, we introduce a method to enlarge an existing pre-trained LLM and question the relevancy of Chinchilla Scaling Law to sequence-to-sequence masked language models.","Our fine-tuned models, tokenizer and cleaned web corpus of 135 GB are publicly available at huggingface.co/vngrs-ai."],"url":"http://arxiv.org/abs/2403.01308v1","category":"cs.CL"}
{"created":"2024-03-02 20:34:44","title":"On the Development of the Concept of the Weak Cosmic Censorship Conjecture in General Relativity","abstract":"In this thesis, we scrutinize the literature to trace the evolution of the concepts surrounding the weak cosmic censorship conjecture and the attempts to prove or disprove it. We discuss its development over the years, its conceptual transformations, and the various thought experiments constructed to validate or invalidate the weak cosmic censorship conjecture. We also discuss possible connections with blackhole thermodynamics, and end with an evaluation of the current status about the subject, and finally, speculations about the future.","sentences":["In this thesis, we scrutinize the literature to trace the evolution of the concepts surrounding the weak cosmic censorship conjecture and the attempts to prove or disprove it.","We discuss its development over the years, its conceptual transformations, and the various thought experiments constructed to validate or invalidate the weak cosmic censorship conjecture.","We also discuss possible connections with blackhole thermodynamics, and end with an evaluation of the current status about the subject, and finally, speculations about the future."],"url":"http://arxiv.org/abs/2403.01305v1","category":"gr-qc"}
{"created":"2024-03-02 20:25:50","title":"Improving the Validity of Automatically Generated Feedback via Reinforcement Learning","abstract":"Automatically generating feedback via large language models (LLMs) in intelligent tutoring systems and online learning platforms has the potential to improve the learning outcomes of many students. However, both feedback generation and evaluation are challenging: feedback content has to be valid especially in subjects like math, which requires models to understand the problem, the solution, and where the student's error lies. Feedback also has to be pedagogically valid to reflect effective tutoring strategies, such as explaining possible misconceptions and encouraging the student, among other desirable features. In this work, we address both problems of automatically generating and evaluating feedback while considering both correctness and alignment. First, we propose a rubric for evaluating math feedback and show that GPT-4 is able to effectively use it to annotate human-written and LLM-generated feedback. Second, we propose a framework for feedback generation that optimizes both correctness and alignment using reinforcement learning (RL). Specifically, we use GPT-4's annotations to create preferences over feedback pairs in an augmented dataset for training via direct preference optimization (DPO). We show that our methods significantly increase the correctness and alignment of generated feedback with Llama 2, an open-source LLM, qualitatively analyze our generation and evaluation systems using case studies, and outline several areas for future work.","sentences":["Automatically generating feedback via large language models (LLMs) in intelligent tutoring systems and online learning platforms has the potential to improve the learning outcomes of many students.","However, both feedback generation and evaluation are challenging: feedback content has to be valid especially in subjects like math, which requires models to understand the problem, the solution, and where the student's error lies.","Feedback also has to be pedagogically valid to reflect effective tutoring strategies, such as explaining possible misconceptions and encouraging the student, among other desirable features.","In this work, we address both problems of automatically generating and evaluating feedback while considering both correctness and alignment.","First, we propose a rubric for evaluating math feedback and show that GPT-4 is able to effectively use it to annotate human-written and LLM-generated feedback.","Second, we propose a framework for feedback generation that optimizes both correctness and alignment using reinforcement learning (RL).","Specifically, we use GPT-4's annotations to create preferences over feedback pairs in an augmented dataset for training via direct preference optimization (DPO).","We show that our methods significantly increase the correctness and alignment of generated feedback with Llama 2, an open-source LLM, qualitatively analyze our generation and evaluation systems using case studies, and outline several areas for future work."],"url":"http://arxiv.org/abs/2403.01304v1","category":"cs.CL"}
{"created":"2024-03-02 19:54:53","title":"Causal Mode Multiplexer: A Novel Framework for Unbiased Multispectral Pedestrian Detection","abstract":"RGBT multispectral pedestrian detection has emerged as a promising solution for safety-critical applications that require day/night operations. However, the modality bias problem remains unsolved as multispectral pedestrian detectors learn the statistical bias in datasets. Specifically, datasets in multispectral pedestrian detection mainly distribute between ROTO (day) and RXTO (night) data; the majority of the pedestrian labels statistically co-occur with their thermal features. As a result, multispectral pedestrian detectors show poor generalization ability on examples beyond this statistical correlation, such as ROTX data. To address this problem, we propose a novel Causal Mode Multiplexer (CMM) framework that effectively learns the causalities between multispectral inputs and predictions. Moreover, we construct a new dataset (ROTX-MP) to evaluate modality bias in multispectral pedestrian detection. ROTX-MP mainly includes ROTX examples not presented in previous datasets. Extensive experiments demonstrate that our proposed CMM framework generalizes well on existing datasets (KAIST, CVC-14, FLIR) and the new ROTX-MP. We will release our new dataset to the public for future research.","sentences":["RGBT multispectral pedestrian detection has emerged as a promising solution for safety-critical applications that require day/night operations.","However, the modality bias problem remains unsolved as multispectral pedestrian detectors learn the statistical bias in datasets.","Specifically, datasets in multispectral pedestrian detection mainly distribute between ROTO (day) and RXTO (night) data; the majority of the pedestrian labels statistically co-occur with their thermal features.","As a result, multispectral pedestrian detectors show poor generalization ability on examples beyond this statistical correlation, such as ROTX data.","To address this problem, we propose a novel Causal Mode Multiplexer (CMM) framework that effectively learns the causalities between multispectral inputs and predictions.","Moreover, we construct a new dataset (ROTX-MP) to evaluate modality bias in multispectral pedestrian detection.","ROTX-MP mainly includes ROTX examples not presented in previous datasets.","Extensive experiments demonstrate that our proposed CMM framework generalizes well on existing datasets (KAIST, CVC-14, FLIR) and the new ROTX-MP.","We will release our new dataset to the public for future research."],"url":"http://arxiv.org/abs/2403.01300v1","category":"cs.CV"}
{"created":"2024-03-02 19:29:52","title":"Experimental Evaluation of the ETSI DCC Adaptive Approach and Related Algorithms","abstract":"Decentralized Congestion Control (DCC) mechanisms have been a core part of protocol stacks for vehicular networks since their inception and standardization. The ETSI ITS-G5 protocol stack for vehicular communications considers the usage of DCC not only in the network or access layers, but also as a part of the cross-layer architecture that influences how often messages are generated and transmitted. ETSI DCC mechanisms have evolved from a reactive approach based on a finite state machine, to an adaptive approach that relies on a linear control algorithm. This linear control algorithm, called LIMERIC, is the basis of the mechanism used in the ETSI DCC Adaptive Approach. The behavior of this algorithm depends on a set of parameters. Different values for these parameters have been proposed in the literature, including those defined in the ETSI specification. A recent proposal is Dual-$\\alpha$, which chooses parameters to improve convergence and fairness when the algorithm has to react to fast changes in the use of the shared medium (transitory situations). This article evaluates, by means of simulations, the performance of the ETSI DCC Adaptive Approach and related algorithms, considering both steady state and transitory situations. Results show that a bad selection of parameters can make a DCC algorithm ineffective, that the ETSI DCC Adaptive algorithm performs well in steady state conditions, and that Dual-$\\alpha$ performs as well in steady state conditions and outperforms the ETSI DCC Adaptive Approach in transitory scenarios.","sentences":["Decentralized Congestion Control (DCC) mechanisms have been a core part of protocol stacks for vehicular networks since their inception and standardization.","The ETSI ITS-G5 protocol stack for vehicular communications considers the usage of DCC not only in the network or access layers, but also as a part of the cross-layer architecture that influences how often messages are generated and transmitted.","ETSI DCC mechanisms have evolved from a reactive approach based on a finite state machine, to an adaptive approach that relies on a linear control algorithm.","This linear control algorithm, called LIMERIC, is the basis of the mechanism used in the ETSI DCC Adaptive Approach.","The behavior of this algorithm depends on a set of parameters.","Different values for these parameters have been proposed in the literature, including those defined in the ETSI specification.","A recent proposal is Dual-$\\alpha$, which chooses parameters to improve convergence and fairness when the algorithm has to react to fast changes in the use of the shared medium (transitory situations).","This article evaluates, by means of simulations, the performance of the ETSI DCC Adaptive Approach and related algorithms, considering both steady state and transitory situations.","Results show that a bad selection of parameters can make a DCC algorithm ineffective, that the ETSI DCC Adaptive algorithm performs well in steady state conditions, and that Dual-$\\alpha$ performs as well in steady state conditions and outperforms the ETSI DCC Adaptive Approach in transitory scenarios."],"url":"http://arxiv.org/abs/2403.01297v1","category":"cs.NI"}
{"created":"2024-03-02 19:28:13","title":"Rate-limited Shuffling for Distributed Computing","abstract":"This paper studies the shuffling phase in a distributed computing model with rate-limited links between nodes. Each node is connected to all other nodes via a noiseless broadcast link with a finite capacity. For this network, the shuffling phase is described as a distributed index-coding problem to extend an outer bound for the latter to the distributed computing problem. An inner bound on the capacity region is also established by using the distributed composite-coding scheme introduced for the distributed index-coding problem. We consider some special cases of the distributed computing problem through two examples for which we prove that the inner and outer bounds agree, thereby establishing the capacity regions. We, then, generalize the special cases to any number of nodes and computation loads under certain constraints.","sentences":["This paper studies the shuffling phase in a distributed computing model with rate-limited links between nodes.","Each node is connected to all other nodes via a noiseless broadcast link with a finite capacity.","For this network, the shuffling phase is described as a distributed index-coding problem to extend an outer bound for the latter to the distributed computing problem.","An inner bound on the capacity region is also established by using the distributed composite-coding scheme introduced for the distributed index-coding problem.","We consider some special cases of the distributed computing problem through two examples for which we prove that the inner and outer bounds agree, thereby establishing the capacity regions.","We, then, generalize the special cases to any number of nodes and computation loads under certain constraints."],"url":"http://arxiv.org/abs/2403.01296v1","category":"cs.IT"}
{"created":"2024-03-02 19:19:29","title":"Anomalous mass dependency in Hydra endoderm cell cluster diffusion","abstract":"Tissue organization plays a crucial role in morphogenesis, wound healing and cancer metastasis. Hydra, known for its regenerative capabilities, serves as an excellent model for studying cellular structures, particularly in pattern formation and the diffusion of cell clusters. Established experimental protocols enable the examination of regeneration and tissue segregation through optical microscopy. Recent experiments challenge previous theories by suggesting that cell collective behavior is a key factor in hydra cell aggregate organization. Utilizing image treatment techniques on fluorescent images from Hydra's segregation experiment, we track endoderm cell clusters and investigate the relationship between their diffusion constant and cluster size. In contrast to results observed in non-active matter, we discover a nearly constant dependence of diffusion on cluster mass. This finding contributes to understanding the rapid segregation observed in recent experiments and holds implications for general cellular tissue processes.","sentences":["Tissue organization plays a crucial role in morphogenesis, wound healing and cancer metastasis.","Hydra, known for its regenerative capabilities, serves as an excellent model for studying cellular structures, particularly in pattern formation and the diffusion of cell clusters.","Established experimental protocols enable the examination of regeneration and tissue segregation through optical microscopy.","Recent experiments challenge previous theories by suggesting that cell collective behavior is a key factor in hydra cell aggregate organization.","Utilizing image treatment techniques on fluorescent images from Hydra's segregation experiment, we track endoderm cell clusters and investigate the relationship between their diffusion constant and cluster size.","In contrast to results observed in non-active matter, we discover a nearly constant dependence of diffusion on cluster mass.","This finding contributes to understanding the rapid segregation observed in recent experiments and holds implications for general cellular tissue processes."],"url":"http://arxiv.org/abs/2403.01294v1","category":"physics.bio-ph"}
{"created":"2024-03-02 19:19:06","title":"Autonomous Intelligent Systems: From Illusion of Control to Inescapable Delusion","abstract":"Autonomous systems, including generative AI, have been adopted faster than previous digital innovations. Their impact on society might as well be more profound, with a radical restructuring of the economy of knowledge and dramatic consequences for social and institutional balances. Different attitudes to control these systems have emerged rooted in the classical pillars of legal systems, proprietary rights, and social responsibility. We show how an illusion of control might be guiding governments and regulators, while autonomous systems might be driving us to inescapable delusion.","sentences":["Autonomous systems, including generative AI, have been adopted faster than previous digital innovations.","Their impact on society might as well be more profound, with a radical restructuring of the economy of knowledge and dramatic consequences for social and institutional balances.","Different attitudes to control these systems have emerged rooted in the classical pillars of legal systems, proprietary rights, and social responsibility.","We show how an illusion of control might be guiding governments and regulators, while autonomous systems might be driving us to inescapable delusion."],"url":"http://arxiv.org/abs/2403.01292v1","category":"cs.CY"}
{"created":"2024-03-02 18:59:03","title":"Summary Paper: Use Case on Building Collaborative Safe Autonomous Systems-A Robotdog for Guiding Visually Impaired People","abstract":"This is a summary paper of a use case of a Robotdog dedicated to guide visually impaired people in complex environment like a smart intersection. In such scenarios, the Robotdog has to autonomously decide whether it is safe to cross the intersection or not in order to further guide the human. We leverage data sharing and collaboration between the Robotdog and other autonomous systems operating in the same environment. We propose a system architecture for autonomous systems through a separation of a collaborative decision layer, to enable collective decision making processes, where data about the environment, relevant to the Robotdog decision, together with evidences for trustworthiness about other systems and the environment are shared.","sentences":["This is a summary paper of a use case of a Robotdog dedicated to guide visually impaired people in complex environment like a smart intersection.","In such scenarios, the Robotdog has to autonomously decide whether it is safe to cross the intersection or not in order to further guide the human.","We leverage data sharing and collaboration between the Robotdog and other autonomous systems operating in the same environment.","We propose a system architecture for autonomous systems through a separation of a collaborative decision layer, to enable collective decision making processes, where data about the environment, relevant to the Robotdog decision, together with evidences for trustworthiness about other systems and the environment are shared."],"url":"http://arxiv.org/abs/2403.01286v1","category":"cs.RO"}
{"created":"2024-03-02 18:44:26","title":"$\u03c0$-systems and the Embedding problem for rank $2$ Kac-Moody Lie algebras","abstract":"$\\pi$-systems are fundamental in the study of Kac-Moody Lie algebras since they arise naturally in the embedding problems. Dynkin introduced them first and showed how they also appear in the classification of semisimple subalgebras of a semisimple Lie algebra. In this article, we explicitly classify the $\\pi$-systems associated to rank $2$ Kac-Moody Lie algebras and prove that in most of the cases they are linearly independent. This classification allows us to determine the root generated subalgebras and which in turn determines all possible Kac-Moody algebras that can be embedded in a rank $2$ Kac-Moody algebra as subalgebras generated by real root vectors. Additionally, following the work of Naito we provide examples illustrating how Borcherds Kac-Moody algebras can also be embedded inside a rank $2$ Kac-Moody algebra.","sentences":["$\\pi$-systems are fundamental in the study of Kac-Moody Lie algebras since they arise naturally in the embedding problems.","Dynkin introduced them first and showed how they also appear in the classification of semisimple subalgebras of a semisimple Lie algebra.","In this article, we explicitly classify the $\\pi$-systems associated to rank $2$ Kac-Moody Lie algebras and prove that in most of the cases they are linearly independent.","This classification allows us to determine the root generated subalgebras and which in turn determines all possible Kac-Moody algebras that can be embedded in a rank $2$ Kac-Moody algebra as subalgebras generated by real root vectors.","Additionally, following the work of Naito we provide examples illustrating how Borcherds Kac-Moody algebras can also be embedded inside a rank $2$ Kac-Moody algebra."],"url":"http://arxiv.org/abs/2403.01285v1","category":"math.RA"}
{"created":"2024-03-02 18:30:18","title":"On the uniqueness of the maximum parsimony tree for data with few substitutions within the NNI neighborhood","abstract":"Estimating species relationship trees, so-called phylogenetic trees, from aligned sequence data (such as DNA, RNA, or proteins) is one of the main aims of evolutionary biology. However, tree reconstruction criteria like maximum parsimony do not necessarily lead to unique trees and in some cases even fail to recognize the \\enquote{correct} tree (i.e., the tree on which the data was generated).   On the other hand, a recent study has shown that for an alignment containing precisely those characters (sites) which require up to two substitutions on a given tree, this tree will be the unique maximum parsimony tree.   It is the aim of the present manuscript to generalize this recent result in the following sense: We show that for a tree with $n$ leaves, as long as $k< \\frac{n}{8}+\\frac{6}{5}-\\frac{1}{10} \\sqrt{\\frac{5}{16} n^2+4}$ (or, equivalently, $n>8 k-\\frac{46}{5}+\\frac{2}{5} \\sqrt{40 k-31} $), the maximum parsimony tree for the alignment containing all characters which require (up to or precisely) $k$ substitutions on a given tree $T$ will be unique in the NNI neighborhood of $T$ and it will coincide with $T$, too. In other words, within the NNI neighborhood of $T$, $T$ is the unique most parsimonious tree for said alignment. This partially answers a recently published conjecture affirmatively.","sentences":["Estimating species relationship trees, so-called phylogenetic trees, from aligned sequence data (such as DNA, RNA, or proteins) is one of the main aims of evolutionary biology.","However, tree reconstruction criteria like maximum parsimony do not necessarily lead to unique trees and in some cases even fail to recognize the \\enquote{correct} tree (i.e., the tree on which the data was generated).   ","On the other hand, a recent study has shown that for an alignment containing precisely those characters (sites) which require up to two substitutions on a given tree, this tree will be the unique maximum parsimony tree.   ","It is the aim of the present manuscript to generalize this recent result in the following sense: We show that for a tree with $n$ leaves, as long as $k< \\frac{n}{8}+\\frac{6}{5}-\\frac{1}{10} \\sqrt{\\frac{5}{16} n^2+4}$ (or, equivalently, $n>8 k-\\frac{46}{5}+\\frac{2}{5} \\sqrt{40 k-31} $), the maximum parsimony tree for the alignment containing all characters which require (up to or precisely) $k$ substitutions on a given tree $T$ will be unique in the NNI neighborhood of $T$ and it will coincide with $T$, too.","In other words, within the NNI neighborhood of $T$, $T$ is the unique most parsimonious tree for said alignment.","This partially answers a recently published conjecture affirmatively."],"url":"http://arxiv.org/abs/2403.01282v1","category":"q-bio.PE"}
{"created":"2024-03-02 18:28:32","title":"Fast Low-parameter Video Activity Localization in Collaborative Learning Environments","abstract":"Research on video activity detection has primarily focused on identifying well-defined human activities in short video segments. The majority of the research on video activity recognition is focused on the development of large parameter systems that require training on large video datasets. This paper develops a low-parameter, modular system with rapid inferencing capabilities that can be trained entirely on limited datasets without requiring transfer learning from large-parameter systems. The system can accurately detect and associate specific activities with the students who perform the activities in real-life classroom videos. Additionally, the paper develops an interactive web-based application to visualize human activity maps over long real-life classroom videos.","sentences":["Research on video activity detection has primarily focused on identifying well-defined human activities in short video segments.","The majority of the research on video activity recognition is focused on the development of large parameter systems that require training on large video datasets.","This paper develops a low-parameter, modular system with rapid inferencing capabilities that can be trained entirely on limited datasets without requiring transfer learning from large-parameter systems.","The system can accurately detect and associate specific activities with the students who perform the activities in real-life classroom videos.","Additionally, the paper develops an interactive web-based application to visualize human activity maps over long real-life classroom videos."],"url":"http://arxiv.org/abs/2403.01281v1","category":"cs.CV"}
{"created":"2024-03-02 17:59:57","title":"Enhancing Audio Generation Diversity with Visual Information","abstract":"Audio and sound generation has garnered significant attention in recent years, with a primary focus on improving the quality of generated audios. However, there has been limited research on enhancing the diversity of generated audio, particularly when it comes to audio generation within specific categories. Current models tend to produce homogeneous audio samples within a category. This work aims to address this limitation by improving the diversity of generated audio with visual information. We propose a clustering-based method, leveraging visual information to guide the model in generating distinct audio content within each category. Results on seven categories indicate that extra visual input can largely enhance audio generation diversity. Audio samples are available at https://zeyuxie29.github.io/DiverseAudioGeneration.","sentences":["Audio and sound generation has garnered significant attention in recent years, with a primary focus on improving the quality of generated audios.","However, there has been limited research on enhancing the diversity of generated audio, particularly when it comes to audio generation within specific categories.","Current models tend to produce homogeneous audio samples within a category.","This work aims to address this limitation by improving the diversity of generated audio with visual information.","We propose a clustering-based method, leveraging visual information to guide the model in generating distinct audio content within each category.","Results on seven categories indicate that extra visual input can largely enhance audio generation diversity.","Audio samples are available at https://zeyuxie29.github.io/DiverseAudioGeneration."],"url":"http://arxiv.org/abs/2403.01278v1","category":"cs.SD"}
{"created":"2024-03-02 17:48:40","title":"Optimal Integrated Task and Path Planning and Its Application to Multi-Robot Pickup and Delivery","abstract":"We propose a generic multi-robot planning mechanism that combines an optimal task planner and an optimal path planner to provide a scalable solution for complex multi-robot planning problems. The Integrated planner, through the interaction of the task planner and the path planner, produces optimal collision-free trajectories for the robots. We illustrate our general algorithm on an object pick-and-drop planning problem in a warehouse scenario where a group of robots is entrusted with moving objects from one location to another in the workspace. We solve the task planning problem by reducing it into an SMT-solving problem and employing the highly advanced SMT solver Z3 to solve it. To generate collision-free movement of the robots, we extend the state-of-the-art algorithm Conflict Based Search with Precedence Constraints with several domain-specific constraints. We evaluate our integrated task and path planner extensively on various instances of the object pick-and-drop planning problem and compare its performance with a state-of-the-art multi-robot classical planner. Experimental results demonstrate that our planning mechanism can deal with complex planning problems and outperforms a state-of-the-art classical planner both in terms of computation time and the quality of the generated plan.","sentences":["We propose a generic multi-robot planning mechanism that combines an optimal task planner and an optimal path planner to provide a scalable solution for complex multi-robot planning problems.","The Integrated planner, through the interaction of the task planner and the path planner, produces optimal collision-free trajectories for the robots.","We illustrate our general algorithm on an object pick-and-drop planning problem in a warehouse scenario where a group of robots is entrusted with moving objects from one location to another in the workspace.","We solve the task planning problem by reducing it into an SMT-solving problem and employing the highly advanced SMT solver Z3 to solve it.","To generate collision-free movement of the robots, we extend the state-of-the-art algorithm Conflict Based Search with Precedence Constraints with several domain-specific constraints.","We evaluate our integrated task and path planner extensively on various instances of the object pick-and-drop planning problem and compare its performance with a state-of-the-art multi-robot classical planner.","Experimental results demonstrate that our planning mechanism can deal with complex planning problems and outperforms a state-of-the-art classical planner both in terms of computation time and the quality of the generated plan."],"url":"http://arxiv.org/abs/2403.01277v1","category":"cs.RO"}
{"created":"2024-03-02 17:47:04","title":"A universal niche geometry governs the response of ecosystems to environmental perturbations","abstract":"How ecosystems respond to environmental perturbations is a fundamental question in ecology, made especially challenging due to the strong coupling between species and their environment. Here, we introduce a theoretical framework for calculating the linear response of ecosystems to environmental perturbations in generalized consumer-resource models. Our construction is applicable to a wide class of systems, including models with non-reciprocal interactions, cross-feeding, and non-linear growth/consumption rates. Within our framework, all ecological variables are embedded into four distinct vector spaces and ecological interactions are represented by geometric transformations between these spaces. We show that near a steady state, such geometric transformations directly map environmental perturbations -- in resource availability and mortality rates -- to shifts in niche structure. We illustrate these ideas in a variety of settings including a minimal model for pH-induced toxicity in bacterial denitrification.","sentences":["How ecosystems respond to environmental perturbations is a fundamental question in ecology, made especially challenging due to the strong coupling between species and their environment.","Here, we introduce a theoretical framework for calculating the linear response of ecosystems to environmental perturbations in generalized consumer-resource models.","Our construction is applicable to a wide class of systems, including models with non-reciprocal interactions, cross-feeding, and non-linear growth/consumption rates.","Within our framework, all ecological variables are embedded into four distinct vector spaces and ecological interactions are represented by geometric transformations between these spaces.","We show that near a steady state, such geometric transformations directly map environmental perturbations -- in resource availability and mortality rates -- to shifts in niche structure.","We illustrate these ideas in a variety of settings including a minimal model for pH-induced toxicity in bacterial denitrification."],"url":"http://arxiv.org/abs/2403.01276v1","category":"q-bio.PE"}
{"created":"2024-03-02 17:29:22","title":"NoMAD-Attention: Efficient LLM Inference on CPUs Through Multiply-add-free Attention","abstract":"Large language model inference on Central Processing Units (CPU) is challenging due to the vast quantities of expensive Multiply-Add (MAD) matrix operations in the attention computations. In this paper, we argue that there is a rare gem in modern CPUs, Single-Instruction-Multiple-Data (SIMD) registers, which allow for ultra-low-latency lookups in batch. We leverage this unique capability of CPUs to propose NoMAD-Attention, an efficient attention algorithm that replaces MAD operations with in-register lookups. Through hardware-aware algorithmic designs, NoMAD-Attention achieves the computation of attention scores using repeated fast accesses to SIMD registers despite their highly limited sizes. Moreover, NoMAD-Attention works with pre-trained attention-based LLMs without model finetuning. Empirical evaluations demonstrate that NoMAD-Attention maintains the quality of the original LLMs well, and speeds up the 4-bit quantized LLaMA-7B-based model by up to 2$\\times$ at 16k context length. Our results are reproducible at https://github.com/tonyzhang617/nomad-dist.","sentences":["Large language model inference on Central Processing Units (CPU) is challenging due to the vast quantities of expensive Multiply-Add (MAD) matrix operations in the attention computations.","In this paper, we argue that there is a rare gem in modern CPUs, Single-Instruction-Multiple-Data (SIMD) registers, which allow for ultra-low-latency lookups in batch.","We leverage this unique capability of CPUs to propose NoMAD-Attention, an efficient attention algorithm that replaces MAD operations with in-register lookups.","Through hardware-aware algorithmic designs, NoMAD-Attention achieves the computation of attention scores using repeated fast accesses to SIMD registers despite their highly limited sizes.","Moreover, NoMAD-Attention works with pre-trained attention-based LLMs without model finetuning.","Empirical evaluations demonstrate that NoMAD-Attention maintains the quality of the original LLMs well, and speeds up the 4-bit quantized LLaMA-7B-based model by up to 2$\\times$ at 16k context length.","Our results are reproducible at https://github.com/tonyzhang617/nomad-dist."],"url":"http://arxiv.org/abs/2403.01273v1","category":"cs.LG"}
{"created":"2024-03-02 17:28:55","title":"Can a Confident Prior Replace a Cold Posterior?","abstract":"Benchmark datasets used for image classification tend to have very low levels of label noise. When Bayesian neural networks are trained on these datasets, they often underfit, misrepresenting the aleatoric uncertainty of the data. A common solution is to cool the posterior, which improves fit to the training data but is challenging to interpret from a Bayesian perspective. We explore whether posterior tempering can be replaced by a confidence-inducing prior distribution. First, we introduce a \"DirClip\" prior that is practical to sample and nearly matches the performance of a cold posterior. Second, we introduce a \"confidence prior\" that directly approximates a cold likelihood in the limit of decreasing temperature but cannot be easily sampled. Lastly, we provide several general insights into confidence-inducing priors, such as when they might diverge and how fine-tuning can mitigate numerical instability.","sentences":["Benchmark datasets used for image classification tend to have very low levels of label noise.","When Bayesian neural networks are trained on these datasets, they often underfit, misrepresenting the aleatoric uncertainty of the data.","A common solution is to cool the posterior, which improves fit to the training data but is challenging to interpret from a Bayesian perspective.","We explore whether posterior tempering can be replaced by a confidence-inducing prior distribution.","First, we introduce a \"DirClip\" prior that is practical to sample and nearly matches the performance of a cold posterior.","Second, we introduce a \"confidence prior\" that directly approximates a cold likelihood in the limit of decreasing temperature but cannot be easily sampled.","Lastly, we provide several general insights into confidence-inducing priors, such as when they might diverge and how fine-tuning can mitigate numerical instability."],"url":"http://arxiv.org/abs/2403.01272v1","category":"cs.LG"}
{"created":"2024-03-02 17:23:41","title":"Employing LLMs for Incident Response Planning and Review","abstract":"Incident Response Planning (IRP) is essential for effective cybersecurity management, requiring detailed documentation (or playbooks) to guide security personnel during incidents. Yet, creating comprehensive IRPs is often hindered by challenges such as complex systems, high turnover rates, and legacy technologies lacking documentation. This paper argues that, despite these obstacles, the development, review, and refinement of IRPs can be significantly enhanced through the utilization of Large Language Models (LLMs) like ChatGPT. By leveraging LLMs for tasks such as drafting initial plans, suggesting best practices, and identifying documentation gaps, organizations can overcome resource constraints and improve their readiness for cybersecurity incidents. We discuss the potential of LLMs to streamline IRP processes, while also considering the limitations and the need for human oversight in ensuring the accuracy and relevance of generated content. Our findings contribute to the cybersecurity field by demonstrating a novel approach to enhancing IRP with AI technologies, offering practical insights for organizations seeking to bolster their incident response capabilities.","sentences":["Incident Response Planning (IRP) is essential for effective cybersecurity management, requiring detailed documentation (or playbooks) to guide security personnel during incidents.","Yet, creating comprehensive IRPs is often hindered by challenges such as complex systems, high turnover rates, and legacy technologies lacking documentation.","This paper argues that, despite these obstacles, the development, review, and refinement of IRPs can be significantly enhanced through the utilization of Large Language Models (LLMs) like ChatGPT.","By leveraging LLMs for tasks such as drafting initial plans, suggesting best practices, and identifying documentation gaps, organizations can overcome resource constraints and improve their readiness for cybersecurity incidents.","We discuss the potential of LLMs to streamline IRP processes, while also considering the limitations and the need for human oversight in ensuring the accuracy and relevance of generated content.","Our findings contribute to the cybersecurity field by demonstrating a novel approach to enhancing IRP with AI technologies, offering practical insights for organizations seeking to bolster their incident response capabilities."],"url":"http://arxiv.org/abs/2403.01271v1","category":"cs.CR"}
{"created":"2024-03-02 17:13:47","title":"A comprehensive cross-language framework for harmful content detection with the aid of sentiment analysis","abstract":"In today's digital world, social media plays a significant role in facilitating communication and content sharing. However, the exponential rise in user-generated content has led to challenges in maintaining a respectful online environment. In some cases, users have taken advantage of anonymity in order to use harmful language, which can negatively affect the user experience and pose serious social problems. Recognizing the limitations of manual moderation, automatic detection systems have been developed to tackle this problem. Nevertheless, several obstacles persist, including the absence of a universal definition for harmful language, inadequate datasets across languages, the need for detailed annotation guideline, and most importantly, a comprehensive framework. This study aims to address these challenges by introducing, for the first time, a detailed framework adaptable to any language. This framework encompasses various aspects of harmful language detection. A key component of the framework is the development of a general and detailed annotation guideline. Additionally, the integration of sentiment analysis represents a novel approach to enhancing harmful language detection. Also, a definition of harmful language based on the review of different related concepts is presented. To demonstrate the effectiveness of the proposed framework, its implementation in a challenging low-resource language is conducted. We collected a Persian dataset and applied the annotation guideline for harmful detection and sentiment analysis. Next, we present baseline experiments utilizing machine and deep learning methods to set benchmarks. Results prove the framework's high performance, achieving an accuracy of 99.4% in offensive language detection and 66.2% in sentiment analysis.","sentences":["In today's digital world, social media plays a significant role in facilitating communication and content sharing.","However, the exponential rise in user-generated content has led to challenges in maintaining a respectful online environment.","In some cases, users have taken advantage of anonymity in order to use harmful language, which can negatively affect the user experience and pose serious social problems.","Recognizing the limitations of manual moderation, automatic detection systems have been developed to tackle this problem.","Nevertheless, several obstacles persist, including the absence of a universal definition for harmful language, inadequate datasets across languages, the need for detailed annotation guideline, and most importantly, a comprehensive framework.","This study aims to address these challenges by introducing, for the first time, a detailed framework adaptable to any language.","This framework encompasses various aspects of harmful language detection.","A key component of the framework is the development of a general and detailed annotation guideline.","Additionally, the integration of sentiment analysis represents a novel approach to enhancing harmful language detection.","Also, a definition of harmful language based on the review of different related concepts is presented.","To demonstrate the effectiveness of the proposed framework, its implementation in a challenging low-resource language is conducted.","We collected a Persian dataset and applied the annotation guideline for harmful detection and sentiment analysis.","Next, we present baseline experiments utilizing machine and deep learning methods to set benchmarks.","Results prove the framework's high performance, achieving an accuracy of 99.4% in offensive language detection and 66.2% in sentiment analysis."],"url":"http://arxiv.org/abs/2403.01270v1","category":"cs.CL"}
{"created":"2024-03-02 17:13:00","title":"Network analysis using Krylov subspace trajectories","abstract":"We describe a set of network analysis methods based on the rows of the Krylov subspace matrix computed from a network adjacency matrix via power iteration using a non-random initial vector. We refer to these node-specific row vectors as Krylov subspace trajectories. While power iteration using a random initial starting vector is commonly applied to the network adjacency matrix to compute eigenvector centrality values, this application only uses the final vector generated after numerical convergence. Importantly, use of a random initial vector means that the intermediate results of power iteration are also random and lack a clear interpretation. To the best of our knowledge, use of intermediate power iteration results for network analysis has been limited to techniques that leverage just a single pre-convergence solution, e.g., Power Iteration Clustering. In this paper, we explore methods that apply power iteration with a non-random inital vector to the network adjacency matrix to generate Krylov subspace trajectories for each node. These non-random trajectories provide important information regarding network structure, node importance, and response to perturbations. We have created this short preprint in part to generate feedback from others in the network analysis community who might be aware of similar existing work.","sentences":["We describe a set of network analysis methods based on the rows of the Krylov subspace matrix computed from a network adjacency matrix via power iteration using a non-random initial vector.","We refer to these node-specific row vectors as Krylov subspace trajectories.","While power iteration using a random initial starting vector is commonly applied to the network adjacency matrix to compute eigenvector centrality values, this application only uses the final vector generated after numerical convergence.","Importantly, use of a random initial vector means that the intermediate results of power iteration are also random and lack a clear interpretation.","To the best of our knowledge, use of intermediate power iteration results for network analysis has been limited to techniques that leverage just a single pre-convergence solution, e.g., Power Iteration Clustering.","In this paper, we explore methods that apply power iteration with a non-random inital vector to the network adjacency matrix to generate Krylov subspace trajectories for each node.","These non-random trajectories provide important information regarding network structure, node importance, and response to perturbations.","We have created this short preprint in part to generate feedback from others in the network analysis community who might be aware of similar existing work."],"url":"http://arxiv.org/abs/2403.01269v1","category":"physics.soc-ph"}
{"created":"2024-03-02 17:03:29","title":"Efficient Alternative Finite Difference WENO Schemes for Hyperbolic Systems with Non-Conservative Products","abstract":"Higher order finite difference Weighted Essentially Non-Oscillatory (WENO) schemes for conservation laws represent a technology that has been reasonably consolidated. They are extremely popular because, when applied to multidimensional problems, they offer high order accuracy at a fraction of the cost of finite volume WENO or DG schemes. They come in two flavors. There is the classical finite difference WENO (FD-WENO) method (Shu and Osher, J. Comput. Phys., 83 (1989) 32-78). However, in recent years there is also an alternative finite difference WENO (AFD-WENO) method which has recently been formalized into a very useful general-purpose algorithm for conservation laws (Balsara et al., Efficient Alternative Finite Difference WENO Schemes for Hyperbolic Conservation Laws, submitted to CAMC (2023)). However, the FD-WENO algorithm has only very recently been formulated for hyperbolic systems with non-conservative products (Balsara et al., Efficient Finite Difference WENO Scheme for Hyperbolic Systems with Non-Conservative Products, to appear CAMC (2023)). In this paper we show that there are substantial advantages in obtaining an AFD-WENO algorithm for hyperbolic systems with non-conservative products. Such an algorithm is documented in this paper. We present an AFD-WENO formulation in fluctuation form that is carefully engineered to retrieve the flux form when that is warranted and nevertheless extends to non-conservative products. The method is flexible because it allows any Riemann solver to be used. The formulation we arrive at is such that when non-conservative products are absent it reverts exactly to the formulation in the second citation above which is in exact flux conservation form. The ability to transition to a precise conservation form when non-conservative products are absent ensures, via the Lax-Wendroff theorem, that shock locations will be exactly ...","sentences":["Higher order finite difference Weighted Essentially Non-Oscillatory (WENO) schemes for conservation laws represent a technology that has been reasonably consolidated.","They are extremely popular because, when applied to multidimensional problems, they offer high order accuracy at a fraction of the cost of finite volume WENO or DG schemes.","They come in two flavors.","There is the classical finite difference WENO (FD-WENO) method (Shu and Osher, J. Comput.","Phys., 83 (1989) 32-78).","However, in recent years there is also an alternative finite difference WENO (AFD-WENO) method which has recently been formalized into a very useful general-purpose algorithm for conservation laws (Balsara et al., Efficient Alternative Finite Difference WENO Schemes for Hyperbolic Conservation Laws, submitted to CAMC (2023)).","However, the FD-WENO algorithm has only very recently been formulated for hyperbolic systems with non-conservative products (Balsara et al., Efficient Finite Difference WENO Scheme for Hyperbolic Systems with Non-Conservative Products, to appear CAMC (2023)).","In this paper we show that there are substantial advantages in obtaining an AFD-WENO algorithm for hyperbolic systems with non-conservative products.","Such an algorithm is documented in this paper.","We present an AFD-WENO formulation in fluctuation form that is carefully engineered to retrieve the flux form when that is warranted and nevertheless extends to non-conservative products.","The method is flexible because it allows any Riemann solver to be used.","The formulation we arrive at is such that when non-conservative products are absent it reverts exactly to the formulation in the second citation above which is in exact flux conservation form.","The ability to transition to a precise conservation form when non-conservative products are absent ensures, via the Lax-Wendroff theorem, that shock locations will be exactly ..."],"url":"http://arxiv.org/abs/2403.01266v1","category":"math.NA"}
{"created":"2024-03-02 16:47:14","title":"Solvability of a group based on its number of subgroups","abstract":"In this paper, we provide some conditions of (super)-solvability and nilpotency of a finite group $G$ based on its number of subgroups $Sub(G)$. Our results generalize the classification of finite groups with less than $20$ subgroups by Betz and Nash. We also provide an application of our results in studying comaximal subgroup graph of a group. Finally, we conclude with some open issues.","sentences":["In this paper, we provide some conditions of (super)-solvability and nilpotency of a finite group $G$ based on its number of subgroups $Sub(G)$. Our results generalize the classification of finite groups with less than $20$ subgroups by Betz and Nash.","We also provide an application of our results in studying comaximal subgroup graph of a group.","Finally, we conclude with some open issues."],"url":"http://arxiv.org/abs/2403.01262v1","category":"math.GR"}
{"created":"2024-03-02 16:25:42","title":"Automatic Speech Recognition using Advanced Deep Learning Approaches: A survey","abstract":"Recent advancements in deep learning (DL) have posed a significant challenge for automatic speech recognition (ASR). ASR relies on extensive training datasets, including confidential ones, and demands substantial computational and storage resources. Enabling adaptive systems improves ASR performance in dynamic environments. DL techniques assume training and testing data originate from the same domain, which is not always true. Advanced DL techniques like deep transfer learning (DTL), federated learning (FL), and reinforcement learning (RL) address these issues. DTL allows high-performance models using small yet related datasets, FL enables training on confidential data without dataset possession, and RL optimizes decision-making in dynamic environments, reducing computation costs. This survey offers a comprehensive review of DTL, FL, and RL-based ASR frameworks, aiming to provide insights into the latest developments and aid researchers and professionals in understanding the current challenges. Additionally, transformers, which are advanced DL techniques heavily used in proposed ASR frameworks, are considered in this survey for their ability to capture extensive dependencies in the input ASR sequence. The paper starts by presenting the background of DTL, FL, RL, and Transformers and then adopts a well-designed taxonomy to outline the state-of-the-art approaches. Subsequently, a critical analysis is conducted to identify the strengths and weaknesses of each framework. Additionally, a comparative study is presented to highlight the existing challenges, paving the way for future research opportunities.","sentences":["Recent advancements in deep learning (DL) have posed a significant challenge for automatic speech recognition (ASR).","ASR relies on extensive training datasets, including confidential ones, and demands substantial computational and storage resources.","Enabling adaptive systems improves ASR performance in dynamic environments.","DL techniques assume training and testing data originate from the same domain, which is not always true.","Advanced DL techniques like deep transfer learning (DTL), federated learning (FL), and reinforcement learning (RL) address these issues.","DTL allows high-performance models using small yet related datasets, FL enables training on confidential data without dataset possession, and RL optimizes decision-making in dynamic environments, reducing computation costs.","This survey offers a comprehensive review of DTL, FL, and RL-based ASR frameworks, aiming to provide insights into the latest developments and aid researchers and professionals in understanding the current challenges.","Additionally, transformers, which are advanced DL techniques heavily used in proposed ASR frameworks, are considered in this survey for their ability to capture extensive dependencies in the input ASR sequence.","The paper starts by presenting the background of DTL, FL, RL, and Transformers and then adopts a well-designed taxonomy to outline the state-of-the-art approaches.","Subsequently, a critical analysis is conducted to identify the strengths and weaknesses of each framework.","Additionally, a comparative study is presented to highlight the existing challenges, paving the way for future research opportunities."],"url":"http://arxiv.org/abs/2403.01255v1","category":"cs.SD"}
{"created":"2024-03-02 16:25:09","title":"RKHS-BA: A Semantic Correspondence-Free Multi-View Registration Framework with Global Tracking","abstract":"This work reports a novel Bundle Adjustment (BA) formulation using a Reproducing Kernel Hilbert Space (RKHS) representation called RKHS-BA. The proposed formulation is correspondence-free, enables the BA to use RGB-D/LiDAR and semantic labels in the optimization directly, and provides a generalization for the photometric loss function commonly used in direct methods. RKHS-BA can incorporate appearance and semantic labels within a continuous spatial-semantic functional representation that does not require optimization via image pyramids. We demonstrate its applications in sliding-window odometry and global LiDAR mapping, which show highly robust performance in extremely challenging scenes and the best trade-off of generalization and accuracy.","sentences":["This work reports a novel Bundle Adjustment (BA) formulation using a Reproducing Kernel Hilbert Space (RKHS) representation called RKHS-BA.","The proposed formulation is correspondence-free, enables the BA to use RGB-D/LiDAR and semantic labels in the optimization directly, and provides a generalization for the photometric loss function commonly used in direct methods.","RKHS-BA can incorporate appearance and semantic labels within a continuous spatial-semantic functional representation that does not require optimization via image pyramids.","We demonstrate its applications in sliding-window odometry and global LiDAR mapping, which show highly robust performance in extremely challenging scenes and the best trade-off of generalization and accuracy."],"url":"http://arxiv.org/abs/2403.01254v1","category":"cs.RO"}
{"created":"2024-03-02 16:20:25","title":"Blockage-Aware Robust Beamforming in RIS-Aided Mobile Millimeter Wave MIMO Systems","abstract":"Millimeter wave (mmWave) communications are sensitive to blockage over radio propagation paths. The emerging paradigm of reconfigurable intelligent surface (RIS) has the potential to overcome this issue by its ability to arbitrarily reflect the incident signals toward desired directions. This paper proposes a Neyman-Pearson (NP) criterion-based blockage-aware algorithm to improve communication resilience against blockage in mobile mmWave multiple input multiple output (MIMO) systems. By virtue of this pragmatic blockage-aware technique, we further propose an outage-constrained beamforming design for downlink mmWave MIMO transmission to achieve outage probability minimization and achievable rate maximization. To minimize the outage probability, a robust RIS beamformer with variant beamwidth is designed to combat uncertain channel state information (CSI). For the rate maximization problem, an accelerated projected gradient descent (PGD) algorithm is developed to solve the computational challenge of high-dimensional RIS phase-shift matrix (PSM) optimization. Particularly, we leverage a subspace constraint to reduce the scope of the projection operation and formulate a new Nesterov momentum acceleration scheme to speed up the convergence process of PGD. Extensive experiments confirm the effectiveness of the proposed blockage-aware approach, and the proposed accelerated PGD algorithm outperforms a number of representative baseline algorithms in terms of the achievable rate.","sentences":["Millimeter wave (mmWave) communications are sensitive to blockage over radio propagation paths.","The emerging paradigm of reconfigurable intelligent surface (RIS) has the potential to overcome this issue by its ability to arbitrarily reflect the incident signals toward desired directions.","This paper proposes a Neyman-Pearson (NP) criterion-based blockage-aware algorithm to improve communication resilience against blockage in mobile mmWave multiple input multiple output (MIMO) systems.","By virtue of this pragmatic blockage-aware technique, we further propose an outage-constrained beamforming design for downlink mmWave MIMO transmission to achieve outage probability minimization and achievable rate maximization.","To minimize the outage probability, a robust RIS beamformer with variant beamwidth is designed to combat uncertain channel state information (CSI).","For the rate maximization problem, an accelerated projected gradient descent (PGD) algorithm is developed to solve the computational challenge of high-dimensional RIS phase-shift matrix (PSM) optimization.","Particularly, we leverage a subspace constraint to reduce the scope of the projection operation and formulate a new Nesterov momentum acceleration scheme to speed up the convergence process of PGD.","Extensive experiments confirm the effectiveness of the proposed blockage-aware approach, and the proposed accelerated PGD algorithm outperforms a number of representative baseline algorithms in terms of the achievable rate."],"url":"http://arxiv.org/abs/2403.01249v1","category":"eess.SP"}
{"created":"2024-03-02 16:16:26","title":"SceneCraft: An LLM Agent for Synthesizing 3D Scene as Blender Code","abstract":"This paper introduces SceneCraft, a Large Language Model (LLM) Agent converting text descriptions into Blender-executable Python scripts which render complex scenes with up to a hundred 3D assets. This process requires complex spatial planning and arrangement. We tackle these challenges through a combination of advanced abstraction, strategic planning, and library learning. SceneCraft first models a scene graph as a blueprint, detailing the spatial relationships among assets in the scene. SceneCraft then writes Python scripts based on this graph, translating relationships into numerical constraints for asset layout. Next, SceneCraft leverages the perceptual strengths of vision-language foundation models like GPT-V to analyze rendered images and iteratively refine the scene. On top of this process, SceneCraft features a library learning mechanism that compiles common script functions into a reusable library, facilitating continuous self-improvement without expensive LLM parameter tuning. Our evaluation demonstrates that SceneCraft surpasses existing LLM-based agents in rendering complex scenes, as shown by its adherence to constraints and favorable human assessments. We also showcase the broader application potential of SceneCraft by reconstructing detailed 3D scenes from the Sintel movie and guiding a video generative model with generated scenes as intermediary control signal.","sentences":["This paper introduces SceneCraft, a Large Language Model (LLM) Agent converting text descriptions into Blender-executable Python scripts which render complex scenes with up to a hundred 3D assets.","This process requires complex spatial planning and arrangement.","We tackle these challenges through a combination of advanced abstraction, strategic planning, and library learning.","SceneCraft first models a scene graph as a blueprint, detailing the spatial relationships among assets in the scene.","SceneCraft then writes Python scripts based on this graph, translating relationships into numerical constraints for asset layout.","Next, SceneCraft leverages the perceptual strengths of vision-language foundation models like GPT-V to analyze rendered images and iteratively refine the scene.","On top of this process, SceneCraft features a library learning mechanism that compiles common script functions into a reusable library, facilitating continuous self-improvement without expensive LLM parameter tuning.","Our evaluation demonstrates that SceneCraft surpasses existing LLM-based agents in rendering complex scenes, as shown by its adherence to constraints and favorable human assessments.","We also showcase the broader application potential of SceneCraft by reconstructing detailed 3D scenes from the Sintel movie and guiding a video generative model with generated scenes as intermediary control signal."],"url":"http://arxiv.org/abs/2403.01248v1","category":"cs.CV"}
{"created":"2024-03-02 16:11:58","title":"AcME-AD: Accelerated Model Explanations for Anomaly Detection","abstract":"Pursuing fast and robust interpretability in Anomaly Detection is crucial, especially due to its significance in practical applications. Traditional Anomaly Detection methods excel in outlier identification but are often black-boxes, providing scant insights into their decision-making process. This lack of transparency compromises their reliability and hampers their adoption in scenarios where comprehending the reasons behind anomaly detection is vital. At the same time, getting explanations quickly is paramount in practical scenarios. To bridge this gap, we present AcME-AD, a novel approach rooted in Explainable Artificial Intelligence principles, designed to clarify Anomaly Detection models for tabular data. AcME-AD transcends the constraints of model-specific or resource-heavy explainability techniques by delivering a model-agnostic, efficient solution for interoperability. It offers local feature importance scores and a what-if analysis tool, shedding light on the factors contributing to each anomaly, thus aiding root cause analysis and decision-making. This paper elucidates AcME-AD's foundation, its benefits over existing methods, and validates its effectiveness with tests on both synthetic and real datasets. AcME-AD's implementation and experiment replication code is accessible in a public repository.","sentences":["Pursuing fast and robust interpretability in Anomaly Detection is crucial, especially due to its significance in practical applications.","Traditional Anomaly Detection methods excel in outlier identification but are often black-boxes, providing scant insights into their decision-making process.","This lack of transparency compromises their reliability and hampers their adoption in scenarios where comprehending the reasons behind anomaly detection is vital.","At the same time, getting explanations quickly is paramount in practical scenarios.","To bridge this gap, we present AcME-AD, a novel approach rooted in Explainable Artificial Intelligence principles, designed to clarify Anomaly Detection models for tabular data.","AcME-AD transcends the constraints of model-specific or resource-heavy explainability techniques by delivering a model-agnostic, efficient solution for interoperability.","It offers local feature importance scores and a what-if analysis tool, shedding light on the factors contributing to each anomaly, thus aiding root cause analysis and decision-making.","This paper elucidates AcME-AD's foundation, its benefits over existing methods, and validates its effectiveness with tests on both synthetic and real datasets.","AcME-AD's implementation and experiment replication code is accessible in a public repository."],"url":"http://arxiv.org/abs/2403.01245v1","category":"cs.LG"}
{"created":"2024-03-02 16:11:23","title":"Mitigating Catastrophic Forgetting in Large Language Models with Self-Synthesized Rehearsal","abstract":"Large language models (LLMs) suffer from catastrophic forgetting during continual learning. Conventional rehearsal-based methods rely on previous training data to retain the model's ability, which may not be feasible in real-world applications. When conducting continual learning based on a publicly-released LLM checkpoint, the availability of the original training data may be non-existent. To address this challenge, we propose a framework called Self-Synthesized Rehearsal (SSR) that uses the LLM to generate synthetic instances for rehearsal. Concretely, we first employ the base LLM for in-context learning to generate synthetic instances. Subsequently, we utilize the latest LLM to refine the instance outputs based on the synthetic inputs, preserving its acquired ability. Finally, we select diverse high-quality synthetic instances for rehearsal in future stages. Experimental results demonstrate that SSR achieves superior or comparable performance compared to conventional rehearsal-based approaches while being more data-efficient. Besides, SSR effectively preserves the generalization capabilities of LLMs in general domains.","sentences":["Large language models (LLMs) suffer from catastrophic forgetting during continual learning.","Conventional rehearsal-based methods rely on previous training data to retain the model's ability, which may not be feasible in real-world applications.","When conducting continual learning based on a publicly-released LLM checkpoint, the availability of the original training data may be non-existent.","To address this challenge, we propose a framework called Self-Synthesized Rehearsal (SSR) that uses the LLM to generate synthetic instances for rehearsal.","Concretely, we first employ the base LLM for in-context learning to generate synthetic instances.","Subsequently, we utilize the latest LLM to refine the instance outputs based on the synthetic inputs, preserving its acquired ability.","Finally, we select diverse high-quality synthetic instances for rehearsal in future stages.","Experimental results demonstrate that SSR achieves superior or comparable performance compared to conventional rehearsal-based approaches while being more data-efficient.","Besides, SSR effectively preserves the generalization capabilities of LLMs in general domains."],"url":"http://arxiv.org/abs/2403.01244v1","category":"cs.CL"}
{"created":"2024-03-02 16:10:12","title":"Simulating chiral spin liquids with fermionic Projected Entangled Paired States","abstract":"Chiral Spin Liquids (CSL) based on spin-1/2 fermionic Projected Entangled Pair States (fPEPS) are considered on the square lattice. First, fPEPS approximants of Gutzwiller-projected Chern insulators (GPCI) are investigated by Variational Monte Carlo (VMC) techniques on finite size tori. We show that such fPEPS of finite bond dimension can correctly capture the topological properties of the chiral spin liquid, as the exact GPCI, with the correct topological ground state degeneracy on the torus. Further, more general fPEPS are considered and optimized (on the infinite plane) to describe the CSL phase of a chiral frustrated Heisenberg antiferromagnet. The chiral modes are computed on the edge of a semi-infinite cylinder (of finite circumference) and shown to follow the predictions from Conformal Field Theory. In contrast to their bosonic analogs the (optimized) fPEPS do not suffer from the replication of the chiral edge mode in the odd topological sector.","sentences":["Chiral Spin Liquids (CSL) based on spin-1/2 fermionic Projected Entangled Pair States (fPEPS) are considered on the square lattice.","First, fPEPS approximants of Gutzwiller-projected Chern insulators (GPCI) are investigated by Variational Monte Carlo (VMC) techniques on finite size tori.","We show that such fPEPS of finite bond dimension can correctly capture the topological properties of the chiral spin liquid, as the exact GPCI, with the correct topological ground state degeneracy on the torus.","Further, more general fPEPS are considered and optimized (on the infinite plane) to describe the CSL phase of a chiral frustrated Heisenberg antiferromagnet.","The chiral modes are computed on the edge of a semi-infinite cylinder (of finite circumference) and shown to follow the predictions from Conformal Field Theory.","In contrast to their bosonic analogs the (optimized) fPEPS do not suffer from the replication of the chiral edge mode in the odd topological sector."],"url":"http://arxiv.org/abs/2403.01243v1","category":"cond-mat.str-el"}
{"created":"2024-03-02 16:06:03","title":"Augmenting Automation: Intent-Based User Instruction Classification with Machine Learning","abstract":"Electric automation systems offer convenience and efficiency in controlling electrical circuits and devices. Traditionally, these systems rely on predefined commands for control, limiting flexibility and adaptability. In this paper, we propose a novel approach to augment automation by introducing intent-based user instruction classification using machine learning techniques. Our system represents user instructions as intents, allowing for dynamic control of electrical circuits without relying on predefined commands. Through a machine learning model trained on a labeled dataset of user instructions, our system classifies intents from user input, enabling a more intuitive and adaptable control scheme. We present the design and implementation of our intent-based electric automation system, detailing the development of the machine learning model for intent classification. Experimental results demonstrate the effectiveness of our approach in enhancing user experience and expanding the capabilities of electric automation systems. Our work contributes to the advancement of smart technologies by providing a more seamless interaction between users and their environments.","sentences":["Electric automation systems offer convenience and efficiency in controlling electrical circuits and devices.","Traditionally, these systems rely on predefined commands for control, limiting flexibility and adaptability.","In this paper, we propose a novel approach to augment automation by introducing intent-based user instruction classification using machine learning techniques.","Our system represents user instructions as intents, allowing for dynamic control of electrical circuits without relying on predefined commands.","Through a machine learning model trained on a labeled dataset of user instructions, our system classifies intents from user input, enabling a more intuitive and adaptable control scheme.","We present the design and implementation of our intent-based electric automation system, detailing the development of the machine learning model for intent classification.","Experimental results demonstrate the effectiveness of our approach in enhancing user experience and expanding the capabilities of electric automation systems.","Our work contributes to the advancement of smart technologies by providing a more seamless interaction between users and their environments."],"url":"http://arxiv.org/abs/2403.01242v1","category":"cs.LG"}
{"created":"2024-03-02 16:05:26","title":"IntactKV: Improving Large Language Model Quantization by Keeping Pivot Tokens Intact","abstract":"Large language models (LLMs) excel in natural language processing but demand intensive computation. To mitigate this, various quantization methods have been explored, yet they compromise LLM performance. This paper unveils a previously overlooked type of outlier in LLMs. Such outliers are found to allocate most of the attention scores on initial tokens of input, termed as pivot tokens, which is crucial to the performance of quantized LLMs. Given that, we propose IntactKV to generate the KV cache of pivot tokens losslessly from the full-precision model. The approach is simple and easy to combine with existing quantization solutions. Besides, IntactKV can be calibrated as additional LLM parameters to boost the quantized LLMs further. Mathematical analysis also proves that IntactKV effectively reduces the upper bound of quantization error. Empirical results show that IntactKV brings consistent improvement and achieves lossless weight-only INT4 quantization on various downstream tasks, leading to the new state-of-the-art for LLM quantization.","sentences":["Large language models (LLMs) excel in natural language processing but demand intensive computation.","To mitigate this, various quantization methods have been explored, yet they compromise LLM performance.","This paper unveils a previously overlooked type of outlier in LLMs.","Such outliers are found to allocate most of the attention scores on initial tokens of input, termed as pivot tokens, which is crucial to the performance of quantized LLMs.","Given that, we propose IntactKV to generate the KV cache of pivot tokens losslessly from the full-precision model.","The approach is simple and easy to combine with existing quantization solutions.","Besides, IntactKV can be calibrated as additional LLM parameters to boost the quantized LLMs further.","Mathematical analysis also proves that IntactKV effectively reduces the upper bound of quantization error.","Empirical results show that IntactKV brings consistent improvement and achieves lossless weight-only INT4 quantization on various downstream tasks, leading to the new state-of-the-art for LLM quantization."],"url":"http://arxiv.org/abs/2403.01241v1","category":"cs.CL"}
{"created":"2024-03-02 15:52:57","title":"First-principle event reconstruction by time-charge readouts for the Taishan Antineutrino Observatory","abstract":"The Taishan Antineutrino Observatory (TAO) is a liquid-scintillator satellite experiment of the Jiangmen Underground Neutrino Observatory (JUNO) to measure the reference reactor neutrino spectrum with sub-percent energy resolution. We use inhomogeous Poisson process and Tweedie generalized linear model (GLM) to calibrate the detector response and the charge distribution of a SiPM. We develop a pure probabilistic method using time and charge of SiPMs from first principles to reconstruct point-like events in the TAO central detector. Thanks to our precise model and the high photo-coverage and quantum efficiency of the SiPM tiles at TAO, we achieve a vertex position resolution better than 16 mm and an energy resolution of about 2% at 1 MeV, marking the world's best performance of liquid scintillator detectors. Our methodology is applicable to other experiments that utilize PMTs for time and charge readouts.","sentences":["The Taishan Antineutrino Observatory (TAO) is a liquid-scintillator satellite experiment of the Jiangmen Underground Neutrino Observatory (JUNO) to measure the reference reactor neutrino spectrum with sub-percent energy resolution.","We use inhomogeous Poisson process and Tweedie generalized linear model (GLM) to calibrate the detector response and the charge distribution of a SiPM.","We develop a pure probabilistic method using time and charge of SiPMs from first principles to reconstruct point-like events in the TAO central detector.","Thanks to our precise model and the high photo-coverage and quantum efficiency of the SiPM tiles at TAO, we achieve a vertex position resolution better than 16 mm and an energy resolution of about 2% at 1 MeV, marking the world's best performance of liquid scintillator detectors.","Our methodology is applicable to other experiments that utilize PMTs for time and charge readouts."],"url":"http://arxiv.org/abs/2403.01239v1","category":"hep-ex"}
{"created":"2024-03-02 15:32:01","title":"Polynormer: Polynomial-Expressive Graph Transformer in Linear Time","abstract":"Graph transformers (GTs) have emerged as a promising architecture that is theoretically more expressive than message-passing graph neural networks (GNNs). However, typical GT models have at least quadratic complexity and thus cannot scale to large graphs. While there are several linear GTs recently proposed, they still lag behind GNN counterparts on several popular graph datasets, which poses a critical concern on their practical expressivity. To balance the trade-off between expressivity and scalability of GTs, we propose Polynormer, a polynomial-expressive GT model with linear complexity. Polynormer is built upon a novel base model that learns a high-degree polynomial on input features. To enable the base model permutation equivariant, we integrate it with graph topology and node features separately, resulting in local and global equivariant attention models. Consequently, Polynormer adopts a linear local-to-global attention scheme to learn high-degree equivariant polynomials whose coefficients are controlled by attention scores. Polynormer has been evaluated on $13$ homophilic and heterophilic datasets, including large graphs with millions of nodes. Our extensive experiment results show that Polynormer outperforms state-of-the-art GNN and GT baselines on most datasets, even without the use of nonlinear activation functions.","sentences":["Graph transformers (GTs) have emerged as a promising architecture that is theoretically more expressive than message-passing graph neural networks (GNNs).","However, typical GT models have at least quadratic complexity and thus cannot scale to large graphs.","While there are several linear GTs recently proposed, they still lag behind GNN counterparts on several popular graph datasets, which poses a critical concern on their practical expressivity.","To balance the trade-off between expressivity and scalability of GTs, we propose Polynormer, a polynomial-expressive GT model with linear complexity.","Polynormer is built upon a novel base model that learns a high-degree polynomial on input features.","To enable the base model permutation equivariant, we integrate it with graph topology and node features separately, resulting in local and global equivariant attention models.","Consequently, Polynormer adopts a linear local-to-global attention scheme to learn high-degree equivariant polynomials whose coefficients are controlled by attention scores.","Polynormer has been evaluated on $13$ homophilic and heterophilic datasets, including large graphs with millions of nodes.","Our extensive experiment results show that Polynormer outperforms state-of-the-art GNN and GT baselines on most datasets, even without the use of nonlinear activation functions."],"url":"http://arxiv.org/abs/2403.01232v1","category":"cs.LG"}
{"created":"2024-03-02 15:14:58","title":"REWIND Dataset: Privacy-preserving Speaking Status Segmentation from Multimodal Body Movement Signals in the Wild","abstract":"Recognizing speaking in humans is a central task towards understanding social interactions. Ideally, speaking would be detected from individual voice recordings, as done previously for meeting scenarios. However, individual voice recordings are hard to obtain in the wild, especially in crowded mingling scenarios due to cost, logistics, and privacy concerns. As an alternative, machine learning models trained on video and wearable sensor data make it possible to recognize speech by detecting its related gestures in an unobtrusive, privacy-preserving way. These models themselves should ideally be trained using labels obtained from the speech signal. However, existing mingling datasets do not contain high quality audio recordings. Instead, speaking status annotations have often been inferred by human annotators from video, without validation of this approach against audio-based ground truth. In this paper we revisit no-audio speaking status estimation by presenting the first publicly available multimodal dataset with high-quality individual speech recordings of 33 subjects in a professional networking event. We present three baselines for no-audio speaking status segmentation: a) from video, b) from body acceleration (chest-worn accelerometer), c) from body pose tracks. In all cases we predict a 20Hz binary speaking status signal extracted from the audio, a time resolution not available in previous datasets. In addition to providing the signals and ground truth necessary to evaluate a wide range of speaking status detection methods, the availability of audio in REWIND makes it suitable for cross-modality studies not feasible with previous mingling datasets. Finally, our flexible data consent setup creates new challenges for multimodal systems under missing modalities.","sentences":["Recognizing speaking in humans is a central task towards understanding social interactions.","Ideally, speaking would be detected from individual voice recordings, as done previously for meeting scenarios.","However, individual voice recordings are hard to obtain in the wild, especially in crowded mingling scenarios due to cost, logistics, and privacy concerns.","As an alternative, machine learning models trained on video and wearable sensor data make it possible to recognize speech by detecting its related gestures in an unobtrusive, privacy-preserving way.","These models themselves should ideally be trained using labels obtained from the speech signal.","However, existing mingling datasets do not contain high quality audio recordings.","Instead, speaking status annotations have often been inferred by human annotators from video, without validation of this approach against audio-based ground truth.","In this paper we revisit no-audio speaking status estimation by presenting the first publicly available multimodal dataset with high-quality individual speech recordings of 33 subjects in a professional networking event.","We present three baselines for no-audio speaking status segmentation: a) from video, b) from body acceleration (chest-worn accelerometer), c) from body pose tracks.","In all cases we predict a 20Hz binary speaking status signal extracted from the audio, a time resolution not available in previous datasets.","In addition to providing the signals and ground truth necessary to evaluate a wide range of speaking status detection methods, the availability of audio in REWIND makes it suitable for cross-modality studies not feasible with previous mingling datasets.","Finally, our flexible data consent setup creates new challenges for multimodal systems under missing modalities."],"url":"http://arxiv.org/abs/2403.01229v1","category":"cs.CV"}
{"created":"2024-03-02 14:58:47","title":"Characterizations of $e^\\star$-open sets and nearby open sets on Infra topological spaces","abstract":"The study of infra-topological spaces focuses on characterizations of $e^\\star$-open sets and nearby open sets in infra-topological spaces. The $e^\\star$-open sets, a variation of open sets, are explored for their unique properties and relationships within the infra-topological framework. Additionally, nearby open sets, which capture the notion of points being close to each other, are investigated to provide a comprehensive understanding of the topological structure. The research aims to contribute to the broader field of topology by extending traditional concepts to infra-topological spaces, offering new perspectives on openness and proximity. The findings not only deepen our understanding of mathematical structures but also open avenues for applications in various scientific and engineering disciplines.","sentences":["The study of infra-topological spaces focuses on characterizations of $e^\\star$-open sets and nearby open sets in infra-topological spaces.","The $e^\\star$-open sets, a variation of open sets, are explored for their unique properties and relationships within the infra-topological framework.","Additionally, nearby open sets, which capture the notion of points being close to each other, are investigated to provide a comprehensive understanding of the topological structure.","The research aims to contribute to the broader field of topology by extending traditional concepts to infra-topological spaces, offering new perspectives on openness and proximity.","The findings not only deepen our understanding of mathematical structures but also open avenues for applications in various scientific and engineering disciplines."],"url":"http://arxiv.org/abs/2403.01228v1","category":"math.GN"}
{"created":"2024-03-02 14:52:58","title":"DiffSal: Joint Audio and Video Learning for Diffusion Saliency Prediction","abstract":"Audio-visual saliency prediction can draw support from diverse modality complements, but further performance enhancement is still challenged by customized architectures as well as task-specific loss functions. In recent studies, denoising diffusion models have shown more promising in unifying task frameworks owing to their inherent ability of generalization. Following this motivation, a novel Diffusion architecture for generalized audio-visual Saliency prediction (DiffSal) is proposed in this work, which formulates the prediction problem as a conditional generative task of the saliency map by utilizing input audio and video as the conditions. Based on the spatio-temporal audio-visual features, an extra network Saliency-UNet is designed to perform multi-modal attention modulation for progressive refinement of the ground-truth saliency map from the noisy map. Extensive experiments demonstrate that the proposed DiffSal can achieve excellent performance across six challenging audio-visual benchmarks, with an average relative improvement of 6.3\\% over the previous state-of-the-art results by six metrics.","sentences":["Audio-visual saliency prediction can draw support from diverse modality complements, but further performance enhancement is still challenged by customized architectures as well as task-specific loss functions.","In recent studies, denoising diffusion models have shown more promising in unifying task frameworks owing to their inherent ability of generalization.","Following this motivation, a novel Diffusion architecture for generalized audio-visual Saliency prediction (DiffSal) is proposed in this work, which formulates the prediction problem as a conditional generative task of the saliency map by utilizing input audio and video as the conditions.","Based on the spatio-temporal audio-visual features, an extra network Saliency-UNet is designed to perform multi-modal attention modulation for progressive refinement of the ground-truth saliency map from the noisy map.","Extensive experiments demonstrate that the proposed DiffSal can achieve excellent performance across six challenging audio-visual benchmarks, with an average relative improvement of 6.3\\% over the previous state-of-the-art results by six metrics."],"url":"http://arxiv.org/abs/2403.01226v1","category":"cs.CV"}
{"created":"2024-03-02 14:45:50","title":"Study of identified particle production as a function of transverse event activity classifier, $S_{T}$ in p$-$p collisions","abstract":"A new observable, $S_{T}$, is introduced in terms of the sum of the transverse momentum of charged particles ($\\sum_{i} p_{T_{i}}$ ) produced in proton proton (p$-$p) collisions at LHC energies to probe the underlying events (UE). The UE are defined as those aspects of proton-proton collisions that are not attributed to the primary hard scattering process, but rather to the accompanying interactions of the rest of the proton. The conventional approach of studying underlying events is usually carried out by defining topological regions with respect to the leading particle in an event. The transverse region is generally sensitive to UE and various classifiers have been used to discriminate the extent of UE activity regions. The production of identified particles like $\\pi^{\\pm}$, $K^{\\pm}$, p , $K_{S}^{0}$, and $\\Lambda^{0}$ are studied in different ranges of transverse activity classifier in p$-$p collisions at $\\sqrt{s} = 13 $ TeV using pQCD inspired PYTHIA 8 event generator. A comparative analysis of the identified particle spectra, mean multiplicity and mean transverse momentum has been carried out with respect to $S_{T}$ and the performance of this new observable is gauged by comparing the results with previously defined $R_{T}$ observable.","sentences":["A new observable, $S_{T}$, is introduced in terms of the sum of the transverse momentum of charged particles ($\\sum_{i} p_{T_{i}}$ ) produced in proton proton (p$-$p) collisions at LHC energies to probe the underlying events (UE).","The UE are defined as those aspects of proton-proton collisions that are not attributed to the primary hard scattering process, but rather to the accompanying interactions of the rest of the proton.","The conventional approach of studying underlying events is usually carried out by defining topological regions with respect to the leading particle in an event.","The transverse region is generally sensitive to UE and various classifiers have been used to discriminate the extent of UE activity regions.","The production of identified particles like $\\pi^{\\pm}$, $K^{\\pm}$, p , $K_{S}^{0}$, and $\\Lambda^{0}$ are studied in different ranges of transverse activity classifier in p$-$p collisions at $\\sqrt{s} = 13 $ TeV using pQCD inspired PYTHIA 8 event generator.","A comparative analysis of the identified particle spectra, mean multiplicity and mean transverse momentum has been carried out with respect to $S_{T}$ and the performance of this new observable is gauged by comparing the results with previously defined $R_{T}$ observable."],"url":"http://arxiv.org/abs/2403.01224v1","category":"hep-ph"}
{"created":"2024-03-02 14:30:57","title":"A Two-Stage Algorithm for Cost-Efficient Multi-instance Counterfactual Explanations","abstract":"Counterfactual explanations constitute among the most popular methods for analyzing the predictions of black-box systems since they can recommend cost-efficient and actionable changes to the input to turn an undesired system's output into a desired output. While most of the existing counterfactual methods explain a single instance, several real-world use cases, such as customer satisfaction, require the identification of a single counterfactual that can satisfy multiple instances (e.g. customers) simultaneously. In this work, we propose a flexible two-stage algorithm for finding groups of instances along with cost-efficient multi-instance counterfactual explanations. This is motivated by the fact that in most previous works the aspect of finding such groups is not addressed.","sentences":["Counterfactual explanations constitute among the most popular methods for analyzing the predictions of black-box systems since they can recommend cost-efficient and actionable changes to the input to turn an undesired system's output into a desired output.","While most of the existing counterfactual methods explain a single instance, several real-world use cases, such as customer satisfaction, require the identification of a single counterfactual that can satisfy multiple instances (e.g. customers) simultaneously.","In this work, we propose a flexible two-stage algorithm for finding groups of instances along with cost-efficient multi-instance counterfactual explanations.","This is motivated by the fact that in most previous works the aspect of finding such groups is not addressed."],"url":"http://arxiv.org/abs/2403.01221v1","category":"cs.LG"}
{"created":"2024-03-02 14:14:45","title":"API Is Enough: Conformal Prediction for Large Language Models Without Logit-Access","abstract":"This study aims to address the pervasive challenge of quantifying uncertainty in large language models (LLMs) without logit-access. Conformal Prediction (CP), known for its model-agnostic and distribution-free features, is a desired approach for various LLMs and data distributions. However, existing CP methods for LLMs typically assume access to the logits, which are unavailable for some API-only LLMs. In addition, logits are known to be miscalibrated, potentially leading to degraded CP performance. To tackle these challenges, we introduce a novel CP method that (1) is tailored for API-only LLMs without logit-access; (2) minimizes the size of prediction sets; and (3) ensures a statistical guarantee of the user-defined coverage. The core idea of this approach is to formulate nonconformity measures using both coarse-grained (i.e., sample frequency) and fine-grained uncertainty notions (e.g., semantic similarity). Experimental results on both close-ended and open-ended Question Answering tasks show our approach can mostly outperform the logit-based CP baselines.","sentences":["This study aims to address the pervasive challenge of quantifying uncertainty in large language models (LLMs) without logit-access.","Conformal Prediction (CP), known for its model-agnostic and distribution-free features, is a desired approach for various LLMs and data distributions.","However, existing CP methods for LLMs typically assume access to the logits, which are unavailable for some API-only LLMs.","In addition, logits are known to be miscalibrated, potentially leading to degraded CP performance.","To tackle these challenges, we introduce a novel CP method that (1) is tailored for API-only LLMs without logit-access; (2) minimizes the size of prediction sets; and (3) ensures a statistical guarantee of the user-defined coverage.","The core idea of this approach is to formulate nonconformity measures using both coarse-grained (i.e., sample frequency) and fine-grained uncertainty notions (e.g., semantic similarity).","Experimental results on both close-ended and open-ended Question Answering tasks show our approach can mostly outperform the logit-based CP baselines."],"url":"http://arxiv.org/abs/2403.01216v1","category":"cs.CL"}
{"created":"2024-03-02 14:05:15","title":"Boosting Box-supervised Instance Segmentation with Pseudo Depth","abstract":"The realm of Weakly Supervised Instance Segmentation (WSIS) under box supervision has garnered substantial attention, showcasing remarkable advancements in recent years. However, the limitations of box supervision become apparent in its inability to furnish effective information for distinguishing foreground from background within the specified target box. This research addresses this challenge by introducing pseudo-depth maps into the training process of the instance segmentation network, thereby boosting its performance by capturing depth differences between instances. These pseudo-depth maps are generated using a readily available depth predictor and are not necessary during the inference stage. To enable the network to discern depth features when predicting masks, we integrate a depth prediction layer into the mask prediction head. This innovative approach empowers the network to simultaneously predict masks and depth, enhancing its ability to capture nuanced depth-related information during the instance segmentation process. We further utilize the mask generated in the training process as supervision to distinguish the foreground from the background. When selecting the best mask for each box through the Hungarian algorithm, we use depth consistency as one calculation cost item. The proposed method achieves significant improvements on Cityscapes and COCO dataset.","sentences":["The realm of Weakly Supervised Instance Segmentation (WSIS) under box supervision has garnered substantial attention, showcasing remarkable advancements in recent years.","However, the limitations of box supervision become apparent in its inability to furnish effective information for distinguishing foreground from background within the specified target box.","This research addresses this challenge by introducing pseudo-depth maps into the training process of the instance segmentation network, thereby boosting its performance by capturing depth differences between instances.","These pseudo-depth maps are generated using a readily available depth predictor and are not necessary during the inference stage.","To enable the network to discern depth features when predicting masks, we integrate a depth prediction layer into the mask prediction head.","This innovative approach empowers the network to simultaneously predict masks and depth, enhancing its ability to capture nuanced depth-related information during the instance segmentation process.","We further utilize the mask generated in the training process as supervision to distinguish the foreground from the background.","When selecting the best mask for each box through the Hungarian algorithm, we use depth consistency as one calculation cost item.","The proposed method achieves significant improvements on Cityscapes and COCO dataset."],"url":"http://arxiv.org/abs/2403.01214v1","category":"cs.CV"}
{"created":"2024-03-02 13:59:02","title":"TCIG: Two-Stage Controlled Image Generation with Quality Enhancement through Diffusion","abstract":"In recent years, significant progress has been made in the development of text- to-image generation models. However, these models still face limitations when it comes to achieving full controllability during the generation process. Often, spe- cific training or the use of limited models is required, and even then, they have certain restrictions. To address these challenges, A two-stage method that effec- tively combines controllability and high quality in the generation of images is proposed. This approach leverages the expertise of pre-trained models to achieve precise control over the generated images, while also harnessing the power of diffusion models to achieve state-of-the-art quality. By separating controllability from high quality, This method achieves outstanding results. It is compatible with both latent and image space diffusion models, ensuring versatility and flexibil- ity. Moreover, This approach consistently produces comparable outcomes to the current state-of-the-art methods in the field. Overall, This proposed method rep- resents a significant advancement in text-to-image generation, enabling improved controllability without compromising on the quality of the generated images.","sentences":["In recent years, significant progress has been made in the development of text- to-image generation models.","However, these models still face limitations when it comes to achieving full controllability during the generation process.","Often, spe- cific training or the use of limited models is required, and even then, they have certain restrictions.","To address these challenges, A two-stage method that effec- tively combines controllability and high quality in the generation of images is proposed.","This approach leverages the expertise of pre-trained models to achieve precise control over the generated images, while also harnessing the power of diffusion models to achieve state-of-the-art quality.","By separating controllability from high quality, This method achieves outstanding results.","It is compatible with both latent and image space diffusion models, ensuring versatility and flexibil- ity.","Moreover, This approach consistently produces comparable outcomes to the current state-of-the-art methods in the field.","Overall, This proposed method rep- resents a significant advancement in text-to-image generation, enabling improved controllability without compromising on the quality of the generated images."],"url":"http://arxiv.org/abs/2403.01212v1","category":"cs.CV"}
{"created":"2024-03-02 13:57:25","title":"Electric polarization evolution equation for antiferromagnetic multiferroics with the polarization proportional to the scalar product of the spins","abstract":"The spin current model of electric polarization of multiferroics is justified via the quantum hydrodynamic method and the mean-field part of the spin-orbit interaction. The spin current model is applied to derive the electric polarization proportional to the scalar product of the spins of the near by ions, which appears to be caused by the Dzylaoshinskii-Moriya interaction. Symmetric tensor spin structure of the polarization is discussed as well. We start our derivations for the ferromagnetic multiferroic materials and present the further generalization for the antiferromagnetic multiferroic materials. We rederive the operator of the electric dipole moment, which provides the macroscopic polarization obtained via the spin current model. Finally, we use the quantum average of the found electric dipole moment operator in order to derive the polarization evolution equation for the antiferromagnetic multiferroic materials. Possibility of spiral spin structures is analyzed.","sentences":["The spin current model of electric polarization of multiferroics is justified via the quantum hydrodynamic method and the mean-field part of the spin-orbit interaction.","The spin current model is applied to derive the electric polarization proportional to the scalar product of the spins of the near by ions, which appears to be caused by the Dzylaoshinskii-Moriya interaction.","Symmetric tensor spin structure of the polarization is discussed as well.","We start our derivations for the ferromagnetic multiferroic materials and present the further generalization for the antiferromagnetic multiferroic materials.","We rederive the operator of the electric dipole moment, which provides the macroscopic polarization obtained via the spin current model.","Finally, we use the quantum average of the found electric dipole moment operator in order to derive the polarization evolution equation for the antiferromagnetic multiferroic materials.","Possibility of spiral spin structures is analyzed."],"url":"http://arxiv.org/abs/2403.01211v1","category":"cond-mat.mtrl-sci"}
{"created":"2024-03-02 13:52:28","title":"SAR-AE-SFP: SAR Imagery Adversarial Example in Real Physics domain with Target Scattering Feature Parameters","abstract":"Deep neural network-based Synthetic Aperture Radar (SAR) target recognition models are susceptible to adversarial examples. Current adversarial example generation methods for SAR imagery primarily operate in the 2D digital domain, known as image adversarial examples. Recent work, while considering SAR imaging scatter mechanisms, fails to account for the actual imaging process, rendering attacks in the three-dimensional physical domain infeasible, termed pseudo physics adversarial examples. To address these challenges, this paper proposes SAR-AE-SFP-Attack, a method to generate real physics adversarial examples by altering the scattering feature parameters of target objects. Specifically, we iteratively optimize the coherent energy accumulation of the target echo by perturbing the reflection coefficient and scattering coefficient in the scattering feature parameters of the three-dimensional target object, and obtain the adversarial example after echo signal processing and imaging processing in the RaySAR simulator. Experimental results show that compared to digital adversarial attack methods, SAR-AE-SFP Attack significantly improves attack efficiency on CNN-based models (over 30\\%) and Transformer-based models (over 13\\%), demonstrating significant transferability of attack effects across different models and perspectives.","sentences":["Deep neural network-based Synthetic Aperture Radar (SAR) target recognition models are susceptible to adversarial examples.","Current adversarial example generation methods for SAR imagery primarily operate in the 2D digital domain, known as image adversarial examples.","Recent work, while considering SAR imaging scatter mechanisms, fails to account for the actual imaging process, rendering attacks in the three-dimensional physical domain infeasible, termed pseudo physics adversarial examples.","To address these challenges, this paper proposes SAR-AE-SFP-Attack, a method to generate real physics adversarial examples by altering the scattering feature parameters of target objects.","Specifically, we iteratively optimize the coherent energy accumulation of the target echo by perturbing the reflection coefficient and scattering coefficient in the scattering feature parameters of the three-dimensional target object, and obtain the adversarial example after echo signal processing and imaging processing in the RaySAR simulator.","Experimental results show that compared to digital adversarial attack methods, SAR-AE-SFP Attack significantly improves attack efficiency on CNN-based models (over 30\\%) and Transformer-based models (over 13\\%), demonstrating significant transferability of attack effects across different models and perspectives."],"url":"http://arxiv.org/abs/2403.01210v1","category":"cs.CV"}
{"created":"2024-03-02 12:44:59","title":"Pseudo-Label Calibration Semi-supervised Multi-Modal Entity Alignment","abstract":"Multi-modal entity alignment (MMEA) aims to identify equivalent entities between two multi-modal knowledge graphs for integration. Unfortunately, prior arts have attempted to improve the interaction and fusion of multi-modal information, which have overlooked the influence of modal-specific noise and the usage of labeled and unlabeled data in semi-supervised settings. In this work, we introduce a Pseudo-label Calibration Multi-modal Entity Alignment (PCMEA) in a semi-supervised way. Specifically, in order to generate holistic entity representations, we first devise various embedding modules and attention mechanisms to extract visual, structural, relational, and attribute features. Different from the prior direct fusion methods, we next propose to exploit mutual information maximization to filter the modal-specific noise and to augment modal-invariant commonality. Then, we combine pseudo-label calibration with momentum-based contrastive learning to make full use of the labeled and unlabeled data, which improves the quality of pseudo-label and pulls aligned entities closer. Finally, extensive experiments on two MMEA datasets demonstrate the effectiveness of our PCMEA, which yields state-of-the-art performance.","sentences":["Multi-modal entity alignment (MMEA) aims to identify equivalent entities between two multi-modal knowledge graphs for integration.","Unfortunately, prior arts have attempted to improve the interaction and fusion of multi-modal information, which have overlooked the influence of modal-specific noise and the usage of labeled and unlabeled data in semi-supervised settings.","In this work, we introduce a Pseudo-label Calibration Multi-modal Entity Alignment (PCMEA) in a semi-supervised way.","Specifically, in order to generate holistic entity representations, we first devise various embedding modules and attention mechanisms to extract visual, structural, relational, and attribute features.","Different from the prior direct fusion methods, we next propose to exploit mutual information maximization to filter the modal-specific noise and to augment modal-invariant commonality.","Then, we combine pseudo-label calibration with momentum-based contrastive learning to make full use of the labeled and unlabeled data, which improves the quality of pseudo-label and pulls aligned entities closer.","Finally, extensive experiments on two MMEA datasets demonstrate the effectiveness of our PCMEA, which yields state-of-the-art performance."],"url":"http://arxiv.org/abs/2403.01203v1","category":"cs.LG"}
{"created":"2024-03-02 12:41:11","title":"The Case for Animal-Friendly AI","abstract":"Artificial intelligence is seen as increasingly important, and potentially profoundly so, but the fields of AI ethics and AI engineering have not fully recognized that these technologies, including large language models (LLMs), will have massive impacts on animals. We argue that this impact matters, because animals matter morally.   As a first experiment in evaluating animal consideration in LLMs, we constructed a proof-of-concept Evaluation System, which assesses LLM responses and biases from multiple perspectives. This system evaluates LLM outputs by two criteria: their truthfulness, and the degree of consideration they give to the interests of animals. We tested OpenAI ChatGPT 4 and Anthropic Claude 2.1 using a set of structured queries and predefined normative perspectives. Preliminary results suggest that the outcomes of the tested models can be benchmarked regarding the consideration they give to animals, and that generated positions and biases might be addressed and mitigated with more developed and validated systems.   Our research contributes one possible approach to integrating animal ethics in AI, opening pathways for future studies and practical applications in various fields, including education, public policy, and regulation, that involve or relate to animals and society. Overall, this study serves as a step towards more useful and responsible AI systems that better recognize and respect the vital interests and perspectives of all sentient beings.","sentences":["Artificial intelligence is seen as increasingly important, and potentially profoundly so, but the fields of AI ethics and AI engineering have not fully recognized that these technologies, including large language models (LLMs), will have massive impacts on animals.","We argue that this impact matters, because animals matter morally.   ","As a first experiment in evaluating animal consideration in LLMs, we constructed a proof-of-concept Evaluation System, which assesses LLM responses and biases from multiple perspectives.","This system evaluates LLM outputs by two criteria: their truthfulness, and the degree of consideration they give to the interests of animals.","We tested OpenAI ChatGPT 4 and Anthropic Claude 2.1 using a set of structured queries and predefined normative perspectives.","Preliminary results suggest that the outcomes of the tested models can be benchmarked regarding the consideration they give to animals, and that generated positions and biases might be addressed and mitigated with more developed and validated systems.   ","Our research contributes one possible approach to integrating animal ethics in AI, opening pathways for future studies and practical applications in various fields, including education, public policy, and regulation, that involve or relate to animals and society.","Overall, this study serves as a step towards more useful and responsible AI systems that better recognize and respect the vital interests and perspectives of all sentient beings."],"url":"http://arxiv.org/abs/2403.01199v1","category":"cs.AI"}
{"created":"2024-03-02 12:31:22","title":"DMoERM: Recipes of Mixture-of-Experts for Effective Reward Modeling","abstract":"The performance of the reward model (RM) is a critical factor in improving the effectiveness of the large language model (LLM) during alignment fine-tuning. There remain two challenges in RM training: 1) training the same RM using various categories of data may cause its generalization performance to suffer from multi-task disturbance, and 2) the human annotation consistency rate is generally only $60\\%$ to $75\\%$, causing training data to contain a lot of noise. To tackle these two challenges, we introduced the idea of Mixture-of-Experts (MoE) into the field of RM for the first time. We propose the Double-Layer MoE RM (DMoERM). The outer layer MoE is a sparse model. After classifying an input into task categories, we route it to the corresponding inner layer task-specific model. The inner layer MoE is a dense model. We decompose the specific task into multiple capability dimensions and individually fine-tune a LoRA expert on each one. Their outputs are then synthesized by an MLP to compute the final rewards. To minimize costs, we call a public LLM API to obtain the capability preference labels. The validation on manually labeled datasets confirms that our model attains superior consistency with human preference and outstrips advanced generative approaches. Meanwhile, through BoN sampling and RL experiments, we demonstrate that our model outperforms state-of-the-art ensemble methods of RM and mitigates the overoptimization problem. Our code and dataset are available at: https://github.com/quanshr/DMoERM-v1.","sentences":["The performance of the reward model (RM) is a critical factor in improving the effectiveness of the large language model (LLM) during alignment fine-tuning.","There remain two challenges in RM training: 1) training the same RM using various categories of data may cause its generalization performance to suffer from multi-task disturbance, and 2) the human annotation consistency rate is generally only $60\\%$ to $75\\%$, causing training data to contain a lot of noise.","To tackle these two challenges, we introduced the idea of Mixture-of-Experts (MoE) into the field of RM for the first time.","We propose the Double-Layer MoE RM (DMoERM).","The outer layer MoE is a sparse model.","After classifying an input into task categories, we route it to the corresponding inner layer task-specific model.","The inner layer MoE is a dense model.","We decompose the specific task into multiple capability dimensions and individually fine-tune a LoRA expert on each one.","Their outputs are then synthesized by an MLP to compute the final rewards.","To minimize costs, we call a public LLM API to obtain the capability preference labels.","The validation on manually labeled datasets confirms that our model attains superior consistency with human preference and outstrips advanced generative approaches.","Meanwhile, through BoN sampling and RL experiments, we demonstrate that our model outperforms state-of-the-art ensemble methods of RM and mitigates the overoptimization problem.","Our code and dataset are available at: https://github.com/quanshr/DMoERM-v1."],"url":"http://arxiv.org/abs/2403.01197v1","category":"cs.CL"}
{"created":"2024-03-02 12:29:28","title":"Machine Translation in the Covid domain: an English-Irish case study for LoResMT 2021","abstract":"Translation models for the specific domain of translating Covid data from English to Irish were developed for the LoResMT 2021 shared task. Domain adaptation techniques, using a Covid-adapted generic 55k corpus from the Directorate General of Translation, were applied. Fine-tuning, mixed fine-tuning and combined dataset approaches were compared with models trained on an extended in-domain dataset. As part of this study, an English-Irish dataset of Covid related data, from the Health and Education domains, was developed. The highest-performing model used a Transformer architecture trained with an extended in-domain Covid dataset. In the context of this study, we have demonstrated that extending an 8k in-domain baseline dataset by just 5k lines improved the BLEU score by 27 points.","sentences":["Translation models for the specific domain of translating Covid data from English to Irish were developed for the LoResMT 2021 shared task.","Domain adaptation techniques, using a Covid-adapted generic 55k corpus from the Directorate General of Translation, were applied.","Fine-tuning, mixed fine-tuning and combined dataset approaches were compared with models trained on an extended in-domain dataset.","As part of this study, an English-Irish dataset of Covid related data, from the Health and Education domains, was developed.","The highest-performing model used a Transformer architecture trained with an extended in-domain Covid dataset.","In the context of this study, we have demonstrated that extending an 8k in-domain baseline dataset by just 5k lines improved the BLEU score by 27 points."],"url":"http://arxiv.org/abs/2403.01196v1","category":"cs.CL"}
{"created":"2024-03-02 12:21:24","title":"A Comparative Study of Rapidly-exploring Random Tree Algorithms Applied to Ship Trajectory Planning and Behavior Generation","abstract":"Rapidly Exploring Random Tree (RRT) algorithms are popular for sampling-based planning for nonholonomic vehicles in unstructured environments. However, we argue that previous work does not illuminate the challenges when employing such algorithms. Thus, in this article, we do a first comparison study of the performance of the following previously proposed RRT algorithm variants; Potential-Quick RRT* (PQ-RRT*), Informed RRT* (IRRT*), RRT* and RRT, for single-query nonholonomic motion planning over several cases in the unstructured maritime environment. The practicalities of employing such algorithms in the maritime domain are also discussed. On the side, we contend that these algorithms offer value not only for Collision Avoidance Systems (CAS) trajectory planning, but also for the verification of CAS through vessel behavior generation.   Naturally, optimal RRT variants yield more distance-optimal paths at the cost of increased computational time due to the tree wiring process with nearest neighbor consideration. PQ-RRT* achieves marginally better results than IRRT* and RRT*, at the cost of higher tuning complexity and increased wiring time. Based on the results, we argue that for time-critical applications the considered RRT algorithms are, as stand-alone planners, more suitable for use in smaller problems or problems with low obstacle congestion ratio. This is attributed to the curse of dimensionality, and trade-off with available memory and computational resources.","sentences":["Rapidly Exploring Random Tree (RRT) algorithms are popular for sampling-based planning for nonholonomic vehicles in unstructured environments.","However, we argue that previous work does not illuminate the challenges when employing such algorithms.","Thus, in this article, we do a first comparison study of the performance of the following previously proposed RRT algorithm variants; Potential-Quick RRT* (PQ-RRT*), Informed RRT* (IRRT*), RRT* and RRT, for single-query nonholonomic motion planning over several cases in the unstructured maritime environment.","The practicalities of employing such algorithms in the maritime domain are also discussed.","On the side, we contend that these algorithms offer value not only for Collision Avoidance Systems (CAS) trajectory planning, but also for the verification of CAS through vessel behavior generation.   ","Naturally, optimal RRT variants yield more distance-optimal paths at the cost of increased computational time due to the tree wiring process with nearest neighbor consideration.","PQ-RRT* achieves marginally better results than IRRT* and RRT*, at the cost of higher tuning complexity and increased wiring time.","Based on the results, we argue that for time-critical applications the considered RRT algorithms are, as stand-alone planners, more suitable for use in smaller problems or problems with low obstacle congestion ratio.","This is attributed to the curse of dimensionality, and trade-off with available memory and computational resources."],"url":"http://arxiv.org/abs/2403.01194v1","category":"cs.RO"}
{"created":"2024-03-02 12:19:04","title":"RAGged Edges: The Double-Edged Sword of Retrieval-Augmented Chatbots","abstract":"Large language models (LLMs) like ChatGPT demonstrate the remarkable progress of artificial intelligence. However, their tendency to hallucinate -- generate plausible but false information -- poses a significant challenge. This issue is critical, as seen in recent court cases where ChatGPT's use led to citations of non-existent legal rulings. This paper explores how Retrieval-Augmented Generation (RAG) can counter hallucinations by integrating external knowledge with prompts. We empirically evaluate RAG against standard LLMs using prompts designed to induce hallucinations. Our results show that RAG increases accuracy in some cases, but can still be misled when prompts directly contradict the model's pre-trained understanding. These findings highlight the complex nature of hallucinations and the need for more robust solutions to ensure LLM reliability in real-world applications. We offer practical recommendations for RAG deployment and discuss implications for the development of more trustworthy LLMs.","sentences":["Large language models (LLMs) like ChatGPT demonstrate the remarkable progress of artificial intelligence.","However, their tendency to hallucinate -- generate plausible but false information -- poses a significant challenge.","This issue is critical, as seen in recent court cases where ChatGPT's use led to citations of non-existent legal rulings.","This paper explores how Retrieval-Augmented Generation (RAG) can counter hallucinations by integrating external knowledge with prompts.","We empirically evaluate RAG against standard LLMs using prompts designed to induce hallucinations.","Our results show that RAG increases accuracy in some cases, but can still be misled when prompts directly contradict the model's pre-trained understanding.","These findings highlight the complex nature of hallucinations and the need for more robust solutions to ensure LLM reliability in real-world applications.","We offer practical recommendations for RAG deployment and discuss implications for the development of more trustworthy LLMs."],"url":"http://arxiv.org/abs/2403.01193v1","category":"cs.CL"}
{"created":"2024-03-02 12:12:04","title":"A Composite Decomposition Method for Large-Scale Global Optimization","abstract":"Cooperative co-evolution (CC) algorithms, based on the divide-and-conquer strategy, have emerged as the predominant approach to solving large-scale global optimization (LSGO) problems. The efficiency and accuracy of the grouping stage significantly impact the performance of the optimization process. While the general separability grouping (GSG) method has overcome the limitation of previous differential grouping (DG) methods by enabling the decomposition of non-additively separable functions, it suffers from high computational complexity. To address this challenge, this article proposes a composite separability grouping (CSG) method, seamlessly integrating DG and GSG into a problem decomposition framework to utilize the strengths of both approaches. CSG introduces a step-by-step decomposition framework that accurately decomposes various problem types using fewer computational resources. By sequentially identifying additively, multiplicatively and generally separable variables, CSG progressively groups non-separable variables by recursively considering the interactions between each non-separable variable and the formed non-separable groups. Furthermore, to enhance the efficiency and accuracy of CSG, we introduce two innovative methods: a multiplicatively separable variable detection method and a non-separable variable grouping method. These two methods are designed to effectively detect multiplicatively separable variables and efficiently group non-separable variables, respectively. Extensive experimental results demonstrate that CSG achieves more accurate variable grouping with lower computational complexity compared to GSG and state-of-the-art DG series designs.","sentences":["Cooperative co-evolution (CC) algorithms, based on the divide-and-conquer strategy, have emerged as the predominant approach to solving large-scale global optimization (LSGO) problems.","The efficiency and accuracy of the grouping stage significantly impact the performance of the optimization process.","While the general separability grouping (GSG) method has overcome the limitation of previous differential grouping (DG) methods by enabling the decomposition of non-additively separable functions, it suffers from high computational complexity.","To address this challenge, this article proposes a composite separability grouping (CSG) method, seamlessly integrating DG and GSG into a problem decomposition framework to utilize the strengths of both approaches.","CSG introduces a step-by-step decomposition framework that accurately decomposes various problem types using fewer computational resources.","By sequentially identifying additively, multiplicatively and generally separable variables, CSG progressively groups non-separable variables by recursively considering the interactions between each non-separable variable and the formed non-separable groups.","Furthermore, to enhance the efficiency and accuracy of CSG, we introduce two innovative methods: a multiplicatively separable variable detection method and a non-separable variable grouping method.","These two methods are designed to effectively detect multiplicatively separable variables and efficiently group non-separable variables, respectively.","Extensive experimental results demonstrate that CSG achieves more accurate variable grouping with lower computational complexity compared to GSG and state-of-the-art DG series designs."],"url":"http://arxiv.org/abs/2403.01192v1","category":"math.OC"}
{"created":"2024-03-02 12:06:42","title":"Training Unbiased Diffusion Models From Biased Dataset","abstract":"With significant advancements in diffusion models, addressing the potential risks of dataset bias becomes increasingly important. Since generated outputs directly suffer from dataset bias, mitigating latent bias becomes a key factor in improving sample quality and proportion. This paper proposes time-dependent importance reweighting to mitigate the bias for the diffusion models. We demonstrate that the time-dependent density ratio becomes more precise than previous approaches, thereby minimizing error propagation in generative learning. While directly applying it to score-matching is intractable, we discover that using the time-dependent density ratio both for reweighting and score correction can lead to a tractable form of the objective function to regenerate the unbiased data density. Furthermore, we theoretically establish a connection with traditional score-matching, and we demonstrate its convergence to an unbiased distribution. The experimental evidence supports the usefulness of the proposed method, which outperforms baselines including time-independent importance reweighting on CIFAR-10, CIFAR-100, FFHQ, and CelebA with various bias settings. Our code is available at https://github.com/alsdudrla10/TIW-DSM.","sentences":["With significant advancements in diffusion models, addressing the potential risks of dataset bias becomes increasingly important.","Since generated outputs directly suffer from dataset bias, mitigating latent bias becomes a key factor in improving sample quality and proportion.","This paper proposes time-dependent importance reweighting to mitigate the bias for the diffusion models.","We demonstrate that the time-dependent density ratio becomes more precise than previous approaches, thereby minimizing error propagation in generative learning.","While directly applying it to score-matching is intractable, we discover that using the time-dependent density ratio both for reweighting and score correction can lead to a tractable form of the objective function to regenerate the unbiased data density.","Furthermore, we theoretically establish a connection with traditional score-matching, and we demonstrate its convergence to an unbiased distribution.","The experimental evidence supports the usefulness of the proposed method, which outperforms baselines including time-independent importance reweighting on CIFAR-10, CIFAR-100, FFHQ, and CelebA with various bias settings.","Our code is available at https://github.com/alsdudrla10/TIW-DSM."],"url":"http://arxiv.org/abs/2403.01189v1","category":"cs.LG"}
{"created":"2024-03-02 11:58:24","title":"A Compositional Typed Semantics for Universal Dependencies","abstract":"Languages may encode similar meanings using different sentence structures. This makes it a challenge to provide a single set of formal rules that can derive meanings from sentences in many languages at once. To overcome the challenge, we can take advantage of language-general connections between meaning and syntax, and build on cross-linguistically parallel syntactic structures. We introduce UD Type Calculus, a compositional, principled, and language-independent system of semantic types and logical forms for lexical items which builds on a widely-used language-general dependency syntax framework. We explain the essential features of UD Type Calculus, which all involve giving dependency relations denotations just like those of words. These allow UD-TC to derive correct meanings for sentences with a wide range of syntactic structures by making use of dependency labels. Finally, we present evaluation results on a large existing corpus of sentences and their logical forms, showing that UD-TC can produce meanings comparable with our baseline.","sentences":["Languages may encode similar meanings using different sentence structures.","This makes it a challenge to provide a single set of formal rules that can derive meanings from sentences in many languages at once.","To overcome the challenge, we can take advantage of language-general connections between meaning and syntax, and build on cross-linguistically parallel syntactic structures.","We introduce UD Type Calculus, a compositional, principled, and language-independent system of semantic types and logical forms for lexical items which builds on a widely-used language-general dependency syntax framework.","We explain the essential features of UD Type Calculus, which all involve giving dependency relations denotations just like those of words.","These allow UD-TC to derive correct meanings for sentences with a wide range of syntactic structures by making use of dependency labels.","Finally, we present evaluation results on a large existing corpus of sentences and their logical forms, showing that UD-TC can produce meanings comparable with our baseline."],"url":"http://arxiv.org/abs/2403.01187v1","category":"cs.CL"}
{"created":"2024-03-02 11:56:40","title":"Evault for legal records","abstract":"Innovative solution for addressing the challenges in the legal records management system through a blockchain-based eVault platform. Our objective is to create a secure, transparent, and accessible ecosystem that caters to the needs of all stakeholders, including lawyers, judges, clients, and registrars. First and foremost, our solution is built on a robust blockchain platform like Ethereum harnessing the power of smart contracts to manage access, permissions, and transactions effectively. This ensures the utmost security and transparency in every interaction within the system. To make our eVault system user-friendly, we've developed intuitive interfaces for all stakeholders. Lawyers, judges, clients, and even registrars can effortlessly upload and retrieve legal documents, track changes, and share information within the platform. But that's not all; we've gone a step further by incorporating a document creation and saving feature within our app and website. This feature allows users to generate and securely store legal documents, streamlining the entire documentation process.","sentences":["Innovative solution for addressing the challenges in the legal records management system through a blockchain-based eVault platform.","Our objective is to create a secure, transparent, and accessible ecosystem that caters to the needs of all stakeholders, including lawyers, judges, clients, and registrars.","First and foremost, our solution is built on a robust blockchain platform like Ethereum harnessing the power of smart contracts to manage access, permissions, and transactions effectively.","This ensures the utmost security and transparency in every interaction within the system.","To make our eVault system user-friendly, we've developed intuitive interfaces for all stakeholders.","Lawyers, judges, clients, and even registrars can effortlessly upload and retrieve legal documents, track changes, and share information within the platform.","But that's not all; we've gone a step further by incorporating a document creation and saving feature within our app and website.","This feature allows users to generate and securely store legal documents, streamlining the entire documentation process."],"url":"http://arxiv.org/abs/2403.01186v1","category":"cs.CR"}
{"created":"2024-03-02 11:54:55","title":"Balancing Exploration and Exploitation in LLM using Soft RLLF for Enhanced Negation Understanding","abstract":"Finetuning approaches in NLP often focus on exploitation rather than exploration, which may lead to suboptimal models. Given the vast search space of natural language, this limited exploration can restrict their performance in complex, high-stakes domains, where accurate negation understanding and logical reasoning abilities are crucial. To address this issue, we leverage Reinforcement Learning from Logical Feedback (RLLF) to create an effective balance between exploration and exploitation in LLMs. Our approach employs an appropriate benchmark dataset for training and evaluation, highlighting the importance of exploration in enhancing negation understanding capabilities. We compare the performance of our RLLF-enhanced LLMs with baseline models trained without RLLF, demonstrating the value of this balanced approach. Furthermore, we showcase the potential of our method in legal AI applications by employing transfer learning and evaluating its impact on negation understanding. Our experimental results exhibit the effectiveness of balancing exploration and exploitation with RLLF in improving LLMs' negation capabilities. This has implications for the development of more accurate, reliable, and logically consistent language models in high-stakes domains.","sentences":["Finetuning approaches in NLP often focus on exploitation rather than exploration, which may lead to suboptimal models.","Given the vast search space of natural language, this limited exploration can restrict their performance in complex, high-stakes domains, where accurate negation understanding and logical reasoning abilities are crucial.","To address this issue, we leverage Reinforcement Learning from Logical Feedback (RLLF) to create an effective balance between exploration and exploitation in LLMs.","Our approach employs an appropriate benchmark dataset for training and evaluation, highlighting the importance of exploration in enhancing negation understanding capabilities.","We compare the performance of our RLLF-enhanced LLMs with baseline models trained without RLLF, demonstrating the value of this balanced approach.","Furthermore, we showcase the potential of our method in legal AI applications by employing transfer learning and evaluating its impact on negation understanding.","Our experimental results exhibit the effectiveness of balancing exploration and exploitation with RLLF in improving LLMs' negation capabilities.","This has implications for the development of more accurate, reliable, and logically consistent language models in high-stakes domains."],"url":"http://arxiv.org/abs/2403.01185v1","category":"cs.CL"}
{"created":"2024-03-02 11:44:14","title":"Leveraging Self-Supervised Learning for Scene Recognition in Child Sexual Abuse Imagery","abstract":"Crime in the 21st century is split into a virtual and real world. However, the former has become a global menace to people's well-being and security in the latter. The challenges it presents must be faced with unified global cooperation, and we must rely more than ever on automated yet trustworthy tools to combat the ever-growing nature of online offenses. Over 10 million child sexual abuse reports are submitted to the US National Center for Missing & Exploited Children every year, and over 80% originated from online sources. Therefore, investigation centers and clearinghouses cannot manually process and correctly investigate all imagery. In light of that, reliable automated tools that can securely and efficiently deal with this data are paramount. In this sense, the scene recognition task looks for contextual cues in the environment, being able to group and classify child sexual abuse data without requiring to be trained on sensitive material. The scarcity and limitations of working with child sexual abuse images lead to self-supervised learning, a machine-learning methodology that leverages unlabeled data to produce powerful representations that can be more easily transferred to target tasks. This work shows that self-supervised deep learning models pre-trained on scene-centric data can reach 71.6% balanced accuracy on our indoor scene classification task and, on average, 2.2 percentage points better performance than a fully supervised version. We cooperate with Brazilian Federal Police experts to evaluate our indoor classification model on actual child abuse material. The results demonstrate a notable discrepancy between the features observed in widely used scene datasets and those depicted on sensitive materials.","sentences":["Crime in the 21st century is split into a virtual and real world.","However, the former has become a global menace to people's well-being and security in the latter.","The challenges it presents must be faced with unified global cooperation, and we must rely more than ever on automated yet trustworthy tools to combat the ever-growing nature of online offenses.","Over 10 million child sexual abuse reports are submitted to the US National Center for Missing & Exploited Children every year, and over 80% originated from online sources.","Therefore, investigation centers and clearinghouses cannot manually process and correctly investigate all imagery.","In light of that, reliable automated tools that can securely and efficiently deal with this data are paramount.","In this sense, the scene recognition task looks for contextual cues in the environment, being able to group and classify child sexual abuse data without requiring to be trained on sensitive material.","The scarcity and limitations of working with child sexual abuse images lead to self-supervised learning, a machine-learning methodology that leverages unlabeled data to produce powerful representations that can be more easily transferred to target tasks.","This work shows that self-supervised deep learning models pre-trained on scene-centric data can reach 71.6% balanced accuracy on our indoor scene classification task and, on average, 2.2 percentage points better performance than a fully supervised version.","We cooperate with Brazilian Federal Police experts to evaluate our indoor classification model on actual child abuse material.","The results demonstrate a notable discrepancy between the features observed in widely used scene datasets and those depicted on sensitive materials."],"url":"http://arxiv.org/abs/2403.01183v1","category":"cs.CV"}
{"created":"2024-03-02 11:22:50","title":"Misconfiguration in O-RAN: Analysis of the impact of AI/ML","abstract":"User demand on network communication infrastructure has never been greater with applications such as extended reality, holographic telepresence, and wireless brain-computer interfaces challenging current networking capabilities. Open RAN (O-RAN) is critical to supporting new and anticipated uses of 6G and beyond. It promotes openness and standardisation, increased flexibility through the disaggregation of Radio Access Network (RAN) components, supports programmability, flexibility, and scalability with technologies such as Software-Defined Networking (SDN), Network Function Virtualization (NFV), and cloud, and brings automation through the RAN Intelligent Controller (RIC). Furthermore, the use of xApps, rApps, and Artificial Intelligence/Machine Learning (AI/ML) within the RIC enables efficient management of complex RAN operations. However, due to the open nature of O-RAN and its support for heterogeneous systems, the possibility of misconfiguration problems becomes critical. In this paper, we present a thorough analysis of the potential misconfiguration issues in O-RAN with respect to integration and operation, the use of SDN and NFV, and, specifically, the use of AI/ML. The opportunity for AI/ML to be used to identify these misconfigurations is investigated. A case study is presented to illustrate the direct impact on the end user of conflicting policies amongst xApps along with a potential AI/ML-based solution to this problem. This research presents a first analysis of the impact of AI/ML on misconfiguration challenges in O-RAN","sentences":["User demand on network communication infrastructure has never been greater with applications such as extended reality, holographic telepresence, and wireless brain-computer interfaces challenging current networking capabilities.","Open RAN (O-RAN) is critical to supporting new and anticipated uses of 6G and beyond.","It promotes openness and standardisation, increased flexibility through the disaggregation of Radio Access Network (RAN) components, supports programmability, flexibility, and scalability with technologies such as Software-Defined Networking (SDN), Network Function Virtualization (NFV), and cloud, and brings automation through the RAN Intelligent Controller (RIC).","Furthermore, the use of xApps, rApps, and Artificial Intelligence/Machine Learning (AI/ML) within the RIC enables efficient management of complex RAN operations.","However, due to the open nature of O-RAN and its support for heterogeneous systems, the possibility of misconfiguration problems becomes critical.","In this paper, we present a thorough analysis of the potential misconfiguration issues in O-RAN with respect to integration and operation, the use of SDN and NFV, and, specifically, the use of AI/ML.","The opportunity for AI/ML to be used to identify these misconfigurations is investigated.","A case study is presented to illustrate the direct impact on the end user of conflicting policies amongst xApps along with a potential AI/ML-based solution to this problem.","This research presents a first analysis of the impact of AI/ML on misconfiguration challenges in O-RAN"],"url":"http://arxiv.org/abs/2403.01180v1","category":"cs.NI"}
{"created":"2024-03-02 11:15:00","title":"Optomechanical cooling with simultaneous intracavity and extracavity squeezed light","abstract":"We propose a novel and experimentally feasible approach to achieve high-efficiency ground-state cooling of a mechanical oscillator in an optomechanical system under the deeply unresolved sideband condition with the assistance of both intracavity and extracavity squeezing. In the scheme, a degenerate optical parametric amplifier is placed inside the optical cavity, generating the intracavity squeezing; besides, the optical cavity is driven by externally generated squeezing light, namely the extracavity squeezing. The quantum interference effect generated by intracavity squeezing and extracavity squeezing can completely suppress the non-resonant Stokes heating process while greatly enhancing the anti-Stokes cooling process. Therefore, the joint-squeezing scheme is capable of cooling the mechanical oscillators to their quantum ground state in a regime far away from the resolved sideband condition. Compared with other traditional optomechanical cooling schemes, the single-photon cooling rate in this joint-squeezing scheme can be tremendously enlarged by nearly three orders of magnitude. At the same time, the coupling strength required to achieve ground-state cooling can be significantly reduced. This scheme is promising for cooling large-mass and low-frequency mechanical oscillators, which provides a prerequisite for preparing and manipulating non-classical states in macroscopic quantum systems and lays a significant foundation for quantum manipulation.","sentences":["We propose a novel and experimentally feasible approach to achieve high-efficiency ground-state cooling of a mechanical oscillator in an optomechanical system under the deeply unresolved sideband condition with the assistance of both intracavity and extracavity squeezing.","In the scheme, a degenerate optical parametric amplifier is placed inside the optical cavity, generating the intracavity squeezing; besides, the optical cavity is driven by externally generated squeezing light, namely the extracavity squeezing.","The quantum interference effect generated by intracavity squeezing and extracavity squeezing can completely suppress the non-resonant Stokes heating process while greatly enhancing the anti-Stokes cooling process.","Therefore, the joint-squeezing scheme is capable of cooling the mechanical oscillators to their quantum ground state in a regime far away from the resolved sideband condition.","Compared with other traditional optomechanical cooling schemes, the single-photon cooling rate in this joint-squeezing scheme can be tremendously enlarged by nearly three orders of magnitude.","At the same time, the coupling strength required to achieve ground-state cooling can be significantly reduced.","This scheme is promising for cooling large-mass and low-frequency mechanical oscillators, which provides a prerequisite for preparing and manipulating non-classical states in macroscopic quantum systems and lays a significant foundation for quantum manipulation."],"url":"http://arxiv.org/abs/2403.01179v1","category":"quant-ph"}
{"created":"2024-03-02 11:09:15","title":"Quantum-number projected generator coordinate method for $^{21}$Ne with a chiral two-nucleon-plus-three-nucleon interaction","abstract":"We report a study of the low-lying states of deformed $^{21}$Ne within the framework of quantum-number projected generator coordinate method (PGCM), starting from a chiral two-nucleon-plus-three-nucleon (NN+3N) interaction. The wave functions of states are constructed as a linear combination of a set of axially-deformed Hartree-Fock-Bogliubov (HFB) wave functions with different quadrupole deformations. These HFB wave functions are projected onto different angular momenta and the correct neutron and proton numbers for $^{21}$Ne. The results of calculations based on the effective Hamiltonians derived by normal-ordering the 3N interaction with respect to three different reference states, including the quantum-number projected HFB wave functions for $^{20}$Ne, $^{22}$Ne, and an ensemble of them with equal weights, are compared. This study serves as a key step towards ab initio calculations of odd-mass deformed nuclei with the in-medium GCM.","sentences":["We report a study of the low-lying states of deformed $^{21}$Ne within the framework of quantum-number projected generator coordinate method (PGCM), starting from a chiral two-nucleon-plus-three-nucleon (NN+3N) interaction.","The wave functions of states are constructed as a linear combination of a set of axially-deformed Hartree-Fock-Bogliubov (HFB) wave functions with different quadrupole deformations.","These HFB wave functions are projected onto different angular momenta and the correct neutron and proton numbers for $^{21}$Ne.","The results of calculations based on the effective Hamiltonians derived by normal-ordering the 3N interaction with respect to three different reference states, including the quantum-number projected HFB wave functions for $^{20}$Ne, $^{22}$Ne, and an ensemble of them with equal weights, are compared.","This study serves as a key step towards ab initio calculations of odd-mass deformed nuclei with the in-medium GCM."],"url":"http://arxiv.org/abs/2403.01177v1","category":"nucl-th"}
{"created":"2024-03-02 10:56:27","title":"Consistent and Asymptotically Statistically-Efficient Solution to Camera Motion Estimation","abstract":"Given 2D point correspondences between an image pair, inferring the camera motion is a fundamental issue in the computer vision community. The existing works generally set out from the epipolar constraint and estimate the essential matrix, which is not optimal in the maximum likelihood (ML) sense. In this paper, we dive into the original measurement model with respect to the rotation matrix and normalized translation vector and formulate the ML problem. We then propose a two-step algorithm to solve it: In the first step, we estimate the variance of measurement noises and devise a consistent estimator based on bias elimination; In the second step, we execute a one-step Gauss-Newton iteration on manifold to refine the consistent estimate. We prove that the proposed estimate owns the same asymptotic statistical properties as the ML estimate: The first is consistency, i.e., the estimate converges to the ground truth as the point number increases; The second is asymptotic efficiency, i.e., the mean squared error of the estimate converges to the theoretical lower bound -- Cramer-Rao bound. In addition, we show that our algorithm has linear time complexity. These appealing characteristics endow our estimator with a great advantage in the case of dense point correspondences. Experiments on both synthetic data and real images demonstrate that when the point number reaches the order of hundreds, our estimator outperforms the state-of-the-art ones in terms of estimation accuracy and CPU time.","sentences":["Given 2D point correspondences between an image pair, inferring the camera motion is a fundamental issue in the computer vision community.","The existing works generally set out from the epipolar constraint and estimate the essential matrix, which is not optimal in the maximum likelihood (ML) sense.","In this paper, we dive into the original measurement model with respect to the rotation matrix and normalized translation vector and formulate the ML problem.","We then propose a two-step algorithm to solve it: In the first step, we estimate the variance of measurement noises and devise a consistent estimator based on bias elimination; In the second step, we execute a one-step Gauss-Newton iteration on manifold to refine the consistent estimate.","We prove that the proposed estimate owns the same asymptotic statistical properties as the ML estimate: The first is consistency, i.e., the estimate converges to the ground truth as the point number increases; The second is asymptotic efficiency, i.e., the mean squared error of the estimate converges to the theoretical lower bound -- Cramer-Rao bound.","In addition, we show that our algorithm has linear time complexity.","These appealing characteristics endow our estimator with a great advantage in the case of dense point correspondences.","Experiments on both synthetic data and real images demonstrate that when the point number reaches the order of hundreds, our estimator outperforms the state-of-the-art ones in terms of estimation accuracy and CPU time."],"url":"http://arxiv.org/abs/2403.01174v1","category":"cs.CV"}
{"created":"2024-03-02 10:56:14","title":"Run-time Introspection of 2D Object Detection in Automated Driving Systems Using Learning Representations","abstract":"Reliable detection of various objects and road users in the surrounding environment is crucial for the safe operation of automated driving systems (ADS). Despite recent progresses in developing highly accurate object detectors based on Deep Neural Networks (DNNs), they still remain prone to detection errors, which can lead to fatal consequences in safety-critical applications such as ADS. An effective remedy to this problem is to equip the system with run-time monitoring, named as introspection in the context of autonomous systems. Motivated by this, we introduce a novel introspection solution, which operates at the frame level for DNN-based 2D object detection and leverages neural network activation patterns. The proposed approach pre-processes the neural activation patterns of the object detector's backbone using several different modes. To provide extensive comparative analysis and fair comparison, we also adapt and implement several state-of-the-art (SOTA) introspection mechanisms for error detection in 2D object detection, using one-stage and two-stage object detectors evaluated on KITTI and BDD datasets. We compare the performance of the proposed solution in terms of error detection, adaptability to dataset shift, and, computational and memory resource requirements. Our performance evaluation shows that the proposed introspection solution outperforms SOTA methods, achieving an absolute reduction in the missed error ratio of 9% to 17% in the BDD dataset.","sentences":["Reliable detection of various objects and road users in the surrounding environment is crucial for the safe operation of automated driving systems (ADS).","Despite recent progresses in developing highly accurate object detectors based on Deep Neural Networks (DNNs), they still remain prone to detection errors, which can lead to fatal consequences in safety-critical applications such as ADS.","An effective remedy to this problem is to equip the system with run-time monitoring, named as introspection in the context of autonomous systems.","Motivated by this, we introduce a novel introspection solution, which operates at the frame level for DNN-based 2D object detection and leverages neural network activation patterns.","The proposed approach pre-processes the neural activation patterns of the object detector's backbone using several different modes.","To provide extensive comparative analysis and fair comparison, we also adapt and implement several state-of-the-art (SOTA) introspection mechanisms for error detection in 2D object detection, using one-stage and two-stage object detectors evaluated on KITTI and BDD datasets.","We compare the performance of the proposed solution in terms of error detection, adaptability to dataset shift, and, computational and memory resource requirements.","Our performance evaluation shows that the proposed introspection solution outperforms SOTA methods, achieving an absolute reduction in the missed error ratio of 9% to 17% in the BDD dataset."],"url":"http://arxiv.org/abs/2403.01172v1","category":"cs.CV"}
{"created":"2024-03-02 10:46:41","title":"Revolutionizing Wireless Communication with Single Layer Capacitor-Based Antenna Technology","abstract":"Single Layer Capacitor-Based Antenna Technology introduces a novel approach to address limitations of traditional antenna designs. It leverages the simplicity and efficiency of single-layer capacitors to achieve:   Compactness: Enables smaller, discreet devices without compromising performance. High Efficiency (97%-99%): Ensures superior signal strength and extended battery life. Broad Frequency Range (few kHz to 100 GHz): Supports diverse applications. Wide Bandwidth: Offers superior performance due to capacitor behavior at resonant frequencies. Cost-Effectiveness: Utilizes readily available, cost-competitive materials. The paper presents the technology's:   Mechanics: Explains the principle contrasting it with traditional designs. Distinguishing Features: Details advantages of size, efficiency, frequency range, bandwidth, and cost. Technical Data Analysis: Provides insights into s-parameter data, impedance matching, and system integration. It also explores the technology's market potential across various industries and discusses integration and implementation, addressing the challenge of impedance mismatch and proposing a solution.   This novel technology holds significant potential to revolutionize wireless communication, paving the way for a new generation of compact, efficient, and versatile connectivity solutions.","sentences":["Single Layer Capacitor-Based Antenna Technology introduces a novel approach to address limitations of traditional antenna designs.","It leverages the simplicity and efficiency of single-layer capacitors to achieve:   Compactness: Enables smaller, discreet devices without compromising performance.","High Efficiency (97%-99%):","Ensures superior signal strength and extended battery life.","Broad Frequency Range (few kHz to 100 GHz):","Supports diverse applications.","Wide Bandwidth:","Offers superior performance due to capacitor behavior at resonant frequencies.","Cost-Effectiveness: Utilizes readily available, cost-competitive materials.","The paper presents the technology's:   Mechanics: Explains the principle contrasting it with traditional designs.","Distinguishing Features: Details advantages of size, efficiency, frequency range, bandwidth, and cost.","Technical Data Analysis: Provides insights into s-parameter data, impedance matching, and system integration.","It also explores the technology's market potential across various industries and discusses integration and implementation, addressing the challenge of impedance mismatch and proposing a solution.   ","This novel technology holds significant potential to revolutionize wireless communication, paving the way for a new generation of compact, efficient, and versatile connectivity solutions."],"url":"http://arxiv.org/abs/2403.01170v1","category":"physics.app-ph"}
{"created":"2024-03-02 10:42:47","title":"Learn Suspected Anomalies from Event Prompts for Video Anomaly Detection","abstract":"Most models for weakly supervised video anomaly detection (WS-VAD) rely on multiple instance learning, aiming to distinguish normal and abnormal snippets without specifying the type of anomaly. The ambiguous nature of anomaly definitions across contexts introduces bias in detecting abnormal and normal snippets within the abnormal bag. Taking the first step to show the model why it is anomalous, a novel framework is proposed to guide the learning of suspected anomalies from event prompts. Given a textual prompt dictionary of potential anomaly events and the captions generated from anomaly videos, the semantic anomaly similarity between them could be calculated to identify the suspected anomalous events for each video snippet. It enables a new multi-prompt learning process to constrain the visual-semantic features across all videos, as well as provides a new way to label pseudo anomalies for self-training. To demonstrate effectiveness, comprehensive experiments and detailed ablation studies are conducted on four datasets, namely XD-Violence, UCF-Crime, TAD, and ShanghaiTech. Our proposed model outperforms most state-of-the-art methods in terms of AP or AUC (82.6\\%, 87.7\\%, 93.1\\%, and 97.4\\%). Furthermore, it shows promising performance in open-set and cross-dataset cases.","sentences":["Most models for weakly supervised video anomaly detection (WS-VAD) rely on multiple instance learning, aiming to distinguish normal and abnormal snippets without specifying the type of anomaly.","The ambiguous nature of anomaly definitions across contexts introduces bias in detecting abnormal and normal snippets within the abnormal bag.","Taking the first step to show the model why it is anomalous, a novel framework is proposed to guide the learning of suspected anomalies from event prompts.","Given a textual prompt dictionary of potential anomaly events and the captions generated from anomaly videos, the semantic anomaly similarity between them could be calculated to identify the suspected anomalous events for each video snippet.","It enables a new multi-prompt learning process to constrain the visual-semantic features across all videos, as well as provides a new way to label pseudo anomalies for self-training.","To demonstrate effectiveness, comprehensive experiments and detailed ablation studies are conducted on four datasets, namely XD-Violence, UCF-Crime, TAD, and ShanghaiTech.","Our proposed model outperforms most state-of-the-art methods in terms of AP or AUC (82.6\\%, 87.7\\%, 93.1\\%, and 97.4\\%).","Furthermore, it shows promising performance in open-set and cross-dataset cases."],"url":"http://arxiv.org/abs/2403.01169v1","category":"cs.CV"}
{"created":"2024-03-02 10:38:31","title":"DINER: Debiasing Aspect-based Sentiment Analysis with Multi-variable Causal Inference","abstract":"Though notable progress has been made, neural-based aspect-based sentiment analysis (ABSA) models are prone to learn spurious correlations from annotation biases, resulting in poor robustness on adversarial data transformations. Among the debiasing solutions, causal inference-based methods have attracted much research attention, which can be mainly categorized into causal intervention methods and counterfactual reasoning methods. However, most of the present debiasing methods focus on single-variable causal inference, which is not suitable for ABSA with two input variables (the target aspect and the review). In this paper, we propose a novel framework based on multi-variable causal inference for debiasing ABSA. In this framework, different types of biases are tackled based on different causal intervention methods. For the review branch, the bias is modeled as indirect confounding from context, where backdoor adjustment intervention is employed for debiasing. For the aspect branch, the bias is described as a direct correlation with labels, where counterfactual reasoning is adopted for debiasing. Extensive experiments demonstrate the effectiveness of the proposed method compared to various baselines on the two widely used real-world aspect robustness test set datasets.","sentences":["Though notable progress has been made, neural-based aspect-based sentiment analysis (ABSA) models are prone to learn spurious correlations from annotation biases, resulting in poor robustness on adversarial data transformations.","Among the debiasing solutions, causal inference-based methods have attracted much research attention, which can be mainly categorized into causal intervention methods and counterfactual reasoning methods.","However, most of the present debiasing methods focus on single-variable causal inference, which is not suitable for ABSA with two input variables (the target aspect and the review).","In this paper, we propose a novel framework based on multi-variable causal inference for debiasing ABSA.","In this framework, different types of biases are tackled based on different causal intervention methods.","For the review branch, the bias is modeled as indirect confounding from context, where backdoor adjustment intervention is employed for debiasing.","For the aspect branch, the bias is described as a direct correlation with labels, where counterfactual reasoning is adopted for debiasing.","Extensive experiments demonstrate the effectiveness of the proposed method compared to various baselines on the two widely used real-world aspect robustness test set datasets."],"url":"http://arxiv.org/abs/2403.01166v1","category":"cs.CL"}
{"created":"2024-03-02 10:38:10","title":"STAR: Constraint LoRA with Dynamic Active Learning for Data-Efficient Fine-Tuning of Large Language Models","abstract":"Though Large Language Models (LLMs) have demonstrated the powerful capabilities of few-shot learning through prompting methods, supervised training is still necessary for complex reasoning tasks. Because of their extensive parameters and memory consumption, both Parameter-Efficient Fine-Tuning (PEFT) methods and Memory-Efficient Fine-Tuning methods have been proposed for LLMs. Nevertheless, the issue of large annotated data consumption, the aim of Data-Efficient Fine-Tuning, remains unexplored. One obvious way is to combine the PEFT method with active learning. However, the experimental results show that such a combination is not trivial and yields inferior results. Through probe experiments, such observation might be explained by two main reasons: uncertainty gap and poor model calibration. Therefore, in this paper, we propose a novel approach to effectively integrate uncertainty-based active learning and LoRA. Specifically, for the uncertainty gap, we introduce a dynamic uncertainty measurement that combines the uncertainty of the base model and the uncertainty of the full model during the iteration of active learning. For poor model calibration, we incorporate the regularization method during LoRA training to keep the model from being over-confident, and the Monte-Carlo dropout mechanism is employed to enhance the uncertainty estimation. Experimental results show that the proposed approach outperforms existing baseline models on three complex reasoning tasks.","sentences":["Though Large Language Models (LLMs) have demonstrated the powerful capabilities of few-shot learning through prompting methods, supervised training is still necessary for complex reasoning tasks.","Because of their extensive parameters and memory consumption, both Parameter-Efficient Fine-Tuning (PEFT) methods and Memory-Efficient Fine-Tuning methods have been proposed for LLMs.","Nevertheless, the issue of large annotated data consumption, the aim of Data-Efficient Fine-Tuning, remains unexplored.","One obvious way is to combine the PEFT method with active learning.","However, the experimental results show that such a combination is not trivial and yields inferior results.","Through probe experiments, such observation might be explained by two main reasons: uncertainty gap and poor model calibration.","Therefore, in this paper, we propose a novel approach to effectively integrate uncertainty-based active learning and LoRA.","Specifically, for the uncertainty gap, we introduce a dynamic uncertainty measurement that combines the uncertainty of the base model and the uncertainty of the full model during the iteration of active learning.","For poor model calibration, we incorporate the regularization method during LoRA training to keep the model from being over-confident, and the Monte-Carlo dropout mechanism is employed to enhance the uncertainty estimation.","Experimental results show that the proposed approach outperforms existing baseline models on three complex reasoning tasks."],"url":"http://arxiv.org/abs/2403.01165v1","category":"cs.CL"}
{"created":"2024-03-02 10:34:11","title":"BootTOD: Bootstrap Task-oriented Dialogue Representations by Aligning Diverse Responses","abstract":"Pre-trained language models have been successful in many scenarios. However, their usefulness in task-oriented dialogues is limited due to the intrinsic linguistic differences between general text and task-oriented dialogues. Current task-oriented dialogue pre-training methods rely on a contrastive framework, which faces challenges such as selecting true positives and hard negatives, as well as lacking diversity. In this paper, we propose a novel dialogue pre-training model called BootTOD. It learns task-oriented dialogue representations via a self-bootstrapping framework. Unlike contrastive counterparts, BootTOD aligns context and context+response representations and dismisses the requirements of contrastive pairs. BootTOD also uses multiple appropriate response targets to model the intrinsic one-to-many diversity of human conversations. Experimental results show that BootTOD outperforms strong TOD baselines on diverse downstream dialogue tasks.","sentences":["Pre-trained language models have been successful in many scenarios.","However, their usefulness in task-oriented dialogues is limited due to the intrinsic linguistic differences between general text and task-oriented dialogues.","Current task-oriented dialogue pre-training methods rely on a contrastive framework, which faces challenges such as selecting true positives and hard negatives, as well as lacking diversity.","In this paper, we propose a novel dialogue pre-training model called BootTOD.","It learns task-oriented dialogue representations via a self-bootstrapping framework.","Unlike contrastive counterparts, BootTOD aligns context and context+response representations and dismisses the requirements of contrastive pairs.","BootTOD also uses multiple appropriate response targets to model the intrinsic one-to-many diversity of human conversations.","Experimental results show that BootTOD outperforms strong TOD baselines on diverse downstream dialogue tasks."],"url":"http://arxiv.org/abs/2403.01163v1","category":"cs.CL"}
{"created":"2024-03-02 10:31:27","title":"Envy-Free House Allocation with Minimum Subsidy","abstract":"House allocation refers to the problem where $m$ houses are to be allocated to $n$ agents so that each agent receives one house. Since an envy-free house allocation does not always exist, we consider finding such an allocation in the presence of subsidy. We show that computing an envy-free allocation with minimum subsidy is NP-hard in general, but can be done efficiently if $m$ differs from $n$ by an additive constant or if the agents have identical utilities.","sentences":["House allocation refers to the problem where $m$ houses are to be allocated to $n$ agents so that each agent receives one house.","Since an envy-free house allocation does not always exist, we consider finding such an allocation in the presence of subsidy.","We show that computing an envy-free allocation with minimum subsidy is NP-hard in general, but can be done efficiently if $m$ differs from $n$ by an additive constant or if the agents have identical utilities."],"url":"http://arxiv.org/abs/2403.01162v1","category":"cs.GT"}
{"created":"2024-03-02 10:25:24","title":"Droplet dynamics in homogeneous isotropic turbulence with the immersed boundary-lattice Boltzmann method","abstract":"We develop a numerical method for simulating the dynamics of a droplet immersed in a generic time-dependent velocity gradient field. This approach is grounded on the hybrid coupling between the lattice Boltzmann (LB) method, employed for the flow simulation, and the immersed boundary (IB) method, utilized to couple the droplet with the surrounding fluid. We show how to enrich the numerical scheme with a mesh regularization technique, allowing droplets to sustain large deformations. The resulting methodology is adapted to simulate the dynamics of droplets in homogeneous and isotropic turbulence, with the characteristic size of the droplet being smaller than the characteristic Kolmogorov scale of the outer turbulent flow. We report on statistical results for droplet deformation and orientation, collected from an ensemble of turbulent trajectories, as well as comparisons with theoretical models in the limit of small deformation.","sentences":["We develop a numerical method for simulating the dynamics of a droplet immersed in a generic time-dependent velocity gradient field.","This approach is grounded on the hybrid coupling between the lattice Boltzmann (LB) method, employed for the flow simulation, and the immersed boundary (IB) method, utilized to couple the droplet with the surrounding fluid.","We show how to enrich the numerical scheme with a mesh regularization technique, allowing droplets to sustain large deformations.","The resulting methodology is adapted to simulate the dynamics of droplets in homogeneous and isotropic turbulence, with the characteristic size of the droplet being smaller than the characteristic Kolmogorov scale of the outer turbulent flow.","We report on statistical results for droplet deformation and orientation, collected from an ensemble of turbulent trajectories, as well as comparisons with theoretical models in the limit of small deformation."],"url":"http://arxiv.org/abs/2403.01161v1","category":"physics.flu-dyn"}
{"created":"2024-03-02 10:24:09","title":"Electron Spectroscopy using Transition-Edge Sensors","abstract":"Transition-edge sensors (TESs) have the potential to perform electron spectroscopic measurements with far greater measurement rates and efficiencies than can be achieved using existing electron spectrometers. Existing spectrometers filter electrons by energy before detecting a narrow energy band at a time, discarding the vast majority of electrons available for measurement. In contrast, transition-edge sensors (TES) have intrinsic energy sensitivity and so do not require prior filtering to perform energy-resolved measurements. Despite this fundamental advantage, TES electron spectroscopy has not, to our knowledge, previously been reported in the literature. We present the results of a set of proof-of-principle experiments demonstrating TES electron spectroscopy experiments using Mo/Au TESs repurposed for electron calorimetry. Using these detectors, we successfully measured the electron spectrum generated by an electron beam striking a graphite target with energies between 750 and 2000 eV, at a noise-limited energy resolution of 4 eV. Based on the findings of these experiments, we suggest improvements that could be made to TES design to enhance their electron detection capabilities through the use of of a dedicated electron absorber in the device with integrated electron optics.","sentences":["Transition-edge sensors (TESs) have the potential to perform electron spectroscopic measurements with far greater measurement rates and efficiencies than can be achieved using existing electron spectrometers.","Existing spectrometers filter electrons by energy before detecting a narrow energy band at a time, discarding the vast majority of electrons available for measurement.","In contrast, transition-edge sensors (TES) have intrinsic energy sensitivity and so do not require prior filtering to perform energy-resolved measurements.","Despite this fundamental advantage, TES electron spectroscopy has not, to our knowledge, previously been reported in the literature.","We present the results of a set of proof-of-principle experiments demonstrating TES electron spectroscopy experiments using Mo/Au TESs repurposed for electron calorimetry.","Using these detectors, we successfully measured the electron spectrum generated by an electron beam striking a graphite target with energies between 750 and 2000 eV, at a noise-limited energy resolution of 4 eV. Based on the findings of these experiments, we suggest improvements that could be made to TES design to enhance their electron detection capabilities through the use of of a dedicated electron absorber in the device with integrated electron optics."],"url":"http://arxiv.org/abs/2403.01160v1","category":"physics.ins-det"}
{"created":"2024-03-02 10:03:21","title":"Auxiliary Tasks Enhanced Dual-affinity Learning for Weakly Supervised Semantic Segmentation","abstract":"Most existing weakly supervised semantic segmentation (WSSS) methods rely on Class Activation Mapping (CAM) to extract coarse class-specific localization maps using image-level labels. Prior works have commonly used an off-line heuristic thresholding process that combines the CAM maps with off-the-shelf saliency maps produced by a general pre-trained saliency model to produce more accurate pseudo-segmentation labels. We propose AuxSegNet+, a weakly supervised auxiliary learning framework to explore the rich information from these saliency maps and the significant inter-task correlation between saliency detection and semantic segmentation. In the proposed AuxSegNet+, saliency detection and multi-label image classification are used as auxiliary tasks to improve the primary task of semantic segmentation with only image-level ground-truth labels. We also propose a cross-task affinity learning mechanism to learn pixel-level affinities from the saliency and segmentation feature maps. In particular, we propose a cross-task dual-affinity learning module to learn both pairwise and unary affinities, which are used to enhance the task-specific features and predictions by aggregating both query-dependent and query-independent global context for both saliency detection and semantic segmentation. The learned cross-task pairwise affinity can also be used to refine and propagate CAM maps to provide better pseudo labels for both tasks. Iterative improvement of segmentation performance is enabled by cross-task affinity learning and pseudo-label updating. Extensive experiments demonstrate the effectiveness of the proposed approach with new state-of-the-art WSSS results on the challenging PASCAL VOC and MS COCO benchmarks.","sentences":["Most existing weakly supervised semantic segmentation (WSSS) methods rely on Class Activation Mapping (CAM) to extract coarse class-specific localization maps using image-level labels.","Prior works have commonly used an off-line heuristic thresholding process that combines the CAM maps with off-the-shelf saliency maps produced by a general pre-trained saliency model to produce more accurate pseudo-segmentation labels.","We propose AuxSegNet+, a weakly supervised auxiliary learning framework to explore the rich information from these saliency maps and the significant inter-task correlation between saliency detection and semantic segmentation.","In the proposed AuxSegNet+, saliency detection and multi-label image classification are used as auxiliary tasks to improve the primary task of semantic segmentation with only image-level ground-truth labels.","We also propose a cross-task affinity learning mechanism to learn pixel-level affinities from the saliency and segmentation feature maps.","In particular, we propose a cross-task dual-affinity learning module to learn both pairwise and unary affinities, which are used to enhance the task-specific features and predictions by aggregating both query-dependent and query-independent global context for both saliency detection and semantic segmentation.","The learned cross-task pairwise affinity can also be used to refine and propagate CAM maps to provide better pseudo labels for both tasks.","Iterative improvement of segmentation performance is enabled by cross-task affinity learning and pseudo-label updating.","Extensive experiments demonstrate the effectiveness of the proposed approach with new state-of-the-art WSSS results on the challenging PASCAL VOC and MS COCO benchmarks."],"url":"http://arxiv.org/abs/2403.01156v1","category":"cs.CV"}
{"created":"2024-03-02 09:39:13","title":"A Survey of AI-generated Text Forensic Systems: Detection, Attribution, and Characterization","abstract":"We have witnessed lately a rapid proliferation of advanced Large Language Models (LLMs) capable of generating high-quality text. While these LLMs have revolutionized text generation across various domains, they also pose significant risks to the information ecosystem, such as the potential for generating convincing propaganda, misinformation, and disinformation at scale. This paper offers a review of AI-generated text forensic systems, an emerging field addressing the challenges of LLM misuses. We present an overview of the existing efforts in AI-generated text forensics by introducing a detailed taxonomy, focusing on three primary pillars: detection, attribution, and characterization. These pillars enable a practical understanding of AI-generated text, from identifying AI-generated content (detection), determining the specific AI model involved (attribution), and grouping the underlying intents of the text (characterization). Furthermore, we explore available resources for AI-generated text forensics research and discuss the evolving challenges and future directions of forensic systems in an AI era.","sentences":["We have witnessed lately a rapid proliferation of advanced Large Language Models (LLMs) capable of generating high-quality text.","While these LLMs have revolutionized text generation across various domains, they also pose significant risks to the information ecosystem, such as the potential for generating convincing propaganda, misinformation, and disinformation at scale.","This paper offers a review of AI-generated text forensic systems, an emerging field addressing the challenges of LLM misuses.","We present an overview of the existing efforts in AI-generated text forensics by introducing a detailed taxonomy, focusing on three primary pillars: detection, attribution, and characterization.","These pillars enable a practical understanding of AI-generated text, from identifying AI-generated content (detection), determining the specific AI model involved (attribution), and grouping the underlying intents of the text (characterization).","Furthermore, we explore available resources for AI-generated text forensics research and discuss the evolving challenges and future directions of forensic systems in an AI era."],"url":"http://arxiv.org/abs/2403.01152v1","category":"cs.CL"}
{"created":"2024-03-02 09:28:04","title":"A Hybrid Model for Traffic Incident Detection based on Generative Adversarial Networks and Transformer Model","abstract":"In addition to enhancing traffic safety and facilitating prompt emergency response, traffic incident detection plays an indispensable role in intelligent transportation systems by providing real-time traffic status information. This enables the realization of intelligent traffic control and management. Previous research has identified that apart from employing advanced algorithmic models, the effectiveness of detection is also significantly influenced by challenges related to acquiring large datasets and addressing dataset imbalances. A hybrid model combining transformer and generative adversarial networks (GANs) is proposed to address these challenges. Experiments are conducted on four real datasets to validate the superiority of the transformer in traffic incident detection. Additionally, GANs are utilized to expand the dataset and achieve a balanced ratio of 1:4, 2:3, and 1:1. The proposed model is evaluated against the baseline model. The results demonstrate that the proposed model enhances the dataset size, balances the dataset, and improves the performance of traffic incident detection in various aspects.","sentences":["In addition to enhancing traffic safety and facilitating prompt emergency response, traffic incident detection plays an indispensable role in intelligent transportation systems by providing real-time traffic status information.","This enables the realization of intelligent traffic control and management.","Previous research has identified that apart from employing advanced algorithmic models, the effectiveness of detection is also significantly influenced by challenges related to acquiring large datasets and addressing dataset imbalances.","A hybrid model combining transformer and generative adversarial networks (GANs) is proposed to address these challenges.","Experiments are conducted on four real datasets to validate the superiority of the transformer in traffic incident detection.","Additionally, GANs are utilized to expand the dataset and achieve a balanced ratio of 1:4, 2:3, and 1:1.","The proposed model is evaluated against the baseline model.","The results demonstrate that the proposed model enhances the dataset size, balances the dataset, and improves the performance of traffic incident detection in various aspects."],"url":"http://arxiv.org/abs/2403.01147v1","category":"cs.LG"}
{"created":"2024-03-02 09:16:45","title":"Mirror real Chern insulator in two and three dimensions","abstract":"A real Chern insulator (RCI) featuring a real Chern number and a second-order boundary mode appears in a two-dimensional (2D) system with the space-time inversion symmetry (PT ). Here, we propose a kind of RCI: mirror real Chern insulator (MRCI) which emerges from the system having additional horizontal mirror symmetry Mz. The MRCI generally is characterized by two independent real Chern numbers, respectively defined in the two mirror subsystems of the system. Hence, the MRCI may host the second-order boundary modes different from the conventional RCI. We show that for spinless systems, the definition of the MRCI is straightforward, as PT keeps each mirror subsystem invariant. For the spinful systems with both PT and Mz, the real Chern number for the total system remain well defined, as MzPT = C2zT , and (C2zT )2= 1. However, since C2zT exchanges the two mirror subsystems, the definition of the MRCI in spinful systems requires the help of projective symmetry algebra. We also discuss the MRCIs in 3D systems, where the MRCI is defined on certain mirror-invariant 2D planes. Compared with its 2D counterpart, the 3D MRCI can exhibit more abundant physics when the systems have additional nonsymmorphic operators. Several concrete MRCI models including 2D and 3D, spinless and spinful models are constructed to further demonstrate our ideas.","sentences":["A real Chern insulator (RCI) featuring a real Chern number and a second-order boundary mode appears in a two-dimensional (2D) system with the space-time inversion symmetry (PT ).","Here, we propose a kind of RCI: mirror real Chern insulator (MRCI) which emerges from the system having additional horizontal mirror symmetry Mz.","The MRCI generally is characterized by two independent real Chern numbers, respectively defined in the two mirror subsystems of the system.","Hence, the MRCI may host the second-order boundary modes different from the conventional RCI.","We show that for spinless systems, the definition of the MRCI is straightforward, as PT keeps each mirror subsystem invariant.","For the spinful systems with both PT and Mz, the real Chern number for the total system remain well defined, as MzPT = C2zT , and (C2zT )2= 1.","However, since C2zT exchanges the two mirror subsystems, the definition of the MRCI in spinful systems requires the help of projective symmetry algebra.","We also discuss the MRCIs in 3D systems, where the MRCI is defined on certain mirror-invariant 2D planes.","Compared with its 2D counterpart, the 3D MRCI can exhibit more abundant physics when the systems have additional nonsymmorphic operators.","Several concrete MRCI models including 2D and 3D, spinless and spinful models are constructed to further demonstrate our ideas."],"url":"http://arxiv.org/abs/2403.01145v1","category":"cond-mat.mtrl-sci"}
{"created":"2024-03-02 08:53:40","title":"ParallelPARC: A Scalable Pipeline for Generating Natural-Language Analogies","abstract":"Analogy-making is central to human cognition, allowing us to adapt to novel situations -- an ability that current AI systems still lack. Most analogy datasets today focus on simple analogies (e.g., word analogies); datasets including complex types of analogies are typically manually curated and very small. We believe that this holds back progress in computational analogy. In this work, we design a data generation pipeline, ParallelPARC (Parallel Paragraph Creator) leveraging state-of-the-art Large Language Models (LLMs) to create complex, paragraph-based analogies, as well as distractors, both simple and challenging. We demonstrate our pipeline and create ProPara-Logy, a dataset of analogies between scientific processes. We publish a gold-set, validated by humans, and a silver-set, generated automatically. We test LLMs' and humans' analogy recognition in binary and multiple-choice settings, and found that humans outperform the best models (~13% gap) after a light supervision. We demonstrate that our silver-set is useful for training models. Lastly, we show challenging distractors confuse LLMs, but not humans. We hope our pipeline will encourage research in this emerging field.","sentences":["Analogy-making is central to human cognition, allowing us to adapt to novel situations -- an ability that current AI systems still lack.","Most analogy datasets today focus on simple analogies (e.g., word analogies); datasets including complex types of analogies are typically manually curated and very small.","We believe that this holds back progress in computational analogy.","In this work, we design a data generation pipeline, ParallelPARC (Parallel Paragraph Creator) leveraging state-of-the-art Large Language Models (LLMs) to create complex, paragraph-based analogies, as well as distractors, both simple and challenging.","We demonstrate our pipeline and create ProPara-Logy, a dataset of analogies between scientific processes.","We publish a gold-set, validated by humans, and a silver-set, generated automatically.","We test LLMs' and humans' analogy recognition in binary and multiple-choice settings, and found that humans outperform the best models (~13% gap) after a light supervision.","We demonstrate that our silver-set is useful for training models.","Lastly, we show challenging distractors confuse LLMs, but not humans.","We hope our pipeline will encourage research in this emerging field."],"url":"http://arxiv.org/abs/2403.01139v1","category":"cs.CL"}
{"created":"2024-03-02 08:49:02","title":"Neural radiance fields-based holography [Invited]","abstract":"This study presents a novel approach for generating holograms based on the neural radiance fields (NeRF) technique. Generating three-dimensional (3D) data is difficult in hologram computation. NeRF is a state-of-the-art technique for 3D light-field reconstruction from 2D images based on volume rendering. The NeRF can rapidly predict new-view images that do not include a training dataset. In this study, we constructed a rendering pipeline directly from a 3D light field generated from 2D images by NeRF for hologram generation using deep neural networks within a reasonable time. The pipeline comprises three main components: the NeRF, a depth predictor, and a hologram generator, all constructed using deep neural networks. The pipeline does not include any physical calculations. The predicted holograms of a 3D scene viewed from any direction were computed using the proposed pipeline. The simulation and experimental results are presented.","sentences":["This study presents a novel approach for generating holograms based on the neural radiance fields (NeRF) technique.","Generating three-dimensional (3D) data is difficult in hologram computation.","NeRF is a state-of-the-art technique for 3D light-field reconstruction from 2D images based on volume rendering.","The NeRF can rapidly predict new-view images that do not include a training dataset.","In this study, we constructed a rendering pipeline directly from a 3D light field generated from 2D images by NeRF for hologram generation using deep neural networks within a reasonable time.","The pipeline comprises three main components: the NeRF, a depth predictor, and a hologram generator, all constructed using deep neural networks.","The pipeline does not include any physical calculations.","The predicted holograms of a 3D scene viewed from any direction were computed using the proposed pipeline.","The simulation and experimental results are presented."],"url":"http://arxiv.org/abs/2403.01137v1","category":"cs.CV"}
{"created":"2024-03-02 08:40:07","title":"LLM-PQ: Serving LLM on Heterogeneous Clusters with Phase-Aware Partition and Adaptive Quantization","abstract":"Recent breakthroughs in Large-scale language models (LLMs) have demonstrated impressive performance on various tasks. The immense sizes of LLMs have led to very high resource demand and cost for running the models. Though the models are largely served using uniform high-caliber GPUs nowadays, utilizing a heterogeneous cluster with a mix of available high- and low-capacity GPUs can potentially substantially reduce the serving cost. There is a lack of designs to support efficient LLM serving using a heterogeneous cluster, while the current solutions focus on model partition and uniform compression among homogeneous devices. This paper proposes LLM-PQ, a system that advocates adaptive model quantization and phase-aware partition to improve LLM serving efficiency on heterogeneous GPU clusters. We carefully decide on mixed-precision model quantization together with phase-aware model partition and micro-batch sizing in distributed LLM serving with an efficient algorithm, to greatly enhance inference throughput while fulfilling user-specified model quality targets. Extensive experiments on production inference workloads in 11 different clusters demonstrate that LLM-PQ achieves up to 2.88x (2.26x on average) throughput improvement in inference, showing great advantages over state-of-the-art works.","sentences":["Recent breakthroughs in Large-scale language models (LLMs) have demonstrated impressive performance on various tasks.","The immense sizes of LLMs have led to very high resource demand and cost for running the models.","Though the models are largely served using uniform high-caliber GPUs nowadays, utilizing a heterogeneous cluster with a mix of available high- and low-capacity GPUs can potentially substantially reduce the serving cost.","There is a lack of designs to support efficient LLM serving using a heterogeneous cluster, while the current solutions focus on model partition and uniform compression among homogeneous devices.","This paper proposes LLM-PQ, a system that advocates adaptive model quantization and phase-aware partition to improve LLM serving efficiency on heterogeneous GPU clusters.","We carefully decide on mixed-precision model quantization together with phase-aware model partition and micro-batch sizing in distributed LLM serving with an efficient algorithm, to greatly enhance inference throughput while fulfilling user-specified model quality targets.","Extensive experiments on production inference workloads in 11 different clusters demonstrate that LLM-PQ achieves up to 2.88x (2.26x on average) throughput improvement in inference, showing great advantages over state-of-the-art works."],"url":"http://arxiv.org/abs/2403.01136v1","category":"cs.LG"}
{"created":"2024-03-02 08:27:05","title":"MPIPN: A Multi Physics-Informed PointNet for solving parametric acoustic-structure systems","abstract":"Machine learning is employed for solving physical systems governed by general nonlinear partial differential equations (PDEs). However, complex multi-physics systems such as acoustic-structure coupling are often described by a series of PDEs that incorporate variable physical quantities, which are referred to as parametric systems. There are lack of strategies for solving parametric systems governed by PDEs that involve explicit and implicit quantities. In this paper, a deep learning-based Multi Physics-Informed PointNet (MPIPN) is proposed for solving parametric acoustic-structure systems. First, the MPIPN induces an enhanced point-cloud architecture that encompasses explicit physical quantities and geometric features of computational domains. Then, the MPIPN extracts local and global features of the reconstructed point-cloud as parts of solving criteria of parametric systems, respectively. Besides, implicit physical quantities are embedded by encoding techniques as another part of solving criteria. Finally, all solving criteria that characterize parametric systems are amalgamated to form distinctive sequences as the input of the MPIPN, whose outputs are solutions of systems. The proposed framework is trained by adaptive physics-informed loss functions for corresponding computational domains. The framework is generalized to deal with new parametric conditions of systems. The effectiveness of the MPIPN is validated by applying it to solve steady parametric acoustic-structure coupling systems governed by the Helmholtz equations. An ablation experiment has been implemented to demonstrate the efficacy of physics-informed impact with a minority of supervised data. The proposed method yields reasonable precision across all computational domains under constant parametric conditions and changeable combinations of parametric conditions for acoustic-structure systems.","sentences":["Machine learning is employed for solving physical systems governed by general nonlinear partial differential equations (PDEs).","However, complex multi-physics systems such as acoustic-structure coupling are often described by a series of PDEs that incorporate variable physical quantities, which are referred to as parametric systems.","There are lack of strategies for solving parametric systems governed by PDEs that involve explicit and implicit quantities.","In this paper, a deep learning-based Multi Physics-Informed PointNet (MPIPN) is proposed for solving parametric acoustic-structure systems.","First, the MPIPN induces an enhanced point-cloud architecture that encompasses explicit physical quantities and geometric features of computational domains.","Then, the MPIPN extracts local and global features of the reconstructed point-cloud as parts of solving criteria of parametric systems, respectively.","Besides, implicit physical quantities are embedded by encoding techniques as another part of solving criteria.","Finally, all solving criteria that characterize parametric systems are amalgamated to form distinctive sequences as the input of the MPIPN, whose outputs are solutions of systems.","The proposed framework is trained by adaptive physics-informed loss functions for corresponding computational domains.","The framework is generalized to deal with new parametric conditions of systems.","The effectiveness of the MPIPN is validated by applying it to solve steady parametric acoustic-structure coupling systems governed by the Helmholtz equations.","An ablation experiment has been implemented to demonstrate the efficacy of physics-informed impact with a minority of supervised data.","The proposed method yields reasonable precision across all computational domains under constant parametric conditions and changeable combinations of parametric conditions for acoustic-structure systems."],"url":"http://arxiv.org/abs/2403.01132v1","category":"cs.LG"}
{"created":"2024-03-02 08:21:59","title":"LLaMoCo: Instruction Tuning of Large Language Models for Optimization Code Generation","abstract":"Recent research explores optimization using large language models (LLMs) by either iteratively seeking next-step solutions from LLMs or directly prompting LLMs for an optimizer. However, these approaches exhibit inherent limitations, including low operational efficiency, high sensitivity to prompt design, and a lack of domain-specific knowledge. We introduce LLaMoCo, the first instruction-tuning framework designed to adapt LLMs for solving optimization problems in a code-to-code manner. Specifically, we establish a comprehensive instruction set containing well-described problem prompts and effective optimization codes. We then develop a novel two-phase learning strategy that incorporates a contrastive learning-based warm-up procedure before the instruction-tuning phase to enhance the convergence behavior during model fine-tuning. The experiment results demonstrate that a CodeGen (350M) model fine-tuned by our LLaMoCo achieves superior optimization performance compared to GPT-4 Turbo and the other competitors across both synthetic and realistic problem sets. The fine-tuned model and the usage instructions are available at https://anonymous.4open.science/r/LLaMoCo-722A.","sentences":["Recent research explores optimization using large language models (LLMs) by either iteratively seeking next-step solutions from LLMs or directly prompting LLMs for an optimizer.","However, these approaches exhibit inherent limitations, including low operational efficiency, high sensitivity to prompt design, and a lack of domain-specific knowledge.","We introduce LLaMoCo, the first instruction-tuning framework designed to adapt LLMs for solving optimization problems in a code-to-code manner.","Specifically, we establish a comprehensive instruction set containing well-described problem prompts and effective optimization codes.","We then develop a novel two-phase learning strategy that incorporates a contrastive learning-based warm-up procedure before the instruction-tuning phase to enhance the convergence behavior during model fine-tuning.","The experiment results demonstrate that a CodeGen (350M) model fine-tuned by our LLaMoCo achieves superior optimization performance compared to GPT-4 Turbo and the other competitors across both synthetic and realistic problem sets.","The fine-tuned model and the usage instructions are available at https://anonymous.4open.science/r/LLaMoCo-722A."],"url":"http://arxiv.org/abs/2403.01131v1","category":"math.OC"}
{"created":"2024-03-02 23:58:33","title":"The Repercussions of the COVID-19 Pandemic on Higher Education and its implications for Syrian Refugees Students (An Analytical Descriptive Study)","abstract":"This study aims to reveal the most important challenges and difficulties that refugee students faced in Jordanian universities (e.g., Yarmouk University, AL Al-Bayt, and the Private Zarqa University) due to the COVID-19 pandemic through measuring a different of indicators that are related, in addition, to identify some of the independent variables on e-educational challenges. In the study, the analytical description approach was used. The data collection tool is a questionnaire, which was distributed to a random sample of students electronically. Results show that the necessity to implement educational and psychological counseling programs and economic support programs to support the e-Learning costs. The study confirmed that refugees are the most affected students with the pandemic compared to the host community.   Keywords: Syrian refugees, COVID-19, e-learning","sentences":["This study aims to reveal the most important challenges and difficulties that refugee students faced in Jordanian universities (e.g., Yarmouk University, AL Al-Bayt, and the Private Zarqa University) due to the COVID-19 pandemic through measuring a different of indicators that are related, in addition, to identify some of the independent variables on e-educational challenges.","In the study, the analytical description approach was used.","The data collection tool is a questionnaire, which was distributed to a random sample of students electronically.","Results show that the necessity to implement educational and psychological counseling programs and economic support programs to support the e-Learning costs.","The study confirmed that refugees are the most affected students with the pandemic compared to the host community.   ","Keywords: Syrian refugees, COVID-19, e-learning"],"url":"http://arxiv.org/abs/2403.01347v1","category":"cs.SI"}
{"created":"2024-03-02 23:33:44","title":"The Effectiveness of a Training Program Based on Health Education to Improve Health Empowerment Level among Refugees in Jordan","abstract":"Objectives: The study aimed to evaluate the effectiveness of a health education-based training program in enhancing the level of health empowerment among refugees in Jordan. Health empowerment is a key component to promote health as it enables individuals to control and manage their health outcomes and improve them. Refugees are a vulnerable population group with limited access to healthcare.   Methodology: The study sample consisted of 38 refugees in Irbid governorate, Jordan, who were conveniently selected in coordination with some organizations working in the field of asylum in the governorate. They were randomly divided into two groups: an experimental group (n = 19) that received the health education training program, and a control group (n = 19) that did not receive any health education training. The Health Empowerment Scale (HES), a validated tool, was used to collect data from both groups in the pre and post-tests, and a follow-up test was conducted for members of the experimental group only. Results: The results showed a statistically significant increase in the health empowerment scores for the experimental group that received the training program compared to the control group. The mean of the pre-test for the experimental group was (1.97 - 0.27), and for the control group, it was (1.84 - 0.21). The post-test mean for the experimental group became (3.88 - 0.13), while for the control group, it was (1.85 - 0.20). The follow-up test also demonstrated that the enhanced health empowerment levels were maintained in the experimental group, with no significant difference between the post-test and follow-up scores, indicating the effectiveness of the health education training program in enhancing health empowerment for refugees in Jordan.","sentences":["Objectives: The study aimed to evaluate the effectiveness of a health education-based training program in enhancing the level of health empowerment among refugees in Jordan.","Health empowerment is a key component to promote health as it enables individuals to control and manage their health outcomes and improve them.","Refugees are a vulnerable population group with limited access to healthcare.   ","Methodology:","The study sample consisted of 38 refugees in Irbid governorate, Jordan, who were conveniently selected in coordination with some organizations working in the field of asylum in the governorate.","They were randomly divided into two groups: an experimental group (n = 19) that received the health education training program, and a control group (n = 19) that did not receive any health education training.","The Health Empowerment Scale (HES), a validated tool, was used to collect data from both groups in the pre and post-tests, and a follow-up test was conducted for members of the experimental group only.","Results:","The results showed a statistically significant increase in the health empowerment scores for the experimental group that received the training program compared to the control group.","The mean of the pre-test for the experimental group was (1.97 - 0.27), and for the control group, it was (1.84 - 0.21).","The post-test mean for the experimental group became (3.88 - 0.13), while for the control group, it was (1.85 - 0.20).","The follow-up test also demonstrated that the enhanced health empowerment levels were maintained in the experimental group, with no significant difference between the post-test and follow-up scores, indicating the effectiveness of the health education training program in enhancing health empowerment for refugees in Jordan."],"url":"http://arxiv.org/abs/2403.01343v1","category":"cs.SI"}
{"created":"2024-03-02 21:16:38","title":"Review of top quark mass measurements in CMS","abstract":"The top quark mass is one of the most intriguing parameters of the standard model (SM). Its value indicates a Yukawa coupling close to unity, and the resulting strong ties to the Higgs physics make the top quark mass a crucial ingredient for understanding essential aspects of the electroweak sector of the SM. While it is such an important parameter of the SM, its measurement and interpretation in terms of the Lagrangian parameter are challenging. The CMS Collaboration has performed multiple measurements of the top quark mass, addressing these challenges from different angles: highly precise `direct' measurements, using the top quark decay products, as well as `indirect' measurements aiming at accurate interpretations in terms of the Lagrangian parameter. Recent mass measurements using Lorentz-boosted top quarks are particularly promising, opening a new avenue of measurements based on top quark decay products contained in a single particle jet, with superior prospects for accurate theoretical interpretations. Moreover, dedicated studies of the dominant uncertainties in the modelling of the signal processes have been performed. This review offers the first comprehensive overview of these measurements performed by the CMS Collaboration using the data collected at centre-of-mass energies of 7, 8, and 13 TeV.","sentences":["The top quark mass is one of the most intriguing parameters of the standard model (SM).","Its value indicates a Yukawa coupling close to unity, and the resulting strong ties to the Higgs physics make the top quark mass a crucial ingredient for understanding essential aspects of the electroweak sector of the SM.","While it is such an important parameter of the SM, its measurement and interpretation in terms of the Lagrangian parameter are challenging.","The CMS Collaboration has performed multiple measurements of the top quark mass, addressing these challenges from different angles: highly precise `direct' measurements, using the top quark decay products, as well as `indirect' measurements aiming at accurate interpretations in terms of the Lagrangian parameter.","Recent mass measurements using Lorentz-boosted top quarks are particularly promising, opening a new avenue of measurements based on top quark decay products contained in a single particle jet, with superior prospects for accurate theoretical interpretations.","Moreover, dedicated studies of the dominant uncertainties in the modelling of the signal processes have been performed.","This review offers the first comprehensive overview of these measurements performed by the CMS Collaboration using the data collected at centre-of-mass energies of 7, 8, and 13 TeV."],"url":"http://arxiv.org/abs/2403.01313v1","category":"hep-ex"}
{"created":"2024-03-02 19:04:20","title":"Characterizing Ethereum Upgradable Smart Contracts and Their Security Implications","abstract":"Upgradeable smart contracts (USCs) have been widely adopted to enable modifying deployed smart contracts. While USCs bring great flexibility to developers, improper usage might introduce new security issues, potentially allowing attackers to hijack USCs and their users. In this paper, we conduct a large-scale measurement study to characterize USCs and their security implications in the wild. We summarize six commonly used USC patterns and develop a tool, USCDetector, to identify USCs without needing source code. Particularly, USCDetector collects various information such as bytecode and transaction information to construct upgrade chains for USCs and disclose potentially vulnerable ones. We evaluate USCDetector using verified smart contracts (i.e., with source code) as ground truth and show that USCDetector can achieve high accuracy with a precision of 96.26%. We then use USCDetector to conduct a large-scale study on Ethereum, covering a total of 60,251,064 smart contracts. USCDetecor constructs 10,218 upgrade chains and discloses multiple real-world USCs with potential security issues.","sentences":["Upgradeable smart contracts (USCs) have been widely adopted to enable modifying deployed smart contracts.","While USCs bring great flexibility to developers, improper usage might introduce new security issues, potentially allowing attackers to hijack USCs and their users.","In this paper, we conduct a large-scale measurement study to characterize USCs and their security implications in the wild.","We summarize six commonly used USC patterns and develop a tool, USCDetector, to identify USCs without needing source code.","Particularly, USCDetector collects various information such as bytecode and transaction information to construct upgrade chains for USCs and disclose potentially vulnerable ones.","We evaluate USCDetector using verified smart contracts (i.e., with source code) as ground truth and show that USCDetector can achieve high accuracy with a precision of 96.26%.","We then use USCDetector to conduct a large-scale study on Ethereum, covering a total of 60,251,064 smart contracts.","USCDetecor constructs 10,218 upgrade chains and discloses multiple real-world USCs with potential security issues."],"url":"http://arxiv.org/abs/2403.01290v1","category":"cs.CR"}
{"created":"2024-03-02 13:34:43","title":"The Science of Data Collection: Insights from Surveys can Improve Machine Learning Models","abstract":"Whether future AI models make the world safer or less safe for humans rests in part on our ability to efficiently collect accurate data from people about what they want the models to do. However, collecting high quality data is difficult, and most AI/ML researchers are not trained in data collection methods. The growing emphasis on data-centric AI highlights the potential of data to enhance model performance. It also reveals an opportunity to gain insights from survey methodology, the science of collecting high-quality survey data.   In this position paper, we summarize lessons from the survey methodology literature and discuss how they can improve the quality of training and feedback data, which in turn improve model performance. Based on the cognitive response process model, we formulate specific hypotheses about the aspects of label collection that may impact training data quality. We also suggest collaborative research ideas into how possible biases in data collection can be mitigated, making models more accurate and human-centric.","sentences":["Whether future AI models make the world safer or less safe for humans rests in part on our ability to efficiently collect accurate data from people about what they want the models to do.","However, collecting high quality data is difficult, and most AI/ML researchers are not trained in data collection methods.","The growing emphasis on data-centric AI highlights the potential of data to enhance model performance.","It also reveals an opportunity to gain insights from survey methodology, the science of collecting high-quality survey data.   ","In this position paper, we summarize lessons from the survey methodology literature and discuss how they can improve the quality of training and feedback data, which in turn improve model performance.","Based on the cognitive response process model, we formulate specific hypotheses about the aspects of label collection that may impact training data quality.","We also suggest collaborative research ideas into how possible biases in data collection can be mitigated, making models more accurate and human-centric."],"url":"http://arxiv.org/abs/2403.01208v1","category":"cs.HC"}
{"created":"2024-03-02 12:44:38","title":"Atacama Large Aperture Submillimeter Telescope (AtLAST) science: Gas and dust in nearby galaxies","abstract":"Understanding the physical processes that regulate star formation and galaxy evolution are major areas of activity in modern astrophysics. Nearby galaxies offer unique opportunities to inspect interstellar medium (ISM), star formation (SF), radiative, dynamic and magnetic physics in great detail from sub-galactic (kpc) scales to sub-cloud (sub-pc) scales, from quiescent galaxies to starbursts, and from field galaxies to overdensities. In this case study, we discuss the major breakthroughs in this area of research that will be enabled by the Atacama Large Aperture Submillimeter Telescope (AtLAST), a proposed 50-m single-dish submillimeter telescope. The new discovery space of AtLAST comes from its exceptional sensitivity, in particular to extended low surface brightness emission, a very large 2 degree field of view, and correspondingly high mapping efficiency. This paper focuses on four themes which will particularly benefit from AtLAST: 1) the LMC and SMC, 2) extragalactic magnetic fields, 3) the physics and chemistry of the interstellar medium, and 4) star formation and galaxy evolution. With ~1000-2000h surveys each, AtLAST could deliver deep dust continuum maps of the entire LMC and SMC fields at parsec-scale resolution, high-resolution maps of the magnetic field structure, gas density, temperature and composition of the dense and diffuse ISM in ~100 nearby galaxies, as well as the first large-scale blind CO survey in the nearby Universe, delivering molecular gas masses for up to 10^6 galaxies (3 orders of magnitude more than current samples). Through such observing campaigns, AtLAST will have a profound impact on our understanding of the baryon cycle and star formation across a wide range of environments.","sentences":["Understanding the physical processes that regulate star formation and galaxy evolution are major areas of activity in modern astrophysics.","Nearby galaxies offer unique opportunities to inspect interstellar medium (ISM), star formation (SF), radiative, dynamic and magnetic physics in great detail from sub-galactic (kpc) scales to sub-cloud (sub-pc) scales, from quiescent galaxies to starbursts, and from field galaxies to overdensities.","In this case study, we discuss the major breakthroughs in this area of research that will be enabled by the Atacama Large Aperture Submillimeter Telescope (AtLAST), a proposed 50-m single-dish submillimeter telescope.","The new discovery space of AtLAST comes from its exceptional sensitivity, in particular to extended low surface brightness emission, a very large 2 degree field of view, and correspondingly high mapping efficiency.","This paper focuses on four themes which will particularly benefit from AtLAST: 1) the LMC and SMC, 2) extragalactic magnetic fields, 3) the physics and chemistry of the interstellar medium, and 4) star formation and galaxy evolution.","With ~1000-2000h surveys each, AtLAST could deliver deep dust continuum maps of the entire LMC and SMC fields at parsec-scale resolution, high-resolution maps of the magnetic field structure, gas density, temperature and composition of the dense and diffuse ISM in ~100 nearby galaxies, as well as the first large-scale blind CO survey in the nearby Universe, delivering molecular gas masses for up to 10^6 galaxies (3 orders of magnitude more than current samples).","Through such observing campaigns, AtLAST will have a profound impact on our understanding of the baryon cycle and star formation across a wide range of environments."],"url":"http://arxiv.org/abs/2403.01202v1","category":"astro-ph.GA"}
{"created":"2024-03-02 11:29:09","title":"Shaping Multi-Robot Patrol Performance with Heterogeneity in Individual Learning Behavior","abstract":"Individual differences in learning behavior within social groups, whether in humans, other animals, or among robots, can have significant effects on collective task performance. This is because it can affect individuals' response to the environment and their interactions with each other. In recent years there has been rising interest in the question of how individual differences, whether in learning or other traits, affect collective outcomes: studied, for example, in social insect foraging behavior. Multi-robot, 'swarm' systems have a heritage of bioinspiration from such examples, and here we consider whether heterogeneity in a learning behavior called latent inhibition (LI) may be useful for a team of patrolling robots tasked with environmental monitoring and anomaly detection. Individuals with high LI can be seen as better at learning to be inattentive to irrelevant or unrewarding stimuli, while low LI individuals might be seen as 'distractible' and yet, more positively, more exploratory. We introduce a simple model of the effects of LI as the probability of re-searching a location for a reward (anomalous reading) where it has previously been found to be unrewarding (irrelevant). In simulated patrols, we find that a negatively skewed distribution of mostly high LI robots, and just a single low LI robot, is collectively most effective at monitoring dynamic environments. These results are an example of 'functional heterogeneity' in 'swarm engineering' and could inform predictions for ecological distributions of learning traits within social groups.","sentences":["Individual differences in learning behavior within social groups, whether in humans, other animals, or among robots, can have significant effects on collective task performance.","This is because it can affect individuals' response to the environment and their interactions with each other.","In recent years there has been rising interest in the question of how individual differences, whether in learning or other traits, affect collective outcomes: studied, for example, in social insect foraging behavior.","Multi-robot, 'swarm' systems have a heritage of bioinspiration from such examples, and here we consider whether heterogeneity in a learning behavior called latent inhibition (LI) may be useful for a team of patrolling robots tasked with environmental monitoring and anomaly detection.","Individuals with high LI can be seen as better at learning to be inattentive to irrelevant or unrewarding stimuli, while low LI individuals might be seen as 'distractible' and yet, more positively, more exploratory.","We introduce a simple model of the effects of LI as the probability of re-searching a location for a reward (anomalous reading) where it has previously been found to be unrewarding (irrelevant).","In simulated patrols, we find that a negatively skewed distribution of mostly high LI robots, and just a single low LI robot, is collectively most effective at monitoring dynamic environments.","These results are an example of 'functional heterogeneity' in 'swarm engineering' and could inform predictions for ecological distributions of learning traits within social groups."],"url":"http://arxiv.org/abs/2403.01181v1","category":"cs.RO"}
{"created":"2024-03-02 10:56:27","title":"Electroproduction of the Lambda/Sigma^0 hyperons at Q^2~0.5 (GeV/c)^2 in forward angles","abstract":"In 2018, the E12-17-003 experiment was conducted at the Thomas Jefferson National Accelerator Facility (JLab) to explore the possible existence of an nnLambda state in the reconstructed missing mass distribution from a tritium gas target. As part of this investigation, data was also collected using a gaseous hydrogen target, not only for a precise absolute mass scale calibration but also for the study of Lambda/Sigma^0 electroproduction. This dataset was acquired at Q^2~0.5 (GeV/c)^2, W=2.14 GeV, and theta_{gamma K}^{c.m.}~8 deg. It covers forward angles where photoproduction data is scarce and a low-Q^2 region that is of interest for hypernuclear experiments. On the other hand, this kinematic region is at a slightly higher Q^2 than previous hypernuclear experiments, thus providing crucial information for understanding the Q^2 dependence of the differential cross sections for Lambda/Sigma^0 hyperon electroproduction. This paper reports on the Q^2 dependence of the differential cross section for the e + p -> e' + K^+ + Lambda/Sigma^0 reaction in the 0.2-0.8 (GeV/c)^2, and provides comparisons with the currently available theoretical models.","sentences":["In 2018, the E12-17-003 experiment was conducted at the Thomas Jefferson National Accelerator Facility (JLab) to explore the possible existence of an nnLambda state in the reconstructed missing mass distribution from a tritium gas target.","As part of this investigation, data was also collected using a gaseous hydrogen target, not only for a precise absolute mass scale calibration but also for the study of Lambda/Sigma^0 electroproduction.","This dataset was acquired at Q^2~0.5 (GeV/c)^2, W=2.14 GeV, and theta_{gamma K}^{c.m.}~8 deg.","It covers forward angles where photoproduction data is scarce and a low-Q^2 region that is of interest for hypernuclear experiments.","On the other hand, this kinematic region is at a slightly higher Q^2 than previous hypernuclear experiments, thus providing crucial information for understanding the Q^2 dependence of the differential cross sections for Lambda/Sigma^0 hyperon electroproduction.","This paper reports on the Q^2 dependence of the differential cross section for the e + p -> e' + K^+ + Lambda/Sigma^0 reaction in the 0.2-0.8 (GeV/c)^2, and provides comparisons with the currently available theoretical models."],"url":"http://arxiv.org/abs/2403.01173v1","category":"nucl-ex"}
{"created":"2024-03-02 10:40:50","title":"Mean-Field Games Modeling of Anticipation in Dense Crowds","abstract":"Understanding and modeling pedestrian dynamics in dense crowds is a complex yet essential aspect of crowd management and urban planning. In this work, we investigate the dynamics of a dense crowd crossed by a cylindrical intruder using a Mean-Field Game (MFG) model. By incorporating a discount factor to account for pedestrians' limited anticipation and information processing, we examine the model's ability to simulate two distinct experimental configurations: pedestrians facing the obstacle and pedestrians giving their back to the intruder. Through a comprehensive comparison with experimental data, we demonstrate that the MFG model effectively captures essential crowd behaviors, including anticipatory motion and collision avoidance.","sentences":["Understanding and modeling pedestrian dynamics in dense crowds is a complex yet essential aspect of crowd management and urban planning.","In this work, we investigate the dynamics of a dense crowd crossed by a cylindrical intruder using a Mean-Field Game (MFG) model.","By incorporating a discount factor to account for pedestrians' limited anticipation and information processing, we examine the model's ability to simulate two distinct experimental configurations: pedestrians facing the obstacle and pedestrians giving their back to the intruder.","Through a comprehensive comparison with experimental data, we demonstrate that the MFG model effectively captures essential crowd behaviors, including anticipatory motion and collision avoidance."],"url":"http://arxiv.org/abs/2403.01168v1","category":"physics.soc-ph"}
{"created":"2024-03-03 01:36:11","title":"Enhancing Retinal Vascular Structure Segmentation in Images With a Novel Design Two-Path Interactive Fusion Module Model","abstract":"Precision in identifying and differentiating micro and macro blood vessels in the retina is crucial for the diagnosis of retinal diseases, although it poses a significant challenge. Current autoencoding-based segmentation approaches encounter limitations as they are constrained by the encoder and undergo a reduction in resolution during the encoding stage. The inability to recover lost information in the decoding phase further impedes these approaches. Consequently, their capacity to extract the retinal microvascular structure is restricted. To address this issue, we introduce Swin-Res-Net, a specialized module designed to enhance the precision of retinal vessel segmentation. Swin-Res-Net utilizes the Swin transformer which uses shifted windows with displacement for partitioning, to reduce network complexity and accelerate model convergence. Additionally, the model incorporates interactive fusion with a functional module in the Res2Net architecture. The Res2Net leverages multi-scale techniques to enlarge the receptive field of the convolutional kernel, enabling the extraction of additional semantic information from the image. This combination creates a new module that enhances the localization and separation of micro vessels in the retina. To improve the efficiency of processing vascular information, we've added a module to eliminate redundant information between the encoding and decoding steps.   Our proposed architecture produces outstanding results, either meeting or surpassing those of other published models. The AUC reflects significant enhancements, achieving values of 0.9956, 0.9931, and 0.9946 in pixel-wise segmentation of retinal vessels across three widely utilized datasets: CHASE-DB1, DRIVE, and STARE, respectively. Moreover, Swin-Res-Net outperforms alternative architectures, demonstrating superior performance in both IOU and F1 measure metrics.","sentences":["Precision in identifying and differentiating micro and macro blood vessels in the retina is crucial for the diagnosis of retinal diseases, although it poses a significant challenge.","Current autoencoding-based segmentation approaches encounter limitations as they are constrained by the encoder and undergo a reduction in resolution during the encoding stage.","The inability to recover lost information in the decoding phase further impedes these approaches.","Consequently, their capacity to extract the retinal microvascular structure is restricted.","To address this issue, we introduce Swin-Res-Net, a specialized module designed to enhance the precision of retinal vessel segmentation.","Swin-Res-Net utilizes the Swin transformer which uses shifted windows with displacement for partitioning, to reduce network complexity and accelerate model convergence.","Additionally, the model incorporates interactive fusion with a functional module in the Res2Net architecture.","The Res2Net leverages multi-scale techniques to enlarge the receptive field of the convolutional kernel, enabling the extraction of additional semantic information from the image.","This combination creates a new module that enhances the localization and separation of micro vessels in the retina.","To improve the efficiency of processing vascular information, we've added a module to eliminate redundant information between the encoding and decoding steps.   ","Our proposed architecture produces outstanding results, either meeting or surpassing those of other published models.","The AUC reflects significant enhancements, achieving values of 0.9956, 0.9931, and 0.9946 in pixel-wise segmentation of retinal vessels across three widely utilized datasets: CHASE-DB1, DRIVE, and STARE, respectively.","Moreover, Swin-Res-Net outperforms alternative architectures, demonstrating superior performance in both IOU and F1 measure metrics."],"url":"http://arxiv.org/abs/2403.01362v1","category":"eess.IV"}
{"created":"2024-03-03 01:09:43","title":"Security and Privacy Enhancing in Blockchain-based IoT Environments via Anonym Auditing","abstract":"The integration of blockchain technology in Internet of Things (IoT) environments is a revolutionary step towards ensuring robust security and enhanced privacy. This paper delves into the unique challenges and solutions associated with securing blockchain-based IoT systems, with a specific focus on anonymous auditing to reinforce privacy and security. We propose a novel framework that combines the decentralized nature of blockchain with advanced security protocols tailored for IoT contexts. Central to our approach is the implementation of anonymization techniques in auditing processes, ensuring user privacy while maintaining the integrity and transparency of blockchain transactions. We outline the architecture of blockchain in IoT environments, emphasizing the workflow and specific security mechanisms employed. Additionally, we introduce a security protocol that integrates privacy-enhancing tools and anonymous auditing methods, including the use of advanced cryptographic techniques for anonymity. This study also includes a comparative analysis of our proposed framework against existing models in the domain. Our work aims to provide a comprehensive blueprint for enhancing security and privacy in blockchain-based IoT environments, paving the way for more secure and private digital ecosystems.","sentences":["The integration of blockchain technology in Internet of Things (IoT) environments is a revolutionary step towards ensuring robust security and enhanced privacy.","This paper delves into the unique challenges and solutions associated with securing blockchain-based IoT systems, with a specific focus on anonymous auditing to reinforce privacy and security.","We propose a novel framework that combines the decentralized nature of blockchain with advanced security protocols tailored for IoT contexts.","Central to our approach is the implementation of anonymization techniques in auditing processes, ensuring user privacy while maintaining the integrity and transparency of blockchain transactions.","We outline the architecture of blockchain in IoT environments, emphasizing the workflow and specific security mechanisms employed.","Additionally, we introduce a security protocol that integrates privacy-enhancing tools and anonymous auditing methods, including the use of advanced cryptographic techniques for anonymity.","This study also includes a comparative analysis of our proposed framework against existing models in the domain.","Our work aims to provide a comprehensive blueprint for enhancing security and privacy in blockchain-based IoT environments, paving the way for more secure and private digital ecosystems."],"url":"http://arxiv.org/abs/2403.01356v1","category":"cs.CR"}
{"created":"2024-03-03 00:08:08","title":"Quantum Stabilization and Flat Hydrogen-based Bands of Nitrogen-doped Lutetium Hydride","abstract":"A plausible candidate for near-ambient superconductivity in the Lu-H-N system, Fm$\\overline{3}$m Lu$_8$H$_{23}$N, is found to be harmonically unstable up to 20 GPa, but is anharmonically stabilized at near-ambient pressures when including quantum corrections. The presence of flat bands near E$_F$ is understood to come from quantum interference caused by the nitrogen, creating a nearly flat hydrogen band at E$_F$ with huge effective mass, meaning non-adiabatic corrections are expected to be anomalously large. The superconducting T$_c$ of Fm$\\overline{3}$m Lu$_8$H$_{23}$N is estimated to be high by comparison to related compounds and flat band models. The resiliency to defects and pressure dependence of the flat bands is examined. The results here imply this structure is metastable yet flexible enough to synthesize and has electronic properties that can explain the reported near-ambient superconductivity in Lu-H-N.","sentences":["A plausible candidate for near-ambient superconductivity in the Lu-H-N system, Fm$\\overline{3}$m Lu$_8$H$_{23}$N, is found to be harmonically unstable up to 20 GPa, but is anharmonically stabilized at near-ambient pressures when including quantum corrections.","The presence of flat bands near E$_F$ is understood to come from quantum interference caused by the nitrogen, creating a nearly flat hydrogen band at E$_F$ with huge effective mass, meaning non-adiabatic corrections are expected to be anomalously large.","The superconducting T$_c$ of Fm$\\overline{3}$m Lu$_8$H$_{23}$N is estimated to be high by comparison to related compounds and flat band models.","The resiliency to defects and pressure dependence of the flat bands is examined.","The results here imply this structure is metastable yet flexible enough to synthesize and has electronic properties that can explain the reported near-ambient superconductivity in Lu-H-N."],"url":"http://arxiv.org/abs/2403.01350v1","category":"cond-mat.supr-con"}
{"created":"2024-03-03 00:03:34","title":"OSM: Leveraging Model Checking for Observing Dynamic 1 behaviors in Aspect-Oriented Applications","abstract":"In the intricate domain of software systems verification, dynamically model checking multifaceted system characteristics remains paramount, yet challenging. This research proposes the advanced observe-based statistical model-checking (OSM) framework, devised to craft executable formal models directly from foundational system code. Leveraging model checking predicates, the framework melds seamlessly with aspect-oriented programming paradigms, yielding a potent method for the analytical verification of varied behavioral attributes. Exploiting the transformative capacity of OSM framework, primary system code undergoes a systematic metamorphosis into multifaceted analysis constructs. This not only simplifies the model verification process but also orchestrates feature interactions using an innovative observing join point abstraction mechanism. Within this framework, components encompassing parsing, formal verification, computational analytics, and rigorous validation are intrinsically interwoven. Marrying the principles of model checking with aspect-oriented (AO) modularization, OSM framework stands as a paragon, proficiently scrutinizing and affirming system specifications. This ensures the unyielding performance of electronic health record systems amidst shifting preconditions. OSM framework offers runtime verification of both object-oriented and AO deployments, positioning itself as an indispensable open-source resource, poised to automate the enhancement of system performance and scalability.","sentences":["In the intricate domain of software systems verification, dynamically model checking multifaceted system characteristics remains paramount, yet challenging.","This research proposes the advanced observe-based statistical model-checking (OSM) framework, devised to craft executable formal models directly from foundational system code.","Leveraging model checking predicates, the framework melds seamlessly with aspect-oriented programming paradigms, yielding a potent method for the analytical verification of varied behavioral attributes.","Exploiting the transformative capacity of OSM framework, primary system code undergoes a systematic metamorphosis into multifaceted analysis constructs.","This not only simplifies the model verification process but also orchestrates feature interactions using an innovative observing join point abstraction mechanism.","Within this framework, components encompassing parsing, formal verification, computational analytics, and rigorous validation are intrinsically interwoven.","Marrying the principles of model checking with aspect-oriented (AO) modularization, OSM framework stands as a paragon, proficiently scrutinizing and affirming system specifications.","This ensures the unyielding performance of electronic health record systems amidst shifting preconditions.","OSM framework offers runtime verification of both object-oriented and AO deployments, positioning itself as an indispensable open-source resource, poised to automate the enhancement of system performance and scalability."],"url":"http://arxiv.org/abs/2403.01349v1","category":"cs.SE"}
{"created":"2024-03-02 23:32:33","title":"LM4OPT: Unveiling the Potential of Large Language Models in Formulating Mathematical Optimization Problems","abstract":"In the rapidly evolving field of natural language processing, the translation of linguistic descriptions into mathematical formulation of optimization problems presents a formidable challenge, demanding intricate understanding and processing capabilities from Large Language Models (LLMs). This study compares prominent LLMs, including GPT-3.5, GPT-4, and Llama-2-7b, in zero-shot and one-shot settings for this task. Our findings show GPT-4's superior performance, particularly in the one-shot scenario. A central part of this research is the introduction of `LM4OPT,' a progressive fine-tuning framework for Llama-2-7b that utilizes noisy embeddings and specialized datasets. However, this research highlights a notable gap in the contextual understanding capabilities of smaller models such as Llama-2-7b compared to larger counterparts, especially in processing lengthy and complex input contexts. Our empirical investigation, utilizing the NL4Opt dataset, unveils that GPT-4 surpasses the baseline performance established by previous research, achieving an F1-score of 0.63, solely based on the problem description in natural language, and without relying on any additional named entity information. GPT-3.5 follows closely, both outperforming the fine-tuned Llama-2-7b. These findings not only benchmark the current capabilities of LLMs in a novel application area but also lay the groundwork for future improvements in mathematical formulation of optimization problems from natural language input.","sentences":["In the rapidly evolving field of natural language processing, the translation of linguistic descriptions into mathematical formulation of optimization problems presents a formidable challenge, demanding intricate understanding and processing capabilities from Large Language Models (LLMs).","This study compares prominent LLMs, including GPT-3.5, GPT-4, and Llama-2-7b, in zero-shot and one-shot settings for this task.","Our findings show GPT-4's superior performance, particularly in the one-shot scenario.","A central part of this research is the introduction of `LM4OPT,' a progressive fine-tuning framework for Llama-2-7b that utilizes noisy embeddings and specialized datasets.","However, this research highlights a notable gap in the contextual understanding capabilities of smaller models such as Llama-2-7b compared to larger counterparts, especially in processing lengthy and complex input contexts.","Our empirical investigation, utilizing the NL4Opt dataset, unveils that GPT-4 surpasses the baseline performance established by previous research, achieving an F1-score of 0.63, solely based on the problem description in natural language, and without relying on any additional named entity information.","GPT-3.5 follows closely, both outperforming the fine-tuned Llama-2-7b.","These findings not only benchmark the current capabilities of LLMs in a novel application area but also lay the groundwork for future improvements in mathematical formulation of optimization problems from natural language input."],"url":"http://arxiv.org/abs/2403.01342v1","category":"cs.CL"}
{"created":"2024-03-02 22:38:44","title":"Quantifying Maximum Actuator Degradation for a Given $H_2/H_{\\infty}$ Performance with Full-State Feedback Control","abstract":"In this paper, we address the issue of quantifying maximum actuator degradation in linear time-invariant dynamical systems. We present a new unified framework for computing the state-feedback controller gain that meets a user-defined closed-loop performance criterion while also maximizing actuator degradation. This degradation is modeled as a first-order filter with additive noise. Our approach involves two novel convex optimization formulations that concurrently determine the controller gain, maximize actuator degradation, and maintain the desired closed-loop performance in both the $H_2$ and $H_{\\infty}$ system norms. The results are limited to open-loop stable systems. We demonstrate the application of our results through the design of a full-state feedback controller for a model representing the longitudinal motion of the F-16 aircraft.","sentences":["In this paper, we address the issue of quantifying maximum actuator degradation in linear time-invariant dynamical systems.","We present a new unified framework for computing the state-feedback controller gain that meets a user-defined closed-loop performance criterion while also maximizing actuator degradation.","This degradation is modeled as a first-order filter with additive noise.","Our approach involves two novel convex optimization formulations that concurrently determine the controller gain, maximize actuator degradation, and maintain the desired closed-loop performance in both the $H_2$ and $H_{\\infty}$ system norms.","The results are limited to open-loop stable systems.","We demonstrate the application of our results through the design of a full-state feedback controller for a model representing the longitudinal motion of the F-16 aircraft."],"url":"http://arxiv.org/abs/2403.01333v1","category":"eess.SY"}
{"created":"2024-03-02 22:25:32","title":"Measuring Entanglement in Physical Networks","abstract":"The links of a physical network cannot cross, which often forces the network layout into non- optimal entangled states. Here we define a network fabric as a two-dimensional projection of a network and propose the average crossing number as a measure of network entanglement. We analytically derive the dependence of the crossing number on network density, average link length, degree heterogeneity, and community structure and show that the predictions accurately estimate the entanglement of both network models and of real physical networks.","sentences":["The links of a physical network cannot cross, which often forces the network layout into non- optimal entangled states.","Here we define a network fabric as a two-dimensional projection of a network and propose the average crossing number as a measure of network entanglement.","We analytically derive the dependence of the crossing number on network density, average link length, degree heterogeneity, and community structure and show that the predictions accurately estimate the entanglement of both network models and of real physical networks."],"url":"http://arxiv.org/abs/2403.01328v1","category":"cond-mat.dis-nn"}
{"created":"2024-03-02 21:33:23","title":"Less is More: Hop-Wise Graph Attention for Scalable and Generalizable Learning on Circuits","abstract":"While graph neural networks (GNNs) have gained popularity for learning circuit representations in various electronic design automation (EDA) tasks, they face challenges in scalability when applied to large graphs and exhibit limited generalizability to new designs. These limitations make them less practical for addressing large-scale, complex circuit problems. In this work we propose HOGA, a novel attention-based model for learning circuit representations in a scalable and generalizable manner. HOGA first computes hop-wise features per node prior to model training. Subsequently, the hop-wise features are solely used to produce node representations through a gated self-attention module, which adaptively learns important features among different hops without involving the graph topology. As a result, HOGA is adaptive to various structures across different circuits and can be efficiently trained in a distributed manner. To demonstrate the efficacy of HOGA, we consider two representative EDA tasks: quality of results (QoR) prediction and functional reasoning. Our experimental results indicate that (1) HOGA reduces estimation error over conventional GNNs by 46.76% for predicting QoR after logic synthesis; (2) HOGA improves 10.0% reasoning accuracy over GNNs for identifying functional blocks on unseen gate-level netlists after complex technology mapping; (3) The training time for HOGA almost linearly decreases with an increase in computing resources.","sentences":["While graph neural networks (GNNs) have gained popularity for learning circuit representations in various electronic design automation (EDA) tasks, they face challenges in scalability when applied to large graphs and exhibit limited generalizability to new designs.","These limitations make them less practical for addressing large-scale, complex circuit problems.","In this work we propose HOGA, a novel attention-based model for learning circuit representations in a scalable and generalizable manner.","HOGA first computes hop-wise features per node prior to model training.","Subsequently, the hop-wise features are solely used to produce node representations through a gated self-attention module, which adaptively learns important features among different hops without involving the graph topology.","As a result, HOGA is adaptive to various structures across different circuits and can be efficiently trained in a distributed manner.","To demonstrate the efficacy of HOGA, we consider two representative EDA tasks: quality of results (QoR) prediction and functional reasoning.","Our experimental results indicate that (1) HOGA reduces estimation error over conventional GNNs by 46.76% for predicting QoR after logic synthesis; (2) HOGA improves 10.0% reasoning accuracy over GNNs for identifying functional blocks on unseen gate-level netlists after complex technology mapping; (3) The training time for HOGA almost linearly decreases with an increase in computing resources."],"url":"http://arxiv.org/abs/2403.01317v1","category":"cs.LG"}
{"created":"2024-03-02 21:10:06","title":"High-coherence superconducting qubits made using industry-standard, advanced semiconductor manufacturing","abstract":"The development of superconducting qubit technology has shown great potential for the construction of practical quantum computers. As the complexity of quantum processors continues to grow, the need for stringent fabrication tolerances becomes increasingly critical. Utilizing advanced industrial fabrication processes could facilitate the necessary level of fabrication control to support the continued scaling of quantum processors. However, these industrial processes are currently not optimized to produce high coherence devices, nor are they a priori compatible with the commonly used approaches to make superconducting qubits. In this work, we demonstrate for the first time superconducting transmon qubits manufactured in a 300 mm CMOS pilot line, using industrial fabrication methods, with resulting relaxation and coherence times already exceeding 100 microseconds. We show across-wafer, large-scale statistics studies of coherence, yield, variability, and aging that confirm the validity of our approach. The presented industry-scale fabrication process, using exclusively optical lithography and reactive ion etching, shows performance and yield similar to the conventional laboratory-style techniques utilizing metal lift-off, angled evaporation, and electron-beam writing. Moreover, it offers potential for further upscaling by including three-dimensional integration and additional process optimization using advanced metrology and judicious choice of processing parameters and splits. This result marks the advent of more reliable, large-scale, truly CMOS-compatible fabrication of superconducting quantum computing processors.","sentences":["The development of superconducting qubit technology has shown great potential for the construction of practical quantum computers.","As the complexity of quantum processors continues to grow, the need for stringent fabrication tolerances becomes increasingly critical.","Utilizing advanced industrial fabrication processes could facilitate the necessary level of fabrication control to support the continued scaling of quantum processors.","However, these industrial processes are currently not optimized to produce high coherence devices, nor are they a priori compatible with the commonly used approaches to make superconducting qubits.","In this work, we demonstrate for the first time superconducting transmon qubits manufactured in a 300 mm CMOS pilot line, using industrial fabrication methods, with resulting relaxation and coherence times already exceeding 100 microseconds.","We show across-wafer, large-scale statistics studies of coherence, yield, variability, and aging that confirm the validity of our approach.","The presented industry-scale fabrication process, using exclusively optical lithography and reactive ion etching, shows performance and yield similar to the conventional laboratory-style techniques utilizing metal lift-off, angled evaporation, and electron-beam writing.","Moreover, it offers potential for further upscaling by including three-dimensional integration and additional process optimization using advanced metrology and judicious choice of processing parameters and splits.","This result marks the advent of more reliable, large-scale, truly CMOS-compatible fabrication of superconducting quantum computing processors."],"url":"http://arxiv.org/abs/2403.01312v1","category":"quant-ph"}
{"created":"2024-03-02 21:01:01","title":"Image-Based Dietary Assessment: A Healthy Eating Plate Estimation System","abstract":"The nutritional quality of diets has significantly deteriorated over the past two to three decades, a decline often underestimated by the people. This deterioration, coupled with a hectic lifestyle, has contributed to escalating health concerns. Recognizing this issue, researchers at Harvard have advocated for a balanced nutritional plate model to promote health. Inspired by this research, our paper introduces an innovative Image-Based Dietary Assessment system aimed at evaluating the healthiness of meals through image analysis. Our system employs advanced image segmentation and classification techniques to analyze food items on a plate, assess their proportions, and calculate meal adherence to Harvard's healthy eating recommendations. This approach leverages machine learning and nutritional science to empower individuals with actionable insights for healthier eating choices. Our four-step framework involves segmenting the image, classifying the items, conducting a nutritional assessment based on the Harvard Healthy Eating Plate research, and offering tailored recommendations. The prototype system has shown promising results in promoting healthier eating habits by providing an accessible, evidence-based tool for dietary assessment.","sentences":["The nutritional quality of diets has significantly deteriorated over the past two to three decades, a decline often underestimated by the people.","This deterioration, coupled with a hectic lifestyle, has contributed to escalating health concerns.","Recognizing this issue, researchers at Harvard have advocated for a balanced nutritional plate model to promote health.","Inspired by this research, our paper introduces an innovative Image-Based Dietary Assessment system aimed at evaluating the healthiness of meals through image analysis.","Our system employs advanced image segmentation and classification techniques to analyze food items on a plate, assess their proportions, and calculate meal adherence to Harvard's healthy eating recommendations.","This approach leverages machine learning and nutritional science to empower individuals with actionable insights for healthier eating choices.","Our four-step framework involves segmenting the image, classifying the items, conducting a nutritional assessment based on the Harvard Healthy Eating Plate research, and offering tailored recommendations.","The prototype system has shown promising results in promoting healthier eating habits by providing an accessible, evidence-based tool for dietary assessment."],"url":"http://arxiv.org/abs/2403.01310v1","category":"cs.CV"}
{"created":"2024-03-02 20:39:36","title":"Negative Temperature in Spin Dynamics Simulations","abstract":"A simple and computationally efficient algorithm enables implementing negative temperature values in a spin dynamics simulation. The algorithm uses a Langevin spin dynamics thermostat with a negative damping parameter, enabling the thermalization of an arbitrary interacting spin system to the Gibbs energy distribution with a given negative temperature value. Canonical spin dynamics simulations at a negative temperature are as robust as conventional positive spin temperature simulations, providing a tool for quantitative dynamic studies of the physics of highly excited magnetic states. Two simulation case studies describing spin systems with antiferromagnetic and ferromagnetic ground states are explored. The phase transitions occurring in the negative temperature range do not necessarily exhibit similarities with their positive temperature counterparts. The transition temperatures and the character of spin alignment vary depending on the spatial range and strength of spin-spin interactions.","sentences":["A simple and computationally efficient algorithm enables implementing negative temperature values in a spin dynamics simulation.","The algorithm uses a Langevin spin dynamics thermostat with a negative damping parameter, enabling the thermalization of an arbitrary interacting spin system to the Gibbs energy distribution with a given negative temperature value.","Canonical spin dynamics simulations at a negative temperature are as robust as conventional positive spin temperature simulations, providing a tool for quantitative dynamic studies of the physics of highly excited magnetic states.","Two simulation case studies describing spin systems with antiferromagnetic and ferromagnetic ground states are explored.","The phase transitions occurring in the negative temperature range do not necessarily exhibit similarities with their positive temperature counterparts.","The transition temperatures and the character of spin alignment vary depending on the spatial range and strength of spin-spin interactions."],"url":"http://arxiv.org/abs/2403.01307v1","category":"cond-mat.mtrl-sci"}
{"created":"2024-03-02 19:55:38","title":"Supplier Recommendation in Online Procurement","abstract":"Supply chain optimization is key to a healthy and profitable business. Many companies use online procurement systems to agree contracts with suppliers. It is vital that the most competitive suppliers are invited to bid for such contracts. In this work, we propose a recommender system to assist with supplier discovery in road freight online procurement. Our system is able to provide personalized supplier recommendations, taking into account customer needs and preferences. This is a novel application of recommender systems, calling for design choices that fit the unique requirements of online procurement. Our preliminary results, using real-world data, are promising.","sentences":["Supply chain optimization is key to a healthy and profitable business.","Many companies use online procurement systems to agree contracts with suppliers.","It is vital that the most competitive suppliers are invited to bid for such contracts.","In this work, we propose a recommender system to assist with supplier discovery in road freight online procurement.","Our system is able to provide personalized supplier recommendations, taking into account customer needs and preferences.","This is a novel application of recommender systems, calling for design choices that fit the unique requirements of online procurement.","Our preliminary results, using real-world data, are promising."],"url":"http://arxiv.org/abs/2403.01301v1","category":"cs.IR"}
{"created":"2024-03-02 19:43:38","title":"Spontaneous assembly of condensate networks during the demixing of structured fluids","abstract":"Liquid-liquid phase separation, whereby two liquids spontaneously demix, is ubiquitous in industrial, environmental, and biological processes. While isotropic fluids are known to condense into spherical droplets in the binodal region, these dynamics are poorly understood for structured fluids. Here, we report the novel observation of condensate networks, which spontaneously assemble during the demixing of a mesogen from a solvent. Condensing mesogens form rapidly-elongating filaments, rather than spheres, to relieve distortion of a simultaneously-forming internal smectic mesophase. As filaments densify, they collapse into bulged discs, lowering the elastic free energy. Additional distortion is relieved by retraction of filaments into the bulged discs, which are straightened under tension to form a ramified network. Understanding and controlling these dynamics may provide new avenues to direct pattern formation or template materials.","sentences":["Liquid-liquid phase separation, whereby two liquids spontaneously demix, is ubiquitous in industrial, environmental, and biological processes.","While isotropic fluids are known to condense into spherical droplets in the binodal region, these dynamics are poorly understood for structured fluids.","Here, we report the novel observation of condensate networks, which spontaneously assemble during the demixing of a mesogen from a solvent.","Condensing mesogens form rapidly-elongating filaments, rather than spheres, to relieve distortion of a simultaneously-forming internal smectic mesophase.","As filaments densify, they collapse into bulged discs, lowering the elastic free energy.","Additional distortion is relieved by retraction of filaments into the bulged discs, which are straightened under tension to form a ramified network.","Understanding and controlling these dynamics may provide new avenues to direct pattern formation or template materials."],"url":"http://arxiv.org/abs/2403.01298v1","category":"cond-mat.soft"}
{"created":"2024-03-02 19:21:04","title":"A Search for Temporal Atmospheric Variability of $\\textit{Kepler}$ Hot Jupiters","abstract":"We perform a systematic search for atmospheric variability in short-period gas-giant planets (hot Jupiters) observed by the Kepler mission, by looking for temporal variability of their secondary eclipse depths. This is motivated by a recent detection of a decrease in the dayside brightness of KELT-1 b between TESS Sectors 17 and 57, separated by about 3 years. We fit the Kepler light curves of 53 hot Jupiters and measure their secondary eclipse depths during individual Kepler quarters and 4-quarter windows. We detect the secondary eclipses in individual quarters or four-quarter windows for 17 out of the 53 systems. In those 17 systems we do not detect statistically significant astrophysical variation in the secondary eclipse depths. We show that the data is sensitive to the variability seen for KELT-1 b in TESS data. Therefore, the absence of detected secondary eclipse variability in Kepler data suggests that the atmospheric variability in KELT-1 b is not common. In addition, several of the 53 targets we investigated display variability in their transit depths with a period of 4 quarters (1 year). This instrumental signal is likely present in the light curves of other transiting planets we did not analyze and other variable stars observed by Kepler. Finally, we find that Kepler-488 b has a secondary eclipse depth that is unphysically large for a planet, and thus is likely a misclassified red dwarf.","sentences":["We perform a systematic search for atmospheric variability in short-period gas-giant planets (hot Jupiters) observed by the Kepler mission, by looking for temporal variability of their secondary eclipse depths.","This is motivated by a recent detection of a decrease in the dayside brightness of KELT-1 b between TESS Sectors 17 and 57, separated by about 3 years.","We fit the Kepler light curves of 53 hot Jupiters and measure their secondary eclipse depths during individual Kepler quarters and 4-quarter windows.","We detect the secondary eclipses in individual quarters or four-quarter windows for 17 out of the 53 systems.","In those 17 systems we do not detect statistically significant astrophysical variation in the secondary eclipse depths.","We show that the data is sensitive to the variability seen for KELT-1 b in TESS data.","Therefore, the absence of detected secondary eclipse variability in Kepler data suggests that the atmospheric variability in KELT-1 b is not common.","In addition, several of the 53 targets we investigated display variability in their transit depths with a period of 4 quarters (1 year).","This instrumental signal is likely present in the light curves of other transiting planets we did not analyze and other variable stars observed by Kepler.","Finally, we find that Kepler-488 b has a secondary eclipse depth that is unphysically large for a planet, and thus is likely a misclassified red dwarf."],"url":"http://arxiv.org/abs/2403.01295v1","category":"astro-ph.EP"}
{"created":"2024-03-02 18:41:14","title":"Angular Momentum Transfer between a Molecular System and a Continuous Circularly Polarized Light Field under the Born-Oppenheimer Framework","abstract":"We demonstrate (both analytically and numerically) total angular momentum conservation for a molecular system subject to circularly polarized light (CPL) field moving along a single Born-Oppenheimer surface, where all of the angular momentum transfer is embodied in a Berry force. Moreover, we demonstrate that the model Hamiltonian proposed in [J. Chem. Phys. 150, 124101 (2019)] in fact corresponds physically to a homonuclear diatomic in a CPL field. Our results not only reveal an interesting microscopic mechanism for angular momentum transfer between a molecule and a radiation field, but they also provide new insight into the nature of novel semiclassical non-adiabatic dynamics methods that conserve the total angular momentum (including, e.g., phase-space surface-hopping methods).","sentences":["We demonstrate (both analytically and numerically) total angular momentum conservation for a molecular system subject to circularly polarized light (CPL) field moving along a single Born-Oppenheimer surface, where all of the angular momentum transfer is embodied in a Berry force.","Moreover, we demonstrate that the model Hamiltonian proposed in [J. Chem.","Phys. 150, 124101 (2019)] in fact corresponds physically to a homonuclear diatomic in a CPL field.","Our results not only reveal an interesting microscopic mechanism for angular momentum transfer between a molecule and a radiation field, but they also provide new insight into the nature of novel semiclassical non-adiabatic dynamics methods that conserve the total angular momentum (including, e.g., phase-space surface-hopping methods)."],"url":"http://arxiv.org/abs/2403.01284v1","category":"physics.chem-ph"}
{"created":"2024-03-02 18:37:08","title":"On the Arnold diffusion mechanism in Medium Earth Orbit","abstract":"Space debris mitigation guidelines represent the most effective method to preserve the circumterrestrial environment. Among them, end-of-life disposal solutions play a key role. A growing effort is devoted to exploit natural perturbations to lead the satellites towards an atmospheric reentry, reducing the disposal cost, also if departing from high-altitude regions. In the case of the Medium Earth Orbit region, home of the navigation satellites (like Galileo), the main driver is the gravitational perturbation due to the Moon, that can increase the eccentricity in the long term. In this way, the pericenter altitude can get into the atmospheric drag domain and the satellite can eventually reenter.   In this work, we show how an Arnold diffusion mechanism can trigger the eccentricity growth. Focusing on the case of Galileo, we consider a hierarchy of Hamiltonian models, assuming that the main perturbations on the motion of the spacecraft are the oblateness of the Earth and the gravitational attraction of the Moon. First, the Moon is assumed to lay on the ecliptic plane and periodic orbits and associated stable and unstable invariant manifolds are computed for various energy levels, in the neighborhood of a given resonance. Along each invariant manifold, the eccentricity increases naturally, achieving its maximum at the first intersection between them. This growth is, however, not sufficient to achieve reentry. By moving to a model where the inclination of the Moon is taken into account, the problem becomes non-autonomous and the satellite is able to move along different energy levels. Under the ansatz of transversality of the manifolds in the autonomous case, checked numerically, Poincar\\'e-Melnikov techniques are applied to show how diffusion can be attained, by constructing a sequence of homoclinic orbits that connect invariant tori at different energy levels.","sentences":["Space debris mitigation guidelines represent the most effective method to preserve the circumterrestrial environment.","Among them, end-of-life disposal solutions play a key role.","A growing effort is devoted to exploit natural perturbations to lead the satellites towards an atmospheric reentry, reducing the disposal cost, also if departing from high-altitude regions.","In the case of the Medium Earth Orbit region, home of the navigation satellites (like Galileo), the main driver is the gravitational perturbation due to the Moon, that can increase the eccentricity in the long term.","In this way, the pericenter altitude can get into the atmospheric drag domain and the satellite can eventually reenter.   ","In this work, we show how an Arnold diffusion mechanism can trigger the eccentricity growth.","Focusing on the case of Galileo, we consider a hierarchy of Hamiltonian models, assuming that the main perturbations on the motion of the spacecraft are the oblateness of the Earth and the gravitational attraction of the Moon.","First, the Moon is assumed to lay on the ecliptic plane and periodic orbits and associated stable and unstable invariant manifolds are computed for various energy levels, in the neighborhood of a given resonance.","Along each invariant manifold, the eccentricity increases naturally, achieving its maximum at the first intersection between them.","This growth is, however, not sufficient to achieve reentry.","By moving to a model where the inclination of the Moon is taken into account, the problem becomes non-autonomous and the satellite is able to move along different energy levels.","Under the ansatz of transversality of the manifolds in the autonomous case, checked numerically, Poincar\\'e-Melnikov techniques are applied to show how diffusion can be attained, by constructing a sequence of homoclinic orbits that connect invariant tori at different energy levels."],"url":"http://arxiv.org/abs/2403.01283v1","category":"math.DS"}
{"created":"2024-03-02 17:32:14","title":"Modal weak Kleene logics: axiomatizations and relational semantics","abstract":"Weak Kleene logics are three-valued logics characterized by the presence of an infectious truth-value. In their external versions, as they were originally introduced by Bochvar and Hallden, these systems are equipped with an additional connective capable of expressing whether a formula is classically true. In this paper we further expand the expressive power of external weak Kleen logics by modalizing them with a unary operator. The addition of an alethic modality gives rise to the two systems $\\B^{\\square}$ and $MPWK$, which have two different readings of the modal operator. We provide these logics with a complete and decidable Hilbert-style axiomatization w.r.t. a three-valued possible worlds semantics. The starting point of these calculi are new axiomatizations for the non-modal bases B and PWKe, which we provide using the recent algebraization results about these two logics. In particular, we prove the algebraizability of $\\PWKe$. Finally some standard extensions of the basic modal systems are provided with their completeness results w.r.t. special classes of frames.","sentences":["Weak Kleene logics are three-valued logics characterized by the presence of an infectious truth-value.","In their external versions, as they were originally introduced by Bochvar and Hallden, these systems are equipped with an additional connective capable of expressing whether a formula is classically true.","In this paper we further expand the expressive power of external weak Kleen logics by modalizing them with a unary operator.","The addition of an alethic modality gives rise to the two systems $\\B^{\\square}$ and $MPWK$, which have two different readings of the modal operator.","We provide these logics with a complete and decidable Hilbert-style axiomatization w.r.t.","a three-valued possible worlds semantics.","The starting point of these calculi are new axiomatizations for the non-modal bases B and PWKe, which we provide using the recent algebraization results about these two logics.","In particular, we prove the algebraizability of $\\PWKe$. Finally some standard extensions of the basic modal systems are provided with their completeness results w.r.t.","special classes of frames."],"url":"http://arxiv.org/abs/2403.01274v1","category":"math.LO"}
{"created":"2024-03-02 16:59:56","title":"Smooth Computation without Input Delay: Robust Tube-Based Model Predictive Control for Robot Manipulator Planning","abstract":"Model Predictive Control (MPC) has exhibited remarkable capabilities in optimizing objectives and meeting constraints. However, the substantial computational burden associated with solving the Optimal Control Problem (OCP) at each triggering instant introduces significant delays between state sampling and control application. These delays limit the practicality of MPC in resource-constrained systems when engaging in complex tasks. The intuition to address this issue in this paper is that by predicting the successor state, the controller can solve the OCP one time step ahead of time thus avoiding the delay of the next action. To this end, we compute deviations between real and nominal system states, predicting forthcoming real states as initial conditions for the imminent OCP solution. Anticipatory computation stores optimal control based on current nominal states, thus mitigating the delay effects. Additionally, we establish an upper bound for linearization error, effectively linearizing the nonlinear system, reducing OCP complexity, and enhancing response speed. We provide empirical validation through two numerical simulations and corresponding real-world robot tasks, demonstrating significant performance improvements and augmented response speed (up to $90\\%$) resulting from the seamless integration of our proposed approach compared to conventional time-triggered MPC strategies.","sentences":["Model Predictive Control (MPC) has exhibited remarkable capabilities in optimizing objectives and meeting constraints.","However, the substantial computational burden associated with solving the Optimal Control Problem (OCP) at each triggering instant introduces significant delays between state sampling and control application.","These delays limit the practicality of MPC in resource-constrained systems when engaging in complex tasks.","The intuition to address this issue in this paper is that by predicting the successor state, the controller can solve the OCP one time step ahead of time thus avoiding the delay of the next action.","To this end, we compute deviations between real and nominal system states, predicting forthcoming real states as initial conditions for the imminent OCP solution.","Anticipatory computation stores optimal control based on current nominal states, thus mitigating the delay effects.","Additionally, we establish an upper bound for linearization error, effectively linearizing the nonlinear system, reducing OCP complexity, and enhancing response speed.","We provide empirical validation through two numerical simulations and corresponding real-world robot tasks, demonstrating significant performance improvements and augmented response speed (up to $90\\%$) resulting from the seamless integration of our proposed approach compared to conventional time-triggered MPC strategies."],"url":"http://arxiv.org/abs/2403.01265v1","category":"cs.RO"}
{"created":"2024-03-02 16:55:17","title":"Efficient Alternative Finite Difference WENO Schemes for Hyperbolic Conservation Laws","abstract":"Higher order finite difference Weighted Essentially Non-Oscillatory (WENO) schemes for conservation laws are extremely popular because, for multidimensional problems, they offer high order accuracy at a fraction of the cost of finite volume WENO or DG schemes. Such schemes come in two formulations. The very popular classical finite difference WENO (FD-WENO) method (Shu and Osher, J. Comput. Phys., 83 (1989) 32-78) relies two reconstruction steps applied to two split fluxes. However, the method cannot accommodate different types of Riemann solvers and cannot preserve free stream boundary conditions on curvilinear meshes. This limits its utility. The alternative finite difference WENO (AFD-WENO) method can overcome these deficiencies, however, much less work has been done on this method. The reasons are three-fold. First, it is difficult for the casual reader to understand the intricate logic that requires higher order derivatives of the fluxes to be evaluated at zone boundaries. The analytical methods for deriving the update equation for AFD-WENO schemes are somewhat recondite. To overcome that difficulty, we provide an easily accessible script that is based on a computer algebra system in Appendix A of this paper. Second, the method relies on interpolation rather than reconstruction, and WENO interpolation formulae have not been documented in the literature as thoroughly as WENO reconstruction formulae. In this paper, we explicitly provide all necessary WENO interpolation formulae that are needed for implementing AFD-WENO up to ninth order. The third reason is that AFD-WENO requires higher order derivatives of the fluxes to be available at zone boundaries. Since those derivatives are usually obtained by finite differencing the zone-centered fluxes, they become susceptible to a Gibbs phenomenon when the solution ...","sentences":["Higher order finite difference Weighted Essentially Non-Oscillatory (WENO) schemes for conservation laws are extremely popular because, for multidimensional problems, they offer high order accuracy at a fraction of the cost of finite volume WENO or DG schemes.","Such schemes come in two formulations.","The very popular classical finite difference WENO (FD-WENO) method (Shu and Osher, J. Comput.","Phys., 83 (1989) 32-78) relies two reconstruction steps applied to two split fluxes.","However, the method cannot accommodate different types of Riemann solvers and cannot preserve free stream boundary conditions on curvilinear meshes.","This limits its utility.","The alternative finite difference WENO (AFD-WENO) method can overcome these deficiencies, however, much less work has been done on this method.","The reasons are three-fold.","First, it is difficult for the casual reader to understand the intricate logic that requires higher order derivatives of the fluxes to be evaluated at zone boundaries.","The analytical methods for deriving the update equation for AFD-WENO schemes are somewhat recondite.","To overcome that difficulty, we provide an easily accessible script that is based on a computer algebra system in Appendix A of this paper.","Second, the method relies on interpolation rather than reconstruction, and WENO interpolation formulae have not been documented in the literature as thoroughly as WENO reconstruction formulae.","In this paper, we explicitly provide all necessary WENO interpolation formulae that are needed for implementing AFD-WENO up to ninth order.","The third reason is that AFD-WENO requires higher order derivatives of the fluxes to be available at zone boundaries.","Since those derivatives are usually obtained by finite differencing the zone-centered fluxes, they become susceptible to a Gibbs phenomenon when the solution ..."],"url":"http://arxiv.org/abs/2403.01264v1","category":"math.NA"}
{"created":"2024-03-02 16:51:35","title":"Single-image camera calibration with model-free distortion correction","abstract":"Camera calibration is a process of paramount importance in computer vision applications that require accurate quantitative measurements. The popular method developed by Zhang relies on the use of a large number of images of a planar grid of fiducial points captured in multiple poses. Although flexible and easy to implement, Zhang's method has some limitations. The simultaneous optimization of the entire parameter set, including the coefficients of a predefined distortion model, may result in poor distortion correction at the image boundaries or in miscalculation of the intrinsic parameters, even with a reasonably small reprojection error. Indeed, applications involving image stitching (e.g. multi-camera systems) require accurate mapping of distortion up to the outermost regions of the image. Moreover, intrinsic parameters affect the accuracy of camera pose estimation, which is fundamental for applications such as vision servoing in robot navigation and automated assembly. This paper proposes a method for estimating the complete set of calibration parameters from a single image of a planar speckle pattern covering the entire sensor. The correspondence between image points and physical points on the calibration target is obtained using Digital Image Correlation. The effective focal length and the extrinsic parameters are calculated separately after a prior evaluation of the principal point. At the end of the procedure, a dense and uniform model-free distortion map is obtained over the entire image. Synthetic data with different noise levels were used to test the feasibility of the proposed method and to compare its metrological performance with Zhang's method. Real-world tests demonstrate the potential of the developed method to reveal aspects of the image formation that are hidden by averaging over multiple images.","sentences":["Camera calibration is a process of paramount importance in computer vision applications that require accurate quantitative measurements.","The popular method developed by Zhang relies on the use of a large number of images of a planar grid of fiducial points captured in multiple poses.","Although flexible and easy to implement, Zhang's method has some limitations.","The simultaneous optimization of the entire parameter set, including the coefficients of a predefined distortion model, may result in poor distortion correction at the image boundaries or in miscalculation of the intrinsic parameters, even with a reasonably small reprojection error.","Indeed, applications involving image stitching (e.g. multi-camera systems) require accurate mapping of distortion up to the outermost regions of the image.","Moreover, intrinsic parameters affect the accuracy of camera pose estimation, which is fundamental for applications such as vision servoing in robot navigation and automated assembly.","This paper proposes a method for estimating the complete set of calibration parameters from a single image of a planar speckle pattern covering the entire sensor.","The correspondence between image points and physical points on the calibration target is obtained using Digital Image Correlation.","The effective focal length and the extrinsic parameters are calculated separately after a prior evaluation of the principal point.","At the end of the procedure, a dense and uniform model-free distortion map is obtained over the entire image.","Synthetic data with different noise levels were used to test the feasibility of the proposed method and to compare its metrological performance with Zhang's method.","Real-world tests demonstrate the potential of the developed method to reveal aspects of the image formation that are hidden by averaging over multiple images."],"url":"http://arxiv.org/abs/2403.01263v1","category":"cs.CV"}
{"created":"2024-03-02 16:41:01","title":"GSL-LPA: Fast Label Propagation Algorithm (LPA) for Community Detection with no Internally-Disconnected Communities","abstract":"Community detection is the problem of identifying tightly connected clusters of nodes within a network. Efficient parallel algorithms for this play a crucial role in various applications, especially as datasets expand to significant sizes. The Label Propagation Algorithm (LPA) is commonly employed for this purpose due to its ease of parallelization, rapid execution, and scalability. However, it may yield internally disconnected communities. This technical report introduces GSL-LPA, derived from our parallelization of LPA, namely GVE-LPA. Our experiments on a system with two 16-core Intel Xeon Gold 6226R processors show that GSL-LPA not only mitigates this issue but also surpasses FLPA, igraph LPA, and NetworKit LPA by 55x, 10,300x, and 5.8x, respectively, achieving a processing rate of 844 M edges/s on a 3.8 B edge graph. Additionally, GSL-LPA scales at a rate of 1.6x for every doubling of threads.","sentences":["Community detection is the problem of identifying tightly connected clusters of nodes within a network.","Efficient parallel algorithms for this play a crucial role in various applications, especially as datasets expand to significant sizes.","The Label Propagation Algorithm (LPA) is commonly employed for this purpose due to its ease of parallelization, rapid execution, and scalability.","However, it may yield internally disconnected communities.","This technical report introduces GSL-LPA, derived from our parallelization of LPA, namely GVE-LPA.","Our experiments on a system with two 16-core Intel Xeon Gold 6226R processors show that GSL-LPA not only mitigates this issue but also surpasses FLPA, igraph LPA, and NetworKit LPA by 55x, 10,300x, and 5.8x, respectively, achieving a processing rate of 844 M edges/s on a 3.8 B edge graph.","Additionally, GSL-LPA scales at a rate of 1.6x for every doubling of threads."],"url":"http://arxiv.org/abs/2403.01261v1","category":"cs.DC"}
{"created":"2024-03-02 16:39:38","title":"Decentralized Implicit Differentiation","abstract":"The ability to differentiate through optimization problems has unlocked numerous applications, from optimization-based layers in machine learning models to complex design problems formulated as bilevel programs. It has been shown that exploiting problem structure can yield significant computation gains for optimization and, in some cases, enable distributed computation. One should expect that this structure can be similarly exploited for gradient computation. In this work, we discuss a decentralized framework for computing gradients of constraint-coupled optimization problems. First, we show that this framework results in significant computational gains, especially for large systems, and provide sufficient conditions for its validity. Second, we leverage exponential decay of sensitivities in graph-structured problems towards building a fully distributed algorithm with convergence guarantees. Finally, we use the methodology to rigorously estimate marginal emissions rates in power systems models. Specifically, we demonstrate how the distributed scheme allows for accurate and efficient estimation of these important emissions metrics on large dynamic power system models.","sentences":["The ability to differentiate through optimization problems has unlocked numerous applications, from optimization-based layers in machine learning models to complex design problems formulated as bilevel programs.","It has been shown that exploiting problem structure can yield significant computation gains for optimization and, in some cases, enable distributed computation.","One should expect that this structure can be similarly exploited for gradient computation.","In this work, we discuss a decentralized framework for computing gradients of constraint-coupled optimization problems.","First, we show that this framework results in significant computational gains, especially for large systems, and provide sufficient conditions for its validity.","Second, we leverage exponential decay of sensitivities in graph-structured problems towards building a fully distributed algorithm with convergence guarantees.","Finally, we use the methodology to rigorously estimate marginal emissions rates in power systems models.","Specifically, we demonstrate how the distributed scheme allows for accurate and efficient estimation of these important emissions metrics on large dynamic power system models."],"url":"http://arxiv.org/abs/2403.01260v1","category":"math.OC"}
{"created":"2024-03-02 16:32:41","title":"Secure and Scalable Network Slicing with Plug-and-Play Support for Power Distribution System Communication Networks","abstract":"With the rapid development of power distribution systems (PDSs), the number of terminal devices and the types of delivered services involved are constantly growing. These trends make the operations of PDSs highly dependent on the support of advanced communication networks, which face two related challenges. The first is to provide sufficient flexibility, resilience, and security to meet varying demands and ensure the proper operation of gradually diversifying network services. The second is to realize the automatic identification of terminal devices, thus reducing the network maintenance burden. To solve these problems, this paper presents a novel multiservice network integration and device authentication slice-based network slicing scheme. In this scheme, the integration of PDS communication networks enables network resource sharing, and recovery from communication interruption is achieved through network slicing in the integrated network. Authentication servers periodically poll terminal devices, adjusting network slice ranges based on authentication results, thereby facilitating dynamic network slicing. Additionally, secure plug-and-play support for PDS terminal devices and network protection are achieved through device identification and dynamic adjustment of network slices. On this basis, a network optimization and upgrading methodology for load balancing and robustness enhancement is further proposed. This approach is designed to improve the performance of PDS communication networks, adapting to ongoing PDS development and the evolution of PDS services. The simulation results show that the proposed schemes endow a PDS communication network with favorable resource utilization, fault recovery, terminal device plug-and-play support, load balancing, and improved network robustness.","sentences":["With the rapid development of power distribution systems (PDSs), the number of terminal devices and the types of delivered services involved are constantly growing.","These trends make the operations of PDSs highly dependent on the support of advanced communication networks, which face two related challenges.","The first is to provide sufficient flexibility, resilience, and security to meet varying demands and ensure the proper operation of gradually diversifying network services.","The second is to realize the automatic identification of terminal devices, thus reducing the network maintenance burden.","To solve these problems, this paper presents a novel multiservice network integration and device authentication slice-based network slicing scheme.","In this scheme, the integration of PDS communication networks enables network resource sharing, and recovery from communication interruption is achieved through network slicing in the integrated network.","Authentication servers periodically poll terminal devices, adjusting network slice ranges based on authentication results, thereby facilitating dynamic network slicing.","Additionally, secure plug-and-play support for PDS terminal devices and network protection are achieved through device identification and dynamic adjustment of network slices.","On this basis, a network optimization and upgrading methodology for load balancing and robustness enhancement is further proposed.","This approach is designed to improve the performance of PDS communication networks, adapting to ongoing PDS development and the evolution of PDS services.","The simulation results show that the proposed schemes endow a PDS communication network with favorable resource utilization, fault recovery, terminal device plug-and-play support, load balancing, and improved network robustness."],"url":"http://arxiv.org/abs/2403.01257v1","category":"eess.SY"}
{"created":"2024-03-02 16:28:04","title":"Resilient Microgrid Formation Considering Communication Interruptions","abstract":"Distribution system (DS) communication failures following extreme events often degrade monitoring and control functions, thus preventing the acquisition of complete global DS component state information, on which existing post-disaster DS restoration methods are based. This letter proposes methods of inferring the states of DS components in the case of incomplete component state information. By using the known DS information, the operating states of unobservable DS branches and buses can be inferred, providing complete information for DS performance restoration before full communication recovery","sentences":["Distribution system (DS) communication failures following extreme events often degrade monitoring and control functions, thus preventing the acquisition of complete global DS component state information, on which existing post-disaster DS restoration methods are based.","This letter proposes methods of inferring the states of DS components in the case of incomplete component state information.","By using the known DS information, the operating states of unobservable DS branches and buses can be inferred, providing complete information for DS performance restoration before full communication recovery"],"url":"http://arxiv.org/abs/2403.01256v1","category":"eess.SY"}
{"created":"2024-03-02 16:24:15","title":"Strategic SDN-based Microgrid Formation for Managing Communication Failures in Distribution System Restoration","abstract":"Grid modernization has increased the reliance of power networks on cyber networks within distribution systems (DSs), heightening their vulnerability to disasters. Communication network failures significantly impede DS load recovery by diminishing observation and control. Prior research has largely ignored the need for integrated recovery of DS power and cyber networks' centralized control. Indeed, communication network restoration is critical for speedy load recovery through DS automation based microgrid formation. This paper exploits the data routing capabilities of software-defined networking (SDN) to enhance centralized control recovery in DS communication networks, incorporating it into a comprehensive DS restoration model. This model, tailored to the control requirements of load restoration, strategically allocates limited communication resources to re-establish connections between the operation center and terminal devices. Subsequently, DS automation is employed to orchestrate DS microgrid formation for power resupply. Additionally, we introduce a cyclic algorithm designed to optimize the load recovery via a multi-step, cooperative process. The efficacy of the proposed method is demonstrated on IEEE 33-node and IEEE 123-node test feeders.","sentences":["Grid modernization has increased the reliance of power networks on cyber networks within distribution systems (DSs), heightening their vulnerability to disasters.","Communication network failures significantly impede DS load recovery by diminishing observation and control.","Prior research has largely ignored the need for integrated recovery of DS power and cyber networks' centralized control.","Indeed, communication network restoration is critical for speedy load recovery through DS automation based microgrid formation.","This paper exploits the data routing capabilities of software-defined networking (SDN) to enhance centralized control recovery in DS communication networks, incorporating it into a comprehensive DS restoration model.","This model, tailored to the control requirements of load restoration, strategically allocates limited communication resources to re-establish connections between the operation center and terminal devices.","Subsequently, DS automation is employed to orchestrate DS microgrid formation for power resupply.","Additionally, we introduce a cyclic algorithm designed to optimize the load recovery via a multi-step, cooperative process.","The efficacy of the proposed method is demonstrated on IEEE 33-node and IEEE 123-node test feeders."],"url":"http://arxiv.org/abs/2403.01253v1","category":"eess.SY"}
{"created":"2024-03-02 16:20:41","title":"Resilient Mobile Energy Storage Resources Based Distribution Network Restoration in Interdependent Power-Transportation-Information Networks","abstract":"The interactions between power, transportation, and information networks (PTIN), are becoming more profound with the advent of smart city technologies. Existing mobile energy storage resource (MESR)-based power distribution network (PDN) restoration schemes often neglect the interdependencies among PTIN, thus, efficient PDN restoration cannot be achieved. This paper outlines the interacting factors of power supply demand, traffic operation efficiency, communication coverage, electric vehicle (EV) deployment capability, and PDN controllability among PTIN and further develops a PTIN-interacting model to reflect the chained recovery effect of the MESR-based restoration process. On this basis, a two-stage PDN restoration scheme is proposed that utilizes three emergency resources, including EVs, mobile energy storage systems (MESSs), and unmanned aerial vehicles (UAVs), to restore the power supply and communication of PDNs. This scheme first improves the distribution automation function, EV deployment capability, and traffic operation efficiency by prioritizing the recovery of communication network (CN) and urban traffic network (UTN) loads. Then, EVs and MESSs are further scheduled to achieve a better PDN restoration effect with the support of the restored CNs and UTNs. Case studies on a PDN, CN, and UTN integrated test system are conducted to verify the effectiveness of the proposed scheme. The results show that the prioritized load recovery operation for CN and UTN facilities in this scheme greatly improves the PDN restoration effect.","sentences":["The interactions between power, transportation, and information networks (PTIN), are becoming more profound with the advent of smart city technologies.","Existing mobile energy storage resource (MESR)-based power distribution network (PDN) restoration schemes often neglect the interdependencies among PTIN, thus, efficient PDN restoration cannot be achieved.","This paper outlines the interacting factors of power supply demand, traffic operation efficiency, communication coverage, electric vehicle (EV) deployment capability, and PDN controllability among PTIN and further develops a PTIN-interacting model to reflect the chained recovery effect of the MESR-based restoration process.","On this basis, a two-stage PDN restoration scheme is proposed that utilizes three emergency resources, including EVs, mobile energy storage systems (MESSs), and unmanned aerial vehicles (UAVs), to restore the power supply and communication of PDNs.","This scheme first improves the distribution automation function, EV deployment capability, and traffic operation efficiency by prioritizing the recovery of communication network (CN) and urban traffic network (UTN) loads.","Then, EVs and MESSs are further scheduled to achieve a better PDN restoration effect with the support of the restored CNs and UTNs.","Case studies on a PDN, CN, and UTN integrated test system are conducted to verify the effectiveness of the proposed scheme.","The results show that the prioritized load recovery operation for CN and UTN facilities in this scheme greatly improves the PDN restoration effect."],"url":"http://arxiv.org/abs/2403.01250v1","category":"eess.SY"}
{"created":"2024-03-02 15:47:42","title":"On the Road to Portability: Compressing End-to-End Motion Planner for Autonomous Driving","abstract":"End-to-end motion planning models equipped with deep neural networks have shown great potential for enabling full autonomous driving. However, the oversized neural networks render them impractical for deployment on resource-constrained systems, which unavoidably requires more computational time and resources during reference.To handle this, knowledge distillation offers a promising approach that compresses models by enabling a smaller student model to learn from a larger teacher model. Nevertheless, how to apply knowledge distillation to compress motion planners has not been explored so far. In this paper, we propose PlanKD, the first knowledge distillation framework tailored for compressing end-to-end motion planners. First, considering that driving scenes are inherently complex, often containing planning-irrelevant or even noisy information, transferring such information is not beneficial for the student planner. Thus, we design an information bottleneck based strategy to only distill planning-relevant information, rather than transfer all information indiscriminately. Second, different waypoints in an output planned trajectory may hold varying degrees of importance for motion planning, where a slight deviation in certain crucial waypoints might lead to a collision. Therefore, we devise a safety-aware waypoint-attentive distillation module that assigns adaptive weights to different waypoints based on the importance, to encourage the student to accurately mimic more crucial waypoints, thereby improving overall safety. Experiments demonstrate that our PlanKD can boost the performance of smaller planners by a large margin, and significantly reduce their reference time.","sentences":["End-to-end motion planning models equipped with deep neural networks have shown great potential for enabling full autonomous driving.","However, the oversized neural networks render them impractical for deployment on resource-constrained systems, which unavoidably requires more computational time and resources during reference.","To handle this, knowledge distillation offers a promising approach that compresses models by enabling a smaller student model to learn from a larger teacher model.","Nevertheless, how to apply knowledge distillation to compress motion planners has not been explored so far.","In this paper, we propose PlanKD, the first knowledge distillation framework tailored for compressing end-to-end motion planners.","First, considering that driving scenes are inherently complex, often containing planning-irrelevant or even noisy information, transferring such information is not beneficial for the student planner.","Thus, we design an information bottleneck based strategy to only distill planning-relevant information, rather than transfer all information indiscriminately.","Second, different waypoints in an output planned trajectory may hold varying degrees of importance for motion planning, where a slight deviation in certain crucial waypoints might lead to a collision.","Therefore, we devise a safety-aware waypoint-attentive distillation module that assigns adaptive weights to different waypoints based on the importance, to encourage the student to accurately mimic more crucial waypoints, thereby improving overall safety.","Experiments demonstrate that our PlanKD can boost the performance of smaller planners by a large margin, and significantly reduce their reference time."],"url":"http://arxiv.org/abs/2403.01238v1","category":"cs.CV"}
{"created":"2024-03-02 15:40:59","title":"Integrable and superintegrable quantum mechanical systems with position dependent masses invariant with respect to one parametric Lie groups. 1. Systems with cylindric symmetry","abstract":"Cylindrically symmetric quantum mechanical systems with position dependent masses (PDM) admitting at least one second order integral of motion are classified. It is proved that there exist 68 such systems which are inequivalent. Among them there are twenty seven superintegrable and twelve maximally superintegrable. The arbitrary elements of the correspondinding Hamiltonians (i.e.,masses and potentials) are presented explicitly.","sentences":["Cylindrically symmetric quantum mechanical systems with position dependent masses (PDM) admitting at least one second order integral of motion are classified.","It is proved that there exist 68 such systems which are inequivalent.","Among them there are twenty seven superintegrable and twelve maximally superintegrable.","The arbitrary elements of the correspondinding Hamiltonians (i.e.,masses and potentials) are presented explicitly."],"url":"http://arxiv.org/abs/2403.01235v1","category":"math-ph"}
{"created":"2024-03-02 15:32:15","title":"Results and Lessons Learned from Autonomous Driving Transportation Services in Airfield, Crowded Indoor, and Urban Environments","abstract":"Autonomous vehicles have been actively investigated over the past few decades. Several recent works show the potential of autonomous driving transportation services in urban environments with impressive experimental results. However, these works note that autonomous vehicles are still occasionally inferior to expert drivers in complex scenarios. Furthermore, they do not focus on the possibilities of autonomous driving transportation services in other areas beyond urban environments. This paper presents the research results and lessons learned from autonomous driving transportation services in airfield, crowded indoor, and urban environments. We discuss how we address several unique challenges in these diverse environments. We also offer an overview of remaining challenges that have not received much attention but must be addressed. This paper aims to share our unique experience to support researchers who are interested in realizing the potential of autonomous vehicles in various real-world environments.","sentences":["Autonomous vehicles have been actively investigated over the past few decades.","Several recent works show the potential of autonomous driving transportation services in urban environments with impressive experimental results.","However, these works note that autonomous vehicles are still occasionally inferior to expert drivers in complex scenarios.","Furthermore, they do not focus on the possibilities of autonomous driving transportation services in other areas beyond urban environments.","This paper presents the research results and lessons learned from autonomous driving transportation services in airfield, crowded indoor, and urban environments.","We discuss how we address several unique challenges in these diverse environments.","We also offer an overview of remaining challenges that have not received much attention but must be addressed.","This paper aims to share our unique experience to support researchers who are interested in realizing the potential of autonomous vehicles in various real-world environments."],"url":"http://arxiv.org/abs/2403.01233v1","category":"cs.RO"}
{"created":"2024-03-02 15:20:09","title":"Benchmarking Segmentation Models with Mask-Preserved Attribute Editing","abstract":"When deploying segmentation models in practice, it is critical to evaluate their behaviors in varied and complex scenes. Different from the previous evaluation paradigms only in consideration of global attribute variations (e.g. adverse weather), we investigate both local and global attribute variations for robustness evaluation. To achieve this, we construct a mask-preserved attribute editing pipeline to edit visual attributes of real images with precise control of structural information. Therefore, the original segmentation labels can be reused for the edited images. Using our pipeline, we construct a benchmark covering both object and image attributes (e.g. color, material, pattern, style). We evaluate a broad variety of semantic segmentation models, spanning from conventional close-set models to recent open-vocabulary large models on their robustness to different types of variations. We find that both local and global attribute variations affect segmentation performances, and the sensitivity of models diverges across different variation types. We argue that local attributes have the same importance as global attributes, and should be considered in the robustness evaluation of segmentation models. Code: https://github.com/PRIS-CV/Pascal-EA.","sentences":["When deploying segmentation models in practice, it is critical to evaluate their behaviors in varied and complex scenes.","Different from the previous evaluation paradigms only in consideration of global attribute variations (e.g. adverse weather), we investigate both local and global attribute variations for robustness evaluation.","To achieve this, we construct a mask-preserved attribute editing pipeline to edit visual attributes of real images with precise control of structural information.","Therefore, the original segmentation labels can be reused for the edited images.","Using our pipeline, we construct a benchmark covering both object and image attributes (e.g. color, material, pattern, style).","We evaluate a broad variety of semantic segmentation models, spanning from conventional close-set models to recent open-vocabulary large models on their robustness to different types of variations.","We find that both local and global attribute variations affect segmentation performances, and the sensitivity of models diverges across different variation types.","We argue that local attributes have the same importance as global attributes, and should be considered in the robustness evaluation of segmentation models.","Code: https://github.com/PRIS-CV/Pascal-EA."],"url":"http://arxiv.org/abs/2403.01231v1","category":"cs.CV"}
{"created":"2024-03-02 15:16:13","title":"Projectional entropy for actions of amenable groups","abstract":"In the current paper we attempt to transfer the notion of the projectional entropy, originally defined for multidimensional subshifts, to the case of actions of amenable groups. The main theorem states that if a system is strongly irreducible the equality of the entropy and the projectional entropy implies that the system has a product-like structure.","sentences":["In the current paper we attempt to transfer the notion of the projectional entropy, originally defined for multidimensional subshifts, to the case of actions of amenable groups.","The main theorem states that if a system is strongly irreducible the equality of the entropy and the projectional entropy implies that the system has a product-like structure."],"url":"http://arxiv.org/abs/2403.01230v1","category":"math.DS"}
{"created":"2024-03-02 14:53:55","title":"Plane-polarised finite-amplitude shear waves in deformed incompressible materials","abstract":"We investigate how two finite-amplitude, transverse, plane body waves may be superposed to propagate in a deformed hyperelastic incompressible solid. We find that the equations of motion reduce to a well-determined system of partial differential equations, making the motion controllable for all solids. We find that in deformed Mooney-Rivlin materials, they may travel along any direction and be polarised along any transverse direction, an extension of a result by Boulanger and Hayes [Quart. J. Mech. Appl. Math. 45 (1992) 575]. Furthermore, their motion is governed by a linear system of partial differential equations, making the Mooney-Rivlin special in that respect. We select another model to show that for other materials, the equations are nonlinear. We use asymptotic equations to reveal the onset of nonlinearity for the waves, paying particular attention to how close the propagation direction is to the principal axes of pre-deformation.","sentences":["We investigate how two finite-amplitude, transverse, plane body waves may be superposed to propagate in a deformed hyperelastic incompressible solid.","We find that the equations of motion reduce to a well-determined system of partial differential equations, making the motion controllable for all solids.","We find that in deformed Mooney-Rivlin materials, they may travel along any direction and be polarised along any transverse direction, an extension of a result by Boulanger and Hayes","[Quart.","J. Mech.","Appl.","Math. 45 (1992) 575].","Furthermore, their motion is governed by a linear system of partial differential equations, making the Mooney-Rivlin special in that respect.","We select another model to show that for other materials, the equations are nonlinear.","We use asymptotic equations to reveal the onset of nonlinearity for the waves, paying particular attention to how close the propagation direction is to the principal axes of pre-deformation."],"url":"http://arxiv.org/abs/2403.01227v1","category":"math.AP"}
{"created":"2024-03-02 14:47:02","title":"A Cost-Effective Cooperative Exploration and Inspection Strategy for Heterogeneous Aerial System","abstract":"In this paper, we propose a cost-effective strategy for heterogeneous UAV swarm systems for cooperative aerial inspection. Unlike previous swarm inspection works, the proposed method does not rely on precise prior knowledge of the environment and can complete full 3D surface coverage of objects in any shape. In this work, agents are partitioned into teams, with each drone assign a different task, including mapping, exploration, and inspection. Task allocation is facilitated by assigning optimal inspection volumes to each team, following best-first rules. A voxel map-based representation of the environment is used for pathfinding, and a rule-based path-planning method is the core of this approach. We achieved the best performance in all challenging experiments with the proposed approach, surpassing all benchmark methods for similar tasks across multiple evaluation trials. The proposed method is open source at https://github.com/ntu-aris/caric_baseline and used as the baseline of the Cooperative Aerial Robots Inspection Challenge at the 62nd IEEE Conference on Decision and Control 2023.","sentences":["In this paper, we propose a cost-effective strategy for heterogeneous UAV swarm systems for cooperative aerial inspection.","Unlike previous swarm inspection works, the proposed method does not rely on precise prior knowledge of the environment and can complete full 3D surface coverage of objects in any shape.","In this work, agents are partitioned into teams, with each drone assign a different task, including mapping, exploration, and inspection.","Task allocation is facilitated by assigning optimal inspection volumes to each team, following best-first rules.","A voxel map-based representation of the environment is used for pathfinding, and a rule-based path-planning method is the core of this approach.","We achieved the best performance in all challenging experiments with the proposed approach, surpassing all benchmark methods for similar tasks across multiple evaluation trials.","The proposed method is open source at https://github.com/ntu-aris/caric_baseline and used as the baseline of the Cooperative Aerial Robots Inspection Challenge at the 62nd IEEE Conference on Decision and Control 2023."],"url":"http://arxiv.org/abs/2403.01225v1","category":"cs.RO"}
{"created":"2024-03-02 14:19:21","title":"The origin of lopsided satellite galaxy distribution around isolated systems in MillenniumTNG","abstract":"Dwarf satellites in galaxy groups are distributed in an anisotropic and asymmetric manner, which is called the ``lopsided satellite distribution''. This lopsided signal has been observed not only in galaxy pairs but also in isolated systems. However, the physical origin of the lopsided signal in isolated systems is still unknown. In this work, we investigate this in the state-of-the-art hydrodynamical simulation of the MillenniumTNG Project by tracing each system back to high redshift. We find that the lopsided signal is dominated by satellites located in the outer regions of the halo and is also dominated by recently accreted satellites. The lopsided signal originates from the anisotropic accretion of galaxies from the surrounding large-scale structure and that, after accretion, the nonlinear evolution of satellites inside the dark-matter halo weakens the lopsidedness. The signal decreases as cosmic time passes because of a competition between anisotropic accretion and internal evolution within dark matter halos. Our findings provide a useful perspective for the study of galaxy evolution, especially for the origin of the spatial satellite galaxy distributions.","sentences":["Dwarf satellites in galaxy groups are distributed in an anisotropic and asymmetric manner, which is called the ``lopsided satellite distribution''.","This lopsided signal has been observed not only in galaxy pairs but also in isolated systems.","However, the physical origin of the lopsided signal in isolated systems is still unknown.","In this work, we investigate this in the state-of-the-art hydrodynamical simulation of the MillenniumTNG Project by tracing each system back to high redshift.","We find that the lopsided signal is dominated by satellites located in the outer regions of the halo and is also dominated by recently accreted satellites.","The lopsided signal originates from the anisotropic accretion of galaxies from the surrounding large-scale structure and that, after accretion, the nonlinear evolution of satellites inside the dark-matter halo weakens the lopsidedness.","The signal decreases as cosmic time passes because of a competition between anisotropic accretion and internal evolution within dark matter halos.","Our findings provide a useful perspective for the study of galaxy evolution, especially for the origin of the spatial satellite galaxy distributions."],"url":"http://arxiv.org/abs/2403.01217v1","category":"astro-ph.CO"}
{"created":"2024-03-02 14:05:56","title":"Efficient Algorithm Level Error Detection for Number-Theoretic Transform Assessed on FPGAs","abstract":"Polynomial multiplication stands out as a highly demanding arithmetic process in the development of post-quantum cryptosystems. The importance of number-theoretic transform (NTT) extends beyond post-quantum cryptosystems, proving valuable in enhancing existing security protocols such as digital signature schemes and hash functions. Due to the potential for errors to significantly disrupt the operation of secure, cryptographically-protected systems, compromising data integrity, and safeguarding against side-channel attacks initiated through faults it is essential to incorporate mitigating error detection schemes. This paper introduces algorithm level fault detection schemes in NTT multiplication, representing a significant enhancement compared to previous research. We evaluate this through the simulation of a fault model, ensuring that the conducted assessments accurately mirror the obtained results. Consequently, we attain a notably comprehensive coverage of errors. Finally, we assess the performance of our efficient error detection scheme on FPGAs to showcase its implementation and resource requirements. Through implementation of our error detection approach on Xilinx/AMD Zynq Ultrascale+ and Artix-7, we achieve a comparable throughput with just a 9% increase in area and 13% increase in latency compared to the original hardware implementations.","sentences":["Polynomial multiplication stands out as a highly demanding arithmetic process in the development of post-quantum cryptosystems.","The importance of number-theoretic transform (NTT) extends beyond post-quantum cryptosystems, proving valuable in enhancing existing security protocols such as digital signature schemes and hash functions.","Due to the potential for errors to significantly disrupt the operation of secure, cryptographically-protected systems, compromising data integrity, and safeguarding against side-channel attacks initiated through faults it is essential to incorporate mitigating error detection schemes.","This paper introduces algorithm level fault detection schemes in NTT multiplication, representing a significant enhancement compared to previous research.","We evaluate this through the simulation of a fault model, ensuring that the conducted assessments accurately mirror the obtained results.","Consequently, we attain a notably comprehensive coverage of errors.","Finally, we assess the performance of our efficient error detection scheme on FPGAs to showcase its implementation and resource requirements.","Through implementation of our error detection approach on Xilinx/AMD Zynq Ultrascale+ and Artix-7, we achieve a comparable throughput with just a 9% increase in area and 13% increase in latency compared to the original hardware implementations."],"url":"http://arxiv.org/abs/2403.01215v1","category":"cs.CR"}
{"created":"2024-03-02 13:19:51","title":"Self-Lubricating Drops","abstract":"Over the past decade, there has been a growing interest in the study of multicomponent drops. These drops exhibit unique phenomena, as the interplay between hydrodynamics and the evolving physicochemical properties of the mixture gives rise to distinct and often unregulated behaviors. Of particular interest is the complex dynamic behavior of the drop contact line, which can display self-lubrication effect. The presence of a slipping contact line in self-lubricating multicomponent drops can suppress the coffee-stain effect, conferring valuable technological applications. This review will explain the current understanding of the self-lubrication effect of drops, and cover an analysis of fundamental concepts and recent advances in colloidal assembly. The potential applications of self-lubricating drops across different fields will also be highlighted.","sentences":["Over the past decade, there has been a growing interest in the study of multicomponent drops.","These drops exhibit unique phenomena, as the interplay between hydrodynamics and the evolving physicochemical properties of the mixture gives rise to distinct and often unregulated behaviors.","Of particular interest is the complex dynamic behavior of the drop contact line, which can display self-lubrication effect.","The presence of a slipping contact line in self-lubricating multicomponent drops can suppress the coffee-stain effect, conferring valuable technological applications.","This review will explain the current understanding of the self-lubrication effect of drops, and cover an analysis of fundamental concepts and recent advances in colloidal assembly.","The potential applications of self-lubricating drops across different fields will also be highlighted."],"url":"http://arxiv.org/abs/2403.01207v1","category":"physics.flu-dyn"}
{"created":"2024-03-02 12:45:01","title":"Stochastic gradient descent for streaming linear and rectified linear systems with Massart noise","abstract":"We propose SGD-exp, a stochastic gradient descent approach for linear and ReLU regressions under Massart noise (adversarial semi-random corruption model) for the fully streaming setting. We show novel nearly linear convergence guarantees of SGD-exp to the true parameter with up to $50\\%$ Massart corruption rate, and with any corruption rate in the case of symmetric oblivious corruptions. This is the first convergence guarantee result for robust ReLU regression in the streaming setting, and it shows the improved convergence rate over previous robust methods for $L_1$ linear regression due to a choice of an exponentially decaying step size, known for its efficiency in practice. Our analysis is based on the drift analysis of a discrete stochastic process, which could also be interesting on its own.","sentences":["We propose SGD-exp, a stochastic gradient descent approach for linear and ReLU regressions under Massart noise (adversarial semi-random corruption model) for the fully streaming setting.","We show novel nearly linear convergence guarantees of SGD-exp to the true parameter with up to $50\\%$ Massart corruption rate, and with any corruption rate in the case of symmetric oblivious corruptions.","This is the first convergence guarantee result for robust ReLU regression in the streaming setting, and it shows the improved convergence rate over previous robust methods for $L_1$ linear regression due to a choice of an exponentially decaying step size, known for its efficiency in practice.","Our analysis is based on the drift analysis of a discrete stochastic process, which could also be interesting on its own."],"url":"http://arxiv.org/abs/2403.01204v1","category":"cs.LG"}
{"created":"2024-03-02 12:42:59","title":"Embedding Theorems for Calabi--Yau Conifolds","abstract":"We prove that compact Calabi--Yau varieties with certain isolated singularities are projective. In dimension 3 we do this by analysis, supposing given conifold metrics. In higher dimensions it follows more readily from Ohsawa's degenerate spectral sequence.","sentences":["We prove that compact Calabi--Yau varieties with certain isolated singularities are projective.","In dimension 3 we do this by analysis, supposing given conifold metrics.","In higher dimensions it follows more readily from Ohsawa's degenerate spectral sequence."],"url":"http://arxiv.org/abs/2403.01200v1","category":"math.AG"}
{"created":"2024-03-02 11:01:33","title":"Zero-field magnetic skyrmions in exchange-biased ferromagnetic-antiferromagnetic bilayers","abstract":"We report on the stabilization of ferromagnetic skyrmions in zero external magnetic fields, in exchange-biased systems composed of ferromagnetic-antiferromagnetic (FM-AFM) bilayers. By performing atomistic spin dynamics simulations, we study cases of compensated, uncompensated, and partly uncompensated FM-AFM interfaces, and investigate the impact of important parameters such as temperature, inter-plane exchange interaction, Dzyaloshinskii-Moria interaction, and magnetic anisotropy on the skyrmions appearance and stability. The model with an uncompensated FM-AFM interface leads to the stabilization of individual skyrmions and skyrmion lattices in the FM layer, caused by the effective field from the AFM instead of an external magnetic field. Similarly, in the case of a fully compensated FM-AFM interface, we show that FM skyrmions can be stabilized. We also demonstrate that accounting for interface roughness leads to stabilization of skyrmions both in compensated and uncompensated interfaces. Moreover, in bilayers with a rough interface, skyrmions in the FM layer are observed for a wide range of exchange interaction values through the FM-AFM interface, and the chirality of the skyrmions depends critically on the exchange interaction.","sentences":["We report on the stabilization of ferromagnetic skyrmions in zero external magnetic fields, in exchange-biased systems composed of ferromagnetic-antiferromagnetic (FM-AFM) bilayers.","By performing atomistic spin dynamics simulations, we study cases of compensated, uncompensated, and partly uncompensated FM-AFM interfaces, and investigate the impact of important parameters such as temperature, inter-plane exchange interaction, Dzyaloshinskii-Moria interaction, and magnetic anisotropy on the skyrmions appearance and stability.","The model with an uncompensated FM-AFM interface leads to the stabilization of individual skyrmions and skyrmion lattices in the FM layer, caused by the effective field from the AFM instead of an external magnetic field.","Similarly, in the case of a fully compensated FM-AFM interface, we show that FM skyrmions can be stabilized.","We also demonstrate that accounting for interface roughness leads to stabilization of skyrmions both in compensated and uncompensated interfaces.","Moreover, in bilayers with a rough interface, skyrmions in the FM layer are observed for a wide range of exchange interaction values through the FM-AFM interface, and the chirality of the skyrmions depends critically on the exchange interaction."],"url":"http://arxiv.org/abs/2403.01175v1","category":"cond-mat.mtrl-sci"}
{"created":"2024-03-02 10:52:38","title":"Bethe $M$-layer construction on the Ising model","abstract":"In statistical physics, one of the standard methods to study second order phase transitions is the renormalization group that usually leads to an expansion around the corresponding fully connected solution. Unfortunately, often in disordered models, some important finite dimensional second-order phase transitions are qualitatively different or absent in the corresponding fully connected model: in such cases the standard expansion fails. Recently, a new method, the $M$-layer one, has been introduced that performs an expansion around a different soluble mean field model: the Bethe lattice one. This new method has been already used to compute the upper critical dimension $D_U$ of different disordered systems such as the Random Field Ising model or the Spin glass model with field. If then one wants to go beyond and construct an expansion around $D_U$ to understand how critical quantities get renormalized, the actual computation of all the numerical factors is needed. This next step has still not been performed, being technically more involved. In this paper we perform this computation for the ferromagnetic Ising model without quenched disorder, in finite dimensions: we show that, at one-loop order inside the $M$-layer approach, we recover the continuum quartic field theory and we are able to identify the coupling constant $g$ and the other parameters of the theory, as a function of macroscopic and microscopic details of the model such as the lattice spacing, the physical lattice dimension and the temperature. This is a fundamental step that will help in applying in the future the same techniques to more complicated systems, for which the standard field theoretical approach is impracticable.","sentences":["In statistical physics, one of the standard methods to study second order phase transitions is the renormalization group that usually leads to an expansion around the corresponding fully connected solution.","Unfortunately, often in disordered models, some important finite dimensional second-order phase transitions are qualitatively different or absent in the corresponding fully connected model: in such cases the standard expansion fails.","Recently, a new method, the $M$-layer one, has been introduced that performs an expansion around a different soluble mean field model: the Bethe lattice one.","This new method has been already used to compute the upper critical dimension $D_U$ of different disordered systems such as the Random Field Ising model or the Spin glass model with field.","If then one wants to go beyond and construct an expansion around $D_U$ to understand how critical quantities get renormalized, the actual computation of all the numerical factors is needed.","This next step has still not been performed, being technically more involved.","In this paper we perform this computation for the ferromagnetic Ising model without quenched disorder, in finite dimensions: we show that, at one-loop order inside the $M$-layer approach, we recover the continuum quartic field theory and we are able to identify the coupling constant $g$ and the other parameters of the theory, as a function of macroscopic and microscopic details of the model such as the lattice spacing, the physical lattice dimension and the temperature.","This is a fundamental step that will help in applying in the future the same techniques to more complicated systems, for which the standard field theoretical approach is impracticable."],"url":"http://arxiv.org/abs/2403.01171v1","category":"cond-mat.stat-mech"}
{"created":"2024-03-02 10:19:00","title":"A new characterization for the distinguished boundaries of a few domains related to $\u03bc$-synthesis","abstract":"In this note, we provide an alternative way of describing the distinguished boundariesof symmetrized bidisc, tetrablock and pentablock. We show that each of these distinguished boundaries can be characterized as the union of orbits of two elements under their automorphism groups.","sentences":["In this note, we provide an alternative way of describing the distinguished boundariesof symmetrized bidisc, tetrablock and pentablock.","We show that each of these distinguished boundaries can be characterized as the union of orbits of two elements under their automorphism groups."],"url":"http://arxiv.org/abs/2403.01159v1","category":"math.CV"}
{"created":"2024-03-02 09:37:25","title":"Error Analysis of a Simple Quaternion Estimator: the Gaussian Case","abstract":"Reference [1] introduces a novel closed-form quaternion estimator from two vector observations. The simplicity of the estimator enables clear physical insights and a closed-form expression for the bias as a function of the quaternion error covariance matrix. The latter could be approximated up to second order with respect to the underlying measurement noise assuming arbitrary probability distribution. The current note relaxes the second-order assumption and provides an expression for the error covariance that is exact to the fourth order, under the assumption of Gaussian distribution. This not only provides increased accuracy but also alleviates issues related to singularity. This technical note presents a comprehensive derivation of the individual components of the quaternion additive error covariance matrix.","sentences":["Reference [1] introduces a novel closed-form quaternion estimator from two vector observations.","The simplicity of the estimator enables clear physical insights and a closed-form expression for the bias as a function of the quaternion error covariance matrix.","The latter could be approximated up to second order with respect to the underlying measurement noise assuming arbitrary probability distribution.","The current note relaxes the second-order assumption and provides an expression for the error covariance that is exact to the fourth order, under the assumption of Gaussian distribution.","This not only provides increased accuracy but also alleviates issues related to singularity.","This technical note presents a comprehensive derivation of the individual components of the quaternion additive error covariance matrix."],"url":"http://arxiv.org/abs/2403.01150v1","category":"stat.ME"}
{"created":"2024-03-02 08:57:46","title":"Singular dynamics for discrete weak K.A.M. solutions of exact twist maps","abstract":"For an exact twist map $f$, we introduce an inherent Lipschitz dynamics $\\Sigma_+$ given by the discrete forward Lax-Oleinik semigroup. We investigate several properties of $\\Sigma_+$ and show that for any discrete weak K.A.M. solution $u$, the non-differentiable points of $u$ are globally propagated and forward invariant by $\\Sigma_+$. In particular, such propagating dynamics possesses the same rotation number as the associated Aubry-Mather set with respect to $u$.   A detailed exposition of the corresponding Arnaud's observation \\cite{Arnaud_2011} is then provided via $\\Sigma_+$. Furthermore, we construct and analyze the dynamics on the pseudo-graphs of discrete weak K.A.M. solutions.","sentences":["For an exact twist map $f$, we introduce an inherent Lipschitz dynamics $\\Sigma_+$ given by the discrete forward Lax-Oleinik semigroup.","We investigate several properties of $\\Sigma_+$ and show that for any discrete weak K.A.M. solution $u$, the non-differentiable points of $u$ are globally propagated and forward invariant by $\\Sigma_+$. In particular, such propagating dynamics possesses the same rotation number as the associated Aubry-Mather set with respect to $u$.   A detailed exposition of the corresponding Arnaud's observation \\cite{Arnaud_2011} is then provided via $\\Sigma_+$. Furthermore, we construct and analyze the dynamics on the pseudo-graphs of discrete weak K.A.M. solutions."],"url":"http://arxiv.org/abs/2403.01141v1","category":"math.DS"}
{"created":"2024-03-02 08:54:51","title":"The evolution of the phase space structure along pitchfork and period-doubling bifurcations in a 3D galactic bar potential","abstract":"We investigate how the phase space structure of a 3D autonomous Hamiltonian system evolves across a series of successive 2D and 3D pitchfork and period-doubling bifurcations, as the transition of the parent families of periodic orbits (POs) from stability to simple instability leads to the creation of new stable POs. Our research illustrates the consecutive alterations in the phase space structure near POs as the stability of the main family of POs changes. This process gives rise to new families of POs within the system, either maintaining the same or exhibiting higher multiplicity compared to their parent families. Tracking such a phase space transformation is challenging in a 3D system. By utilizing the color and rotation technique to visualize the 4D Poincar'e surfaces of section of the system, i.e. projecting them onto a 3D subspace and employing color to represent the fourth dimension, we can identify distinct structural patterns. Perturbations of parent and bifurcating stable POs result in the creation of tori characterized by a smooth color variation on their surface. Furthermore, perturbations of simple unstable parent POs beyond the bifurcation point which lead to the birth of new stable families of POs, result in the formation of figure-8 structures of smooth color variations. These figure-8 formations surround well-shaped tori around the bifurcated stable POs, losing their well-defined forms for energies further away from the bifurcation point. We also observe that even slight perturbations of highly unstable POs create a cloud of mixed color points, which rapidly move away from the location of the PO. Our study introduces, for the first time, a systematic visualization of 4D surfaces of section within the vicinity of higher multiplicity POs. It elucidates how, in these cases, the coexistence of regular and chaotic orbits contributes to shaping the phase space landscape.","sentences":["We investigate how the phase space structure of a 3D autonomous Hamiltonian system evolves across a series of successive 2D and 3D pitchfork and period-doubling bifurcations, as the transition of the parent families of periodic orbits (POs) from stability to simple instability leads to the creation of new stable POs.","Our research illustrates the consecutive alterations in the phase space structure near POs as the stability of the main family of POs changes.","This process gives rise to new families of POs within the system, either maintaining the same or exhibiting higher multiplicity compared to their parent families.","Tracking such a phase space transformation is challenging in a 3D system.","By utilizing the color and rotation technique to visualize the 4D Poincar'e surfaces of section of the system, i.e. projecting them onto a 3D subspace and employing color to represent the fourth dimension, we can identify distinct structural patterns.","Perturbations of parent and bifurcating stable POs result in the creation of tori characterized by a smooth color variation on their surface.","Furthermore, perturbations of simple unstable parent POs beyond the bifurcation point which lead to the birth of new stable families of POs, result in the formation of figure-8 structures of smooth color variations.","These figure-8 formations surround well-shaped tori around the bifurcated stable POs, losing their well-defined forms for energies further away from the bifurcation point.","We also observe that even slight perturbations of highly unstable POs create a cloud of mixed color points, which rapidly move away from the location of the PO.","Our study introduces, for the first time, a systematic visualization of 4D surfaces of section within the vicinity of higher multiplicity POs.","It elucidates how, in these cases, the coexistence of regular and chaotic orbits contributes to shaping the phase space landscape."],"url":"http://arxiv.org/abs/2403.01140v1","category":"nlin.CD"}
{"created":"2024-03-02 08:29:23","title":"Semismooth Newton Method for Boundary Bilinear Control","abstract":"We study a control-constrained optimal control problem governed by a semilinear elliptic equation. The control acts in a bilinear way on the boundary, and can be interpreted as a heat transfer coefficient. A detailed study of the state equation is performed and differentiability properties of the control-to-state mapping are shown. First and second order optimality conditions are derived. Our main result is the proof of superlinear convergence of the semismooth Newton method to local solutions satisfying no-gap second order sufficient optimality conditions as well as a strict complementarity condition.","sentences":["We study a control-constrained optimal control problem governed by a semilinear elliptic equation.","The control acts in a bilinear way on the boundary, and can be interpreted as a heat transfer coefficient.","A detailed study of the state equation is performed and differentiability properties of the control-to-state mapping are shown.","First and second order optimality conditions are derived.","Our main result is the proof of superlinear convergence of the semismooth Newton method to local solutions satisfying no-gap second order sufficient optimality conditions as well as a strict complementarity condition."],"url":"http://arxiv.org/abs/2403.01135v1","category":"math.OC"}
{"created":"2024-03-02 08:29:21","title":"Multi-Source Interactive Resilient Fusion Algorithm Based on RIEKF","abstract":"As the number of heterogeneous redundant sensors on unmanned aerial vehicle (UAV) increases, onboard sensors require a more rational and efficient credibility evaluation system and a resilient fusion framework to achieve the essence of seamless sensor group switching. A simple and efficient sensor credibility evaluation system is proposed to guide the selection of the optimal multi-source sensor submodel combination, thereby providing key model prior knowledge for multi-source resilient fusion. Furthermore, a multi-model interactive resilient fusion framework based on RIEKF is proposed, utilizing the defined sensor credibility indexes to guide the design of the model transition probability matrix, thereby reducing the sensitivity of submodel weights to fusion stability and solving the problem of the model transition matrix lacking a basis for adjustment. Model weights are updated in real time through credibility prior information and submodel posterior probabilities, thus leveraging the adaptive resilience advantage between models to achieve seamless switching between submodels in complex environments. Experimental results show that the algorithm presented in this paper, without using any sensor fault diagnosis and isolation logic, without setting any complex detection timing and thresholds, demonstrates a resilience advantage, thereby enhancing the adaptability of the state estimation system in complex environments.","sentences":["As the number of heterogeneous redundant sensors on unmanned aerial vehicle (UAV) increases, onboard sensors require a more rational and efficient credibility evaluation system and a resilient fusion framework to achieve the essence of seamless sensor group switching.","A simple and efficient sensor credibility evaluation system is proposed to guide the selection of the optimal multi-source sensor submodel combination, thereby providing key model prior knowledge for multi-source resilient fusion.","Furthermore, a multi-model interactive resilient fusion framework based on RIEKF is proposed, utilizing the defined sensor credibility indexes to guide the design of the model transition probability matrix, thereby reducing the sensitivity of submodel weights to fusion stability and solving the problem of the model transition matrix lacking a basis for adjustment.","Model weights are updated in real time through credibility prior information and submodel posterior probabilities, thus leveraging the adaptive resilience advantage between models to achieve seamless switching between submodels in complex environments.","Experimental results show that the algorithm presented in this paper, without using any sensor fault diagnosis and isolation logic, without setting any complex detection timing and thresholds, demonstrates a resilience advantage, thereby enhancing the adaptability of the state estimation system in complex environments."],"url":"http://arxiv.org/abs/2403.01134v1","category":"eess.SP"}
{"created":"2024-03-02 08:19:58","title":"Arbitrary Discrete Fourier Analysis and Its Application in Replayed Speech Detection","abstract":"In this paper, a signal analysis concept is derived when revisiting how a specific frequency component in spectrum is analyzed in Fourier analysis. Three signal analysis methods are then developed based on the derived concept, namely Arbitrary Discrete Fourier Analysis (ADFA), Mel-scale Discrete Fourier Analysis (MDFA), and constant Q Analysis (CQA). I validate the effectiveness of these three signal analysis methods by testing their performance on a replayed speech detection benchmark (i.e., the ASVspoof 2019 Physical Access) along with a state-of-the-art model. Experimental results show that the performance of these three signal analysis methods is comparable to the best reported systems. At the same time, it is show that the computation time of the developed method CQA is much shorter than the convention method constant Q Transform, which is commonly used in spoofed and fake speech detection and music processing.","sentences":["In this paper, a signal analysis concept is derived when revisiting how a specific frequency component in spectrum is analyzed in Fourier analysis.","Three signal analysis methods are then developed based on the derived concept, namely Arbitrary Discrete Fourier Analysis (ADFA), Mel-scale Discrete Fourier Analysis (MDFA), and constant Q Analysis (CQA).","I validate the effectiveness of these three signal analysis methods by testing their performance on a replayed speech detection benchmark (i.e., the ASVspoof 2019 Physical Access) along with a state-of-the-art model.","Experimental results show that the performance of these three signal analysis methods is comparable to the best reported systems.","At the same time, it is show that the computation time of the developed method CQA is much shorter than the convention method constant Q Transform, which is commonly used in spoofed and fake speech detection and music processing."],"url":"http://arxiv.org/abs/2403.01130v1","category":"eess.AS"}
{"created":"2024-03-03 00:58:27","title":"a-DCF: an architecture agnostic metric with application to spoofing-robust speaker verification","abstract":"Spoofing detection is today a mainstream research topic. Standard metrics can be applied to evaluate the performance of isolated spoofing detection solutions and others have been proposed to support their evaluation when they are combined with speaker detection. These either have well-known deficiencies or restrict the architectural approach to combine speaker and spoof detectors. In this paper, we propose an architecture-agnostic detection cost function (a-DCF). A generalisation of the original DCF used widely for the assessment of automatic speaker verification (ASV), the a-DCF is designed for the evaluation of spoofing-robust ASV. Like the DCF, the a-DCF reflects the cost of decisions in a Bayes risk sense, with explicitly defined class priors and detection cost model. We demonstrate the merit of the a-DCF through the benchmarking evaluation of architecturally-heterogeneous spoofing-robust ASV solutions.","sentences":["Spoofing detection is today a mainstream research topic.","Standard metrics can be applied to evaluate the performance of isolated spoofing detection solutions and others have been proposed to support their evaluation when they are combined with speaker detection.","These either have well-known deficiencies or restrict the architectural approach to combine speaker and spoof detectors.","In this paper, we propose an architecture-agnostic detection cost function (a-DCF).","A generalisation of the original DCF used widely for the assessment of automatic speaker verification (ASV), the a-DCF is designed for the evaluation of spoofing-robust ASV.","Like the DCF, the a-DCF reflects the cost of decisions in a Bayes risk sense, with explicitly defined class priors and detection cost model.","We demonstrate the merit of the a-DCF through the benchmarking evaluation of architecturally-heterogeneous spoofing-robust ASV solutions."],"url":"http://arxiv.org/abs/2403.01355v1","category":"eess.AS"}
{"created":"2024-03-02 23:53:24","title":"Improve Cost Efficiency of Active Learning over Noisy Dataset","abstract":"Active learning is a learning strategy whereby the machine learning algorithm actively identifies and labels data points to optimize its learning. This strategy is particularly effective in domains where an abundance of unlabeled data exists, but the cost of labeling these data points is prohibitively expensive. In this paper, we consider cases of binary classification, where acquiring a positive instance incurs a significantly higher cost compared to that of negative instances. For example, in the financial industry, such as in money-lending businesses, a defaulted loan constitutes a positive event leading to substantial financial loss. To address this issue, we propose a shifted normal distribution sampling function that samples from a wider range than typical uncertainty sampling. Our simulation underscores that our proposed sampling function limits both noisy and positive label selection, delivering between 20% and 32% improved cost efficiency over different test datasets.","sentences":["Active learning is a learning strategy whereby the machine learning algorithm actively identifies and labels data points to optimize its learning.","This strategy is particularly effective in domains where an abundance of unlabeled data exists, but the cost of labeling these data points is prohibitively expensive.","In this paper, we consider cases of binary classification, where acquiring a positive instance incurs a significantly higher cost compared to that of negative instances.","For example, in the financial industry, such as in money-lending businesses, a defaulted loan constitutes a positive event leading to substantial financial loss.","To address this issue, we propose a shifted normal distribution sampling function that samples from a wider range than typical uncertainty sampling.","Our simulation underscores that our proposed sampling function limits both noisy and positive label selection, delivering between 20% and 32% improved cost efficiency over different test datasets."],"url":"http://arxiv.org/abs/2403.01346v1","category":"cs.LG"}
{"created":"2024-03-02 23:37:16","title":"Mitigating the Bias in the Model for Continual Test-Time Adaptation","abstract":"Continual Test-Time Adaptation (CTA) is a challenging task that aims to adapt a source pre-trained model to continually changing target domains. In the CTA setting, a model does not know when the target domain changes, thus facing a drastic change in the distribution of streaming inputs during the test-time. The key challenge is to keep adapting the model to the continually changing target domains in an online manner. We find that a model shows highly biased predictions as it constantly adapts to the chaining distribution of the target data. It predicts certain classes more often than other classes, making inaccurate over-confident predictions. This paper mitigates this issue to improve performance in the CTA scenario. To alleviate the bias issue, we make class-wise exponential moving average target prototypes with reliable target samples and exploit them to cluster the target features class-wisely. Moreover, we aim to align the target distributions to the source distribution by anchoring the target feature to its corresponding source prototype. With extensive experiments, our proposed method achieves noteworthy performance gain when applied on top of existing CTA methods without substantial adaptation time overhead.","sentences":["Continual Test-Time Adaptation (CTA) is a challenging task that aims to adapt a source pre-trained model to continually changing target domains.","In the CTA setting, a model does not know when the target domain changes, thus facing a drastic change in the distribution of streaming inputs during the test-time.","The key challenge is to keep adapting the model to the continually changing target domains in an online manner.","We find that a model shows highly biased predictions as it constantly adapts to the chaining distribution of the target data.","It predicts certain classes more often than other classes, making inaccurate over-confident predictions.","This paper mitigates this issue to improve performance in the CTA scenario.","To alleviate the bias issue, we make class-wise exponential moving average target prototypes with reliable target samples and exploit them to cluster the target features class-wisely.","Moreover, we aim to align the target distributions to the source distribution by anchoring the target feature to its corresponding source prototype.","With extensive experiments, our proposed method achieves noteworthy performance gain when applied on top of existing CTA methods without substantial adaptation time overhead."],"url":"http://arxiv.org/abs/2403.01344v1","category":"cs.LG"}
{"created":"2024-03-02 23:04:53","title":"Europa's structural conditions for the existence of subsurface ocean and the absence of metallic core-driven magnetic field","abstract":"Europa's interior is expected to be divided into the metallic core, rocky mantle and hydrosphere based on the moment of inertia factor estimated from gravity field measurements. Specifically, the thickness of the outermost water layer is 120-170 km, and the radius of the metallic core is 0.12-0.43 times the surface radius. No systematic study of Europa's internal evolution has been conducted to estimate the current state of the subsurface ocean and to explain the absence of a core dynamo field within such uncertainty for internal structure and material properties. Herein, I performed a numerical simulation of the long-term thermal evolution of Europa's interior and investigated the temporal changes in the ocean thickness as well as the temperature and heat flow of the metallic core. If the ice reference viscosity is greater than 5$\\times$10$^{14}$ Pa s, the ocean can persist even in the absence of tidal heating. In the case of a tidal heating of 10 and 20 mW/m$^{2}$, the ice shell thickness is $\\le$90 km if the ice viscosity is $\\ge$1$\\times$10$^{15}$ and 1$\\times$10$^{14}$ Pa s, respectively. Regardless of the ice viscosity, if the tidal heating is $\\ge$50 mW/m$^{2}$, the shell thickness will be $\\le$40 km. The thermal history of the metallic core is determined by the hydrosphere thickness and the metallic core density, and is unaffected by variations in the ice shell (ocean) thickness. Preferred conditions for the absence of the core dynamo include CI chondritic abundance for the long-lived radioactive isotopes, lower initial core-mantle boundary (CMB) temperature and thicker hydrosphere. The core may be molten without convection if the composition is near the eutectic in a Fe-FeS alloy, or not molten (without convection) if the composition is near the Fe or FeS endmember.","sentences":["Europa's interior is expected to be divided into the metallic core, rocky mantle and hydrosphere based on the moment of inertia factor estimated from gravity field measurements.","Specifically, the thickness of the outermost water layer is 120-170 km, and the radius of the metallic core is 0.12-0.43 times the surface radius.","No systematic study of Europa's internal evolution has been conducted to estimate the current state of the subsurface ocean and to explain the absence of a core dynamo field within such uncertainty for internal structure and material properties.","Herein, I performed a numerical simulation of the long-term thermal evolution of Europa's interior and investigated the temporal changes in the ocean thickness as well as the temperature and heat flow of the metallic core.","If the ice reference viscosity is greater than 5$\\times$10$^{14}$ Pa s, the ocean can persist even in the absence of tidal heating.","In the case of a tidal heating of 10 and 20 mW/m$^{2}$, the ice shell thickness is $\\le$90 km if the ice viscosity is $\\ge$1$\\times$10$^{15}$ and 1$\\times$10$^{14}$ Pa s, respectively.","Regardless of the ice viscosity, if the tidal heating is $\\ge$50 mW/m$^{2}$, the shell thickness will be $\\le$40 km.","The thermal history of the metallic core is determined by the hydrosphere thickness and the metallic core density, and is unaffected by variations in the ice shell (ocean) thickness.","Preferred conditions for the absence of the core dynamo include CI chondritic abundance for the long-lived radioactive isotopes, lower initial core-mantle boundary (CMB) temperature and thicker hydrosphere.","The core may be molten without convection if the composition is near the eutectic in a Fe-FeS alloy, or not molten (without convection) if the composition is near the Fe or FeS endmember."],"url":"http://arxiv.org/abs/2403.01336v1","category":"astro-ph.EP"}
{"created":"2024-03-02 22:53:06","title":"Making Hybrid Languages: A Recipe","abstract":"The dominant programming languages support only linear text to express ideas. Visual languages offer graphical representations for entire programs, when viewed with special tools. Hybrid languages, with support from existing tools, allow developers to express their ideas with a mix of textual and graphical syntax tailored to an application domain. This mix puts both kinds of syntax on equal footing and, importantly, the enriched language does not disrupt a programmer's typical workflow. This paper presents a recipe for equipping existing textual programming languages as well as accompanying IDEs with a mechanism for creating and using graphical interactive syntax. It also presents the first hybrid language and IDE created using the recipe.","sentences":["The dominant programming languages support only linear text to express ideas.","Visual languages offer graphical representations for entire programs, when viewed with special tools.","Hybrid languages, with support from existing tools, allow developers to express their ideas with a mix of textual and graphical syntax tailored to an application domain.","This mix puts both kinds of syntax on equal footing and, importantly, the enriched language does not disrupt a programmer's typical workflow.","This paper presents a recipe for equipping existing textual programming languages as well as accompanying IDEs with a mechanism for creating and using graphical interactive syntax.","It also presents the first hybrid language and IDE created using the recipe."],"url":"http://arxiv.org/abs/2403.01335v1","category":"cs.PL"}
{"created":"2024-03-02 21:40:46","title":"A Polychromatic Theory of Emission","abstract":"The control of thermal radiation by means of micro-structured materials is an active area of research with applications such as thermophotovoltaics and radiative cooling. The original theories of thermal radiation, derived for electromagnetically large objects, predict unpolarized, omnidirectional and uncorrelated radiation. Microstructures, however, exhibit thermal emissions that can be polarized, highly directional, and spatially and temporally correlated. The original theories are also restricted to thermal equilibrium situations. In particular, they do not apply to steady-state emissions of electromagnetically small objects under a stationary illumination, where one expects significant differences in the shape and number of photons of the illuminating and emitted spectra, much as what happens when an object is under the sun. In here, we establish a polychromatic framework to predict thermal radiation in the stationary regime, which includes thermal equilibrium. After identifying an object-dependent set of independent polychromatic absorption modes, we assume that the emission also occurs independently through the outgoing versions of each polychromatic mode. Energy conservation leads then to a Kirchhoff-like law for each polychromatic mode. The salient properties of the polychromatic theory are: Emission in frequencies absent in the illumination, change in the number of photons, and applicability to both thermal radiation and luminescence upon illumination with a continuous wave laser, as long as the emitted power depends linearly on the input intensity. These properties are independent of the chosen set of polychromatic modes. In this work, we chose the absorption modes derived from the scattering operator of a given object. Some counter-intuitive results motivate the future search for a different set of modes.","sentences":["The control of thermal radiation by means of micro-structured materials is an active area of research with applications such as thermophotovoltaics and radiative cooling.","The original theories of thermal radiation, derived for electromagnetically large objects, predict unpolarized, omnidirectional and uncorrelated radiation.","Microstructures, however, exhibit thermal emissions that can be polarized, highly directional, and spatially and temporally correlated.","The original theories are also restricted to thermal equilibrium situations.","In particular, they do not apply to steady-state emissions of electromagnetically small objects under a stationary illumination, where one expects significant differences in the shape and number of photons of the illuminating and emitted spectra, much as what happens when an object is under the sun.","In here, we establish a polychromatic framework to predict thermal radiation in the stationary regime, which includes thermal equilibrium.","After identifying an object-dependent set of independent polychromatic absorption modes, we assume that the emission also occurs independently through the outgoing versions of each polychromatic mode.","Energy conservation leads then to a Kirchhoff-like law for each polychromatic mode.","The salient properties of the polychromatic theory are: Emission in frequencies absent in the illumination, change in the number of photons, and applicability to both thermal radiation and luminescence upon illumination with a continuous wave laser, as long as the emitted power depends linearly on the input intensity.","These properties are independent of the chosen set of polychromatic modes.","In this work, we chose the absorption modes derived from the scattering operator of a given object.","Some counter-intuitive results motivate the future search for a different set of modes."],"url":"http://arxiv.org/abs/2403.01319v1","category":"physics.optics"}
{"created":"2024-03-02 21:29:04","title":"TUMTraf V2X Cooperative Perception Dataset","abstract":"Cooperative perception offers several benefits for enhancing the capabilities of autonomous vehicles and improving road safety. Using roadside sensors in addition to onboard sensors increases reliability and extends the sensor range. External sensors offer higher situational awareness for automated vehicles and prevent occlusions. We propose CoopDet3D, a cooperative multi-modal fusion model, and TUMTraf-V2X, a perception dataset, for the cooperative 3D object detection and tracking task. Our dataset contains 2,000 labeled point clouds and 5,000 labeled images from five roadside and four onboard sensors. It includes 30k 3D boxes with track IDs and precise GPS and IMU data. We labeled eight categories and covered occlusion scenarios with challenging driving maneuvers, like traffic violations, near-miss events, overtaking, and U-turns. Through multiple experiments, we show that our CoopDet3D camera-LiDAR fusion model achieves an increase of +14.36 3D mAP compared to a vehicle camera-LiDAR fusion model. Finally, we make our dataset, model, labeling tool, and dev-kit publicly available on our website: https://tum-traffic-dataset.github.io/tumtraf-v2x.","sentences":["Cooperative perception offers several benefits for enhancing the capabilities of autonomous vehicles and improving road safety.","Using roadside sensors in addition to onboard sensors increases reliability and extends the sensor range.","External sensors offer higher situational awareness for automated vehicles and prevent occlusions.","We propose CoopDet3D, a cooperative multi-modal fusion model, and TUMTraf-V2X, a perception dataset, for the cooperative 3D object detection and tracking task.","Our dataset contains 2,000 labeled point clouds and 5,000 labeled images from five roadside and four onboard sensors.","It includes 30k 3D boxes with track IDs and precise GPS and IMU data.","We labeled eight categories and covered occlusion scenarios with challenging driving maneuvers, like traffic violations, near-miss events, overtaking, and U-turns.","Through multiple experiments, we show that our CoopDet3D camera-LiDAR fusion model achieves an increase of +14.36 3D mAP compared to a vehicle camera-LiDAR fusion model.","Finally, we make our dataset, model, labeling tool, and dev-kit publicly available on our website: https://tum-traffic-dataset.github.io/tumtraf-v2x."],"url":"http://arxiv.org/abs/2403.01316v1","category":"cs.CV"}
{"created":"2024-03-02 21:22:36","title":"Superflows: A New Tool for Forensic Network Flow Analysis","abstract":"Network security analysts gather data from diverse sources, from high-level summaries of network flow and traffic volumes to low-level details such as service logs from servers and the contents of individual packets. They validate and check this data against traffic patterns and historical indicators of compromise. Based on the results of this analysis, a decision is made to either automatically manage the traffic or report it to an analyst for further investigation. Unfortunately, due rapidly increasing traffic volumes, there are far more events to check than operational teams can handle for effective forensic analysis. However, just as packets are grouped into flows that share a commonality, we argue that a high-level construct for grouping network flows into a set a flows that share a hypothesis is needed to significantly improve the quality of operational network response by increasing Events Per Analysts Hour (EPAH).   In this paper, we propose a formalism for describing a superflow construct, which we characterize as an aggregation of one or more flows based on an analyst-specific hypothesis about traffic behavior. We demonstrate simple superflow constructions and representations, and perform a case study to explain how the formalism can be used to reduce the volume of data for forensic analysis.","sentences":["Network security analysts gather data from diverse sources, from high-level summaries of network flow and traffic volumes to low-level details such as service logs from servers and the contents of individual packets.","They validate and check this data against traffic patterns and historical indicators of compromise.","Based on the results of this analysis, a decision is made to either automatically manage the traffic or report it to an analyst for further investigation.","Unfortunately, due rapidly increasing traffic volumes, there are far more events to check than operational teams can handle for effective forensic analysis.","However, just as packets are grouped into flows that share a commonality, we argue that a high-level construct for grouping network flows into a set a flows that share a hypothesis is needed to significantly improve the quality of operational network response by increasing Events Per Analysts Hour (EPAH).   ","In this paper, we propose a formalism for describing a superflow construct, which we characterize as an aggregation of one or more flows based on an analyst-specific hypothesis about traffic behavior.","We demonstrate simple superflow constructions and representations, and perform a case study to explain how the formalism can be used to reduce the volume of data for forensic analysis."],"url":"http://arxiv.org/abs/2403.01314v1","category":"cs.NI"}
{"created":"2024-03-02 19:58:04","title":"Longtime behavior of semilinear multi-term fractional in time diffusion","abstract":"In the paper, the initial-boundary value problems to a semilinear integro-differential equation with multi-term fractional Caputo derivatives are analyzed. A particular case of this equation models oxygen diffusion through capillaries. Under proper assumptions on the coefficients and a nonlinearity, the longtime behavior (as $t\\to+\\infty$) of a solution is discussed. In particular, the existence of absorbing sets in suitable functional spaces is established.","sentences":["In the paper, the initial-boundary value problems to a semilinear integro-differential equation with multi-term fractional Caputo derivatives are analyzed.","A particular case of this equation models oxygen diffusion through capillaries.","Under proper assumptions on the coefficients and a nonlinearity, the longtime behavior (as $t\\to+\\infty$) of a solution is discussed.","In particular, the existence of absorbing sets in suitable functional spaces is established."],"url":"http://arxiv.org/abs/2403.01302v1","category":"math.AP"}
{"created":"2024-03-02 19:19:08","title":"Automorphism group of a family of distance regular graphs which are not distance transitive","abstract":"Let $G_n=\\mathbb{Z}_n\\times \\mathbb{Z}_n$ for $n\\geq 4$ and $S=\\{(i,0),(0,i),(i,i): 1\\leq i \\leq n-1\\}\\subset G_n$. Define $\\Gamma(n)$ to be the Cayley graph of $G_n$ with respect to the connecting set $S$. It is known that $\\Gamma(n)$ is a strongly regular graph with the parameters $(n^2,3n-3,n,6)$ \\cite{19}. Hence $\\Gamma(n)$ is a distance regular graph. It is known that every distance transitive graph is distance regular, but the converse is not true. In this paper, we study some algebraic properties of the graph $\\Gamma(n)$. Then by determining the automorphism group of this family of graphs, we show that the graphs under study are not distance transitive.","sentences":["Let $G_n=\\mathbb{Z}_n\\times \\mathbb{Z}_n$ for $n\\geq 4$ and $S=\\{(i,0),(0,i),(i,i): 1\\leq i \\leq n-1\\}\\subset","G_n$.","Define $\\Gamma(n)$ to be the Cayley graph of $G_n$ with respect to the connecting set $S$. It is known that $\\Gamma(n)$ is a strongly regular graph with the parameters $(n^2,3n-3,n,6)$ \\cite{19}.","Hence $\\Gamma(n)$ is a distance regular graph.","It is known that every distance transitive graph is distance regular, but the converse is not true.","In this paper, we study some algebraic properties of the graph $\\Gamma(n)$. Then by determining the automorphism group of this family of graphs, we show that the graphs under study are not distance transitive."],"url":"http://arxiv.org/abs/2403.01293v1","category":"math.CO"}
{"created":"2024-03-02 17:12:32","title":"Defending Against Data Reconstruction Attacks in Federated Learning: An Information Theory Approach","abstract":"Federated Learning (FL) trains a black-box and high-dimensional model among different clients by exchanging parameters instead of direct data sharing, which mitigates the privacy leak incurred by machine learning. However, FL still suffers from membership inference attacks (MIA) or data reconstruction attacks (DRA). In particular, an attacker can extract the information from local datasets by constructing DRA, which cannot be effectively throttled by existing techniques, e.g., Differential Privacy (DP).   In this paper, we aim to ensure a strong privacy guarantee for FL under DRA. We prove that reconstruction errors under DRA are constrained by the information acquired by an attacker, which means that constraining the transmitted information can effectively throttle DRA. To quantify the information leakage incurred by FL, we establish a channel model, which depends on the upper bound of joint mutual information between the local dataset and multiple transmitted parameters. Moreover, the channel model indicates that the transmitted information can be constrained through data space operation, which can improve training efficiency and the model accuracy under constrained information. According to the channel model, we propose algorithms to constrain the information transmitted in a single round of local training. With a limited number of training rounds, the algorithms ensure that the total amount of transmitted information is limited. Furthermore, our channel model can be applied to various privacy-enhancing techniques (such as DP) to enhance privacy guarantees against DRA. Extensive experiments with real-world datasets validate the effectiveness of our methods.","sentences":["Federated Learning (FL) trains a black-box and high-dimensional model among different clients by exchanging parameters instead of direct data sharing, which mitigates the privacy leak incurred by machine learning.","However, FL still suffers from membership inference attacks (MIA) or data reconstruction attacks (DRA).","In particular, an attacker can extract the information from local datasets by constructing DRA, which cannot be effectively throttled by existing techniques, e.g., Differential Privacy (DP).   ","In this paper, we aim to ensure a strong privacy guarantee for FL under DRA.","We prove that reconstruction errors under DRA are constrained by the information acquired by an attacker, which means that constraining the transmitted information can effectively throttle DRA.","To quantify the information leakage incurred by FL, we establish a channel model, which depends on the upper bound of joint mutual information between the local dataset and multiple transmitted parameters.","Moreover, the channel model indicates that the transmitted information can be constrained through data space operation, which can improve training efficiency and the model accuracy under constrained information.","According to the channel model, we propose algorithms to constrain the information transmitted in a single round of local training.","With a limited number of training rounds, the algorithms ensure that the total amount of transmitted information is limited.","Furthermore, our channel model can be applied to various privacy-enhancing techniques (such as DP) to enhance privacy guarantees against DRA.","Extensive experiments with real-world datasets validate the effectiveness of our methods."],"url":"http://arxiv.org/abs/2403.01268v1","category":"cs.LG"}
{"created":"2024-03-02 15:34:31","title":"Active Deep Kernel Learning of Molecular Functionalities: Realizing Dynamic Structural Embeddings","abstract":"Exploring molecular spaces is crucial for advancing our understanding of chemical properties and reactions, leading to groundbreaking innovations in materials science, medicine, and energy. This paper explores an approach for active learning in molecular discovery using Deep Kernel Learning (DKL), a novel approach surpassing the limits of classical Variational Autoencoders (VAEs). Employing the QM9 dataset, we contrast DKL with traditional VAEs, which analyze molecular structures based on similarity, revealing limitations due to sparse regularities in latent spaces. DKL, however, offers a more holistic perspective by correlating structure with properties, creating latent spaces that prioritize molecular functionality. This is achieved by recalculating embedding vectors iteratively, aligning with the experimental availability of target properties. The resulting latent spaces are not only better organized but also exhibit unique characteristics such as concentrated maxima representing molecular functionalities and a correlation between predictive uncertainty and error. Additionally, the formation of exclusion regions around certain compounds indicates unexplored areas with potential for groundbreaking functionalities. This study underscores DKL's potential in molecular research, offering new avenues for understanding and discovering molecular functionalities beyond classical VAE limitations.","sentences":["Exploring molecular spaces is crucial for advancing our understanding of chemical properties and reactions, leading to groundbreaking innovations in materials science, medicine, and energy.","This paper explores an approach for active learning in molecular discovery using Deep Kernel Learning (DKL), a novel approach surpassing the limits of classical Variational Autoencoders (VAEs).","Employing the QM9 dataset, we contrast DKL with traditional VAEs, which analyze molecular structures based on similarity, revealing limitations due to sparse regularities in latent spaces.","DKL, however, offers a more holistic perspective by correlating structure with properties, creating latent spaces that prioritize molecular functionality.","This is achieved by recalculating embedding vectors iteratively, aligning with the experimental availability of target properties.","The resulting latent spaces are not only better organized but also exhibit unique characteristics such as concentrated maxima representing molecular functionalities and a correlation between predictive uncertainty and error.","Additionally, the formation of exclusion regions around certain compounds indicates unexplored areas with potential for groundbreaking functionalities.","This study underscores DKL's potential in molecular research, offering new avenues for understanding and discovering molecular functionalities beyond classical VAE limitations."],"url":"http://arxiv.org/abs/2403.01234v1","category":"cs.LG"}
{"created":"2024-03-02 14:22:40","title":"Inexact Unlearning Needs More Careful Evaluations to Avoid a False Sense of Privacy","abstract":"The high cost of model training makes it increasingly desirable to develop techniques for unlearning. These techniques seek to remove the influence of a training example without having to retrain the model from scratch. Intuitively, once a model has unlearned, an adversary that interacts with the model should no longer be able to tell whether the unlearned example was included in the model's training set or not. In the privacy literature, this is known as membership inference. In this work, we discuss adaptations of Membership Inference Attacks (MIAs) to the setting of unlearning (leading to their ``U-MIA'' counterparts). We propose a categorization of existing U-MIAs into ``population U-MIAs'', where the same attacker is instantiated for all examples, and ``per-example U-MIAs'', where a dedicated attacker is instantiated for each example. We show that the latter category, wherein the attacker tailors its membership prediction to each example under attack, is significantly stronger. Indeed, our results show that the commonly used U-MIAs in the unlearning literature overestimate the privacy protection afforded by existing unlearning techniques on both vision and language models. Our investigation reveals a large variance in the vulnerability of different examples to per-example U-MIAs. In fact, several unlearning algorithms lead to a reduced vulnerability for some, but not all, examples that we wish to unlearn, at the expense of increasing it for other examples. Notably, we find that the privacy protection for the remaining training examples may worsen as a consequence of unlearning. We also discuss the fundamental difficulty of equally protecting all examples using existing unlearning schemes, due to the different rates at which examples are unlearned. We demonstrate that naive attempts at tailoring unlearning stopping criteria to different examples fail to alleviate these issues.","sentences":["The high cost of model training makes it increasingly desirable to develop techniques for unlearning.","These techniques seek to remove the influence of a training example without having to retrain the model from scratch.","Intuitively, once a model has unlearned, an adversary that interacts with the model should no longer be able to tell whether the unlearned example was included in the model's training set or not.","In the privacy literature, this is known as membership inference.","In this work, we discuss adaptations of Membership Inference Attacks (MIAs) to the setting of unlearning (leading to their ``U-MIA'' counterparts).","We propose a categorization of existing U-MIAs into ``population U-MIAs'', where the same attacker is instantiated for all examples, and ``per-example U-MIAs'', where a dedicated attacker is instantiated for each example.","We show that the latter category, wherein the attacker tailors its membership prediction to each example under attack, is significantly stronger.","Indeed, our results show that the commonly used U-MIAs in the unlearning literature overestimate the privacy protection afforded by existing unlearning techniques on both vision and language models.","Our investigation reveals a large variance in the vulnerability of different examples to per-example U-MIAs.","In fact, several unlearning algorithms lead to a reduced vulnerability for some, but not all, examples that we wish to unlearn, at the expense of increasing it for other examples.","Notably, we find that the privacy protection for the remaining training examples may worsen as a consequence of unlearning.","We also discuss the fundamental difficulty of equally protecting all examples using existing unlearning schemes, due to the different rates at which examples are unlearned.","We demonstrate that naive attempts at tailoring unlearning stopping criteria to different examples fail to alleviate these issues."],"url":"http://arxiv.org/abs/2403.01218v1","category":"cs.LG"}
{"created":"2024-03-02 13:07:02","title":"Control of cascading failures using protective measures","abstract":"Cascading failures, triggered by a local perturbation, can be catastrophic and cause irreparable damages in a wide area. Hence, blocking the devastating cascades is an important issue in real world networks. One of the ways to control the cascade is to use protective measures, so that the agents decide to be protected against failure. Here, we consider a coevolution of the linear threshold model for the spread of cascading failures and a decision-making game based on the perceived risk of failure. Protected agents are less vulnerable to failure and in return the size of the cascade affects the agent's decision to get insured. We find at what range of protection efficiency and cost of failure, the global cascades stop. Also we observe that in some range of protection efficiency, a bistable region emerges for the size of cascade and the prevalence of protected agents. Moreover, we show how savings or the ability of agents to repair can prevent cascades from occurring","sentences":["Cascading failures, triggered by a local perturbation, can be catastrophic and cause irreparable damages in a wide area.","Hence, blocking the devastating cascades is an important issue in real world networks.","One of the ways to control the cascade is to use protective measures, so that the agents decide to be protected against failure.","Here, we consider a coevolution of the linear threshold model for the spread of cascading failures and a decision-making game based on the perceived risk of failure.","Protected agents are less vulnerable to failure and in return the size of the cascade affects the agent's decision to get insured.","We find at what range of protection efficiency and cost of failure, the global cascades stop.","Also we observe that in some range of protection efficiency, a bistable region emerges for the size of cascade and the prevalence of protected agents.","Moreover, we show how savings or the ability of agents to repair can prevent cascades from occurring"],"url":"http://arxiv.org/abs/2403.01205v1","category":"physics.soc-ph"}
{"created":"2024-03-02 12:23:02","title":"Understanding Energy Level Structure Using Quantum Rubik's Cube","abstract":"This article combines the quantum Rubik's cube matrix with the BBH model, defines the matrix algorithm based on the reverse process of convolution, constructs the expression of quantum Rubik's cube matrix and Hamiltonian. Furthermore, in order to make the operation process of the quantum Rubik's cube matrix clearer, we used Joseph ring to draw a topology graph of the Rubik's cube expansion. This article uses a Quantum Rubik's cube to achieve energy level transitions of electrons, and its operation corresponds to path integration, obtaining the band dispersion. This work provides new ideas and methods for calculating Hamiltonian and studying energy level structure.","sentences":["This article combines the quantum Rubik's cube matrix with the BBH model, defines the matrix algorithm based on the reverse process of convolution, constructs the expression of quantum Rubik's cube matrix and Hamiltonian.","Furthermore, in order to make the operation process of the quantum Rubik's cube matrix clearer, we used Joseph ring to draw a topology graph of the Rubik's cube expansion.","This article uses a Quantum Rubik's cube to achieve energy level transitions of electrons, and its operation corresponds to path integration, obtaining the band dispersion.","This work provides new ideas and methods for calculating Hamiltonian and studying energy level structure."],"url":"http://arxiv.org/abs/2403.01195v1","category":"quant-ph"}
{"created":"2024-03-02 09:35:45","title":"Unified understanding to the rich electronic-structure evolutions of 2D black phosphorus under pressure","abstract":"The electronic structure evolutions of few-layer black phosphorus (BP) under pressure shows a wealth of phenomena, such as the nonmonotonic change of direct gap at the {\\Gamma} point, the layer-number dependence, and the distinct responses to normal and hydrostatic pressures. A full and unified understanding to these rich phenomena remains lacking. Here, we provide a unified understanding from the competition between interlayer quasi-bonding (QB) interactions and intralayer chemical bonding interactions. The former decreases while the latter increases the band gap under pressure and the origin can be correlated to different combinations of inter- and intra-layer antibonding or bonding interactions at the band edges. More interestingly, the interlayer QB interactions are a coexistence of two categories of interactions, namely, the coexistence of interactions between bands of the same occupancy (occupied-occupied and empty-empty interactions) and of different occupancies (occupied-empty interaction); and, the overall effect is a four-level interaction, which explains the anomalous interlayer-antibonding feature of the conduction band edge of bilayer BP. Our current study lay the foundation for the electronic structure tuning of two-dimensional (2D) BP, and, our analysis method for multi-energy-level interactions can be applied to other 2D semiconductor homo- and hetero-structures that have occupied-empty interlayer interactions.","sentences":["The electronic structure evolutions of few-layer black phosphorus (BP) under pressure shows a wealth of phenomena, such as the nonmonotonic change of direct gap at the {\\Gamma} point, the layer-number dependence, and the distinct responses to normal and hydrostatic pressures.","A full and unified understanding to these rich phenomena remains lacking.","Here, we provide a unified understanding from the competition between interlayer quasi-bonding (QB) interactions and intralayer chemical bonding interactions.","The former decreases while the latter increases the band gap under pressure and the origin can be correlated to different combinations of inter- and intra-layer antibonding or bonding interactions at the band edges.","More interestingly, the interlayer QB interactions are a coexistence of two categories of interactions, namely, the coexistence of interactions between bands of the same occupancy (occupied-occupied and empty-empty interactions) and of different occupancies (occupied-empty interaction); and, the overall effect is a four-level interaction, which explains the anomalous interlayer-antibonding feature of the conduction band edge of bilayer BP.","Our current study lay the foundation for the electronic structure tuning of two-dimensional (2D) BP, and, our analysis method for multi-energy-level interactions can be applied to other 2D semiconductor homo- and hetero-structures that have occupied-empty interlayer interactions."],"url":"http://arxiv.org/abs/2403.01149v1","category":"cond-mat.mtrl-sci"}
{"created":"2024-03-02 09:20:46","title":"Mutation Analysis with Execution Taints","abstract":"Mutation analysis is one of the most effective, but costly means of assessing the ability of software test suites to prevent bugs. Traditional mutation analysis involves producing and evaluating syntactic variants of the original to check whether the test suite under evaluation is capable of distinguishing between the variant and the original in terms of behavior.   Evaluating each mutant separately means a large amount of redundant computation, both between the original program and mutants, and also between different mutants. Previous work explored numerous means of removing redundancy. However, some amount of redundancy has remained especially in the post-mutation phase.   In this paper, we propose execution taints--A novel technique that repurposes dynamic data-flow taints for mutation analysis. Our technique is the only technique that can remove the redundancy in post-mutation phase, achieving better efficiency in mutation analysis. We further leverage memoization to eliminate redundant execution between program variants.","sentences":["Mutation analysis is one of the most effective, but costly means of assessing the ability of software test suites to prevent bugs.","Traditional mutation analysis involves producing and evaluating syntactic variants of the original to check whether the test suite under evaluation is capable of distinguishing between the variant and the original in terms of behavior.   ","Evaluating each mutant separately means a large amount of redundant computation, both between the original program and mutants, and also between different mutants.","Previous work explored numerous means of removing redundancy.","However, some amount of redundancy has remained especially in the post-mutation phase.   ","In this paper, we propose execution taints--A novel technique that repurposes dynamic data-flow taints for mutation analysis.","Our technique is the only technique that can remove the redundancy in post-mutation phase, achieving better efficiency in mutation analysis.","We further leverage memoization to eliminate redundant execution between program variants."],"url":"http://arxiv.org/abs/2403.01146v1","category":"cs.SE"}
{"created":"2024-03-02 08:29:08","title":"Evaluating Large Language Models as Virtual Annotators for Time-series Physical Sensing Data","abstract":"Traditional human-in-the-loop-based annotation for time-series data like inertial data often requires access to alternate modalities like video or audio from the environment. These alternate sources provide the necessary information to the human annotator, as the raw numeric data is often too obfuscated even for an expert. However, this traditional approach has many concerns surrounding overall cost, efficiency, storage of additional modalities, time, scalability, and privacy. Interestingly, recent large language models (LLMs) are also trained with vast amounts of publicly available alphanumeric data, which allows them to comprehend and perform well on tasks beyond natural language processing. Naturally, this opens up a potential avenue to explore LLMs as virtual annotators where the LLMs will be directly provided the raw sensor data for annotation instead of relying on any alternate modality. Naturally, this could mitigate the problems of the traditional human-in-the-loop approach. Motivated by this observation, we perform a detailed study in this paper to assess whether the state-of-the-art (SOTA) LLMs can be used as virtual annotators for labeling time-series physical sensing data. To perform this in a principled manner, we segregate the study into two major phases. In the first phase, we investigate the challenges an LLM like GPT-4 faces in comprehending raw sensor data. Considering the observations from phase 1, in the next phase, we investigate the possibility of encoding the raw sensor data using SOTA SSL approaches and utilizing the projected time-series data to get annotations from the LLM. Detailed evaluation with four benchmark HAR datasets shows that SSL-based encoding and metric-based guidance allow the LLM to make more reasonable decisions and provide accurate annotations without requiring computationally expensive fine-tuning or sophisticated prompt engineering.","sentences":["Traditional human-in-the-loop-based annotation for time-series data like inertial data often requires access to alternate modalities like video or audio from the environment.","These alternate sources provide the necessary information to the human annotator, as the raw numeric data is often too obfuscated even for an expert.","However, this traditional approach has many concerns surrounding overall cost, efficiency, storage of additional modalities, time, scalability, and privacy.","Interestingly, recent large language models (LLMs) are also trained with vast amounts of publicly available alphanumeric data, which allows them to comprehend and perform well on tasks beyond natural language processing.","Naturally, this opens up a potential avenue to explore LLMs as virtual annotators where the LLMs will be directly provided the raw sensor data for annotation instead of relying on any alternate modality.","Naturally, this could mitigate the problems of the traditional human-in-the-loop approach.","Motivated by this observation, we perform a detailed study in this paper to assess whether the state-of-the-art (SOTA) LLMs can be used as virtual annotators for labeling time-series physical sensing data.","To perform this in a principled manner, we segregate the study into two major phases.","In the first phase, we investigate the challenges an LLM like GPT-4 faces in comprehending raw sensor data.","Considering the observations from phase 1, in the next phase, we investigate the possibility of encoding the raw sensor data using SOTA SSL approaches and utilizing the projected time-series data to get annotations from the LLM.","Detailed evaluation with four benchmark HAR datasets shows that SSL-based encoding and metric-based guidance allow the LLM to make more reasonable decisions and provide accurate annotations without requiring computationally expensive fine-tuning or sophisticated prompt engineering."],"url":"http://arxiv.org/abs/2403.01133v1","category":"cs.LG"}
{"created":"2024-03-02 22:28:36","title":"Re-evaluating the impact of hormone replacement therapy on heart disease using match-adaptive randomization inference","abstract":"Matching is an appealing way to design observational studies because it mimics the data structure produced by stratified randomized trials, pairing treated individuals with similar controls. After matching, inference is often conducted using methods tailored for stratified randomized trials in which treatments are permuted within matched pairs. However, in observational studies, matched pairs are not predetermined before treatment; instead, they are constructed based on observed treatment status. This introduces a challenge as the permutation distributions used in standard inference methods do not account for the possibility that permuting treatments might lead to a different selection of matched pairs ($Z$-dependence). To address this issue, we propose a novel and computationally efficient algorithm that characterizes and enables sampling from the correct conditional distribution of treatment after an optimal propensity score matching, accounting for $Z$-dependence. We show how this new procedure, called match-adaptive randomization inference, corrects for an anticonservative result in a well-known observational study investigating the impact of hormone replacement theory (HRT) on coronary heart disease and corroborates experimental findings about heterogeneous effects of HRT across different ages of initiation in women. Keywords: matching, causal inference, propensity score, permutation test, Type I error, graphs.","sentences":["Matching is an appealing way to design observational studies because it mimics the data structure produced by stratified randomized trials, pairing treated individuals with similar controls.","After matching, inference is often conducted using methods tailored for stratified randomized trials in which treatments are permuted within matched pairs.","However, in observational studies, matched pairs are not predetermined before treatment; instead, they are constructed based on observed treatment status.","This introduces a challenge as the permutation distributions used in standard inference methods do not account for the possibility that permuting treatments might lead to a different selection of matched pairs ($Z$-dependence).","To address this issue, we propose a novel and computationally efficient algorithm that characterizes and enables sampling from the correct conditional distribution of treatment after an optimal propensity score matching, accounting for $Z$-dependence.","We show how this new procedure, called match-adaptive randomization inference, corrects for an anticonservative result in a well-known observational study investigating the impact of hormone replacement theory (HRT) on coronary heart disease and corroborates experimental findings about heterogeneous effects of HRT across different ages of initiation in women.","Keywords: matching, causal inference, propensity score, permutation test, Type I error, graphs."],"url":"http://arxiv.org/abs/2403.01330v1","category":"stat.ME"}
{"created":"2024-03-02 13:43:32","title":"Data-free Multi-label Image Recognition via LLM-powered Prompt Tuning","abstract":"This paper proposes a novel framework for multi-label image recognition without any training data, called data-free framework, which uses knowledge of pre-trained Large Language Model (LLM) to learn prompts to adapt pretrained Vision-Language Model (VLM) like CLIP to multilabel classification. Through asking LLM by well-designed questions, we acquire comprehensive knowledge about characteristics and contexts of objects, which provides valuable text descriptions for learning prompts. Then we propose a hierarchical prompt learning method by taking the multi-label dependency into consideration, wherein a subset of category-specific prompt tokens are shared when the corresponding objects exhibit similar attributes or are more likely to co-occur. Benefiting from the remarkable alignment between visual and linguistic semantics of CLIP, the hierarchical prompts learned from text descriptions are applied to perform classification of images during inference. Our framework presents a new way to explore the synergies between multiple pre-trained models for novel category recognition. Extensive experiments on three public datasets (MS-COCO, VOC2007, and NUS-WIDE) demonstrate that our method achieves better results than the state-of-the-art methods, especially outperforming the zero-shot multi-label recognition methods by 4.7% in mAP on MS-COCO.","sentences":["This paper proposes a novel framework for multi-label image recognition without any training data, called data-free framework, which uses knowledge of pre-trained Large Language Model (LLM) to learn prompts to adapt pretrained Vision-Language Model (VLM) like CLIP to multilabel classification.","Through asking LLM by well-designed questions, we acquire comprehensive knowledge about characteristics and contexts of objects, which provides valuable text descriptions for learning prompts.","Then we propose a hierarchical prompt learning method by taking the multi-label dependency into consideration, wherein a subset of category-specific prompt tokens are shared when the corresponding objects exhibit similar attributes or are more likely to co-occur.","Benefiting from the remarkable alignment between visual and linguistic semantics of CLIP, the hierarchical prompts learned from text descriptions are applied to perform classification of images during inference.","Our framework presents a new way to explore the synergies between multiple pre-trained models for novel category recognition.","Extensive experiments on three public datasets (MS-COCO, VOC2007, and NUS-WIDE) demonstrate that our method achieves better results than the state-of-the-art methods, especially outperforming the zero-shot multi-label recognition methods by 4.7% in mAP on MS-COCO."],"url":"http://arxiv.org/abs/2403.01209v1","category":"cs.CV"}
{"created":"2024-03-02 12:00:17","title":"Volume diffusion modelling of a sheared granular gas","abstract":"Continuum fluid dynamic models based on the Navier-Stokes equations have previously been used to simulate granular media undergoing fluid-like shearing. These models, however, typically fail to predict the flow behaviour in confined environments as non-equilibrium particle effects dominate near walls. We adapt an extended hydrodynamic model for granular flows, which uses a density-gradient dependent ``volume diffusion'' term to correct the viscous stress tensor and heat flux, to simulate the shearing of a granular gas between two rough walls, and with corresponding boundary conditions. We use our volume diffusion model to predict channel flows for a range of mean volume fraction $\\bar{\\phi}=0.01$--$0.4$, and inter-particle coefficients of restitution $e=0.8$ and $0.9$, and compare with Discrete Element Method (DEM) simulations and classical Navier-Stokes equations. Our model is capable of predicting non-uniform pressure, volume fraction and granular temperature, which become more significant for cases with mean volume fraction $\\bar{\\phi}\\sim0.1$, in which we typically observe non-uniform peak density variations, and large volume fraction gradients.","sentences":["Continuum fluid dynamic models based on the Navier-Stokes equations have previously been used to simulate granular media undergoing fluid-like shearing.","These models, however, typically fail to predict the flow behaviour in confined environments as non-equilibrium particle effects dominate near walls.","We adapt an extended hydrodynamic model for granular flows, which uses a density-gradient dependent ``volume diffusion'' term to correct the viscous stress tensor and heat flux, to simulate the shearing of a granular gas between two rough walls, and with corresponding boundary conditions.","We use our volume diffusion model to predict channel flows for a range of mean volume fraction $\\bar{\\phi}=0.01$--$0.4$, and inter-particle coefficients of restitution $e=0.8$ and $0.9$, and compare with Discrete Element Method (DEM) simulations and classical Navier-Stokes equations.","Our model is capable of predicting non-uniform pressure, volume fraction and granular temperature, which become more significant for cases with mean volume fraction $\\bar{\\phi}\\sim0.1$, in which we typically observe non-uniform peak density variations, and large volume fraction gradients."],"url":"http://arxiv.org/abs/2403.01188v1","category":"physics.flu-dyn"}
{"created":"2024-03-02 10:18:37","title":"A Bayesian Committee Machine Potential for Oxygen-containing Organic Compounds","abstract":"Understanding the pivotal role of oxygen-containing organic compounds in serving as an energy source for living organisms and contributing to protein formation is crucial in the field of biochemistry. This study addresses the challenge of comprehending protein-protein interactions (PPI) and developing predicitive models for proteins and organic compounds, with a specific focus on quantifying their binding affinity. Here, we introduce the active Bayesian Committee Machine (BCM) potential, specifically designed to predict oxygen-containing organic compounds within eight groups of CHO. The BCM potential adopts a committee-based approach to tackle scalability issues associated with kernel regressors, particularly when dealing with large datasets. Its adaptable structure allows for efficient and cost-effective expansion, maintaing both transferability and scalability. Through systematic benchmarking, we position the sparse BCM potential as a promising contender in the pursuit of a universal machine learning potential.","sentences":["Understanding the pivotal role of oxygen-containing organic compounds in serving as an energy source for living organisms and contributing to protein formation is crucial in the field of biochemistry.","This study addresses the challenge of comprehending protein-protein interactions (PPI) and developing predicitive models for proteins and organic compounds, with a specific focus on quantifying their binding affinity.","Here, we introduce the active Bayesian Committee Machine (BCM) potential, specifically designed to predict oxygen-containing organic compounds within eight groups of CHO.","The BCM potential adopts a committee-based approach to tackle scalability issues associated with kernel regressors, particularly when dealing with large datasets.","Its adaptable structure allows for efficient and cost-effective expansion, maintaing both transferability and scalability.","Through systematic benchmarking, we position the sparse BCM potential as a promising contender in the pursuit of a universal machine learning potential."],"url":"http://arxiv.org/abs/2403.01158v1","category":"cond-mat.mtrl-sci"}
{"created":"2024-03-02 09:40:11","title":"Transfer Learning-Enhanced Instantaneous Multi-Person Indoor Localization by CSI","abstract":"Passive indoor localization, integral to smart buildings, emergency response, and indoor navigation, has traditionally been limited by a focus on single-target localization and reliance on multi-packet CSI. We introduce a novel Multi-target loss, notably enhancing multi-person localization. Utilizing this loss function, our instantaneous CSI-ResNet achieves an impressive 99.21% accuracy at 0.6m precision with single-timestamp CSI. A preprocessing algorithm is implemented to counteract WiFi-induced variability, thereby augmenting robustness. Furthermore, we incorporate Nuclear Norm-Based Transfer Pre-Training, ensuring adaptability in diverse environments, which provides a new paradigm for indoor multi-person localization. Additionally, we have developed an extensive dataset, surpassing existing ones in scope and diversity, to underscore the efficacy of our method and facilitate future fingerprint-based localization research.","sentences":["Passive indoor localization, integral to smart buildings, emergency response, and indoor navigation, has traditionally been limited by a focus on single-target localization and reliance on multi-packet CSI.","We introduce a novel Multi-target loss, notably enhancing multi-person localization.","Utilizing this loss function, our instantaneous CSI-ResNet achieves an impressive 99.21% accuracy at 0.6m precision with single-timestamp CSI.","A preprocessing algorithm is implemented to counteract WiFi-induced variability, thereby augmenting robustness.","Furthermore, we incorporate Nuclear Norm-Based Transfer Pre-Training, ensuring adaptability in diverse environments, which provides a new paradigm for indoor multi-person localization.","Additionally, we have developed an extensive dataset, surpassing existing ones in scope and diversity, to underscore the efficacy of our method and facilitate future fingerprint-based localization research."],"url":"http://arxiv.org/abs/2403.01153v1","category":"eess.SP"}
{"created":"2024-03-02 23:25:23","title":"An eternal hypersurface flow arising in centro-affine geometry","abstract":"In this paper, the existence and uniqueness for a specific centro-affine invariant hypersurface flow in $R^{n+1}$ are studied, and the corresponding evolutionary processes in both centro-affine and Euclidean settings are explored. It turns out that the flow exhibits similar properties as the standard heat flow. In addition, the long time existence of the flow is investigated, which asserts that the hypersurface governed by the flow converges asymptotically toward an ellipsoid via systematically investigating evolutions of the centro-affine invariants. Furthermore, the classification of the eternal solutions for the flow is provided.","sentences":["In this paper, the existence and uniqueness for a specific centro-affine invariant hypersurface flow in $R^{n+1}$ are studied, and the corresponding evolutionary processes in both centro-affine and Euclidean settings are explored.","It turns out that the flow exhibits similar properties as the standard heat flow.","In addition, the long time existence of the flow is investigated, which asserts that the hypersurface governed by the flow converges asymptotically toward an ellipsoid via systematically investigating evolutions of the centro-affine invariants.","Furthermore, the classification of the eternal solutions for the flow is provided."],"url":"http://arxiv.org/abs/2403.01340v1","category":"math.DG"}
{"created":"2024-03-02 16:13:06","title":"Dual Graph Attention based Disentanglement Multiple Instance Learning for Brain Age Estimation","abstract":"Deep learning techniques have demonstrated great potential for accurately estimating brain age by analyzing Magnetic Resonance Imaging (MRI) data from healthy individuals. However, current methods for brain age estimation often directly utilize whole input images, overlooking two important considerations: 1) the heterogeneous nature of brain aging, where different brain regions may degenerate at different rates, and 2) the existence of age-independent redundancies in brain structure. To overcome these limitations, we propose a Dual Graph Attention based Disentanglement Multi-instance Learning (DGA-DMIL) framework for improving brain age estimation. Specifically, the 3D MRI data, treated as a bag of instances, is fed into a 2D convolutional neural network backbone, to capture the unique aging patterns in MRI. A dual graph attention aggregator is then proposed to learn the backbone features by exploiting the intra- and inter-instance relationships. Furthermore, a disentanglement branch is introduced to separate age-related features from age-independent structural representations to ameliorate the interference of redundant information on age prediction. To verify the effectiveness of the proposed framework, we evaluate it on two datasets, UK Biobank and ADNI, containing a total of 35,388 healthy individuals. Our proposed model demonstrates exceptional accuracy in estimating brain age, achieving a remarkable mean absolute error of 2.12 years in the UK Biobank. The results establish our approach as state-of-the-art compared to other competing brain age estimation models. In addition, the instance contribution scores identify the varied importance of brain areas for aging prediction, which provides deeper insights into the understanding of brain aging.","sentences":["Deep learning techniques have demonstrated great potential for accurately estimating brain age by analyzing Magnetic Resonance Imaging (MRI) data from healthy individuals.","However, current methods for brain age estimation often directly utilize whole input images, overlooking two important considerations: 1) the heterogeneous nature of brain aging, where different brain regions may degenerate at different rates, and 2) the existence of age-independent redundancies in brain structure.","To overcome these limitations, we propose a Dual Graph Attention based Disentanglement Multi-instance Learning (DGA-DMIL) framework for improving brain age estimation.","Specifically, the 3D MRI data, treated as a bag of instances, is fed into a 2D convolutional neural network backbone, to capture the unique aging patterns in MRI.","A dual graph attention aggregator is then proposed to learn the backbone features by exploiting the intra- and inter-instance relationships.","Furthermore, a disentanglement branch is introduced to separate age-related features from age-independent structural representations to ameliorate the interference of redundant information on age prediction.","To verify the effectiveness of the proposed framework, we evaluate it on two datasets, UK Biobank and ADNI, containing a total of 35,388 healthy individuals.","Our proposed model demonstrates exceptional accuracy in estimating brain age, achieving a remarkable mean absolute error of 2.12 years in the UK Biobank.","The results establish our approach as state-of-the-art compared to other competing brain age estimation models.","In addition, the instance contribution scores identify the varied importance of brain areas for aging prediction, which provides deeper insights into the understanding of brain aging."],"url":"http://arxiv.org/abs/2403.01246v1","category":"cs.CV"}
{"created":"2024-03-02 16:03:53","title":"Analyzing the transport coefficients and observables of a rotating QGP medium in kinetic theory framework with a novel approach to the collision integral","abstract":"In the present work, we have studied how the rotation of the QGP medium affects the transport coefficients and observables in heavy ion collisions. For the noncentral collisions, although most of the angular momentum gets carried away by the spectators, there still remains a finite angular momentum with a finite range of angular velocity, which thus incites rotation in the produced matter. As a result, various properties of the QGP medium are likely to be modulated by the rotation. We have calculated the transport coefficients and observables, such as electrical conductivity, thermal conductivity, Knudsen number, elliptic flow, specific heat at constant pressure, specific heat at constant volume, trace anomaly, thermal diffusion constant and isothermal compressibility using the kinetic theory to see the effect of rotation on them. In particular, we have used the novel relaxation time approximation for the collision integral in the relativistic Boltzmann transport equation to derive the transport coefficients and compared them with their values in the relaxation time approximation within the kinetic theory approach in conjunction with the finite angular velocity. We have found that the angular velocity plays an important role and enhances the flow of charge and heat in the medium. Further, as compared to the relaxation time approximation, the electrical and thermal conductivities have smaller values in the novel relaxation time approximation and these differences between the conductivities in the said approximations are more pronounced at high temperature than at low temperature. Furthermore, all the aforesaid observables are found to be sensitive to the rotation of the QGP medium.","sentences":["In the present work, we have studied how the rotation of the QGP medium affects the transport coefficients and observables in heavy ion collisions.","For the noncentral collisions, although most of the angular momentum gets carried away by the spectators, there still remains a finite angular momentum with a finite range of angular velocity, which thus incites rotation in the produced matter.","As a result, various properties of the QGP medium are likely to be modulated by the rotation.","We have calculated the transport coefficients and observables, such as electrical conductivity, thermal conductivity, Knudsen number, elliptic flow, specific heat at constant pressure, specific heat at constant volume, trace anomaly, thermal diffusion constant and isothermal compressibility using the kinetic theory to see the effect of rotation on them.","In particular, we have used the novel relaxation time approximation for the collision integral in the relativistic Boltzmann transport equation to derive the transport coefficients and compared them with their values in the relaxation time approximation within the kinetic theory approach in conjunction with the finite angular velocity.","We have found that the angular velocity plays an important role and enhances the flow of charge and heat in the medium.","Further, as compared to the relaxation time approximation, the electrical and thermal conductivities have smaller values in the novel relaxation time approximation and these differences between the conductivities in the said approximations are more pronounced at high temperature than at low temperature.","Furthermore, all the aforesaid observables are found to be sensitive to the rotation of the QGP medium."],"url":"http://arxiv.org/abs/2403.01240v1","category":"hep-ph"}
{"created":"2024-03-02 12:43:46","title":"Modelling ion acceleration and transport in corotating interaction regions: the mass-to-charge ratio dependence of the particle spectrum","abstract":"We investigate the role of perpendicular diffusion in shaping energetic ion spectrum in corotating interaction regions (CIRs), focusing on its mass-to-charge ($A/Q$) dependence. We simulate a synthetic CIR using the EUropean Heliospheric FORcasting Information Asset (EUHFORIA) and model the subsequent ion acceleration and transport by solving the focused transport equation incorporating both parallel and perpendicular diffusion. Our results reveal distinct differences in ion spectra between scenarios with and without perpendicular diffusion. In the absence of perpendicular diffusion, ion spectra near CIRs show a strong $(A/Q)^{\\epsilon}$ dependence with $\\epsilon$ depending on the turbulence spectral index, agreeing with theoretical predictions. In contrast, the incorporation of perpendicular diffusion, characterized by a weak $A/Q$ dependence, leading to similar spectra for different ion species. This qualitatively agrees with observations of energetic particles in CIRs.","sentences":["We investigate the role of perpendicular diffusion in shaping energetic ion spectrum in corotating interaction regions (CIRs), focusing on its mass-to-charge ($A/Q$) dependence.","We simulate a synthetic CIR using the EUropean Heliospheric FORcasting Information Asset (EUHFORIA) and model the subsequent ion acceleration and transport by solving the focused transport equation incorporating both parallel and perpendicular diffusion.","Our results reveal distinct differences in ion spectra between scenarios with and without perpendicular diffusion.","In the absence of perpendicular diffusion, ion spectra near CIRs show a strong $(A/Q)^{\\epsilon}$ dependence with $\\epsilon$ depending on the turbulence spectral index, agreeing with theoretical predictions.","In contrast, the incorporation of perpendicular diffusion, characterized by a weak $A/Q$ dependence, leading to similar spectra for different ion species.","This qualitatively agrees with observations of energetic particles in CIRs."],"url":"http://arxiv.org/abs/2403.01201v1","category":"astro-ph.SR"}
{"created":"2024-03-02 11:12:13","title":"RAIDER: Rapid, anatomy-independent deep learning-based chemical shift-encoded MRI","abstract":"Purpose: Despite recent advances, chemical shift-encoded MRI (CSE-MRI) remains a challenging problem and many algorithms are computationally expensive, leading to interest in deep learning-based methods. However, initial attempts have used convolutional neural networks (CNNs), which are limited by data requirements, poor generalisability across different anatomies (anatomy- dependence) and training time. To address these limitations, we propose RAIDER, a method for rapid, anatomy-independent deep learning-based CSE-MRI.   Theory and Methods: RAIDER uses two multilayer perceptrons (MLPs), each trained separately with simulated single-voxel data, thus avoiding the degeneracy encountered during training when using only one network. During inference, the solution from one of the two networks is chosen based on likelihood. Performance and speed are investigated in a series of simulation experiments, in phantoms and in vivo.   Results: RAIDER is approximately 700 times faster than conventional fitting, taking 14us per voxel rather than 10ms, and offers performance similar to that of conventional fitting. It produces accurate fat fraction measurements in phantoms and in vivo images with different anatomies, despite having been trained only on simulation data.   Conclusion: RAIDER resolves the problems posed by degeneracy, avoids the training data requirements of CNN-based methods and markedly reduces computational cost compared to conventional fitting.","sentences":["Purpose: Despite recent advances, chemical shift-encoded MRI (CSE-MRI) remains a challenging problem and many algorithms are computationally expensive, leading to interest in deep learning-based methods.","However, initial attempts have used convolutional neural networks (CNNs), which are limited by data requirements, poor generalisability across different anatomies (anatomy- dependence) and training time.","To address these limitations, we propose RAIDER, a method for rapid, anatomy-independent deep learning-based CSE-MRI.   Theory and Methods: RAIDER uses two multilayer perceptrons (MLPs), each trained separately with simulated single-voxel data, thus avoiding the degeneracy encountered during training when using only one network.","During inference, the solution from one of the two networks is chosen based on likelihood.","Performance and speed are investigated in a series of simulation experiments, in phantoms and in vivo.   ","Results: RAIDER is approximately 700 times faster than conventional fitting, taking 14us per voxel rather than 10ms, and offers performance similar to that of conventional fitting.","It produces accurate fat fraction measurements in phantoms and in vivo images with different anatomies, despite having been trained only on simulation data.   ","Conclusion: RAIDER resolves the problems posed by degeneracy, avoids the training data requirements of CNN-based methods and markedly reduces computational cost compared to conventional fitting."],"url":"http://arxiv.org/abs/2403.01178v1","category":"physics.med-ph"}
{"created":"2024-03-02 09:37:55","title":"A Ricci flow on graphs from effective resistance","abstract":"In this paper, we introduce a new notion of curvature on the edges of a graph that is defined in terms of effective resistances. We call this the Ricci--Foster curvature. We study the Ricci flow resulting from this curvature. We prove the existence of solutions to Ricci flow on short time intervals, and prove that Ricci flow preserves graphs with nonnegative (resp. positive) curvature.","sentences":["In this paper, we introduce a new notion of curvature on the edges of a graph that is defined in terms of effective resistances.","We call this the Ricci--Foster curvature.","We study the Ricci flow resulting from this curvature.","We prove the existence of solutions to Ricci flow on short time intervals, and prove that Ricci flow preserves graphs with nonnegative (resp.","positive) curvature."],"url":"http://arxiv.org/abs/2403.01151v1","category":"math.CO"}
{"created":"2024-03-02 09:13:23","title":"Extrapolated Plug-and-Play Three-Operator Splitting Methods for Nonconvex Optimization with Applications to Image Restoration","abstract":"This paper investigates the convergence properties and applications of the three-operator splitting method, also known as Davis-Yin splitting (DYS) method, integrated with extrapolation and Plug-and-Play (PnP) denoiser within a nonconvex framework. We first propose an extrapolated DYS method to effectively solve a class of structural nonconvex optimization problems that involve minimizing the sum of three possible nonconvex functions. Our approach provides an algorithmic framework that encompasses both extrapolated forward-backward splitting and extrapolated Douglas-Rachford splitting methods.To establish the convergence of the proposed method, we rigorously analyze its behavior based on the Kurdyka-{\\L}ojasiewicz property, subject to some tight parameter conditions. Moreover, we introduce two extrapolated PnP-DYS methods with convergence guarantee, where the traditional regularization prior is replaced by a gradient step-based denoiser. This denoiser is designed using a differentiable neural network and can be reformulated as the proximal operator of a specific nonconvex functional. We conduct extensive experiments on image deblurring and image super-resolution problems, where our results showcase the advantage of the extrapolation strategy and the superior performance of the learning-based model that incorporates the PnP denoiser in terms of achieving high-quality recovery images.","sentences":["This paper investigates the convergence properties and applications of the three-operator splitting method, also known as Davis-Yin splitting (DYS) method, integrated with extrapolation and Plug-and-Play (PnP) denoiser within a nonconvex framework.","We first propose an extrapolated DYS method to effectively solve a class of structural nonconvex optimization problems that involve minimizing the sum of three possible nonconvex functions.","Our approach provides an algorithmic framework that encompasses both extrapolated forward-backward splitting and extrapolated Douglas-Rachford splitting methods.","To establish the convergence of the proposed method, we rigorously analyze its behavior based on the Kurdyka-{\\L}ojasiewicz property, subject to some tight parameter conditions.","Moreover, we introduce two extrapolated PnP-DYS methods with convergence guarantee, where the traditional regularization prior is replaced by a gradient step-based denoiser.","This denoiser is designed using a differentiable neural network and can be reformulated as the proximal operator of a specific nonconvex functional.","We conduct extensive experiments on image deblurring and image super-resolution problems, where our results showcase the advantage of the extrapolation strategy and the superior performance of the learning-based model that incorporates the PnP denoiser in terms of achieving high-quality recovery images."],"url":"http://arxiv.org/abs/2403.01144v1","category":"math.NA"}
{"created":"2024-03-02 08:49:22","title":"First eigenvalue characterization of Clifford hypersurfaces and Veronese surface","abstract":"We give an estimate for the first eigenvalue of the Schr\\\"odinger operator $L:=-\\Delta-\\sigma$ which defined on the closed minimal submanifold $M^{n}$ in the unit sphere $\\mathbb{S}^{n+m}$, where $\\sigma$ is the square norm of the second fundamental form.","sentences":["We give an estimate for the first eigenvalue of the Schr\\\"odinger operator $L:=-\\Delta-\\sigma$ which defined on the closed minimal submanifold $M^{n}$ in the unit sphere $\\mathbb{S}^{n+m}$, where $\\sigma$ is the square norm of the second fundamental form."],"url":"http://arxiv.org/abs/2403.01138v1","category":"math.DG"}
{"created":"2024-03-02 23:19:10","title":"Uniform $\\mathcal{C}^k$ Approximation of $G$-Invariant and Antisymmetric Functions, Embedding Dimensions, and Polynomial Representations","abstract":"For any subgroup $G$ of the symmetric group $\\mathcal{S}_n$ on $n$ symbols, we present results for the uniform $\\mathcal{C}^k$ approximation of $G$-invariant functions by $G$-invariant polynomials. For the case of totally symmetric functions ($G = \\mathcal{S}_n$), we show that this gives rise to the sum-decomposition Deep Sets ansatz of Zaheer et al. (2018), where both the inner and outer functions can be chosen to be smooth, and moreover, the inner function can be chosen to be independent of the target function being approximated. In particular, we show that the embedding dimension required is independent of the regularity of the target function, the accuracy of the desired approximation, as well as $k$. Next, we show that a similar procedure allows us to obtain a uniform $\\mathcal{C}^k$ approximation of antisymmetric functions as a sum of $K$ terms, where each term is a product of a smooth totally symmetric function and a smooth antisymmetric homogeneous polynomial of degree at most $\\binom{n}{2}$. We also provide upper and lower bounds on $K$ and show that $K$ is independent of the regularity of the target function, the desired approximation accuracy, and $k$.","sentences":["For any subgroup $G$ of the symmetric group $\\mathcal{S}_n$ on $n$ symbols, we present results for the uniform $\\mathcal{C}^k$ approximation of $G$-invariant functions by $G$-invariant polynomials.","For the case of totally symmetric functions ($G = \\mathcal{S}_n$), we show that this gives rise to the sum-decomposition Deep Sets ansatz of Zaheer et al. (2018), where both the inner and outer functions can be chosen to be smooth, and moreover, the inner function can be chosen to be independent of the target function being approximated.","In particular, we show that the embedding dimension required is independent of the regularity of the target function, the accuracy of the desired approximation, as well as $k$. Next, we show that a similar procedure allows us to obtain a uniform $\\mathcal{C}^k$ approximation of antisymmetric functions as a sum of $K$ terms, where each term is a product of a smooth totally symmetric function and a smooth antisymmetric homogeneous polynomial of degree at most $\\binom{n}{2}$. We also provide upper and lower bounds on $K$ and show that $K$ is independent of the regularity of the target function, the desired approximation accuracy, and $k$."],"url":"http://arxiv.org/abs/2403.01339v1","category":"cs.LG"}
{"created":"2024-03-02 21:37:40","title":"High-Dimensional Tail Index Regression: with An Application to Text Analyses of Viral Posts in Social Media","abstract":"Motivated by the empirical power law of the distributions of credits (e.g., the number of \"likes\") of viral posts in social media, we introduce the high-dimensional tail index regression and methods of estimation and inference for its parameters. We propose a regularized estimator, establish its consistency, and derive its convergence rate. To conduct inference, we propose to debias the regularized estimate, and establish the asymptotic normality of the debiased estimator. Simulation studies support our theory. These methods are applied to text analyses of viral posts in X (formerly Twitter) concerning LGBTQ+.","sentences":["Motivated by the empirical power law of the distributions of credits (e.g., the number of \"likes\") of viral posts in social media, we introduce the high-dimensional tail index regression and methods of estimation and inference for its parameters.","We propose a regularized estimator, establish its consistency, and derive its convergence rate.","To conduct inference, we propose to debias the regularized estimate, and establish the asymptotic normality of the debiased estimator.","Simulation studies support our theory.","These methods are applied to text analyses of viral posts in X (formerly Twitter) concerning LGBTQ+."],"url":"http://arxiv.org/abs/2403.01318v1","category":"stat.ML"}
{"created":"2024-03-02 20:36:10","title":"ICC: Quantifying Image Caption Concreteness for Multimodal Dataset Curation","abstract":"Web-scale training on paired text-image data is becoming increasingly central to multimodal learning, but is challenged by the highly noisy nature of datasets in the wild. Standard data filtering approaches succeed in removing mismatched text-image pairs, but permit semantically related but highly abstract or subjective text. These approaches lack the fine-grained ability to isolate the most concrete samples that provide the strongest signal for learning in a noisy dataset. In this work, we propose a new metric, image caption concreteness, that evaluates caption text without an image reference to measure its concreteness and relevancy for use in multimodal learning. Our approach leverages strong foundation models for measuring visual-semantic information loss in multimodal representations. We demonstrate that this strongly correlates with human evaluation of concreteness in both single-word and sentence-level texts. Moreover, we show that curation using ICC complements existing approaches: It succeeds in selecting the highest quality samples from multimodal web-scale datasets to allow for efficient training in resource-constrained settings.","sentences":["Web-scale training on paired text-image data is becoming increasingly central to multimodal learning, but is challenged by the highly noisy nature of datasets in the wild.","Standard data filtering approaches succeed in removing mismatched text-image pairs, but permit semantically related but highly abstract or subjective text.","These approaches lack the fine-grained ability to isolate the most concrete samples that provide the strongest signal for learning in a noisy dataset.","In this work, we propose a new metric, image caption concreteness, that evaluates caption text without an image reference to measure its concreteness and relevancy for use in multimodal learning.","Our approach leverages strong foundation models for measuring visual-semantic information loss in multimodal representations.","We demonstrate that this strongly correlates with human evaluation of concreteness in both single-word and sentence-level texts.","Moreover, we show that curation using ICC complements existing approaches: It succeeds in selecting the highest quality samples from multimodal web-scale datasets to allow for efficient training in resource-constrained settings."],"url":"http://arxiv.org/abs/2403.01306v1","category":"cs.LG"}
{"created":"2024-03-02 19:44:19","title":"A Photonic Physically Unclonable Function's Resilience to Multiple-Valued Machine Learning Attacks","abstract":"Physically unclonable functions (PUFs) identify integrated circuits using nonlinearly-related challenge-response pairs (CRPs). Ideally, the relationship between challenges and corresponding responses is unpredictable, even if a subset of CRPs is known. Previous work developed a photonic PUF offering improved security compared to non-optical counterparts. Here, we investigate this PUF's susceptibility to Multiple-Valued-Logic-based machine learning attacks. We find that approximately 1,000 CRPs are necessary to train models that predict response bits better than random chance. Given the significant challenge of acquiring a vast number of CRPs from a photonic PUF, our results demonstrate photonic PUF resilience against such attacks.","sentences":["Physically unclonable functions (PUFs) identify integrated circuits using nonlinearly-related challenge-response pairs (CRPs).","Ideally, the relationship between challenges and corresponding responses is unpredictable, even if a subset of CRPs is known.","Previous work developed a photonic PUF offering improved security compared to non-optical counterparts.","Here, we investigate this PUF's susceptibility to Multiple-Valued-Logic-based machine learning attacks.","We find that approximately 1,000 CRPs are necessary to train models that predict response bits better than random chance.","Given the significant challenge of acquiring a vast number of CRPs from a photonic PUF, our results demonstrate photonic PUF resilience against such attacks."],"url":"http://arxiv.org/abs/2403.01299v1","category":"cs.CR"}
{"created":"2024-03-02 17:10:44","title":"Dissecting Language Models: Machine Unlearning via Selective Pruning","abstract":"Understanding and shaping the behaviour of Large Language Models (LLMs) is increasingly important as applications become more powerful and more frequently adopted. This paper introduces a machine unlearning method specifically designed for LLMs. We introduce a selective pruning method for LLMs that removes neurons based on their relative importance on a targeted capability compared to overall network performance. This approach is a compute- and data-efficient method for identifying and removing neurons that enable specific behaviours. Our findings reveal that both feed-forward and attention neurons in LLMs are specialized; that is, for specific tasks, certain neurons are more crucial than others.","sentences":["Understanding and shaping the behaviour of Large Language Models (LLMs) is increasingly important as applications become more powerful and more frequently adopted.","This paper introduces a machine unlearning method specifically designed for LLMs.","We introduce a selective pruning method for LLMs that removes neurons based on their relative importance on a targeted capability compared to overall network performance.","This approach is a compute- and data-efficient method for identifying and removing neurons that enable specific behaviours.","Our findings reveal that both feed-forward and attention neurons in LLMs are specialized; that is, for specific tasks, certain neurons are more crucial than others."],"url":"http://arxiv.org/abs/2403.01267v1","category":"cs.LG"}
{"created":"2024-03-02 15:44:21","title":"Performance evaluation of acceleration of convolutional layers on OpenEdgeCGRA","abstract":"Recently, efficiently deploying deep learning solutions on the edge has received increasing attention. New platforms are emerging to support the increasing demand for flexibility and high performance. In this work, we explore the efficient mapping of convolutional layers on an open-hardware, low-power Coarse-Grain Reconfigurable Array (CGRA), namely OpenEdgeCGRA. We explore both direct implementations of convolution and solutions that transform it into a matrix multiplication through an Im2col transformation, and experiment with various tensor parallelism axes. We show that for this hardware target, direct convolution, coupled with weight parallelism reaches the best latency and energy efficiency, outperforming a CPU implementation by 3.4x and 9.9x in terms of energy and latency, respectively.","sentences":["Recently, efficiently deploying deep learning solutions on the edge has received increasing attention.","New platforms are emerging to support the increasing demand for flexibility and high performance.","In this work, we explore the efficient mapping of convolutional layers on an open-hardware, low-power Coarse-Grain Reconfigurable Array (CGRA), namely OpenEdgeCGRA.","We explore both direct implementations of convolution and solutions that transform it into a matrix multiplication through an Im2col transformation, and experiment with various tensor parallelism axes.","We show that for this hardware target, direct convolution, coupled with weight parallelism reaches the best latency and energy efficiency, outperforming a CPU implementation by 3.4x and 9.9x in terms of energy and latency, respectively."],"url":"http://arxiv.org/abs/2403.01236v1","category":"cs.AR"}
{"created":"2024-03-03 01:17:53","title":"On odd-normal numbers","abstract":"A real number $x$ is considered normal in an integer base $b \\geq 2$ if its digit expansion in this base is ``equitable'', ensuring that for each $k \\geq 1$, every ordered sequence of $k$ digits from $\\{0, 1, \\ldots, b-1\\}$ occurs in the digit expansion of $x$ with the same limiting frequency. Borel's classical result \\cite{b09} asserts that Lebesgue-almost every $x \\in \\mathbb R$ is normal in every base $b \\geq 2$. This paper serves as a case study of the measure-theoretic properties of Lebesgue-null sets containing numbers that are normal only in certain bases. We consider the set $\\mathscr N(\\mathscr{O}, \\mathscr{E})$ of reals that are normal in odd bases but not in even ones. This set has full Hausdorff dimension \\cite{p81} but zero Fourier dimension. The latter condition means that $\\mathscr N(\\mathscr{O}, \\mathscr{E})$ cannot support a probability measure whose Fourier transform has power decay at infinity. Our main result is that $\\mathscr N(\\mathscr{O}, \\mathscr{E})$ supports a Rajchman measure $\\mu$, whose Fourier transform $\\widehat{\\mu}(\\xi)$ approaches 0 as $|\\xi| \\rightarrow \\infty$ by definiton, albeit slower than any negative power of $|\\xi|$. Moreover, the decay rate of $\\widehat{\\mu}$ is essentially optimal, subject to the constraints of its support. The methods draw inspiration from the number-theoretic results of Schmidt \\cite{s60} and a construction of Lyons \\cite{l86}. As a consequence, $\\mathscr N(\\mathscr{O}, \\mathscr{E})$ emerges as a set of multiplicity, in the sense of Fourier analysis. This addresses a question posed by Kahane and Salem \\cite{Kahane-Salem-64} in the special case of $\\mathscr N(\\mathscr{O}, \\mathscr{E})$.","sentences":["A real number $x$ is considered normal in an integer base $b \\geq 2$ if its digit expansion in this base is ``equitable'', ensuring that for each $k \\geq 1$, every ordered sequence of $k$ digits from $\\{0, 1, \\ldots, b-1\\}$ occurs in the digit expansion of $x$ with the same limiting frequency.","Borel's classical result \\cite{b09} asserts that Lebesgue-almost every $x \\in \\mathbb R$ is normal in every base $b \\geq 2$.","This paper serves as a case study of the measure-theoretic properties of Lebesgue-null sets containing numbers that are normal only in certain bases.","We consider the set $\\mathscr N(\\mathscr{O}, \\mathscr{E})$ of reals that are normal in odd bases but not in even ones.","This set has full Hausdorff dimension \\cite{p81} but zero Fourier dimension.","The latter condition means that $\\mathscr N(\\mathscr{O}, \\mathscr{E})$ cannot support a probability measure whose Fourier transform has power decay at infinity.","Our main result is that $\\mathscr N(\\mathscr{O}, \\mathscr{E})$ supports a Rajchman measure $\\mu$, whose Fourier transform $\\widehat{\\mu}(\\xi)$ approaches 0 as $|\\xi| \\rightarrow \\infty$ by definiton, albeit slower than any negative power of $|\\xi|$. Moreover, the decay rate of $\\widehat{\\mu}$ is essentially optimal, subject to the constraints of its support.","The methods draw inspiration from the number-theoretic results of Schmidt \\cite{s60} and a construction of Lyons \\cite{l86}.","As a consequence, $\\mathscr N(\\mathscr{O}, \\mathscr{E})$ emerges as a set of multiplicity, in the sense of Fourier analysis.","This addresses a question posed by Kahane and Salem \\cite{Kahane-Salem-64} in the special case of $\\mathscr N(\\mathscr{O}, \\mathscr{E})$."],"url":"http://arxiv.org/abs/2403.01358v1","category":"math.CA"}
{"created":"2024-03-02 21:03:12","title":"A peridynamic investigation of particle oxidation, size and material during cold-spray","abstract":"Cold spray technology, distinguished by its unique ability to deposit particles in a solid state, offers unparalleled potential for applications such as coating, repair, and additive manufacturing. In this research, we employed a peridynamic modeling approach to systematically analyze the effects of key powder features on deposit properties. Notably, our model incorporates the explicit modeling of nanometer-sized oxide layers, providing a more accurate representation of real-world conditions. We assessed the influence of parameters such as particle size, oxidation conditions, and material type on crucial deposition indicators like critical velocity and compression ratio. Our results demonstrated excellent agreement with reported experimental data, affirming the effectiveness of the proposed numerical framework. Specifically, our findings highlighted that, for a given impact velocity, smaller particles, thicker oxide layers, and harder materials contribute to limited oxide removal and a decreased likelihood of successful adhesion. Additionally, we present a predictive framework that establishes a correlation between particle size and critical velocity, providing valuable insights for optimizing cold spray deposition parameters. This innovative approach not only enhances our understanding of the intricate interplay between powder features and deposit properties but also paves the way for a more efficient and cost-effective optimization process in cold spray applications.","sentences":["Cold spray technology, distinguished by its unique ability to deposit particles in a solid state, offers unparalleled potential for applications such as coating, repair, and additive manufacturing.","In this research, we employed a peridynamic modeling approach to systematically analyze the effects of key powder features on deposit properties.","Notably, our model incorporates the explicit modeling of nanometer-sized oxide layers, providing a more accurate representation of real-world conditions.","We assessed the influence of parameters such as particle size, oxidation conditions, and material type on crucial deposition indicators like critical velocity and compression ratio.","Our results demonstrated excellent agreement with reported experimental data, affirming the effectiveness of the proposed numerical framework.","Specifically, our findings highlighted that, for a given impact velocity, smaller particles, thicker oxide layers, and harder materials contribute to limited oxide removal and a decreased likelihood of successful adhesion.","Additionally, we present a predictive framework that establishes a correlation between particle size and critical velocity, providing valuable insights for optimizing cold spray deposition parameters.","This innovative approach not only enhances our understanding of the intricate interplay between powder features and deposit properties but also paves the way for a more efficient and cost-effective optimization process in cold spray applications."],"url":"http://arxiv.org/abs/2403.01311v1","category":"physics.app-ph"}
{"created":"2024-03-02 16:23:44","title":"Accelerating Greedy Coordinate Gradient via Probe Sampling","abstract":"Safety of Large Language Models (LLMs) has become a central issue given their rapid progress and wide applications. Greedy Coordinate Gradient (GCG) is shown to be effective in constructing prompts containing adversarial suffixes to break the presumingly safe LLMs, but the optimization of GCG is time-consuming and limits its practicality. To reduce the time cost of GCG and enable more comprehensive studies of LLM safety, in this work, we study a new algorithm called $\\texttt{Probe sampling}$ to accelerate the GCG algorithm. At the core of the algorithm is a mechanism that dynamically determines how similar a smaller draft model's predictions are to the target model's predictions for prompt candidates. When the target model is similar to the draft model, we rely heavily on the draft model to filter out a large number of potential prompt candidates to reduce the computation time. Probe sampling achieves up to $5.6$ times speedup using Llama2-7b and leads to equal or improved attack success rate (ASR) on the AdvBench.","sentences":["Safety of Large Language Models (LLMs) has become a central issue given their rapid progress and wide applications.","Greedy Coordinate Gradient (GCG) is shown to be effective in constructing prompts containing adversarial suffixes to break the presumingly safe LLMs, but the optimization of GCG is time-consuming and limits its practicality.","To reduce the time cost of GCG and enable more comprehensive studies of LLM safety, in this work, we study a new algorithm called $\\texttt{Probe sampling}$ to accelerate the GCG algorithm.","At the core of the algorithm is a mechanism that dynamically determines how similar a smaller draft model's predictions are to the target model's predictions for prompt candidates.","When the target model is similar to the draft model, we rely heavily on the draft model to filter out a large number of potential prompt candidates to reduce the computation time.","Probe sampling achieves up to $5.6$ times speedup using Llama2-7b and leads to equal or improved attack success rate (ASR) on the AdvBench."],"url":"http://arxiv.org/abs/2403.01251v1","category":"cs.CL"}
{"created":"2024-03-02 12:33:45","title":"Organic solvent boosts charge storage and charging dynamics of conductive MOF supercapacitors","abstract":"Conductive metal-organic frameworks (c-MOFs) and ionic liquids (ILs) have emerged as auspicious combinations for high-performance supercapacitors. However, the nanoconfinement from c-MOFs and high viscosity of ILs slow down the charging process. This hindrance can, however, be resolved by adding solvent. Here, we performed constant-potential molecular simulations to scrutinize the solvent impact on charge storage and charging dynamics of MOF-IL-based supercapacitors. We find conditions for >100% enhancement in capacity and ~6 times increase in charging speed. These improvements were confirmed by synthesizing near-ideal c-MOFs and developing multiscale models linking molecular simulations to electrochemical measurements. Fundamentally, our findings elucidate that the solvent acts as an ionophobic agent to induce a substantial enhancement in charge storage, and as an ion traffic police to eliminate convoluted counterion and co-ion motion paths and create two distinct ion transport highways to accelerate charging dynamics. This work paves the way for the optimal design of MOF supercapacitors.","sentences":["Conductive metal-organic frameworks (c-MOFs) and ionic liquids (ILs) have emerged as auspicious combinations for high-performance supercapacitors.","However, the nanoconfinement from c-MOFs and high viscosity of ILs slow down the charging process.","This hindrance can, however, be resolved by adding solvent.","Here, we performed constant-potential molecular simulations to scrutinize the solvent impact on charge storage and charging dynamics of MOF-IL-based supercapacitors.","We find conditions for >100% enhancement in capacity and ~6 times increase in charging speed.","These improvements were confirmed by synthesizing near-ideal c-MOFs and developing multiscale models linking molecular simulations to electrochemical measurements.","Fundamentally, our findings elucidate that the solvent acts as an ionophobic agent to induce a substantial enhancement in charge storage, and as an ion traffic police to eliminate convoluted counterion and co-ion motion paths and create two distinct ion transport highways to accelerate charging dynamics.","This work paves the way for the optimal design of MOF supercapacitors."],"url":"http://arxiv.org/abs/2403.01198v1","category":"physics.app-ph"}
{"created":"2024-03-02 09:00:57","title":"Edge-guided Low-light Image Enhancement with Inertial Bregman Alternating Linearized Minimization","abstract":"Prior-based methods for low-light image enhancement often face challenges in extracting available prior information from dim images. To overcome this limitation, we introduce a simple yet effective Retinex model with the proposed edge extraction prior. More specifically, we design an edge extraction network to capture the fine edge features from the low-light image directly. Building upon the Retinex theory, we decompose the low-light image into its illumination and reflectance components and introduce an edge-guided Retinex model for enhancing low-light images. To solve the proposed model, we propose a novel inertial Bregman alternating linearized minimization algorithm. This algorithm addresses the optimization problem associated with the edge-guided Retinex model, enabling effective enhancement of low-light images. Through rigorous theoretical analysis, we establish the convergence properties of the algorithm. Besides, we prove that the proposed algorithm converges to a stationary point of the problem through nonconvex optimization theory. Furthermore, extensive experiments are conducted on multiple real-world low-light image datasets to demonstrate the efficiency and superiority of the proposed scheme.","sentences":["Prior-based methods for low-light image enhancement often face challenges in extracting available prior information from dim images.","To overcome this limitation, we introduce a simple yet effective Retinex model with the proposed edge extraction prior.","More specifically, we design an edge extraction network to capture the fine edge features from the low-light image directly.","Building upon the Retinex theory, we decompose the low-light image into its illumination and reflectance components and introduce an edge-guided Retinex model for enhancing low-light images.","To solve the proposed model, we propose a novel inertial Bregman alternating linearized minimization algorithm.","This algorithm addresses the optimization problem associated with the edge-guided Retinex model, enabling effective enhancement of low-light images.","Through rigorous theoretical analysis, we establish the convergence properties of the algorithm.","Besides, we prove that the proposed algorithm converges to a stationary point of the problem through nonconvex optimization theory.","Furthermore, extensive experiments are conducted on multiple real-world low-light image datasets to demonstrate the efficiency and superiority of the proposed scheme."],"url":"http://arxiv.org/abs/2403.01142v1","category":"cs.CV"}
{"created":"2024-03-02 23:04:56","title":"Embeddability of higher-rank graphs in groupoids, and the structure of their C*-algebras","abstract":"We show that the C*-algebra of a row-finite source-free k-graph is Rieffel-Morita equivalent to a crossed product of an AF algebra by the fundamental group of the k-graph. When the k-graph embeds in its fundamental groupoid, this AF algebra is a Fell algebra; and simple-connectedness of a certain sub-1-graph characterises when this Fell algebra is Rieffel--Morita equivalent to a commutative C*-algebra. We provide a substantial suite of results for determining if a given k-graph embeds in its fundamental groupoid, and provide a large class of examples, arising via work of Cartwright, Robertson, Steger et al. from the theory of $\\tilde{A_2}$-groups, that do embed.","sentences":["We show that the C*-algebra of a row-finite source-free k-graph is Rieffel-Morita equivalent to a crossed product of an AF algebra by the fundamental group of the k-graph.","When the k-graph embeds in its fundamental groupoid, this AF algebra is a Fell algebra; and simple-connectedness of a certain sub-1-graph characterises when this Fell algebra is Rieffel--Morita equivalent to a commutative C*-algebra.","We provide a substantial suite of results for determining if a given k-graph embeds in its fundamental groupoid, and provide a large class of examples, arising via work of Cartwright, Robertson, Steger et al.","from the theory of $\\tilde{A_2}$-groups, that do embed."],"url":"http://arxiv.org/abs/2403.01337v1","category":"math.OA"}
{"created":"2024-03-02 22:32:49","title":"The legacy of Bletchley Park on UK mathematics","abstract":"The second world war saw a major influx of mathematical talent into the areas of cryptanalysis and cryptography. This was particularly true at the UK's Government Codes and Cypher School (GCCS) at Bletchley Park. The success of introducing mathematical thinking into activities previously dominated by linguists is well-studied, but the reciprocal question of how the cryptologic effort affected the field of mathematics has been less investigated. Although their cryptologic achievements are not as celebrated as those of Turing, Tutte and Welchman, Bletchley Park's effort was supplemented by more eminent mathematicians, and those who would achieve eminence and provide leadership and direction for mathematical research in the United Kingdom. Amongst their number were Ian Cassels, Sandy Green, Philip Hall, Max Newman and Henry Whitehead. This paper considers how the experience of these and other mathematicians at Bletchley Park may have informed and influenced the mathematics that was produced in their post-war careers.","sentences":["The second world war saw a major influx of mathematical talent into the areas of cryptanalysis and cryptography.","This was particularly true at the UK's Government Codes and Cypher School (GCCS) at Bletchley Park.","The success of introducing mathematical thinking into activities previously dominated by linguists is well-studied, but the reciprocal question of how the cryptologic effort affected the field of mathematics has been less investigated.","Although their cryptologic achievements are not as celebrated as those of Turing, Tutte and Welchman, Bletchley Park's effort was supplemented by more eminent mathematicians, and those who would achieve eminence and provide leadership and direction for mathematical research in the United Kingdom.","Amongst their number were Ian Cassels, Sandy Green, Philip Hall, Max Newman and Henry Whitehead.","This paper considers how the experience of these and other mathematicians at Bletchley Park may have informed and influenced the mathematics that was produced in their post-war careers."],"url":"http://arxiv.org/abs/2403.01331v1","category":"math.HO"}
{"created":"2024-03-02 19:01:40","title":"Greed is All You Need: An Evaluation of Tokenizer Inference Methods","abstract":"While subword tokenizers such as BPE and WordPiece are typically used to build vocabularies for NLP models, the method of decoding text into a sequence of tokens from these vocabularies is often left unspecified, or ill-suited to the method in which they were constructed. We provide a controlled analysis of seven tokenizer inference methods across four different algorithms and three vocabulary sizes, performed on a novel intrinsic evaluation suite we curated for English, combining measures rooted in morphology, cognition, and information theory. We show that for the most commonly used tokenizers, greedy inference performs surprisingly well; and that SaGe, a recently-introduced contextually-informed tokenizer, outperforms all others on morphological alignment.","sentences":["While subword tokenizers such as BPE and WordPiece are typically used to build vocabularies for NLP models, the method of decoding text into a sequence of tokens from these vocabularies is often left unspecified, or ill-suited to the method in which they were constructed.","We provide a controlled analysis of seven tokenizer inference methods across four different algorithms and three vocabulary sizes, performed on a novel intrinsic evaluation suite we curated for English, combining measures rooted in morphology, cognition, and information theory.","We show that for the most commonly used tokenizers, greedy inference performs surprisingly well; and that SaGe, a recently-introduced contextually-informed tokenizer, outperforms all others on morphological alignment."],"url":"http://arxiv.org/abs/2403.01289v1","category":"cs.CL"}
{"created":"2024-03-02 16:38:35","title":"Improved Modelling of Detector Response Effects in Phonon-based Crystal Detectors used for Dark Matter Searches","abstract":"Various dark matter search experiments employ phonon-based crystal detectors operated at cryogenic temperatures. Some of these detectors, including certain silicon detectors used by the SuperCDMS collaboration, are able to achieve single-charge sensitivity when a voltage bias is applied across the detector. The total amount of phonon energy measured by such a detector is proportional to the number of electron-hole pairs created by the interaction. However, crystal impurities and surface effects can cause propagating charges to either become trapped inside the crystal or create additional unpaired charges, producing non-quantized measured energy as a result. A new analytical model for describing these detector response effects in phonon-based crystal detectors is presented. This model improves upon previous versions by demonstrating how the detector response, and thus the measured energy spectrum, is expected to differ depending on the source of events. We use this model to extract detector response parameters for SuperCDMS HVeV detectors, and illustrate how this robust modelling can help statistically discriminate between sources of events in order to improve the sensitivity of dark matter search experiments.","sentences":["Various dark matter search experiments employ phonon-based crystal detectors operated at cryogenic temperatures.","Some of these detectors, including certain silicon detectors used by the SuperCDMS collaboration, are able to achieve single-charge sensitivity when a voltage bias is applied across the detector.","The total amount of phonon energy measured by such a detector is proportional to the number of electron-hole pairs created by the interaction.","However, crystal impurities and surface effects can cause propagating charges to either become trapped inside the crystal or create additional unpaired charges, producing non-quantized measured energy as a result.","A new analytical model for describing these detector response effects in phonon-based crystal detectors is presented.","This model improves upon previous versions by demonstrating how the detector response, and thus the measured energy spectrum, is expected to differ depending on the source of events.","We use this model to extract detector response parameters for SuperCDMS HVeV detectors, and illustrate how this robust modelling can help statistically discriminate between sources of events in order to improve the sensitivity of dark matter search experiments."],"url":"http://arxiv.org/abs/2403.01259v1","category":"physics.ins-det"}
{"created":"2024-03-02 16:35:54","title":"Feedback and ionized gas outflows in four low-radio power AGN at z $\\sim$0.15","abstract":"An increasing number of observations and simulations suggests that low-power (<10$^{44}$ erg s$^{-1}$) jets may be a significant channel of feedback produced by active galactic nuclei (AGN), but little is known about their actual effect on their host galaxies from the observational point of view. We targeted four luminous type 2 AGN hosting moderately powerful radio emission ($\\sim$10$^{44}$ erg s$^{-1}$), two of which and possibly a third are associated with jets, with optical integral field spectroscopy observations from the Multi Unit Spectroscopic Explorer (MUSE) at the Very Large Telescope (VLT) to analyze the properties of their ionized gas as well as the properties and effects of ionized outflows. We combined these observations with Very Large Array (VLA) and e-MERLIN data to investigate the relations and interactions between the radio jets and host galaxies. We detected ionized outflows as traced by the fast bulk motion of the gas. The outflows extended over kiloparsec scales in the direction of the jet, when present. In the two sources with resolved radio jets, we detected a strong enhancement in the emission-line velocity dispersion (up to 1000 km s$^{-1}$) perpendicular to the direction of the radio jets. We also found a correlation between the mass and the energetics of this high-velocity dispersion gas and the radio power, which supports the idea that the radio emission may cause the enhanced turbulence. This phenomenon, which is now being observed in an increasing number of objects, might represent an important channel for AGN feedback on galaxies.","sentences":["An increasing number of observations and simulations suggests that low-power (<10$^{44}$ erg s$^{-1}$) jets may be a significant channel of feedback produced by active galactic nuclei (AGN), but little is known about their actual effect on their host galaxies from the observational point of view.","We targeted four luminous type 2 AGN hosting moderately powerful radio emission ($\\sim$10$^{44}$ erg s$^{-1}$), two of which and possibly a third are associated with jets, with optical integral field spectroscopy observations from the Multi Unit Spectroscopic Explorer (MUSE) at the Very Large Telescope (VLT) to analyze the properties of their ionized gas as well as the properties and effects of ionized outflows.","We combined these observations with Very Large Array (VLA) and e-MERLIN data to investigate the relations and interactions between the radio jets and host galaxies.","We detected ionized outflows as traced by the fast bulk motion of the gas.","The outflows extended over kiloparsec scales in the direction of the jet, when present.","In the two sources with resolved radio jets, we detected a strong enhancement in the emission-line velocity dispersion (up to 1000 km s$^{-1}$) perpendicular to the direction of the radio jets.","We also found a correlation between the mass and the energetics of this high-velocity dispersion gas and the radio power, which supports the idea that the radio emission may cause the enhanced turbulence.","This phenomenon, which is now being observed in an increasing number of objects, might represent an important channel for AGN feedback on galaxies."],"url":"http://arxiv.org/abs/2403.01258v1","category":"astro-ph.GA"}
{"created":"2024-03-02 15:45:13","title":"Ultra-high numerical aperture waveguide-integrated meta beam shaper","abstract":"Integration of metasurfaces with guided mode sources like waveguides have opened new frontiers for on-chip optical integration. However, the state-of-the-art in the field has targeted applications where long focal distances over thousands of light wavelengths are needed. This regime where the paraxial approximation holds enables inverse design of the metasurfaces with weakly confining elements that are typically thicker than the wavelength in the material. For short-focal length applications at distances less than 100{\\lambda} where the paraxial approximation fails, and high numerical apertures (NA) are necessary, a different approach is required. Here we designed and experimentally demonstrated single-mode waveguide-integrated meta beam shapers capable of redirecting the confined light into the free space and focusing it at focal distances less than 100{\\lambda} above the chip surface into a tightly focused spot. Focal spot characteristics measured at 460nm operating wavelength are approaching diffraction limited focusing across a range of focal lengths, device footprints, and numerical apertures demonstrating the robustness of our approach. Focal volumes smaller than 1{\\mu}m^3 are demonstrated for a range of focal distances below 50{\\mu}m. For a device with some of the highest NA amongst integrated metasurfaces of 0.95 the measured focal volume is as small as just 0.06{\\mu}m^3 at a focal distance of 13{\\mu}m. These on-chip integrated ultra-high NA meta beam shapers have the potential to unlock new applications in quantum optical computing with trapped ions, localized optogenetic neurostimulation, and high resolution in-situ microscopy.","sentences":["Integration of metasurfaces with guided mode sources like waveguides have opened new frontiers for on-chip optical integration.","However, the state-of-the-art in the field has targeted applications where long focal distances over thousands of light wavelengths are needed.","This regime where the paraxial approximation holds enables inverse design of the metasurfaces with weakly confining elements that are typically thicker than the wavelength in the material.","For short-focal length applications at distances less than 100{\\lambda} where the paraxial approximation fails, and high numerical apertures (NA) are necessary, a different approach is required.","Here we designed and experimentally demonstrated single-mode waveguide-integrated meta beam shapers capable of redirecting the confined light into the free space and focusing it at focal distances less than 100{\\lambda} above the chip surface into a tightly focused spot.","Focal spot characteristics measured at 460nm operating wavelength are approaching diffraction limited focusing across a range of focal lengths, device footprints, and numerical apertures demonstrating the robustness of our approach.","Focal volumes smaller than 1{\\mu}m^3 are demonstrated for a range of focal distances below 50{\\mu}m.","For a device with some of the highest NA amongst integrated metasurfaces of 0.95 the measured focal volume is as small as just 0.06{\\mu}m^3 at a focal distance of 13{\\mu}m.","These on-chip integrated ultra-high NA meta beam shapers have the potential to unlock new applications in quantum optical computing with trapped ions, localized optogenetic neurostimulation, and high resolution in-situ microscopy."],"url":"http://arxiv.org/abs/2403.01237v1","category":"physics.optics"}
{"created":"2024-03-02 14:39:43","title":"The generalised Mooney space for modelling the response of rubber-like materials","abstract":"Soft materials such as rubbers, silicones, gels and biological tissues have a nonlinear response to large deformations, a phenomenon which in principle can be captured by hyperelastic models. The suitability of a candidate hyperelastic strain energy function is then determined by comparing its predicted response to the data gleaned from tests and adjusting the material parameters to get a good fit, an exercise which can be deceptive because of nonlinearity. Here we propose to generalise the approach of Rivlin and Saunders [Phil Trans A 243 (1951) 251-288] who, instead of reporting the data as stress against stretch, manipulated these measures to create the 'Mooney plot', where the Mooney-Rivlin model is expected to produce a linear fit. We show that extending this idea to other models and modes of deformation (tension, shear, torsion, etc.) is advantageous, not only (a) for the fitting procedure, but also to (b) delineate trends in the deformation which are not obvious from the raw data (and may be interpreted in terms of micro-, meso-, and macro-structures) and (c) obtain a bounded condition number \\k{appa} over the whole range of deformation; a robustness which is lacking in other plots and spaces.","sentences":["Soft materials such as rubbers, silicones, gels and biological tissues have a nonlinear response to large deformations, a phenomenon which in principle can be captured by hyperelastic models.","The suitability of a candidate hyperelastic strain energy function is then determined by comparing its predicted response to the data gleaned from tests and adjusting the material parameters to get a good fit, an exercise which can be deceptive because of nonlinearity.","Here we propose to generalise the approach of Rivlin and Saunders","[Phil Trans A 243 (1951) 251-288] who, instead of reporting the data as stress against stretch, manipulated these measures to create the 'Mooney plot', where the Mooney-Rivlin model is expected to produce a linear fit.","We show that extending this idea to other models and modes of deformation (tension, shear, torsion, etc.) is advantageous, not only (a) for the fitting procedure, but also to (b) delineate trends in the deformation which are not obvious from the raw data (and may be interpreted in terms of micro-, meso-, and macro-structures) and (c) obtain a bounded condition number \\k{appa} over the whole range of deformation; a robustness which is lacking in other plots and spaces."],"url":"http://arxiv.org/abs/2403.01223v1","category":"cond-mat.soft"}
{"created":"2024-03-02 12:10:43","title":"Strangeness plus-one ($S=+1$) resonance-state $P^{+*}_0$ via $K^+n\\to K^{*0}p$","abstract":"In our current study, we delve into the peak-like structure observed during the reaction process of $K^+n\\to K^{0}p$ at approximately $\\sqrt{s}\\sim2.5$ GeV. Our focus centers on exploring the potential $S=+1$ resonance $P^{+*}_0\\equiv P^*_0$ as an excited state within the extended vector-meson and baryon ($VB$) antidecuplet. To achieve this aim, we employ the effective Lagrangian method in conjunction with the $(u,t)$-channel Regge approach, operating within the tree-level Born approximation. We thoroughly examine various spin-parity quantum numbers for the resonance, resulting in a compelling description of the data, where $M_{P^*_0}\\approx2.5$ GeV and $\\Gamma_{P^*_0}\\approx100$ MeV. Furthermore, we propose an experimental technique to amplify the signal-to-noise ratio ($S/N$) for accurately measuring the resonance. Notably, our findings reveal that background interference diminishes significantly within the $K^*$ forward-scattering region in the center-of-mass frame when the $K^*$ is perpendicularly polarized to the reaction plane. Additionally, we explore the recoil-proton spin asymmetry to definitively determine the spin and parity of the resonance. This study stands to serve as a valuable reference for designing experimental setups aimed at investigating and comprehending exotic phenomena in QCD. Specifically, our insights will inform future J-PARC experiments, particularly those employing higher kaon beam energies.","sentences":["In our current study, we delve into the peak-like structure observed during the reaction process of $K^+n\\to K^{0}p$ at approximately $\\sqrt{s}\\sim2.5$ GeV. Our focus centers on exploring the potential $S=+1$ resonance $P^{+*}_0\\equiv P^*_0$ as an excited state within the extended vector-meson and baryon ($VB$) antidecuplet.","To achieve this aim, we employ the effective Lagrangian method in conjunction with the $(u,t)$-channel Regge approach, operating within the tree-level Born approximation.","We thoroughly examine various spin-parity quantum numbers for the resonance, resulting in a compelling description of the data, where $M_{P^*_0}\\approx2.5$ GeV and $\\Gamma_{P^*_0}\\approx100$ MeV.","Furthermore, we propose an experimental technique to amplify the signal-to-noise ratio ($S/N$) for accurately measuring the resonance.","Notably, our findings reveal that background interference diminishes significantly within the $K^*$ forward-scattering region in the center-of-mass frame when the $K^*$ is perpendicularly polarized to the reaction plane.","Additionally, we explore the recoil-proton spin asymmetry to definitively determine the spin and parity of the resonance.","This study stands to serve as a valuable reference for designing experimental setups aimed at investigating and comprehending exotic phenomena in QCD.","Specifically, our insights will inform future J-PARC experiments, particularly those employing higher kaon beam energies."],"url":"http://arxiv.org/abs/2403.01191v1","category":"hep-ph"}
{"created":"2024-03-02 11:02:10","title":"Hydrogen uptake kinetics of cathodic polarized metals in aqueous electrolytes","abstract":"We use a unique combination of electrochemical techniques to elucidate the dependency of hydrogen evolution reaction (HER) and absorption on pH and overpotential for iron and nickel. Impedance spectroscopy shows the dominance of the Volmer-Heyrovsky reaction pathway, challenging the common consideration of Volmer-Tafel dominance. Polarization slopes agree with the Volmer or Heyrovsky rate-determining step, with limitations at high overpotential. The evolution of steady-state permeation current density with overpotential is rationalised through newly-developed theory. Surface activity and absorption trends are captured. Combined with modelling, this work provides a path for quantifying hydrogen uptake and establishing an equivalent fugacity for aqueous electrolytes.","sentences":["We use a unique combination of electrochemical techniques to elucidate the dependency of hydrogen evolution reaction (HER) and absorption on pH and overpotential for iron and nickel.","Impedance spectroscopy shows the dominance of the Volmer-Heyrovsky reaction pathway, challenging the common consideration of Volmer-Tafel dominance.","Polarization slopes agree with the Volmer or Heyrovsky rate-determining step, with limitations at high overpotential.","The evolution of steady-state permeation current density with overpotential is rationalised through newly-developed theory.","Surface activity and absorption trends are captured.","Combined with modelling, this work provides a path for quantifying hydrogen uptake and establishing an equivalent fugacity for aqueous electrolytes."],"url":"http://arxiv.org/abs/2403.01176v1","category":"physics.chem-ph"}
{"created":"2024-03-02 10:37:21","title":"HeteGen: Heterogeneous Parallel Inference for Large Language Models on Resource-Constrained Devices","abstract":"In recent times, the emergence of Large Language Models (LLMs) has resulted in increasingly larger model size, posing challenges for inference on low-resource devices. Prior approaches have explored offloading to facilitate low-memory inference but often suffer from efficiency due to I/O bottlenecks. To achieve low-latency LLMs inference on resource-constrained devices, we introduce HeteGen, a novel approach that presents a principled framework for heterogeneous parallel computing using CPUs and GPUs. Based on this framework, HeteGen further employs heterogeneous parallel computing and asynchronous overlap for LLMs to mitigate I/O bottlenecks. Our experiments demonstrate a substantial improvement in inference speed, surpassing state-of-the-art methods by over 317% at most.","sentences":["In recent times, the emergence of Large Language Models (LLMs) has resulted in increasingly larger model size, posing challenges for inference on low-resource devices.","Prior approaches have explored offloading to facilitate low-memory inference but often suffer from efficiency due to I/O bottlenecks.","To achieve low-latency LLMs inference on resource-constrained devices, we introduce HeteGen, a novel approach that presents a principled framework for heterogeneous parallel computing using CPUs and GPUs.","Based on this framework, HeteGen further employs heterogeneous parallel computing and asynchronous overlap for LLMs to mitigate I/O bottlenecks.","Our experiments demonstrate a substantial improvement in inference speed, surpassing state-of-the-art methods by over 317% at most."],"url":"http://arxiv.org/abs/2403.01164v1","category":"cs.PF"}
{"created":"2024-03-02 09:32:49","title":"Spectra of phosphorus ions for astrophysical modeling: P I - P XV","abstract":"Phosphorus (P), a basic element of life, has been a least studied element due to its poor presence in astrophysical spectra. However, search for the P lines has increased considerably with discoveries of exoplanets and are being detected by high resolution and sophisticated astronomical observatories, e.g. James Webb Space Telescope (JWST). JWST may provide a clue for life with detection of P in its infrared (IR) region. Identification of the element and analysis of the observed spectra will require high accuracy data for atomic processes that produces lines and their predicted features. The present study focuses on these needs and reports systematically regions of wavelengths, from x-ray to IR, that show prominent lines by the 15 individual ionization stages of phosphorus, P I - P XV for the first time. We present large amount of relevant atomic data for energies, transition parameters, and lifetimes obtained in relativistic Breit-Pauli approximation using the R-matrix method and atomic structure program SUPERSTRUCTURE. Our spectral features for the fifteen ions, P I - P XV, predict strengths of lines in various wavelength regions. They show dominance of P~I and P~II in the infrared region and other ions in the ultraviolet and optical regions often stretching to IR in the continuum. For determination of accuracy, we have made extensive comparisons of our atomic data with available experimental and theoretical values. Based on these, our results and features are expected to provide precise plasma diagnostics and astrophysical modeling.","sentences":["Phosphorus (P), a basic element of life, has been a least studied element due to its poor presence in astrophysical spectra.","However, search for the P lines has increased considerably with discoveries of exoplanets and are being detected by high resolution and sophisticated astronomical observatories, e.g. James Webb Space Telescope (JWST).","JWST may provide a clue for life with detection of P in its infrared (IR) region.","Identification of the element and analysis of the observed spectra will require high accuracy data for atomic processes that produces lines and their predicted features.","The present study focuses on these needs and reports systematically regions of wavelengths, from x-ray to IR, that show prominent lines by the 15 individual ionization stages of phosphorus, P I - P XV for the first time.","We present large amount of relevant atomic data for energies, transition parameters, and lifetimes obtained in relativistic Breit-Pauli approximation using the R-matrix method and atomic structure program SUPERSTRUCTURE.","Our spectral features for the fifteen ions, P I - P XV, predict strengths of lines in various wavelength regions.","They show dominance of P~I and P~II in the infrared region and other ions in the ultraviolet and optical regions often stretching to IR in the continuum.","For determination of accuracy, we have made extensive comparisons of our atomic data with available experimental and theoretical values.","Based on these, our results and features are expected to provide precise plasma diagnostics and astrophysical modeling."],"url":"http://arxiv.org/abs/2403.01148v1","category":"physics.atom-ph"}
{"created":"2024-03-02 09:07:52","title":"Angular analyses of rare decays at the LHC","abstract":"Loop-suppressed penguin $b\\to s$ transitions are sensitive to heavy New Physics particles propagating inside the loops. Thanks to the large sample sizes from the LHC, we are able to perform multidimensional angular analyses that are sensitive to interferences between the Standard Model and New Physics terms. This article surveys the latest results, primarily from LHCb, on $b\\to s\\mu^+\\mu^-$ electroweak and $b\\to s\\gamma$ radiative penguins.","sentences":["Loop-suppressed penguin $b\\to s$ transitions are sensitive to heavy New Physics particles propagating inside the loops.","Thanks to the large sample sizes from the LHC, we are able to perform multidimensional angular analyses that are sensitive to interferences between the Standard Model and New Physics terms.","This article surveys the latest results, primarily from LHCb, on $b\\to s\\mu^+\\mu^-$ electroweak and $b\\to s\\gamma$ radiative penguins."],"url":"http://arxiv.org/abs/2403.01143v1","category":"hep-ex"}
