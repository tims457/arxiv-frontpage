{"created":"2024-03-14 17:32:31","title":"cosmocnc: A fast, flexible, and accurate galaxy cluster number count likelihood code for cosmology","abstract":"We introduce cosmocnc, a Python package for computing the number count likelihood of galaxy cluster catalogues in a fast, flexible and accurate way. cosmocnc offers three types of likelihoods: an unbinned, a binned, and an extreme value likelihood. It also supports the addition of stacked cluster data, which is modelled consistently with the cluster catalogue. The unbinned likelihood, which is the main focus of the code, can take an arbitrary number of mass observables as input and deal with several complexities in the data, such as variations in the properties of the cluster observable across the survey footprint, the possibility of different clusters having measurements for different combinations of mass observables, redshift measurement uncertainties, and the presence on unconfirmed detections in the catalogue. If there are more than one mass observables, the unbinned likelihood is computed with the backward convolutional approach, a novel approach that is first implemented in cosmocnc. After developing the likelihood formalism and describing its implementation, we validate the code with synthetic Simons-Observatory-like catalogues, finding excellent agreement between their properties and cosmocnc's predictions and obtaining constraints on cosmological and scaling relation parameters featuring negligible biases. cosmocnc is publicly available at github.com/inigozubeldia/cosmocnc.","sentences":["We introduce cosmocnc, a Python package for computing the number count likelihood of galaxy cluster catalogues in a fast, flexible and accurate way.","cosmocnc offers three types of likelihoods: an unbinned, a binned, and an extreme value likelihood.","It also supports the addition of stacked cluster data, which is modelled consistently with the cluster catalogue.","The unbinned likelihood, which is the main focus of the code, can take an arbitrary number of mass observables as input and deal with several complexities in the data, such as variations in the properties of the cluster observable across the survey footprint, the possibility of different clusters having measurements for different combinations of mass observables, redshift measurement uncertainties, and the presence on unconfirmed detections in the catalogue.","If there are more than one mass observables, the unbinned likelihood is computed with the backward convolutional approach, a novel approach that is first implemented in cosmocnc.","After developing the likelihood formalism and describing its implementation, we validate the code with synthetic Simons-Observatory-like catalogues, finding excellent agreement between their properties and cosmocnc's predictions and obtaining constraints on cosmological and scaling relation parameters featuring negligible biases.","cosmocnc is publicly available at github.com/inigozubeldia/cosmocnc."],"url":"http://arxiv.org/abs/2403.09589v1","category":"astro-ph.CO"}
{"created":"2024-03-14 17:56:14","title":"Score-Guided Diffusion for 3D Human Recovery","abstract":"We present Score-Guided Human Mesh Recovery (ScoreHMR), an approach for solving inverse problems for 3D human pose and shape reconstruction. These inverse problems involve fitting a human body model to image observations, traditionally solved through optimization techniques. ScoreHMR mimics model fitting approaches, but alignment with the image observation is achieved through score guidance in the latent space of a diffusion model. The diffusion model is trained to capture the conditional distribution of the human model parameters given an input image. By guiding its denoising process with a task-specific score, ScoreHMR effectively solves inverse problems for various applications without the need for retraining the task-agnostic diffusion model. We evaluate our approach on three settings/applications. These are: (i) single-frame model fitting; (ii) reconstruction from multiple uncalibrated views; (iii) reconstructing humans in video sequences. ScoreHMR consistently outperforms all optimization baselines on popular benchmarks across all settings. We make our code and models available at the https://statho.github.io/ScoreHMR.","sentences":["We present Score-Guided Human Mesh Recovery (ScoreHMR), an approach for solving inverse problems for 3D human pose and shape reconstruction.","These inverse problems involve fitting a human body model to image observations, traditionally solved through optimization techniques.","ScoreHMR mimics model fitting approaches, but alignment with the image observation is achieved through score guidance in the latent space of a diffusion model.","The diffusion model is trained to capture the conditional distribution of the human model parameters given an input image.","By guiding its denoising process with a task-specific score, ScoreHMR effectively solves inverse problems for various applications without the need for retraining the task-agnostic diffusion model.","We evaluate our approach on three settings/applications.","These are: (i) single-frame model fitting; (ii) reconstruction from multiple uncalibrated views; (iii) reconstructing humans in video sequences.","ScoreHMR consistently outperforms all optimization baselines on popular benchmarks across all settings.","We make our code and models available at the https://statho.github.io/ScoreHMR."],"url":"http://arxiv.org/abs/2403.09623v1","category":"cs.CV"}
{"created":"2024-03-14 17:17:16","title":"High-dimensional expansion and soficity of groups","abstract":"For $d \\geq 4$ and $p$ a sufficiently large prime, we construct a lattice $\\Gamma \\leq {\\rm PSp}_{2d}(\\mathbb Q_p),$ such that its universal central extension cannot be sofic if $\\Gamma$ satisfies some weak form of stability in permutations. In the proof, we make use of high-dimensional expansion phenomena and, extending results of Lubotzky, we construct new examples of cosystolic expanders over arbitrary finite abelian groups.","sentences":["For $d \\geq 4$ and $p$ a sufficiently large prime, we construct a lattice $\\Gamma \\leq {\\rm PSp}_{2d}(\\mathbb Q_p),$ such that its universal central extension cannot be sofic if $\\Gamma$ satisfies some weak form of stability in permutations.","In the proof, we make use of high-dimensional expansion phenomena and, extending results of Lubotzky, we construct new examples of cosystolic expanders over arbitrary finite abelian groups."],"url":"http://arxiv.org/abs/2403.09582v1","category":"math.GR"}
{"created":"2024-03-14 17:11:49","title":"The NeRFect Match: Exploring NeRF Features for Visual Localization","abstract":"In this work, we propose the use of Neural Radiance Fields (NeRF) as a scene representation for visual localization. Recently, NeRF has been employed to enhance pose regression and scene coordinate regression models by augmenting the training database, providing auxiliary supervision through rendered images, or serving as an iterative refinement module. We extend its recognized advantages -- its ability to provide a compact scene representation with realistic appearances and accurate geometry -- by exploring the potential of NeRF's internal features in establishing precise 2D-3D matches for localization. To this end, we conduct a comprehensive examination of NeRF's implicit knowledge, acquired through view synthesis, for matching under various conditions. This includes exploring different matching network architectures, extracting encoder features at multiple layers, and varying training configurations. Significantly, we introduce NeRFMatch, an advanced 2D-3D matching function that capitalizes on the internal knowledge of NeRF learned via view synthesis. Our evaluation of NeRFMatch on standard localization benchmarks, within a structure-based pipeline, sets a new state-of-the-art for localization performance on Cambridge Landmarks.","sentences":["In this work, we propose the use of Neural Radiance Fields (NeRF) as a scene representation for visual localization.","Recently, NeRF has been employed to enhance pose regression and scene coordinate regression models by augmenting the training database, providing auxiliary supervision through rendered images, or serving as an iterative refinement module.","We extend its recognized advantages -- its ability to provide a compact scene representation with realistic appearances and accurate geometry -- by exploring the potential of NeRF's internal features in establishing precise 2D-3D matches for localization.","To this end, we conduct a comprehensive examination of NeRF's implicit knowledge, acquired through view synthesis, for matching under various conditions.","This includes exploring different matching network architectures, extracting encoder features at multiple layers, and varying training configurations.","Significantly, we introduce NeRFMatch, an advanced 2D-3D matching function that capitalizes on the internal knowledge of NeRF learned via view synthesis.","Our evaluation of NeRFMatch on standard localization benchmarks, within a structure-based pipeline, sets a new state-of-the-art for localization performance on Cambridge Landmarks."],"url":"http://arxiv.org/abs/2403.09577v1","category":"cs.CV"}
{"created":"2024-03-14 16:39:23","title":"\"Are You Really Sure?\" Understanding the Effects of Human Self-Confidence Calibration in AI-Assisted Decision Making","abstract":"In AI-assisted decision-making, it is crucial but challenging for humans to achieve appropriate reliance on AI. This paper approaches this problem from a human-centered perspective, \"human self-confidence calibration\". We begin by proposing an analytical framework to highlight the importance of calibrated human self-confidence. In our first study, we explore the relationship between human self-confidence appropriateness and reliance appropriateness. Then in our second study, We propose three calibration mechanisms and compare their effects on humans' self-confidence and user experience. Subsequently, our third study investigates the effects of self-confidence calibration on AI-assisted decision-making. Results show that calibrating human self-confidence enhances human-AI team performance and encourages more rational reliance on AI (in some aspects) compared to uncalibrated baselines. Finally, we discuss our main findings and provide implications for designing future AI-assisted decision-making interfaces.","sentences":["In AI-assisted decision-making, it is crucial but challenging for humans to achieve appropriate reliance on AI.","This paper approaches this problem from a human-centered perspective, \"human self-confidence calibration\".","We begin by proposing an analytical framework to highlight the importance of calibrated human self-confidence.","In our first study, we explore the relationship between human self-confidence appropriateness and reliance appropriateness.","Then in our second study, We propose three calibration mechanisms and compare their effects on humans' self-confidence and user experience.","Subsequently, our third study investigates the effects of self-confidence calibration on AI-assisted decision-making.","Results show that calibrating human self-confidence enhances human-AI team performance and encourages more rational reliance on AI (in some aspects) compared to uncalibrated baselines.","Finally, we discuss our main findings and provide implications for designing future AI-assisted decision-making interfaces."],"url":"http://arxiv.org/abs/2403.09552v1","category":"cs.HC"}
{"created":"2024-03-14 16:39:11","title":"WeakSurg: Weakly supervised surgical instrument segmentation using temporal equivariance and semantic continuity","abstract":"Weakly supervised surgical instrument segmentation with only instrument presence labels has been rarely explored in surgical domain. To mitigate the highly under-constrained challenges, we extend a two-stage weakly supervised segmentation paradigm with temporal attributes from two perspectives. From a temporal equivariance perspective, we propose a prototype-based temporal equivariance regulation loss to enhance pixel-wise consistency between adjacent features. From a semantic continuity perspective, we propose a class-aware temporal semantic continuity loss to constrain the semantic consistency between a global view of target frame and local non-discriminative regions of adjacent reference frame. To the best of our knowledge, WeakSurg is the first instrument-presence-only weakly supervised segmentation architecture to take temporal information into account for surgical scenarios. Extensive experiments are validated on Cholec80, an open benchmark for phase and instrument recognition. We annotate instance-wise instrument labels with fixed time-steps which are double checked by a clinician with 3-years experience. Our results show that WeakSurg compares favorably with state-of-the-art methods not only on semantic segmentation metrics but also on instance segmentation metrics.","sentences":["Weakly supervised surgical instrument segmentation with only instrument presence labels has been rarely explored in surgical domain.","To mitigate the highly under-constrained challenges, we extend a two-stage weakly supervised segmentation paradigm with temporal attributes from two perspectives.","From a temporal equivariance perspective, we propose a prototype-based temporal equivariance regulation loss to enhance pixel-wise consistency between adjacent features.","From a semantic continuity perspective, we propose a class-aware temporal semantic continuity loss to constrain the semantic consistency between a global view of target frame and local non-discriminative regions of adjacent reference frame.","To the best of our knowledge, WeakSurg is the first instrument-presence-only weakly supervised segmentation architecture to take temporal information into account for surgical scenarios.","Extensive experiments are validated on Cholec80, an open benchmark for phase and instrument recognition.","We annotate instance-wise instrument labels with fixed time-steps which are double checked by a clinician with 3-years experience.","Our results show that WeakSurg compares favorably with state-of-the-art methods not only on semantic segmentation metrics but also on instance segmentation metrics."],"url":"http://arxiv.org/abs/2403.09551v1","category":"cs.CV"}
{"created":"2024-03-14 16:34:30","title":"de Leeuw representations of functionals on Lipschitz spaces","abstract":"Let $\\mathrm{Lip}_0(M)$ be the space of Lipschitz functions on a complete metric space $(M,d)$ that vanish at a point $0\\in M$. We investigate its dual $\\mathrm{Lip}_0(M)^*$ using the de Leeuw transform, which allows representing each functional on $\\mathrm{Lip}_0(M)$ as a (non-unique) measure on $\\beta\\widetilde{M}$, where $\\widetilde{M}$ is the space of pairs $(x,y)\\in M\\times M$, $x\\neq y$. We distinguish a set of points of $\\beta\\widetilde{M}$ that are \"away from infinity\", which can be assigned coordinates belonging to the Lipschitz realcompactification $M^{\\mathcal{R}}$ of $M$. We define a natural metric $\\bar{d}$ on $M^{\\mathcal{R}}$ extending $d$ and we show that optimal (i.e. positive and norm-minimal) de Leeuw representations of well-behaved functionals are characterised by $\\bar{d}$-cyclical monotonicity of their support, extending known results for functionals in $\\mathcal{F}(M)$, the predual of $\\mathrm{Lip}_0(M)$. We also extend the Kantorovich-Rubinstein theorem to normal Hausdorff spaces, in particular to $M^{\\mathcal{R}}$, and use this to characterise measure-induced and majorisable functionals in $\\mathrm{Lip}_0(M)^*$ as those admitting optimal representations with additional finiteness properties. Finally, we use de Leeuw representations to define a natural L-projection of $\\mathrm{Lip}_0(M)^*$ onto $\\mathcal{F}(M)$ under some conditions on $M$.","sentences":["Let $\\mathrm{Lip}_0(M)$ be the space of Lipschitz functions on a complete metric space $(M,d)$ that vanish at a point $0\\in M$. We investigate its dual $\\mathrm{Lip}_0(M)^*$ using the de Leeuw transform, which allows representing each functional on $\\mathrm{Lip}_0(M)$ as a (non-unique) measure on $\\beta\\widetilde{M}$, where $\\widetilde{M}$ is the space of pairs $(x,y)\\in M\\times M$, $x\\neq y$. We distinguish a set of points of $\\beta\\widetilde{M}$ that are \"away from infinity\", which can be assigned coordinates belonging to the Lipschitz realcompactification $M^{\\mathcal{R}}$ of $M$. We define a natural metric $\\bar{d}$ on $M^{\\mathcal{R}}$ extending $d$ and we show that optimal (i.e. positive and norm-minimal) de Leeuw representations of well-behaved functionals are characterised by $\\bar{d}$-cyclical monotonicity of their support, extending known results for functionals in $\\mathcal{F}(M)$, the predual of $\\mathrm{Lip}_0(M)$. We also extend the Kantorovich-Rubinstein theorem to normal Hausdorff spaces, in particular to $M^{\\mathcal{R}}$, and use this to characterise measure-induced and majorisable functionals in $\\mathrm{Lip}_0(M)^*$ as those admitting optimal representations with additional finiteness properties.","Finally, we use de Leeuw representations to define a natural L-projection of $\\mathrm{Lip}_0(M)^*$ onto $\\mathcal{F}(M)$ under some conditions on $M$."],"url":"http://arxiv.org/abs/2403.09546v1","category":"math.FA"}
{"created":"2024-03-14 16:32:29","title":"Sequential Contracts","abstract":"We study the principal-agent setting, where a principal delegates the execution of a costly project to an agent. In the classical model, the agent chooses an action among a set of available actions. Every action is associated with some cost, and leads to a stochastic outcome for the project. The agent's action is hidden from the principal, who only observes the outcome. The principal incentivizes the agent through a payment scheme (a contract) that maps outcomes to payments, with the objective of finding the optimal contract - the contract maximizing the principal's expected utility.   In this work, we introduce a sequential variant of the model, capturing many real-life settings, where the agent engages in multiple attempts, incurring the sum of costs of the actions taken and being compensated for the best realized outcome. We study the contract design problem in this new setting. We first observe that the agent's problem - finding the sequential set of actions that maximizes his utility for a given contract - is equivalent to the well-known Pandora's Box problem. With this insight at hand, we provide algorithms and hardness results for the (principal's) contract design problem, under both independent and correlated actions. For independent actions, we show that the optimal linear contract can be computed in polynomial time. Furthermore, this result extends to the optimal arbitrary contract when the number of outcomes is a constant. For correlated actions we find that approximating the optimal contract within any constant ratio is NP-hard.","sentences":["We study the principal-agent setting, where a principal delegates the execution of a costly project to an agent.","In the classical model, the agent chooses an action among a set of available actions.","Every action is associated with some cost, and leads to a stochastic outcome for the project.","The agent's action is hidden from the principal, who only observes the outcome.","The principal incentivizes the agent through a payment scheme (a contract) that maps outcomes to payments, with the objective of finding the optimal contract - the contract maximizing the principal's expected utility.   ","In this work, we introduce a sequential variant of the model, capturing many real-life settings, where the agent engages in multiple attempts, incurring the sum of costs of the actions taken and being compensated for the best realized outcome.","We study the contract design problem in this new setting.","We first observe that the agent's problem - finding the sequential set of actions that maximizes his utility for a given contract - is equivalent to the well-known Pandora's Box problem.","With this insight at hand, we provide algorithms and hardness results for the (principal's) contract design problem, under both independent and correlated actions.","For independent actions, we show that the optimal linear contract can be computed in polynomial time.","Furthermore, this result extends to the optimal arbitrary contract when the number of outcomes is a constant.","For correlated actions we find that approximating the optimal contract within any constant ratio is NP-hard."],"url":"http://arxiv.org/abs/2403.09545v1","category":"cs.GT"}
{"created":"2024-03-14 16:31:18","title":"Effect of external characteristics of a virtual human being during the use of a computer-assisted therapy tool","abstract":"Identification within media, whether with real or fictional characters, significantly impacts users, shaping their behavior and enriching their social and emotional experiences. Immersive media, like video games, utilize virtual entities such as agents, avatars, or NPCs to connect users with virtual worlds, fostering a heightened sense of immersion and identification. However, challenges arise in visually representing these entities, with design decisions crucial for enhancing user interaction. Recent research highlights the potential of user-defined design, or customization, which goes beyond mere visual resemblance to the user. Understanding how identification with virtual avatars influences user experiences, especially in psychological interventions, is pivotal. In a study exploring this, 22 participants created virtual agents either similar or dissimilar to themselves, which then addressed their dysfunctional thoughts. Results indicate that similarity between users and virtual agents not only boosts identification but also positively impacts emotions and motivation, enhancing interest and enjoyment. This study sheds light on the significance of customization and identification, particularly in computer-assisted therapy tools, underscoring the importance of visual design for optimizing user experiences.","sentences":["Identification within media, whether with real or fictional characters, significantly impacts users, shaping their behavior and enriching their social and emotional experiences.","Immersive media, like video games, utilize virtual entities such as agents, avatars, or NPCs to connect users with virtual worlds, fostering a heightened sense of immersion and identification.","However, challenges arise in visually representing these entities, with design decisions crucial for enhancing user interaction.","Recent research highlights the potential of user-defined design, or customization, which goes beyond mere visual resemblance to the user.","Understanding how identification with virtual avatars influences user experiences, especially in psychological interventions, is pivotal.","In a study exploring this, 22 participants created virtual agents either similar or dissimilar to themselves, which then addressed their dysfunctional thoughts.","Results indicate that similarity between users and virtual agents not only boosts identification but also positively impacts emotions and motivation, enhancing interest and enjoyment.","This study sheds light on the significance of customization and identification, particularly in computer-assisted therapy tools, underscoring the importance of visual design for optimizing user experiences."],"url":"http://arxiv.org/abs/2403.09544v1","category":"cs.HC"}
{"created":"2024-03-14 16:21:32","title":"Robust SGLD algorithm for solving non-convex distributionally robust optimisation problems","abstract":"In this paper we develop a Stochastic Gradient Langevin Dynamics (SGLD) algorithm tailored for solving a certain class of non-convex distributionally robust optimisation problems. By deriving non-asymptotic convergence bounds, we build an algorithm which for any prescribed accuracy $\\varepsilon>0$ outputs an estimator whose expected excess risk is at most $\\varepsilon$. As a concrete application, we employ our robust SGLD algorithm to solve the (regularised) distributionally robust Mean-CVaR portfolio optimisation problem using real financial data. We empirically demonstrate that the trading strategy obtained by our robust SGLD algorithm outperforms the trading strategy obtained when solving the corresponding non-robust Mean-CVaR portfolio optimisation problem using, e.g., a classical SGLD algorithm. This highlights the practical relevance of incorporating model uncertainty when optimising portfolios in real financial markets.","sentences":["In this paper we develop a Stochastic Gradient Langevin Dynamics (SGLD) algorithm tailored for solving a certain class of non-convex distributionally robust optimisation problems.","By deriving non-asymptotic convergence bounds, we build an algorithm which for any prescribed accuracy $\\varepsilon>0$ outputs an estimator whose expected excess risk is at most $\\varepsilon$. As a concrete application, we employ our robust SGLD algorithm to solve the (regularised) distributionally robust Mean-CVaR portfolio optimisation problem using real financial data.","We empirically demonstrate that the trading strategy obtained by our robust SGLD algorithm outperforms the trading strategy obtained when solving the corresponding non-robust Mean-CVaR portfolio optimisation problem using, e.g., a classical SGLD algorithm.","This highlights the practical relevance of incorporating model uncertainty when optimising portfolios in real financial markets."],"url":"http://arxiv.org/abs/2403.09532v1","category":"math.OC"}
{"created":"2024-03-14 17:57:03","title":"Physically motivated improvements of Variational Quantum Eigensolvers","abstract":"The Adaptive Derivative-Assembled Pseudo-Trotter Variational Quantum Eigensolver (ADAPT-VQE) has emerged as a pivotal promising approach for electronic structure challenges in quantum chemistry with noisy quantum devices. Nevertheless, to surmount existing technological constraints, this study endeavors to enhance ADAPT-VQE's efficacy. Leveraging insights from electronic structure theory, we concentrate on optimizing state preparation without added computational burden and guiding ansatz expansion to yield more concise wavefunctions with expedited convergence toward exact solutions. These advancements culminate in shallower circuits and, as demonstrated, reduced measurement requirements. This research delineates these enhancements and assesses their performance across mono, di, and tridimensional arrangements of H4 models, as well as in the water molecule. Ultimately, this work attests to the viability of physically-motivated strategies in fortifying ADAPT-VQE's efficiency, marking a significant stride in quantum chemistry simulations.","sentences":["The Adaptive Derivative-Assembled Pseudo-Trotter Variational Quantum Eigensolver (ADAPT-VQE) has emerged as a pivotal promising approach for electronic structure challenges in quantum chemistry with noisy quantum devices.","Nevertheless, to surmount existing technological constraints, this study endeavors to enhance ADAPT-VQE's efficacy.","Leveraging insights from electronic structure theory, we concentrate on optimizing state preparation without added computational burden and guiding ansatz expansion to yield more concise wavefunctions with expedited convergence toward exact solutions.","These advancements culminate in shallower circuits and, as demonstrated, reduced measurement requirements.","This research delineates these enhancements and assesses their performance across mono, di, and tridimensional arrangements of H4 models, as well as in the water molecule.","Ultimately, this work attests to the viability of physically-motivated strategies in fortifying ADAPT-VQE's efficiency, marking a significant stride in quantum chemistry simulations."],"url":"http://arxiv.org/abs/2403.09624v1","category":"quant-ph"}
{"created":"2024-03-14 17:13:37","title":"uaMix-MAE: Efficient Tuning of Pretrained Audio Transformers with Unsupervised Audio Mixtures","abstract":"Masked Autoencoders (MAEs) learn rich low-level representations from unlabeled data but require substantial labeled data to effectively adapt to downstream tasks. Conversely, Instance Discrimination (ID) emphasizes high-level semantics, offering a potential solution to alleviate annotation requirements in MAEs. Although combining these two approaches can address downstream tasks with limited labeled data, naively integrating ID into MAEs leads to extended training times and high computational costs. To address this challenge, we introduce uaMix-MAE, an efficient ID tuning strategy that leverages unsupervised audio mixtures. Utilizing contrastive tuning, uaMix-MAE aligns the representations of pretrained MAEs, thereby facilitating effective adaptation to task-specific semantics. To optimize the model with small amounts of unlabeled data, we propose an audio mixing technique that manipulates audio samples in both input and virtual label spaces. Experiments in low/few-shot settings demonstrate that \\modelname achieves 4-6% accuracy improvements over various benchmarks when tuned with limited unlabeled data, such as AudioSet-20K. Code is available at https://github.com/PLAN-Lab/uamix-MAE","sentences":["Masked Autoencoders (MAEs) learn rich low-level representations from unlabeled data but require substantial labeled data to effectively adapt to downstream tasks.","Conversely, Instance Discrimination (ID) emphasizes high-level semantics, offering a potential solution to alleviate annotation requirements in MAEs.","Although combining these two approaches can address downstream tasks with limited labeled data, naively integrating ID into MAEs leads to extended training times and high computational costs.","To address this challenge, we introduce uaMix-MAE, an efficient ID tuning strategy that leverages unsupervised audio mixtures.","Utilizing contrastive tuning, uaMix-MAE aligns the representations of pretrained MAEs, thereby facilitating effective adaptation to task-specific semantics.","To optimize the model with small amounts of unlabeled data, we propose an audio mixing technique that manipulates audio samples in both input and virtual label spaces.","Experiments in low/few-shot settings demonstrate that \\modelname achieves 4-6% accuracy improvements over various benchmarks when tuned with limited unlabeled data, such as AudioSet-20K. Code is available at https://github.com/PLAN-Lab/uamix-MAE"],"url":"http://arxiv.org/abs/2403.09579v1","category":"cs.SD"}
{"created":"2024-03-14 17:51:54","title":"Reawakening knowledge: Anticipatory recovery from catastrophic interference via structured training","abstract":"We explore the training dynamics of neural networks in a structured non-IID setting where documents are presented cyclically in a fixed, repeated sequence. Typically, networks suffer from catastrophic interference when training on a sequence of documents; however, we discover a curious and remarkable property of LLMs fine-tuned sequentially in this setting: they exhibit anticipatory behavior, recovering from the forgetting on documents before encountering them again. The behavior emerges and becomes more robust as the architecture scales up its number of parameters. Through comprehensive experiments and visualizations, we uncover new insights into training over-parameterized networks in structured environments.","sentences":["We explore the training dynamics of neural networks in a structured non-IID setting where documents are presented cyclically in a fixed, repeated sequence.","Typically, networks suffer from catastrophic interference when training on a sequence of documents; however, we discover a curious and remarkable property of LLMs fine-tuned sequentially in this setting: they exhibit anticipatory behavior, recovering from the forgetting on documents before encountering them again.","The behavior emerges and becomes more robust as the architecture scales up its number of parameters.","Through comprehensive experiments and visualizations, we uncover new insights into training over-parameterized networks in structured environments."],"url":"http://arxiv.org/abs/2403.09613v1","category":"cs.LG"}
{"created":"2024-03-14 17:12:17","title":"Commutation principles for nonsmooth variational problems on Euclidean Jordan algebras","abstract":"The commutation principle proved by Ram\\'irez, Seeger, and Sossa (SIAM J Optim 23:687-694, 2013) in the setting of Euclidean Jordan algebras says that for a Fr\\'echet differentiable function $\\Theta$ and a spectral function $F$, any local minimizer or maximizer $a$ of $\\Theta+F$ over a spectral set $\\mathcal{E}$ operator commutes with the gradient of $\\Theta$ at $a$. In this paper, we improve this commutation principle by allowing $\\Theta$ to be nonsmooth with mild regularity assumptions over it. For example, for the case of local minimizer, we show that $a$ operator commutes with some element of the limiting (Mordukhovich) subdifferential of $\\Theta$ at $a$ provided that $\\Theta$ is subdifferentially regular at $a$ satisfying a qualification condition. For the case of local maximizer, we prove that $a$ operator commutes with each element of the (Fenchel) subdifferential of $\\Theta$ at $a$ whenever this subdifferential is nonempty. As an application, we characterize the local optimizers of shifted strictly convex spectral functions and norms over automorphism invariant sets.","sentences":["The commutation principle proved by Ram\\'irez, Seeger, and Sossa (SIAM J Optim 23:687-694, 2013) in the setting of Euclidean Jordan algebras says that for a Fr\\'echet differentiable function $\\Theta$ and a spectral function $F$, any local minimizer or maximizer $a$ of $\\Theta+F$ over a spectral set $\\mathcal{E}$ operator commutes with the gradient of $\\Theta$ at $a$. In this paper, we improve this commutation principle by allowing $\\Theta$ to be nonsmooth with mild regularity assumptions over it.","For example, for the case of local minimizer, we show that $a$ operator commutes with some element of the limiting (Mordukhovich) subdifferential of $\\Theta$ at $a$ provided that $\\Theta$ is subdifferentially regular at $a$ satisfying a qualification condition.","For the case of local maximizer, we prove that $a$ operator commutes with each element of the (Fenchel) subdifferential of $\\Theta$ at $a$ whenever this subdifferential is nonempty.","As an application, we characterize the local optimizers of shifted strictly convex spectral functions and norms over automorphism invariant sets."],"url":"http://arxiv.org/abs/2403.09578v1","category":"math.OC"}
{"created":"2024-03-14 16:55:04","title":"Comments on the quantitative uniqueness of continuation for evolution equations","abstract":"We establish near-optimal quantitative uniqueness of continuation for solutions of evolution equations vanishing on the lateral boundary. These results were obtained simply by combining existing observability inequalities and energy estimates.","sentences":["We establish near-optimal quantitative uniqueness of continuation for solutions of evolution equations vanishing on the lateral boundary.","These results were obtained simply by combining existing observability inequalities and energy estimates."],"url":"http://arxiv.org/abs/2403.09564v1","category":"math.AP"}
{"created":"2024-03-14 17:59:59","title":"GroupContrast: Semantic-aware Self-supervised Representation Learning for 3D Understanding","abstract":"Self-supervised 3D representation learning aims to learn effective representations from large-scale unlabeled point clouds. Most existing approaches adopt point discrimination as the pretext task, which assigns matched points in two distinct views as positive pairs and unmatched points as negative pairs. However, this approach often results in semantically identical points having dissimilar representations, leading to a high number of false negatives and introducing a \"semantic conflict\" problem. To address this issue, we propose GroupContrast, a novel approach that combines segment grouping and semantic-aware contrastive learning. Segment grouping partitions points into semantically meaningful regions, which enhances semantic coherence and provides semantic guidance for the subsequent contrastive representation learning. Semantic-aware contrastive learning augments the semantic information extracted from segment grouping and helps to alleviate the issue of \"semantic conflict\". We conducted extensive experiments on multiple 3D scene understanding tasks. The results demonstrate that GroupContrast learns semantically meaningful representations and achieves promising transfer learning performance.","sentences":["Self-supervised 3D representation learning aims to learn effective representations from large-scale unlabeled point clouds.","Most existing approaches adopt point discrimination as the pretext task, which assigns matched points in two distinct views as positive pairs and unmatched points as negative pairs.","However, this approach often results in semantically identical points having dissimilar representations, leading to a high number of false negatives and introducing a \"semantic conflict\" problem.","To address this issue, we propose GroupContrast, a novel approach that combines segment grouping and semantic-aware contrastive learning.","Segment grouping partitions points into semantically meaningful regions, which enhances semantic coherence and provides semantic guidance for the subsequent contrastive representation learning.","Semantic-aware contrastive learning augments the semantic information extracted from segment grouping and helps to alleviate the issue of \"semantic conflict\".","We conducted extensive experiments on multiple 3D scene understanding tasks.","The results demonstrate that GroupContrast learns semantically meaningful representations and achieves promising transfer learning performance."],"url":"http://arxiv.org/abs/2403.09639v1","category":"cs.CV"}
{"created":"2024-03-14 17:51:32","title":"MM1: Methods, Analysis & Insights from Multimodal LLM Pre-training","abstract":"In this work, we discuss building performant Multimodal Large Language Models (MLLMs). In particular, we study the importance of various architecture components and data choices. Through careful and comprehensive ablations of the image encoder, the vision language connector, and various pre-training data choices, we identified several crucial design lessons. For example, we demonstrate that for large-scale multimodal pre-training using a careful mix of image-caption, interleaved image-text, and text-only data is crucial for achieving state-of-the-art (SOTA) few-shot results across multiple benchmarks, compared to other published pre-training results. Further, we show that the image encoder together with image resolution and the image token count has substantial impact, while the vision-language connector design is of comparatively negligible importance. By scaling up the presented recipe, we build MM1, a family of multimodal models up to 30B parameters, consisting of both dense models and mixture-of-experts (MoE) variants, that are SOTA in pre-training metrics and achieve competitive performance after supervised fine-tuning on a range of established multimodal benchmarks. Thanks to large-scale pre-training, MM1 enjoys appealing properties such as enhanced in-context learning, and multi-image reasoning, enabling few-shot chain-of-thought prompting.","sentences":["In this work, we discuss building performant Multimodal Large Language Models (MLLMs).","In particular, we study the importance of various architecture components and data choices.","Through careful and comprehensive ablations of the image encoder, the vision language connector, and various pre-training data choices, we identified several crucial design lessons.","For example, we demonstrate that for large-scale multimodal pre-training using a careful mix of image-caption, interleaved image-text, and text-only data is crucial for achieving state-of-the-art (SOTA) few-shot results across multiple benchmarks, compared to other published pre-training results.","Further, we show that the image encoder together with image resolution and the image token count has substantial impact, while the vision-language connector design is of comparatively negligible importance.","By scaling up the presented recipe, we build MM1, a family of multimodal models up to 30B parameters, consisting of both dense models and mixture-of-experts (MoE) variants, that are SOTA in pre-training metrics and achieve competitive performance after supervised fine-tuning on a range of established multimodal benchmarks.","Thanks to large-scale pre-training, MM1 enjoys appealing properties such as enhanced in-context learning, and multi-image reasoning, enabling few-shot chain-of-thought prompting."],"url":"http://arxiv.org/abs/2403.09611v1","category":"cs.CV"}
{"created":"2024-03-14 17:50:51","title":"Signal Recovery with Proximal Comixtures","abstract":"In variational signal processing and machine learning problems, loss functions and linear operators are typically aggregated as an average of composite terms. We propose an alternative formulation using proximal comixtures, an operation that combines functions and linear operators in such a way that the proximity operator of the resulting function is computable explicitly. The benefits of comixture formulations are illustrated through image recovery and machine learning applications.","sentences":["In variational signal processing and machine learning problems, loss functions and linear operators are typically aggregated as an average of composite terms.","We propose an alternative formulation using proximal comixtures, an operation that combines functions and linear operators in such a way that the proximity operator of the resulting function is computable explicitly.","The benefits of comixture formulations are illustrated through image recovery and machine learning applications."],"url":"http://arxiv.org/abs/2403.09610v1","category":"math.OC"}
{"created":"2024-03-14 17:45:24","title":"Extremal graphical modeling with latent variables","abstract":"Extremal graphical models encode the conditional independence structure of multivariate extremes and provide a powerful tool for quantifying the risk of rare events. Prior work on learning these graphs from data has focused on the setting where all relevant variables are observed. For the popular class of H\\\"usler-Reiss models, we propose the \\texttt{eglatent} method, a tractable convex program for learning extremal graphical models in the presence of latent variables. Our approach decomposes the H\\\"usler-Reiss precision matrix into a sparse component encoding the graphical structure among the observed variables after conditioning on the latent variables, and a low-rank component encoding the effect of a few latent variables on the observed variables. We provide finite-sample guarantees of \\texttt{eglatent} and show that it consistently recovers the conditional graph as well as the number of latent variables. We highlight the improved performances of our approach on synthetic and real data.","sentences":["Extremal graphical models encode the conditional independence structure of multivariate extremes and provide a powerful tool for quantifying the risk of rare events.","Prior work on learning these graphs from data has focused on the setting where all relevant variables are observed.","For the popular class of H\\\"usler-Reiss models, we propose the \\texttt{eglatent} method, a tractable convex program for learning extremal graphical models in the presence of latent variables.","Our approach decomposes the H\\\"usler-Reiss precision matrix into a sparse component encoding the graphical structure among the observed variables after conditioning on the latent variables, and a low-rank component encoding the effect of a few latent variables on the observed variables.","We provide finite-sample guarantees of \\texttt{eglatent} and show that it consistently recovers the conditional graph as well as the number of latent variables.","We highlight the improved performances of our approach on synthetic and real data."],"url":"http://arxiv.org/abs/2403.09604v1","category":"stat.ME"}
{"created":"2024-03-14 17:39:14","title":"Mixture of Mixups for Multi-label Classification of Rare Anuran Sounds","abstract":"Multi-label imbalanced classification poses a significant challenge in machine learning, particularly evident in bioacoustics where animal sounds often co-occur, and certain sounds are much less frequent than others. This paper focuses on the specific case of classifying anuran species sounds using the dataset AnuraSet, that contains both class imbalance and multi-label examples. To address these challenges, we introduce Mixture of Mixups (Mix2), a framework that leverages mixing regularization methods Mixup, Manifold Mixup, and MultiMix. Experimental results show that these methods, individually, may lead to suboptimal results; however, when applied randomly, with one selected at each training iteration, they prove effective in addressing the mentioned challenges, particularly for rare classes with few occurrences. Further analysis reveals that Mix2 is also proficient in classifying sounds across various levels of class co-occurrences.","sentences":["Multi-label imbalanced classification poses a significant challenge in machine learning, particularly evident in bioacoustics where animal sounds often co-occur, and certain sounds are much less frequent than others.","This paper focuses on the specific case of classifying anuran species sounds using the dataset AnuraSet, that contains both class imbalance and multi-label examples.","To address these challenges, we introduce Mixture of Mixups (Mix2), a framework that leverages mixing regularization methods Mixup, Manifold Mixup, and MultiMix.","Experimental results show that these methods, individually, may lead to suboptimal results; however, when applied randomly, with one selected at each training iteration, they prove effective in addressing the mentioned challenges, particularly for rare classes with few occurrences.","Further analysis reveals that Mix2 is also proficient in classifying sounds across various levels of class co-occurrences."],"url":"http://arxiv.org/abs/2403.09598v1","category":"cs.SD"}
{"created":"2024-03-14 17:18:15","title":"ExploRLLM: Guiding Exploration in Reinforcement Learning with Large Language Models","abstract":"In image-based robot manipulation tasks with large observation and action spaces, reinforcement learning struggles with low sample efficiency, slow training speed, and uncertain convergence. As an alternative, large pre-trained foundation models have shown promise in robotic manipulation, particularly in zero-shot and few-shot applications. However, using these models directly is unreliable due to limited reasoning capabilities and challenges in understanding physical and spatial contexts. This paper introduces ExploRLLM, a novel approach that leverages the inductive bias of foundation models (e.g. Large Language Models) to guide exploration in reinforcement learning. We also exploit these foundation models to reformulate the action and observation spaces to enhance the training efficiency in reinforcement learning. Our experiments demonstrate that guided exploration enables much quicker convergence than training without it. Additionally, we validate that ExploRLLM outperforms vanilla foundation model baselines and that the policy trained in simulation can be applied in real-world settings without additional training.","sentences":["In image-based robot manipulation tasks with large observation and action spaces, reinforcement learning struggles with low sample efficiency, slow training speed, and uncertain convergence.","As an alternative, large pre-trained foundation models have shown promise in robotic manipulation, particularly in zero-shot and few-shot applications.","However, using these models directly is unreliable due to limited reasoning capabilities and challenges in understanding physical and spatial contexts.","This paper introduces ExploRLLM, a novel approach that leverages the inductive bias of foundation models (e.g. Large Language Models) to guide exploration in reinforcement learning.","We also exploit these foundation models to reformulate the action and observation spaces to enhance the training efficiency in reinforcement learning.","Our experiments demonstrate that guided exploration enables much quicker convergence than training without it.","Additionally, we validate that ExploRLLM outperforms vanilla foundation model baselines and that the policy trained in simulation can be applied in real-world settings without additional training."],"url":"http://arxiv.org/abs/2403.09583v1","category":"cs.RO"}
{"created":"2024-03-14 16:35:43","title":"Breast Cancer Classification Using Gradient Boosting Algorithms Focusing on Reducing the False Negative and SHAP for Explainability","abstract":"Cancer is one of the diseases that kill the most women in the world, with breast cancer being responsible for the highest number of cancer cases and consequently deaths. However, it can be prevented by early detection and, consequently, early treatment. Any development for detection or perdition this kind of cancer is important for a better healthy life. Many studies focus on a model with high accuracy in cancer prediction, but sometimes accuracy alone may not always be a reliable metric. This study implies an investigative approach to studying the performance of different machine learning algorithms based on boosting to predict breast cancer focusing on the recall metric. Boosting machine learning algorithms has been proven to be an effective tool for detecting medical diseases. The dataset of the University of California, Irvine (UCI) repository has been utilized to train and test the model classifier that contains their attributes. The main objective of this study is to use state-of-the-art boosting algorithms such as AdaBoost, XGBoost, CatBoost and LightGBM to predict and diagnose breast cancer and to find the most effective metric regarding recall, ROC-AUC, and confusion matrix. Furthermore, our study is the first to use these four boosting algorithms with Optuna, a library for hyperparameter optimization, and the SHAP method to improve the interpretability of our model, which can be used as a support to identify and predict breast cancer. We were able to improve AUC or recall for all the models and reduce the False Negative for AdaBoost and LigthGBM the final AUC were more than 99.41\\% for all models.","sentences":["Cancer is one of the diseases that kill the most women in the world, with breast cancer being responsible for the highest number of cancer cases and consequently deaths.","However, it can be prevented by early detection and, consequently, early treatment.","Any development for detection or perdition this kind of cancer is important for a better healthy life.","Many studies focus on a model with high accuracy in cancer prediction, but sometimes accuracy alone may not always be a reliable metric.","This study implies an investigative approach to studying the performance of different machine learning algorithms based on boosting to predict breast cancer focusing on the recall metric.","Boosting machine learning algorithms has been proven to be an effective tool for detecting medical diseases.","The dataset of the University of California, Irvine (UCI) repository has been utilized to train and test the model classifier that contains their attributes.","The main objective of this study is to use state-of-the-art boosting algorithms such as AdaBoost, XGBoost, CatBoost and LightGBM to predict and diagnose breast cancer and to find the most effective metric regarding recall, ROC-AUC, and confusion matrix.","Furthermore, our study is the first to use these four boosting algorithms with Optuna, a library for hyperparameter optimization, and the SHAP method to improve the interpretability of our model, which can be used as a support to identify and predict breast cancer.","We were able to improve AUC or recall for all the models and reduce the False Negative for AdaBoost and LigthGBM the final AUC were more than 99.41\\% for all models."],"url":"http://arxiv.org/abs/2403.09548v1","category":"cs.LG"}
{"created":"2024-03-14 16:35:39","title":"How do Machine Learning Projects use Continuous Integration Practices? An Empirical Study on GitHub Actions","abstract":"Continuous Integration (CI) is a well-established practice in traditional software development, but its nuances in the domain of Machine Learning (ML) projects remain relatively unexplored. Given the distinctive nature of ML development, understanding how CI practices are adopted in this context is crucial for tailoring effective approaches. In this study, we conduct a comprehensive analysis of 185 open-source projects on GitHub (93 ML and 92 non-ML projects). Our investigation comprises both quantitative and qualitative dimensions, aiming to uncover differences in CI adoption between ML and non-ML projects. Our findings indicate that ML projects often require longer build durations, and medium-sized ML projects exhibit lower test coverage compared to non-ML projects. Moreover, small and medium-sized ML projects show a higher prevalence of increasing build duration trends compared to their non-ML counterparts. Additionally, our qualitative analysis illuminates the discussions around CI in both ML and non-ML projects, encompassing themes like CI Build Execution and Status, CI Testing, and CI Infrastructure. These insights shed light on the unique challenges faced by ML projects in adopting CI practices effectively.","sentences":["Continuous Integration (CI) is a well-established practice in traditional software development, but its nuances in the domain of Machine Learning (ML) projects remain relatively unexplored.","Given the distinctive nature of ML development, understanding how CI practices are adopted in this context is crucial for tailoring effective approaches.","In this study, we conduct a comprehensive analysis of 185 open-source projects on GitHub (93 ML and 92 non-ML projects).","Our investigation comprises both quantitative and qualitative dimensions, aiming to uncover differences in CI adoption between ML and non-ML projects.","Our findings indicate that ML projects often require longer build durations, and medium-sized ML projects exhibit lower test coverage compared to non-ML projects.","Moreover, small and medium-sized ML projects show a higher prevalence of increasing build duration trends compared to their non-ML counterparts.","Additionally, our qualitative analysis illuminates the discussions around CI in both ML and non-ML projects, encompassing themes like CI Build Execution and Status, CI Testing, and CI Infrastructure.","These insights shed light on the unique challenges faced by ML projects in adopting CI practices effectively."],"url":"http://arxiv.org/abs/2403.09547v1","category":"cs.SE"}
{"created":"2024-03-14 16:30:52","title":"Explorations in Texture Learning","abstract":"In this work, we investigate \\textit{texture learning}: the identification of textures learned by object classification models, and the extent to which they rely on these textures. We build texture-object associations that uncover new insights about the relationships between texture and object classes in CNNs and find three classes of results: associations that are strong and expected, strong and not expected, and expected but not present. Our analysis demonstrates that investigations in texture learning enable new methods for interpretability and have the potential to uncover unexpected biases.","sentences":["In this work, we investigate \\textit{texture learning}: the identification of textures learned by object classification models, and the extent to which they rely on these textures.","We build texture-object associations that uncover new insights about the relationships between texture and object classes in CNNs and find three classes of results: associations that are strong and expected, strong and not expected, and expected but not present.","Our analysis demonstrates that investigations in texture learning enable new methods for interpretability and have the potential to uncover unexpected biases."],"url":"http://arxiv.org/abs/2403.09543v1","category":"cs.CV"}
{"created":"2024-03-14 17:54:21","title":"Dynamically accelerating the power iteration with momentum","abstract":"In this paper, we propose, analyze and demonstrate a dynamic momentum method to accelerate power and inverse power iterations with minimal computational overhead. The method is appropriate for real, diagonalizable matrices, and does not require a priori spectral knowledge. We review and extend background results on previously developed static momentum accelerations for the power iteration through the connection between the momentum accelerated iteration and the standard power iteration applied to an augmented matrix. We show that the augmented matrix is defective for the optimal parameter choice. We then present our dynamic method which updates the momentum parameter at each iteration based on the Rayleigh quotient and two previous residuals. We present convergence and stability theory for the method by considering a power-like method consisting of multiplying an initial vector by a sequence of augmented matrices. We demonstrate the developed method on a number of benchmark problems, and see that it outperforms both the power iteration and often the static momentum acceleration with optimal parameter choice. Finally, we present and demonstrate an explicit extension of the algorithm to inverse power iterations.","sentences":["In this paper, we propose, analyze and demonstrate a dynamic momentum method to accelerate power and inverse power iterations with minimal computational overhead.","The method is appropriate for real, diagonalizable matrices, and does not require a priori spectral knowledge.","We review and extend background results on previously developed static momentum accelerations for the power iteration through the connection between the momentum accelerated iteration and the standard power iteration applied to an augmented matrix.","We show that the augmented matrix is defective for the optimal parameter choice.","We then present our dynamic method which updates the momentum parameter at each iteration based on the Rayleigh quotient and two previous residuals.","We present convergence and stability theory for the method by considering a power-like method consisting of multiplying an initial vector by a sequence of augmented matrices.","We demonstrate the developed method on a number of benchmark problems, and see that it outperforms both the power iteration and often the static momentum acceleration with optimal parameter choice.","Finally, we present and demonstrate an explicit extension of the algorithm to inverse power iterations."],"url":"http://arxiv.org/abs/2403.09618v1","category":"math.NA"}
{"created":"2024-03-14 17:57:40","title":"On spontaneous breaking of the $\\text{SO}(2N)$ symmetry in the Gross-Neveu model","abstract":"The canonical Gross-Neveu model for $N$ two-component Dirac fermions in $2+1$ dimensions suffers a continuous phase transition at a critical interaction $g_{c1} \\sim 1/N$ at large $N$, at which its continuous symmetry $\\text{SO}(2N)$ is preserved and a discrete (Ising) symmetry becomes spontaneously broken. A recent mean-field calculation, however, points to an additional transition at a diffferent critical $g_{c2}\\sim -N g_{c1}$, at which $\\text{SO}(2N) \\rightarrow \\text{SO}(N) \\times \\text{SO}(N)$. To study the latter phase transition we rewrite the Gross-Neveu interaction $g (\\bar{\\psi} \\psi)^2$ in terms of three different quartic terms for the single ($L=1$) $4N$-component real (Majorana) fermion, and then extend the theory to $L>1$. This allows us to track the evolution of the fixed points of the renormalization group transformation starting from $L\\gg 1$, where one can discern three distinct critical points which correspond to continuous phase transitions into (1) $\\text{SO}(2N)$-singlet mass-order-parameter, (2) $\\text{SO}(2N)$-symmetric-tensor mass-order-parameters, and (3) $\\text{SO}(2N)$-adjoint nematic-order-parameters, down to $L=1$ value that is relevant to standard Gross-Neveu model. Below the critical value of $L_c (N)\\approx 0.35 N$ for $N\\gg1$ only the Gross-Neveu critical point (1) still implies a diverging susceptibility for its corresponding ($\\text{SO}(2N)$-singlet) order parameter, whereas the two new critical points that existed at large $L$ ultimately become equivalent to the Gaussian fixed point at $L=1$. We interpret this metamorphosis of the $\\text{SO}(2N)$-symmetric-tensor fixed point from critical to spurious as an indication that the transition at $g_{c2}$ in the original Gross-Neveu model is turned first-order by fluctuations.","sentences":["The canonical Gross-Neveu model for $N$ two-component Dirac fermions in $2+1$ dimensions suffers a continuous phase transition at a critical interaction $g_{c1} \\sim 1/N$ at large $N$, at which its continuous symmetry $\\text{SO}(2N)$ is preserved and a discrete (Ising) symmetry becomes spontaneously broken.","A recent mean-field calculation, however, points to an additional transition at a diffferent critical $g_{c2}\\sim -N g_{c1}$, at which $\\text{SO}(2N) \\rightarrow \\text{SO}(N) \\times \\text{SO}(N)$. To study the latter phase transition we rewrite the Gross-Neveu interaction $g (\\bar{\\psi} \\psi)^2$ in terms of three different quartic terms for the single ($L=1$) $4N$-component real (Majorana) fermion, and then extend the theory to $L>1$.","This allows us to track the evolution of the fixed points of the renormalization group transformation starting from $L\\gg 1$, where one can discern three distinct critical points which correspond to continuous phase transitions into (1) $\\text{SO}(2N)$-singlet mass-order-parameter, (2) $\\text{SO}(2N)$-symmetric-tensor mass-order-parameters, and (3) $\\text{SO}(2N)$-adjoint nematic-order-parameters, down to $L=1$ value that is relevant to standard Gross-Neveu model.","Below the critical value of $L_c (N)\\approx 0.35 N$ for $N\\gg1$ only the Gross-Neveu critical point (1) still implies a diverging susceptibility for its corresponding ($\\text{SO}(2N)$-singlet) order parameter, whereas the two new critical points that existed at large $L$ ultimately become equivalent to the Gaussian fixed point at $L=1$. We interpret this metamorphosis of the $\\text{SO}(2N)$-symmetric-tensor fixed point from critical to spurious as an indication that the transition at $g_{c2}$ in the original Gross-Neveu model is turned first-order by fluctuations."],"url":"http://arxiv.org/abs/2403.09627v1","category":"hep-th"}
{"created":"2024-03-14 17:42:03","title":"Tree-Level Superstring Amplitudes: The Neveu-Schwarz Sector","abstract":"We present a complete computation of superstring scattering amplitudes at tree level, for the case of Neveu-Schwarz insertions. Mathematically, this is to say that we determine explicitly the superstring measure on the moduli space $\\mathcal{M}_{0,n,0}$ of super Riemann surfaces of genus zero with $n \\ge 3$ Neveu-Schwarz punctures. While, of course, an expression for the measure was previously known, we do this from first principles, using the canonically defined super Mumford isomorphism. We thus determine the scattering amplitudes, explicitly in the global coordinates on $\\mathcal{M}_{0,n,0}$, without the need for picture changing operators or ghosts, and are also able to determine canonically the value of the coupling constant. Our computation should be viewed as a step towards performing similar analysis on $\\mathcal{M}_{0,0,n}$, to derive explicit tree-level scattering amplitudes with Ramond insertions.","sentences":["We present a complete computation of superstring scattering amplitudes at tree level, for the case of Neveu-Schwarz insertions.","Mathematically, this is to say that we determine explicitly the superstring measure on the moduli space $\\mathcal{M}_{0,n,0}$ of super Riemann surfaces of genus zero with $n \\ge 3$ Neveu-Schwarz punctures.","While, of course, an expression for the measure was previously known, we do this from first principles, using the canonically defined super Mumford isomorphism.","We thus determine the scattering amplitudes, explicitly in the global coordinates on $\\mathcal{M}_{0,n,0}$, without the need for picture changing operators or ghosts, and are also able to determine canonically the value of the coupling constant.","Our computation should be viewed as a step towards performing similar analysis on $\\mathcal{M}_{0,0,n}$, to derive explicit tree-level scattering amplitudes with Ramond insertions."],"url":"http://arxiv.org/abs/2403.09600v1","category":"hep-th"}
{"created":"2024-03-14 17:35:48","title":"The Size-Linewidth Relation and Signatures of Feedback from Quiescent to Active Star Forming Regions in the LMC","abstract":"To investigate the effects of stellar feedback on the gravitational state of giant molecular clouds (GMCs), we study $^{12}$CO and $^{13}$CO ALMA maps of nine GMCs distributed throughout the Large Magellanic Cloud (LMC), the nearest star-forming galaxy to our own. We perform noise and resolution matching on the sample, working at a common resolution of 3.5 arcseconds (0.85 pc at the LMC distance of 50 kpc), and use the \\textit{SCIMES} clustering algorithm to identify discrete substructure, or \"clumps.\" We supplement these data with three tracers of recent star formation: $8\\mu$m surface brightness, continuum-subtracted H$\\alpha$ flux, and interstellar radiation field energy density inferred from dust emission. The $^{12}$CO clumps identified cover a range of 3.6 dex in luminosity-based mass and 2.4 dex in average $8\\mu$m surface brightness, representative of the wide range of conditions of the interstellar medium in the LMC. Our observations suggest evidence for increased turbulence in these clouds. While the turbulent linewidths are correlated with clump surface density, in agreement with previous observations, we find even better correlation with the three star formation activity tracers considered, suggesting stellar energy injection plays a significant role in the dynamical state of the clumps. The excess linewidths we measure do not appear to result from opacity broadening. $^{12}$CO clumps are found to be typically less gravitationally bound than $^{13}$CO clumps, with some evidence of the kinetic-to-gravitational potential energy ratio increasing with star-formation tracers. Further multi-line analysis may better constrain the assumptions made in these calculations.","sentences":["To investigate the effects of stellar feedback on the gravitational state of giant molecular clouds (GMCs), we study $^{12}$CO and $^{13}$CO ALMA maps of nine GMCs distributed throughout the Large Magellanic Cloud (LMC), the nearest star-forming galaxy to our own.","We perform noise and resolution matching on the sample, working at a common resolution of 3.5 arcseconds (0.85 pc at the LMC distance of 50 kpc), and use the \\textit{SCIMES} clustering algorithm to identify discrete substructure, or \"clumps.\"","We supplement these data with three tracers of recent star formation: $8\\mu$m surface brightness, continuum-subtracted H$\\alpha$ flux, and interstellar radiation field energy density inferred from dust emission.","The $^{12}$CO clumps identified cover a range of 3.6 dex in luminosity-based mass and 2.4 dex in average $8\\mu$m surface brightness, representative of the wide range of conditions of the interstellar medium in the LMC.","Our observations suggest evidence for increased turbulence in these clouds.","While the turbulent linewidths are correlated with clump surface density, in agreement with previous observations, we find even better correlation with the three star formation activity tracers considered, suggesting stellar energy injection plays a significant role in the dynamical state of the clumps.","The excess linewidths we measure do not appear to result from opacity broadening.","$^{12}$CO clumps are found to be typically less gravitationally bound than $^{13}$CO clumps, with some evidence of the kinetic-to-gravitational potential energy ratio increasing with star-formation tracers.","Further multi-line analysis may better constrain the assumptions made in these calculations."],"url":"http://arxiv.org/abs/2403.09594v1","category":"astro-ph.GA"}
{"created":"2024-03-14 17:33:32","title":"The effect of spatially-varying collision frequency on the development of the Rayleigh-Taylor instability","abstract":"The Rayleigh-Taylor (RT) instability is ubiquitously observed, yet has traditionally been studied using ideal fluid models. Collisionality can vary strongly across the fluid interface, and previous work demonstrates the necessity of kinetic models to completely capture dynamics in certain collisional regimes. Where previous kinetic simulations used spatially- and temporally-constant collision frequency, this work presents 5-dimensional (two spatial, three velocity dimensions) continuum-kinetic simulations of the RT instability using a more realistic spatially-varying collision frequency. Three cases of collisional variation are explored for two Atwood numbers: low to intermediate, intermediate to high, and low to high. The low to intermediate case exhibits no RT instability growth, while the intermediate to high case is similar to a fluid limit kinetic case with interface widening biased towards the lower collisionality region. A novel contribution of this work is the low to high collisionality case that shows significantly altered instability growth through upward movement of the interface and damped spike growth due to increased free-streaming particle diffusion in the lower region. Contributions to the energy-flux from the non-Maxwellian portions of the distribution function are not accessible to fluid models and are greatest in magnitude in the spike and regions of low collisionality. Increasing the Atwood number results in greater RT instability growth and reduced upward interface movement. Deviation of the distribution function from Maxwellian is inversely proportional to collision frequency and concentrated around the fluid interface. The linear phase of RT instability growth is well-described by theoretical linear growth rates accounting for viscosity and diffusion.","sentences":["The Rayleigh-Taylor (RT) instability is ubiquitously observed, yet has traditionally been studied using ideal fluid models.","Collisionality can vary strongly across the fluid interface, and previous work demonstrates the necessity of kinetic models to completely capture dynamics in certain collisional regimes.","Where previous kinetic simulations used spatially- and temporally-constant collision frequency, this work presents 5-dimensional (two spatial, three velocity dimensions) continuum-kinetic simulations of the RT instability using a more realistic spatially-varying collision frequency.","Three cases of collisional variation are explored for two Atwood numbers: low to intermediate, intermediate to high, and low to high.","The low to intermediate case exhibits no RT instability growth, while the intermediate to high case is similar to a fluid limit kinetic case with interface widening biased towards the lower collisionality region.","A novel contribution of this work is the low to high collisionality case that shows significantly altered instability growth through upward movement of the interface and damped spike growth due to increased free-streaming particle diffusion in the lower region.","Contributions to the energy-flux from the non-Maxwellian portions of the distribution function are not accessible to fluid models and are greatest in magnitude in the spike and regions of low collisionality.","Increasing the Atwood number results in greater RT instability growth and reduced upward interface movement.","Deviation of the distribution function from Maxwellian is inversely proportional to collision frequency and concentrated around the fluid interface.","The linear phase of RT instability growth is well-described by theoretical linear growth rates accounting for viscosity and diffusion."],"url":"http://arxiv.org/abs/2403.09591v1","category":"physics.flu-dyn"}
{"created":"2024-03-14 16:54:58","title":"A perturbative approach to the non-relativistic string spectrum","abstract":"In this letter we use a perturbative approach to find the spectrum of non-relativistic strings in the String Newton-Cartan (SNC) AdS$_5\\times$S$^5$ spacetime. We perturb the bosonic sector of the action around a BMN-like folded string solution in light-cone gauge. We find strong evidence that the theory is described by a combination of massive and massless free fields in an anti-de Sitter background by showing that interaction terms up to six scalars vanish after field redefinitions.","sentences":["In this letter we use a perturbative approach to find the spectrum of non-relativistic strings in the String Newton-Cartan (SNC) AdS$_5\\times$S$^5$ spacetime.","We perturb the bosonic sector of the action around a BMN-like folded string solution in light-cone gauge.","We find strong evidence that the theory is described by a combination of massive and massless free fields in an anti-de Sitter background by showing that interaction terms up to six scalars vanish after field redefinitions."],"url":"http://arxiv.org/abs/2403.09563v1","category":"hep-th"}
{"created":"2024-03-14 16:44:35","title":"Cosmologically Consistent Analysis of Gravitational Waves from hidden sectors","abstract":"Production of gravitational waves in the early universe is discussed in a cosmologically consistent analysis within a first order phase transition involving a hidden sector feebly coupled with the visible sector. Each sector resides in its own heat bath leading to a potential dependent on two temperatures, and on two fields: one a standard model Higgs and the other a scalar arising from a hidden sector $U(1)$ gauge theory. A synchronous evolution of the hidden and visible sector temperatures is carried out from the reheat temperature down to the electroweak scale.The hydrodynamics of two-field phase transitions, one for the visible and the other for the hidden is discussed, which leads to separate tunneling temperatures, and different sound speeds for the two sectors. Gravitational waves emerging from the two sectors are computed and their imprint on the measured gravitational wave power spectrum vs frequency is analyzed in terms of bubble nucleation signature, i.e., detonation, deflagration, and hybrid. It is shown that the two-field model predicts gravitational waves accessible at several proposed gravitational wave detectors: LISA, DECIGO, BBO, Taiji and their discovery would probe specific regions of the hidden sector parameter space and may also shed light on the nature of bubble nucleation in the early universe. The analysis presented here indicates that the cosmologically preferred models are those where the tunneling in the visible sector precedes the tunneling in the hidden sector and the sound speed $c_s$ lies below its maximum, i.e., $c^2_s<\\frac{1}{3}$. It is of interest to investigate if these features are universal and applicable to a wider class of cosmologically consistent models.","sentences":["Production of gravitational waves in the early universe is discussed in a cosmologically consistent analysis within a first order phase transition involving a hidden sector feebly coupled with the visible sector.","Each sector resides in its own heat bath leading to a potential dependent on two temperatures, and on two fields: one a standard model Higgs and the other a scalar arising from a hidden sector $U(1)$ gauge theory.","A synchronous evolution of the hidden and visible sector temperatures is carried out from the reheat temperature down to the electroweak scale.","The hydrodynamics of two-field phase transitions, one for the visible and the other for the hidden is discussed, which leads to separate tunneling temperatures, and different sound speeds for the two sectors.","Gravitational waves emerging from the two sectors are computed and their imprint on the measured gravitational wave power spectrum vs frequency is analyzed in terms of bubble nucleation signature, i.e., detonation, deflagration, and hybrid.","It is shown that the two-field model predicts gravitational waves accessible at several proposed gravitational wave detectors: LISA, DECIGO, BBO, Taiji and their discovery would probe specific regions of the hidden sector parameter space and may also shed light on the nature of bubble nucleation in the early universe.","The analysis presented here indicates that the cosmologically preferred models are those where the tunneling in the visible sector precedes the tunneling in the hidden sector and the sound speed $c_s$ lies below its maximum, i.e., $c^2_s<\\frac{1}{3}$. It is of interest to investigate if these features are universal and applicable to a wider class of cosmologically consistent models."],"url":"http://arxiv.org/abs/2403.09558v1","category":"hep-ph"}
{"created":"2024-03-14 16:27:21","title":"Supermassive Black Hole Winds in X-rays -- SUBWAYS. III. A population study on Ultra-Fast Outflows","abstract":"The detection of blue-shifted absorption lines likely associated with ionized Iron K-shell transitions in the X-ray spectra of many Active Galactic Nuclei (AGN) suggests the presence of a highly ionized gas outflowing with mildly relativistic velocities (0.03c-0.6c), named Ultra-Fast Outflow (UFO). Within the SUBWAYS project we characterized these winds starting from a sample of 22 radio-quiet quasars at 0.1 < z < 0.4, and compared the results with similar studies in the literature on samples of 42 local radio-quiet Seyfert galaxies and 14 high redshift radio-quiet quasars. The scope of our work is a statistical study of UFO parameters and incidence, considering key physical properties of the sources, e.g. supermassive black hole (SMBH) mass, bolometric luminosity, accretion rates and Spectral Energy Distribution, with the aim of gaining new insights into the UFO launching mechanisms. We find indications that highly luminous AGN with steeper X-ray/UV ratio, are more likely to host UFO. The presence of UFO is not significantly related to any other AGN property in our sample. These findings suggest that the UFO phenomenon may be transient. Focusing on AGN with UFO, other important results are: (1) faster UFO have larger ionization parameters and column densities; (2) X-ray radiation plays a more crucial role in driving highly ionized winds compared to UV; (3) the correlation between outflow velocity and luminosity is significantly flatter than what expected for radiatively driven winds; (4) more massive BH experience higher wind mass-losses, suppressing accretion of matter onto the BH; (5) the UFO launching radius is positively correlated with the Eddington ratio. Furthermore, our analysis suggest the involvement of multiple launching mechanisms, including radiation pressure and magneto-hydrodynamic processes, rather than pointing to a single, universally applicable mechanism.","sentences":["The detection of blue-shifted absorption lines likely associated with ionized Iron K-shell transitions in the X-ray spectra of many Active Galactic Nuclei (AGN) suggests the presence of a highly ionized gas outflowing with mildly relativistic velocities (0.03c-0.6c), named Ultra-Fast Outflow (UFO).","Within the SUBWAYS project we characterized these winds starting from a sample of 22 radio-quiet quasars at 0.1 < z < 0.4, and compared the results with similar studies in the literature on samples of 42 local radio-quiet Seyfert galaxies and 14 high redshift radio-quiet quasars.","The scope of our work is a statistical study of UFO parameters and incidence, considering key physical properties of the sources, e.g. supermassive black hole (SMBH) mass, bolometric luminosity, accretion rates and Spectral Energy Distribution, with the aim of gaining new insights into the UFO launching mechanisms.","We find indications that highly luminous AGN with steeper X-ray/UV ratio, are more likely to host UFO.","The presence of UFO is not significantly related to any other AGN property in our sample.","These findings suggest that the UFO phenomenon may be transient.","Focusing on AGN with UFO, other important results are: (1) faster UFO have larger ionization parameters and column densities; (2) X-ray radiation plays a more crucial role in driving highly ionized winds compared to UV; (3) the correlation between outflow velocity and luminosity is significantly flatter than what expected for radiatively driven winds; (4) more massive BH experience higher wind mass-losses, suppressing accretion of matter onto the BH; (5) the UFO launching radius is positively correlated with the Eddington ratio.","Furthermore, our analysis suggest the involvement of multiple launching mechanisms, including radiation pressure and magneto-hydrodynamic processes, rather than pointing to a single, universally applicable mechanism."],"url":"http://arxiv.org/abs/2403.09538v1","category":"astro-ph.GA"}
{"created":"2024-03-14 16:21:42","title":"The affine Artin group of type $\\widetilde B_n$ is virtually poly-free","abstract":"In this note we prove that the affine Artin group of type $\\widetilde B_n$ is virtually poly-free. The proof also gives another solution of the $K(\\pi, 1)$ problem for $\\widetilde B_n$.","sentences":["In this note we prove that the affine Artin group of type $\\widetilde B_n$ is virtually poly-free.","The proof also gives another solution of the $K(\\pi, 1)$ problem for $\\widetilde B_n$."],"url":"http://arxiv.org/abs/2403.09533v1","category":"math.GR"}
