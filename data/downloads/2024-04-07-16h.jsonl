{"created":"2024-04-04 17:59:59","title":"Know Your Neighbors: Improving Single-View Reconstruction via Spatial Vision-Language Reasoning","abstract":"Recovering the 3D scene geometry from a single view is a fundamental yet ill-posed problem in computer vision. While classical depth estimation methods infer only a 2.5D scene representation limited to the image plane, recent approaches based on radiance fields reconstruct a full 3D representation. However, these methods still struggle with occluded regions since inferring geometry without visual observation requires (i) semantic knowledge of the surroundings, and (ii) reasoning about spatial context. We propose KYN, a novel method for single-view scene reconstruction that reasons about semantic and spatial context to predict each point's density. We introduce a vision-language modulation module to enrich point features with fine-grained semantic information. We aggregate point representations across the scene through a language-guided spatial attention mechanism to yield per-point density predictions aware of the 3D semantic context. We show that KYN improves 3D shape recovery compared to predicting density for each 3D point in isolation. We achieve state-of-the-art results in scene and object reconstruction on KITTI-360, and show improved zero-shot generalization compared to prior work. Project page: https://ruili3.github.io/kyn.","sentences":["Recovering the 3D scene geometry from a single view is a fundamental yet ill-posed problem in computer vision.","While classical depth estimation methods infer only a 2.5D scene representation limited to the image plane, recent approaches based on radiance fields reconstruct a full 3D representation.","However, these methods still struggle with occluded regions since inferring geometry without visual observation requires (i) semantic knowledge of the surroundings, and (ii) reasoning about spatial context.","We propose KYN, a novel method for single-view scene reconstruction that reasons about semantic and spatial context to predict each point's density.","We introduce a vision-language modulation module to enrich point features with fine-grained semantic information.","We aggregate point representations across the scene through a language-guided spatial attention mechanism to yield per-point density predictions aware of the 3D semantic context.","We show that KYN improves 3D shape recovery compared to predicting density for each 3D point in isolation.","We achieve state-of-the-art results in scene and object reconstruction on KITTI-360, and show improved zero-shot generalization compared to prior work.","Project page: https://ruili3.github.io/kyn."],"url":"http://arxiv.org/abs/2404.03658v1","category":"cs.CV"}
{"created":"2024-04-04 17:59:58","title":"OW-VISCap: Open-World Video Instance Segmentation and Captioning","abstract":"Open-world video instance segmentation is an important video understanding task. Yet most methods either operate in a closed-world setting, require an additional user-input, or use classic region-based proposals to identify never before seen objects. Further, these methods only assign a one-word label to detected objects, and don't generate rich object-centric descriptions. They also often suffer from highly overlapping predictions. To address these issues, we propose Open-World Video Instance Segmentation and Captioning (OW-VISCap), an approach to jointly segment, track, and caption previously seen or unseen objects in a video. For this, we introduce open-world object queries to discover never before seen objects without additional user-input. We generate rich and descriptive object-centric captions for each detected object via a masked attention augmented LLM input. We introduce an inter-query contrastive loss to ensure that the object queries differ from one another. Our generalized approach matches or surpasses state-of-the-art on three tasks: open-world video instance segmentation on the BURST dataset, dense video object captioning on the VidSTG dataset, and closed-world video instance segmentation on the OVIS dataset.","sentences":["Open-world video instance segmentation is an important video understanding task.","Yet most methods either operate in a closed-world setting, require an additional user-input, or use classic region-based proposals to identify never before seen objects.","Further, these methods only assign a one-word label to detected objects, and don't generate rich object-centric descriptions.","They also often suffer from highly overlapping predictions.","To address these issues, we propose Open-World Video Instance Segmentation and Captioning (OW-VISCap), an approach to jointly segment, track, and caption previously seen or unseen objects in a video.","For this, we introduce open-world object queries to discover never before seen objects without additional user-input.","We generate rich and descriptive object-centric captions for each detected object via a masked attention augmented LLM input.","We introduce an inter-query contrastive loss to ensure that the object queries differ from one another.","Our generalized approach matches or surpasses state-of-the-art on three tasks: open-world video instance segmentation on the BURST dataset, dense video object captioning on the VidSTG dataset, and closed-world video instance segmentation on the OVIS dataset."],"url":"http://arxiv.org/abs/2404.03657v1","category":"cs.CV"}
{"created":"2024-04-04 17:59:57","title":"MVD-Fusion: Single-view 3D via Depth-consistent Multi-view Generation","abstract":"We present MVD-Fusion: a method for single-view 3D inference via generative modeling of multi-view-consistent RGB-D images. While recent methods pursuing 3D inference advocate learning novel-view generative models, these generations are not 3D-consistent and require a distillation process to generate a 3D output. We instead cast the task of 3D inference as directly generating mutually-consistent multiple views and build on the insight that additionally inferring depth can provide a mechanism for enforcing this consistency. Specifically, we train a denoising diffusion model to generate multi-view RGB-D images given a single RGB input image and leverage the (intermediate noisy) depth estimates to obtain reprojection-based conditioning to maintain multi-view consistency. We train our model using large-scale synthetic dataset Obajverse as well as the real-world CO3D dataset comprising of generic camera viewpoints. We demonstrate that our approach can yield more accurate synthesis compared to recent state-of-the-art, including distillation-based 3D inference and prior multi-view generation methods. We also evaluate the geometry induced by our multi-view depth prediction and find that it yields a more accurate representation than other direct 3D inference approaches.","sentences":["We present MVD-Fusion: a method for single-view 3D inference via generative modeling of multi-view-consistent RGB-D images.","While recent methods pursuing 3D inference advocate learning novel-view generative models, these generations are not 3D-consistent and require a distillation process to generate a 3D output.","We instead cast the task of 3D inference as directly generating mutually-consistent multiple views and build on the insight that additionally inferring depth can provide a mechanism for enforcing this consistency.","Specifically, we train a denoising diffusion model to generate multi-view RGB-D images given a single RGB input image and leverage the (intermediate noisy) depth estimates to obtain reprojection-based conditioning to maintain multi-view consistency.","We train our model using large-scale synthetic dataset Obajverse as well as the real-world CO3D dataset comprising of generic camera viewpoints.","We demonstrate that our approach can yield more accurate synthesis compared to recent state-of-the-art, including distillation-based 3D inference and prior multi-view generation methods.","We also evaluate the geometry induced by our multi-view depth prediction and find that it yields a more accurate representation than other direct 3D inference approaches."],"url":"http://arxiv.org/abs/2404.03656v1","category":"cs.CV"}
{"created":"2024-04-04 17:59:52","title":"Magnetic fields from small-scale primordial perturbations","abstract":"Weak magnetic fields must have existed in the early Universe, as they were sourced by the cross product of electron density and temperature gradients through the Biermann-battery mechanism. In this paper we calculate the magnetic fields generated at cosmic dawn by a variety of small-scale primordial perturbations, carefully computing the evolution of electron density and temperature fluctuations, and consistently accounting for relative velocities between baryons and dark matter. We first compute the magnetic field resulting from standard, nearly scale-invariant primordial adiabatic perturbations, making significant improvements to previous calculations. This \"standard\" primordial field has a root mean square (rms) of $\\sim10^{-15}$ nG at $20\\lesssim z \\lesssim 100$, with fluctuations on $\\sim$ kpc comoving scales, and could serve as the seed of present-day magnetic fields observed in galaxies and galaxy clusters. In addition, we consider early-Universe magnetic fields as a possible probe of non-standard initial conditions of the Universe on small scales $k \\sim 1-10^3$ Mpc$^{-1}$. To this end, we compute the maximally-allowed magnetic fields within current upper limits on small-scale adiabatic and isocurvature perturbations. Under the current Cosmic Microwave Background spectral-distortion constraints magnetic fields could be produced with a rms of $\\sim 5\\times 10^{-11}$ nG at $z = 20$. Uncorrelated small-scale isocurvature perturbations within current Big-Bang Nucleosynthesis bounds could potentially enhance the magnetic field to $\\sim 10^{-14}-10^{-10}$ nG at $z = 20$, depending on the specific isocurvature mode considered. While these very weak fields remain well below current observational capabilities, our work points out that magnetic fields could potentially provide an interesting window into the poorly constrained small-scale initial conditions of the Universe.","sentences":["Weak magnetic fields must have existed in the early Universe, as they were sourced by the cross product of electron density and temperature gradients through the Biermann-battery mechanism.","In this paper we calculate the magnetic fields generated at cosmic dawn by a variety of small-scale primordial perturbations, carefully computing the evolution of electron density and temperature fluctuations, and consistently accounting for relative velocities between baryons and dark matter.","We first compute the magnetic field resulting from standard, nearly scale-invariant primordial adiabatic perturbations, making significant improvements to previous calculations.","This \"standard\" primordial field has a root mean square (rms) of $\\sim10^{-15}$ nG at $20\\lesssim z \\lesssim 100$, with fluctuations on $\\sim$ kpc comoving scales, and could serve as the seed of present-day magnetic fields observed in galaxies and galaxy clusters.","In addition, we consider early-Universe magnetic fields as a possible probe of non-standard initial conditions of the Universe on small scales $k \\sim 1-10^3$ Mpc$^{-1}$. To this end, we compute the maximally-allowed magnetic fields within current upper limits on small-scale adiabatic and isocurvature perturbations.","Under the current Cosmic Microwave Background spectral-distortion constraints magnetic fields could be produced with a rms of $\\sim 5\\times 10^{-11}$ nG at $z = 20$. Uncorrelated small-scale isocurvature perturbations within current Big-Bang Nucleosynthesis bounds could potentially enhance the magnetic field to $\\sim 10^{-14}-10^{-10}$ nG at $z = 20$, depending on the specific isocurvature mode considered.","While these very weak fields remain well below current observational capabilities, our work points out that magnetic fields could potentially provide an interesting window into the poorly constrained small-scale initial conditions of the Universe."],"url":"http://arxiv.org/abs/2404.03655v1","category":"astro-ph.CO"}
{"created":"2024-04-04 17:59:50","title":"RaFE: Generative Radiance Fields Restoration","abstract":"NeRF (Neural Radiance Fields) has demonstrated tremendous potential in novel view synthesis and 3D reconstruction, but its performance is sensitive to input image quality, which struggles to achieve high-fidelity rendering when provided with low-quality sparse input viewpoints. Previous methods for NeRF restoration are tailored for specific degradation type, ignoring the generality of restoration. To overcome this limitation, we propose a generic radiance fields restoration pipeline, named RaFE, which applies to various types of degradations, such as low resolution, blurriness, noise, compression artifacts, or their combinations. Our approach leverages the success of off-the-shelf 2D restoration methods to recover the multi-view images individually. Instead of reconstructing a blurred NeRF by averaging inconsistencies, we introduce a novel approach using Generative Adversarial Networks (GANs) for NeRF generation to better accommodate the geometric and appearance inconsistencies present in the multi-view images. Specifically, we adopt a two-level tri-plane architecture, where the coarse level remains fixed to represent the low-quality NeRF, and a fine-level residual tri-plane to be added to the coarse level is modeled as a distribution with GAN to capture potential variations in restoration. We validate RaFE on both synthetic and real cases for various restoration tasks, demonstrating superior performance in both quantitative and qualitative evaluations, surpassing other 3D restoration methods specific to single task. Please see our project website https://zkaiwu.github.io/RaFE-Project/.","sentences":["NeRF (Neural Radiance Fields) has demonstrated tremendous potential in novel view synthesis and 3D reconstruction, but its performance is sensitive to input image quality, which struggles to achieve high-fidelity rendering when provided with low-quality sparse input viewpoints.","Previous methods for NeRF restoration are tailored for specific degradation type, ignoring the generality of restoration.","To overcome this limitation, we propose a generic radiance fields restoration pipeline, named RaFE, which applies to various types of degradations, such as low resolution, blurriness, noise, compression artifacts, or their combinations.","Our approach leverages the success of off-the-shelf 2D restoration methods to recover the multi-view images individually.","Instead of reconstructing a blurred NeRF by averaging inconsistencies, we introduce a novel approach using Generative Adversarial Networks (GANs) for NeRF generation to better accommodate the geometric and appearance inconsistencies present in the multi-view images.","Specifically, we adopt a two-level tri-plane architecture, where the coarse level remains fixed to represent the low-quality NeRF, and a fine-level residual tri-plane to be added to the coarse level is modeled as a distribution with GAN to capture potential variations in restoration.","We validate RaFE on both synthetic and real cases for various restoration tasks, demonstrating superior performance in both quantitative and qualitative evaluations, surpassing other 3D restoration methods specific to single task.","Please see our project website https://zkaiwu.github.io/RaFE-Project/."],"url":"http://arxiv.org/abs/2404.03654v1","category":"cs.CV"}
{"created":"2024-04-04 17:59:46","title":"CoMat: Aligning Text-to-Image Diffusion Model with Image-to-Text Concept Matching","abstract":"Diffusion models have demonstrated great success in the field of text-to-image generation. However, alleviating the misalignment between the text prompts and images is still challenging. The root reason behind the misalignment has not been extensively investigated. We observe that the misalignment is caused by inadequate token attention activation. We further attribute this phenomenon to the diffusion model's insufficient condition utilization, which is caused by its training paradigm. To address the issue, we propose CoMat, an end-to-end diffusion model fine-tuning strategy with an image-to-text concept matching mechanism. We leverage an image captioning model to measure image-to-text alignment and guide the diffusion model to revisit ignored tokens. A novel attribute concentration module is also proposed to address the attribute binding problem. Without any image or human preference data, we use only 20K text prompts to fine-tune SDXL to obtain CoMat-SDXL. Extensive experiments show that CoMat-SDXL significantly outperforms the baseline model SDXL in two text-to-image alignment benchmarks and achieves start-of-the-art performance.","sentences":["Diffusion models have demonstrated great success in the field of text-to-image generation.","However, alleviating the misalignment between the text prompts and images is still challenging.","The root reason behind the misalignment has not been extensively investigated.","We observe that the misalignment is caused by inadequate token attention activation.","We further attribute this phenomenon to the diffusion model's insufficient condition utilization, which is caused by its training paradigm.","To address the issue, we propose CoMat, an end-to-end diffusion model fine-tuning strategy with an image-to-text concept matching mechanism.","We leverage an image captioning model to measure image-to-text alignment and guide the diffusion model to revisit ignored tokens.","A novel attribute concentration module is also proposed to address the attribute binding problem.","Without any image or human preference data, we use only 20K text prompts to fine-tune SDXL to obtain CoMat-SDXL.","Extensive experiments show that CoMat-SDXL significantly outperforms the baseline model SDXL in two text-to-image alignment benchmarks and achieves start-of-the-art performance."],"url":"http://arxiv.org/abs/2404.03653v1","category":"cs.CV"}
{"created":"2024-04-04 17:59:05","title":"Toric Promotion with Reflections and Refractions","abstract":"Inspired by recent work on refraction billiards in dynamics, we introduce a notion of refraction for combinatorial billiards. This allows us to define a generalization of toric promotion that we call toric promotion with reflections and refractions, which is a dynamical system defined via a graph $G$ whose edges are partitioned into a set of reflection edges and a set of refraction edges. This system is a discretization of a billiards system in which a beam of light can pass through, reflect off of, or refract through each toric hyperplane in a toric arrangement. Vastly generalizing the main theorem known about toric promotion, we give a simple formula for the orbit structure of toric promotion with reflections and refractions when $G$ is a forest. We also completely describe the orbit sizes when $G$ is a cycle with an even number of refraction edges; this result is new even for ordinary toric promotion (i.e., when there are no refraction edges). When $G$ is a cycle of even size with no reflection edges, we obtain an interesting instance of the cyclic sieving phenomenon.","sentences":["Inspired by recent work on refraction billiards in dynamics, we introduce a notion of refraction for combinatorial billiards.","This allows us to define a generalization of toric promotion that we call toric promotion with reflections and refractions, which is a dynamical system defined via a graph $G$ whose edges are partitioned into a set of reflection edges and a set of refraction edges.","This system is a discretization of a billiards system in which a beam of light can pass through, reflect off of, or refract through each toric hyperplane in a toric arrangement.","Vastly generalizing the main theorem known about toric promotion, we give a simple formula for the orbit structure of toric promotion with reflections and refractions when $G$ is a forest.","We also completely describe the orbit sizes when $G$ is a cycle with an even number of refraction edges; this result is new even for ordinary toric promotion (i.e., when there are no refraction edges).","When $G$ is a cycle of even size with no reflection edges, we obtain an interesting instance of the cyclic sieving phenomenon."],"url":"http://arxiv.org/abs/2404.03649v1","category":"math.CO"}
{"created":"2024-04-04 17:58:40","title":"AutoWebGLM: Bootstrap And Reinforce A Large Language Model-based Web Navigating Agent","abstract":"Large language models (LLMs) have fueled many intelligent agent tasks, such as web navigation -- but most existing agents perform far from satisfying in real-world webpages due to three factors: (1) the versatility of actions on webpages, (2) HTML text exceeding model processing capacity, and (3) the complexity of decision-making due to the open-domain nature of web. In light of the challenge, we develop AutoWebGLM, a GPT-4-outperforming automated web navigation agent built upon ChatGLM3-6B. Inspired by human browsing patterns, we design an HTML simplification algorithm to represent webpages, preserving vital information succinctly. We employ a hybrid human-AI method to build web browsing data for curriculum training. Then, we bootstrap the model by reinforcement learning and rejection sampling to further facilitate webpage comprehension, browser operations, and efficient task decomposition by itself. For testing, we establish a bilingual benchmark -- AutoWebBench -- for real-world web browsing tasks. We evaluate AutoWebGLM across diverse web navigation benchmarks, revealing its improvements but also underlying challenges to tackle real environments. Related code, model, and data will be released at \\url{https://github.com/THUDM/AutoWebGLM}.","sentences":["Large language models (LLMs) have fueled many intelligent agent tasks, such as web navigation -- but most existing agents perform far from satisfying in real-world webpages due to three factors: (1) the versatility of actions on webpages, (2) HTML text exceeding model processing capacity, and (3) the complexity of decision-making due to the open-domain nature of web.","In light of the challenge, we develop AutoWebGLM, a GPT-4-outperforming automated web navigation agent built upon ChatGLM3-6B. Inspired by human browsing patterns, we design an HTML simplification algorithm to represent webpages, preserving vital information succinctly.","We employ a hybrid human-AI method to build web browsing data for curriculum training.","Then, we bootstrap the model by reinforcement learning and rejection sampling to further facilitate webpage comprehension, browser operations, and efficient task decomposition by itself.","For testing, we establish a bilingual benchmark -- AutoWebBench -- for real-world web browsing tasks.","We evaluate AutoWebGLM across diverse web navigation benchmarks, revealing its improvements but also underlying challenges to tackle real environments.","Related code, model, and data will be released at \\url{https://github.com/THUDM/AutoWebGLM}."],"url":"http://arxiv.org/abs/2404.03648v1","category":"cs.CL"}
{"created":"2024-04-04 17:58:38","title":"Capabilities of Large Language Models in Control Engineering: A Benchmark Study on GPT-4, Claude 3 Opus, and Gemini 1.0 Ultra","abstract":"In this paper, we explore the capabilities of state-of-the-art large language models (LLMs) such as GPT-4, Claude 3 Opus, and Gemini 1.0 Ultra in solving undergraduate-level control problems. Controls provides an interesting case study for LLM reasoning due to its combination of mathematical theory and engineering design. We introduce ControlBench, a benchmark dataset tailored to reflect the breadth, depth, and complexity of classical control design. We use this dataset to study and evaluate the problem-solving abilities of these LLMs in the context of control engineering. We present evaluations conducted by a panel of human experts, providing insights into the accuracy, reasoning, and explanatory prowess of LLMs in control engineering. Our analysis reveals the strengths and limitations of each LLM in the context of classical control, and our results imply that Claude 3 Opus has become the state-of-the-art LLM for solving undergraduate control problems. Our study serves as an initial step towards the broader goal of employing artificial general intelligence in control engineering.","sentences":["In this paper, we explore the capabilities of state-of-the-art large language models (LLMs) such as GPT-4, Claude 3 Opus, and Gemini 1.0 Ultra in solving undergraduate-level control problems.","Controls provides an interesting case study for LLM reasoning due to its combination of mathematical theory and engineering design.","We introduce ControlBench, a benchmark dataset tailored to reflect the breadth, depth, and complexity of classical control design.","We use this dataset to study and evaluate the problem-solving abilities of these LLMs in the context of control engineering.","We present evaluations conducted by a panel of human experts, providing insights into the accuracy, reasoning, and explanatory prowess of LLMs in control engineering.","Our analysis reveals the strengths and limitations of each LLM in the context of classical control, and our results imply that Claude 3 Opus has become the state-of-the-art LLM for solving undergraduate control problems.","Our study serves as an initial step towards the broader goal of employing artificial general intelligence in control engineering."],"url":"http://arxiv.org/abs/2404.03647v1","category":"math.OC"}
{"created":"2024-04-04 17:58:01","title":"Hamiltonian simulation for low-energy states with optimal time dependence","abstract":"We consider the task of simulating time evolution under a Hamiltonian $H$ within its low-energy subspace. Assuming access to a block-encoding of $H'=(H-E)/\\lambda$ for some $E \\in \\mathbb R$, the goal is to implement an $\\epsilon$-approximation to $e^{-itH}$ when the initial state is confined to the subspace corresponding to eigenvalues $[-1, -1+\\Delta/\\lambda]$ of $H'$. We present a quantum algorithm that uses $O(t\\sqrt{\\lambda\\Gamma} + \\sqrt{\\lambda/\\Gamma}\\log(1/\\epsilon))$ queries to the block-encoding for any $\\Gamma$ such that $\\Delta \\leq \\Gamma \\leq \\lambda$. When $\\log(1/\\epsilon) = o(t\\lambda)$ and $\\Delta/\\lambda = o(1)$, this result improves over generic methods with query complexity $\\Omega(t\\lambda)$. Our quantum algorithm leverages spectral gap amplification and the quantum singular value transform. Using standard access models for $H$, we show that the ability to efficiently block-encode $H'$ is equivalent to $H$ being what we refer to as a \"gap-amplifiable\" Hamiltonian. This includes physically relevant examples such as frustration-free systems, and it encompasses all previously considered settings of low-energy simulation algorithms. We also provide lower bounds for low-energy simulation. In the worst case, we show that the low-energy condition cannot be used to improve the runtime of Hamiltonian simulation. For gap-amplifiable Hamiltonians, we prove that our algorithm is tight in the query model with respect to $t$, $\\Delta$, and $\\lambda$. In the practically relevant regime where $\\log (1/\\epsilon) = o(t\\Delta)$ and $\\Delta/\\lambda = o(1)$, we also prove a matching lower bound in gate complexity (up to log factors). To establish the query lower bounds, we consider $\\mathrm{PARITY}\\circ\\mathrm{OR}$ and degree bounds on trigonometric polynomials. To establish the lower bound on gate complexity, we use a circuit-to-Hamiltonian reduction acting on a low-energy state.","sentences":["We consider the task of simulating time evolution under a Hamiltonian $H$ within its low-energy subspace.","Assuming access to a block-encoding of $H'=(H-E)/\\lambda$ for some $E \\in \\mathbb R$, the goal is to implement an $\\epsilon$-approximation to $e^{-itH}$ when the initial state is confined to the subspace corresponding to eigenvalues $[-1, -1+\\Delta/\\lambda]$ of $H'$. We present a quantum algorithm that uses $O(t\\sqrt{\\lambda\\Gamma} + \\sqrt{\\lambda/\\Gamma}\\log(1/\\epsilon))$ queries to the block-encoding for any $\\Gamma$ such that $\\Delta \\leq \\Gamma","\\leq \\lambda$.","When $\\log(1/\\epsilon) = o(t\\lambda)$ and $\\Delta/\\lambda = o(1)$, this result improves over generic methods with query complexity $\\Omega(t\\lambda)$. Our quantum algorithm leverages spectral gap amplification and the quantum singular value transform.","Using standard access models for $H$, we show that the ability to efficiently block-encode $H'$ is equivalent to $H$ being what we refer to as a \"gap-amplifiable\" Hamiltonian.","This includes physically relevant examples such as frustration-free systems, and it encompasses all previously considered settings of low-energy simulation algorithms.","We also provide lower bounds for low-energy simulation.","In the worst case, we show that the low-energy condition cannot be used to improve the runtime of Hamiltonian simulation.","For gap-amplifiable Hamiltonians, we prove that our algorithm is tight in the query model with respect to $t$, $\\Delta$, and $\\lambda$. In the practically relevant regime where $\\log (1/\\epsilon) = o(t\\Delta)$ and $\\Delta/\\lambda = o(1)$, we also prove a matching lower bound in gate complexity (up to log factors).","To establish the query lower bounds, we consider $\\mathrm{PARITY}\\circ\\mathrm{OR}$ and degree bounds on trigonometric polynomials.","To establish the lower bound on gate complexity, we use a circuit-to-Hamiltonian reduction acting on a low-energy state."],"url":"http://arxiv.org/abs/2404.03644v1","category":"quant-ph"}
{"created":"2024-04-04 17:57:25","title":"DiffBody: Human Body Restoration by Imagining with Generative Diffusion Prior","abstract":"Human body restoration plays a vital role in various applications related to the human body. Despite recent advances in general image restoration using generative models, their performance in human body restoration remains mediocre, often resulting in foreground and background blending, over-smoothing surface textures, missing accessories, and distorted limbs. Addressing these challenges, we propose a novel approach by constructing a human body-aware diffusion model that leverages domain-specific knowledge to enhance performance. Specifically, we employ a pretrained body attention module to guide the diffusion model's focus on the foreground, addressing issues caused by blending between the subject and background. We also demonstrate the value of revisiting the language modality of the diffusion model in restoration tasks by seamlessly incorporating text prompt to improve the quality of surface texture and additional clothing and accessories details. Additionally, we introduce a diffusion sampler tailored for fine-grained human body parts, utilizing local semantic information to rectify limb distortions. Lastly, we collect a comprehensive dataset for benchmarking and advancing the field of human body restoration. Extensive experimental validation showcases the superiority of our approach, both quantitatively and qualitatively, over existing methods.","sentences":["Human body restoration plays a vital role in various applications related to the human body.","Despite recent advances in general image restoration using generative models, their performance in human body restoration remains mediocre, often resulting in foreground and background blending, over-smoothing surface textures, missing accessories, and distorted limbs.","Addressing these challenges, we propose a novel approach by constructing a human body-aware diffusion model that leverages domain-specific knowledge to enhance performance.","Specifically, we employ a pretrained body attention module to guide the diffusion model's focus on the foreground, addressing issues caused by blending between the subject and background.","We also demonstrate the value of revisiting the language modality of the diffusion model in restoration tasks by seamlessly incorporating text prompt to improve the quality of surface texture and additional clothing and accessories details.","Additionally, we introduce a diffusion sampler tailored for fine-grained human body parts, utilizing local semantic information to rectify limb distortions.","Lastly, we collect a comprehensive dataset for benchmarking and advancing the field of human body restoration.","Extensive experimental validation showcases the superiority of our approach, both quantitatively and qualitatively, over existing methods."],"url":"http://arxiv.org/abs/2404.03642v1","category":"cs.CV"}
{"created":"2024-04-04 17:57:22","title":"Amortized Analysis via Coalgebra","abstract":"Amortized analysis is a cost analysis technique for data structures in which cost is studied in aggregate, rather than considering the maximum cost of a single operation. Traditionally, amortized analysis has been phrased inductively, in terms of finite sequences of operations. Connecting to prior work on coalgebraic semantics for data structures, we develop the perspective that amortized analysis is naturally viewed coalgebraically in the category of algebras for a cost monad, where a morphism of coalgebras serves as a first-class generalization of potential function suitable for integrating cost and behavior. Using this simple definition, we consider amortization of other effects, such as randomization, and we compose amortization arguments in the indexed category of coalgebras. We generalize this to parallel data structure usage patterns by using coalgebras for an endoprofunctor instead of an endofunctor, combining potential using a monoidal structure on the underlying category. Finally, we adapt our discussion to the bicategorical setting, supporting imprecise amortized upper bounds.","sentences":["Amortized analysis is a cost analysis technique for data structures in which cost is studied in aggregate, rather than considering the maximum cost of a single operation.","Traditionally, amortized analysis has been phrased inductively, in terms of finite sequences of operations.","Connecting to prior work on coalgebraic semantics for data structures, we develop the perspective that amortized analysis is naturally viewed coalgebraically in the category of algebras for a cost monad, where a morphism of coalgebras serves as a first-class generalization of potential function suitable for integrating cost and behavior.","Using this simple definition, we consider amortization of other effects, such as randomization, and we compose amortization arguments in the indexed category of coalgebras.","We generalize this to parallel data structure usage patterns by using coalgebras for an endoprofunctor instead of an endofunctor, combining potential using a monoidal structure on the underlying category.","Finally, we adapt our discussion to the bicategorical setting, supporting imprecise amortized upper bounds."],"url":"http://arxiv.org/abs/2404.03641v1","category":"cs.PL"}
{"created":"2024-04-04 17:55:49","title":"On-demand higher-harmonic generation through nonlinear Hall effects in curved nanomembranes","abstract":"The high-order Hall effects, which go beyond the ordinary, unlock more possibilities of electronic transport properties and functionalities. Pioneer works focus on the manufacture of complex nanostructures with low lattice symmetry to produce them. In this paper, we theoretically show that such high-order Hall effects can alternatively be generated by curving a conducting nanomembrane which is highly tunable and also enables anisotropy. Its Hall response can be tuned from first to fourth order by simply varying the direction and magnitude of the applied magnetic field. The dominant Hall current frequency can also be altered from zero to double, or even four times that of the applied alternating electric field. This phenomenon is critically dependent on the occurrence of high-order snake orbits associated with the effective magnetic-field dipoles and quadruples induced by the curved geometry. Our results offer pathways for spatially engineering magnetotransport, current rectification, and frequency multiplication in the bent conducting nanomembrane.","sentences":["The high-order Hall effects, which go beyond the ordinary, unlock more possibilities of electronic transport properties and functionalities.","Pioneer works focus on the manufacture of complex nanostructures with low lattice symmetry to produce them.","In this paper, we theoretically show that such high-order Hall effects can alternatively be generated by curving a conducting nanomembrane which is highly tunable and also enables anisotropy.","Its Hall response can be tuned from first to fourth order by simply varying the direction and magnitude of the applied magnetic field.","The dominant Hall current frequency can also be altered from zero to double, or even four times that of the applied alternating electric field.","This phenomenon is critically dependent on the occurrence of high-order snake orbits associated with the effective magnetic-field dipoles and quadruples induced by the curved geometry.","Our results offer pathways for spatially engineering magnetotransport, current rectification, and frequency multiplication in the bent conducting nanomembrane."],"url":"http://arxiv.org/abs/2404.03639v1","category":"cond-mat.mes-hall"}
{"created":"2024-04-04 17:54:33","title":"WorDepth: Variational Language Prior for Monocular Depth Estimation","abstract":"Three-dimensional (3D) reconstruction from a single image is an ill-posed problem with inherent ambiguities, i.e. scale. Predicting a 3D scene from text description(s) is similarly ill-posed, i.e. spatial arrangements of objects described. We investigate the question of whether two inherently ambiguous modalities can be used in conjunction to produce metric-scaled reconstructions. To test this, we focus on monocular depth estimation, the problem of predicting a dense depth map from a single image, but with an additional text caption describing the scene. To this end, we begin by encoding the text caption as a mean and standard deviation; using a variational framework, we learn the distribution of the plausible metric reconstructions of 3D scenes corresponding to the text captions as a prior. To \"select\" a specific reconstruction or depth map, we encode the given image through a conditional sampler that samples from the latent space of the variational text encoder, which is then decoded to the output depth map. Our approach is trained alternatingly between the text and image branches: in one optimization step, we predict the mean and standard deviation from the text description and sample from a standard Gaussian, and in the other, we sample using a (image) conditional sampler. Once trained, we directly predict depth from the encoded text using the conditional sampler. We demonstrate our approach on indoor (NYUv2) and outdoor (KITTI) scenarios, where we show that language can consistently improve performance in both.","sentences":["Three-dimensional (3D) reconstruction from a single image is an ill-posed problem with inherent ambiguities, i.e. scale.","Predicting a 3D scene from text description(s) is similarly ill-posed, i.e. spatial arrangements of objects described.","We investigate the question of whether two inherently ambiguous modalities can be used in conjunction to produce metric-scaled reconstructions.","To test this, we focus on monocular depth estimation, the problem of predicting a dense depth map from a single image, but with an additional text caption describing the scene.","To this end, we begin by encoding the text caption as a mean and standard deviation; using a variational framework, we learn the distribution of the plausible metric reconstructions of 3D scenes corresponding to the text captions as a prior.","To \"select\" a specific reconstruction or depth map, we encode the given image through a conditional sampler that samples from the latent space of the variational text encoder, which is then decoded to the output depth map.","Our approach is trained alternatingly between the text and image branches: in one optimization step, we predict the mean and standard deviation from the text description and sample from a standard Gaussian, and in the other, we sample using a (image) conditional sampler.","Once trained, we directly predict depth from the encoded text using the conditional sampler.","We demonstrate our approach on indoor (NYUv2) and outdoor (KITTI) scenarios, where we show that language can consistently improve performance in both."],"url":"http://arxiv.org/abs/2404.03635v1","category":"cs.CV"}
{"created":"2024-04-04 17:53:33","title":"Reference-Based 3D-Aware Image Editing with Triplane","abstract":"Generative Adversarial Networks (GANs) have emerged as powerful tools not only for high-quality image generation but also for real image editing through manipulation of their interpretable latent spaces. Recent advancements in GANs include the development of 3D-aware models such as EG3D, characterized by efficient triplane-based architectures enabling the reconstruction of 3D geometry from single images. However, scant attention has been devoted to providing an integrated framework for high-quality reference-based 3D-aware image editing within this domain. This study addresses this gap by exploring and demonstrating the effectiveness of EG3D's triplane space for achieving advanced reference-based edits, presenting a unique perspective on 3D-aware image editing through our novel pipeline. Our approach integrates the encoding of triplane features, spatial disentanglement and automatic localization of features in the triplane domain, and fusion learning for desired image editing. Moreover, our framework demonstrates versatility across domains, extending its effectiveness to animal face edits and partial stylization of cartoon portraits. The method shows significant improvements over relevant 3D-aware latent editing and 2D reference-based editing methods, both qualitatively and quantitatively. Project page: https://three-bee.github.io/triplane_edit","sentences":["Generative Adversarial Networks (GANs) have emerged as powerful tools not only for high-quality image generation but also for real image editing through manipulation of their interpretable latent spaces.","Recent advancements in GANs include the development of 3D-aware models such as EG3D, characterized by efficient triplane-based architectures enabling the reconstruction of 3D geometry from single images.","However, scant attention has been devoted to providing an integrated framework for high-quality reference-based 3D-aware image editing within this domain.","This study addresses this gap by exploring and demonstrating the effectiveness of EG3D's triplane space for achieving advanced reference-based edits, presenting a unique perspective on 3D-aware image editing through our novel pipeline.","Our approach integrates the encoding of triplane features, spatial disentanglement and automatic localization of features in the triplane domain, and fusion learning for desired image editing.","Moreover, our framework demonstrates versatility across domains, extending its effectiveness to animal face edits and partial stylization of cartoon portraits.","The method shows significant improvements over relevant 3D-aware latent editing and 2D reference-based editing methods, both qualitatively and quantitatively.","Project page: https://three-bee.github.io/triplane_edit"],"url":"http://arxiv.org/abs/2404.03632v1","category":"cs.CV"}
{"created":"2024-04-04 17:52:13","title":"Robust Concept Erasure Using Task Vectors","abstract":"With the rapid growth of text-to-image models, a variety of techniques have been suggested to prevent undesirable image generations. Yet, these methods often only protect against specific user prompts and have been shown to allow unsafe generations with other inputs. Here we focus on unconditionally erasing a concept from a text-to-image model rather than conditioning the erasure on the user's prompt. We first show that compared to input-dependent erasure methods, concept erasure that uses Task Vectors (TV) is more robust to unexpected user inputs, not seen during training. However, TV-based erasure can also affect the core performance of the edited model, particularly when the required edit strength is unknown. To this end, we propose a method called Diverse Inversion, which we use to estimate the required strength of the TV edit. Diverse Inversion finds within the model input space a large set of word embeddings, each of which induces the generation of the target concept. We find that encouraging diversity in the set makes our estimation more robust to unexpected prompts. Finally, we show that Diverse Inversion enables us to apply a TV edit only to a subset of the model weights, enhancing the erasure capabilities while better maintaining the core functionality of the model.","sentences":["With the rapid growth of text-to-image models, a variety of techniques have been suggested to prevent undesirable image generations.","Yet, these methods often only protect against specific user prompts and have been shown to allow unsafe generations with other inputs.","Here we focus on unconditionally erasing a concept from a text-to-image model rather than conditioning the erasure on the user's prompt.","We first show that compared to input-dependent erasure methods, concept erasure that uses Task Vectors (TV) is more robust to unexpected user inputs, not seen during training.","However, TV-based erasure can also affect the core performance of the edited model, particularly when the required edit strength is unknown.","To this end, we propose a method called Diverse Inversion, which we use to estimate the required strength of the TV edit.","Diverse Inversion finds within the model input space a large set of word embeddings, each of which induces the generation of the target concept.","We find that encouraging diversity in the set makes our estimation more robust to unexpected prompts.","Finally, we show that Diverse Inversion enables us to apply a TV edit only to a subset of the model weights, enhancing the erasure capabilities while better maintaining the core functionality of the model."],"url":"http://arxiv.org/abs/2404.03631v1","category":"cs.CV"}
{"created":"2024-04-04 17:52:05","title":"Lie-algebraic K\u00e4hler sigma models with the U(1) isotropy","abstract":"We discuss various questions which emerge in connection with the Lie-algebraic deformation of $\\mathbb{CP}^1$ sigma model in two dimensions. First we supersymmetrize the original model endowing it with the minimal ${\\cal N}=(0,2)$ and extended ${\\cal N}=(2,2)$ supersymmetries. Then we derive the general hypercurrent anomaly in the both cases. In the latter case this anomaly is one-loop but is somewhat different from the standard expressions one can find in the literature because the target manifold is non-symmetric. We also show how to introduce the twisted masses and the $\\theta$ term, and study the BPS equation for instantons, in particular the value of the topological charge. Then we demonstrate that the second loop in the $\\beta$ function of the non-supersymmetric Lie-algebraic sigma model is due to an infrared effect. To this end we use a supersymmetric regularization. We also conjecture that the above statement is valid for higher loops too, similar to the parallel phenomenon in four-dimensional ${\\cal N}=1$ super-Yang-Mills. In the second part of the paper we develop a special dimensional reduction -- namely, starting from the two-dimensional Lie-algebraic model we arrive at a quasi-exactly solvable quantum-mechanical problem of the Lam\\'e type.","sentences":["We discuss various questions which emerge in connection with the Lie-algebraic deformation of $\\mathbb{CP}^1$ sigma model in two dimensions.","First we supersymmetrize the original model endowing it with the minimal ${\\cal N}=(0,2)$ and extended ${\\cal N}=(2,2)$ supersymmetries.","Then we derive the general hypercurrent anomaly in the both cases.","In the latter case this anomaly is one-loop but is somewhat different from the standard expressions one can find in the literature because the target manifold is non-symmetric.","We also show how to introduce the twisted masses and the $\\theta$ term, and study the BPS equation for instantons, in particular the value of the topological charge.","Then we demonstrate that the second loop in the $\\beta$ function of the non-supersymmetric Lie-algebraic sigma model is due to an infrared effect.","To this end we use a supersymmetric regularization.","We also conjecture that the above statement is valid for higher loops too, similar to the parallel phenomenon in four-dimensional ${\\cal N}=1$ super-Yang-Mills.","In the second part of the paper we develop a special dimensional reduction -- namely, starting from the two-dimensional Lie-algebraic model we arrive at a quasi-exactly solvable quantum-mechanical problem of the Lam\\'e type."],"url":"http://arxiv.org/abs/2404.03630v1","category":"hep-th"}
{"created":"2024-04-04 17:49:23","title":"Injective norm of real and complex random tensors I: From spin glasses to geometric entanglement","abstract":"The injective norm is a natural generalization to tensors of the operator norm of a matrix. In quantum information, the injective norm is one important measure of genuine multipartite entanglement of quantum states, where it is known as the geometric entanglement. In this paper, we give a high-probability upper bound on the injective norm of real and complex Gaussian random tensors, corresponding to a lower bound on the geometric entanglement of random quantum states, and to a bound on the ground-state energy of a particular multispecies spherical spin glass model. For some cases of our model, previous work used $\\epsilon$-net techniques to identify the correct order of magnitude; in the present work, we use the Kac--Rice formula to give a one-sided bound on the constant which we believe to be tight.","sentences":["The injective norm is a natural generalization to tensors of the operator norm of a matrix.","In quantum information, the injective norm is one important measure of genuine multipartite entanglement of quantum states, where it is known as the geometric entanglement.","In this paper, we give a high-probability upper bound on the injective norm of real and complex Gaussian random tensors, corresponding to a lower bound on the geometric entanglement of random quantum states, and to a bound on the ground-state energy of a particular multispecies spherical spin glass model.","For some cases of our model, previous work used $\\epsilon$-net techniques to identify the correct order of magnitude; in the present work, we use the Kac--Rice formula to give a one-sided bound on the constant which we believe to be tight."],"url":"http://arxiv.org/abs/2404.03627v1","category":"math.PR"}
{"created":"2024-04-04 17:48:28","title":"Training LLMs over Neurally Compressed Text","abstract":"In this paper, we explore the idea of training large language models (LLMs) over highly compressed text. While standard subword tokenizers compress text by a small factor, neural text compressors can achieve much higher rates of compression. If it were possible to train LLMs directly over neurally compressed text, this would confer advantages in training and serving efficiency, as well as easier handling of long text spans. The main obstacle to this goal is that strong compression tends to produce opaque outputs that are not well-suited for learning. In particular, we find that text na\\\"ively compressed via Arithmetic Coding is not readily learnable by LLMs. To overcome this, we propose Equal-Info Windows, a novel compression technique whereby text is segmented into blocks that each compress to the same bit length. Using this method, we demonstrate effective learning over neurally compressed text that improves with scale, and outperforms byte-level baselines by a wide margin on perplexity and inference speed benchmarks. While our method delivers worse perplexity than subword tokenizers for models trained with the same parameter count, it has the benefit of shorter sequence lengths. Shorter sequence lengths require fewer autoregressive generation steps, and reduce latency. Finally, we provide extensive analysis of the properties that contribute to learnability, and offer concrete suggestions for how to further improve the performance of high-compression tokenizers.","sentences":["In this paper, we explore the idea of training large language models (LLMs) over highly compressed text.","While standard subword tokenizers compress text by a small factor, neural text compressors can achieve much higher rates of compression.","If it were possible to train LLMs directly over neurally compressed text, this would confer advantages in training and serving efficiency, as well as easier handling of long text spans.","The main obstacle to this goal is that strong compression tends to produce opaque outputs that are not well-suited for learning.","In particular, we find that text na\\\"ively compressed via Arithmetic Coding is not readily learnable by LLMs.","To overcome this, we propose Equal-Info Windows, a novel compression technique whereby text is segmented into blocks that each compress to the same bit length.","Using this method, we demonstrate effective learning over neurally compressed text that improves with scale, and outperforms byte-level baselines by a wide margin on perplexity and inference speed benchmarks.","While our method delivers worse perplexity than subword tokenizers for models trained with the same parameter count, it has the benefit of shorter sequence lengths.","Shorter sequence lengths require fewer autoregressive generation steps, and reduce latency.","Finally, we provide extensive analysis of the properties that contribute to learnability, and offer concrete suggestions for how to further improve the performance of high-compression tokenizers."],"url":"http://arxiv.org/abs/2404.03626v1","category":"cs.CL"}
{"created":"2024-04-04 17:47:52","title":"Universal Time-Entanglement Trade-off in Open Quantum Systems","abstract":"We demonstrate a surprising connection between pure steady state entanglement and relaxation timescales in an extremely broad class of Markovian open systems, where two (possibly many-body) systems $A$ and $B$ interact locally with a common dissipative environment. This setup also encompases a broad class of adaptive quantum dynamics based on continuous measurement and feedback. As steady state entanglement increases, there is generically an emergent strong symmetry that leads to a dynamical slow down. Using this we can prove rigorous bounds on relaxation times set by steady state entanglement. We also find that this time must necessarily diverge for maximal entanglement. To test our bound, we consider the dynamics of a random ensemble of local Lindbladians that support pure steady states, finding that the bound does an excellent job of predicting how the dissipative gap varies with the amount of entanglement. Our work provides general insights into how dynamics and entanglement are connected in open systems, and has specific relevance to quantum reservoir engineering.","sentences":["We demonstrate a surprising connection between pure steady state entanglement and relaxation timescales in an extremely broad class of Markovian open systems, where two (possibly many-body) systems $A$ and $B$ interact locally with a common dissipative environment.","This setup also encompases a broad class of adaptive quantum dynamics based on continuous measurement and feedback.","As steady state entanglement increases, there is generically an emergent strong symmetry that leads to a dynamical slow down.","Using this we can prove rigorous bounds on relaxation times set by steady state entanglement.","We also find that this time must necessarily diverge for maximal entanglement.","To test our bound, we consider the dynamics of a random ensemble of local Lindbladians that support pure steady states, finding that the bound does an excellent job of predicting how the dissipative gap varies with the amount of entanglement.","Our work provides general insights into how dynamics and entanglement are connected in open systems, and has specific relevance to quantum reservoir engineering."],"url":"http://arxiv.org/abs/2404.03625v1","category":"quant-ph"}
{"created":"2024-04-04 17:46:32","title":"Standardizing Knowledge Engineering Practices with a Reference Architecture","abstract":"Knowledge engineering is the process of creating and maintaining knowledge-producing systems. Throughout the history of computer science and AI, knowledge engineering workflows have been widely used given the importance of high-quality knowledge for reliable intelligent agents. Meanwhile, the scope of knowledge engineering, as apparent from its target tasks and use cases, has been shifting, together with its paradigms such as expert systems, semantic web, and language modeling. The intended use cases and supported user requirements between these paradigms have not been analyzed globally, as new paradigms often satisfy prior pain points while possibly introducing new ones. The recent abstraction of systemic patterns into a boxology provides an opening for aligning the requirements and use cases of knowledge engineering with the systems, components, and software that can satisfy them best. This paper proposes a vision of harmonizing the best practices in the field of knowledge engineering by leveraging the software engineering methodology of creating reference architectures. We describe how a reference architecture can be iteratively designed and implemented to associate user needs with recurring systemic patterns, building on top of existing knowledge engineering workflows and boxologies. We provide a six-step roadmap that can enable the development of such an architecture, providing an initial design and outcome of the definition of architectural scope, selection of information sources, and analysis. We expect that following through on this vision will lead to well-grounded reference architectures for knowledge engineering, will advance the ongoing initiatives of organizing the neurosymbolic knowledge engineering space, and will build new links to the software architectures and data science communities.","sentences":["Knowledge engineering is the process of creating and maintaining knowledge-producing systems.","Throughout the history of computer science and AI, knowledge engineering workflows have been widely used given the importance of high-quality knowledge for reliable intelligent agents.","Meanwhile, the scope of knowledge engineering, as apparent from its target tasks and use cases, has been shifting, together with its paradigms such as expert systems, semantic web, and language modeling.","The intended use cases and supported user requirements between these paradigms have not been analyzed globally, as new paradigms often satisfy prior pain points while possibly introducing new ones.","The recent abstraction of systemic patterns into a boxology provides an opening for aligning the requirements and use cases of knowledge engineering with the systems, components, and software that can satisfy them best.","This paper proposes a vision of harmonizing the best practices in the field of knowledge engineering by leveraging the software engineering methodology of creating reference architectures.","We describe how a reference architecture can be iteratively designed and implemented to associate user needs with recurring systemic patterns, building on top of existing knowledge engineering workflows and boxologies.","We provide a six-step roadmap that can enable the development of such an architecture, providing an initial design and outcome of the definition of architectural scope, selection of information sources, and analysis.","We expect that following through on this vision will lead to well-grounded reference architectures for knowledge engineering, will advance the ongoing initiatives of organizing the neurosymbolic knowledge engineering space, and will build new links to the software architectures and data science communities."],"url":"http://arxiv.org/abs/2404.03624v1","category":"cs.AI"}
{"created":"2024-04-04 17:45:59","title":"Unveiling LLMs: The Evolution of Latent Representations in a Temporal Knowledge Graph","abstract":"Large Language Models (LLMs) demonstrate an impressive capacity to recall a vast range of common factual knowledge information. However, unravelling the underlying reasoning of LLMs and explaining their internal mechanisms of exploiting this factual knowledge remain active areas of investigation. Our work analyzes the factual knowledge encoded in the latent representation of LLMs when prompted to assess the truthfulness of factual claims. We propose an end-to-end framework that jointly decodes the factual knowledge embedded in the latent space of LLMs from a vector space to a set of ground predicates and represents its evolution across the layers using a temporal knowledge graph. Our framework relies on the technique of activation patching which intervenes in the inference computation of a model by dynamically altering its latent representations. Consequently, we neither rely on external models nor training processes. We showcase our framework with local and global interpretability analyses using two claim verification datasets: FEVER and CLIMATE-FEVER. The local interpretability analysis exposes different latent errors from representation to multi-hop reasoning errors. On the other hand, the global analysis uncovered patterns in the underlying evolution of the model's factual knowledge (e.g., store-and-seek factual information). By enabling graph-based analyses of the latent representations, this work represents a step towards the mechanistic interpretability of LLMs.","sentences":["Large Language Models (LLMs) demonstrate an impressive capacity to recall a vast range of common factual knowledge information.","However, unravelling the underlying reasoning of LLMs and explaining their internal mechanisms of exploiting this factual knowledge remain active areas of investigation.","Our work analyzes the factual knowledge encoded in the latent representation of LLMs when prompted to assess the truthfulness of factual claims.","We propose an end-to-end framework that jointly decodes the factual knowledge embedded in the latent space of LLMs from a vector space to a set of ground predicates and represents its evolution across the layers using a temporal knowledge graph.","Our framework relies on the technique of activation patching which intervenes in the inference computation of a model by dynamically altering its latent representations.","Consequently, we neither rely on external models nor training processes.","We showcase our framework with local and global interpretability analyses using two claim verification datasets: FEVER and CLIMATE-FEVER.","The local interpretability analysis exposes different latent errors from representation to multi-hop reasoning errors.","On the other hand, the global analysis uncovered patterns in the underlying evolution of the model's factual knowledge (e.g., store-and-seek factual information).","By enabling graph-based analyses of the latent representations, this work represents a step towards the mechanistic interpretability of LLMs."],"url":"http://arxiv.org/abs/2404.03623v1","category":"cs.CL"}
{"created":"2024-04-04 17:45:08","title":"Visualization-of-Thought Elicits Spatial Reasoning in Large Language Models","abstract":"Large language models (LLMs) have exhibited impressive performance in language comprehension and various reasoning tasks. However, their abilities in spatial reasoning, a crucial aspect of human cognition, remain relatively unexplored. Human possess a remarkable ability to create mental images of unseen objects and actions through a process known as \\textbf{the Mind's Eye}, enabling the imagination of the unseen world. Inspired by this cognitive capacity, we propose Visualization-of-Thought (\\textbf{VoT}) prompting. VoT aims to elicit spatial reasoning of LLMs by visualizing their reasoning traces, thereby guiding subsequent reasoning steps. We employed VoT for multi-hop spatial reasoning tasks, including natural language navigation, visual navigation, and visual tiling in 2D grid worlds. Experimental results demonstrated that VoT significantly enhances the spatial reasoning abilities of LLMs. Notably, VoT outperformed existing multimodal large language models (MLLMs) in these tasks. While VoT works surprisingly well on LLMs, the ability to generate \\textit{mental images} to facilitate spatial reasoning resembles the mind's eye process, suggesting its potential viability in MLLMs.","sentences":["Large language models (LLMs) have exhibited impressive performance in language comprehension and various reasoning tasks.","However, their abilities in spatial reasoning, a crucial aspect of human cognition, remain relatively unexplored.","Human possess a remarkable ability to create mental images of unseen objects and actions through a process known as \\textbf{the Mind's Eye}, enabling the imagination of the unseen world.","Inspired by this cognitive capacity, we propose Visualization-of-Thought (\\textbf{VoT}) prompting.","VoT aims to elicit spatial reasoning of LLMs by visualizing their reasoning traces, thereby guiding subsequent reasoning steps.","We employed VoT for multi-hop spatial reasoning tasks, including natural language navigation, visual navigation, and visual tiling in 2D grid worlds.","Experimental results demonstrated that VoT significantly enhances the spatial reasoning abilities of LLMs.","Notably, VoT outperformed existing multimodal large language models (MLLMs) in these tasks.","While VoT works surprisingly well on LLMs, the ability to generate \\textit{mental images} to facilitate spatial reasoning resembles the mind's eye process, suggesting its potential viability in MLLMs."],"url":"http://arxiv.org/abs/2404.03622v1","category":"cs.CL"}
{"created":"2024-04-04 17:43:06","title":"LCM-Lookahead for Encoder-based Text-to-Image Personalization","abstract":"Recent advancements in diffusion models have introduced fast sampling methods that can effectively produce high-quality images in just one or a few denoising steps. Interestingly, when these are distilled from existing diffusion models, they often maintain alignment with the original model, retaining similar outputs for similar prompts and seeds. These properties present opportunities to leverage fast sampling methods as a shortcut-mechanism, using them to create a preview of denoised outputs through which we can backpropagate image-space losses. In this work, we explore the potential of using such shortcut-mechanisms to guide the personalization of text-to-image models to specific facial identities. We focus on encoder-based personalization approaches, and demonstrate that by tuning them with a lookahead identity loss, we can achieve higher identity fidelity, without sacrificing layout diversity or prompt alignment. We further explore the use of attention sharing mechanisms and consistent data generation for the task of personalization, and find that encoder training can benefit from both.","sentences":["Recent advancements in diffusion models have introduced fast sampling methods that can effectively produce high-quality images in just one or a few denoising steps.","Interestingly, when these are distilled from existing diffusion models, they often maintain alignment with the original model, retaining similar outputs for similar prompts and seeds.","These properties present opportunities to leverage fast sampling methods as a shortcut-mechanism, using them to create a preview of denoised outputs through which we can backpropagate image-space losses.","In this work, we explore the potential of using such shortcut-mechanisms to guide the personalization of text-to-image models to specific facial identities.","We focus on encoder-based personalization approaches, and demonstrate that by tuning them with a lookahead identity loss, we can achieve higher identity fidelity, without sacrificing layout diversity or prompt alignment.","We further explore the use of attention sharing mechanisms and consistent data generation for the task of personalization, and find that encoder training can benefit from both."],"url":"http://arxiv.org/abs/2404.03620v1","category":"cs.CV"}
{"created":"2024-04-04 17:41:13","title":"Circuit Knitting Faces Exponential Sampling Overhead Scaling Bounded by Entanglement Cost","abstract":"Circuit knitting, a method for connecting quantum circuits across multiple processors to simulate nonlocal quantum operations, is a promising approach for distributed quantum computing. While various techniques have been developed for circuit knitting, we uncover fundamental limitations to the scalability of this technology. We prove that the sampling overhead of circuit knitting is exponentially lower bounded by the exact entanglement cost of the target bipartite dynamic, even for asymptotic overhead in the parallel cut regime. Specifically, we prove that the regularized sampling overhead assisted with local operations and classical communication (LOCC), of any bipartite quantum channel is lower bounded by the exponential of its exact entanglement cost under separable preserving operations. Furthermore, we show that the regularized sampling overhead for simulating a general bipartite channel via LOCC is lower bounded by $\\kappa$-entanglement and max-Rains information, providing efficiently computable benchmarks. Our work reveals a profound connection between virtual quantum information processing via quasi-probability decomposition and quantum Shannon theory, highlighting the critical role of entanglement in distributed quantum computing.","sentences":["Circuit knitting, a method for connecting quantum circuits across multiple processors to simulate nonlocal quantum operations, is a promising approach for distributed quantum computing.","While various techniques have been developed for circuit knitting, we uncover fundamental limitations to the scalability of this technology.","We prove that the sampling overhead of circuit knitting is exponentially lower bounded by the exact entanglement cost of the target bipartite dynamic, even for asymptotic overhead in the parallel cut regime.","Specifically, we prove that the regularized sampling overhead assisted with local operations and classical communication (LOCC), of any bipartite quantum channel is lower bounded by the exponential of its exact entanglement cost under separable preserving operations.","Furthermore, we show that the regularized sampling overhead for simulating a general bipartite channel via LOCC is lower bounded by $\\kappa$-entanglement and max-Rains information, providing efficiently computable benchmarks.","Our work reveals a profound connection between virtual quantum information processing via quasi-probability decomposition and quantum Shannon theory, highlighting the critical role of entanglement in distributed quantum computing."],"url":"http://arxiv.org/abs/2404.03619v1","category":"quant-ph"}
{"created":"2024-04-04 17:40:06","title":"DeViDe: Faceted medical knowledge for improved medical vision-language pre-training","abstract":"Vision-language pre-training for chest X-rays has made significant strides, primarily by utilizing paired radiographs and radiology reports. However, existing approaches often face challenges in encoding medical knowledge effectively. While radiology reports provide insights into the current disease manifestation, medical definitions (as used by contemporary methods) tend to be overly abstract, creating a gap in knowledge. To address this, we propose DeViDe, a novel transformer-based method that leverages radiographic descriptions from the open web. These descriptions outline general visual characteristics of diseases in radiographs, and when combined with abstract definitions and radiology reports, provide a holistic snapshot of knowledge. DeViDe incorporates three key features for knowledge-augmented vision language alignment: First, a large-language model-based augmentation is employed to homogenise medical knowledge from diverse sources. Second, this knowledge is aligned with image information at various levels of granularity. Third, a novel projection layer is proposed to handle the complexity of aligning each image with multiple descriptions arising in a multi-label setting. In zero-shot settings, DeViDe performs comparably to fully supervised models on external datasets and achieves state-of-the-art results on three large-scale datasets. Additionally, fine-tuning DeViDe on four downstream tasks and six segmentation tasks showcases its superior performance across data from diverse distributions.","sentences":["Vision-language pre-training for chest X-rays has made significant strides, primarily by utilizing paired radiographs and radiology reports.","However, existing approaches often face challenges in encoding medical knowledge effectively.","While radiology reports provide insights into the current disease manifestation, medical definitions (as used by contemporary methods) tend to be overly abstract, creating a gap in knowledge.","To address this, we propose DeViDe, a novel transformer-based method that leverages radiographic descriptions from the open web.","These descriptions outline general visual characteristics of diseases in radiographs, and when combined with abstract definitions and radiology reports, provide a holistic snapshot of knowledge.","DeViDe incorporates three key features for knowledge-augmented vision language alignment: First, a large-language model-based augmentation is employed to homogenise medical knowledge from diverse sources.","Second, this knowledge is aligned with image information at various levels of granularity.","Third, a novel projection layer is proposed to handle the complexity of aligning each image with multiple descriptions arising in a multi-label setting.","In zero-shot settings, DeViDe performs comparably to fully supervised models on external datasets and achieves state-of-the-art results on three large-scale datasets.","Additionally, fine-tuning DeViDe on four downstream tasks and six segmentation tasks showcases its superior performance across data from diverse distributions."],"url":"http://arxiv.org/abs/2404.03618v1","category":"cs.CV"}
{"created":"2024-04-04 17:38:28","title":"On algebras of Dirichlet series invariant under permutations of coefficients","abstract":"Let $\\mathscr O_u$ be the algebra of holomorphic functions on ${\\bf C}_+:=\\{s\\in{\\bf C}:\\text{Re }s>0\\}$ that are limits of Dirichlet series $D=\\sum_{n=1}^\\infty a_n n^{-s}$, $s\\in \\bf{C}_+$, that converge uniformly on proper half-planes of $\\bf{C}_+$. We study algebraic-topological properties of subalgebras of $\\mathscr O_u$: the Banach algebras $\\mathscr W, \\mathscr A, \\mathscr H^\\infty$ and the Frechet algebra $\\mathscr O_b$. Here $\\mathscr W$ consists of functions in $\\mathscr O_u$ of absolutely convergent Dirichlet series on the closure of $\\bf{C}_+$, $\\mathscr A$ is the uniform closure of $\\mathscr W$, $\\mathscr H^\\infty$ is the algebra of all bounded functions in $\\mathscr O_u$, and $\\mathscr O_b$ is set of all $f(s)=\\sum_{n=1}^\\infty a_n n^{-s}$ in $\\mathscr O_u$ so that $f_r\\in \\mathscr H^\\infty$, $r\\in (0,1)$, where $f_r(s):=\\sum_{n=1}^\\infty a_n r^{\\Omega(n)} n^{-s}$ and $\\Omega(n)$ is the number of prime factors of $n$. Let $S_\\bf{N}$ be the group of permutations of $\\bf{N}$. Each $\\sigma\\in S_\\bf{N}$ determines a permutation $\\hat\\sigma\\in S_\\bf{N}$ (i.e., such that $\\hat\\sigma(mn)=\\hat\\sigma(n)\\hat\\sigma(m)$ for all $m,n\\in \\bf{N}$) via the fundamental theorem of arithmetic. For a Dirichlet series $D=\\sum_{n=1}^\\infty a_n n^{-s}$, and $\\sigma \\in S_\\bf{N}$, $S_\\sigma(D)=\\sum_{n=1}^\\infty a_{\\hat{\\sigma}^{-1}(n)} n^{-s}$ determines an action of $S_\\bf{N}$ on the set of all Dirichlet series. It is shown that each of the algebras above is invariant with respect to this action. Given a subgroup $G$ of $S_\\bf{N}$, the set of $G$-invariant subalgebras of these algebras are studied, and their maximal ideal spaces are described, and used to characterise groups of units and of invertible elements having logarithms, find the stable rank, show projective freeness, and describe when the special linear group is generated by elementary matrices, with bounds on the number of factors.","sentences":["Let $\\mathscr O_u$ be the algebra of holomorphic functions on ${\\bf C}_+:=\\{s\\in{\\bf C}:\\text{Re }s>0\\}$ that are limits of Dirichlet series $D=\\sum_{n=1}^\\infty a_n n^{-s}$, $s\\in \\bf{C}_+$, that converge uniformly on proper half-planes of $\\bf{C}_+$. We study algebraic-topological properties of subalgebras of $\\mathscr O_u$: the Banach algebras $\\mathscr W, \\mathscr A, \\mathscr H^\\infty$ and the Frechet algebra $\\mathscr O_b$. Here $\\mathscr W$ consists of functions in $\\mathscr O_u$ of absolutely convergent Dirichlet series on the closure of $\\bf{C}_+$, $\\mathscr A$ is the uniform closure of $\\mathscr W$, $\\mathscr H^\\infty$ is the algebra of all bounded functions in $\\mathscr O_u$, and $\\mathscr O_b$ is set of all $f(s)=\\sum_{n=1}^\\infty a_n n^{-s}$ in $\\mathscr O_u$ so that $f_r\\in \\mathscr H^\\infty$, $r\\in (0,1)$, where $f_r(s):=\\sum_{n=1}^\\infty a_n r^{\\Omega(n)} n^{-s}$ and $\\Omega(n)$ is the number of prime factors of $n$. Let $S_\\bf{N}$ be the group of permutations of $\\bf{N}$. Each $\\sigma\\in S_\\bf{N}$ determines a permutation $\\hat\\sigma\\in S_\\bf{N}$ (i.e., such that $\\hat\\sigma(mn)=\\hat\\sigma(n)\\hat\\sigma(m)$ for all $m,n\\in \\bf{N}$) via the fundamental theorem of arithmetic.","For a Dirichlet series $D=\\sum_{n=1}^\\infty a_n n^{-s}$, and $\\sigma \\in S_\\bf{N}$, $S_\\sigma(D)=\\sum_{n=1}^\\infty a_{\\hat{\\sigma}^{-1}(n)} n^{-s}$ determines an action of $S_\\bf{N}$ on the set of all Dirichlet series.","It is shown that each of the algebras above is invariant with respect to this action.","Given a subgroup $G$ of $S_\\bf{N}$, the set of $G$-invariant subalgebras of these algebras are studied, and their maximal ideal spaces are described, and used to characterise groups of units and of invertible elements having logarithms, find the stable rank, show projective freeness, and describe when the special linear group is generated by elementary matrices, with bounds on the number of factors."],"url":"http://arxiv.org/abs/2404.03616v1","category":"math.CV"}
{"created":"2024-04-04 17:36:20","title":"Towards Trustworthy Automated Program Verifiers: Formally Validating Translations into an Intermediate Verification Language (extended version)","abstract":"Automated program verifiers are typically implemented using an intermediate verification language (IVL), such as Boogie or Why3. A verifier front-end translates the input program and specification into an IVL program, while the back-end generates proof obligations for the IVL program and employs an SMT solver to discharge them. Soundness of such verifiers therefore requires that the front-end translation faithfully captures the semantics of the input program and specification in the IVL program, and that the back-end reports success only if the IVL program is actually correct. For a verification tool to be trustworthy, these soundness conditions must be satisfied by its actual implementation, not just the program logic it uses.   In this paper, we present a novel validation methodology that, given a formal semantics for the input language and IVL, provides formal soundness guarantees for front-end implementations. For each run of the verifier, we automatically generate a proof in Isabelle showing that the correctness of the produced IVL program implies the correctness of the input program. This proof can be checked independently from the verifier in Isabelle and can be combined with existing work on validating back-ends to obtain an end-to-end soundness result. Our methodology based on forward simulation employs several modularisation strategies to handle the large semantic gap between the input language and the IVL, as well as the intricacies of practical, optimised translations. We present our methodology for the widely-used Viper and Boogie languages. Our evaluation shows that it is effective in validating the translations performed by the existing Viper implementation.","sentences":["Automated program verifiers are typically implemented using an intermediate verification language (IVL), such as Boogie or Why3.","A verifier front-end translates the input program and specification into an IVL program, while the back-end generates proof obligations for the IVL program and employs an SMT solver to discharge them.","Soundness of such verifiers therefore requires that the front-end translation faithfully captures the semantics of the input program and specification in the IVL program, and that the back-end reports success only if the IVL program is actually correct.","For a verification tool to be trustworthy, these soundness conditions must be satisfied by its actual implementation, not just the program logic it uses.   ","In this paper, we present a novel validation methodology that, given a formal semantics for the input language and IVL, provides formal soundness guarantees for front-end implementations.","For each run of the verifier, we automatically generate a proof in Isabelle showing that the correctness of the produced IVL program implies the correctness of the input program.","This proof can be checked independently from the verifier in Isabelle and can be combined with existing work on validating back-ends to obtain an end-to-end soundness result.","Our methodology based on forward simulation employs several modularisation strategies to handle the large semantic gap between the input language and the IVL, as well as the intricacies of practical, optimised translations.","We present our methodology for the widely-used Viper and Boogie languages.","Our evaluation shows that it is effective in validating the translations performed by the existing Viper implementation."],"url":"http://arxiv.org/abs/2404.03614v1","category":"cs.PL"}
{"created":"2024-04-04 17:34:21","title":"InsectMamba: Insect Pest Classification with State Space Model","abstract":"The classification of insect pests is a critical task in agricultural technology, vital for ensuring food security and environmental sustainability. However, the complexity of pest identification, due to factors like high camouflage and species diversity, poses significant obstacles. Existing methods struggle with the fine-grained feature extraction needed to distinguish between closely related pest species. Although recent advancements have utilized modified network structures and combined deep learning approaches to improve accuracy, challenges persist due to the similarity between pests and their surroundings. To address this problem, we introduce InsectMamba, a novel approach that integrates State Space Models (SSMs), Convolutional Neural Networks (CNNs), Multi-Head Self-Attention mechanism (MSA), and Multilayer Perceptrons (MLPs) within Mix-SSM blocks. This integration facilitates the extraction of comprehensive visual features by leveraging the strengths of each encoding strategy. A selective module is also proposed to adaptively aggregate these features, enhancing the model's ability to discern pest characteristics. InsectMamba was evaluated against strong competitors across five insect pest classification datasets. The results demonstrate its superior performance and verify the significance of each model component by an ablation study.","sentences":["The classification of insect pests is a critical task in agricultural technology, vital for ensuring food security and environmental sustainability.","However, the complexity of pest identification, due to factors like high camouflage and species diversity, poses significant obstacles.","Existing methods struggle with the fine-grained feature extraction needed to distinguish between closely related pest species.","Although recent advancements have utilized modified network structures and combined deep learning approaches to improve accuracy, challenges persist due to the similarity between pests and their surroundings.","To address this problem, we introduce InsectMamba, a novel approach that integrates State Space Models (SSMs), Convolutional Neural Networks (CNNs), Multi-Head Self-Attention mechanism (MSA), and Multilayer Perceptrons (MLPs) within Mix-SSM blocks.","This integration facilitates the extraction of comprehensive visual features by leveraging the strengths of each encoding strategy.","A selective module is also proposed to adaptively aggregate these features, enhancing the model's ability to discern pest characteristics.","InsectMamba was evaluated against strong competitors across five insect pest classification datasets.","The results demonstrate its superior performance and verify the significance of each model component by an ablation study."],"url":"http://arxiv.org/abs/2404.03611v1","category":"cs.CV"}
{"created":"2024-04-04 17:34:08","title":"Deriving Compact QUBO Models via Multilevel Constraint Transformation","abstract":"With the advances in customized hardware for quantum annealing and digital/CMOS Annealing, Quadratic Unconstrained Binary Optimization (QUBO) models have received growing attention in the optimization literature. Motivated by an existing general-purpose approach that derives QUBO models from binary linear programs (BLP), we propose a novel Multilevel Constraint Transformation Scheme (MLCTS) that derives QUBO models with fewer ancillary binary variables. We formulate sufficient conditions for the existence of a compact QUBO formulation (i.e., in the original BLP decision space) in terms of constraint levelness and demonstrate the flexibility and applicability of MLCTS on synthetic examples and several well-known combinatorial optimization problems, i.e., the Maximum 2-Satisfiability Problem, the Linear Ordering Problem, the Community Detection Problem, and the Maximum Independence Set Problem. For a proof-of-concept, we compare the performance of two QUBO models for the latter problem on both a general-purpose software-based solver and a hardware-based QUBO solver. The MLCTS-derived models demonstrate significantly better performance for both solvers, in particular, solving up to seven times more instances with the hardware-based approach.","sentences":["With the advances in customized hardware for quantum annealing and digital/CMOS Annealing, Quadratic Unconstrained Binary Optimization (QUBO) models have received growing attention in the optimization literature.","Motivated by an existing general-purpose approach that derives QUBO models from binary linear programs (BLP), we propose a novel Multilevel Constraint Transformation Scheme (MLCTS) that derives QUBO models with fewer ancillary binary variables.","We formulate sufficient conditions for the existence of a compact QUBO formulation (i.e., in the original BLP decision space) in terms of constraint levelness and demonstrate the flexibility and applicability of MLCTS on synthetic examples and several well-known combinatorial optimization problems, i.e., the Maximum 2-Satisfiability Problem, the Linear Ordering Problem, the Community Detection Problem, and the Maximum Independence Set Problem.","For a proof-of-concept, we compare the performance of two QUBO models for the latter problem on both a general-purpose software-based solver and a hardware-based QUBO solver.","The MLCTS-derived models demonstrate significantly better performance for both solvers, in particular, solving up to seven times more instances with the hardware-based approach."],"url":"http://arxiv.org/abs/2404.03610v1","category":"quant-ph"}
{"created":"2024-04-04 17:31:32","title":"Sailor: Open Language Models for South-East Asia","abstract":"We present Sailor, a family of open language models ranging from 0.5B to 7B parameters, tailored for South-East Asian (SEA) languages. These models are continually pre-trained from Qwen1.5, a great language model for multilingual use cases. From Qwen1.5, Sailor models accept 200B to 400B tokens, primarily covering the languages of English, Chinese, Vietnamese, Thai, Indonesian, Malay, and Lao. The training leverages several techniques, including BPE dropout for improving the model robustness, aggressive data cleaning and deduplication, and small proxy models to optimize data mixture. Experimental results on four typical tasks indicate that Sailor models demonstrate strong performance across different benchmarks, including commonsense reasoning, question answering, reading comprehension and examination. Embracing the open-source spirit, we share our insights through this report to spark a wider interest in developing large language models for multilingual use cases.","sentences":["We present Sailor, a family of open language models ranging from 0.5B to 7B parameters, tailored for South-East Asian (SEA) languages.","These models are continually pre-trained from Qwen1.5, a great language model for multilingual use cases.","From Qwen1.5, Sailor models accept 200B to 400B tokens, primarily covering the languages of English, Chinese, Vietnamese, Thai, Indonesian, Malay, and Lao.","The training leverages several techniques, including BPE dropout for improving the model robustness, aggressive data cleaning and deduplication, and small proxy models to optimize data mixture.","Experimental results on four typical tasks indicate that Sailor models demonstrate strong performance across different benchmarks, including commonsense reasoning, question answering, reading comprehension and examination.","Embracing the open-source spirit, we share our insights through this report to spark a wider interest in developing large language models for multilingual use cases."],"url":"http://arxiv.org/abs/2404.03608v1","category":"cs.CL"}
{"created":"2024-04-04 17:28:43","title":"Testing the Boundary-to-Bound Correspondence with Numerical Relativity","abstract":"The Boundary-to-Bound (B2B) correspondence, which connects orbital and radiative observables between bound and unbound orbits, has recently been introduced and demonstrated in the perturbative regime. We produce a large number of numerical relativity simulations of bound and unbound encounters between two nonspinning equal mass black holes in order to test this correspondence in the non-perturbative regime. We focus on testing the radiated energy and angular momentum, as well as orbital parameters such as the period and periastron advance. We find that, across a wide range of eccentricities, the B2B relationships do not hold in the non-perturbative regime, thereby placing a clear limit on the applicability of these relationships. We also approximate the separatrix between bound and unbound relativistic encounters as a function of their initial energies and angular momenta.","sentences":["The Boundary-to-Bound (B2B) correspondence, which connects orbital and radiative observables between bound and unbound orbits, has recently been introduced and demonstrated in the perturbative regime.","We produce a large number of numerical relativity simulations of bound and unbound encounters between two nonspinning equal mass black holes in order to test this correspondence in the non-perturbative regime.","We focus on testing the radiated energy and angular momentum, as well as orbital parameters such as the period and periastron advance.","We find that, across a wide range of eccentricities, the B2B relationships do not hold in the non-perturbative regime, thereby placing a clear limit on the applicability of these relationships.","We also approximate the separatrix between bound and unbound relativistic encounters as a function of their initial energies and angular momenta."],"url":"http://arxiv.org/abs/2404.03607v1","category":"gr-qc"}
{"created":"2024-04-04 17:25:31","title":"Analyzing Musical Characteristics of National Anthems in Relation to Global Indices","abstract":"Music plays a huge part in shaping peoples' psychology and behavioral patterns. This paper investigates the connection between national anthems and different global indices with computational music analysis and statistical correlation analysis. We analyze national anthem musical data to determine whether certain musical characteristics are associated with peace, happiness, suicide rate, crime rate, etc. To achieve this, we collect national anthems from 169 countries and use computational music analysis techniques to extract pitch, tempo, beat, and other pertinent audio features. We then compare these musical characteristics with data on different global indices to ascertain whether a significant correlation exists. Our findings indicate that there may be a correlation between the musical characteristics of national anthems and the indices we investigated. The implications of our findings for music psychology and policymakers interested in promoting social well-being are discussed. This paper emphasizes the potential of musical data analysis in social research and offers a novel perspective on the relationship between music and social indices. The source code and data are made open-access for reproducibility and future research endeavors. It can be accessed at http://bit.ly/na_code.","sentences":["Music plays a huge part in shaping peoples' psychology and behavioral patterns.","This paper investigates the connection between national anthems and different global indices with computational music analysis and statistical correlation analysis.","We analyze national anthem musical data to determine whether certain musical characteristics are associated with peace, happiness, suicide rate, crime rate, etc.","To achieve this, we collect national anthems from 169 countries and use computational music analysis techniques to extract pitch, tempo, beat, and other pertinent audio features.","We then compare these musical characteristics with data on different global indices to ascertain whether a significant correlation exists.","Our findings indicate that there may be a correlation between the musical characteristics of national anthems and the indices we investigated.","The implications of our findings for music psychology and policymakers interested in promoting social well-being are discussed.","This paper emphasizes the potential of musical data analysis in social research and offers a novel perspective on the relationship between music and social indices.","The source code and data are made open-access for reproducibility and future research endeavors.","It can be accessed at http://bit.ly/na_code."],"url":"http://arxiv.org/abs/2404.03606v1","category":"cs.SD"}
{"created":"2024-04-04 17:19:19","title":"Trimming Five Generated Gorenstein Ideals","abstract":"Let $(R,\\mathfrak{m},\\Bbbk)$ be a regular local ring of dimension 3. Let $I$ be a Gorenstein ideal of $R$ of grade 3. It follows from a result of Buchsbaum and Eisenbud that there is a skew-symmetric matrix of odd size such that $I$ is generated by the sub-maximal pfaffians of this matrix. Let $J$ be the ideal obtained by multiplying some of the pfaffian generators of $I$ by $\\mathfrak{m}$; we say that $J$ is a trimming of $I$. In a previous work, the first author and A. Hardesty constructed an explicit free resolution of $R/J$ and computed a DG algebra structure on this resolution. They utilized these products to analyze the Tor algebra of such trimmed ideals. Missing from their result was the case where $I$ is five generated. In this paper we address this case.","sentences":["Let $(R,\\mathfrak{m},\\Bbbk)$ be a regular local ring of dimension 3.","Let $I$ be a Gorenstein ideal of $R$ of grade 3.","It follows from a result of Buchsbaum and Eisenbud that there is a skew-symmetric matrix of odd size such that $I$ is generated by the sub-maximal pfaffians of this matrix.","Let $J$ be the ideal obtained by multiplying some of the pfaffian generators of $I$ by $\\mathfrak{m}$; we say that $J$ is a trimming of $I$. In a previous work, the first author and A. Hardesty constructed an explicit free resolution of $R/J$ and computed a DG algebra structure on this resolution.","They utilized these products to analyze the Tor algebra of such trimmed ideals.","Missing from their result was the case where $I$ is five generated.","In this paper we address this case."],"url":"http://arxiv.org/abs/2404.03601v1","category":"math.AC"}
{"created":"2024-04-04 17:18:38","title":"Deformation-induced CPT violation in entangled pairs of neutral kaons","abstract":"In this paper we consider description of kaon -- anti-kaon interference in the context of a theory with deformed $\\cal CPT$ symmetry. In the case of such theoretical models, deviations from the standard $\\cal CPT$ invariance is related to the momentum carried by the particles; in particular the rest masses of particles and antiparticles are equal. We find that the decay intensity of kaon -- anti-kaon pair has three contributing terms: the correct-parity, the wrong-parity, and the interference between them, all of which are affected by deformation. Using the fact that the presence of such terms were not observed we estimate the magnitude of deformation parameter $\\kappa \\gtrsim 10^{18}$ GeV, very close to the expected Planck mass scale. This raises hopes that the effect, if exists, could be detected in a near future accelerator experiments. An uncertainty of the energy measurement is crucial for accuracy of these predictions.","sentences":["In this paper we consider description of kaon -- anti-kaon interference in the context of a theory with deformed $\\cal CPT$ symmetry.","In the case of such theoretical models, deviations from the standard $\\cal CPT$ invariance is related to the momentum carried by the particles; in particular the rest masses of particles and antiparticles are equal.","We find that the decay intensity of kaon -- anti-kaon pair has three contributing terms: the correct-parity, the wrong-parity, and the interference between them, all of which are affected by deformation.","Using the fact that the presence of such terms were not observed we estimate the magnitude of deformation parameter $\\kappa \\gtrsim 10^{18}$ GeV, very close to the expected Planck mass scale.","This raises hopes that the effect, if exists, could be detected in a near future accelerator experiments.","An uncertainty of the energy measurement is crucial for accuracy of these predictions."],"url":"http://arxiv.org/abs/2404.03600v1","category":"hep-ph"}
{"created":"2024-04-04 17:10:32","title":"A mini-course on Generalized Symmetries and a relation to Cobordisms and K-theory","abstract":"This mini-course, conducted at the XI School on Geometric, Algebraic, and Topological Methods in Quantum Field Theory held in Villa de Leyva, Colombia, provides an overview of the interconnection between generalized symmetries and cohomology. It is designed for advanced undergraduate students with a background in physics or mathematics. Additionally, we describe a method for connecting generalized symmetries with cobordisms and K-theory within the framework of string theory. We assume basic knowledge in quantum field theory and differential forms.","sentences":["This mini-course, conducted at the XI School on Geometric, Algebraic, and Topological Methods in Quantum Field Theory held in Villa de Leyva, Colombia, provides an overview of the interconnection between generalized symmetries and cohomology.","It is designed for advanced undergraduate students with a background in physics or mathematics.","Additionally, we describe a method for connecting generalized symmetries with cobordisms and K-theory within the framework of string theory.","We assume basic knowledge in quantum field theory and differential forms."],"url":"http://arxiv.org/abs/2404.03599v1","category":"hep-th"}
{"created":"2024-04-04 17:09:52","title":"Intent Detection and Entity Extraction from BioMedical Literature","abstract":"Biomedical queries have become increasingly prevalent in web searches, reflecting the growing interest in accessing biomedical literature. Despite recent research on large-language models (LLMs) motivated by endeavours to attain generalized intelligence, their efficacy in replacing task and domain-specific natural language understanding approaches remains questionable. In this paper, we address this question by conducting a comprehensive empirical evaluation of intent detection and named entity recognition (NER) tasks from biomedical text. We show that Supervised Fine Tuned approaches are still relevant and more effective than general-purpose LLMs. Biomedical transformer models such as PubMedBERT can surpass ChatGPT on NER task with only 5 supervised examples.","sentences":["Biomedical queries have become increasingly prevalent in web searches, reflecting the growing interest in accessing biomedical literature.","Despite recent research on large-language models (LLMs) motivated by endeavours to attain generalized intelligence, their efficacy in replacing task and domain-specific natural language understanding approaches remains questionable.","In this paper, we address this question by conducting a comprehensive empirical evaluation of intent detection and named entity recognition (NER) tasks from biomedical text.","We show that Supervised Fine Tuned approaches are still relevant and more effective than general-purpose LLMs.","Biomedical transformer models such as PubMedBERT can surpass ChatGPT on NER task with only 5 supervised examples."],"url":"http://arxiv.org/abs/2404.03598v1","category":"cs.CL"}
{"created":"2024-04-04 17:08:47","title":"Chain union closures","abstract":"We study spherical completeness of ball spaces and its stability under expansions. We give some criteria for ball spaces that guarantee that spherical completeness is preserved when the ball space is closed under unions of chains. This applies in particular to the spaces of closed ultrametric balls in ultrametric spaces with linearly ordered value sets, or more generally, with countable narrow value sets. We show that in general, chain union closures of ultrametric spaces with partially ordered value sets do not preserve spherical completeness. Further, we introduce and study the notions of chain union stability and of chain union rank, which measure how often the process of closing a ball space under all unions of chains has to be iterated until a ball space is obtained that is closed under unions of chains.","sentences":["We study spherical completeness of ball spaces and its stability under expansions.","We give some criteria for ball spaces that guarantee that spherical completeness is preserved when the ball space is closed under unions of chains.","This applies in particular to the spaces of closed ultrametric balls in ultrametric spaces with linearly ordered value sets, or more generally, with countable narrow value sets.","We show that in general, chain union closures of ultrametric spaces with partially ordered value sets do not preserve spherical completeness.","Further, we introduce and study the notions of chain union stability and of chain union rank, which measure how often the process of closing a ball space under all unions of chains has to be iterated until a ball space is obtained that is closed under unions of chains."],"url":"http://arxiv.org/abs/2404.03597v1","category":"math.LO"}
{"created":"2024-04-04 17:05:42","title":"Laser Learning Environment: A new environment for coordination-critical multi-agent tasks","abstract":"We introduce the Laser Learning Environment (LLE), a collaborative multi-agent reinforcement learning environment in which coordination is central. In LLE, agents depend on each other to make progress (interdependence), must jointly take specific sequences of actions to succeed (perfect coordination), and accomplishing those joint actions does not yield any intermediate reward (zero-incentive dynamics). The challenge of such problems lies in the difficulty of escaping state space bottlenecks caused by interdependence steps since escaping those bottlenecks is not rewarded. We test multiple state-of-the-art value-based MARL algorithms against LLE and show that they consistently fail at the collaborative task because of their inability to escape state space bottlenecks, even though they successfully achieve perfect coordination. We show that Q-learning extensions such as prioritized experience replay and n-steps return hinder exploration in environments with zero-incentive dynamics, and find that intrinsic curiosity with random network distillation is not sufficient to escape those bottlenecks. We demonstrate the need for novel methods to solve this problem and the relevance of LLE as cooperative MARL benchmark.","sentences":["We introduce the Laser Learning Environment (LLE), a collaborative multi-agent reinforcement learning environment in which coordination is central.","In LLE, agents depend on each other to make progress (interdependence), must jointly take specific sequences of actions to succeed (perfect coordination), and accomplishing those joint actions does not yield any intermediate reward (zero-incentive dynamics).","The challenge of such problems lies in the difficulty of escaping state space bottlenecks caused by interdependence steps since escaping those bottlenecks is not rewarded.","We test multiple state-of-the-art value-based MARL algorithms against LLE and show that they consistently fail at the collaborative task because of their inability to escape state space bottlenecks, even though they successfully achieve perfect coordination.","We show that Q-learning extensions such as prioritized experience replay and n-steps return hinder exploration in environments with zero-incentive dynamics, and find that intrinsic curiosity with random network distillation is not sufficient to escape those bottlenecks.","We demonstrate the need for novel methods to solve this problem and the relevance of LLE as cooperative MARL benchmark."],"url":"http://arxiv.org/abs/2404.03596v1","category":"cs.LG"}
{"created":"2024-04-04 17:02:08","title":"Setpoint control of bilinear systems from noisy data","abstract":"We consider the problem of designing a controller for an unknown bilinear system using only noisy input-states data points generated by it. The controller should achieve regulation to a given state setpoint and provide a guaranteed basin of attraction. Determining the equilibrium input to achieve that setpoint is not trivial in a data-based setting and we propose the design of a controller in two scenarios. The design takes the form of linear matrix inequalities and is validated numerically for a Cuk converter.","sentences":["We consider the problem of designing a controller for an unknown bilinear system using only noisy input-states data points generated by it.","The controller should achieve regulation to a given state setpoint and provide a guaranteed basin of attraction.","Determining the equilibrium input to achieve that setpoint is not trivial in a data-based setting and we propose the design of a controller in two scenarios.","The design takes the form of linear matrix inequalities and is validated numerically for a Cuk converter."],"url":"http://arxiv.org/abs/2404.03594v1","category":"eess.SY"}
{"created":"2024-04-04 17:00:37","title":"ReFT: Representation Finetuning for Language Models","abstract":"Parameter-efficient fine-tuning (PEFT) methods seek to adapt large models via updates to a small number of weights. However, much prior interpretability work has shown that representations encode rich semantic information, suggesting that editing representations might be a more powerful alternative. Here, we pursue this hypothesis by developing a family of $\\textbf{Representation Finetuning (ReFT)}$ methods. ReFT methods operate on a frozen base model and learn task-specific interventions on hidden representations. We define a strong instance of the ReFT family, Low-rank Linear Subspace ReFT (LoReFT). LoReFT is a drop-in replacement for existing PEFTs and learns interventions that are 10x-50x more parameter-efficient than prior state-of-the-art PEFTs. We showcase LoReFT on eight commonsense reasoning tasks, four arithmetic reasoning tasks, Alpaca-Eval v1.0, and GLUE. In all these evaluations, LoReFT delivers the best balance of efficiency and performance, and almost always outperforms state-of-the-art PEFTs. We release a generic ReFT training library publicly at https://github.com/stanfordnlp/pyreft.","sentences":["Parameter-efficient fine-tuning (PEFT) methods seek to adapt large models via updates to a small number of weights.","However, much prior interpretability work has shown that representations encode rich semantic information, suggesting that editing representations might be a more powerful alternative.","Here, we pursue this hypothesis by developing a family of $\\textbf{Representation Finetuning (ReFT)}$ methods.","ReFT methods operate on a frozen base model and learn task-specific interventions on hidden representations.","We define a strong instance of the ReFT family, Low-rank Linear Subspace ReFT (LoReFT).","LoReFT is a drop-in replacement for existing PEFTs and learns interventions that are 10x-50x more parameter-efficient than prior state-of-the-art PEFTs.","We showcase LoReFT on eight commonsense reasoning tasks, four arithmetic reasoning tasks, Alpaca-Eval v1.0, and GLUE.","In all these evaluations, LoReFT delivers the best balance of efficiency and performance, and almost always outperforms state-of-the-art PEFTs.","We release a generic ReFT training library publicly at https://github.com/stanfordnlp/pyreft."],"url":"http://arxiv.org/abs/2404.03592v1","category":"cs.CL"}
{"created":"2024-04-04 16:58:26","title":"SemGrasp: Semantic Grasp Generation via Language Aligned Discretization","abstract":"Generating natural human grasps necessitates consideration of not just object geometry but also semantic information. Solely depending on object shape for grasp generation confines the applications of prior methods in downstream tasks. This paper presents a novel semantic-based grasp generation method, termed SemGrasp, which generates a static human grasp pose by incorporating semantic information into the grasp representation. We introduce a discrete representation that aligns the grasp space with semantic space, enabling the generation of grasp postures in accordance with language instructions. A Multimodal Large Language Model (MLLM) is subsequently fine-tuned, integrating object, grasp, and language within a unified semantic space. To facilitate the training of SemGrasp, we have compiled a large-scale, grasp-text-aligned dataset named CapGrasp, featuring about 260k detailed captions and 50k diverse grasps. Experimental findings demonstrate that SemGrasp efficiently generates natural human grasps in alignment with linguistic intentions. Our code, models, and dataset are available publicly at: https://kailinli.github.io/SemGrasp.","sentences":["Generating natural human grasps necessitates consideration of not just object geometry but also semantic information.","Solely depending on object shape for grasp generation confines the applications of prior methods in downstream tasks.","This paper presents a novel semantic-based grasp generation method, termed SemGrasp, which generates a static human grasp pose by incorporating semantic information into the grasp representation.","We introduce a discrete representation that aligns the grasp space with semantic space, enabling the generation of grasp postures in accordance with language instructions.","A Multimodal Large Language Model (MLLM) is subsequently fine-tuned, integrating object, grasp, and language within a unified semantic space.","To facilitate the training of SemGrasp, we have compiled a large-scale, grasp-text-aligned dataset named CapGrasp, featuring about 260k detailed captions and 50k diverse grasps.","Experimental findings demonstrate that SemGrasp efficiently generates natural human grasps in alignment with linguistic intentions.","Our code, models, and dataset are available publicly at: https://kailinli.github.io/SemGrasp."],"url":"http://arxiv.org/abs/2404.03590v1","category":"cs.CV"}
{"created":"2024-04-04 16:52:48","title":"Anticipate & Collab: Data-driven Task Anticipation and Knowledge-driven Planning for Human-robot Collaboration","abstract":"An agent assisting humans in daily living activities can collaborate more effectively by anticipating upcoming tasks. Data-driven methods represent the state of the art in task anticipation, planning, and related problems, but these methods are resource-hungry and opaque. Our prior work introduced a proof of concept framework that used an LLM to anticipate 3 high-level tasks that served as goals for a classical planning system that computed a sequence of low-level actions for the agent to achieve these goals. This paper describes DaTAPlan, our framework that significantly extends our prior work toward human-robot collaboration. Specifically, DaTAPlan planner computes actions for an agent and a human to collaboratively and jointly achieve the tasks anticipated by the LLM, and the agent automatically adapts to unexpected changes in human action outcomes and preferences. We evaluate DaTAPlan capabilities in a realistic simulation environment, demonstrating accurate task anticipation, effective human-robot collaboration, and the ability to adapt to unexpected changes. Project website: https://dataplan-hrc.github.io","sentences":["An agent assisting humans in daily living activities can collaborate more effectively by anticipating upcoming tasks.","Data-driven methods represent the state of the art in task anticipation, planning, and related problems, but these methods are resource-hungry and opaque.","Our prior work introduced a proof of concept framework that used an LLM to anticipate 3 high-level tasks that served as goals for a classical planning system that computed a sequence of low-level actions for the agent to achieve these goals.","This paper describes DaTAPlan, our framework that significantly extends our prior work toward human-robot collaboration.","Specifically, DaTAPlan planner computes actions for an agent and a human to collaboratively and jointly achieve the tasks anticipated by the LLM, and the agent automatically adapts to unexpected changes in human action outcomes and preferences.","We evaluate DaTAPlan capabilities in a realistic simulation environment, demonstrating accurate task anticipation, effective human-robot collaboration, and the ability to adapt to unexpected changes.","Project website: https://dataplan-hrc.github.io"],"url":"http://arxiv.org/abs/2404.03587v1","category":"cs.RO"}
{"created":"2024-04-04 16:52:17","title":"Leveraging Interpolation Models and Error Bounds for Verifiable Scientific Machine Learning","abstract":"Effective verification and validation techniques for modern scientific machine learning workflows are challenging to devise. Statistical methods are abundant and easily deployed, but often rely on speculative assumptions about the data and methods involved. Error bounds for classical interpolation techniques can provide mathematically rigorous estimates of accuracy, but often are difficult or impractical to determine computationally. In this work, we present a best-of-both-worlds approach to verifiable scientific machine learning by demonstrating that (1) multiple standard interpolation techniques have informative error bounds that can be computed or estimated efficiently; (2) comparative performance among distinct interpolants can aid in validation goals; (3) deploying interpolation methods on latent spaces generated by deep learning techniques enables some interpretability for black-box models. We present a detailed case study of our approach for predicting lift-drag ratios from airfoil images. Code developed for this work is available in a public Github repository.","sentences":["Effective verification and validation techniques for modern scientific machine learning workflows are challenging to devise.","Statistical methods are abundant and easily deployed, but often rely on speculative assumptions about the data and methods involved.","Error bounds for classical interpolation techniques can provide mathematically rigorous estimates of accuracy, but often are difficult or impractical to determine computationally.","In this work, we present a best-of-both-worlds approach to verifiable scientific machine learning by demonstrating that (1) multiple standard interpolation techniques have informative error bounds that can be computed or estimated efficiently; (2) comparative performance among distinct interpolants can aid in validation goals; (3) deploying interpolation methods on latent spaces generated by deep learning techniques enables some interpretability for black-box models.","We present a detailed case study of our approach for predicting lift-drag ratios from airfoil images.","Code developed for this work is available in a public Github repository."],"url":"http://arxiv.org/abs/2404.03586v1","category":"cs.LG"}
{"created":"2024-04-04 16:43:40","title":"Consumer Behavior under Benevolent Price Discrimination","abstract":"Extensive research shows that consumers are generally averse to price discrimination. However, instruments of differential pricing can benefit consumer surplus and alleviate inequity through targeted price discounts. This paper examines how these outcome considerations influence consumer reactions to price discrimination. Six studies with 3951 participants show that a large share of consumers is willing to costly switch away from a store that introduces a discount for low-income consumers. This happens irrespective of whether income differences are due to luck or merit. While the price-discriminating store does attract some new high-income consumers, it cannot compensate the loss of existing consumers. Allowing for altruistic preferences by simulating a market mechanism increases costly support for price discounts, but does not alleviate consumer aversions. Finally, we provide evidence that warm glow drives costly support for price discounts.","sentences":["Extensive research shows that consumers are generally averse to price discrimination.","However, instruments of differential pricing can benefit consumer surplus and alleviate inequity through targeted price discounts.","This paper examines how these outcome considerations influence consumer reactions to price discrimination.","Six studies with 3951 participants show that a large share of consumers is willing to costly switch away from a store that introduces a discount for low-income consumers.","This happens irrespective of whether income differences are due to luck or merit.","While the price-discriminating store does attract some new high-income consumers, it cannot compensate the loss of existing consumers.","Allowing for altruistic preferences by simulating a market mechanism increases costly support for price discounts, but does not alleviate consumer aversions.","Finally, we provide evidence that warm glow drives costly support for price discounts."],"url":"http://arxiv.org/abs/2404.03581v1","category":"econ.GN"}
{"created":"2024-04-04 16:40:22","title":"Distributionally Robust Reinforcement Learning with Interactive Data Collection: Fundamental Hardness and Near-Optimal Algorithm","abstract":"The sim-to-real gap, which represents the disparity between training and testing environments, poses a significant challenge in reinforcement learning (RL). A promising approach to addressing this challenge is distributionally robust RL, often framed as a robust Markov decision process (RMDP). In this framework, the objective is to find a robust policy that achieves good performance under the worst-case scenario among all environments within a pre-specified uncertainty set centered around the training environment. Unlike previous work, which relies on a generative model or a pre-collected offline dataset enjoying good coverage of the deployment environment, we tackle robust RL via interactive data collection, where the learner interacts with the training environment only and refines the policy through trial and error. In this robust RL paradigm, two main challenges emerge: managing distributional robustness while striking a balance between exploration and exploitation during data collection. Initially, we establish that sample-efficient learning without additional assumptions is unattainable owing to the curse of support shift; i.e., the potential disjointedness of the distributional supports between the training and testing environments. To circumvent such a hardness result, we introduce the vanishing minimal value assumption to RMDPs with a total-variation (TV) distance robust set, postulating that the minimal value of the optimal robust value function is zero. We prove that such an assumption effectively eliminates the support shift issue for RMDPs with a TV distance robust set, and present an algorithm with a provable sample complexity guarantee. Our work makes the initial step to uncovering the inherent difficulty of robust RL via interactive data collection and sufficient conditions for designing a sample-efficient algorithm accompanied by sharp sample complexity analysis.","sentences":["The sim-to-real gap, which represents the disparity between training and testing environments, poses a significant challenge in reinforcement learning (RL).","A promising approach to addressing this challenge is distributionally robust RL, often framed as a robust Markov decision process (RMDP).","In this framework, the objective is to find a robust policy that achieves good performance under the worst-case scenario among all environments within a pre-specified uncertainty set centered around the training environment.","Unlike previous work, which relies on a generative model or a pre-collected offline dataset enjoying good coverage of the deployment environment, we tackle robust RL via interactive data collection, where the learner interacts with the training environment only and refines the policy through trial and error.","In this robust RL paradigm, two main challenges emerge: managing distributional robustness while striking a balance between exploration and exploitation during data collection.","Initially, we establish that sample-efficient learning without additional assumptions is unattainable owing to the curse of support shift; i.e., the potential disjointedness of the distributional supports between the training and testing environments.","To circumvent such a hardness result, we introduce the vanishing minimal value assumption to RMDPs with a total-variation (TV) distance robust set, postulating that the minimal value of the optimal robust value function is zero.","We prove that such an assumption effectively eliminates the support shift issue for RMDPs with a TV distance robust set, and present an algorithm with a provable sample complexity guarantee.","Our work makes the initial step to uncovering the inherent difficulty of robust RL via interactive data collection and sufficient conditions for designing a sample-efficient algorithm accompanied by sharp sample complexity analysis."],"url":"http://arxiv.org/abs/2404.03578v1","category":"cs.LG"}
{"created":"2024-04-04 16:38:57","title":"DreamScene: 3D Gaussian-based Text-to-3D Scene Generation via Formation Pattern Sampling","abstract":"Text-to-3D scene generation holds immense potential for the gaming, film, and architecture sectors. Despite significant progress, existing methods struggle with maintaining high quality, consistency, and editing flexibility. In this paper, we propose DreamScene, a 3D Gaussian-based novel text-to-3D scene generation framework, to tackle the aforementioned three challenges mainly via two strategies. First, DreamScene employs Formation Pattern Sampling (FPS), a multi-timestep sampling strategy guided by the formation patterns of 3D objects, to form fast, semantically rich, and high-quality representations. FPS uses 3D Gaussian filtering for optimization stability, and leverages reconstruction techniques to generate plausible textures. Second, DreamScene employs a progressive three-stage camera sampling strategy, specifically designed for both indoor and outdoor settings, to effectively ensure object-environment integration and scene-wide 3D consistency. Last, DreamScene enhances scene editing flexibility by integrating objects and environments, enabling targeted adjustments. Extensive experiments validate DreamScene's superiority over current state-of-the-art techniques, heralding its wide-ranging potential for diverse applications. Code and demos will be released at https://dreamscene-project.github.io .","sentences":["Text-to-3D scene generation holds immense potential for the gaming, film, and architecture sectors.","Despite significant progress, existing methods struggle with maintaining high quality, consistency, and editing flexibility.","In this paper, we propose DreamScene, a 3D Gaussian-based novel text-to-3D scene generation framework, to tackle the aforementioned three challenges mainly via two strategies.","First, DreamScene employs Formation Pattern Sampling (FPS), a multi-timestep sampling strategy guided by the formation patterns of 3D objects, to form fast, semantically rich, and high-quality representations.","FPS uses 3D Gaussian filtering for optimization stability, and leverages reconstruction techniques to generate plausible textures.","Second, DreamScene employs a progressive three-stage camera sampling strategy, specifically designed for both indoor and outdoor settings, to effectively ensure object-environment integration and scene-wide 3D consistency.","Last, DreamScene enhances scene editing flexibility by integrating objects and environments, enabling targeted adjustments.","Extensive experiments validate DreamScene's superiority over current state-of-the-art techniques, heralding its wide-ranging potential for diverse applications.","Code and demos will be released at https://dreamscene-project.github.io ."],"url":"http://arxiv.org/abs/2404.03575v1","category":"cs.CV"}
{"created":"2024-04-04 16:38:49","title":"TinyVQA: Compact Multimodal Deep Neural Network for Visual Question Answering on Resource-Constrained Devices","abstract":"Traditional machine learning models often require powerful hardware, making them unsuitable for deployment on resource-limited devices. Tiny Machine Learning (tinyML) has emerged as a promising approach for running machine learning models on these devices, but integrating multiple data modalities into tinyML models still remains a challenge due to increased complexity, latency, and power consumption. This paper proposes TinyVQA, a novel multimodal deep neural network for visual question answering tasks that can be deployed on resource-constrained tinyML hardware. TinyVQA leverages a supervised attention-based model to learn how to answer questions about images using both vision and language modalities. Distilled knowledge from the supervised attention-based VQA model trains the memory aware compact TinyVQA model and low bit-width quantization technique is employed to further compress the model for deployment on tinyML devices. The TinyVQA model was evaluated on the FloodNet dataset, which is used for post-disaster damage assessment. The compact model achieved an accuracy of 79.5%, demonstrating the effectiveness of TinyVQA for real-world applications. Additionally, the model was deployed on a Crazyflie 2.0 drone, equipped with an AI deck and GAP8 microprocessor. The TinyVQA model achieved low latencies of 56 ms and consumes 693 mW power while deployed on the tiny drone, showcasing its suitability for resource-constrained embedded systems.","sentences":["Traditional machine learning models often require powerful hardware, making them unsuitable for deployment on resource-limited devices.","Tiny Machine Learning (tinyML) has emerged as a promising approach for running machine learning models on these devices, but integrating multiple data modalities into tinyML models still remains a challenge due to increased complexity, latency, and power consumption.","This paper proposes TinyVQA, a novel multimodal deep neural network for visual question answering tasks that can be deployed on resource-constrained tinyML hardware.","TinyVQA leverages a supervised attention-based model to learn how to answer questions about images using both vision and language modalities.","Distilled knowledge from the supervised attention-based VQA model trains the memory aware compact TinyVQA model and low bit-width quantization technique is employed to further compress the model for deployment on tinyML devices.","The TinyVQA model was evaluated on the FloodNet dataset, which is used for post-disaster damage assessment.","The compact model achieved an accuracy of 79.5%, demonstrating the effectiveness of TinyVQA for real-world applications.","Additionally, the model was deployed on a Crazyflie 2.0 drone, equipped with an AI deck and GAP8 microprocessor.","The TinyVQA model achieved low latencies of 56 ms and consumes 693 mW power while deployed on the tiny drone, showcasing its suitability for resource-constrained embedded systems."],"url":"http://arxiv.org/abs/2404.03574v1","category":"cs.CV"}
{"created":"2024-04-04 16:25:23","title":"Factored Task and Motion Planning with Combined Optimization, Sampling and Learning","abstract":"In this thesis, we aim to improve the performance of TAMP algorithms from three complementary perspectives. First, we investigate the integration of discrete task planning with continuous trajectory optimization. Our main contribution is a conflict-based solver that automatically discovers why a task plan might fail when considering the constraints of the physical world. This information is then fed back into the task planner, resulting in an efficient, bidirectional, and intuitive interface between task and motion, capable of solving TAMP problems with multiple objects, robots, and tight physical constraints. In the second part, we first illustrate that, given the wide range of tasks and environments within TAMP, neither sampling nor optimization is superior in all settings. To combine the strengths of both approaches, we have designed meta-solvers for TAMP, adaptive solvers that automatically select which algorithms and computations to use and how to best decompose each problem to find a solution faster. In the third part, we combine deep learning architectures with model-based reasoning to accelerate computations within our TAMP solver. Specifically, we target infeasibility detection and nonlinear optimization, focusing on generalization, accuracy, compute time, and data efficiency. At the core of our contributions is a refined, factored representation of the trajectory optimization problems inside TAMP. This structure not only facilitates more efficient planning, encoding of geometric infeasibility, and meta-reasoning but also provides better generalization in neural architectures.","sentences":["In this thesis, we aim to improve the performance of TAMP algorithms from three complementary perspectives.","First, we investigate the integration of discrete task planning with continuous trajectory optimization.","Our main contribution is a conflict-based solver that automatically discovers why a task plan might fail when considering the constraints of the physical world.","This information is then fed back into the task planner, resulting in an efficient, bidirectional, and intuitive interface between task and motion, capable of solving TAMP problems with multiple objects, robots, and tight physical constraints.","In the second part, we first illustrate that, given the wide range of tasks and environments within TAMP, neither sampling nor optimization is superior in all settings.","To combine the strengths of both approaches, we have designed meta-solvers for TAMP, adaptive solvers that automatically select which algorithms and computations to use and how to best decompose each problem to find a solution faster.","In the third part, we combine deep learning architectures with model-based reasoning to accelerate computations within our TAMP solver.","Specifically, we target infeasibility detection and nonlinear optimization, focusing on generalization, accuracy, compute time, and data efficiency.","At the core of our contributions is a refined, factored representation of the trajectory optimization problems inside TAMP.","This structure not only facilitates more efficient planning, encoding of geometric infeasibility, and meta-reasoning but also provides better generalization in neural architectures."],"url":"http://arxiv.org/abs/2404.03567v1","category":"cs.RO"}
{"created":"2024-04-04 16:24:32","title":"PointInfinity: Resolution-Invariant Point Diffusion Models","abstract":"We present PointInfinity, an efficient family of point cloud diffusion models. Our core idea is to use a transformer-based architecture with a fixed-size, resolution-invariant latent representation. This enables efficient training with low-resolution point clouds, while allowing high-resolution point clouds to be generated during inference. More importantly, we show that scaling the test-time resolution beyond the training resolution improves the fidelity of generated point clouds and surfaces. We analyze this phenomenon and draw a link to classifier-free guidance commonly used in diffusion models, demonstrating that both allow trading off fidelity and variability during inference. Experiments on CO3D show that PointInfinity can efficiently generate high-resolution point clouds (up to 131k points, 31 times more than Point-E) with state-of-the-art quality.","sentences":["We present PointInfinity, an efficient family of point cloud diffusion models.","Our core idea is to use a transformer-based architecture with a fixed-size, resolution-invariant latent representation.","This enables efficient training with low-resolution point clouds, while allowing high-resolution point clouds to be generated during inference.","More importantly, we show that scaling the test-time resolution beyond the training resolution improves the fidelity of generated point clouds and surfaces.","We analyze this phenomenon and draw a link to classifier-free guidance commonly used in diffusion models, demonstrating that both allow trading off fidelity and variability during inference.","Experiments on CO3D show that PointInfinity can efficiently generate high-resolution point clouds (up to 131k points, 31 times more than Point-E) with state-of-the-art quality."],"url":"http://arxiv.org/abs/2404.03566v1","category":"cs.CV"}
{"created":"2024-04-04 16:20:34","title":"Personalized LLM Response Generation with Parameterized Memory Injection","abstract":"Large Language Models (LLMs) have exhibited remarkable proficiency in comprehending and generating natural language. On the other hand, personalized LLM response generation holds the potential to offer substantial benefits for individuals in critical areas such as medical. Existing research has explored memory-augmented methods to prompt the LLM with pre-stored user-specific knowledge for personalized response generation in terms of new queries. We contend that such paradigm is unable to perceive fine-granularity information. In this study, we propose a novel \\textbf{M}emory-\\textbf{i}njected approach using parameter-efficient fine-tuning (PEFT) and along with a Bayesian Optimisation searching strategy to achieve \\textbf{L}LM \\textbf{P}ersonalization(\\textbf{MiLP}).","sentences":["Large Language Models (LLMs) have exhibited remarkable proficiency in comprehending and generating natural language.","On the other hand, personalized LLM response generation holds the potential to offer substantial benefits for individuals in critical areas such as medical.","Existing research has explored memory-augmented methods to prompt the LLM with pre-stored user-specific knowledge for personalized response generation in terms of new queries.","We contend that such paradigm is unable to perceive fine-granularity information.","In this study, we propose a novel \\textbf{M}emory-\\textbf{i}njected approach using parameter-efficient fine-tuning (PEFT) and along with a Bayesian Optimisation searching strategy to achieve \\textbf{L}LM \\textbf{P}ersonalization(\\textbf{MiLP})."],"url":"http://arxiv.org/abs/2404.03565v1","category":"cs.CL"}
{"created":"2024-04-04 16:20:07","title":"Polytope symmetries of Feynman integrals","abstract":"Feynman integrals appropriately generalized are $\\mathsf A$-hypergeometric functions. Among the properties of $\\mathsf A$-hypergeometric functions are symmetries associated with the Newton polytope. In ordinary hypergeometric functions these symmetries lead to linear transformations. Combining tools of $\\mathsf A$-hypergeometric systems and the computation of symmetries of polytopes, we consider the associated symmetries of Feynman integrals in the Lee-Pomeransky representation. We compute the symmetries of $\\mathtt n$-gon integrals up to $\\mathtt n=8$, massive banana integrals up to 5-loop, and on-shell ladders up to 3-loop. We apply these symmetries to study finite on-shell ladder integrals up to 3-loop.","sentences":["Feynman integrals appropriately generalized are $\\mathsf A$-hypergeometric functions.","Among the properties of $\\mathsf A$-hypergeometric functions are symmetries associated with the Newton polytope.","In ordinary hypergeometric functions these symmetries lead to linear transformations.","Combining tools of $\\mathsf A$-hypergeometric systems and the computation of symmetries of polytopes, we consider the associated symmetries of Feynman integrals in the Lee-Pomeransky representation.","We compute the symmetries of $\\mathtt n$-gon integrals up to $\\mathtt n=8$, massive banana integrals up to 5-loop, and on-shell ladders up to 3-loop.","We apply these symmetries to study finite on-shell ladder integrals up to 3-loop."],"url":"http://arxiv.org/abs/2404.03564v1","category":"hep-th"}
{"created":"2024-04-04 17:36:24","title":"Collective coupling of driven multilevel atoms and its effect on four-wave mixing","abstract":"Microscopic models based on multilevel atoms are central to controlling non-linear optical responses and coherent control of light. These models are traditionally based on single-atom responses that are then parametrically extrapolated to include collective effects, such as an enhanced response or propagation within the medium. In this work we present a systematic analysis of the cooperative effects arising in driven systems composed of multi-level atoms coupled by a common electromagnetic environment. The analysis is based on an interplay between dressed states induced by the driving field, photon exchanges, and the collective decay channels. This theory is applied to the case of four-wave mixing mediated by a pair of atoms in the diamond configuration, a nonlinear process commonly used to create correlated photon pairs. The effects of inter-atomic correlations and collective decay channels over outgoing photons are then explored. We find that the resulting correlation function changes from a Lorentzian distribution for independent atoms to a two-peaked distribution when dipole-dipole interactions are included. The two-peak structure is related to a joint action between the dressed states and the collective decay channels. Signatures of these processes are identified for existing experimental realizations. The intuition obtained from this connection helps to uncover relevant parameters that could be exploited for quantum control protocols based on dispersive and dissipative cooperative effects in multi-level systems.","sentences":["Microscopic models based on multilevel atoms are central to controlling non-linear optical responses and coherent control of light.","These models are traditionally based on single-atom responses that are then parametrically extrapolated to include collective effects, such as an enhanced response or propagation within the medium.","In this work we present a systematic analysis of the cooperative effects arising in driven systems composed of multi-level atoms coupled by a common electromagnetic environment.","The analysis is based on an interplay between dressed states induced by the driving field, photon exchanges, and the collective decay channels.","This theory is applied to the case of four-wave mixing mediated by a pair of atoms in the diamond configuration, a nonlinear process commonly used to create correlated photon pairs.","The effects of inter-atomic correlations and collective decay channels over outgoing photons are then explored.","We find that the resulting correlation function changes from a Lorentzian distribution for independent atoms to a two-peaked distribution when dipole-dipole interactions are included.","The two-peak structure is related to a joint action between the dressed states and the collective decay channels.","Signatures of these processes are identified for existing experimental realizations.","The intuition obtained from this connection helps to uncover relevant parameters that could be exploited for quantum control protocols based on dispersive and dissipative cooperative effects in multi-level systems."],"url":"http://arxiv.org/abs/2404.03615v1","category":"quant-ph"}
{"created":"2024-04-04 17:19:47","title":"Evaluating LLMs at Detecting Errors in LLM Responses","abstract":"With Large Language Models (LLMs) being widely used across various tasks, detecting errors in their responses is increasingly crucial. However, little research has been conducted on error detection of LLM responses. Collecting error annotations on LLM responses is challenging due to the subjective nature of many NLP tasks, and thus previous research focuses on tasks of little practical value (e.g., word sorting) or limited error types (e.g., faithfulness in summarization). This work introduces ReaLMistake, the first error detection benchmark consisting of objective, realistic, and diverse errors made by LLMs. ReaLMistake contains three challenging and meaningful tasks that introduce objectively assessable errors in four categories (reasoning correctness, instruction-following, context-faithfulness, and parameterized knowledge), eliciting naturally observed and diverse errors in responses of GPT-4 and Llama 2 70B annotated by experts. We use ReaLMistake to evaluate error detectors based on 12 LLMs. Our findings show: 1) Top LLMs like GPT-4 and Claude 3 detect errors made by LLMs at very low recall, and all LLM-based error detectors perform much worse than humans. 2) Explanations by LLM-based error detectors lack reliability. 3) LLMs-based error detection is sensitive to small changes in prompts but remains challenging to improve. 4) Popular approaches to improving LLMs, including self-consistency and majority vote, do not improve the error detection performance. Our benchmark and code are provided at https://github.com/psunlpgroup/ReaLMistake.","sentences":["With Large Language Models (LLMs) being widely used across various tasks, detecting errors in their responses is increasingly crucial.","However, little research has been conducted on error detection of LLM responses.","Collecting error annotations on LLM responses is challenging due to the subjective nature of many NLP tasks, and thus previous research focuses on tasks of little practical value (e.g., word sorting) or limited error types (e.g., faithfulness in summarization).","This work introduces ReaLMistake, the first error detection benchmark consisting of objective, realistic, and diverse errors made by LLMs.","ReaLMistake contains three challenging and meaningful tasks that introduce objectively assessable errors in four categories (reasoning correctness, instruction-following, context-faithfulness, and parameterized knowledge), eliciting naturally observed and diverse errors in responses of GPT-4 and Llama 2 70B annotated by experts.","We use ReaLMistake to evaluate error detectors based on 12 LLMs.","Our findings show: 1) Top LLMs like GPT-4 and Claude 3 detect errors made by LLMs at very low recall, and all LLM-based error detectors perform much worse than humans.","2) Explanations by LLM-based error detectors lack reliability.","3) LLMs-based error detection is sensitive to small changes in prompts but remains challenging to improve.","4) Popular approaches to improving LLMs, including self-consistency and majority vote, do not improve the error detection performance.","Our benchmark and code are provided at https://github.com/psunlpgroup/ReaLMistake."],"url":"http://arxiv.org/abs/2404.03602v1","category":"cs.CL"}
