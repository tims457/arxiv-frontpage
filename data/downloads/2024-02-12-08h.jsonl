{"created":"2024-02-09 18:59:29","title":"Feedback Loops With Language Models Drive In-Context Reward Hacking","abstract":"Language models influence the external world: they query APIs that read and write to web pages, generate content that shapes human behavior, and run system commands as autonomous agents. These interactions form feedback loops: LLM outputs affect the world, which in turn affect subsequent LLM outputs. In this work, we show that feedback loops can cause in-context reward hacking (ICRH), where the LLM at test-time optimizes a (potentially implicit) objective but creates negative side effects in the process. For example, consider an LLM agent deployed to increase Twitter engagement; the LLM may retrieve its previous tweets into the context window and make them more controversial, increasing engagement but also toxicity. We identify and study two processes that lead to ICRH: output-refinement and policy-refinement. For these processes, evaluations on static datasets are insufficient -- they miss the feedback effects and thus cannot capture the most harmful behavior. In response, we provide three recommendations for evaluation to capture more instances of ICRH. As AI development accelerates, the effects of feedback loops will proliferate, increasing the need to understand their role in shaping LLM behavior.","sentences":["Language models influence the external world: they query APIs that read and write to web pages, generate content that shapes human behavior, and run system commands as autonomous agents.","These interactions form feedback loops: LLM outputs affect the world, which in turn affect subsequent LLM outputs.","In this work, we show that feedback loops can cause in-context reward hacking (ICRH), where the LLM at test-time optimizes a (potentially implicit) objective but creates negative side effects in the process.","For example, consider an LLM agent deployed to increase Twitter engagement; the LLM may retrieve its previous tweets into the context window and make them more controversial, increasing engagement but also toxicity.","We identify and study two processes that lead to ICRH: output-refinement and policy-refinement.","For these processes, evaluations on static datasets are insufficient -- they miss the feedback effects and thus cannot capture the most harmful behavior.","In response, we provide three recommendations for evaluation to capture more instances of ICRH.","As AI development accelerates, the effects of feedback loops will proliferate, increasing the need to understand their role in shaping LLM behavior."],"url":"http://arxiv.org/abs/2402.06627v1","category":"cs.LG"}
{"created":"2024-02-09 18:57:08","title":"Understanding the Effects of Iterative Prompting on Truthfulness","abstract":"The development of Large Language Models (LLMs) has notably transformed numerous sectors, offering impressive text generation capabilities. Yet, the reliability and truthfulness of these models remain pressing concerns. To this end, we investigate iterative prompting, a strategy hypothesized to refine LLM responses, assessing its impact on LLM truthfulness, an area which has not been thoroughly explored. Our extensive experiments delve into the intricacies of iterative prompting variants, examining their influence on the accuracy and calibration of model responses. Our findings reveal that naive prompting methods significantly undermine truthfulness, leading to exacerbated calibration errors. In response to these challenges, we introduce several prompting variants designed to address the identified issues. These variants demonstrate marked improvements over existing baselines, signaling a promising direction for future research. Our work provides a nuanced understanding of iterative prompting and introduces novel approaches to enhance the truthfulness of LLMs, thereby contributing to the development of more accurate and trustworthy AI systems.","sentences":["The development of Large Language Models (LLMs) has notably transformed numerous sectors, offering impressive text generation capabilities.","Yet, the reliability and truthfulness of these models remain pressing concerns.","To this end, we investigate iterative prompting, a strategy hypothesized to refine LLM responses, assessing its impact on LLM truthfulness, an area which has not been thoroughly explored.","Our extensive experiments delve into the intricacies of iterative prompting variants, examining their influence on the accuracy and calibration of model responses.","Our findings reveal that naive prompting methods significantly undermine truthfulness, leading to exacerbated calibration errors.","In response to these challenges, we introduce several prompting variants designed to address the identified issues.","These variants demonstrate marked improvements over existing baselines, signaling a promising direction for future research.","Our work provides a nuanced understanding of iterative prompting and introduces novel approaches to enhance the truthfulness of LLMs, thereby contributing to the development of more accurate and trustworthy AI systems."],"url":"http://arxiv.org/abs/2402.06625v1","category":"cs.CL"}
{"created":"2024-02-09 18:56:07","title":"A two-stage algorithm in evolutionary product unit neural networks for classification","abstract":"This paper presents a procedure to add broader diversity at the beginning of the evolutionary process. It consists of creating two initial populations with different parameter settings, evolving them for a small number of generations, selecting the best individuals from each population in the same proportion and combining them to constitute a new initial population. At this point the main loop of an evolutionary algorithm is applied to the new population. The results show that our proposal considerably improves both the efficiency of previous methodologies and also, significantly, their efficacy in most of the data sets. We have carried out our experimentation on twelve data sets from the UCI repository and two complex real-world problems which differ in their number of instances, features and classes.","sentences":["This paper presents a procedure to add broader diversity at the beginning of the evolutionary process.","It consists of creating two initial populations with different parameter settings, evolving them for a small number of generations, selecting the best individuals from each population in the same proportion and combining them to constitute a new initial population.","At this point the main loop of an evolutionary algorithm is applied to the new population.","The results show that our proposal considerably improves both the efficiency of previous methodologies and also, significantly, their efficacy in most of the data sets.","We have carried out our experimentation on twelve data sets from the UCI repository and two complex real-world problems which differ in their number of instances, features and classes."],"url":"http://arxiv.org/abs/2402.06622v1","category":"cs.NE"}
{"created":"2024-02-09 18:51:49","title":"Aya Dataset: An Open-Access Collection for Multilingual Instruction Tuning","abstract":"Datasets are foundational to many breakthroughs in modern artificial intelligence. Many recent achievements in the space of natural language processing (NLP) can be attributed to the finetuning of pre-trained models on a diverse set of tasks that enables a large language model (LLM) to respond to instructions. Instruction fine-tuning (IFT) requires specifically constructed and annotated datasets. However, existing datasets are almost all in the English language. In this work, our primary goal is to bridge the language gap by building a human-curated instruction-following dataset spanning 65 languages. We worked with fluent speakers of languages from around the world to collect natural instances of instructions and completions. Furthermore, we create the most extensive multilingual collection to date, comprising 513 million instances through templating and translating existing datasets across 114 languages. In total, we contribute four key resources: we develop and open-source the Aya Annotation Platform, the Aya Dataset, the Aya Collection, and the Aya Evaluation Suite. The Aya initiative also serves as a valuable case study in participatory research, involving collaborators from 119 countries. We see this as a valuable framework for future research collaborations that aim to bridge gaps in resources.","sentences":["Datasets are foundational to many breakthroughs in modern artificial intelligence.","Many recent achievements in the space of natural language processing (NLP) can be attributed to the finetuning of pre-trained models on a diverse set of tasks that enables a large language model (LLM) to respond to instructions.","Instruction fine-tuning (IFT) requires specifically constructed and annotated datasets.","However, existing datasets are almost all in the English language.","In this work, our primary goal is to bridge the language gap by building a human-curated instruction-following dataset spanning 65 languages.","We worked with fluent speakers of languages from around the world to collect natural instances of instructions and completions.","Furthermore, we create the most extensive multilingual collection to date, comprising 513 million instances through templating and translating existing datasets across 114 languages.","In total, we contribute four key resources: we develop and open-source the Aya Annotation Platform, the Aya Dataset, the Aya Collection, and the Aya Evaluation Suite.","The Aya initiative also serves as a valuable case study in participatory research, involving collaborators from 119 countries.","We see this as a valuable framework for future research collaborations that aim to bridge gaps in resources."],"url":"http://arxiv.org/abs/2402.06619v1","category":"cs.CL"}
{"created":"2024-02-09 18:47:18","title":"Bakry-\u00c9mery-Ricci curvature: An alternative network geometry measure in the expanding toolbox of graph Ricci curvatures","abstract":"The characterization of complex networks with tools originating in geometry, for instance through the statistics of so-called Ricci curvatures, is a well established tool of network science. There exist various types of such Ricci curvatures, capturing different aspects of network geometry. In the present work, we investigate Bakry-\\'Emery-Ricci curvature, a notion of discrete Ricci curvature that has been studied much in geometry, but so far has not been applied to networks. We explore on standard classes of artificial networks as well as on selected empirical ones to what the statistics of that curvature are similar to or different from that of other curvatures, how it is correlated to other important network measures, and what it tells us about the underlying network. We observe that most vertices typically have negative curvature. Random and small-world networks exhibit a narrow curvature distribution whereas other classes and most of the real-world networks possess a wide curvature distribution. When we compare Bakry-\\'Emery-Ricci curvature with two other discrete notions of Ricci-curvature, Forman-Ricci and Ollivier-Ricci curvature for both model and real-world networks, we observe a high positive correlation between Bakry-\\'Emery-Ricci and both Forman-Ricci and Ollivier-Ricci curvature, and in particular with the augmented version of Forman-Ricci curvature. Bakry-\\'Emery-Ricci curvature also exhibits a high negative correlation with the vertex centrality measure and degree for most of the model and real-world networks. However, it does not correlate with the clustering coefficient. Also, we investigate the importance of vertices with highly negative curvature values to maintain communication in the network. The computational time for Bakry-\\'Emery-Ricci curvature is shorter than that required for Ollivier-Ricci curvature but higher than for Augmented Forman-Ricci curvature.","sentences":["The characterization of complex networks with tools originating in geometry, for instance through the statistics of so-called Ricci curvatures, is a well established tool of network science.","There exist various types of such Ricci curvatures, capturing different aspects of network geometry.","In the present work, we investigate Bakry-\\'Emery-Ricci curvature, a notion of discrete Ricci curvature that has been studied much in geometry, but so far has not been applied to networks.","We explore on standard classes of artificial networks as well as on selected empirical ones to what the statistics of that curvature are similar to or different from that of other curvatures, how it is correlated to other important network measures, and what it tells us about the underlying network.","We observe that most vertices typically have negative curvature.","Random and small-world networks exhibit a narrow curvature distribution whereas other classes and most of the real-world networks possess a wide curvature distribution.","When we compare Bakry-\\'Emery-Ricci curvature with two other discrete notions of Ricci-curvature, Forman-Ricci and Ollivier-Ricci curvature for both model and real-world networks, we observe a high positive correlation between Bakry-\\'Emery-Ricci and both Forman-Ricci and Ollivier-Ricci curvature, and in particular with the augmented version of Forman-Ricci curvature.","Bakry-\\'Emery-Ricci curvature also exhibits a high negative correlation with the vertex centrality measure and degree for most of the model and real-world networks.","However, it does not correlate with the clustering coefficient.","Also, we investigate the importance of vertices with highly negative curvature values to maintain communication in the network.","The computational time for Bakry-\\'Emery-Ricci curvature is shorter than that required for Ollivier-Ricci curvature but higher than for Augmented Forman-Ricci curvature."],"url":"http://arxiv.org/abs/2402.06616v1","category":"physics.comp-ph"}
{"created":"2024-02-09 18:44:36","title":"Primordial Black Holes and Scalar-induced Gravitational Waves in Radiative Hybrid Inflation","abstract":"We study the possibility that primordial black holes (PBHs) can be formed from large curvature perturbations generated during the waterfall phase transition due to the effects of one-loop radiative corrections of Yukawa couplings between the inflaton and a dark fermion in a non-supersymmetric hybrid inflationary model. We obtain a spectral index, $n_s$ and a tensor-to-scalar ratio, $r$ consistent with the current Planck data. Our findings show that the abundance of PBHs are correlated to the dark fermion mass $m_N$ and peak in the GW spectrum. We identify parameter space where PBHs can be the entire dark matter (DM) candidate of the universe or a fraction of it. Our predictions are consistent with any existing constraints of PBH from microlensing, BBN, and CMB, etc. Moreover, the scenario is also testable via induced gravitational waves (GWs) from first-order scalar perturbations detectable in future observatories such as LISA and ET. For instance, with inflaton mass $m \\sim 2\\times 10^{12}$ GeV, $m_N \\sim 5.4\\times 10^{15}$ GeV, we obtain PBHs of around $10^{-13}\\, M_\\odot$ mass that can explain the entire abundance of DM and predict GWs with amplitude $\\Omega_{\\rm GW}h^2$ $\\sim 10^{-9}$ with peak frequency $f$ $\\sim$ $0.1$ Hz in LISA. By explicitly estimating fine-tuning we show the model has very mild tuning. We discuss successful reheating at the end of the inflationary phase via the conversion of the waterfall field into standard model (SM) particles. We also briefly speculate a scenario where the dark fermion can be the possible heavy right-handed neutrino (RHN) which is responsible for generating the SM neutrino masses via the seesaw mechanism. The RHN can be produced due to waterfall field decay and its subsequent decay may also explain the observed baryon asymmetry in the universe via leptogenesis.","sentences":["We study the possibility that primordial black holes (PBHs) can be formed from large curvature perturbations generated during the waterfall phase transition due to the effects of one-loop radiative corrections of Yukawa couplings between the inflaton and a dark fermion in a non-supersymmetric hybrid inflationary model.","We obtain a spectral index, $n_s$ and a tensor-to-scalar ratio, $r$ consistent with the current Planck data.","Our findings show that the abundance of PBHs are correlated to the dark fermion mass $m_N$ and peak in the GW spectrum.","We identify parameter space where PBHs can be the entire dark matter (DM) candidate of the universe or a fraction of it.","Our predictions are consistent with any existing constraints of PBH from microlensing, BBN, and CMB, etc.","Moreover, the scenario is also testable via induced gravitational waves (GWs) from first-order scalar perturbations detectable in future observatories such as LISA and ET.","For instance, with inflaton mass $m \\sim 2\\times 10^{12}$ GeV, $m_N \\sim 5.4\\times 10^{15}$ GeV, we obtain PBHs of around $10^{-13}\\, M_\\odot$ mass that can explain the entire abundance of DM and predict GWs with amplitude $\\Omega_{\\rm GW}h^2$ $\\sim 10^{-9}$ with peak frequency $f$ $\\sim$ $0.1$ Hz in LISA.","By explicitly estimating fine-tuning we show the model has very mild tuning.","We discuss successful reheating at the end of the inflationary phase via the conversion of the waterfall field into standard model (SM) particles.","We also briefly speculate a scenario where the dark fermion can be the possible heavy right-handed neutrino (RHN) which is responsible for generating the SM neutrino masses via the seesaw mechanism.","The RHN can be produced due to waterfall field decay and its subsequent decay may also explain the observed baryon asymmetry in the universe via leptogenesis."],"url":"http://arxiv.org/abs/2402.06613v1","category":"astro-ph.CO"}
{"created":"2024-02-09 18:39:13","title":"TIC: Translate-Infer-Compile for accurate 'text to plan' using LLMs and logical intermediate representations","abstract":"We study the problem of generating plans for given natural language planning task requests. On one hand, LLMs excel at natural language processing but do not perform well on planning. On the other hand, classical planning tools excel at planning tasks but require input in a structured language such as the Planning Domain Definition Language (PDDL). We leverage the strengths of both the techniques by using an LLM for generating the PDDL representation (task PDDL) of planning task requests followed by using a classical planner for computing a plan. Unlike previous approaches that use LLMs for generating task PDDLs directly, our approach comprises of (a) translate: using an LLM only for generating a logically interpretable intermediate representation of natural language task descriptions, (b) infer: deriving additional logically dependent information from the intermediate representation using a logic reasoner (currently, Answer Set Programming solver), and (c) compile: generating the target task PDDL from the base and inferred information. We observe that using an LLM to only output the intermediate representation significantly reduces LLM errors. Consequently, TIC approach achieves, for at least one LLM, high accuracy on task PDDL generation for all seven domains of our evaluation dataset.","sentences":["We study the problem of generating plans for given natural language planning task requests.","On one hand, LLMs excel at natural language processing but do not perform well on planning.","On the other hand, classical planning tools excel at planning tasks but require input in a structured language such as the Planning Domain Definition Language (PDDL).","We leverage the strengths of both the techniques by using an LLM for generating the PDDL representation (task PDDL) of planning task requests followed by using a classical planner for computing a plan.","Unlike previous approaches that use LLMs for generating task PDDLs directly, our approach comprises of (a) translate: using an LLM only for generating a logically interpretable intermediate representation of natural language task descriptions, (b) infer: deriving additional logically dependent information from the intermediate representation using a logic reasoner (currently, Answer Set Programming solver), and (c) compile: generating the target task PDDL from the base and inferred information.","We observe that using an LLM to only output the intermediate representation significantly reduces LLM errors.","Consequently, TIC approach achieves, for at least one LLM, high accuracy on task PDDL generation for all seven domains of our evaluation dataset."],"url":"http://arxiv.org/abs/2402.06608v1","category":"cs.CL"}
{"created":"2024-02-09 18:34:08","title":"RQP-SGD: Differential Private Machine Learning through Noisy SGD and Randomized Quantization","abstract":"The rise of IoT devices has prompted the demand for deploying machine learning at-the-edge with real-time, efficient, and secure data processing. In this context, implementing machine learning (ML) models with real-valued weight parameters can prove to be impractical particularly for large models, and there is a need to train models with quantized discrete weights. At the same time, these low-dimensional models also need to preserve privacy of the underlying dataset. In this work, we present RQP-SGD, a new approach for privacy-preserving quantization to train machine learning models for low-memory ML-at-the-edge. This approach combines differentially private stochastic gradient descent (DP-SGD) with randomized quantization, providing a measurable privacy guarantee in machine learning. In particular, we study the utility convergence of implementing RQP-SGD on ML tasks with convex objectives and quantization constraints and demonstrate its efficacy over deterministic quantization. Through experiments conducted on two datasets, we show the practical effectiveness of RQP-SGD.","sentences":["The rise of IoT devices has prompted the demand for deploying machine learning at-the-edge with real-time, efficient, and secure data processing.","In this context, implementing machine learning (ML) models with real-valued weight parameters can prove to be impractical particularly for large models, and there is a need to train models with quantized discrete weights.","At the same time, these low-dimensional models also need to preserve privacy of the underlying dataset.","In this work, we present RQP-SGD, a new approach for privacy-preserving quantization to train machine learning models for low-memory ML-at-the-edge.","This approach combines differentially private stochastic gradient descent (DP-SGD) with randomized quantization, providing a measurable privacy guarantee in machine learning.","In particular, we study the utility convergence of implementing RQP-SGD on ML tasks with convex objectives and quantization constraints and demonstrate its efficacy over deterministic quantization.","Through experiments conducted on two datasets, we show the practical effectiveness of RQP-SGD."],"url":"http://arxiv.org/abs/2402.06606v1","category":"cs.LG"}
{"created":"2024-02-09 18:29:57","title":"Gravitational Waveform: A Tale of Two Formalisms","abstract":"We revisit the quantum-amplitude-based derivation of the gravitational waveform emitted by the scattering of two spinless massive bodies at the third order in Newton's constant, $h \\sim G+G^2+G^3$ (one-loop level), and correspondingly update its comparison with its classically-derived multipolar-post-Minkowskian counterpart. A spurious-pole-free reorganization of the one-loop five-point amplitude substantially simplifies the post-Newtonian expansion. We find complete agreement between the two results up to the fifth order in the small velocity expansion after taking into account three subtle aspects of the amplitude derivation: (1) in agreement with [arXiv:2312.07452 [hep-th]], the term quadratic in the amplitude in the observable-based formalism [JHEP 02, 137 (2019)] generates a frame rotation by half the classical scattering angle; (2) the dimensional regularization of the infrared divergences of the amplitude introduces an additional $(d-4)/(d-4)$ finite term; and (3) zero-frequency gravitons are found to contribute additional terms both at order $h \\sim G^1$ and at order $h \\sim G^3$ when including disconnected diagrams in the observable-based formalism.","sentences":["We revisit the quantum-amplitude-based derivation of the gravitational waveform emitted by the scattering of two spinless massive bodies at the third order in Newton's constant, $h \\sim G+G^2+G^3$ (one-loop level), and correspondingly update its comparison with its classically-derived multipolar-post-Minkowskian counterpart.","A spurious-pole-free reorganization of the one-loop five-point amplitude substantially simplifies the post-Newtonian expansion.","We find complete agreement between the two results up to the fifth order in the small velocity expansion after taking into account three subtle aspects of the amplitude derivation: (1) in agreement with [arXiv:2312.07452 [hep-th]], the term quadratic in the amplitude in the observable-based formalism [JHEP 02, 137 (2019)] generates a frame rotation by half the classical scattering angle; (2) the dimensional regularization of the infrared divergences of the amplitude introduces an additional $(d-4)/(d-4)$ finite term; and (3) zero-frequency gravitons are found to contribute additional terms both at order $h \\sim G^1$ and at order $h \\sim G^3$ when including disconnected diagrams in the observable-based formalism."],"url":"http://arxiv.org/abs/2402.06604v1","category":"hep-th"}
{"created":"2024-02-09 18:21:51","title":"On the Out-Of-Distribution Generalization of Multimodal Large Language Models","abstract":"We investigate the generalization boundaries of current Multimodal Large Language Models (MLLMs) via comprehensive evaluation under out-of-distribution scenarios and domain-specific tasks. We evaluate their zero-shot generalization across synthetic images, real-world distributional shifts, and specialized datasets like medical and molecular imagery. Empirical results indicate that MLLMs struggle with generalization beyond common training domains, limiting their direct application without adaptation. To understand the cause of unreliable performance, we analyze three hypotheses: semantic misinterpretation, visual feature extraction insufficiency, and mapping deficiency. Results identify mapping deficiency as the primary hurdle. To address this problem, we show that in-context learning (ICL) can significantly enhance MLLMs' generalization, opening new avenues for overcoming generalization barriers. We further explore the robustness of ICL under distribution shifts and show its vulnerability to domain shifts, label shifts, and spurious correlation shifts between in-context examples and test data.","sentences":["We investigate the generalization boundaries of current Multimodal Large Language Models (MLLMs) via comprehensive evaluation under out-of-distribution scenarios and domain-specific tasks.","We evaluate their zero-shot generalization across synthetic images, real-world distributional shifts, and specialized datasets like medical and molecular imagery.","Empirical results indicate that MLLMs struggle with generalization beyond common training domains, limiting their direct application without adaptation.","To understand the cause of unreliable performance, we analyze three hypotheses: semantic misinterpretation, visual feature extraction insufficiency, and mapping deficiency.","Results identify mapping deficiency as the primary hurdle.","To address this problem, we show that in-context learning (ICL) can significantly enhance MLLMs' generalization, opening new avenues for overcoming generalization barriers.","We further explore the robustness of ICL under distribution shifts and show its vulnerability to domain shifts, label shifts, and spurious correlation shifts between in-context examples and test data."],"url":"http://arxiv.org/abs/2402.06599v1","category":"cs.CV"}
{"created":"2024-02-09 18:21:45","title":"CigaR: Cost-efficient Program Repair with LLMs","abstract":"Large language models (LLM) have proven to be effective at automated program repair (APR). However, using LLMs can be highly costly, with companies invoicing users by the number of tokens. In this paper, we propose CigaR, the first LLM-based APR tool that focuses on minimizing the repair cost. CigaR works in two major steps: generating a plausible patch and multiplying plausible patches. CigaR optimizes the prompts and the prompt setting to maximize the information given to LLMs in the smallest possible number of tokens. Our experiments on 267 bugs from the widely used Defects4J dataset shows that CigaR reduces the token cost by 62. On average, CigaR spends 171k tokens per bug while the baseline uses 451k tokens. On the subset of bugs that are fixed by both, CigaR spends 20k per bug while the baseline uses 695k tokens, a cost saving of 97. Our extensive experiments show that CigaR is a cost-effective LLM-based program repair tool that uses a low number of tokens to generate automatic patches.","sentences":["Large language models (LLM) have proven to be effective at automated program repair (APR).","However, using LLMs can be highly costly, with companies invoicing users by the number of tokens.","In this paper, we propose CigaR, the first LLM-based APR tool that focuses on minimizing the repair cost.","CigaR works in two major steps: generating a plausible patch and multiplying plausible patches.","CigaR optimizes the prompts and the prompt setting to maximize the information given to LLMs in the smallest possible number of tokens.","Our experiments on 267 bugs from the widely used Defects4J dataset shows that CigaR reduces the token cost by 62.","On average, CigaR spends 171k tokens per bug while the baseline uses 451k tokens.","On the subset of bugs that are fixed by both, CigaR spends 20k per bug while the baseline uses 695k tokens, a cost saving of 97.","Our extensive experiments show that CigaR is a cost-effective LLM-based program repair tool that uses a low number of tokens to generate automatic patches."],"url":"http://arxiv.org/abs/2402.06598v1","category":"cs.SE"}
{"created":"2024-02-09 18:19:25","title":"Understanding the Weakness of Large Language Model Agents within a Complex Android Environment","abstract":"Large language models (LLMs) have empowered intelligent agents to execute intricate tasks within domain-specific software such as browsers and games. However, when applied to general-purpose software systems like operating systems, LLM agents face three primary challenges. Firstly, the action space is vast and dynamic, posing difficulties for LLM agents to maintain an up-to-date understanding and deliver accurate responses. Secondly, real-world tasks often require inter-application cooperation}, demanding farsighted planning from LLM agents. Thirdly, agents need to identify optimal solutions aligning with user constraints, such as security concerns and preferences. These challenges motivate AndroidArena, an environment and benchmark designed to evaluate LLM agents on a modern operating system. To address high-cost of manpower, we design a scalable and semi-automated method to construct the benchmark. In the task evaluation, AndroidArena incorporates accurate and adaptive metrics to address the issue of non-unique solutions. Our findings reveal that even state-of-the-art LLM agents struggle in cross-APP scenarios and adhering to specific constraints. Additionally, we identify a lack of four key capabilities, i.e., understanding, reasoning, exploration, and reflection, as primary reasons for the failure of LLM agents. Furthermore, we provide empirical analysis on the failure of reflection, and improve the success rate by 27% with our proposed exploration strategy. This work is the first to present valuable insights in understanding fine-grained weakness of LLM agents, and offers a path forward for future research in this area. Environment, benchmark, and evaluation code for AndroidArena are released at https://github.com/AndroidArenaAgent/AndroidArena.","sentences":["Large language models (LLMs) have empowered intelligent agents to execute intricate tasks within domain-specific software such as browsers and games.","However, when applied to general-purpose software systems like operating systems, LLM agents face three primary challenges.","Firstly, the action space is vast and dynamic, posing difficulties for LLM agents to maintain an up-to-date understanding and deliver accurate responses.","Secondly, real-world tasks often require inter-application cooperation}, demanding farsighted planning from LLM agents.","Thirdly, agents need to identify optimal solutions aligning with user constraints, such as security concerns and preferences.","These challenges motivate AndroidArena, an environment and benchmark designed to evaluate LLM agents on a modern operating system.","To address high-cost of manpower, we design a scalable and semi-automated method to construct the benchmark.","In the task evaluation, AndroidArena incorporates accurate and adaptive metrics to address the issue of non-unique solutions.","Our findings reveal that even state-of-the-art LLM agents struggle in cross-APP scenarios and adhering to specific constraints.","Additionally, we identify a lack of four key capabilities, i.e., understanding, reasoning, exploration, and reflection, as primary reasons for the failure of LLM agents.","Furthermore, we provide empirical analysis on the failure of reflection, and improve the success rate by 27% with our proposed exploration strategy.","This work is the first to present valuable insights in understanding fine-grained weakness of LLM agents, and offers a path forward for future research in this area.","Environment, benchmark, and evaluation code for AndroidArena are released at https://github.com/AndroidArenaAgent/AndroidArena."],"url":"http://arxiv.org/abs/2402.06596v1","category":"cs.AI"}
{"created":"2024-02-09 18:13:47","title":"They were robbed! Scoring by the middlemost to attenuate biased judging in boxing","abstract":"Boxing has a long-standing problem with biased judging, impacting both professional and Olympic bouts. ''Robberies'', where boxers are widely seen as being denied rightful victories, threaten to drive fans and athletes away from the sport. To tackle this problem, we propose a minimalist adjustment in how boxing is scored: the winner would be decided by the majority of round-by-round victories according to the judges, rather than relying on the judges' overall bout scores. This approach, rooted in social choice theory and utilising majority rule and middlemost aggregation functions, creates a coordination problem for partisan judges and attenuates their influence. Our model analysis and simulations demonstrate the potential to significantly decrease the likelihood of a partisan judge swaying the result of a bout.","sentences":["Boxing has a long-standing problem with biased judging, impacting both professional and Olympic bouts.","''Robberies'', where boxers are widely seen as being denied rightful victories, threaten to drive fans and athletes away from the sport.","To tackle this problem, we propose a minimalist adjustment in how boxing is scored: the winner would be decided by the majority of round-by-round victories according to the judges, rather than relying on the judges' overall bout scores.","This approach, rooted in social choice theory and utilising majority rule and middlemost aggregation functions, creates a coordination problem for partisan judges and attenuates their influence.","Our model analysis and simulations demonstrate the potential to significantly decrease the likelihood of a partisan judge swaying the result of a bout."],"url":"http://arxiv.org/abs/2402.06594v1","category":"econ.GN"}
{"created":"2024-02-09 18:12:15","title":"Linear and Non-Linear Response of Quadratic Lindbladians","abstract":"Quadratic Lindbladians encompass a rich class of dissipative electronic and bosonic quantum systems, which have been predicted to host new and exotic physics. In this study, we develop a Lindblad-Keldysh spectroscopic response formalism for open quantum systems that elucidates their steady-state response properties and dissipative phase transitions via finite-frequency linear and non-linear probes. As illustrative examples, we utilize this formalism to calculate the (1) density and dynamic spin susceptibilities of a boundary driven XY model at and near criticality, (2) linear and non-linear optical responses in Bernal bilayer graphene coupled to dissipative leads, and (3) steady state susceptibilities in a bosonic optical lattice. We find that the XY model spin density wavelength diverges with critical exponent 1/2, and there are gapless dispersive modes in the dynamic spin response and the coupling to these modes decreases as the spin density wavelength increases. In the optical response of the Bernal bilayer, we find that the diamagnetic response can decrease with increasing occupation, as opposed to in closed systems where the response increases monotonically with occupation; we study the effect of second harmonic generation and shift current and find that these responses, forbidden in centrosymmetric closed systems, can manifest in these open systems as a result of dissipation. We compare this formalism to its equilibrium counterpart and draw analogies between these non-interacting open systems and strongly interacting closed systems.","sentences":["Quadratic Lindbladians encompass a rich class of dissipative electronic and bosonic quantum systems, which have been predicted to host new and exotic physics.","In this study, we develop a Lindblad-Keldysh spectroscopic response formalism for open quantum systems that elucidates their steady-state response properties and dissipative phase transitions via finite-frequency linear and non-linear probes.","As illustrative examples, we utilize this formalism to calculate the (1) density and dynamic spin susceptibilities of a boundary driven XY model at and near criticality, (2) linear and non-linear optical responses in Bernal bilayer graphene coupled to dissipative leads, and (3) steady state susceptibilities in a bosonic optical lattice.","We find that the XY model spin density wavelength diverges with critical exponent 1/2, and there are gapless dispersive modes in the dynamic spin response and the coupling to these modes decreases as the spin density wavelength increases.","In the optical response of the Bernal bilayer, we find that the diamagnetic response can decrease with increasing occupation, as opposed to in closed systems where the response increases monotonically with occupation; we study the effect of second harmonic generation and shift current and find that these responses, forbidden in centrosymmetric closed systems, can manifest in these open systems as a result of dissipation.","We compare this formalism to its equilibrium counterpart and draw analogies between these non-interacting open systems and strongly interacting closed systems."],"url":"http://arxiv.org/abs/2402.06593v1","category":"cond-mat.mes-hall"}
{"created":"2024-02-09 18:10:38","title":"Predictive representations: building blocks of intelligence","abstract":"Adaptive behavior often requires predicting future events. The theory of reinforcement learning prescribes what kinds of predictive representations are useful and how to compute them. This paper integrates these theoretical ideas with work on cognition and neuroscience. We pay special attention to the successor representation (SR) and its generalizations, which have been widely applied both as engineering tools and models of brain function. This convergence suggests that particular kinds of predictive representations may function as versatile building blocks of intelligence.","sentences":["Adaptive behavior often requires predicting future events.","The theory of reinforcement learning prescribes what kinds of predictive representations are useful and how to compute them.","This paper integrates these theoretical ideas with work on cognition and neuroscience.","We pay special attention to the successor representation (SR) and its generalizations, which have been widely applied both as engineering tools and models of brain function.","This convergence suggests that particular kinds of predictive representations may function as versatile building blocks of intelligence."],"url":"http://arxiv.org/abs/2402.06590v1","category":"cs.AI"}
{"created":"2024-02-09 18:06:26","title":"Generating Higher Order Modes from Binary Black Hole mergers with Machine Learning","abstract":"We introduce a machine learning model designed to rapidly and accurately predict the time domain gravitational wave emission of non-precessing binary black hole coalescences, incorporating the effects of higher order modes of the multipole expansion of the waveform. Expanding on our prior work, we decompose each mode by amplitude and phase and reduce dimensionality using principal component analysis. An ensemble of artificial neural networks is trained to learn the relationship between orbital parameters and the low-dimensional representation of each mode. We train our model on $\\sim 10^5$ signals with mass ratio $q \\in [1,10]$ and dimensionless spins $\\chi_i \\in [-0.9, 0.9]$, generated with the state-of-the-art approximant SEOBNRv4HM. We find that it achieves a median faithfulness of $10^{-4}$ averaged across the parameter space. We show that our model generates a single waveform two orders of magnitude faster than the training model, with the speed up increasing when waveforms are generated in batches. This framework is entirely general and can be applied to any other time domain approximant capable of generating waveforms from aligned spin circular binaries, possibly incorporating higher order modes.","sentences":["We introduce a machine learning model designed to rapidly and accurately predict the time domain gravitational wave emission of non-precessing binary black hole coalescences, incorporating the effects of higher order modes of the multipole expansion of the waveform.","Expanding on our prior work, we decompose each mode by amplitude and phase and reduce dimensionality using principal component analysis.","An ensemble of artificial neural networks is trained to learn the relationship between orbital parameters and the low-dimensional representation of each mode.","We train our model on $\\sim 10^5$ signals with mass ratio $q \\in [1,10]$ and dimensionless spins $\\chi_i \\in","[-0.9, 0.9]$, generated with the state-of-the-art approximant SEOBNRv4HM.","We find that it achieves a median faithfulness of $10^{-4}$ averaged across the parameter space.","We show that our model generates a single waveform two orders of magnitude faster than the training model, with the speed up increasing when waveforms are generated in batches.","This framework is entirely general and can be applied to any other time domain approximant capable of generating waveforms from aligned spin circular binaries, possibly incorporating higher order modes."],"url":"http://arxiv.org/abs/2402.06587v1","category":"gr-qc"}
{"created":"2024-02-09 18:05:49","title":"Analytical model for the relation between signal bandwidth and spatial resolution in Steered-Response Power Phase Transform (SRP-PHAT) maps","abstract":"An analysis of the relationship between the bandwidth of acoustic signals and the required resolution of steered-response power phase transform (SRP-PHAT) maps used for sound source localization is presented. This relationship does not rely on the far-field assumption, nor does it depend on any specific array topology. The proposed analysis considers the computation of a SRP map as a process of sampling a set of generalized cross-correlation (GCC) functions, each one corresponding to a different microphone pair. From this approach, we derive a rule that relates GCC bandwidth with inter-microphone distance, resolution of the SRP map, and the potential position of the sound source relative to the array position. This rule is a sufficient condition for an aliasing-free calculation of the specified SRP-PHAT map. Simulation results show that limiting the bandwidth of the GCC according to such rule leads to significant reductions in sound source localization errors when sources are not in the immediate vicinity of the microphone array. These error reductions are more relevant for coarser resolutions of the SRP map, and they happen in both anechoic and reverberant environments.","sentences":["An analysis of the relationship between the bandwidth of acoustic signals and the required resolution of steered-response power phase transform (SRP-PHAT) maps used for sound source localization is presented.","This relationship does not rely on the far-field assumption, nor does it depend on any specific array topology.","The proposed analysis considers the computation of a SRP map as a process of sampling a set of generalized cross-correlation (GCC) functions, each one corresponding to a different microphone pair.","From this approach, we derive a rule that relates GCC bandwidth with inter-microphone distance, resolution of the SRP map, and the potential position of the sound source relative to the array position.","This rule is a sufficient condition for an aliasing-free calculation of the specified SRP-PHAT map.","Simulation results show that limiting the bandwidth of the GCC according to such rule leads to significant reductions in sound source localization errors when sources are not in the immediate vicinity of the microphone array.","These error reductions are more relevant for coarser resolutions of the SRP map, and they happen in both anechoic and reverberant environments."],"url":"http://arxiv.org/abs/2402.06586v1","category":"cs.SD"}
{"created":"2024-02-09 18:05:03","title":"G-SciEdBERT: A Contextualized LLM for Science Assessment Tasks in German","abstract":"The advancement of natural language processing has paved the way for automated scoring systems in various languages, such as German (e.g., German BERT [G-BERT]). Automatically scoring written responses to science questions in German is a complex task and challenging for standard G-BERT as they lack contextual knowledge in the science domain and may be unaligned with student writing styles. This paper developed a contextualized German Science Education BERT (G-SciEdBERT), an innovative large language model tailored for scoring German-written responses to science tasks. Using G-BERT, we pre-trained G-SciEdBERT on a corpus of 50K German written science responses with 5M tokens to the Programme for International Student Assessment (PISA) 2015. We fine-tuned G-SciEdBERT on 59 assessment items and examined the scoring accuracy. We then compared its performance with G-BERT. Our findings reveal a substantial improvement in scoring accuracy with G-SciEdBERT, demonstrating a 10% increase of quadratic weighted kappa compared to G-BERT (mean accuracy difference = 0.096, SD = 0.024). These insights underline the significance of specialized language models like G-SciEdBERT, which is trained to enhance the accuracy of automated scoring, offering a substantial contribution to the field of AI in education.","sentences":["The advancement of natural language processing has paved the way for automated scoring systems in various languages, such as German (e.g., German BERT [G-BERT]).","Automatically scoring written responses to science questions in German is a complex task and challenging for standard G-BERT as they lack contextual knowledge in the science domain and may be unaligned with student writing styles.","This paper developed a contextualized German Science Education BERT (G-SciEdBERT), an innovative large language model tailored for scoring German-written responses to science tasks.","Using G-BERT, we pre-trained G-SciEdBERT on a corpus of 50K German written science responses with 5M tokens to the Programme for International Student Assessment (PISA) 2015.","We fine-tuned G-SciEdBERT on 59 assessment items and examined the scoring accuracy.","We then compared its performance with G-BERT.","Our findings reveal a substantial improvement in scoring accuracy with G-SciEdBERT, demonstrating a 10% increase of quadratic weighted kappa compared to G-BERT (mean accuracy difference = 0.096, SD = 0.024).","These insights underline the significance of specialized language models like G-SciEdBERT, which is trained to enhance the accuracy of automated scoring, offering a substantial contribution to the field of AI in education."],"url":"http://arxiv.org/abs/2402.06584v1","category":"cs.CL"}
{"created":"2024-02-09 17:51:43","title":"On the Universality of Coupling-based Normalizing Flows","abstract":"We present a novel theoretical framework for understanding the expressive power of coupling-based normalizing flows such as RealNVP. Despite their prevalence in scientific applications, a comprehensive understanding of coupling flows remains elusive due to their restricted architectures. Existing theorems fall short as they require the use of arbitrarily ill-conditioned neural networks, limiting practical applicability. Additionally, we demonstrate that these constructions inherently lead to volume-preserving flows, a property which we show to be a fundamental constraint for expressivity. We propose a new distributional universality theorem for coupling-based normalizing flows, which overcomes several limitations of prior work. Our results support the general wisdom that the coupling architecture is expressive and provide a nuanced view for choosing the expressivity of coupling functions, bridging a gap between empirical results and theoretical understanding.","sentences":["We present a novel theoretical framework for understanding the expressive power of coupling-based normalizing flows such as RealNVP.","Despite their prevalence in scientific applications, a comprehensive understanding of coupling flows remains elusive due to their restricted architectures.","Existing theorems fall short as they require the use of arbitrarily ill-conditioned neural networks, limiting practical applicability.","Additionally, we demonstrate that these constructions inherently lead to volume-preserving flows, a property which we show to be a fundamental constraint for expressivity.","We propose a new distributional universality theorem for coupling-based normalizing flows, which overcomes several limitations of prior work.","Our results support the general wisdom that the coupling architecture is expressive and provide a nuanced view for choosing the expressivity of coupling functions, bridging a gap between empirical results and theoretical understanding."],"url":"http://arxiv.org/abs/2402.06578v1","category":"cs.LG"}
{"created":"2024-02-09 17:51:32","title":"Determinant and Derivative-Free Quantum Monte Carlo Within the Stochastic Representation of Wavefunctions","abstract":"Describing the ground states of continuous, real-space quantum many-body systems, like atoms and molecules, is a significant computational challenge with applications throughout the physical sciences. Recent progress was made by variational methods based on machine learning (ML) ansatzes. However, since these approaches are based on energy minimization, ansatzes must be twice differentiable. This (a) precludes the use of many powerful classes of ML models; and (b) makes the enforcement of bosonic, fermionic, and other symmetries costly. Furthermore, (c) the optimization procedure is often unstable unless it is done by imaginary time propagation, which is often impractically expensive in modern ML models with many parameters. The stochastic representation of wavefunctions (SRW), introduced in Nat Commun 14, 3601 (2023), is a recent approach to overcoming (c). SRW enables imaginary time propagation at scale, and makes some headway towards the solution of problem (b), but remains limited by problem (a). Here, we argue that combining SRW with path integral techniques leads to a new formulation that overcomes all three problems simultaneously. As a demonstration, we apply the approach to generalized ``Hooke's atoms'': interacting particles in harmonic wells. We benchmark our results against state-of-the-art data where possible, and use it to investigate the crossover between the Fermi liquid and the Wigner molecule within closed-shell systems. Our results shed new light on the competition between interaction-driven symmetry breaking and kinetic-energy-driven delocalization.","sentences":["Describing the ground states of continuous, real-space quantum many-body systems, like atoms and molecules, is a significant computational challenge with applications throughout the physical sciences.","Recent progress was made by variational methods based on machine learning (ML) ansatzes.","However, since these approaches are based on energy minimization, ansatzes must be twice differentiable.","This (a) precludes the use of many powerful classes of ML models; and (b) makes the enforcement of bosonic, fermionic, and other symmetries costly.","Furthermore, (c) the optimization procedure is often unstable unless it is done by imaginary time propagation, which is often impractically expensive in modern ML models with many parameters.","The stochastic representation of wavefunctions (SRW), introduced in Nat Commun 14, 3601 (2023), is a recent approach to overcoming (c).","SRW enables imaginary time propagation at scale, and makes some headway towards the solution of problem (b), but remains limited by problem (a).","Here, we argue that combining SRW with path integral techniques leads to a new formulation that overcomes all three problems simultaneously.","As a demonstration, we apply the approach to generalized ``Hooke's atoms'': interacting particles in harmonic wells.","We benchmark our results against state-of-the-art data where possible, and use it to investigate the crossover between the Fermi liquid and the Wigner molecule within closed-shell systems.","Our results shed new light on the competition between interaction-driven symmetry breaking and kinetic-energy-driven delocalization."],"url":"http://arxiv.org/abs/2402.06577v1","category":"cond-mat.str-el"}
{"created":"2024-02-09 17:45:21","title":"Formal Siegel modular forms for arithmetic subgroups","abstract":"The notion of formal Siegel modular forms for an arithmetic subgroup $\\Gamma$ of the symplectic group of genus $n$ is a generalization of symmetric formal Fourier-Jacobi series. Assuming an upper bound on the affine covering number of the Siegel modular variety associated with $\\Gamma$, we prove that all formal Siegel modular forms are given by Fourier-Jacobi expansions of classical holomorphic Siegel modular forms. We also show that the required upper bound is always met if $2\\leq n \\leq 4$. As an application we consider the case of the paramodular group of squarefree level and genus $2$.","sentences":["The notion of formal Siegel modular forms for an arithmetic subgroup $\\Gamma$ of the symplectic group of genus $n$ is a generalization of symmetric formal Fourier-Jacobi series.","Assuming an upper bound on the affine covering number of the Siegel modular variety associated with $\\Gamma$, we prove that all formal Siegel modular forms are given by Fourier-Jacobi expansions of classical holomorphic Siegel modular forms.","We also show that the required upper bound is always met if $2\\leq n \\leq 4$.","As an application we consider the case of the paramodular group of squarefree level and genus $2$."],"url":"http://arxiv.org/abs/2402.06572v1","category":"math.NT"}
{"created":"2024-02-09 17:41:49","title":"Weighted cumulative residual Entropy Generating Function and its properties","abstract":"The study on the generating function approach to entropy become popular as it generates several well-known entropy measures discussed in the literature. In this work, we define the weighted cumulative residual entropy generating function (WCREGF) and study its properties. We then introduce the dynamic weighted cumulative residual entropy generating function (DWCREGF). It is shown that the DWCREGF determines the distribution uniquely. We study some characterization results using the relationship between the DWCREGF and the hazard rate and/or the mean residual life function. Using a characterization based on DWCREGF, we develop a new goodness fit test for Rayleigh distribution. A Monte Carlo simulation study is conducted to evaluate the proposed test. Finally, the test is illustrated using two real data sets.","sentences":["The study on the generating function approach to entropy become popular as it generates several well-known entropy measures discussed in the literature.","In this work, we define the weighted cumulative residual entropy generating function (WCREGF) and study its properties.","We then introduce the dynamic weighted cumulative residual entropy generating function (DWCREGF).","It is shown that the DWCREGF determines the distribution uniquely.","We study some characterization results using the relationship between the DWCREGF and the hazard rate and/or the mean residual life function.","Using a characterization based on DWCREGF, we develop a new goodness fit test for Rayleigh distribution.","A Monte Carlo simulation study is conducted to evaluate the proposed test.","Finally, the test is illustrated using two real data sets."],"url":"http://arxiv.org/abs/2402.06571v1","category":"math.ST"}
{"created":"2024-02-09 17:40:51","title":"Distilling Morphology-Conditioned Hypernetworks for Efficient Universal Morphology Control","abstract":"Learning a universal policy across different robot morphologies can significantly improve learning efficiency and enable zero-shot generalization to unseen morphologies. However, learning a highly performant universal policy requires sophisticated architectures like transformers (TF) that have larger memory and computational cost than simpler multi-layer perceptrons (MLP). To achieve both good performance like TF and high efficiency like MLP at inference time, we propose HyperDistill, which consists of: (1) A morphology-conditioned hypernetwork (HN) that generates robot-wise MLP policies, and (2) A policy distillation approach that is essential for successful training. We show that on UNIMAL, a benchmark with hundreds of diverse morphologies, HyperDistill performs as well as a universal TF teacher policy on both training and unseen test robots, but reduces model size by 6-14 times, and computational cost by 67-160 times in different environments. Our analysis attributes the efficiency advantage of HyperDistill at inference time to knowledge decoupling, i.e., the ability to decouple inter-task and intra-task knowledge, a general principle that could also be applied to improve inference efficiency in other domains.","sentences":["Learning a universal policy across different robot morphologies can significantly improve learning efficiency and enable zero-shot generalization to unseen morphologies.","However, learning a highly performant universal policy requires sophisticated architectures like transformers (TF) that have larger memory and computational cost than simpler multi-layer perceptrons (MLP).","To achieve both good performance like TF and high efficiency like MLP at inference time, we propose HyperDistill, which consists of: (1) A morphology-conditioned hypernetwork (HN) that generates robot-wise MLP policies, and (2) A policy distillation approach that is essential for successful training.","We show that on UNIMAL, a benchmark with hundreds of diverse morphologies, HyperDistill performs as well as a universal TF teacher policy on both training and unseen test robots, but reduces model size by 6-14 times, and computational cost by 67-160 times in different environments.","Our analysis attributes the efficiency advantage of HyperDistill at inference time to knowledge decoupling, i.e., the ability to decouple inter-task and intra-task knowledge, a general principle that could also be applied to improve inference efficiency in other domains."],"url":"http://arxiv.org/abs/2402.06570v1","category":"cs.LG"}
{"created":"2024-02-09 17:39:02","title":"Constrained multi-objective optimization for multi-UAV planning","abstract":"Over the last decade, developments in unmanned aerial vehicles (UAVs) has greatly increased, and they are being used in many fields including surveillance, crisis management or automated mission planning. This last field implies the search of plans for missions with multiple tasks, UAVs and ground control stations; and the optimization of several objectives, including makespan, fuel consumption or cost, among others. In this work, this problem has been solved using a multi-objective evolutionary algorithm combined with a constraint satisfaction problem model, which is used in the fitness function of the algorithm. The algorithm has been tested on several missions of increasing complexity, and the computational complexity of the different element considered in the missions has been studied.","sentences":["Over the last decade, developments in unmanned aerial vehicles (UAVs) has greatly increased, and they are being used in many fields including surveillance, crisis management or automated mission planning.","This last field implies the search of plans for missions with multiple tasks, UAVs and ground control stations; and the optimization of several objectives, including makespan, fuel consumption or cost, among others.","In this work, this problem has been solved using a multi-objective evolutionary algorithm combined with a constraint satisfaction problem model, which is used in the fitness function of the algorithm.","The algorithm has been tested on several missions of increasing complexity, and the computational complexity of the different element considered in the missions has been studied."],"url":"http://arxiv.org/abs/2402.06568v1","category":"cs.NE"}
{"created":"2024-02-09 17:32:35","title":"PocketWATCH: Design and operation of a multi-use test bed for water Cherenkov detector components in pure and gadolinium loaded water","abstract":"The PocketWATCH facility is a unique multi-purpose test bed designed to replicate the conditions of large water Cherenkov detectors. Housed at the University of Sheffield, the facility consists of a light-tight 2000L ultrapure water tank with purification and temperature control systems. Water temperature, resistivity, and UV attenuation in the tank are monitored and shown to be stable over time. The system is also shown to be compatible with a solution of 0.2% gadolinium sulfate, allowing further utility in testing equipment bound for the next generation neutrino and nucleon decay water Cherenkov particle detectors. The relevant water quality parameters are shown to be stable whilst running in Gd-mode, thereby providing a suitable test bed for hardware development in a realistic, ex situ environment.","sentences":["The PocketWATCH facility is a unique multi-purpose test bed designed to replicate the conditions of large water Cherenkov detectors.","Housed at the University of Sheffield, the facility consists of a light-tight 2000L ultrapure water tank with purification and temperature control systems.","Water temperature, resistivity, and UV attenuation in the tank are monitored and shown to be stable over time.","The system is also shown to be compatible with a solution of 0.2% gadolinium sulfate, allowing further utility in testing equipment bound for the next generation neutrino and nucleon decay water Cherenkov particle detectors.","The relevant water quality parameters are shown to be stable whilst running in Gd-mode, thereby providing a suitable test bed for hardware development in a realistic, ex situ environment."],"url":"http://arxiv.org/abs/2402.06565v1","category":"physics.ins-det"}
{"created":"2024-02-09 17:27:35","title":"What is Hiding in Medicine's Dark Matter? Learning with Missing Data in Medical Practices","abstract":"Electronic patient records (EPRs) produce a wealth of data but contain significant missing information. Understanding and handling this missing data is an important part of clinical data analysis and if left unaddressed could result in bias in analysis and distortion in critical conclusions. Missing data may be linked to health care professional practice patterns and imputation of missing data can increase the validity of clinical decisions. This study focuses on statistical approaches for understanding and interpreting the missing data and machine learning based clinical data imputation using a single centre's paediatric emergency data and the data from UK's largest clinical audit for traumatic injury database (TARN). In the study of 56,961 data points related to initial vital signs and observations taken on children presenting to an Emergency Department, we have shown that missing data are likely to be non-random and how these are linked to health care professional practice patterns. We have then examined 79 TARN fields with missing values for 5,791 trauma cases. Singular Value Decomposition (SVD) and k-Nearest Neighbour (kNN) based missing data imputation methods are used and imputation results against the original dataset are compared and statistically tested. We have concluded that the 1NN imputer is the best imputation which indicates a usual pattern of clinical decision making: find the most similar patients and take their attributes as imputation.","sentences":["Electronic patient records (EPRs) produce a wealth of data but contain significant missing information.","Understanding and handling this missing data is an important part of clinical data analysis and if left unaddressed could result in bias in analysis and distortion in critical conclusions.","Missing data may be linked to health care professional practice patterns and imputation of missing data can increase the validity of clinical decisions.","This study focuses on statistical approaches for understanding and interpreting the missing data and machine learning based clinical data imputation using a single centre's paediatric emergency data and the data from UK's largest clinical audit for traumatic injury database (TARN).","In the study of 56,961 data points related to initial vital signs and observations taken on children presenting to an Emergency Department, we have shown that missing data are likely to be non-random and how these are linked to health care professional practice patterns.","We have then examined 79 TARN fields with missing values for 5,791 trauma cases.","Singular Value Decomposition (SVD) and k-Nearest Neighbour (kNN) based missing data imputation methods","are used and imputation results against the original dataset are compared and statistically tested.","We have concluded that the 1NN imputer is the best imputation which indicates a usual pattern of clinical decision making: find the most similar patients and take their attributes as imputation."],"url":"http://arxiv.org/abs/2402.06563v1","category":"cs.LG"}
{"created":"2024-02-09 17:26:26","title":"Safe Guaranteed Exploration for Non-linear Systems","abstract":"Safely exploring environments with a-priori unknown constraints is a fundamental challenge that restricts the autonomy of robots. While safety is paramount, guarantees on sufficient exploration are also crucial for ensuring autonomous task completion. To address these challenges, we propose a novel safe guaranteed exploration framework using optimal control, which achieves first-of-its-kind results: guaranteed exploration for non-linear systems with finite time sample complexity bounds, while being provably safe with arbitrarily high probability. The framework is general and applicable to many real-world scenarios with complex non-linear dynamics and unknown domains. Based on this framework we propose an efficient algorithm, SageMPC, SAfe Guaranteed Exploration using Model Predictive Control. SageMPC improves efficiency by incorporating three techniques: i) exploiting a Lipschitz bound, ii) goal-directed exploration, and iii) receding horizon style re-planning, all while maintaining the desired sample complexity, safety and exploration guarantees of the framework. Lastly, we demonstrate safe efficient exploration in challenging unknown environments using SageMPC with a car model.","sentences":["Safely exploring environments with a-priori unknown constraints is a fundamental challenge that restricts the autonomy of robots.","While safety is paramount, guarantees on sufficient exploration are also crucial for ensuring autonomous task completion.","To address these challenges, we propose a novel safe guaranteed exploration framework using optimal control, which achieves first-of-its-kind results: guaranteed exploration for non-linear systems with finite time sample complexity bounds, while being provably safe with arbitrarily high probability.","The framework is general and applicable to many real-world scenarios with complex non-linear dynamics and unknown domains.","Based on this framework we propose an efficient algorithm, SageMPC, SAfe Guaranteed Exploration using Model Predictive Control.","SageMPC improves efficiency by incorporating three techniques: i) exploiting a Lipschitz bound, ii) goal-directed exploration, and iii) receding horizon style re-planning, all while maintaining the desired sample complexity, safety and exploration guarantees of the framework.","Lastly, we demonstrate safe efficient exploration in challenging unknown environments using SageMPC with a car model."],"url":"http://arxiv.org/abs/2402.06562v1","category":"eess.SY"}
{"created":"2024-02-09 17:18:33","title":"Diffusion-ES: Gradient-free Planning with Diffusion for Autonomous Driving and Zero-Shot Instruction Following","abstract":"Diffusion models excel at modeling complex and multimodal trajectory distributions for decision-making and control. Reward-gradient guided denoising has been recently proposed to generate trajectories that maximize both a differentiable reward function and the likelihood under the data distribution captured by a diffusion model. Reward-gradient guided denoising requires a differentiable reward function fitted to both clean and noised samples, limiting its applicability as a general trajectory optimizer. In this paper, we propose DiffusionES, a method that combines gradient-free optimization with trajectory denoising to optimize black-box non-differentiable objectives while staying in the data manifold. Diffusion-ES samples trajectories during evolutionary search from a diffusion model and scores them using a black-box reward function. It mutates high-scoring trajectories using a truncated diffusion process that applies a small number of noising and denoising steps, allowing for much more efficient exploration of the solution space. We show that DiffusionES achieves state-of-the-art performance on nuPlan, an established closed-loop planning benchmark for autonomous driving. Diffusion-ES outperforms existing sampling-based planners, reactive deterministic or diffusion-based policies, and reward-gradient guidance. Additionally, we show that unlike prior guidance methods, our method can optimize non-differentiable language-shaped reward functions generated by few-shot LLM prompting. When guided by a human teacher that issues instructions to follow, our method can generate novel, highly complex behaviors, such as aggressive lane weaving, which are not present in the training data. This allows us to solve the hardest nuPlan scenarios which are beyond the capabilities of existing trajectory optimization methods and driving policies.","sentences":["Diffusion models excel at modeling complex and multimodal trajectory distributions for decision-making and control.","Reward-gradient guided denoising has been recently proposed to generate trajectories that maximize both a differentiable reward function and the likelihood under the data distribution captured by a diffusion model.","Reward-gradient guided denoising requires a differentiable reward function fitted to both clean and noised samples, limiting its applicability as a general trajectory optimizer.","In this paper, we propose DiffusionES, a method that combines gradient-free optimization with trajectory denoising to optimize black-box non-differentiable objectives while staying in the data manifold.","Diffusion-ES samples trajectories during evolutionary search from a diffusion model and scores them using a black-box reward function.","It mutates high-scoring trajectories using a truncated diffusion process that applies a small number of noising and denoising steps, allowing for much more efficient exploration of the solution space.","We show that DiffusionES achieves state-of-the-art performance on nuPlan, an established closed-loop planning benchmark for autonomous driving.","Diffusion-ES outperforms existing sampling-based planners, reactive deterministic or diffusion-based policies, and reward-gradient guidance.","Additionally, we show that unlike prior guidance methods, our method can optimize non-differentiable language-shaped reward functions generated by few-shot LLM prompting.","When guided by a human teacher that issues instructions to follow, our method can generate novel, highly complex behaviors, such as aggressive lane weaving, which are not present in the training data.","This allows us to solve the hardest nuPlan scenarios which are beyond the capabilities of existing trajectory optimization methods and driving policies."],"url":"http://arxiv.org/abs/2402.06559v1","category":"cs.LG"}
{"created":"2024-02-09 17:18:27","title":"The Asymptotic Structure of Cosmological Integrals","abstract":"We provide a general analysis of the asymptotic behaviour of perturbative contributions to observables in arbitrary power-law FRW cosmologies, indistinctly the Bunch-Davies wavefunction and cosmological correlators. We consider a large class of scalar toy models, including conformally-coupled and massless scalars in arbitrary dimensions, that admits a first principle definition in terms of (generalised/weighted) cosmological polytopes. The perturbative contributions to an observable can be expressed as an integral of the canonical function associated to such polytopes and to weighted graphs. We show how the asymptotic behaviour of these integrals is governed by a special class of nestohedra living in the graph-weight space, both at tree and loop level. As the singularities of a cosmological process described by a graph can be associated to its subgraphs, we provide a realisation of the nestohedra as a sequential truncation of a top-dimensional simplex based on the underlying graph. This allows us to determine all the possible directions -- both in the infrared and in the ultraviolet --, where the integral can diverge as well as their divergence degree. Both of them are associated to the facets of the nestohedra, which are identified by overlapping tubings of the graph: the specific tubing determines the divergent directions while the number of overlapping tubings its degree of divergence. This combinatorial formulation makes straightforward the application of sector decomposition for extracting both leading and subleading divergences from the integral, as the sectors in which the integration domain can be tiled are identified by the collection of compatible facets of the nestohedra, with the latter that can be determined via the graph tubings. Finally, the leading divergence can be interpreted as a restriction of the canonical function of the relevant polytope onto a special hyperplane.","sentences":["We provide a general analysis of the asymptotic behaviour of perturbative contributions to observables in arbitrary power-law FRW cosmologies, indistinctly the Bunch-Davies wavefunction and cosmological correlators.","We consider a large class of scalar toy models, including conformally-coupled and massless scalars in arbitrary dimensions, that admits a first principle definition in terms of (generalised/weighted) cosmological polytopes.","The perturbative contributions to an observable can be expressed as an integral of the canonical function associated to such polytopes and to weighted graphs.","We show how the asymptotic behaviour of these integrals is governed by a special class of nestohedra living in the graph-weight space, both at tree and loop level.","As the singularities of a cosmological process described by a graph can be associated to its subgraphs, we provide a realisation of the nestohedra as a sequential truncation of a top-dimensional simplex based on the underlying graph.","This allows us to determine all the possible directions -- both in the infrared and in the ultraviolet --, where the integral can diverge as well as their divergence degree.","Both of them are associated to the facets of the nestohedra, which are identified by overlapping tubings of the graph: the specific tubing determines the divergent directions while the number of overlapping tubings its degree of divergence.","This combinatorial formulation makes straightforward the application of sector decomposition for extracting both leading and subleading divergences from the integral, as the sectors in which the integration domain can be tiled are identified by the collection of compatible facets of the nestohedra, with the latter that can be determined via the graph tubings.","Finally, the leading divergence can be interpreted as a restriction of the canonical function of the relevant polytope onto a special hyperplane."],"url":"http://arxiv.org/abs/2402.06558v1","category":"hep-th"}
{"created":"2024-02-09 17:15:45","title":"The Quantified Boolean Bayesian Network: Theory and Experiments with a Logical Graphical Model","abstract":"This paper introduces the Quantified Boolean Bayesian Network (QBBN), which provides a unified view of logical and probabilistic reasoning. The QBBN is meant to address a central problem with the Large Language Model (LLM), which has become extremely popular in Information Retrieval, which is that the LLM hallucinates. A Bayesian Network, by construction, cannot hallucinate, because it can only return answers that it can explain. We show how a Bayesian Network over an unbounded number of boolean variables can be configured to represent the logical reasoning underlying human language. We do this by creating a key-value version of the First-Order Calculus, for which we can prove consistency and completeness. We show that the model is trivially trained over fully observed data, but that inference is non-trivial. Exact inference in a Bayesian Network is intractable (i.e. $\\Omega(2^N)$ for $N$ variables). For inference, we investigate the use of Loopy Belief Propagation (LBP), which is not guaranteed to converge, but which has been shown to often converge in practice. Our experiments show that LBP indeed does converge very reliably, and our analysis shows that a round of LBP takes time $O(N2^n)$, where $N$ bounds the number of variables considered, and $n$ bounds the number of incoming connections to any factor, and further improvements may be possible. Our network is specifically designed to alternate between AND and OR gates in a Boolean Algebra, which connects more closely to logical reasoning, allowing a completeness proof for an expanded version of our network, and also allows inference to follow specific but adequate pathways, that turn out to be fast.","sentences":["This paper introduces the Quantified Boolean Bayesian Network (QBBN), which provides a unified view of logical and probabilistic reasoning.","The QBBN is meant to address a central problem with the Large Language Model (LLM), which has become extremely popular in Information Retrieval, which is that the LLM hallucinates.","A Bayesian Network, by construction, cannot hallucinate, because it can only return answers that it can explain.","We show how a Bayesian Network over an unbounded number of boolean variables can be configured to represent the logical reasoning underlying human language.","We do this by creating a key-value version of the First-Order Calculus, for which we can prove consistency and completeness.","We show that the model is trivially trained over fully observed data, but that inference is non-trivial.","Exact inference in a Bayesian Network is intractable (i.e. $\\Omega(2^N)$ for $N$ variables).","For inference, we investigate the use of Loopy Belief Propagation (LBP), which is not guaranteed to converge, but which has been shown to often converge in practice.","Our experiments show that LBP indeed does converge very reliably, and our analysis shows that a round of LBP takes time $O(N2^n)$, where $N$ bounds the number of variables considered, and $n$ bounds the number of incoming connections to any factor, and further improvements may be possible.","Our network is specifically designed to alternate between AND and OR gates in a Boolean Algebra, which connects more closely to logical reasoning, allowing a completeness proof for an expanded version of our network, and also allows inference to follow specific but adequate pathways, that turn out to be fast."],"url":"http://arxiv.org/abs/2402.06557v1","category":"cs.AI"}
{"created":"2024-02-09 17:14:38","title":"Parameter estimation for quantum jump unraveling","abstract":"We consider the estimation of parameters encoded in the measurement record of a continuously monitored quantum system in the jump unraveling. This unraveling picture corresponds to a single-shot scenario, where information is continuously gathered. Here, it is generally difficult to assess the precision of the estimation procedure via the Fisher Information due to intricate temporal correlations and memory effects. In this paper we provide a full set of solutions to this problem. First, for multi-channel renewal processes we relate the Fisher Information to an underlying Markov chain and derive a easily computable expression for it. For non-renewal processes, we introduce a new algorithm that combines two methods: the monitoring operator method for metrology and the Gillespie algorithm which allows for efficient sampling of a stochastic form of the Fisher Information along individual quantum trajectories. We show that this stochastic Fisher Information satisfies useful properties related to estimation in the single-shot scenario. Finally, we consider the case where some information is lost in data compression/post-selection, and provide tools for computing the Fisher Information in this case. All scenarios are illustrated with instructive examples from quantum optics and condensed matter.","sentences":["We consider the estimation of parameters encoded in the measurement record of a continuously monitored quantum system in the jump unraveling.","This unraveling picture corresponds to a single-shot scenario, where information is continuously gathered.","Here, it is generally difficult to assess the precision of the estimation procedure via the Fisher Information due to intricate temporal correlations and memory effects.","In this paper we provide a full set of solutions to this problem.","First, for multi-channel renewal processes we relate the Fisher Information to an underlying Markov chain and derive a easily computable expression for it.","For non-renewal processes, we introduce a new algorithm that combines two methods: the monitoring operator method for metrology and the Gillespie algorithm which allows for efficient sampling of a stochastic form of the Fisher Information along individual quantum trajectories.","We show that this stochastic Fisher Information satisfies useful properties related to estimation in the single-shot scenario.","Finally, we consider the case where some information is lost in data compression/post-selection, and provide tools for computing the Fisher Information in this case.","All scenarios are illustrated with instructive examples from quantum optics and condensed matter."],"url":"http://arxiv.org/abs/2402.06556v1","category":"quant-ph"}
{"created":"2024-02-09 17:13:50","title":"Cosmology and the classical limit of the S-matrix","abstract":"We investigate the relationships between classical observables in cosmology and the classical limit of quantum scattering amplitudes. We first look at the relation between Bogoliubov transformations and the notion of classical limit. Then, we compute the cosmological redshift for a particle in a cosmological background and the emitted gravitational waveform from a quantum field theory basis and its classical limit. We observe that there is no interpretation for the geodesic redshift purely in terms of on-shell amplitudes in flat space, given that the classical limit of a scalar 2-point vanishes when considering an FRW background with two asymptotically flat in and out regions. We resolve this apparent conundrum and recover the correct observable by showing that the action of Hermitian operators differ between the in and out regions, unlike standard approaches in flat spacetime. We then argue that the redshift is an exact result even in the presence of radiation emitted from the geodesic motion. Furthermore, we demonstrate that the emitted waveform can be represented solely in terms of an on-shell 3-point amplitude in flat space without energy conservation, providing a closed formula for the waveform in an impulsive FRW.","sentences":["We investigate the relationships between classical observables in cosmology and the classical limit of quantum scattering amplitudes.","We first look at the relation between Bogoliubov transformations and the notion of classical limit.","Then, we compute the cosmological redshift for a particle in a cosmological background and the emitted gravitational waveform from a quantum field theory basis and its classical limit.","We observe that there is no interpretation for the geodesic redshift purely in terms of on-shell amplitudes in flat space, given that the classical limit of a scalar 2-point vanishes when considering an FRW background with two asymptotically flat in and out regions.","We resolve this apparent conundrum and recover the correct observable by showing that the action of Hermitian operators differ between the in and out regions, unlike standard approaches in flat spacetime.","We then argue that the redshift is an exact result even in the presence of radiation emitted from the geodesic motion.","Furthermore, we demonstrate that the emitted waveform can be represented solely in terms of an on-shell 3-point amplitude in flat space without energy conservation, providing a closed formula for the waveform in an impulsive FRW."],"url":"http://arxiv.org/abs/2402.06555v1","category":"hep-th"}
{"created":"2024-02-09 17:07:31","title":"Deceptive Path Planning via Reinforcement Learning with Graph Neural Networks","abstract":"Deceptive path planning (DPP) is the problem of designing a path that hides its true goal from an outside observer. Existing methods for DPP rely on unrealistic assumptions, such as global state observability and perfect model knowledge, and are typically problem-specific, meaning that even minor changes to a previously solved problem can force expensive computation of an entirely new solution. Given these drawbacks, such methods do not generalize to unseen problem instances, lack scalability to realistic problem sizes, and preclude both on-the-fly tunability of deception levels and real-time adaptivity to changing environments. In this paper, we propose a reinforcement learning (RL)-based scheme for training policies to perform DPP over arbitrary weighted graphs that overcomes these issues. The core of our approach is the introduction of a local perception model for the agent, a new state space representation distilling the key components of the DPP problem, the use of graph neural network-based policies to facilitate generalization and scaling, and the introduction of new deception bonuses that translate the deception objectives of classical methods to the RL setting. Through extensive experimentation we show that, without additional fine-tuning, at test time the resulting policies successfully generalize, scale, enjoy tunable levels of deception, and adapt in real-time to changes in the environment.","sentences":["Deceptive path planning (DPP) is the problem of designing a path that hides its true goal from an outside observer.","Existing methods for DPP rely on unrealistic assumptions, such as global state observability and perfect model knowledge, and are typically problem-specific, meaning that even minor changes to a previously solved problem can force expensive computation of an entirely new solution.","Given these drawbacks, such methods do not generalize to unseen problem instances, lack scalability to realistic problem sizes, and preclude both on-the-fly tunability of deception levels and real-time adaptivity to changing environments.","In this paper, we propose a reinforcement learning (RL)-based scheme for training policies to perform DPP over arbitrary weighted graphs that overcomes these issues.","The core of our approach is the introduction of a local perception model for the agent, a new state space representation distilling the key components of the DPP problem, the use of graph neural network-based policies to facilitate generalization and scaling, and the introduction of new deception bonuses that translate the deception objectives of classical methods to the RL setting.","Through extensive experimentation we show that, without additional fine-tuning, at test time the resulting policies successfully generalize, scale, enjoy tunable levels of deception, and adapt in real-time to changes in the environment."],"url":"http://arxiv.org/abs/2402.06552v1","category":"cs.LG"}
{"created":"2024-02-09 17:02:41","title":"Bryndza at ClimateActivism 2024: Stance, Target and Hate Event Detection via Retrieval-Augmented GPT-4 and LLaMA","abstract":"This study details our approach for the CASE 2024 Shared Task on Climate Activism Stance and Hate Event Detection, focusing on Hate Speech Detection, Hate Speech Target Identification, and Stance Detection as classification challenges. We explored the capability of Large Language Models (LLMs), particularly GPT-4, in zero- or few-shot settings enhanced by retrieval augmentation and re-ranking for Tweet classification. Our goal was to determine if LLMs could match or surpass traditional methods in this context.   We conducted an ablation study with LLaMA for comparison, and our results indicate that our models significantly outperformed the baselines, securing second place in the Target Detection task. The code for our submission is available at https://github.com/NaiveNeuron/bryndza-case-2024","sentences":["This study details our approach for the CASE 2024 Shared Task on Climate Activism Stance and Hate Event Detection, focusing on Hate Speech Detection, Hate Speech Target Identification, and Stance Detection as classification challenges.","We explored the capability of Large Language Models (LLMs), particularly GPT-4, in zero- or few-shot settings enhanced by retrieval augmentation and re-ranking for Tweet classification.","Our goal was to determine if LLMs could match or surpass traditional methods in this context.   ","We conducted an ablation study with LLaMA for comparison, and our results indicate that our models significantly outperformed the baselines, securing second place in the Target Detection task.","The code for our submission is available at https://github.com/NaiveNeuron/bryndza-case-2024"],"url":"http://arxiv.org/abs/2402.06549v1","category":"cs.CL"}
{"created":"2024-02-09 17:02:13","title":"Coexistence of asynchronous and clustered dynamics in noisy inhibitory neural networks","abstract":"A regime of coexistence of asynchronous and clustered dynamics is analyzed for globally coupled homogeneous and heterogeneous inhibitory networks of quadratic integrate-and-fire (QIF) neurons subject to Gaussian noise. The analysis is based on accurate extensive simulations and complemented by a mean-field description in terms of low-dimensional next generation neural mass models for heterogeneously distributed synaptic couplings. The asynchronous regime is observable at low noise and becomes unstable via a sub-critical Hopf bifurcation at sufficiently large noise. This gives rise to a coexistence region between the asynchronous and the clustered regime. The clustered phase is characterized by population bursts in the {\\gamma}-range (30-120 Hz), where neurons are split in two equally populated clusters firing in alternation. This clustering behaviour is quite peculiar: despite the global activity being essentially periodic, single neurons display switching between the two clusters due to heterogeneity and/or noise.","sentences":["A regime of coexistence of asynchronous and clustered dynamics is analyzed for globally coupled homogeneous and heterogeneous inhibitory networks of quadratic integrate-and-fire (QIF) neurons subject to Gaussian noise.","The analysis is based on accurate extensive simulations and complemented by a mean-field description in terms of low-dimensional next generation neural mass models for heterogeneously distributed synaptic couplings.","The asynchronous regime is observable at low noise and becomes unstable via a sub-critical Hopf bifurcation at sufficiently large noise.","This gives rise to a coexistence region between the asynchronous and the clustered regime.","The clustered phase is characterized by population bursts in the {\\gamma}-range (30-120 Hz), where neurons are split in two equally populated clusters firing in alternation.","This clustering behaviour is quite peculiar: despite the global activity being essentially periodic, single neurons display switching between the two clusters due to heterogeneity and/or noise."],"url":"http://arxiv.org/abs/2402.06548v1","category":"cond-mat.dis-nn"}
{"created":"2024-02-09 17:00:53","title":"Flip graphs of coloured triangulations of convex polygons","abstract":"A triangulation of a polygon is a subdivision of it into triangles, using diagonals between its vertices. Two different triangulations of a polygon can be related by a sequence of flips: a flip replaces a diagonal by the unique other diagonal in the quadrilateral it defines. In this paper, we study coloured triangulations and coloured flips. In this more general situation, it is no longer true that any two triangulations can be linked by a sequence of (coloured) flips. In this paper, we study the connected components of the coloured flip graphs of triangulations. The motivation for this is a result of Gravier and Payan proving that the Four-Colour Theorem is equivalent to the connectedness of the flip graph of 2-coloured triangulations.","sentences":["A triangulation of a polygon is a subdivision of it into triangles, using diagonals between its vertices.","Two different triangulations of a polygon can be related by a sequence of flips: a flip replaces a diagonal by the unique other diagonal in the quadrilateral it defines.","In this paper, we study coloured triangulations and coloured flips.","In this more general situation, it is no longer true that any two triangulations can be linked by a sequence of (coloured) flips.","In this paper, we study the connected components of the coloured flip graphs of triangulations.","The motivation for this is a result of Gravier and Payan proving that the Four-Colour Theorem is equivalent to the connectedness of the flip graph of 2-coloured triangulations."],"url":"http://arxiv.org/abs/2402.06546v1","category":"math.CO"}
{"created":"2024-02-09 17:00:32","title":"Calibrating Long-form Generations from Large Language Models","abstract":"To enhance Large Language Models' (LLMs) reliability, calibration is essential -- the model's assessed confidence scores should align with the actual likelihood of its responses being correct. However, current confidence elicitation methods and calibration metrics typically rely on a binary true/false assessment of response correctness. This approach does not apply to long-form generation, where an answer can be partially correct. Addressing this gap, we introduce a unified calibration framework, in which both the correctness of the LLMs' responses and their associated confidence levels are treated as distributions across a range of scores. Within this framework, we develop three metrics to precisely evaluate LLM calibration and further propose two confidence elicitation methods based on self-consistency and self-evaluation. Our experiments, which include long-form QA and summarization tasks, demonstrate that larger models don't necessarily guarantee better calibration, that calibration performance is found to be metric-dependent, and that self-consistency methods excel in factoid datasets. We also find that calibration can be enhanced through techniques such as fine-tuning, integrating relevant source documents, scaling the temperature, and combining self-consistency with self-evaluation. Lastly, we showcase a practical application of our system: selecting and cascading open-source models and ChatGPT to optimize correctness given a limited API budget. This research not only challenges existing notions of LLM calibration but also offers practical methodologies for improving trustworthiness in long-form generation.","sentences":["To enhance Large Language Models' (LLMs) reliability, calibration is essential -- the model's assessed confidence scores should align with the actual likelihood of its responses being correct.","However, current confidence elicitation methods and calibration metrics typically rely on a binary true/false assessment of response correctness.","This approach does not apply to long-form generation, where an answer can be partially correct.","Addressing this gap, we introduce a unified calibration framework, in which both the correctness of the LLMs' responses and their associated confidence levels are treated as distributions across a range of scores.","Within this framework, we develop three metrics to precisely evaluate LLM calibration and further propose two confidence elicitation methods based on self-consistency and self-evaluation.","Our experiments, which include long-form QA and summarization tasks, demonstrate that larger models don't necessarily guarantee better calibration, that calibration performance is found to be metric-dependent, and that self-consistency methods excel in factoid datasets.","We also find that calibration can be enhanced through techniques such as fine-tuning, integrating relevant source documents, scaling the temperature, and combining self-consistency with self-evaluation.","Lastly, we showcase a practical application of our system: selecting and cascading open-source models and ChatGPT to optimize correctness given a limited API budget.","This research not only challenges existing notions of LLM calibration but also offers practical methodologies for improving trustworthiness in long-form generation."],"url":"http://arxiv.org/abs/2402.06544v1","category":"cs.CL"}
{"created":"2024-02-09 16:57:31","title":"Charge collective modes in strongly correlated electron systems with long range interactions","abstract":"Elucidating the impact of strong electronic correlations on the collective modes of metallic systems has been of longstanding interest, mainly due to the inadequacy of the random phase approximation (RPA) in the strongly correlated regime. In his regard, we analyze the charge excitation spectrum of a Hubbard model on the face centered cubic lattice, extended with long range interactions, in different coupling regimes ranging from uncorrelated to the metal-to-insulator transition at half filling. We argue that the slave boson representation introduced by Kotliar and Ruckenstein, when formulated in radial gauge, constitutes a suitable framework to carry out this endeavor, and we compare its results to conventional RPA as a benchmark. We focus on the influence of the local and long range couplings on the particle-hole excitation continuum and the quantum collective phenomena generically comprised in our spectra, and find numerous qualitative and quantitative discrepancies between our method and standard RPA in the intermediate-to-strong coupling regime. At the onset of the Mott transition, the plasmon gap is found to vanish, supporting a quasiparticle description of the mode.","sentences":["Elucidating the impact of strong electronic correlations on the collective modes of metallic systems has been of longstanding interest, mainly due to the inadequacy of the random phase approximation (RPA) in the strongly correlated regime.","In his regard, we analyze the charge excitation spectrum of a Hubbard model on the face centered cubic lattice, extended with long range interactions, in different coupling regimes ranging from uncorrelated to the metal-to-insulator transition at half filling.","We argue that the slave boson representation introduced by Kotliar and Ruckenstein, when formulated in radial gauge, constitutes a suitable framework to carry out this endeavor, and we compare its results to conventional RPA as a benchmark.","We focus on the influence of the local and long range couplings on the particle-hole excitation continuum and the quantum collective phenomena generically comprised in our spectra, and find numerous qualitative and quantitative discrepancies between our method and standard RPA in the intermediate-to-strong coupling regime.","At the onset of the Mott transition, the plasmon gap is found to vanish, supporting a quasiparticle description of the mode."],"url":"http://arxiv.org/abs/2402.06541v1","category":"cond-mat.str-el"}
{"created":"2024-02-09 16:43:58","title":"2PM waveform from loop corrected soft theorems","abstract":"We introduce a classical version of the loop corrected soft graviton theorem and we use it to compute the universal part of the one-loop (2PM) waveform up to sub-subleading order in the energy $\\omega$ of the emitted graviton for spinless black-hole scattering. In particular, we compute the action of the soft operators on the classically resummed four-point amplitude, that can be written in terms of the exponential of the eikonal phase (and is therefore non-perturbative in the Newton's constant $G_N$) and then we perform the usual PM expansion in powers of $G_N$ . We find perfect agreement with the existing 2PM literature at the orders $\\log\\omega$ and $\\omega\\log^2\\omega$, which are universal. Furthermore, we use this method to compute the universal part of the $\\omega\\log\\omega$ contribution to the 2PM waveform. Our approach, based on the resummed eikonal amplitude, gives a unified picture of the various computations of the classical soft graviton behaviour that are present in the literature since the seminal paper by Weinberg in 1965.","sentences":["We introduce a classical version of the loop corrected soft graviton theorem","and we use it to compute the universal part of the one-loop (2PM) waveform up to sub-subleading order in the energy $\\omega$ of the emitted graviton for spinless black-hole scattering.","In particular, we compute the action of the soft operators on the classically resummed four-point amplitude, that can be written in terms of the exponential of the eikonal phase (and is therefore non-perturbative in the Newton's constant $G_N$) and then we perform the usual PM expansion in powers of $G_N$ .","We find perfect agreement with the existing 2PM literature at the orders $\\log\\omega$ and $\\omega\\log^2\\omega$, which are universal.","Furthermore, we use this method to compute the universal part of the $\\omega\\log\\omega$ contribution to the 2PM waveform.","Our approach, based on the resummed eikonal amplitude, gives a unified picture of the various computations of the classical soft graviton behaviour that are present in the literature since the seminal paper by Weinberg in 1965."],"url":"http://arxiv.org/abs/2402.06533v1","category":"hep-th"}
{"created":"2024-02-09 16:43:57","title":"Generative Adversarial Bayesian Optimization for Surrogate Objectives","abstract":"Offline model-based policy optimization seeks to optimize a learned surrogate objective function without querying the true oracle objective during optimization. However, inaccurate surrogate model predictions are frequently encountered along the optimization trajectory. To address this limitation, we propose generative adversarial Bayesian optimization (GABO) using adaptive source critic regularization, a task-agnostic framework for Bayesian optimization that employs a Lipschitz-bounded source critic model to constrain the optimization trajectory to regions where the surrogate function is reliable. We show that under certain assumptions for the continuous input space prior, our algorithm dynamically adjusts the strength of the source critic regularization. GABO outperforms existing baselines on a number of different offline optimization tasks across a variety of scientific domains. Our code is available at https://github.com/michael-s-yao/gabo","sentences":["Offline model-based policy optimization seeks to optimize a learned surrogate objective function without querying the true oracle objective during optimization.","However, inaccurate surrogate model predictions are frequently encountered along the optimization trajectory.","To address this limitation, we propose generative adversarial Bayesian optimization (GABO) using adaptive source critic regularization, a task-agnostic framework for Bayesian optimization that employs a Lipschitz-bounded source critic model to constrain the optimization trajectory to regions where the surrogate function is reliable.","We show that under certain assumptions for the continuous input space prior, our algorithm dynamically adjusts the strength of the source critic regularization.","GABO outperforms existing baselines on a number of different offline optimization tasks across a variety of scientific domains.","Our code is available at https://github.com/michael-s-yao/gabo"],"url":"http://arxiv.org/abs/2402.06532v1","category":"cs.LG"}
{"created":"2024-02-09 16:41:50","title":"Refining Myocardial Infarction Detection: A Novel Multi-Modal Composite Kernel Strategy in One-Class Classification","abstract":"Early detection of myocardial infarction (MI), a critical condition arising from coronary artery disease (CAD), is vital to prevent further myocardial damage. This study introduces a novel method for early MI detection using a one-class classification (OCC) algorithm in echocardiography. Our study overcomes the challenge of limited echocardiography data availability by adopting a novel approach based on Multi-modal Subspace Support Vector Data Description. The proposed technique involves a specialized MI detection framework employing multi-view echocardiography incorporating a composite kernel in the non-linear projection trick, fusing Gaussian and Laplacian sigmoid functions. Additionally, we enhance the update strategy of the projection matrices by adapting maximization for both or one of the modalities in the optimization process. Our method boosts MI detection capability by efficiently transforming features extracted from echocardiography data into an optimized lower-dimensional subspace. The OCC model trained specifically on target class instances from the comprehensive HMC-QU dataset that includes multiple echocardiography views indicates a marked improvement in MI detection accuracy. Our findings reveal that our proposed multi-view approach achieves a geometric mean of 71.24\\%, signifying a substantial advancement in echocardiography-based MI diagnosis and offering more precise and efficient diagnostic tools.","sentences":["Early detection of myocardial infarction (MI), a critical condition arising from coronary artery disease (CAD), is vital to prevent further myocardial damage.","This study introduces a novel method for early MI detection using a one-class classification (OCC) algorithm in echocardiography.","Our study overcomes the challenge of limited echocardiography data availability by adopting a novel approach based on Multi-modal Subspace Support Vector Data Description.","The proposed technique involves a specialized MI detection framework employing multi-view echocardiography incorporating a composite kernel in the non-linear projection trick, fusing Gaussian and Laplacian sigmoid functions.","Additionally, we enhance the update strategy of the projection matrices by adapting maximization for both or one of the modalities in the optimization process.","Our method boosts MI detection capability by efficiently transforming features extracted from echocardiography data into an optimized lower-dimensional subspace.","The OCC model trained specifically on target class instances from the comprehensive HMC-QU dataset that includes multiple echocardiography views indicates a marked improvement in MI detection accuracy.","Our findings reveal that our proposed multi-view approach achieves a geometric mean of 71.24\\%, signifying a substantial advancement in echocardiography-based MI diagnosis and offering more precise and efficient diagnostic tools."],"url":"http://arxiv.org/abs/2402.06530v1","category":"cs.LG"}
{"created":"2024-02-09 16:40:59","title":"Introspective Planning: Guiding Language-Enabled Agents to Refine Their Own Uncertainty","abstract":"Large language models (LLMs) exhibit advanced reasoning skills, enabling robots to comprehend natural language instructions and strategically plan high-level actions through proper grounding. However, LLM hallucination may result in robots confidently executing plans that are misaligned with user goals or, in extreme cases, unsafe. Additionally, inherent ambiguity in natural language instructions can induce task uncertainty, particularly in situations where multiple valid options exist. To address this issue, LLMs must identify such uncertainty and proactively seek clarification. This paper explores the concept of introspective planning as a systematic method for guiding LLMs in forming uncertainty--aware plans for robotic task execution without the need for fine-tuning. We investigate uncertainty quantification in task-level robot planning and demonstrate that introspection significantly improves both success rates and safety compared to state-of-the-art LLM-based planning approaches. Furthermore, we assess the effectiveness of introspective planning in conjunction with conformal prediction, revealing that this combination yields tighter confidence bounds, thereby maintaining statistical success guarantees with fewer superfluous user clarification queries.","sentences":["Large language models (LLMs) exhibit advanced reasoning skills, enabling robots to comprehend natural language instructions and strategically plan high-level actions through proper grounding.","However, LLM hallucination may result in robots confidently executing plans that are misaligned with user goals or, in extreme cases, unsafe.","Additionally, inherent ambiguity in natural language instructions can induce task uncertainty, particularly in situations where multiple valid options exist.","To address this issue, LLMs must identify such uncertainty and proactively seek clarification.","This paper explores the concept of introspective planning as a systematic method for guiding LLMs in forming uncertainty--aware plans for robotic task execution without the need for fine-tuning.","We investigate uncertainty quantification in task-level robot planning and demonstrate that introspection significantly improves both success rates and safety compared to state-of-the-art LLM-based planning approaches.","Furthermore, we assess the effectiveness of introspective planning in conjunction with conformal prediction, revealing that this combination yields tighter confidence bounds, thereby maintaining statistical success guarantees with fewer superfluous user clarification queries."],"url":"http://arxiv.org/abs/2402.06529v1","category":"cs.AI"}
{"created":"2024-02-09 16:15:30","title":"Asking the Right Question at the Right Time: Human and Model Uncertainty Guidance to Ask Clarification Questions","abstract":"Clarification questions are an essential dialogue tool to signal misunderstanding, ambiguities, and under-specification in language use. While humans are able to resolve uncertainty by asking questions since childhood, modern dialogue systems struggle to generate effective questions. To make progress in this direction, in this work we take a collaborative dialogue task as a testbed and study how model uncertainty relates to human uncertainty -- an as yet under-explored problem. We show that model uncertainty does not mirror human clarification-seeking behavior, which suggests that using human clarification questions as supervision for deciding when to ask may not be the most effective way to resolve model uncertainty. To address this issue, we propose an approach to generating clarification questions based on model uncertainty estimation, compare it to several alternatives, and show that it leads to significant improvements in terms of task success. Our findings highlight the importance of equipping dialogue systems with the ability to assess their own uncertainty and exploit in interaction.","sentences":["Clarification questions are an essential dialogue tool to signal misunderstanding, ambiguities, and under-specification in language use.","While humans are able to resolve uncertainty by asking questions since childhood, modern dialogue systems struggle to generate effective questions.","To make progress in this direction, in this work we take a collaborative dialogue task as a testbed and study how model uncertainty relates to human uncertainty -- an as yet under-explored problem.","We show that model uncertainty does not mirror human clarification-seeking behavior, which suggests that using human clarification questions as supervision for deciding when to ask may not be the most effective way to resolve model uncertainty.","To address this issue, we propose an approach to generating clarification questions based on model uncertainty estimation, compare it to several alternatives, and show that it leads to significant improvements in terms of task success.","Our findings highlight the importance of equipping dialogue systems with the ability to assess their own uncertainty and exploit in interaction."],"url":"http://arxiv.org/abs/2402.06509v1","category":"cs.CL"}
{"created":"2024-02-09 16:14:50","title":"Seismic structure of the southern Rivera plate and Jalisco block subduction zone","abstract":"Structural and tectonic features in the Pacific Coast of Mexico generate a high level of seismic activity in the Jalisco block (JB) region, making it one of the most attractive areas of the world for geophysical investigations. The Rivera North America contact zone has been the object of different tectonic studies in recent years framed within the TsuJal project. To this day, this project is generating numerous crucial geophysical results, which significantly improve our understanding of the region. Our study is focused on the interaction between the south of the JB and Rivera plate (RP), which crosses the Middle America trench. We also cover an offshore onshore transect of 130 km length between the eastern Rivera fracture zone and La Huerta region, in the Jalisco state. To characterize this region,we interpreted wide angle seismic, multichannel seismic, and multibeam bathymetry data. The integration of these results, with the local and regional seismicity recorded by the Jalisco Seismic Accelerometric Telemetric Network and by the Mapping the Rivera Subduction Zone experiment, provides new insights into the geometry of the southern RP, which is dipping 12 14 degrees under the JB in the northeast southwest direction. Moreover, our results provide new seismic images of the accretionary wedge, the shallow crust, the deep crust, and the upper-mantle structure along this profile.","sentences":["Structural and tectonic features in the Pacific Coast of Mexico generate a high level of seismic activity in the Jalisco block (JB) region, making it one of the most attractive areas of the world for geophysical investigations.","The Rivera North America contact zone has been the object of different tectonic studies in recent years framed within the TsuJal project.","To this day, this project is generating numerous crucial geophysical results, which significantly improve our understanding of the region.","Our study is focused on the interaction between the south of the JB and Rivera plate (RP), which crosses the Middle America trench.","We also cover an offshore onshore transect of 130 km length between the eastern Rivera fracture zone and La Huerta region, in the Jalisco state.","To characterize this region,we interpreted wide angle seismic, multichannel seismic, and multibeam bathymetry data.","The integration of these results, with the local and regional seismicity recorded by the Jalisco Seismic Accelerometric Telemetric Network and by the Mapping the Rivera Subduction Zone experiment, provides new insights into the geometry of the southern RP, which is dipping 12 14 degrees under the JB in the northeast southwest direction.","Moreover, our results provide new seismic images of the accretionary wedge, the shallow crust, the deep crust, and the upper-mantle structure along this profile."],"url":"http://arxiv.org/abs/2402.06508v1","category":"physics.geo-ph"}
{"created":"2024-02-09 16:14:30","title":"Classifying point clouds at the facade-level using geometric features and deep learning networks","abstract":"3D building models with facade details are playing an important role in many applications now. Classifying point clouds at facade-level is key to create such digital replicas of the real world. However, few studies have focused on such detailed classification with deep neural networks. We propose a method fusing geometric features with deep learning networks for point cloud classification at facade-level. Our experiments conclude that such early-fused features improve deep learning methods' performance. This method can be applied for compensating deep learning networks' ability in capturing local geometric information and promoting the advancement of semantic segmentation.","sentences":["3D building models with facade details are playing an important role in many applications now.","Classifying point clouds at facade-level is key to create such digital replicas of the real world.","However, few studies have focused on such detailed classification with deep neural networks.","We propose a method fusing geometric features with deep learning networks for point cloud classification at facade-level.","Our experiments conclude that such early-fused features improve deep learning methods' performance.","This method can be applied for compensating deep learning networks' ability in capturing local geometric information and promoting the advancement of semantic segmentation."],"url":"http://arxiv.org/abs/2402.06506v1","category":"cs.CV"}
{"created":"2024-02-09 16:13:54","title":"The role of mobility in epidemics near criticality","abstract":"The general epidemic process (GEP), also known as susceptible-infected-recovered model (SIR), describes how an epidemic spreads within a population of susceptible individuals who acquire permanent immunization upon recovery. This model exhibits a second-order absorbing state phase transition, commonly studied assuming immobile healthy individuals. We investigate the impact of mobility on disease spreading near the extinction threshold by introducing two generalizations of GEP, where the mobility of susceptible and recovered individuals is examined independently. In both cases, including mobility violates GEP's rapidity reversal symmetry and alters the number of absorbing states. The critical dynamics of the models are analyzed through a perturbative renormalization group approach and large-scale stochastic simulations using a Gillespie algorithm. The renormalization group analysis predicts both models to belong to the same novel universality class describing the critical dynamics of epidemic spreading when the infected individuals interact with a diffusive species and gain immunization upon recovery. At the associated renormalization group fixed point, the immobile species decouples from the dynamics of the infected species, dominated by the coupling with the diffusive species. Numerical simulations in two dimensions affirm our renormalization group results by identifying the same set of critical exponents for both models. Violation of the rapidity reversal symmetry is confirmed by breaking the associated hyperscaling relation. Our study underscores the significance of mobility in shaping population spreading dynamics near the extinction threshold.","sentences":["The general epidemic process (GEP), also known as susceptible-infected-recovered model (SIR), describes how an epidemic spreads within a population of susceptible individuals who acquire permanent immunization upon recovery.","This model exhibits a second-order absorbing state phase transition, commonly studied assuming immobile healthy individuals.","We investigate the impact of mobility on disease spreading near the extinction threshold by introducing two generalizations of GEP, where the mobility of susceptible and recovered individuals is examined independently.","In both cases, including mobility violates GEP's rapidity reversal symmetry and alters the number of absorbing states.","The critical dynamics of the models are analyzed through a perturbative renormalization group approach and large-scale stochastic simulations using a Gillespie algorithm.","The renormalization group analysis predicts both models to belong to the same novel universality class describing the critical dynamics of epidemic spreading when the infected individuals interact with a diffusive species and gain immunization upon recovery.","At the associated renormalization group fixed point, the immobile species decouples from the dynamics of the infected species, dominated by the coupling with the diffusive species.","Numerical simulations in two dimensions affirm our renormalization group results by identifying the same set of critical exponents for both models.","Violation of the rapidity reversal symmetry is confirmed by breaking the associated hyperscaling relation.","Our study underscores the significance of mobility in shaping population spreading dynamics near the extinction threshold."],"url":"http://arxiv.org/abs/2402.06505v1","category":"cond-mat.stat-mech"}
{"created":"2024-02-09 16:12:53","title":"ACTER: Diverse and Actionable Counterfactual Sequences for Explaining and Diagnosing RL Policies","abstract":"Understanding how failure occurs and how it can be prevented in reinforcement learning (RL) is necessary to enable debugging, maintain user trust, and develop personalized policies. Counterfactual reasoning has often been used to assign blame and understand failure by searching for the closest possible world in which the failure is avoided. However, current counterfactual state explanations in RL can only explain an outcome using just the current state features and offer no actionable recourse on how a negative outcome could have been prevented. In this work, we propose ACTER (Actionable Counterfactual Sequences for Explaining Reinforcement Learning Outcomes), an algorithm for generating counterfactual sequences that provides actionable advice on how failure can be avoided. ACTER investigates actions leading to a failure and uses the evolutionary algorithm NSGA-II to generate counterfactual sequences of actions that prevent it with minimal changes and high certainty even in stochastic environments. Additionally, ACTER generates a set of multiple diverse counterfactual sequences that enable users to correct failure in the way that best fits their preferences. We also introduce three diversity metrics that can be used for evaluating the diversity of counterfactual sequences. We evaluate ACTER in two RL environments, with both discrete and continuous actions, and show that it can generate actionable and diverse counterfactual sequences. We conduct a user study to explore how explanations generated by ACTER help users identify and correct failure.","sentences":["Understanding how failure occurs and how it can be prevented in reinforcement learning (RL) is necessary to enable debugging, maintain user trust, and develop personalized policies.","Counterfactual reasoning has often been used to assign blame and understand failure by searching for the closest possible world in which the failure is avoided.","However, current counterfactual state explanations in RL can only explain an outcome using just the current state features and offer no actionable recourse on how a negative outcome could have been prevented.","In this work, we propose ACTER (Actionable Counterfactual Sequences for Explaining Reinforcement Learning Outcomes), an algorithm for generating counterfactual sequences that provides actionable advice on how failure can be avoided.","ACTER investigates actions leading to a failure and uses the evolutionary algorithm NSGA-II to generate counterfactual sequences of actions that prevent it with minimal changes and high certainty even in stochastic environments.","Additionally, ACTER generates a set of multiple diverse counterfactual sequences that enable users to correct failure in the way that best fits their preferences.","We also introduce three diversity metrics that can be used for evaluating the diversity of counterfactual sequences.","We evaluate ACTER in two RL environments, with both discrete and continuous actions, and show that it can generate actionable and diverse counterfactual sequences.","We conduct a user study to explore how explanations generated by ACTER help users identify and correct failure."],"url":"http://arxiv.org/abs/2402.06503v1","category":"cs.AI"}
{"created":"2024-02-09 16:12:37","title":"Continuation of Periodic Orbits in Conservative Hybrid Dynamical Systems and its Application to Mechanical Systems with Impulsive Dynamics","abstract":"In autonomous differential equations where a single first integral is present, periodic orbits are well-known to belong to one-parameter families, parameterized by the first integral's values. This paper shows that this characteristic extends to a broader class of conservative hybrid dynamical systems (cHDSs). We define recurrent cHDSs to study periodic orbits, introducing the concept of a hybrid first integral to characterize conservation in these systems. Additionally, our work presents a methodology that utilizes numerical continuation methods to generate these periodic orbits, building upon the concept of normal periodic orbits. We specifically compare state-based and time-based implementations of an cHDS as an important application detail in generating periodic orbits. Furthermore, we showcase the continuation process using exemplary conservative mechanical systems with impulsive dynamics.","sentences":["In autonomous differential equations where a single first integral is present, periodic orbits are well-known to belong to one-parameter families, parameterized by the first integral's values.","This paper shows that this characteristic extends to a broader class of conservative hybrid dynamical systems (cHDSs).","We define recurrent cHDSs to study periodic orbits, introducing the concept of a hybrid first integral to characterize conservation in these systems.","Additionally, our work presents a methodology that utilizes numerical continuation methods to generate these periodic orbits, building upon the concept of normal periodic orbits.","We specifically compare state-based and time-based implementations of an cHDS as an important application detail in generating periodic orbits.","Furthermore, we showcase the continuation process using exemplary conservative mechanical systems with impulsive dynamics."],"url":"http://arxiv.org/abs/2402.06502v1","category":"math.DS"}
{"created":"2024-02-09 16:11:04","title":"Scalable Interactive Machine Learning for Future Command and Control","abstract":"Future warfare will require Command and Control (C2) personnel to make decisions at shrinking timescales in complex and potentially ill-defined situations. Given the need for robust decision-making processes and decision-support tools, integration of artificial and human intelligence holds the potential to revolutionize the C2 operations process to ensure adaptability and efficiency in rapidly changing operational environments. We propose to leverage recent promising breakthroughs in interactive machine learning, in which humans can cooperate with machine learning algorithms to guide machine learning algorithm behavior. This paper identifies several gaps in state-of-the-art science and technology that future work should address to extend these approaches to function in complex C2 contexts. In particular, we describe three research focus areas that together, aim to enable scalable interactive machine learning (SIML): 1) developing human-AI interaction algorithms to enable planning in complex, dynamic situations; 2) fostering resilient human-AI teams through optimizing roles, configurations, and trust; and 3) scaling algorithms and human-AI teams for flexibility across a range of potential contexts and situations.","sentences":["Future warfare will require Command and Control (C2) personnel to make decisions at shrinking timescales in complex and potentially ill-defined situations.","Given the need for robust decision-making processes and decision-support tools, integration of artificial and human intelligence holds the potential to revolutionize the C2 operations process to ensure adaptability and efficiency in rapidly changing operational environments.","We propose to leverage recent promising breakthroughs in interactive machine learning, in which humans can cooperate with machine learning algorithms to guide machine learning algorithm behavior.","This paper identifies several gaps in state-of-the-art science and technology that future work should address to extend these approaches to function in complex C2 contexts.","In particular, we describe three research focus areas that together, aim to enable scalable interactive machine learning (SIML): 1) developing human-AI interaction algorithms to enable planning in complex, dynamic situations; 2) fostering resilient human-AI teams through optimizing roles, configurations, and trust; and 3) scaling algorithms and human-AI teams for flexibility across a range of potential contexts and situations."],"url":"http://arxiv.org/abs/2402.06501v1","category":"cs.LG"}
{"created":"2024-02-09 16:10:19","title":"On the Fly Detection of Root Causes from Observed Data with Application to IT Systems","abstract":"This paper introduces a new structural causal model tailored for representing threshold-based IT systems and presents a new algorithm designed to rapidly detect root causes of anomalies in such systems. When root causes are not causally related, the method is proven to be correct; while an extension is proposed based on the intervention of an agent to relax this assumption. Our algorithm and its agent-based extension leverage causal discovery from offline data and engage in subgraph traversal when encountering new anomalies in online data. Our extensive experiments demonstrate the superior performance of our methods, even when applied to data generated from alternative structural causal models or real IT monitoring data.","sentences":["This paper introduces a new structural causal model tailored for representing threshold-based IT systems and presents a new algorithm designed to rapidly detect root causes of anomalies in such systems.","When root causes are not causally related, the method is proven to be correct; while an extension is proposed based on the intervention of an agent to relax this assumption.","Our algorithm and its agent-based extension leverage causal discovery from offline data and engage in subgraph traversal when encountering new anomalies in online data.","Our extensive experiments demonstrate the superior performance of our methods, even when applied to data generated from alternative structural causal models or real IT monitoring data."],"url":"http://arxiv.org/abs/2402.06500v1","category":"cs.AI"}
{"created":"2024-02-09 16:10:09","title":"Signatures of Nuclear Isomers in Gamma-Ray Bursts from Binary Neutron Star Mergers","abstract":"Neutron star mergers are astrophysical `gold mines,' synthesizing over half of the elements heavier than iron through rapid neutron capture nucleosynthesis. The observation of the binary neutron star merger GW170817, detected both in gravitational waves and electromagnetic radiation, marked a breakthrough. One electromagnetic component of this event, the gamma ray burst GRB 170817A, has an unresolved aspect: the characteristics of its prompt gamma-ray emission spectrum. In this work, we propose that gamma-ray spectra in such GRBs may be influenced by de-excitations from isomeric transitions. Our study begins with a review of current knowledge on GRB structure and of r-process nucleosynthesis in neutron star collisions, focusing on the role of nuclear isomers in these settings. We then test our hypothesis by developing criteria to select representative isomers, based on known solar element abundances, for modeling GRB spectral characteristics. We integrate these criteria into an interactive web page, facilitating the construction and analysis of relevant gamma-ray spectra from isomeric transitions. Our analysis reveals that three isomers (zirconium, lead and yttrium) stand out for their potential to impact the prompt GRB spectrum due to their specific properties. This information allows us to incorporate nuclear isomer data into astrophysical simulations and calculate isomeric abundances generated by astrophysical r-processes in neutron star mergers and their imprint on the detected signal.","sentences":["Neutron star mergers are astrophysical `gold mines,' synthesizing over half of the elements heavier than iron through rapid neutron capture nucleosynthesis.","The observation of the binary neutron star merger GW170817, detected both in gravitational waves and electromagnetic radiation, marked a breakthrough.","One electromagnetic component of this event, the gamma ray burst GRB 170817A, has an unresolved aspect: the characteristics of its prompt gamma-ray emission spectrum.","In this work, we propose that gamma-ray spectra in such GRBs may be influenced by de-excitations from isomeric transitions.","Our study begins with a review of current knowledge on GRB structure and of r-process nucleosynthesis in neutron star collisions, focusing on the role of nuclear isomers in these settings.","We then test our hypothesis by developing criteria to select representative isomers, based on known solar element abundances, for modeling GRB spectral characteristics.","We integrate these criteria into an interactive web page, facilitating the construction and analysis of relevant gamma-ray spectra from isomeric transitions.","Our analysis reveals that three isomers (zirconium, lead and yttrium) stand out for their potential to impact the prompt GRB spectrum due to their specific properties.","This information allows us to incorporate nuclear isomer data into astrophysical simulations and calculate isomeric abundances generated by astrophysical r-processes in neutron star mergers and their imprint on the detected signal."],"url":"http://arxiv.org/abs/2402.06498v1","category":"astro-ph.HE"}
{"created":"2024-02-09 15:53:15","title":"Inducing Systematicity in Transformers by Attending to Structurally Quantized Embeddings","abstract":"Transformers generalize to novel compositions of structures and entities after being trained on a complex dataset, but easily overfit on datasets of insufficient complexity. We observe that when the training set is sufficiently complex, the model encodes sentences that have a common syntactic structure using a systematic attention pattern. Inspired by this observation, we propose SQ-Transformer (Structurally Quantized) that explicitly encourages systematicity in the embeddings and attention layers, even with a training set of low complexity. At the embedding level, we introduce Structure-oriented Vector Quantization (SoVQ) to cluster word embeddings into several classes of structurally equivalent entities. At the attention level, we devise the Systematic Attention Layer (SAL) and an alternative, Systematically Regularized Layer (SRL) that operate on the quantized word embeddings so that sentences of the same structure are encoded with invariant or similar attention patterns. Empirically, we show that SQ-Transformer achieves stronger compositional generalization than the vanilla Transformer on multiple low-complexity semantic parsing and machine translation datasets. In our analysis, we show that SoVQ indeed learns a syntactically clustered embedding space and SAL/SRL induces generalizable attention patterns, which lead to improved systematicity.","sentences":["Transformers generalize to novel compositions of structures and entities after being trained on a complex dataset, but easily overfit on datasets of insufficient complexity.","We observe that when the training set is sufficiently complex, the model encodes sentences that have a common syntactic structure using a systematic attention pattern.","Inspired by this observation, we propose SQ-Transformer (Structurally Quantized) that explicitly encourages systematicity in the embeddings and attention layers, even with a training set of low complexity.","At the embedding level, we introduce Structure-oriented Vector Quantization (SoVQ) to cluster word embeddings into several classes of structurally equivalent entities.","At the attention level, we devise the Systematic Attention Layer (SAL) and an alternative, Systematically Regularized Layer (SRL) that operate on the quantized word embeddings so that sentences of the same structure are encoded with invariant or similar attention patterns.","Empirically, we show that SQ-Transformer achieves stronger compositional generalization than the vanilla Transformer on multiple low-complexity semantic parsing and machine translation datasets.","In our analysis, we show that SoVQ indeed learns a syntactically clustered embedding space and SAL/SRL induces generalizable attention patterns, which lead to improved systematicity."],"url":"http://arxiv.org/abs/2402.06492v1","category":"cs.CL"}
{"created":"2024-02-09 15:52:30","title":"A new parallel solver suited for arbitrary semilinear parabolic partial differential equations based on generalized random trees","abstract":"A probabilistic representation for initial value semilinear parabolic problems based on generalized random trees has been derived. Two different strategies have been proposed, both requiring generating suitable random trees combined with a Pade approximant for approximating accurately a given divergent series. Such series are obtained by summing the partial contribution to the solution coming from trees with arbitrary number of branches. The new representation greatly expands the class of problems amenable to be solved probabilistically, and was used successfully to develop a generalized probabilistic domain decomposition method. Such a method has been shown to be suited for massively parallel computers, enjoying full scalability and fault tolerance. Finally, a few numerical examples are given to illustrate the remarkable performance of the algorithm, comparing the results with those obtained with a classical method.","sentences":["A probabilistic representation for initial value semilinear parabolic problems based on generalized random trees has been derived.","Two different strategies have been proposed, both requiring generating suitable random trees combined with a Pade approximant for approximating accurately a given divergent series.","Such series are obtained by summing the partial contribution to the solution coming from trees with arbitrary number of branches.","The new representation greatly expands the class of problems amenable to be solved probabilistically, and was used successfully to develop a generalized probabilistic domain decomposition method.","Such a method has been shown to be suited for massively parallel computers, enjoying full scalability and fault tolerance.","Finally, a few numerical examples are given to illustrate the remarkable performance of the algorithm, comparing the results with those obtained with a classical method."],"url":"http://arxiv.org/abs/2402.06491v1","category":"math.NA"}
{"created":"2024-02-09 15:46:21","title":"Observing quantum many-body scars in random quantum circuits","abstract":"The Schwinger model describes quantum electrodynamics in 1+1-dimensions, it is a prototype for quantum chromodynamics, and its lattice version allows for a quantum link model description that can be simulated using modern quantum devices. In this work, we devise quantum simulations to investigate the dynamics of this model in its low dimensional form, where the gauge field degrees of freedom are described by spin 1/2 operators. We apply trotterization to write quantum circuits that effectively generate the evolution under the Schwinger model Hamiltonian. We consider both sequential circuits, with a fixed gate sequence, and randomized ones. Utilizing the correspondence between the Schwinger model and the PXP model, known for its quantum scars, we investigate the presence of quantum scar states in the Schwinger model by identifying states exhibiting extended thermalization times in our circuit evolutions. Our comparison of sequential and randomized circuit dynamics shows that the non-thermal sector of the Hilbert space, including the scars, are more sensitive to randomization, a feature which can be detected even on relatively short time scales.","sentences":["The Schwinger model describes quantum electrodynamics in 1+1-dimensions, it is a prototype for quantum chromodynamics, and its lattice version allows for a quantum link model description that can be simulated using modern quantum devices.","In this work, we devise quantum simulations to investigate the dynamics of this model in its low dimensional form, where the gauge field degrees of freedom are described by spin 1/2 operators.","We apply trotterization to write quantum circuits that effectively generate the evolution under the Schwinger model Hamiltonian.","We consider both sequential circuits, with a fixed gate sequence, and randomized ones.","Utilizing the correspondence between the Schwinger model and the PXP model, known for its quantum scars, we investigate the presence of quantum scar states in the Schwinger model by identifying states exhibiting extended thermalization times in our circuit evolutions.","Our comparison of sequential and randomized circuit dynamics shows that the non-thermal sector of the Hilbert space, including the scars, are more sensitive to randomization, a feature which can be detected even on relatively short time scales."],"url":"http://arxiv.org/abs/2402.06489v1","category":"quant-ph"}
{"created":"2024-02-09 15:43:31","title":"Le Nozze di Giustizia. Interactions between Artificial Intelligence, Law, Logic, Language and Computation with some case studies in Traffic Regulations and Health Care","abstract":"An important aim of this paper is to convey some basics of mathematical logic to the legal community working with Artificial Intelligence. After analysing what AI is, we decide to delimit ourselves to rule-based AI leaving Neural Networks and Machine Learning aside. Rule based AI allows for Formal methods which are described in a rudimentary form. We will then see how mathematical logic interacts with legal rule-based AI practice. We shall see how mathematical logic imposes limitations and complications to AI applications. We classify the limitations and interactions between mathematical logic and legal AI in three categories: logical, computational and mathematical. The examples to showcase the interactions will largely come from European traffic regulations. The paper closes off with some reflections on how and where AI could be used and on basic mechanisms that shape society.","sentences":["An important aim of this paper is to convey some basics of mathematical logic to the legal community working with Artificial Intelligence.","After analysing what AI is, we decide to delimit ourselves to rule-based AI leaving Neural Networks and Machine Learning aside.","Rule based AI allows for Formal methods which are described in a rudimentary form.","We will then see how mathematical logic interacts with legal rule-based AI practice.","We shall see how mathematical logic imposes limitations and complications to AI applications.","We classify the limitations and interactions between mathematical logic and legal AI in three categories: logical, computational and mathematical.","The examples to showcase the interactions will largely come from European traffic regulations.","The paper closes off with some reflections on how and where AI could be used and on basic mechanisms that shape society."],"url":"http://arxiv.org/abs/2402.06487v1","category":"cs.AI"}
{"created":"2024-02-09 15:42:07","title":"The structural evolution of temporal hypergraphs through the lens of hyper-cores","abstract":"The richness of many complex systems stems from the interactions among their components. The higher-order nature of these interactions, involving many units at once, and their temporal dynamics constitute crucial properties that shape the behaviour of the system itself. An adequate description of these systems is offered by temporal hypergraphs, that integrate these features within the same framework. However, tools for their temporal and topological characterization are still scarce. Here we develop a series of methods specifically designed to analyse the structural properties of temporal hypergraphs at multiple scales. Leveraging the hyper-core decomposition of hypergraphs, we follow the evolution of the hyper-cores through time, characterizing the hypergraph structure and its temporal dynamics at different topological scales, and quantifying the multi-scale structural stability of the system. We also define two static hypercoreness centrality measures that provide an overall description of the nodes aggregated structural behaviour. We apply the characterization methods to several data sets, establishing connections between structural properties and specific activities within the systems. Finally, we show how the proposed method can be used as a model-validation tool for synthetic temporal hypergraphs, distinguishing the higher-order structures and dynamics generated by different models from the empirical ones, and thus identifying the essential model mechanisms to reproduce the empirical hypergraph structure and evolution. Our work opens several research directions, from the understanding of dynamic processes on temporal higher-order networks to the design of new models of time-varying hypergraphs.","sentences":["The richness of many complex systems stems from the interactions among their components.","The higher-order nature of these interactions, involving many units at once, and their temporal dynamics constitute crucial properties that shape the behaviour of the system itself.","An adequate description of these systems is offered by temporal hypergraphs, that integrate these features within the same framework.","However, tools for their temporal and topological characterization are still scarce.","Here we develop a series of methods specifically designed to analyse the structural properties of temporal hypergraphs at multiple scales.","Leveraging the hyper-core decomposition of hypergraphs, we follow the evolution of the hyper-cores through time, characterizing the hypergraph structure and its temporal dynamics at different topological scales, and quantifying the multi-scale structural stability of the system.","We also define two static hypercoreness centrality measures that provide an overall description of the nodes aggregated structural behaviour.","We apply the characterization methods to several data sets, establishing connections between structural properties and specific activities within the systems.","Finally, we show how the proposed method can be used as a model-validation tool for synthetic temporal hypergraphs, distinguishing the higher-order structures and dynamics generated by different models from the empirical ones, and thus identifying the essential model mechanisms to reproduce the empirical hypergraph structure and evolution.","Our work opens several research directions, from the understanding of dynamic processes on temporal higher-order networks to the design of new models of time-varying hypergraphs."],"url":"http://arxiv.org/abs/2402.06485v1","category":"physics.soc-ph"}
{"created":"2024-02-09 15:40:45","title":"Optimal Forecast Reconciliation with Uncertainty Quantification","abstract":"We propose to estimate the weight matrix used for forecast reconciliation as parameters in a general linear model in order to quantify its uncertainty. This implies that forecast reconciliation can be formulated as an orthogonal projection from the space of base-forecast errors into a coherent linear subspace. We use variance decomposition together with the Wishart distribution to derive the central estimator for the forecast-error covariance matrix. In addition, we prove that distance-reducing properties apply to the reconciled forecasts at all levels of the hierarchy as well as to the forecast-error covariance. A covariance matrix for the reconciliation weight matrix is derived, which leads to improved estimates of the forecast-error covariance matrix. We show how shrinkage can be introduced in the formulated model by imposing specific priors on the weight matrix and the forecast-error covariance matrix. The method is illustrated in a simulation study that shows consistent improvements in the log-score. Finally, standard errors for the weight matrix and the variance-separation formula are illustrated using a case study of forecasting electricity load in Sweden.","sentences":["We propose to estimate the weight matrix used for forecast reconciliation as parameters in a general linear model in order to quantify its uncertainty.","This implies that forecast reconciliation can be formulated as an orthogonal projection from the space of base-forecast errors into a coherent linear subspace.","We use variance decomposition together with the Wishart distribution to derive the central estimator for the forecast-error covariance matrix.","In addition, we prove that distance-reducing properties apply to the reconciled forecasts at all levels of the hierarchy as well as to the forecast-error covariance.","A covariance matrix for the reconciliation weight matrix is derived, which leads to improved estimates of the forecast-error covariance matrix.","We show how shrinkage can be introduced in the formulated model by imposing specific priors on the weight matrix and the forecast-error covariance matrix.","The method is illustrated in a simulation study that shows consistent improvements in the log-score.","Finally, standard errors for the weight matrix and the variance-separation formula are illustrated using a case study of forecasting electricity load in Sweden."],"url":"http://arxiv.org/abs/2402.06480v1","category":"stat.ME"}
{"created":"2024-02-09 15:31:01","title":"Large Language Models for Captioning and Retrieving Remote Sensing Images","abstract":"Image captioning and cross-modal retrieval are examples of tasks that involve the joint analysis of visual and linguistic information. In connection to remote sensing imagery, these tasks can help non-expert users in extracting relevant Earth observation information for a variety of applications. Still, despite some previous efforts, the development and application of vision and language models to the remote sensing domain have been hindered by the relatively small size of the available datasets and models used in previous studies. In this work, we propose RS-CapRet, a Vision and Language method for remote sensing tasks, in particular image captioning and text-image retrieval. We specifically propose to use a highly capable large decoder language model together with image encoders adapted to remote sensing imagery through contrastive language-image pre-training. To bridge together the image encoder and language decoder, we propose training simple linear layers with examples from combining different remote sensing image captioning datasets, keeping the other parameters frozen. RS-CapRet can then generate descriptions for remote sensing images and retrieve images from textual descriptions, achieving SOTA or competitive performance with existing methods. Qualitative results illustrate that RS-CapRet can effectively leverage the pre-trained large language model to describe remote sensing images, retrieve them based on different types of queries, and also show the ability to process interleaved sequences of images and text in a dialogue manner.","sentences":["Image captioning and cross-modal retrieval are examples of tasks that involve the joint analysis of visual and linguistic information.","In connection to remote sensing imagery, these tasks can help non-expert users in extracting relevant Earth observation information for a variety of applications.","Still, despite some previous efforts, the development and application of vision and language models to the remote sensing domain have been hindered by the relatively small size of the available datasets and models used in previous studies.","In this work, we propose RS-CapRet, a Vision and Language method for remote sensing tasks, in particular image captioning and text-image retrieval.","We specifically propose to use a highly capable large decoder language model together with image encoders adapted to remote sensing imagery through contrastive language-image pre-training.","To bridge together the image encoder and language decoder, we propose training simple linear layers with examples from combining different remote sensing image captioning datasets, keeping the other parameters frozen.","RS-CapRet can then generate descriptions for remote sensing images and retrieve images from textual descriptions, achieving SOTA or competitive performance with existing methods.","Qualitative results illustrate that RS-CapRet can effectively leverage the pre-trained large language model to describe remote sensing images, retrieve them based on different types of queries, and also show the ability to process interleaved sequences of images and text in a dialogue manner."],"url":"http://arxiv.org/abs/2402.06475v1","category":"cs.CV"}
{"created":"2024-02-09 15:26:14","title":"Conservative polynomial approximations and applications to Fokker-Planck equations","abstract":"We address the problem of constructing approximations based on orthogonal polynomials that preserve an arbitrary set of moments of a given function without loosing the spectral convergence property. To this aim, we compute the constrained polynomial of best approximation for a generic basis of orthogonal polynomials. The construction is entirely general and allows us to derive structure preserving numerical methods for partial differential equations that require the conservation of some moments of the solution, typically representing relevant physical quantities of the problem. These properties are essential to capture with high accuracy the long-time behavior of the solution. We illustrate with the aid of several numerical applications to Fokker-Planck equations the generality and the performances of the present approach.","sentences":["We address the problem of constructing approximations based on orthogonal polynomials that preserve an arbitrary set of moments of a given function without loosing the spectral convergence property.","To this aim, we compute the constrained polynomial of best approximation for a generic basis of orthogonal polynomials.","The construction is entirely general and allows us to derive structure preserving numerical methods for partial differential equations that require the conservation of some moments of the solution, typically representing relevant physical quantities of the problem.","These properties are essential to capture with high accuracy the long-time behavior of the solution.","We illustrate with the aid of several numerical applications to Fokker-Planck equations the generality and the performances of the present approach."],"url":"http://arxiv.org/abs/2402.06473v1","category":"math.NA"}
{"created":"2024-02-09 15:25:36","title":"\"When He Feels Cold, He Goes to the Seahorse\"-Blending Generative AI into Multimaterial Storymaking for Family Expressive Arts Therapy","abstract":"Storymaking, as an integrative form of expressive arts therapy, is an effective means to foster family communication. Yet, the integration of generative AI as expressive materials in therapeutic storymaking remains underexplored. And there is a lack of HCI implications on how to support families and therapists in this context. Addressing this, our study involved five weeks of storymaking sessions with seven families guided by a professional therapist. In these sessions, the families used both traditional art-making materials and image-based generative AI to create and evolve their family stories. Via the rich empirical data and commentaries from four expert therapists, we contextualize how families creatively melded AI and traditional expressive materials to externalize their ideas and feelings. Through the lens of Expressive Therapies Continuum (ETC), we characterize the therapeutic implications of AI as expressive materials. Desirable interaction qualities to support children, parents, and therapists are distilled for future HCI research.","sentences":["Storymaking, as an integrative form of expressive arts therapy, is an effective means to foster family communication.","Yet, the integration of generative AI as expressive materials in therapeutic storymaking remains underexplored.","And there is a lack of HCI implications on how to support families and therapists in this context.","Addressing this, our study involved five weeks of storymaking sessions with seven families guided by a professional therapist.","In these sessions, the families used both traditional art-making materials and image-based generative AI to create and evolve their family stories.","Via the rich empirical data and commentaries from four expert therapists, we contextualize how families creatively melded AI and traditional expressive materials to externalize their ideas and feelings.","Through the lens of Expressive Therapies Continuum (ETC), we characterize the therapeutic implications of AI as expressive materials.","Desirable interaction qualities to support children, parents, and therapists are distilled for future HCI research."],"url":"http://arxiv.org/abs/2402.06472v1","category":"cs.HC"}
{"created":"2024-02-09 15:23:05","title":"Environmental Awareness Dynamic 5G QoS for Retaining Real Time Constraints in Robotic Applications","abstract":"The fifth generation (5G) cellular network technology is mature and increasingly utilized in many industrial and robotics applications, while an important functionality is the advanced Quality of Service (QoS) features. Despite the prevalence of 5G QoS discussions in the related literature, there is a notable absence of real-life implementations and studies concerning their application in time-critical robotics scenarios. This article considers the operation of time-critical applications for 5G-enabled unmanned aerial vehicles (UAVs) and how their operation can be improved by the possibility to dynamically switch between QoS data flows with different priorities. As such, we introduce a robotics oriented analysis on the impact of the 5G QoS functionality on the performance of 5G-enabled UAVs. Furthermore, we introduce a novel framework for the dynamic selection of distinct 5G QoS data flows that is autonomously managed by the 5G-enabled UAV. This problem is addressed in a novel feedback loop fashion utilizing a probabilistic finite state machine (PFSM). Finally, the efficacy of the proposed scheme is experimentally validated with a 5G-enabled UAV in a real-world 5G stand-alone (SA) network.","sentences":["The fifth generation (5G) cellular network technology is mature and increasingly utilized in many industrial and robotics applications, while an important functionality is the advanced Quality of Service (QoS) features.","Despite the prevalence of 5G QoS discussions in the related literature, there is a notable absence of real-life implementations and studies concerning their application in time-critical robotics scenarios.","This article considers the operation of time-critical applications for 5G-enabled unmanned aerial vehicles (UAVs) and how their operation can be improved by the possibility to dynamically switch between QoS data flows with different priorities.","As such, we introduce a robotics oriented analysis on the impact of the 5G QoS functionality on the performance of 5G-enabled UAVs.","Furthermore, we introduce a novel framework for the dynamic selection of distinct 5G QoS data flows that is autonomously managed by the 5G-enabled UAV.","This problem is addressed in a novel feedback loop fashion utilizing a probabilistic finite state machine (PFSM).","Finally, the efficacy of the proposed scheme is experimentally validated with a 5G-enabled UAV in a real-world 5G stand-alone (SA) network."],"url":"http://arxiv.org/abs/2402.06470v1","category":"cs.RO"}
{"created":"2024-02-09 15:17:53","title":"On Differentially Private Subspace Estimation Without Distributional Assumptions","abstract":"Private data analysis faces a significant challenge known as the curse of dimensionality, leading to increased costs. However, many datasets possess an inherent low-dimensional structure. For instance, during optimization via gradient descent, the gradients frequently reside near a low-dimensional subspace. If the low-dimensional structure could be privately identified using a small amount of points, we could avoid paying (in terms of privacy and accuracy) for the high ambient dimension.   On the negative side, Dwork, Talwar, Thakurta, and Zhang (STOC 2014) proved that privately estimating subspaces, in general, requires an amount of points that depends on the dimension. But Singhal and Steinke (NeurIPS 2021) bypassed this limitation by considering points that are i.i.d. samples from a Gaussian distribution whose covariance matrix has a certain eigenvalue gap. Yet, it was still left unclear whether we could provide similar upper bounds without distributional assumptions and whether we could prove lower bounds that depend on similar eigenvalue gaps.   In this work, we make progress in both directions. We formulate the problem of private subspace estimation under two different types of singular value gaps of the input data and prove new upper and lower bounds for both types. In particular, our results determine what type of gap is sufficient and necessary for estimating a subspace with an amount of points that is independent of the dimension.","sentences":["Private data analysis faces a significant challenge known as the curse of dimensionality, leading to increased costs.","However, many datasets possess an inherent low-dimensional structure.","For instance, during optimization via gradient descent, the gradients frequently reside near a low-dimensional subspace.","If the low-dimensional structure could be privately identified using a small amount of points, we could avoid paying (in terms of privacy and accuracy) for the high ambient dimension.   ","On the negative side, Dwork, Talwar, Thakurta, and Zhang (STOC 2014) proved that privately estimating subspaces, in general, requires an amount of points that depends on the dimension.","But Singhal and Steinke (NeurIPS 2021) bypassed this limitation by considering points that are i.i.d. samples from a Gaussian distribution whose covariance matrix has a certain eigenvalue gap.","Yet, it was still left unclear whether we could provide similar upper bounds without distributional assumptions and whether we could prove lower bounds that depend on similar eigenvalue gaps.   ","In this work, we make progress in both directions.","We formulate the problem of private subspace estimation under two different types of singular value gaps of the input data and prove new upper and lower bounds for both types.","In particular, our results determine what type of gap is sufficient and necessary for estimating a subspace with an amount of points that is independent of the dimension."],"url":"http://arxiv.org/abs/2402.06465v1","category":"cs.LG"}
{"created":"2024-02-09 15:14:48","title":"Cardiac ultrasound simulation for autonomous ultrasound navigation","abstract":"Ultrasound is well-established as an imaging modality for diagnostic and interventional purposes. However, the image quality varies with operator skills as acquiring and interpreting ultrasound images requires extensive training due to the imaging artefacts, the range of acquisition parameters and the variability of patient anatomies. Automating the image acquisition task could improve acquisition reproducibility and quality but training such an algorithm requires large amounts of navigation data, not saved in routine examinations. Thus, we propose a method to generate large amounts of ultrasound images from other modalities and from arbitrary positions, such that this pipeline can later be used by learning algorithms for navigation. We present a novel simulation pipeline which uses segmentations from other modalities, an optimized volumetric data representation and GPU-accelerated Monte Carlo path tracing to generate view-dependent and patient-specific ultrasound images. We extensively validate the correctness of our pipeline with a phantom experiment, where structures' sizes, contrast and speckle noise properties are assessed. Furthermore, we demonstrate its usability to train neural networks for navigation in an echocardiography view classification experiment by generating synthetic images from more than 1000 patients. Networks pre-trained with our simulations achieve significantly superior performance in settings where large real datasets are not available, especially for under-represented classes. The proposed approach allows for fast and accurate patient-specific ultrasound image generation, and its usability for training networks for navigation-related tasks is demonstrated.","sentences":["Ultrasound is well-established as an imaging modality for diagnostic and interventional purposes.","However, the image quality varies with operator skills as acquiring and interpreting ultrasound images requires extensive training due to the imaging artefacts, the range of acquisition parameters and the variability of patient anatomies.","Automating the image acquisition task could improve acquisition reproducibility and quality but training such an algorithm requires large amounts of navigation data, not saved in routine examinations.","Thus, we propose a method to generate large amounts of ultrasound images from other modalities and from arbitrary positions, such that this pipeline can later be used by learning algorithms for navigation.","We present a novel simulation pipeline which uses segmentations from other modalities, an optimized volumetric data representation and GPU-accelerated Monte Carlo path tracing to generate view-dependent and patient-specific ultrasound images.","We extensively validate the correctness of our pipeline with a phantom experiment, where structures' sizes, contrast and speckle noise properties are assessed.","Furthermore, we demonstrate its usability to train neural networks for navigation in an echocardiography view classification experiment by generating synthetic images from more than 1000 patients.","Networks pre-trained with our simulations achieve significantly superior performance in settings where large real datasets are not available, especially for under-represented classes.","The proposed approach allows for fast and accurate patient-specific ultrasound image generation, and its usability for training networks for navigation-related tasks is demonstrated."],"url":"http://arxiv.org/abs/2402.06463v1","category":"eess.IV"}
{"created":"2024-02-09 15:09:38","title":"Sequential Flow Matching for Generative Modeling","abstract":"Straightening the probability flow of the continuous-time generative models, such as diffusion models or flow-based models, is the key to fast sampling through the numerical solvers, existing methods learn a linear path by directly generating the probability path the joint distribution between the noise and data distribution. One key reason for the slow sampling speed of the ODE-based solvers that simulate these generative models is the global truncation error of the ODE solver, caused by the high curvature of the ODE trajectory, which explodes the truncation error of the numerical solvers in the low-NFE regime. To address this challenge, We propose a novel method called SeqRF, a learning technique that straightens the probability flow to reduce the global truncation error and hence enable acceleration of sampling and improve the synthesis quality. In both theoretical and empirical studies, we first observe the straightening property of our SeqRF. Through empirical evaluations via SeqRF over flow-based generative models, We achieve surpassing results on CIFAR-10, CelebA-$64 \\times 64$, and LSUN-Church datasets.","sentences":["Straightening the probability flow of the continuous-time generative models, such as diffusion models or flow-based models, is the key to fast sampling through the numerical solvers, existing methods learn a linear path by directly generating the probability path the joint distribution between the noise and data distribution.","One key reason for the slow sampling speed of the ODE-based solvers that simulate these generative models is the global truncation error of the ODE solver, caused by the high curvature of the ODE trajectory, which explodes the truncation error of the numerical solvers in the low-NFE regime.","To address this challenge, We propose a novel method called SeqRF, a learning technique that straightens the probability flow to reduce the global truncation error and hence enable acceleration of sampling and improve the synthesis quality.","In both theoretical and empirical studies, we first observe the straightening property of our SeqRF.","Through empirical evaluations via SeqRF over flow-based generative models, We achieve surpassing results on CIFAR-10, CelebA-$64 \\times 64$, and LSUN-Church datasets."],"url":"http://arxiv.org/abs/2402.06461v1","category":"cs.LG"}
{"created":"2024-02-09 15:04:16","title":"Maximizing NFT Incentives: References Make You Rich","abstract":"In this paper, we study how to optimize existing Non-Fungible Token (NFT) incentives. Upon exploring a large number of NFT-related standards and real-world projects, we come across an unexpected finding. That is, the current NFT incentive mechanisms, often organized in an isolated and one-time-use fashion, tend to overlook their potential for scalable organizational structures.   We propose, analyze, and implement a novel reference incentive model, which is inherently structured as a Directed Acyclic Graph (DAG)-based NFT network. This model aims to maximize connections (or references) between NFTs, enabling each isolated NFT to expand its network and accumulate rewards derived from subsequent or subscribed ones. We conduct both theoretical and practical analyses of the model, demonstrating its optimal utility.","sentences":["In this paper, we study how to optimize existing Non-Fungible Token (NFT) incentives.","Upon exploring a large number of NFT-related standards and real-world projects, we come across an unexpected finding.","That is, the current NFT incentive mechanisms, often organized in an isolated and one-time-use fashion, tend to overlook their potential for scalable organizational structures.   ","We propose, analyze, and implement a novel reference incentive model, which is inherently structured as a Directed Acyclic Graph (DAG)-based NFT network.","This model aims to maximize connections (or references) between NFTs, enabling each isolated NFT to expand its network and accumulate rewards derived from subsequent or subscribed ones.","We conduct both theoretical and practical analyses of the model, demonstrating its optimal utility."],"url":"http://arxiv.org/abs/2402.06459v1","category":"cs.GT"}
{"created":"2024-02-09 15:03:37","title":"A new proof of the Perron-Frobeniuos theorem, a variational approach","abstract":"We generalized the Perron-Frobenious theory by using a variational approach and extended it to sets of arbitrary matrices, including those that are not either irreducible or essentially positive. We introduce a new concept called a \"quasi-eigenvalues of a matrix\", which is invariant under orthogonal transformations of variables, and has various useful properties, including such as determining the largest of the real parts of eigenvalues of a matrix. Additionally, we establish new results on the continuity of the spectral radius, as well as obtain new types of estimates for the ranges of the sets of eigenvalues and their real parts.","sentences":["We generalized the Perron-Frobenious theory by using a variational approach and extended it to sets of arbitrary matrices, including those that are not either irreducible or essentially positive.","We introduce a new concept called a \"quasi-eigenvalues of a matrix\", which is invariant under orthogonal transformations of variables, and has various useful properties, including such as determining the largest of the real parts of eigenvalues of a matrix.","Additionally, we establish new results on the continuity of the spectral radius, as well as obtain new types of estimates for the ranges of the sets of eigenvalues and their real parts."],"url":"http://arxiv.org/abs/2402.06458v1","category":"math.AP"}
{"created":"2024-02-09 15:02:56","title":"V-STaR: Training Verifiers for Self-Taught Reasoners","abstract":"Common self-improvement approaches for large language models (LLMs), such as STaR (Zelikman et al., 2022), iteratively fine-tune LLMs on self-generated solutions to improve their problem-solving ability. However, these approaches discard the large amounts of incorrect solutions generated during this process, potentially neglecting valuable information in such solutions. To address this shortcoming, we propose V-STaR that utilizes both the correct and incorrect solutions generated during the self-improvement process to train a verifier using DPO that judges correctness of model-generated solutions. This verifier is used at inference time to select one solution among many candidate solutions. Running V-STaR for multiple iterations results in progressively better reasoners and verifiers, delivering a 4% to 17% test accuracy improvement over existing self-improvement and verification approaches on common code generation and math reasoning benchmarks with LLaMA2 models.","sentences":["Common self-improvement approaches for large language models (LLMs), such as STaR (Zelikman et al., 2022), iteratively fine-tune LLMs on self-generated solutions to improve their problem-solving ability.","However, these approaches discard the large amounts of incorrect solutions generated during this process, potentially neglecting valuable information in such solutions.","To address this shortcoming, we propose V-STaR that utilizes both the correct and incorrect solutions generated during the self-improvement process to train a verifier using DPO that judges correctness of model-generated solutions.","This verifier is used at inference time to select one solution among many candidate solutions.","Running V-STaR for multiple iterations results in progressively better reasoners and verifiers, delivering a 4% to 17% test accuracy improvement over existing self-improvement and verification approaches on common code generation and math reasoning benchmarks with LLaMA2 models."],"url":"http://arxiv.org/abs/2402.06457v1","category":"cs.LG"}
{"created":"2024-02-09 14:50:09","title":"On the irreducibility and convergence of a class of nonsmooth nonlinear state-space models on manifolds","abstract":"In this paper, we analyze a large class of general nonlinear state-space models on a state-space X, defined by the recursion $\\phi_{k+1} = F(\\phi_k,\\alpha(\\phi_k,U_{k+1}))$, $k \\in\\bN$, where $F,\\alpha$ are some functions and $\\{U_{k+1}\\}_{k\\in\\bN}$ is a sequence of i.i.d. random variables. More precisely, we extend conditions under which this class of Markov chains is irreducible, aperiodic and satisfies important continuity properties, relaxing two key assumptions from prior works. First, the state-space X is supposed to be a smooth manifold instead of an open subset of a Euclidean space. Second, we only suppose that $F is locally Lipschitz continuous.   We demonstrate the significance of our results through their application to Markov chains underlying optimization algorithms. These schemes belong to the class of evolution strategies with covariance matrix adaptation and step-size adaptation.","sentences":["In this paper, we analyze a large class of general nonlinear state-space models on a state-space X, defined by the recursion $\\phi_{k+1} = F(\\phi_k,\\alpha(\\phi_k,U_{k+1}))$, $k \\in\\bN$, where $F,\\alpha$ are some functions and $\\{U_{k+1}\\}_{k\\in\\bN}$ is a sequence of i.i.d. random variables.","More precisely, we extend conditions under which this class of Markov chains is irreducible, aperiodic and satisfies important continuity properties, relaxing two key assumptions from prior works.","First, the state-space X is supposed to be a smooth manifold instead of an open subset of a Euclidean space.","Second, we only suppose that $F is locally Lipschitz continuous.   ","We demonstrate the significance of our results through their application to Markov chains underlying optimization algorithms.","These schemes belong to the class of evolution strategies with covariance matrix adaptation and step-size adaptation."],"url":"http://arxiv.org/abs/2402.06447v1","category":"math.OC"}
{"created":"2024-02-09 14:48:20","title":"ControlUDA: Controllable Diffusion-assisted Unsupervised Domain Adaptation for Cross-Weather Semantic Segmentation","abstract":"Data generation is recognized as a potent strategy for unsupervised domain adaptation (UDA) pertaining semantic segmentation in adverse weathers. Nevertheless, these adverse weather scenarios encompass multiple possibilities, and high-fidelity data synthesis with controllable weather is under-researched in previous UDA works. The recent strides in large-scale text-to-image diffusion models (DM) have ushered in a novel avenue for research, enabling the generation of realistic images conditioned on semantic labels. This capability proves instrumental for cross-domain data synthesis from source to target domain owing to their shared label space. Thus, source domain labels can be paired with those generated pseudo target data for training UDA. However, from the UDA perspective, there exists several challenges for DM training: (i) ground-truth labels from target domain are missing; (ii) the prompt generator may produce vague or noisy descriptions of images from adverse weathers; (iii) existing arts often struggle to well handle the complex scene structure and geometry of urban scenes when conditioned only on semantic labels. To tackle the above issues, we propose ControlUDA, a diffusion-assisted framework tailored for UDA segmentation under adverse weather conditions. It first leverages target prior from a pre-trained segmentor for tuning the DM, compensating the missing target domain labels; It also contains UDAControlNet, a condition-fused multi-scale and prompt-enhanced network targeted at high-fidelity data generation in adverse weathers. Training UDA with our generated data brings the model performances to a new milestone (72.0 mIoU) on the popular Cityscapes-to-ACDC benchmark for adverse weathers. Furthermore, ControlUDA helps to achieve good model generalizability on unseen data.","sentences":["Data generation is recognized as a potent strategy for unsupervised domain adaptation (UDA) pertaining semantic segmentation in adverse weathers.","Nevertheless, these adverse weather scenarios encompass multiple possibilities, and high-fidelity data synthesis with controllable weather is under-researched in previous UDA works.","The recent strides in large-scale text-to-image diffusion models (DM) have ushered in a novel avenue for research, enabling the generation of realistic images conditioned on semantic labels.","This capability proves instrumental for cross-domain data synthesis from source to target domain owing to their shared label space.","Thus, source domain labels can be paired with those generated pseudo target data for training UDA.","However, from the UDA perspective, there exists several challenges for DM training: (i) ground-truth labels from target domain are missing; (ii) the prompt generator may produce vague or noisy descriptions of images from adverse weathers; (iii) existing arts often struggle to well handle the complex scene structure and geometry of urban scenes when conditioned only on semantic labels.","To tackle the above issues, we propose ControlUDA, a diffusion-assisted framework tailored for UDA segmentation under adverse weather conditions.","It first leverages target prior from a pre-trained segmentor for tuning the DM, compensating the missing target domain labels; It also contains UDAControlNet, a condition-fused multi-scale and prompt-enhanced network targeted at high-fidelity data generation in adverse weathers.","Training UDA with our generated data brings the model performances to a new milestone (72.0 mIoU) on the popular Cityscapes-to-ACDC benchmark for adverse weathers.","Furthermore, ControlUDA helps to achieve good model generalizability on unseen data."],"url":"http://arxiv.org/abs/2402.06446v1","category":"cs.CV"}
{"created":"2024-02-09 14:44:18","title":"The real spectrum and the oriented Gromov--Hausdorff compactifications of character varieties","abstract":"The character variety, which parametrizes reductive representations of finitely generated groups in $\\mathrm{PSL}_2(\\mathbb{R})$, has many compactifications. We construct a continuous surjection from the real spectrum compactification to the oriented Gromov--Hausdorff compactification of the character variety. For this purpose, we assign an orientation to the real trees appearing in the boundary of the real spectrum compactification using that the usual orientation on the circle is described by a semi-algebraic equation. Moreover, we show that the orientation on the real trees which appear in the boundary of both compactifications are well understood by the study of sequences within the character variety that converge toward the points in the boundary.","sentences":["The character variety, which parametrizes reductive representations of finitely generated groups in $\\mathrm{PSL}_2(\\mathbb{R})$, has many compactifications.","We construct a continuous surjection from the real spectrum compactification to the oriented Gromov--Hausdorff compactification of the character variety.","For this purpose, we assign an orientation to the real trees appearing in the boundary of the real spectrum compactification using that the usual orientation on the circle is described by a semi-algebraic equation.","Moreover, we show that the orientation on the real trees which appear in the boundary of both compactifications are well understood by the study of sequences within the character variety that converge toward the points in the boundary."],"url":"http://arxiv.org/abs/2402.06444v1","category":"math.GT"}
{"created":"2024-02-09 14:39:20","title":"Explaining Veracity Predictions with Evidence Summarization: A Multi-Task Model Approach","abstract":"The rapid dissemination of misinformation through social media increased the importance of automated fact-checking. Furthermore, studies on what deep neural models pay attention to when making predictions have increased in recent years. While significant progress has been made in this field, it has not yet reached a level of reasoning comparable to human reasoning. To address these gaps, we propose a multi-task explainable neural model for misinformation detection. Specifically, this work formulates an explanation generation process of the model's veracity prediction as a text summarization problem. Additionally, the performance of the proposed model is discussed on publicly available datasets and the findings are evaluated with related studies.","sentences":["The rapid dissemination of misinformation through social media increased the importance of automated fact-checking.","Furthermore, studies on what deep neural models pay attention to when making predictions have increased in recent years.","While significant progress has been made in this field, it has not yet reached a level of reasoning comparable to human reasoning.","To address these gaps, we propose a multi-task explainable neural model for misinformation detection.","Specifically, this work formulates an explanation generation process of the model's veracity prediction as a text summarization problem.","Additionally, the performance of the proposed model is discussed on publicly available datasets and the findings are evaluated with related studies."],"url":"http://arxiv.org/abs/2402.06443v1","category":"cs.CL"}
{"created":"2024-02-09 14:34:09","title":"A Method for Decrypting Data Infected with Rhysida Ransomware","abstract":"Ransomware is malicious software that is a prominent global cybersecurity threat. Typically, ransomware encrypts data on a system, rendering the victim unable to decrypt it without the attacker's private key. Subsequently, victims often pay a substantial ransom to recover their data, yet some may still incur damage or loss. This study examines Rhysida ransomware, which caused significant damage in the second half of 2023, and proposes a decryption method. Rhysida ransomware employed a secure random number generator to generate the encryption key and subsequently encrypt the data. However, an implementation vulnerability existed that enabled us to regenerate the internal state of the random number generator at the time of infection. We successfully decrypted the data using the regenerated random number generator. To the best of our knowledge, this is the first successful decryption of Rhysida ransomware. We aspire for our work to contribute to mitigating the damage inflicted by the Rhysida ransomware.","sentences":["Ransomware is malicious software that is a prominent global cybersecurity threat.","Typically, ransomware encrypts data on a system, rendering the victim unable to decrypt it without the attacker's private key.","Subsequently, victims often pay a substantial ransom to recover their data, yet some may still incur damage or loss.","This study examines Rhysida ransomware, which caused significant damage in the second half of 2023, and proposes a decryption method.","Rhysida ransomware employed a secure random number generator to generate the encryption key and subsequently encrypt the data.","However, an implementation vulnerability existed that enabled us to regenerate the internal state of the random number generator at the time of infection.","We successfully decrypted the data using the regenerated random number generator.","To the best of our knowledge, this is the first successful decryption of Rhysida ransomware.","We aspire for our work to contribute to mitigating the damage inflicted by the Rhysida ransomware."],"url":"http://arxiv.org/abs/2402.06440v1","category":"cs.CR"}
{"created":"2024-02-09 14:30:47","title":"Selective Radiance in Super-Wavelength Atomic Arrays","abstract":"A novel way to create efficient atom-light interfaces is to engineer collective atomic states that selectively radiate into a target optical mode by suppressing emission into undesired modes through destructive interference. While it is generally assumed that this approach requires dense atomic arrays with sub-wavelength lattice constants, here we show that selective radiance can also be achieved in arrays with super-wavelength spacing. By stacking multiple two-dimensional arrays we find super-wavelength mirror configurations where one can eliminate emission into unwanted diffraction orders while enhancing emission into the desired specular mode, leading to near-perfect reflection of weak resonant light. These super-wavelength arrays can also be functionalized into efficient quantum memories, with error probabilities on the order of ~1 for a trilayer with only around ~100 atoms per layer. Relaxing the previous constraint of sub-wavelength spacing could potentially ease the technical requirements for realizing efficient atom-light interfaces, such as enabling the use of tweezer arrays.","sentences":["A novel way to create efficient atom-light interfaces is to engineer collective atomic states that selectively radiate into a target optical mode by suppressing emission into undesired modes through destructive interference.","While it is generally assumed that this approach requires dense atomic arrays with sub-wavelength lattice constants, here we show that selective radiance can also be achieved in arrays with super-wavelength spacing.","By stacking multiple two-dimensional arrays we find super-wavelength mirror configurations where one can eliminate emission into unwanted diffraction orders while enhancing emission into the desired specular mode, leading to near-perfect reflection of weak resonant light.","These super-wavelength arrays can also be functionalized into efficient quantum memories, with error probabilities on the order of ~1 for a trilayer with only around ~100 atoms per layer.","Relaxing the previous constraint of sub-wavelength spacing could potentially ease the technical requirements for realizing efficient atom-light interfaces, such as enabling the use of tweezer arrays."],"url":"http://arxiv.org/abs/2402.06439v1","category":"quant-ph"}
{"created":"2024-02-09 14:24:18","title":"Where is the Truth? The Risk of Getting Confounded in a Continual World","abstract":"A dataset is confounded if it is most easily solved via a spurious correlation which fails to generalize to new data. We will show that, in a continual learning setting where confounders may vary in time across tasks, the resulting challenge far exceeds the standard forgetting problem normally considered. In particular, we derive mathematically the effect of such confounders on the space of valid joint solutions to sets of confounded tasks. Interestingly, our theory predicts that for many such continual datasets, spurious correlations are easily ignored when the tasks are trained on jointly, but it is far harder to avoid confounding when they are considered sequentially. We construct such a dataset and demonstrate empirically that standard continual learning methods fail to ignore confounders, while training jointly on all tasks is successful. Our continually confounded dataset, ConCon, is based on CLEVR images and demonstrates the need for continual learning methods with more robust behavior with respect to confounding.","sentences":["A dataset is confounded if it is most easily solved via a spurious correlation which fails to generalize to new data.","We will show that, in a continual learning setting where confounders may vary in time across tasks, the resulting challenge far exceeds the standard forgetting problem normally considered.","In particular, we derive mathematically the effect of such confounders on the space of valid joint solutions to sets of confounded tasks.","Interestingly, our theory predicts that for many such continual datasets, spurious correlations are easily ignored when the tasks are trained on jointly, but it is far harder to avoid confounding when they are considered sequentially.","We construct such a dataset and demonstrate empirically that standard continual learning methods fail to ignore confounders, while training jointly on all tasks is successful.","Our continually confounded dataset, ConCon, is based on CLEVR images and demonstrates the need for continual learning methods with more robust behavior with respect to confounding."],"url":"http://arxiv.org/abs/2402.06434v1","category":"cs.LG"}
{"created":"2024-02-09 14:24:15","title":"Reaction rate of the radiative capture proton by 10B","abstract":"The 10B(p,{\\gamma})11C reaction is of significant interest in nuclear astrophysics and in the field of controlled thermonuclear fusion. This reaction is one of the reactions of 11B production, which is carried out through the 10B(p,{\\gamma})11C(\\b{eta}+{\\nu})11B chain. The rate of the 10B(p,{\\gamma})11C reaction (occurring in the interiors of first-generation stars) can be of great importance for the amount of 10B and 11B observed today in the interstellar medium and in the Earth's crust. In thermonuclear reactors, structural elements containing boron can be used as neutron absorbers, etc. Therefore, in this work, within the framework of a modified potential cluster model with a classification of orbital states according to Young's diagrams and taking into account allowed and forbidden states, we examined the possibility of describing the available experimental data for the total cross sections of the radiative p10B capture to the ground state of the 11C nucleus at energies up to 1 MeV. It is shown that only on the basis of E1 and M1 transitions from the p10B scattering states, taking into account the first resonance for the ground state of the 11C nucleus, it is quite possible to explain the magnitude and shape of the experimental astrophysical S-factor. The work presents comparisons the astrophysical S-factors of the radiative p10B capture to the ground state of the 11C nucleus found by us with the experimental data available in the literature. Based on the obtained theoretical S-factor, the rate of this reaction was calculated in the temperature range from 0.01 to 1 T9. The calculated results for rates are approximated by a simple expression, which simplifies their use in applied thermonuclear and astrophysical research.","sentences":["The 10B(p,{\\gamma})11C reaction is of significant interest in nuclear astrophysics and in the field of controlled thermonuclear fusion.","This reaction is one of the reactions of 11B production, which is carried out through the 10B(p,{\\gamma})11C(\\b{eta}+{\\nu})11B chain.","The rate of the 10B(p,{\\gamma})11C reaction (occurring in the interiors of first-generation stars) can be of great importance for the amount of 10B and 11B observed today in the interstellar medium and in the Earth's crust.","In thermonuclear reactors, structural elements containing boron can be used as neutron absorbers, etc.","Therefore, in this work, within the framework of a modified potential cluster model with a classification of orbital states according to Young's diagrams and taking into account allowed and forbidden states, we examined the possibility of describing the available experimental data for the total cross sections of the radiative p10B capture to the ground state of the 11C nucleus at energies up to 1 MeV.","It is shown that only on the basis of E1 and M1 transitions from the p10B scattering states, taking into account the first resonance for the ground state of the 11C nucleus, it is quite possible to explain the magnitude and shape of the experimental astrophysical S-factor.","The work presents comparisons the astrophysical S-factors of the radiative p10B capture to the ground state of the 11C nucleus found by us with the experimental data available in the literature.","Based on the obtained theoretical S-factor, the rate of this reaction was calculated in the temperature range from 0.01 to 1 T9.","The calculated results for rates are approximated by a simple expression, which simplifies their use in applied thermonuclear and astrophysical research."],"url":"http://arxiv.org/abs/2402.06433v1","category":"nucl-th"}
{"created":"2024-02-09 14:13:40","title":"CurveFormer++: 3D Lane Detection by Curve Propagation with Temporal Curve Queries and Attention","abstract":"In autonomous driving, 3D lane detection using monocular cameras is an important task for various downstream planning and control tasks. Recent CNN and Transformer approaches usually apply a two-stage scheme in the model design. The first stage transforms the image feature from a front image into a bird's-eye-view (BEV) representation. Subsequently, a sub-network processes the BEV feature map to generate the 3D detection results. However, these approaches heavily rely on a challenging image feature transformation module from a perspective view to a BEV representation. In our work, we present CurveFormer++, a single-stage Transformer-based method that does not require the image feature view transform module and directly infers 3D lane detection results from the perspective image features. Specifically, our approach models the 3D detection task as a curve propagation problem, where each lane is represented by a curve query with a dynamic and ordered anchor point set. By employing a Transformer decoder, the model can iteratively refine the 3D lane detection results. A curve cross-attention module is introduced in the Transformer decoder to calculate similarities between image features and curve queries of lanes. To handle varying lane lengths, we employ context sampling and anchor point restriction techniques to compute more relevant image features for a curve query. Furthermore, we apply a temporal fusion module that incorporates selected informative sparse curve queries and their corresponding anchor point sets to leverage historical lane information. In the experiments, we evaluate our approach for the 3D lane detection task on two publicly available real-world datasets. The results demonstrate that our method provides outstanding performance compared with both CNN and Transformer based methods. We also conduct ablation studies to analyze the impact of each component in our approach.","sentences":["In autonomous driving, 3D lane detection using monocular cameras is an important task for various downstream planning and control tasks.","Recent CNN and Transformer approaches usually apply a two-stage scheme in the model design.","The first stage transforms the image feature from a front image into a bird's-eye-view (BEV) representation.","Subsequently, a sub-network processes the BEV feature map to generate the 3D detection results.","However, these approaches heavily rely on a challenging image feature transformation module from a perspective view to a BEV representation.","In our work, we present CurveFormer++, a single-stage Transformer-based method that does not require the image feature view transform module and directly infers 3D lane detection results from the perspective image features.","Specifically, our approach models the 3D detection task as a curve propagation problem, where each lane is represented by a curve query with a dynamic and ordered anchor point set.","By employing a Transformer decoder, the model can iteratively refine the 3D lane detection results.","A curve cross-attention module is introduced in the Transformer decoder to calculate similarities between image features and curve queries of lanes.","To handle varying lane lengths, we employ context sampling and anchor point restriction techniques to compute more relevant image features for a curve query.","Furthermore, we apply a temporal fusion module that incorporates selected informative sparse curve queries and their corresponding anchor point sets to leverage historical lane information.","In the experiments, we evaluate our approach for the 3D lane detection task on two publicly available real-world datasets.","The results demonstrate that our method provides outstanding performance compared with both CNN and Transformer based methods.","We also conduct ablation studies to analyze the impact of each component in our approach."],"url":"http://arxiv.org/abs/2402.06423v1","category":"cs.CV"}
{"created":"2024-02-09 14:08:23","title":"Findings of the First Workshop on Simulating Conversational Intelligence in Chat","abstract":"The aim of this workshop is to bring together experts working on open-domain dialogue research. In this speedily advancing research area many challenges still exist, such as learning information from conversations, engaging in realistic and convincing simulation of human intelligence and reasoning. SCI-CHAT follows previous workshops on open domain dialogue but with a focus on the simulation of intelligent conversation as judged in a live human evaluation. Models aim to include the ability to follow a challenging topic over a multi-turn conversation, while positing, refuting and reasoning over arguments. The workshop included both a research track and shared task. The main goal of this paper is to provide an overview of the shared task and a link to an additional paper that will include an in depth analysis of the shared task results following presentation at the workshop.","sentences":["The aim of this workshop is to bring together experts working on open-domain dialogue research.","In this speedily advancing research area many challenges still exist, such as learning information from conversations, engaging in realistic and convincing simulation of human intelligence and reasoning.","SCI-CHAT follows previous workshops on open domain dialogue but with a focus on the simulation of intelligent conversation as judged in a live human evaluation.","Models aim to include the ability to follow a challenging topic over a multi-turn conversation, while positing, refuting and reasoning over arguments.","The workshop included both a research track and shared task.","The main goal of this paper is to provide an overview of the shared task and a link to an additional paper that will include an in depth analysis of the shared task results following presentation at the workshop."],"url":"http://arxiv.org/abs/2402.06420v1","category":"cs.CL"}
{"created":"2024-02-09 14:06:18","title":"Electron-nucleus scattering and the polarization sum rules","abstract":"A formal derivation of the polarization correlations between the incident electron and the scattered electron is given for a general class of transition operators. In correspondence to the case of bremsstrahlung emission, three sum rules for the polarization correlations are predicted, which reduce to the known one for potential scattering. Further examples, including the 1_2^+ and 2_1^+ excitations of the 12C nucleus and a 1^- excitation of the 208Pb nucleus, are discussed and the validity of the corresponding sum rules is investigated.","sentences":["A formal derivation of the polarization correlations between the incident electron and the scattered electron is given for a general class of transition operators.","In correspondence to the case of bremsstrahlung emission, three sum rules for the polarization correlations are predicted, which reduce to the known one for potential scattering.","Further examples, including the 1_2^+ and 2_1^+ excitations of the 12C nucleus and a 1^- excitation of the 208Pb nucleus, are discussed and the validity of the corresponding sum rules is investigated."],"url":"http://arxiv.org/abs/2402.06418v1","category":"nucl-th"}
{"created":"2024-02-09 14:04:23","title":"Isometric Representations of Calibrated Ordered Spaces on $C(X)$","abstract":"The problem of characterizing normed ordered spaces which admit a representation in the algebraic, order and norm sense as a subspace of $C(X)$, the space of all continuous functions on a compact Hausdorff space is a classical problem that has been considered by many authors. In this article we consider the more general case of calibrated ordered spaces, that is, ordered spaces with a specified family of seminorms generating its topology. For such spaces equivalent conditions on representability as a subspace of $C(X)$ for some locally compact Hausdorff space $X$, in the algebraic, order and seminorm sense are stated and proved. Some characterizations appear to be new even in the normed case. As an application of the main theorem, we state and prove a characterization of norm additivity property of two positive functionals.","sentences":["The problem of characterizing normed ordered spaces which admit a representation in the algebraic, order and norm sense as a subspace of $C(X)$, the space of all continuous functions on a compact Hausdorff space is a classical problem that has been considered by many authors.","In this article we consider the more general case of calibrated ordered spaces, that is, ordered spaces with a specified family of seminorms generating its topology.","For such spaces equivalent conditions on representability as a subspace of $C(X)$ for some locally compact Hausdorff space $X$, in the algebraic, order and seminorm sense are stated and proved.","Some characterizations appear to be new even in the normed case.","As an application of the main theorem, we state and prove a characterization of norm additivity property of two positive functionals."],"url":"http://arxiv.org/abs/2402.06417v1","category":"math.FA"}
{"created":"2024-02-09 14:03:13","title":"Reactor neutrino background in third-generation dark matter detectors","abstract":"Third-generation dark matter detectors will be fully sensitive to the boron-8 solar neutrino flux. Because of this, the characterization of such a background has been the subject of extensive analyses over the last few years. In contrast, little is known about the impact of reactor neutrinos. In this letter we report on the implications of such a flux for dark matter direct detection searches. We consider five potential detector deployment sites envisioned by the recently established XLZD consortium: SURF, SNOLAB, Kamioka, LNGS and Boulby. By using public reactor data we construct five reactor clusters -- involving about 100 currently operating commercial nuclear reactors each -- and determine the net neutrino flux at each detector site. Assuming a xenon-based detector and a 50 tonne-year exposure, we show that in all cases the neutrino event rate may be sizable, depending on energy recoil thresholds. Of all possible detector sites, SURF and LNGS are those with the smallest reactor neutrino background. On the contrary, SNOLAB and Boulby are subject to the strongest reactor neutrino fluxes, with Kamioka being subject to a more moderate background. Our findings demonstrate that reactor neutrino fluxes should be taken into account in the next round of dark matter searches. We argue that this background may be particularly relevant for directional detectors, provided they meet the requirements we have employed in this analysis.","sentences":["Third-generation dark matter detectors will be fully sensitive to the boron-8 solar neutrino flux.","Because of this, the characterization of such a background has been the subject of extensive analyses over the last few years.","In contrast, little is known about the impact of reactor neutrinos.","In this letter we report on the implications of such a flux for dark matter direct detection searches.","We consider five potential detector deployment sites envisioned by the recently established XLZD consortium: SURF, SNOLAB, Kamioka, LNGS and Boulby.","By using public reactor data we construct five reactor clusters -- involving about 100 currently operating commercial nuclear reactors each -- and determine the net neutrino flux at each detector site.","Assuming a xenon-based detector and a 50 tonne-year exposure, we show that in all cases the neutrino event rate may be sizable, depending on energy recoil thresholds.","Of all possible detector sites, SURF and LNGS are those with the smallest reactor neutrino background.","On the contrary, SNOLAB and Boulby are subject to the strongest reactor neutrino fluxes, with Kamioka being subject to a more moderate background.","Our findings demonstrate that reactor neutrino fluxes should be taken into account in the next round of dark matter searches.","We argue that this background may be particularly relevant for directional detectors, provided they meet the requirements we have employed in this analysis."],"url":"http://arxiv.org/abs/2402.06416v1","category":"hep-ph"}
{"created":"2024-02-09 14:00:16","title":"Trust the Process: Zero-Knowledge Machine Learning to Enhance Trust in Generative AI Interactions","abstract":"Generative AI, exemplified by models like transformers, has opened up new possibilities in various domains but also raised concerns about fairness, transparency and reliability, especially in fields like medicine and law. This paper emphasizes the urgency of ensuring fairness and quality in these domains through generative AI. It explores using cryptographic techniques, particularly Zero-Knowledge Proofs (ZKPs), to address concerns regarding performance fairness and accuracy while protecting model privacy. Applying ZKPs to Machine Learning models, known as ZKML (Zero-Knowledge Machine Learning), enables independent validation of AI-generated content without revealing sensitive model information, promoting transparency and trust. ZKML enhances AI fairness by providing cryptographic audit trails for model predictions and ensuring uniform performance across users. We introduce snarkGPT, a practical ZKML implementation for transformers, to empower users to verify output accuracy and quality while preserving model privacy. We present a series of empirical results studying snarkGPT's scalability and performance to assess the feasibility and challenges of adopting a ZKML-powered approach to capture quality and performance fairness problems in generative AI models.","sentences":["Generative AI, exemplified by models like transformers, has opened up new possibilities in various domains but also raised concerns about fairness, transparency and reliability, especially in fields like medicine and law.","This paper emphasizes the urgency of ensuring fairness and quality in these domains through generative AI.","It explores using cryptographic techniques, particularly Zero-Knowledge Proofs (ZKPs), to address concerns regarding performance fairness and accuracy while protecting model privacy.","Applying ZKPs to Machine Learning models, known as ZKML (Zero-Knowledge Machine Learning), enables independent validation of AI-generated content without revealing sensitive model information, promoting transparency and trust.","ZKML enhances AI fairness by providing cryptographic audit trails for model predictions and ensuring uniform performance across users.","We introduce snarkGPT, a practical ZKML implementation for transformers, to empower users to verify output accuracy and quality while preserving model privacy.","We present a series of empirical results studying snarkGPT's scalability and performance to assess the feasibility and challenges of adopting a ZKML-powered approach to capture quality and performance fairness problems in generative AI models."],"url":"http://arxiv.org/abs/2402.06414v1","category":"cs.LG"}
{"created":"2024-02-09 14:00:09","title":"Distinguishing the Observational Signatures of Hot Spots Orbiting Reissner-Nordstr\u00f6m Spacetime","abstract":"This paper delves into observable signatures of hot spots orbiting Reissner-Nordstr\\\"om (RN) black holes and naked singularities. In a RN black hole case, we find two discernible lensing image tracks in time integrated images capturing a complete orbit of hot spots, and a image shadow within the critical curve where photons with a small impact parameter fall into the event horizon. Conversely, in RN singularities, additional image tracks can be found inner the critical curve, originating from photons reflected by the infinitely high effective potential well. Moreover, we found incomplete and converge tracks from the time integrated images of hot spot orbiting RN singularities lacking of a photon sphere. The presence of these additional image tracks exerts a significant influence on temporal magnitudes at their local maxima, allowing us to differentiate between RN black holes and RN naked singularities.","sentences":["This paper delves into observable signatures of hot spots orbiting Reissner-Nordstr\\\"om (RN) black holes and naked singularities.","In a RN black hole case, we find two discernible lensing image tracks in time integrated images capturing a complete orbit of hot spots, and a image shadow within the critical curve where photons with a small impact parameter fall into the event horizon.","Conversely, in RN singularities, additional image tracks can be found inner the critical curve, originating from photons reflected by the infinitely high effective potential well.","Moreover, we found incomplete and converge tracks from the time integrated images of hot spot orbiting RN singularities lacking of a photon sphere.","The presence of these additional image tracks exerts a significant influence on temporal magnitudes at their local maxima, allowing us to differentiate between RN black holes and RN naked singularities."],"url":"http://arxiv.org/abs/2402.06413v1","category":"gr-qc"}
{"created":"2024-02-09 13:46:36","title":"Finite-sided Dirichlet domains and Anosov subgroups","abstract":"We consider Dirichlet domains for Anosov subgroups $\\Gamma$ of semisimple Lie groups $G$ acting on the associated symmetric space $G/K$. More precisely, we consider certain Finsler metrics on $G/K$ and a sufficient condition so that every Dirichlet domain for $\\Gamma$ is finite-sided in a strong sense. Under the same condition, the group $\\Gamma$ admits a domain of discontinuity in a flag manifold where the Dirichlet domain extends to a compact fundamental domain. As an application we show that Dirichlet-Selberg domains for $n$-Anosov subgroups $\\Gamma$ of $SL(2n,\\mathbb{R})$ are finite-sided when all singular values of elements of $\\Gamma$ diverge exponentially in the word length. For every $d\\ge 3$, there are projective Anosov subgroups of $SL(d,\\mathbb{R})$ which do not satisfy this property and have Dirichlet-Selberg domains with infinitely many sides. More generally, we give a sufficient condition for a subgroup of $SL(d,\\mathbb{R})$ to admit a Dirichlet-Selberg domain whose intersection with an invariant convex set is finite-sided.","sentences":["We consider Dirichlet domains for Anosov subgroups $\\Gamma$ of semisimple Lie groups $G$ acting on the associated symmetric space $G/K$. More precisely, we consider certain Finsler metrics on $G/K$ and a sufficient condition so that every Dirichlet domain for $\\Gamma$ is finite-sided in a strong sense.","Under the same condition, the group $\\Gamma$ admits a domain of discontinuity in a flag manifold where the Dirichlet domain extends to a compact fundamental domain.","As an application we show that Dirichlet-Selberg domains for $n$-Anosov subgroups $\\Gamma$ of $SL(2n,\\mathbb{R})$ are finite-sided when all singular values of elements of $\\Gamma$ diverge exponentially in the word length.","For every $d\\ge 3$, there are projective Anosov subgroups of $SL(d,\\mathbb{R})$ which do not satisfy this property and have Dirichlet-Selberg domains with infinitely many sides.","More generally, we give a sufficient condition for a subgroup of $SL(d,\\mathbb{R})$ to admit a Dirichlet-Selberg domain whose intersection with an invariant convex set is finite-sided."],"url":"http://arxiv.org/abs/2402.06408v1","category":"math.GT"}
{"created":"2024-02-09 13:45:31","title":"Quick-Sort Style Approximation Algorithms for Generalizations of Feedback Vertex Set in Tournaments","abstract":"A feedback vertex set (FVS) in a digraph is a subset of vertices whose removal makes the digraph acyclic. In other words, it hits all cycles in the digraph. Lokshtanov et al. [TALG '21] gave a factor 2 randomized approximation algorithm for finding a minimum weight FVS in tournaments. We generalize the result by presenting a factor $2\\alpha$ randomized approximation algorithm for finding a minimum weight FVS in digraphs of independence number $\\alpha$; a generalization of tournaments which are digraphs with independence number $1$. Using the same framework, we present a factor $2$ randomized approximation algorithm for finding a minimum weight Subset FVS in tournaments: given a vertex subset $S$ in addition to the graph, find a subset of vertices that hits all cycles containing at least one vertex in $S$. Note that FVS in tournaments is a special case of Subset FVS in tournaments in which $S = V(T)$.","sentences":["A feedback vertex set (FVS) in a digraph is a subset of vertices whose removal makes the digraph acyclic.","In other words, it hits all cycles in the digraph.","Lokshtanov et al.","[TALG '21] gave a factor 2 randomized approximation algorithm for finding a minimum weight FVS in tournaments.","We generalize the result by presenting a factor $2\\alpha$ randomized approximation algorithm for finding a minimum weight FVS in digraphs of independence number $\\alpha$; a generalization of tournaments which are digraphs with independence number $1$. Using the same framework, we present a factor $2$ randomized approximation algorithm for finding a minimum weight Subset FVS in tournaments: given a vertex subset $S$ in addition to the graph, find a subset of vertices that hits all cycles containing at least one vertex in $S$. Note that FVS in tournaments is a special case of Subset FVS in tournaments in which $S = V(T)$."],"url":"http://arxiv.org/abs/2402.06407v1","category":"cs.DS"}
{"created":"2024-02-09 13:42:34","title":"Vacuum Force and Confinement","abstract":"We show that confinement of quarks and gluons can be explained by their interaction with the vacuum Abelian gauge field $A_{\\sf{vac}}$, which is implicitly introduced by the canonical commutation relations and generates the vacuum force. The background gauge field $A_{\\sf{vac}}$, linear in coordinates of $\\mathbb{R}^3$, is inherently present in quantum mechanics: it is introduced during the canonical quantization of phase space $(T^*\\mathbb{R}^3, \\omega )$ of a nonrelativistic particle, when a potential $\\theta$ of the symplectic 2-form $\\omega =\\mathrm{d}\\theta$ on $T^*\\mathbb{R}^3$ is mapped into a connection $A_{\\sf{vac}}=-\\mathrm{i}\\theta$ on a complex line bundle $L_{\\sf{v}}$ over $T^*\\mathbb{R}^3$ with gauge group U(1)$_{\\sf{v}}$ and curvature $F_{\\sf{vac}}=\\mathrm{d} A_{\\sf{vac}}=-\\mathrm{i}\\omega$. Generalizing this correspondence to the relativistic phase space $T^*\\mathbb{R}^{3,1}$, we extend the Dirac equation from $\\mathbb{R}^{3,1}$ to $T^*\\mathbb{R}^{3,1}$ while maintaining the condition that fermions depend only on $x\\in\\mathbb{R}^{3,1}$. The generalized Dirac equation contains the interaction of fermions with $A_{\\sf{vac}}$ and has particle-like solutions localized in space. Thus, the wave-particle duality can be explained by turning on or off the interaction with the vacuum field $A_{\\sf{vac}}$. Accordingly, confinement of quarks and gluons can be explained by the fact that their interaction with $A_{\\sf{vac}}$ is always on and therefore they can only exist in bound states in the form of hadrons.","sentences":["We show that confinement of quarks and gluons can be explained by their interaction with the vacuum Abelian gauge field $A_{\\sf{vac}}$, which is implicitly introduced by the canonical commutation relations and generates the vacuum force.","The background gauge field $A_{\\sf{vac}}$, linear in coordinates of $\\mathbb{R}^3$, is inherently present in quantum mechanics: it is introduced during the canonical quantization of phase space $(T^*\\mathbb{R}^3, \\omega )$ of a nonrelativistic particle, when a potential $\\theta$ of the symplectic 2-form $\\omega =\\mathrm{d}\\theta$ on $T^*\\mathbb{R}^3$ is mapped into a connection $A_{\\sf{vac}}=-\\mathrm{i}\\theta$ on a complex line bundle $L_{\\sf{v}}$ over $T^*\\mathbb{R}^3$ with gauge group U(1)$_{\\sf{v}}$ and curvature $F_{\\sf{vac}}=\\mathrm{d} A_{\\sf{vac}}=-\\mathrm{i}\\omega$.","Generalizing this correspondence to the relativistic phase space $T^*\\mathbb{R}^{3,1}$, we extend the Dirac equation from $\\mathbb{R}^{3,1}$ to $T^*\\mathbb{R}^{3,1}$ while maintaining the condition that fermions depend only on $x\\in\\mathbb{R}^{3,1}$. The generalized Dirac equation contains the interaction of fermions with $A_{\\sf{vac}}$ and has particle-like solutions localized in space.","Thus, the wave-particle duality can be explained by turning on or off the interaction with the vacuum field $A_{\\sf{vac}}$. Accordingly, confinement of quarks and gluons can be explained by the fact that their interaction with $A_{\\sf{vac}}$ is always on and therefore they can only exist in bound states in the form of hadrons."],"url":"http://arxiv.org/abs/2402.06404v1","category":"hep-th"}
{"created":"2024-02-09 13:40:11","title":"Hierarchical Transformers are Efficient Meta-Reinforcement Learners","abstract":"We introduce Hierarchical Transformers for Meta-Reinforcement Learning (HTrMRL), a powerful online meta-reinforcement learning approach. HTrMRL aims to address the challenge of enabling reinforcement learning agents to perform effectively in previously unseen tasks. We demonstrate how past episodes serve as a rich source of information, which our model effectively distills and applies to new contexts. Our learned algorithm is capable of outperforming the previous state-of-the-art and provides more efficient meta-training while significantly improving generalization capabilities. Experimental results, obtained across various simulated tasks of the Meta-World Benchmark, indicate a significant improvement in learning efficiency and adaptability compared to the state-of-the-art on a variety of tasks. Our approach not only enhances the agent's ability to generalize from limited data but also paves the way for more robust and versatile AI systems.","sentences":["We introduce Hierarchical Transformers for Meta-Reinforcement Learning (HTrMRL), a powerful online meta-reinforcement learning approach.","HTrMRL aims to address the challenge of enabling reinforcement learning agents to perform effectively in previously unseen tasks.","We demonstrate how past episodes serve as a rich source of information, which our model effectively distills and applies to new contexts.","Our learned algorithm is capable of outperforming the previous state-of-the-art and provides more efficient meta-training while significantly improving generalization capabilities.","Experimental results, obtained across various simulated tasks of the Meta-World Benchmark, indicate a significant improvement in learning efficiency and adaptability compared to the state-of-the-art on a variety of tasks.","Our approach not only enhances the agent's ability to generalize from limited data but also paves the way for more robust and versatile AI systems."],"url":"http://arxiv.org/abs/2402.06402v1","category":"cs.LG"}
{"created":"2024-02-09 13:29:44","title":"Finding hardness reductions automatically using SAT solvers","abstract":"In this article, we show that the completion problem, i.e. the decision problem whether a partial structure can be completed to a full structure, is NP-complete for many combinatorial structures. While the gadgets for most reductions in literature are found by hand, we present an algorithm to construct gadgets in a fully automated way. Using our framework which is based on SAT, we present the first thorough study of the completion problem on sign mappings with forbidden substructures by classifying thousands of structures for which the completion problem is NP-complete. Our list in particular includes interior triple systems, which were introduced by Knuth towards an axiomatization of planar point configurations. Last but not least, we give an infinite family of structures generalizing interior triple system to higher dimensions for which the completion problem is NP-complete.","sentences":["In this article, we show that the completion problem, i.e. the decision problem whether a partial structure can be completed to a full structure, is NP-complete for many combinatorial structures.","While the gadgets for most reductions in literature are found by hand, we present an algorithm to construct gadgets in a fully automated way.","Using our framework which is based on SAT, we present the first thorough study of the completion problem on sign mappings with forbidden substructures by classifying thousands of structures for which the completion problem is NP-complete.","Our list in particular includes interior triple systems, which were introduced by Knuth towards an axiomatization of planar point configurations.","Last but not least, we give an infinite family of structures generalizing interior triple system to higher dimensions for which the completion problem is NP-complete."],"url":"http://arxiv.org/abs/2402.06397v1","category":"cs.CC"}
{"created":"2024-02-09 13:18:39","title":"Dense and nondense limits for uniform random intersection graphs","abstract":"We obtain the scaling limits of random graphs drawn uniformly in three families of intersection graphs: permutation graphs, circle graphs, and unit interval graphs. The two first families typically generate dense graphs, in these cases we prove a.s. convergence to an explicit deterministic graphon. Uniform unit interval graphs are nondense and we prove convergence in the sense of Gromov-Prokhorov after normalization of the distances: the limiting object is the interval $[0,1]$ endowed with a random metric defined through a Brownian excursion. Asymptotic results for the number of cliques of size $k$ ($k$ fixed) in a uniform random graph in each of these three families are also given.   In all three cases, an important ingredient of the proof is that, for indecomposable graphs in each class (where the notion of indecomposability depends on the class), the combinatorial object defining the graph (permutation, matching, or intervals) is essentially unique.","sentences":["We obtain the scaling limits of random graphs drawn uniformly in three families of intersection graphs: permutation graphs, circle graphs, and unit interval graphs.","The two first families typically generate dense graphs, in these cases we prove a.s. convergence to an explicit deterministic graphon.","Uniform unit interval graphs are nondense and we prove convergence in the sense of Gromov-Prokhorov after normalization of the distances: the limiting object is the interval $[0,1]$ endowed with a random metric defined through a Brownian excursion.","Asymptotic results for the number of cliques of size $k$ ($k$ fixed) in a uniform random graph in each of these three families are also given.   ","In all three cases, an important ingredient of the proof is that, for indecomposable graphs in each class (where the notion of indecomposability depends on the class), the combinatorial object defining the graph (permutation, matching, or intervals) is essentially unique."],"url":"http://arxiv.org/abs/2402.06394v1","category":"math.PR"}
{"created":"2024-02-09 13:15:32","title":"A glance at evolvability: a theoretical analysis of its role in the evolutionary dynamics of cell populations","abstract":"Evolvability is defined as the ability of a population to generate heritable variation to facilitate its adaptation to new environments or selection pressures. In this article, we consider evolvability as a phenotypic trait subject to evolution and discuss its implications in the adaptation of cell populations. We explore the evolutionary dynamics of an actively proliferating population of cells subject to changes in their proliferative potential and their evolvability using a stochastic individual-based model and its deterministic continuum counterpart through numerical simulations of these models. We find robust adaptive trajectories that rely on cells with high evolvability rapidly exploring the phenotypic landscape and reaching the proliferative potential with the highest fitness. The strength of selection on the proliferative potential, and the cost associated with evolvability, can alter these trajectories such that, if both are sufficiently constraining, highly evolvable populations can become extinct in our individual-based model simulations. We explore the impact of this interaction at various scales, discussing its effects in undisturbed environments and also in disrupted contexts, such as cancer.","sentences":["Evolvability is defined as the ability of a population to generate heritable variation to facilitate its adaptation to new environments or selection pressures.","In this article, we consider evolvability as a phenotypic trait subject to evolution and discuss its implications in the adaptation of cell populations.","We explore the evolutionary dynamics of an actively proliferating population of cells subject to changes in their proliferative potential and their evolvability using a stochastic individual-based model and its deterministic continuum counterpart through numerical simulations of these models.","We find robust adaptive trajectories that rely on cells with high evolvability rapidly exploring the phenotypic landscape and reaching the proliferative potential with the highest fitness.","The strength of selection on the proliferative potential, and the cost associated with evolvability, can alter these trajectories such that, if both are sufficiently constraining, highly evolvable populations can become extinct in our individual-based model simulations.","We explore the impact of this interaction at various scales, discussing its effects in undisturbed environments and also in disrupted contexts, such as cancer."],"url":"http://arxiv.org/abs/2402.06392v1","category":"q-bio.PE"}
{"created":"2024-02-09 13:11:57","title":"ImplicitDeepfake: Plausible Face-Swapping through Implicit Deepfake Generation using NeRF and Gaussian Splatting","abstract":"Numerous emerging deep-learning techniques have had a substantial impact on computer graphics. Among the most promising breakthroughs are the recent rise of Neural Radiance Fields (NeRFs) and Gaussian Splatting (GS). NeRFs encode the object's shape and color in neural network weights using a handful of images with known camera positions to generate novel views. In contrast, GS provides accelerated training and inference without a decrease in rendering quality by encoding the object's characteristics in a collection of Gaussian distributions. These two techniques have found many use cases in spatial computing and other domains. On the other hand, the emergence of deepfake methods has sparked considerable controversy. Such techniques can have a form of artificial intelligence-generated videos that closely mimic authentic footage. Using generative models, they can modify facial features, enabling the creation of altered identities or facial expressions that exhibit a remarkably realistic appearance to a real person. Despite these controversies, deepfake can offer a next-generation solution for avatar creation and gaming when of desirable quality. To that end, we show how to combine all these emerging technologies to obtain a more plausible outcome. Our ImplicitDeepfake1 uses the classical deepfake algorithm to modify all training images separately and then train NeRF and GS on modified faces. Such relatively simple strategies can produce plausible 3D deepfake-based avatars.","sentences":["Numerous emerging deep-learning techniques have had a substantial impact on computer graphics.","Among the most promising breakthroughs are the recent rise of Neural Radiance Fields (NeRFs) and Gaussian Splatting (GS).","NeRFs encode the object's shape and color in neural network weights using a handful of images with known camera positions to generate novel views.","In contrast, GS provides accelerated training and inference without a decrease in rendering quality by encoding the object's characteristics in a collection of Gaussian distributions.","These two techniques have found many use cases in spatial computing and other domains.","On the other hand, the emergence of deepfake methods has sparked considerable controversy.","Such techniques can have a form of artificial intelligence-generated videos that closely mimic authentic footage.","Using generative models, they can modify facial features, enabling the creation of altered identities or facial expressions that exhibit a remarkably realistic appearance to a real person.","Despite these controversies, deepfake can offer a next-generation solution for avatar creation and gaming when of desirable quality.","To that end, we show how to combine all these emerging technologies to obtain a more plausible outcome.","Our ImplicitDeepfake1 uses the classical deepfake algorithm to modify all training images separately and then train NeRF and GS on modified faces.","Such relatively simple strategies can produce plausible 3D deepfake-based avatars."],"url":"http://arxiv.org/abs/2402.06390v1","category":"cs.CV"}
{"created":"2024-02-09 13:11:19","title":"Human Aesthetic Preference-Based Large Text-to-Image Model Personalization: Kandinsky Generation as an Example","abstract":"With the advancement of neural generative capabilities, the art community has actively embraced GenAI (generative artificial intelligence) for creating painterly content. Large text-to-image models can quickly generate aesthetically pleasing outcomes. However, the process can be non-deterministic and often involves tedious trial-and-error, as users struggle with formulating effective prompts to achieve their desired results. This paper introduces a prompting-free generative approach that empowers users to automatically generate personalized painterly content that incorporates their aesthetic preferences in a customized artistic style. This approach involves utilizing ``semantic injection'' to customize an artist model in a specific artistic style, and further leveraging a genetic algorithm to optimize the prompt generation process through real-time iterative human feedback. By solely relying on the user's aesthetic evaluation and preference for the artist model-generated images, this approach creates the user a personalized model that encompasses their aesthetic preferences and the customized artistic style.","sentences":["With the advancement of neural generative capabilities, the art community has actively embraced GenAI (generative artificial intelligence) for creating painterly content.","Large text-to-image models can quickly generate aesthetically pleasing outcomes.","However, the process can be non-deterministic and often involves tedious trial-and-error, as users struggle with formulating effective prompts to achieve their desired results.","This paper introduces a prompting-free generative approach that empowers users to automatically generate personalized painterly content that incorporates their aesthetic preferences in a customized artistic style.","This approach involves utilizing ``semantic injection'' to customize an artist model in a specific artistic style, and further leveraging a genetic algorithm to optimize the prompt generation process through real-time iterative human feedback.","By solely relying on the user's aesthetic evaluation and preference for the artist model-generated images, this approach creates the user a personalized model that encompasses their aesthetic preferences and the customized artistic style."],"url":"http://arxiv.org/abs/2402.06389v1","category":"cs.AI"}
{"created":"2024-02-09 13:10:04","title":"On the Convergence Rate of the Stochastic Gradient Descent (SGD) and application to a modified policy gradient for the Multi Armed Bandit","abstract":"We present a self-contained proof of the convergence rate of the Stochastic Gradient Descent (SGD) when the learning rate follows an inverse time decays schedule; we next apply the results to the convergence of a modified form of policy gradient Multi-Armed Bandit (MAB) with $L2$ regularization.","sentences":["We present a self-contained proof of the convergence rate of the Stochastic Gradient Descent (SGD) when the learning rate follows an inverse time decays schedule; we next apply the results to the convergence of a modified form of policy gradient Multi-Armed Bandit (MAB) with $L2$ regularization."],"url":"http://arxiv.org/abs/2402.06388v1","category":"stat.ML"}
{"created":"2024-02-09 13:00:51","title":"Exact solutions to $\\displaystyle{\\max_{\\|x\\|=1} \\sum_{i=1}^\\infty\\|T_i(x)\\|^2}$ with applications to Physics, Bioengineering and Statistics","abstract":"The supporting vectors of a matrix A are the solutions of max || x ||_2 =1 {||Ax||_2^2}. The generalized supporting vectors of matrices A_1 , . . . , A_k are the solutions of max || x ||_2 =1 {||A_1x||_2^2 + ||A_2x||_2^2 + ... + ||A_kx||_2^2}. Notice that the previous optimization problem is also a boundary element problem since the maximum is attained on the unit sphere. Many problems in Physics, Statistics and Engineering can be modeled by using generalized supporting vectors. In this manuscript we first raise the generalized supporting vectors to the infinite dimensional case by solving the optimization problem max || x || =1 sum_{i=1}^\\infty ||T i (x )||^2 where (T i )_i is a sequence ofbounded linear operators between Hilbert spaces H and K of any dimension. Observe that the previous optimization problem generalizes the first two. Then a unified MATLAB code is presented for computing generalized supporting vectors of a finite number of matrices. Some particular cases are considered and three novel examples are provided to which our technique applies: optimized observable magnitudes by a pure state in a quantum mechanical system, a TMS optimized coil and an optimal location problem using statistics multivariate analysis. These three examples show the wide applicability of our theoretical and computational model.","sentences":["The supporting vectors of a matrix A are the solutions of max ||","x ||_2 =1 {||Ax||_2^2}.","The generalized supporting vectors of matrices A_1 , . . .",", A_k are the solutions of max ||","x ||_2 =1 {||A_1x||_2^2 + ||A_2x||_2^2","+ ...","+ ||A_kx||_2^2}.","Notice that the previous optimization problem is also a boundary element problem since the maximum is attained on the unit sphere.","Many problems in Physics, Statistics and Engineering can be modeled by using generalized supporting vectors.","In this manuscript we first raise the generalized supporting vectors to the infinite dimensional case by solving the optimization problem max || x || =1 sum_{i=1}^\\infty ||T i (x )||^2 where (T i )_","i is a sequence ofbounded linear operators between Hilbert spaces H and K of any dimension.","Observe that the previous optimization problem generalizes the first two.","Then a unified MATLAB code is presented for computing generalized supporting vectors of a finite number of matrices.","Some particular cases are considered and three novel examples are provided to which our technique applies: optimized observable magnitudes by a pure state in a quantum mechanical system, a TMS optimized coil and an optimal location problem using statistics multivariate analysis.","These three examples show the wide applicability of our theoretical and computational model."],"url":"http://arxiv.org/abs/2402.06383v1","category":"math.FA"}
{"created":"2024-02-09 12:54:34","title":"High-Precision Geosteering via Reinforcement Learning and Particle Filters","abstract":"Geosteering, a key component of drilling operations, traditionally involves manual interpretation of various data sources such as well-log data. This introduces subjective biases and inconsistent procedures. Academic attempts to solve geosteering decision optimization with greedy optimization and Approximate Dynamic Programming (ADP) showed promise but lacked adaptivity to realistic diverse scenarios. Reinforcement learning (RL) offers a solution to these challenges, facilitating optimal decision-making through reward-based iterative learning. State estimation methods, e.g., particle filter (PF), provide a complementary strategy for geosteering decision-making based on online information. We integrate an RL-based geosteering with PF to address realistic geosteering scenarios. Our framework deploys PF to process real-time well-log data to estimate the location of the well relative to the stratigraphic layers, which then informs the RL-based decision-making process. We compare our method's performance with that of using solely either RL or PF. Our findings indicate a synergy between RL and PF in yielding optimized geosteering decisions.","sentences":["Geosteering, a key component of drilling operations, traditionally involves manual interpretation of various data sources such as well-log data.","This introduces subjective biases and inconsistent procedures.","Academic attempts to solve geosteering decision optimization with greedy optimization and Approximate Dynamic Programming (ADP) showed promise but lacked adaptivity to realistic diverse scenarios.","Reinforcement learning (RL) offers a solution to these challenges, facilitating optimal decision-making through reward-based iterative learning.","State estimation methods, e.g., particle filter (PF), provide a complementary strategy for geosteering decision-making based on online information.","We integrate an RL-based geosteering with PF to address realistic geosteering scenarios.","Our framework deploys PF to process real-time well-log data to estimate the location of the well relative to the stratigraphic layers, which then informs the RL-based decision-making process.","We compare our method's performance with that of using solely either RL or PF.","Our findings indicate a synergy between RL and PF in yielding optimized geosteering decisions."],"url":"http://arxiv.org/abs/2402.06377v1","category":"cs.LG"}
{"created":"2024-02-09 12:48:40","title":"A Descent Method for Nonsmooth Multiobjective Optimization in Hilbert Spaces","abstract":"The efficient optimization method for locally Lipschitz continuous multiobjective optimization problems from [1] is extended from finite-dimensional problems to general Hilbert spaces. The method iteratively computes Pareto critical points, where in each iteration, an approximation of the subdifferential is computed in an efficient manner and then used to compute a common descent direction for all objective functions. To prove convergence, we present some new optimality results for nonsmooth multiobjective optimization problems in Hilbert spaces. Using these, we can show that every accumulation point of the sequence generated by our algorithm is Pareto critical under common assumptions. Computational efficiency for finding Pareto critical points is numerically demonstrated for multiobjective optimal control of an obstacle problem.","sentences":["The efficient optimization method for locally Lipschitz continuous multiobjective optimization problems from [1] is extended from finite-dimensional problems to general Hilbert spaces.","The method iteratively computes Pareto critical points, where in each iteration, an approximation of the subdifferential is computed in an efficient manner and then used to compute a common descent direction for all objective functions.","To prove convergence, we present some new optimality results for nonsmooth multiobjective optimization problems in Hilbert spaces.","Using these, we can show that every accumulation point of the sequence generated by our algorithm is Pareto critical under common assumptions.","Computational efficiency for finding Pareto critical points is numerically demonstrated for multiobjective optimal control of an obstacle problem."],"url":"http://arxiv.org/abs/2402.06376v1","category":"math.OC"}
{"created":"2024-02-09 12:45:40","title":"Deconfinement transitions in three-dimensional compact lattice Abelian Higgs models with multiple-charge scalar fields","abstract":"We investigate the nature of the deconfinement transitions in three-dimensional lattice Abelian Higgs models, in which a complex scalar field of integer charge $Q\\ge 2$ is minimally coupled with a compact $U(1)$ gauge field. Their phase diagram presents two phases separated by a transition line where static charges $q$, with $q<Q$, deconfine. We argue that these deconfinement transitions belong to the same universality class as transitions in generic three-dimensional ${\\mathbb Z}_Q$ gauge models. In particular, they are Ising-like for $Q=2$, of first order for $Q=3$, and belong to the three-dimensional gauge $XY$ universality class for $Q\\ge 4$. This general scenario is supported by numerical finite-size scaling analyses of the energy cumulants for $Q=2$, $Q=4$, and $Q=6$.","sentences":["We investigate the nature of the deconfinement transitions in three-dimensional lattice Abelian Higgs models, in which a complex scalar field of integer charge $Q\\ge 2$ is minimally coupled with a compact $U(1)$ gauge field.","Their phase diagram presents two phases separated by a transition line where static charges $q$, with $q<Q$, deconfine.","We argue that these deconfinement transitions belong to the same universality class as transitions in generic three-dimensional ${\\mathbb Z}_Q$ gauge models.","In particular, they are Ising-like for $Q=2$, of first order for $Q=3$, and belong to the three-dimensional gauge $XY$ universality class for $Q\\ge 4$.","This general scenario is supported by numerical finite-size scaling analyses of the energy cumulants for $Q=2$, $Q=4$, and $Q=6$."],"url":"http://arxiv.org/abs/2402.06374v1","category":"hep-lat"}
{"created":"2024-02-09 12:41:51","title":"A new edge betweenness measure using a game theoretical approach: an application to hierarchical community detection","abstract":"In this paper we formally define the hierarchical clustering network problem (HCNP) as the problem to find a good hierarchical partition of a network. This new problem focuses on the dynamic process of the clustering rather than on the final picture of the clustering process. To address it, we introduce a new ierarchical clustering algorithm in networks, based on a new shortest path betweenness measure. To calculate it, the communication between each pair of nodes is weighed by he importance of the nodes that establish this communication. The weights or importance associated to each pair of nodes are calculated as the Shapley value of a game, named as the linear modularity game. This new measure, (the node-game shortest path betweenness measure), is used to obtain a hierarchical partition of the network by eliminating the link with the highest value. To evaluate the performance of our algorithm, we introduce several criteria that allow us to compare different dendrograms of a network from two point of view: modularity and homogeneity. Finally, we propose a faster algorithm based on a simplification of the node-game shortest path betweenness measure, whose order is quadratic on sparse networks. This fast version is competitive from a computational point of view with other hierarchical fast algorithms, and, in general, it provides better results.","sentences":["In this paper we formally define the hierarchical clustering network problem (HCNP) as the problem to find a good hierarchical partition of a network.","This new problem focuses on the dynamic process of the clustering rather than on the final picture of the clustering process.","To address it, we introduce a new ierarchical clustering algorithm in networks, based on a new shortest path betweenness measure.","To calculate it, the communication between each pair of nodes is weighed by he importance of the nodes that establish this communication.","The weights or importance associated to each pair of nodes are calculated as the Shapley value of a game, named as the linear modularity game.","This new measure, (the node-game shortest path betweenness measure), is used to obtain a hierarchical partition of the network by eliminating the link with the highest value.","To evaluate the performance of our algorithm, we introduce several criteria that allow us to compare different dendrograms of a network from two point of view: modularity and homogeneity.","Finally, we propose a faster algorithm based on a simplification of the node-game shortest path betweenness measure, whose order is quadratic on sparse networks.","This fast version is competitive from a computational point of view with other hierarchical fast algorithms, and, in general, it provides better results."],"url":"http://arxiv.org/abs/2402.06373v1","category":"cs.SI"}
{"created":"2024-02-09 12:18:17","title":"SAT-based Learning of Computation Tree Logic","abstract":"The CTL learning problem consists in finding for a given sample of positive and negative Kripke structures a distinguishing CTL formula that is verified by the former but not by the latter. Further constraints may bound the size and shape of the desired formula or even ask for its minimality in terms of syntactic size. This synthesis problem is motivated by explanation generation for dissimilar models, e.g. comparing a faulty implementation with the original protocol. We devise a SAT-based encoding for a fixed size CTL formula, then provide an incremental approach that guarantees minimality. We further report on a prototype implementation whose contribution is twofold: first, it allows us to assess the efficiency of various output fragments and optimizations. Secondly, we can experimentally evaluate this tool by randomly mutating Kripke structures or syntactically introducing errors in higher-level models, then learning CTL distinguishing formulas.","sentences":["The CTL learning problem consists in finding for a given sample of positive and negative Kripke structures a distinguishing CTL formula that is verified by the former but not by the latter.","Further constraints may bound the size and shape of the desired formula or even ask for its minimality in terms of syntactic size.","This synthesis problem is motivated by explanation generation for dissimilar models, e.g. comparing a faulty implementation with the original protocol.","We devise a SAT-based encoding for a fixed size CTL formula, then provide an incremental approach that guarantees minimality.","We further report on a prototype implementation whose contribution is twofold: first, it allows us to assess the efficiency of various output fragments and optimizations.","Secondly, we can experimentally evaluate this tool by randomly mutating Kripke structures or syntactically introducing errors in higher-level models, then learning CTL distinguishing formulas."],"url":"http://arxiv.org/abs/2402.06366v1","category":"cs.LO"}
{"created":"2024-02-09 12:16:07","title":"Quadratic lifespan for the sublinear $\u03b1$-SQG sharp front problem","abstract":"In this paper we consider the generalized surface quasi-geostrophic $\\alpha$-SQG equations, in the \"sublinear regime\" $\\alpha \\in (0, 1)$ and we study the stability of vortex patches close to vortex discs. We shall prove that for regular, Sobolev initial vortex patches $\\varepsilon$-close to a vortex disc, the solutions stay $\\varepsilon$-close to a vortex disc for a time interval of order $O(\\varepsilon^{- 2})$. The proof is based on a paradifferential Birkhoff normal form reduction, implemented in the case where the dispersion relation is sublinear.","sentences":["In this paper we consider the generalized surface quasi-geostrophic $\\alpha$-SQG equations, in the \"sublinear regime\" $\\alpha \\in (0, 1)$ and we study the stability of vortex patches close to vortex discs.","We shall prove that for regular, Sobolev initial vortex patches $\\varepsilon$-close to a vortex disc, the solutions stay $\\varepsilon$-close to a vortex disc for a time interval of order $O(\\varepsilon^{- 2})$. The proof is based on a paradifferential Birkhoff normal form reduction, implemented in the case where the dispersion relation is sublinear."],"url":"http://arxiv.org/abs/2402.06364v1","category":"math.AP"}
{"created":"2024-02-09 12:15:51","title":"StruQ: Defending Against Prompt Injection with Structured Queries","abstract":"Recent advances in Large Language Models (LLMs) enable exciting LLM-integrated applications, which perform text-based tasks by utilizing their advanced language understanding capabilities. However, as LLMs have improved, so have the attacks against them. Prompt injection attacks are an important threat: they trick the model to deviate from the original application's instructions and instead follow user directives. These attacks rely on the LLM's ability to follow instructions and inability to separate the prompts and user data. We introduce structured queries, a general approach to tackle this problem. Structured queries separate prompts and data into two channels. We implement a system that supports structured queries. This system is made of (1) a secure front-end that formats a prompt and user data into a special format, and (2) a specially trained LLM that can produce high-quality outputs from these inputs. The LLM is trained using a novel fine-tuning strategy: we convert a base (non-instruction-tuned) LLM to a structured instruction-tuned model that will only follow instructions in the prompt portion of a query. To do so, we augment standard instruction tuning datasets with examples that also include instructions in the data portion of the query, and fine-tune the model to ignore these. Our system significantly improves resistance to prompt injection attacks, with little or no impact on utility. Our code is released at https://github.com/Sizhe-Chen/PromptInjectionDefense.","sentences":["Recent advances in Large Language Models (LLMs) enable exciting LLM-integrated applications, which perform text-based tasks by utilizing their advanced language understanding capabilities.","However, as LLMs have improved, so have the attacks against them.","Prompt injection attacks are an important threat: they trick the model to deviate from the original application's instructions and instead follow user directives.","These attacks rely on the LLM's ability to follow instructions and inability to separate the prompts and user data.","We introduce structured queries, a general approach to tackle this problem.","Structured queries separate prompts and data into two channels.","We implement a system that supports structured queries.","This system is made of (1) a secure front-end that formats a prompt and user data into a special format, and (2) a specially trained LLM that can produce high-quality outputs from these inputs.","The LLM is trained using a novel fine-tuning strategy: we convert a base (non-instruction-tuned) LLM to a structured instruction-tuned model that will only follow instructions in the prompt portion of a query.","To do so, we augment standard instruction tuning datasets with examples that also include instructions in the data portion of the query, and fine-tune the model to ignore these.","Our system significantly improves resistance to prompt injection attacks, with little or no impact on utility.","Our code is released at https://github.com/Sizhe-Chen/PromptInjectionDefense."],"url":"http://arxiv.org/abs/2402.06363v1","category":"cs.CR"}
{"created":"2024-02-09 12:12:53","title":"Post-Newtonian Multipoles from the Next-to-Leading Post-Minkowskian Gravitational Waveform","abstract":"We consider the frequency-domain LO and NLO post-Minkowskian (PM) waveforms obtained from the tree-level and one-loop amplitudes describing the scattering of two massive scalar objects and the emission of one graviton. We explicitly calculate their post-Newtonian (PN) limit obtaining an expansion up to the third subleading PN order in all ingredients: the tree-level amplitude, the odd and even parts of the real one-loop kernel, and the Compton or \"rescattering\" cuts, thus reaching 3PN precision for the latter. We provide explicit expressions for the multipole decomposition of these results in the center-of-mass frame and compare them with the results obtained from the classical Multipolar post-Minkowskian (MPM) method. We find perfect agreement between the two, once the BMS supertranslation frame is properly adjusted and the infrared divergences due to rescattering are suitably subtracted in dimensional regularization. This shows that the approach proposed in arXiv:2312.07452 can be applied beyond the soft-regime ensuring the agreement between amplitude-based and MPM results for generic frequencies.","sentences":["We consider the frequency-domain LO and NLO post-Minkowskian (PM) waveforms obtained from the tree-level and one-loop amplitudes describing the scattering of two massive scalar objects and the emission of one graviton.","We explicitly calculate their post-Newtonian (PN) limit obtaining an expansion up to the third subleading PN order in all ingredients: the tree-level amplitude, the odd and even parts of the real one-loop kernel, and the Compton or \"rescattering\" cuts, thus reaching 3PN precision for the latter.","We provide explicit expressions for the multipole decomposition of these results in the center-of-mass frame and compare them with the results obtained from the classical Multipolar post-Minkowskian (MPM) method.","We find perfect agreement between the two, once the BMS supertranslation frame is properly adjusted and the infrared divergences due to rescattering are suitably subtracted in dimensional regularization.","This shows that the approach proposed in arXiv:2312.07452 can be applied beyond the soft-regime ensuring the agreement between amplitude-based and MPM results for generic frequencies."],"url":"http://arxiv.org/abs/2402.06361v1","category":"hep-th"}
{"created":"2024-02-09 12:10:00","title":"CoSearchAgent: A Lightweight Collaborative Search Agent with Large Language Models","abstract":"Collaborative search supports multiple users working together to accomplish a specific search task. Research has found that designing lightweight collaborative search plugins within instant messaging platforms aligns better with users' collaborative habits. However, due to the complexity of multi-user interaction scenarios, it is challenging to implement a fully functioning lightweight collaborative search system. Therefore, previous studies on lightweight collaborative search had to rely on the Wizard of Oz paradigm. In recent years, large language models (LLMs) have been demonstrated to interact naturally with users and achieve complex information-seeking tasks through LLM-based agents. Hence, to better support the research in collaborative search, in this demo, we propose CoSearchAgent, a lightweight collaborative search agent powered by LLMs. CoSearchAgent is designed as a Slack plugin that can support collaborative search during multi-party conversations on this platform. Equipped with the capacity to understand the queries and context in multi-user conversations and the ability to search the Web for relevant information via APIs, CoSearchAgent can respond to user queries with answers grounded on the relevant search results. It can also ask clarifying questions when the information needs are unclear. The proposed CoSearchAgent is highly flexible and would be useful for supporting further research on collaborative search. The code and demo video are accessible.","sentences":["Collaborative search supports multiple users working together to accomplish a specific search task.","Research has found that designing lightweight collaborative search plugins within instant messaging platforms aligns better with users' collaborative habits.","However, due to the complexity of multi-user interaction scenarios, it is challenging to implement a fully functioning lightweight collaborative search system.","Therefore, previous studies on lightweight collaborative search had to rely on the Wizard of Oz paradigm.","In recent years, large language models (LLMs) have been demonstrated to interact naturally with users and achieve complex information-seeking tasks through LLM-based agents.","Hence, to better support the research in collaborative search, in this demo, we propose CoSearchAgent, a lightweight collaborative search agent powered by LLMs.","CoSearchAgent is designed as a Slack plugin that can support collaborative search during multi-party conversations on this platform.","Equipped with the capacity to understand the queries and context in multi-user conversations and the ability to search the Web for relevant information via APIs, CoSearchAgent can respond to user queries with answers grounded on the relevant search results.","It can also ask clarifying questions when the information needs are unclear.","The proposed CoSearchAgent is highly flexible and would be useful for supporting further research on collaborative search.","The code and demo video are accessible."],"url":"http://arxiv.org/abs/2402.06360v1","category":"cs.IR"}
{"created":"2024-02-09 12:08:49","title":"Modelling Human Values for AI Reasoning","abstract":"One of today's most significant societal challenges is building AI systems whose behaviour, or the behaviour it enables within communities of interacting agents (human and artificial), aligns with human values. To address this challenge, we detail a formal model of human values for their explicit computational representation. To our knowledge, this has not been attempted as yet, which is surprising given the growing volume of research integrating values within AI. Taking as our starting point the wealth of research investigating the nature of human values from social psychology over the last few decades, we set out to provide such a formal model. We show how this model can provide the foundational apparatus for AI-based reasoning over values, and demonstrate its applicability in real-world use cases. We illustrate how our model captures the key ideas from social psychology research and propose a roadmap for future integrated, and interdisciplinary, research into human values in AI. The ability to automatically reason over values not only helps address the value alignment problem but also facilitates the design of AI systems that can support individuals and communities in making more informed, value-aligned decisions. More and more, individuals and organisations are motivated to understand their values more explicitly and explore whether their behaviours and attitudes properly reflect them. Our work on modelling human values will enable AI systems to be designed and deployed to meet this growing need.","sentences":["One of today's most significant societal challenges is building AI systems whose behaviour, or the behaviour it enables within communities of interacting agents (human and artificial), aligns with human values.","To address this challenge, we detail a formal model of human values for their explicit computational representation.","To our knowledge, this has not been attempted as yet, which is surprising given the growing volume of research integrating values within AI.","Taking as our starting point the wealth of research investigating the nature of human values from social psychology over the last few decades, we set out to provide such a formal model.","We show how this model can provide the foundational apparatus for AI-based reasoning over values, and demonstrate its applicability in real-world use cases.","We illustrate how our model captures the key ideas from social psychology research and propose a roadmap for future integrated, and interdisciplinary, research into human values in AI.","The ability to automatically reason over values not only helps address the value alignment problem but also facilitates the design of AI systems that can support individuals and communities in making more informed, value-aligned decisions.","More and more, individuals and organisations are motivated to understand their values more explicitly and explore whether their behaviours and attitudes properly reflect them.","Our work on modelling human values will enable AI systems to be designed and deployed to meet this growing need."],"url":"http://arxiv.org/abs/2402.06359v1","category":"cs.AI"}
{"created":"2024-02-09 12:08:05","title":"Robust inference for an interval-monitored step-stress experiment under proportional hazards","abstract":"Accelerated life tests (ALTs) play a crucial role in reliability analyses, providing lifetime estimates of highly reliable products. Among ALTs, step-stress design increases the stress level at predefined times, while maintaining a constant stress level between successive changes. This approach accelerates the occurrence of failures, reducing experimental duration and cost. While many studies assume a specific form for the lifetime distribution, in certain applications instead a general form satisfying certain properties should be preferred. Proportional hazard model assumes that applied stresses act multiplicatively on the hazard rate, so the hazards function may be divided into two factors, with one representing the effect of the stress, and the other representing the baseline hazard. In this work we examine two particular forms of baseline hazards, namely, linear and quadratic. Moreover, certain experiments may face practical constraints making continuous monitoring of devices infeasible. Instead, devices under test are inspected at predetermined intervals, leading to interval-censoring data. On the other hand, recent works have shown an appealing trade-off between the efficiency and robustness of divergence-based estimators. This paper introduces the step-stress ALT model under proportional hazards and presents a robust family of minimum density power divergence estimators (MDPDEs) for estimating device reliability and related lifetime characteristics such as mean lifetime and distributional quantiles. The asymptotic distributions of these estimates are derived, providing approximate confidence intervals. Empirical evaluations through Monte Carlo simulations demonstrate their performance in terms of robustness and efficiency. Finally, an illustrative example is provided to demonstrate the usefulness of the model and associated methods developed.","sentences":["Accelerated life tests (ALTs) play a crucial role in reliability analyses, providing lifetime estimates of highly reliable products.","Among ALTs, step-stress design increases the stress level at predefined times, while maintaining a constant stress level between successive changes.","This approach accelerates the occurrence of failures, reducing experimental duration and cost.","While many studies assume a specific form for the lifetime distribution, in certain applications instead a general form satisfying certain properties should be preferred.","Proportional hazard model assumes that applied stresses act multiplicatively on the hazard rate, so the hazards function may be divided into two factors, with one representing the effect of the stress, and the other representing the baseline hazard.","In this work we examine two particular forms of baseline hazards, namely, linear and quadratic.","Moreover, certain experiments may face practical constraints making continuous monitoring of devices infeasible.","Instead, devices under test are inspected at predetermined intervals, leading to interval-censoring data.","On the other hand, recent works have shown an appealing trade-off between the efficiency and robustness of divergence-based estimators.","This paper introduces the step-stress ALT model under proportional hazards and presents a robust family of minimum density power divergence estimators (MDPDEs) for estimating device reliability and related lifetime characteristics such as mean lifetime and distributional quantiles.","The asymptotic distributions of these estimates are derived, providing approximate confidence intervals.","Empirical evaluations through Monte Carlo simulations demonstrate their performance in terms of robustness and efficiency.","Finally, an illustrative example is provided to demonstrate the usefulness of the model and associated methods developed."],"url":"http://arxiv.org/abs/2402.06358v1","category":"math.ST"}
{"created":"2024-02-09 12:06:27","title":"On the geometry of quantum spheres and hyperboloids","abstract":"We study two classes of quantum spheres and hyperboloids which are $*$-quantum spaces for the quantum orthogonal group $\\mathcal{O}(SO_q(3))$. We construct line bundles over the quantum homogeneous space of invariant elements for the quantum subgroup $SO(2)$ of $SO_q(3)$. These are associated to the quantum principal bundle via corepresentations of $SO(2)$ and are given by finitely-generated projective modules $\\mathcal{E}_n$ of rank $1$ and even degree $-2n$. The corresponding idempotents, representing classes in K-theory, are explicitly worked out. For $q$ real, we diagonalise the Casimir operator of the Hopf algebra ${\\mathcal{U}_{q^{1/2}}(sl_2)}$ dual to $\\mathcal{O}(SO_q(3))$.","sentences":["We study two classes of quantum spheres and hyperboloids which are $*$-quantum spaces for the quantum orthogonal group $\\mathcal{O}(SO_q(3))$. We construct line bundles over the quantum homogeneous space of invariant elements for the quantum subgroup $SO(2)$ of $SO_q(3)$. These are associated to the quantum principal bundle via corepresentations of $SO(2)$ and are given by finitely-generated projective modules $\\mathcal{E}_n$ of rank $1$ and even degree $-2n$.","The corresponding idempotents, representing classes in K-theory, are explicitly worked out.","For $q$ real, we diagonalise the Casimir operator of the Hopf algebra ${\\mathcal{U}_{q^{1/2}}(sl_2)}$ dual to $\\mathcal{O}(SO_q(3))$."],"url":"http://arxiv.org/abs/2402.06356v1","category":"math.QA"}
{"created":"2024-02-09 12:03:02","title":"Sparse identification of nonlocal interaction kernels in nonlinear gradient flow equations via partial inversion","abstract":"We address the inverse problem of identifying nonlocal interaction potentials in nonlinear aggregation-diffusion equations from noisy discrete trajectory data. Our approach involves formulating and solving a regularized variational problem, which requires minimizing a quadratic error functional across a set of hypothesis functions, further augmented by a sparsity-enhancing regularizer. We employ a partial inversion algorithm, akin to the CoSaMP [57] and subspace pursuit algorithms [31], to solve the Basis Pursuit problem. A key theoretical contribution is our novel stability estimate for the PDEs, validating the error functional ability in controlling the 2-Wasserstein distance between solutions generated using the true and estimated interaction potentials. Our work also includes an error analysis of estimators caused by discretization and observational errors in practical implementations. We demonstrate the effectiveness of the methods through various 1D and 2D examples showcasing collective behaviors.","sentences":["We address the inverse problem of identifying nonlocal interaction potentials in nonlinear aggregation-diffusion equations from noisy discrete trajectory data.","Our approach involves formulating and solving a regularized variational problem, which requires minimizing a quadratic error functional across a set of hypothesis functions, further augmented by a sparsity-enhancing regularizer.","We employ a partial inversion algorithm, akin to the CoSaMP","[57] and subspace pursuit algorithms","[31], to solve the Basis Pursuit problem.","A key theoretical contribution is our novel stability estimate for the PDEs, validating the error functional ability in controlling the 2-Wasserstein distance between solutions generated using the true and estimated interaction potentials.","Our work also includes an error analysis of estimators caused by discretization and observational errors in practical implementations.","We demonstrate the effectiveness of the methods through various 1D and 2D examples showcasing collective behaviors."],"url":"http://arxiv.org/abs/2402.06355v1","category":"math.AP"}
{"created":"2024-02-09 12:01:48","title":"Taming the Bloch-Redfield equation: Recovering an accurate Lindblad equation for general open quantum systems","abstract":"Master equations play a pivotal role in investigating open quantum systems. In particular, the Bloch-Redfield equation stands out due to its relation to a concrete physical environment. However, without further approximations it does not lead to a Lindblad master equation that guarantees that the density matrix stays completely positive, which has raised some concerns regarding its use. This study builds on previous efforts to transform the Bloch-Redfield framework into a mathematically robust Lindblad equation, while fully preserving the effects that are lost within the secular approximation that is commonly used to guarantee positivity. These previous approaches introduce two potential deficiencies: the environment-induced energy shift can be non-Hermitian and some decay rates can be negative, violating the assumptions of Lindblad's theorem. Here, we propose and evaluate straightforward solutions to both problems. Our approach offers an effective and general procedure for obtaining a Lindblad equation, derived from a concrete physical environment, while mitigating the unphysical dynamics present in the Bloch-Redfield equation.","sentences":["Master equations play a pivotal role in investigating open quantum systems.","In particular, the Bloch-Redfield equation stands out due to its relation to a concrete physical environment.","However, without further approximations it does not lead to a Lindblad master equation that guarantees that the density matrix stays completely positive, which has raised some concerns regarding its use.","This study builds on previous efforts to transform the Bloch-Redfield framework into a mathematically robust Lindblad equation, while fully preserving the effects that are lost within the secular approximation that is commonly used to guarantee positivity.","These previous approaches introduce two potential deficiencies: the environment-induced energy shift can be non-Hermitian and some decay rates can be negative, violating the assumptions of Lindblad's theorem.","Here, we propose and evaluate straightforward solutions to both problems.","Our approach offers an effective and general procedure for obtaining a Lindblad equation, derived from a concrete physical environment, while mitigating the unphysical dynamics present in the Bloch-Redfield equation."],"url":"http://arxiv.org/abs/2402.06354v1","category":"quant-ph"}
{"created":"2024-02-09 12:01:22","title":"Towards actionability for open medical imaging datasets: lessons from community-contributed platforms for data management and stewardship","abstract":"Medical imaging datasets are fundamental to artificial intelligence (AI) in healthcare. The accuracy, robustness and fairness of diagnostic algorithms depend on the data (and its quality) on which the models are trained and evaluated. Medical imaging datasets have become increasingly available to the public, and are often hosted on Community-Contributed Platforms (CCP), including private companies like Kaggle or HuggingFace. While open data is important to enhance the redistribution of data's public value, we find that the current CCP governance model fails to uphold the quality needed and recommended practices for sharing, documenting, and evaluating datasets. In this paper we investigate medical imaging datasets on CCPs and how they are documented, shared, and maintained. We first highlight some differences between medical imaging and computer vision, particularly in the potentially harmful downstream effects due to poor adoption of recommended dataset management practices. We then analyze 20 (10 medical and 10 computer vision) popular datasets on CCPs and find vague licenses, lack of persistent identifiers and storage, duplicates and missing metadata, with differences between the platforms. We present \"actionability\" as a conceptual metric to reveal the data quality gap between characteristics of data on CCPs and the desired characteristics of data for AI in healthcare. Finally, we propose a commons-based stewardship model for documenting, sharing and maintaining datasets on CCPs and end with a discussion of limitations and open questions.","sentences":["Medical imaging datasets are fundamental to artificial intelligence (AI) in healthcare.","The accuracy, robustness and fairness of diagnostic algorithms depend on the data (and its quality) on which the models are trained and evaluated.","Medical imaging datasets have become increasingly available to the public, and are often hosted on Community-Contributed Platforms (CCP), including private companies like Kaggle or HuggingFace.","While open data is important to enhance the redistribution of data's public value, we find that the current CCP governance model fails to uphold the quality needed and recommended practices for sharing, documenting, and evaluating datasets.","In this paper we investigate medical imaging datasets on CCPs and how they are documented, shared, and maintained.","We first highlight some differences between medical imaging and computer vision, particularly in the potentially harmful downstream effects due to poor adoption of recommended dataset management practices.","We then analyze 20 (10 medical and 10 computer vision) popular datasets on CCPs and find vague licenses, lack of persistent identifiers and storage, duplicates and missing metadata, with differences between the platforms.","We present \"actionability\" as a conceptual metric to reveal the data quality gap between characteristics of data on CCPs and the desired characteristics of data for AI in healthcare.","Finally, we propose a commons-based stewardship model for documenting, sharing and maintaining datasets on CCPs and end with a discussion of limitations and open questions."],"url":"http://arxiv.org/abs/2402.06353v1","category":"cs.CV"}
{"created":"2024-02-09 11:55:04","title":"Characterization of the Clinically Approved MRI Tracer Resotran for Magnetic Particle Imaging in a Comparison Study","abstract":"Objective. The availability of magnetic nanoparticles with medical approval for human intervention is fundamental to the clinical translation of magnetic particle imaging (MPI). In this work, we thoroughly evaluate and compare the magnetic properties of an magnetic resonance imaging (MRI) approved tracer to validate its performance for MPI in future human trials. Approach. We analyze whether the recently approved MRI tracer Resotran is suitable for MPI. In addition, we compare Resotran with the previously approved and extensively studied tracer Resovist, with Ferrotran, which is currently in a clinical phase III study, and with the tailored MPI tracer Perimag. Main results. Initial magnetic particle spectroscopy measurements indicate that Resotran exhibits performance characteristics akin to Resovist, but below Perimag. We provide data on four different tracers using dynamic light scattering, transmission electron microscopy, vibrating sample magnetometry measurements, magnetic particle spectroscopy to derive hysteresis, point spread functions, and a serial dilution, as well as system matrix based MPI measurements on a preclinical scanner (Bruker 25/20 FF), including reconstructed images. Significance. Numerous approved magnetic nanoparticles used as tracers in MRI lack the necessary magnetic properties essential for robust signal generation in MPI. The process of obtaining medical approval for dedicated MPI tracers optimized for signal performance is an arduous and costly endeavor, often only justifiable for companies with a well-defined clinical business case. Resotran is an approved tracer that has become available in Europe for MRI. In this work, we study the eligibility of Resotran for MPI in an effort to pave the way for human MPI trials.","sentences":["Objective.","The availability of magnetic nanoparticles with medical approval for human intervention is fundamental to the clinical translation of magnetic particle imaging (MPI).","In this work, we thoroughly evaluate and compare the magnetic properties of an magnetic resonance imaging (MRI) approved tracer to validate its performance for MPI in future human trials.","Approach.","We analyze whether the recently approved MRI tracer Resotran is suitable for MPI.","In addition, we compare Resotran with the previously approved and extensively studied tracer Resovist, with Ferrotran, which is currently in a clinical phase III study, and with the tailored MPI tracer Perimag.","Main results.","Initial magnetic particle spectroscopy measurements indicate that Resotran exhibits performance characteristics akin to Resovist, but below Perimag.","We provide data on four different tracers using dynamic light scattering, transmission electron microscopy, vibrating sample magnetometry measurements, magnetic particle spectroscopy to derive hysteresis, point spread functions, and a serial dilution, as well as system matrix based MPI measurements on a preclinical scanner (Bruker 25/20 FF), including reconstructed images.","Significance.","Numerous approved magnetic nanoparticles used as tracers in MRI lack the necessary magnetic properties essential for robust signal generation in MPI.","The process of obtaining medical approval for dedicated MPI tracers optimized for signal performance is an arduous and costly endeavor, often only justifiable for companies with a well-defined clinical business case.","Resotran is an approved tracer that has become available in Europe for MRI.","In this work, we study the eligibility of Resotran for MPI in an effort to pave the way for human MPI trials."],"url":"http://arxiv.org/abs/2402.06350v1","category":"physics.med-ph"}
{"created":"2024-02-09 11:53:27","title":"Fairness of Exposure in Online Restless Multi-armed Bandits","abstract":"Restless multi-armed bandits (RMABs) generalize the multi-armed bandits where each arm exhibits Markovian behavior and transitions according to their transition dynamics. Solutions to RMAB exist for both offline and online cases. However, they do not consider the distribution of pulls among the arms. Studies have shown that optimal policies lead to unfairness, where some arms are not exposed enough. Existing works in fairness in RMABs focus heavily on the offline case, which diminishes their application in real-world scenarios where the environment is largely unknown. In the online scenario, we propose the first fair RMAB framework, where each arm receives pulls in proportion to its merit. We define the merit of an arm as a function of its stationary reward distribution. We prove that our algorithm achieves sublinear fairness regret in the single pull case $O(\\sqrt{T\\ln T})$, with $T$ being the total number of episodes. Empirically, we show that our algorithm performs well in the multi-pull scenario as well.","sentences":["Restless multi-armed bandits (RMABs) generalize the multi-armed bandits where each arm exhibits Markovian behavior and transitions according to their transition dynamics.","Solutions to RMAB exist for both offline and online cases.","However, they do not consider the distribution of pulls among the arms.","Studies have shown that optimal policies lead to unfairness, where some arms are not exposed enough.","Existing works in fairness in RMABs focus heavily on the offline case, which diminishes their application in real-world scenarios where the environment is largely unknown.","In the online scenario, we propose the first fair RMAB framework, where each arm receives pulls in proportion to its merit.","We define the merit of an arm as a function of its stationary reward distribution.","We prove that our algorithm achieves sublinear fairness regret in the single pull case $O(\\sqrt{T\\ln T})$, with $T$ being the total number of episodes.","Empirically, we show that our algorithm performs well in the multi-pull scenario as well."],"url":"http://arxiv.org/abs/2402.06348v1","category":"cs.LG"}
{"created":"2024-02-09 11:28:37","title":"Photon Number-Resolving Quantum Reservoir Computing","abstract":"Neuromorphic processors improve the efficiency of machine learning algorithms through the implementation of physical artificial neurons to perform computations. However, whilst efficient classical neuromorphic processors have been demonstrated in various forms, practical quantum neuromorphic platforms are still in the early stages of development. Here we propose a fixed optical network for photonic quantum reservoir computing that is enabled by photon number-resolved detection of the output states. This significantly reduces the required complexity of the input quantum states while still accessing a high-dimensional Hilbert space. The approach is implementable with currently available technology and lowers the barrier to entry to quantum machine learning.","sentences":["Neuromorphic processors improve the efficiency of machine learning algorithms through the implementation of physical artificial neurons to perform computations.","However, whilst efficient classical neuromorphic processors have been demonstrated in various forms, practical quantum neuromorphic platforms are still in the early stages of development.","Here we propose a fixed optical network for photonic quantum reservoir computing that is enabled by photon number-resolved detection of the output states.","This significantly reduces the required complexity of the input quantum states while still accessing a high-dimensional Hilbert space.","The approach is implementable with currently available technology and lowers the barrier to entry to quantum machine learning."],"url":"http://arxiv.org/abs/2402.06339v1","category":"quant-ph"}
{"created":"2024-02-09 11:25:23","title":"Degree reduction techniques for polynomial optimization problems","abstract":"This paper presents a new approach to quadrify a polynomial programming problem, i.e. reduce the polynomial program to a quadratic program, before solving it. The proposed approach, QUAD-RLT, exploits the Reformulation-Linearization Technique (RLT) structure to obtain smaller relaxations that can be solved faster and still provide high quality bounds. QUAD-RLT is compared to other quadrification techniques that have been previously discussed in the literature. The paper presents theoretical as well as computational results showing the advantage of QUAD-RLT compared to other quadrification techniques. Furthermore, rather than quadrifying a polynomial program, QUAD-RLT is generalized to reduce the degree of the polynomial to any degree. Computational results show that reducing the degree of the polynomial to a degree that is higher than two provides computational advantages in certain cases compared to fully quadrifying the problem. Finally, QUAD-RLT along with other quadrification/degree reduction schemes are implemented and made available in the freely available software RAPOSa.","sentences":["This paper presents a new approach to quadrify a polynomial programming problem, i.e. reduce the polynomial program to a quadratic program, before solving it.","The proposed approach, QUAD-RLT, exploits the Reformulation-Linearization Technique (RLT) structure to obtain smaller relaxations that can be solved faster and still provide high quality bounds.","QUAD-RLT is compared to other quadrification techniques that have been previously discussed in the literature.","The paper presents theoretical as well as computational results showing the advantage of QUAD-RLT compared to other quadrification techniques.","Furthermore, rather than quadrifying a polynomial program, QUAD-RLT is generalized to reduce the degree of the polynomial to any degree.","Computational results show that reducing the degree of the polynomial to a degree that is higher than two provides computational advantages in certain cases compared to fully quadrifying the problem.","Finally, QUAD-RLT along with other quadrification/degree reduction schemes are implemented and made available in the freely available software RAPOSa."],"url":"http://arxiv.org/abs/2402.06336v1","category":"math.OC"}
{"created":"2024-02-09 11:23:14","title":"ExaRanker-Open: Synthetic Explanation for IR using Open-Source LLMs","abstract":"ExaRanker recently introduced an approach to training information retrieval (IR) models, incorporating natural language explanations as additional labels. The method addresses the challenge of limited labeled examples, leading to improvements in the effectiveness of IR models. However, the initial results were based on proprietary language models such as GPT-3.5, which posed constraints on dataset size due to its cost and data privacy. In this paper, we introduce ExaRanker-Open, where we adapt and explore the use of open-source language models to generate explanations. The method has been tested using different LLMs and datasets sizes to better comprehend the effective contribution of data augmentation. Our findings reveal that incorporating explanations consistently enhances neural rankers, with benefits escalating as the LLM size increases. Notably, the data augmentation method proves advantageous even with large datasets, as evidenced by ExaRanker surpassing the target baseline by 0.6 nDCG@10 points in our study. To encourage further advancements by the research community, we have open-sourced both the code and datasets at https://github.com/unicamp-dl/ExaRanker.","sentences":["ExaRanker recently introduced an approach to training information retrieval (IR) models, incorporating natural language explanations as additional labels.","The method addresses the challenge of limited labeled examples, leading to improvements in the effectiveness of IR models.","However, the initial results were based on proprietary language models such as GPT-3.5, which posed constraints on dataset size due to its cost and data privacy.","In this paper, we introduce ExaRanker-Open, where we adapt and explore the use of open-source language models to generate explanations.","The method has been tested using different LLMs and datasets sizes to better comprehend the effective contribution of data augmentation.","Our findings reveal that incorporating explanations consistently enhances neural rankers, with benefits escalating as the LLM size increases.","Notably, the data augmentation method proves advantageous even with large datasets, as evidenced by ExaRanker surpassing the target baseline by 0.6 nDCG@10 points in our study.","To encourage further advancements by the research community, we have open-sourced both the code and datasets at https://github.com/unicamp-dl/ExaRanker."],"url":"http://arxiv.org/abs/2402.06334v1","category":"cs.IR"}
{"created":"2024-02-09 11:09:52","title":"A Network for structural dense displacement based on 3D deformable mesh model and optical flow","abstract":"This study proposes a Network to recognize displacement of a RC frame structure from a video by a monocular camera. The proposed Network consists of two modules which is FlowNet2 and POFRN-Net. FlowNet2 is used to generate dense optical flow as well as POFRN-Net is to extract pose parameter H. FlowNet2 convert two video frames into dense optical flow. POFRN-Net is inputted dense optical flow from FlowNet2 to output the pose parameter H. The displacement of any points of structure can be calculated from parameter H. The Fast Fourier Transform (FFT) is applied to obtain frequency domain signal from corresponding displacement signal. Furthermore, the comparison of the truth displacement on the First floor of the First video is shown in this study. Finally, the predicted displacements on four floors of RC frame structure of given three videos are exhibited in the last of this study.","sentences":["This study proposes a Network to recognize displacement of a RC frame structure from a video by a monocular camera.","The proposed Network consists of two modules which is FlowNet2 and POFRN-Net.","FlowNet2 is used to generate dense optical flow as well as POFRN-Net is to extract pose parameter H. FlowNet2 convert two video frames into dense optical flow.","POFRN-Net is inputted dense optical flow from FlowNet2 to output the pose parameter H.","The displacement of any points of structure can be calculated from parameter H. The Fast Fourier Transform (FFT) is applied to obtain frequency domain signal from corresponding displacement signal.","Furthermore, the comparison of the truth displacement on the First floor of the First video is shown in this study.","Finally, the predicted displacements on four floors of RC frame structure of given three videos are exhibited in the last of this study."],"url":"http://arxiv.org/abs/2402.06329v1","category":"cs.CV"}
{"created":"2024-02-09 11:06:20","title":"Prompt Learning on Temporal Interaction Graphs","abstract":"Temporal Interaction Graphs (TIGs) are widely utilized to represent real-world systems. To facilitate representation learning on TIGs, researchers have proposed a series of TIG models. However, these models are still facing two tough gaps between the pre-training and downstream predictions in their ``pre-train, predict'' training paradigm. First, the temporal discrepancy between the pre-training and inference data severely undermines the models' applicability in distant future predictions on the dynamically evolving data. Second, the semantic divergence between pretext and downstream tasks hinders their practical applications, as they struggle to align with their learning and prediction capabilities across application scenarios.   Recently, the ``pre-train, prompt'' paradigm has emerged as a lightweight mechanism for model generalization. Applying this paradigm is a potential solution to solve the aforementioned challenges. However, the adaptation of this paradigm to TIGs is not straightforward. The application of prompting in static graph contexts falls short in temporal settings due to a lack of consideration for time-sensitive dynamics and a deficiency in expressive power. To address this issue, we introduce Temporal Interaction Graph Prompting (TIGPrompt), a versatile framework that seamlessly integrates with TIG models, bridging both the temporal and semantic gaps. In detail, we propose a temporal prompt generator to offer temporally-aware prompts for different tasks. These prompts stand out for their minimalistic design, relying solely on the tuning of the prompt generator with very little supervision data. To cater to varying computational resource demands, we propose an extended ``pre-train, prompt-based fine-tune'' paradigm, offering greater flexibility. Through extensive experiments, the TIGPrompt demonstrates the SOTA performance and remarkable efficiency advantages.","sentences":["Temporal Interaction Graphs (TIGs) are widely utilized to represent real-world systems.","To facilitate representation learning on TIGs, researchers have proposed a series of TIG models.","However, these models are still facing two tough gaps between the pre-training and downstream predictions in their ``pre-train, predict'' training paradigm.","First, the temporal discrepancy between the pre-training and inference data severely undermines the models' applicability in distant future predictions on the dynamically evolving data.","Second, the semantic divergence between pretext and downstream tasks hinders their practical applications, as they struggle to align with their learning and prediction capabilities across application scenarios.   ","Recently, the ``pre-train, prompt'' paradigm has emerged as a lightweight mechanism for model generalization.","Applying this paradigm is a potential solution to solve the aforementioned challenges.","However, the adaptation of this paradigm to TIGs is not straightforward.","The application of prompting in static graph contexts falls short in temporal settings due to a lack of consideration for time-sensitive dynamics and a deficiency in expressive power.","To address this issue, we introduce Temporal Interaction Graph Prompting (TIGPrompt), a versatile framework that seamlessly integrates with TIG models, bridging both the temporal and semantic gaps.","In detail, we propose a temporal prompt generator to offer temporally-aware prompts for different tasks.","These prompts stand out for their minimalistic design, relying solely on the tuning of the prompt generator with very little supervision data.","To cater to varying computational resource demands, we propose an extended ``pre-train, prompt-based fine-tune'' paradigm, offering greater flexibility.","Through extensive experiments, the TIGPrompt demonstrates the SOTA performance and remarkable efficiency advantages."],"url":"http://arxiv.org/abs/2402.06326v1","category":"cs.AI"}
{"created":"2024-02-09 11:03:52","title":"How Uniform Random Weights Induce Non-uniform Bias: Typical Interpolating Neural Networks Generalize with Narrow Teachers","abstract":"Background. A main theoretical puzzle is why over-parameterized Neural Networks (NNs) generalize well when trained to zero loss (i.e., so they interpolate the data). Usually, the NN is trained with Stochastic Gradient Descent (SGD) or one of its variants. However, recent empirical work examined the generalization of a random NN that interpolates the data: the NN was sampled from a seemingly uniform prior over the parameters, conditioned on that the NN perfectly classifying the training set. Interestingly, such a NN sample typically generalized as well as SGD-trained NNs.   Contributions. We prove that such a random NN interpolator typically generalizes well if there exists an underlying narrow ``teacher NN\" that agrees with the labels. Specifically, we show that such a `flat' prior over the NN parametrization induces a rich prior over the NN functions, due to the redundancy in the NN structure. In particular, this creates a bias towards simpler functions, which require less relevant parameters to represent -- enabling learning with a sample complexity approximately proportional to the complexity of the teacher (roughly, the number of non-redundant parameters), rather than the student's.","sentences":["Background.","A main theoretical puzzle is why over-parameterized Neural Networks (NNs) generalize well when trained to zero loss (i.e., so they interpolate the data).","Usually, the NN is trained with Stochastic Gradient Descent (SGD) or one of its variants.","However, recent empirical work examined the generalization of a random NN that interpolates the data: the NN was sampled from a seemingly uniform prior over the parameters, conditioned on that the NN perfectly classifying the training set.","Interestingly, such a NN sample typically generalized as well as SGD-trained NNs.   ","Contributions.","We prove that such a random NN interpolator typically generalizes well if there exists an underlying narrow ``teacher NN\" that agrees with the labels.","Specifically, we show that such a `flat' prior over the NN parametrization induces a rich prior over the NN functions, due to the redundancy in the NN structure.","In particular, this creates a bias towards simpler functions, which require less relevant parameters to represent -- enabling learning with a sample complexity approximately proportional to the complexity of the teacher (roughly, the number of non-redundant parameters), rather than the student's."],"url":"http://arxiv.org/abs/2402.06323v1","category":"cs.LG"}
{"created":"2024-02-09 11:03:51","title":"Categorical-Symmetry Resolved Entanglement in CFT","abstract":"We propose a symmetry-resolved entanglement for categorical non-invertible generalized symmetries (CaT-SREE) in (1+1)-dimensional CFTs. The definition parallels that of group-like invertible symmetries employing the concept of symmetric boundary states with respect to a categorical symmetry. Our examination extends to rational CFTs, where the behavior of CaT-SREE mirrors that of group-like invertible symmetries. This includes instances of the breakdown of entanglement equipartition at the next-to-leading order in the cutoff expansion. The findings shed light on the interplay between categorical symmetries, entanglement, and boundary conditions in (1 + 1)-dimensional CFTs.","sentences":["We propose a symmetry-resolved entanglement for categorical non-invertible generalized symmetries (CaT-SREE) in (1+1)-dimensional CFTs.","The definition parallels that of group-like invertible symmetries employing the concept of symmetric boundary states with respect to a categorical symmetry.","Our examination extends to rational CFTs, where the behavior of CaT-SREE mirrors that of group-like invertible symmetries.","This includes instances of the breakdown of entanglement equipartition at the next-to-leading order in the cutoff expansion.","The findings shed light on the interplay between categorical symmetries, entanglement, and boundary conditions in (1 + 1)-dimensional CFTs."],"url":"http://arxiv.org/abs/2402.06322v1","category":"hep-th"}
{"created":"2024-02-09 11:01:35","title":"Particle Denoising Diffusion Sampler","abstract":"Denoising diffusion models have become ubiquitous for generative modeling. The core idea is to transport the data distribution to a Gaussian by using a diffusion. Approximate samples from the data distribution are then obtained by estimating the time-reversal of this diffusion using score matching ideas. We follow here a similar strategy to sample from unnormalized probability densities and compute their normalizing constants. However, the time-reversed diffusion is here simulated by using an original iterative particle scheme relying on a novel score matching loss. Contrary to standard denoising diffusion models, the resulting Particle Denoising Diffusion Sampler (PDDS) provides asymptotically consistent estimates under mild assumptions. We demonstrate PDDS on multimodal and high dimensional sampling tasks.","sentences":["Denoising diffusion models have become ubiquitous for generative modeling.","The core idea is to transport the data distribution to a Gaussian by using a diffusion.","Approximate samples from the data distribution are then obtained by estimating the time-reversal of this diffusion using score matching ideas.","We follow here a similar strategy to sample from unnormalized probability densities and compute their normalizing constants.","However, the time-reversed diffusion is here simulated by using an original iterative particle scheme relying on a novel score matching loss.","Contrary to standard denoising diffusion models, the resulting Particle Denoising Diffusion Sampler (PDDS) provides asymptotically consistent estimates under mild assumptions.","We demonstrate PDDS on multimodal and high dimensional sampling tasks."],"url":"http://arxiv.org/abs/2402.06320v1","category":"stat.ML"}
{"created":"2024-02-09 10:57:14","title":"TimEHR: Image-based Time Series Generation for Electronic Health Records","abstract":"Time series in Electronic Health Records (EHRs) present unique challenges for generative models, such as irregular sampling, missing values, and high dimensionality. In this paper, we propose a novel generative adversarial network (GAN) model, TimEHR, to generate time series data from EHRs. In particular, TimEHR treats time series as images and is based on two conditional GANs. The first GAN generates missingness patterns, and the second GAN generates time series values based on the missingness pattern. Experimental results on three real-world EHR datasets show that TimEHR outperforms state-of-the-art methods in terms of fidelity, utility, and privacy metrics.","sentences":["Time series in Electronic Health Records (EHRs) present unique challenges for generative models, such as irregular sampling, missing values, and high dimensionality.","In this paper, we propose a novel generative adversarial network (GAN) model, TimEHR, to generate time series data from EHRs.","In particular, TimEHR treats time series as images and is based on two conditional GANs.","The first GAN generates missingness patterns, and the second GAN generates time series values based on the missingness pattern.","Experimental results on three real-world EHR datasets show that TimEHR outperforms state-of-the-art methods in terms of fidelity, utility, and privacy metrics."],"url":"http://arxiv.org/abs/2402.06318v1","category":"cs.LG"}
{"created":"2024-02-09 10:50:28","title":"Multisource Semisupervised Adversarial Domain Generalization Network for Cross-Scene Sea\\textendash Land Clutter Classification","abstract":"Deep learning (DL)-based sea\\textendash land clutter classification for sky-wave over-the-horizon-radar (OTHR) has become a novel research topic. In engineering applications, real-time predictions of sea\\textendash land clutter with existing distribution discrepancies are crucial. To solve this problem, this article proposes a novel Multisource Semisupervised Adversarial Domain Generalization Network (MSADGN) for cross-scene sea\\textendash land clutter classification. MSADGN can extract domain-invariant and domain-specific features from one labeled source domain and multiple unlabeled source domains, and then generalize these features to an arbitrary unseen target domain for real-time prediction of sea\\textendash land clutter. Specifically, MSADGN consists of three modules: domain-related pseudolabeling module, domain-invariant module, and domain-specific module. The first module introduces an improved pseudolabel method called domain-related pseudolabel, which is designed to generate reliable pseudolabels to fully exploit unlabeled source domains. The second module utilizes a generative adversarial network (GAN) with a multidiscriminator to extract domain-invariant features, to enhance the model's transferability in the target domain. The third module employs a parallel multiclassifier branch to extract domain-specific features, to enhance the model's discriminability in the target domain. The effectiveness of our method is validated in twelve domain generalizations (DG) scenarios. Meanwhile, we selected 10 state-of-the-art DG methods for comparison. The experimental results demonstrate the superiority of our method.","sentences":["Deep learning (DL)-based sea\\textendash land clutter classification for sky-wave over-the-horizon-radar (OTHR) has become a novel research topic.","In engineering applications, real-time predictions of sea\\textendash land clutter with existing distribution discrepancies are crucial.","To solve this problem, this article proposes a novel Multisource Semisupervised Adversarial Domain Generalization Network (MSADGN) for cross-scene sea\\textendash land clutter classification.","MSADGN can extract domain-invariant and domain-specific features from one labeled source domain and multiple unlabeled source domains, and then generalize these features to an arbitrary unseen target domain for real-time prediction of sea\\textendash land clutter.","Specifically, MSADGN consists of three modules: domain-related pseudolabeling module, domain-invariant module, and domain-specific module.","The first module introduces an improved pseudolabel method called domain-related pseudolabel, which is designed to generate reliable pseudolabels to fully exploit unlabeled source domains.","The second module utilizes a generative adversarial network (GAN) with a multidiscriminator to extract domain-invariant features, to enhance the model's transferability in the target domain.","The third module employs a parallel multiclassifier branch to extract domain-specific features, to enhance the model's discriminability in the target domain.","The effectiveness of our method is validated in twelve domain generalizations (DG) scenarios.","Meanwhile, we selected 10 state-of-the-art DG methods for comparison.","The experimental results demonstrate the superiority of our method."],"url":"http://arxiv.org/abs/2402.06315v1","category":"cs.CV"}
{"created":"2024-02-09 10:43:17","title":"A plastic correction algorithm for full-field elasto-plastic finite element simulations : critical assessment of predictive capabilities and improvement by machine learning","abstract":"This paper introduces a new local plastic correction algorithm developed to accelerate finite element simulations for structures with elasto-plastic constitutive laws. The proposed method belongs to the category of generalized multiaxial Neuber-type methods enabled by pointwise proportional evolution rules. The algorithm numerically integrates J2 plasticity laws as a function of the finite element elastic response of the structure, to obtain full-field 3D elasto-plastic quantities for any proportionally applied loading. Examples of the numerical capabilities of this algorithm are shown on a structure containing a distribution of pores, for monotonic and fatigue loading. The approximation errors due to the proposed local plastic correction are also investigated. As a second point of innovation, we show that the proposed local plastic correction can be accelerated when dealing with large-scale structures by employing a simple meta-model, with virtually no added errors. Finally, we develop and investigate the merits of an additional deep-learning-based corrective layer to reduce approximations errors on a subset of structures for which full elasto-plastic FE simulations are performed, the solutions of which are subsequently used as training set for a Convolutional Neural Network algorithm designed to learn the error between full FE and plastic correction approximations.","sentences":["This paper introduces a new local plastic correction algorithm developed to accelerate finite element simulations for structures with elasto-plastic constitutive laws.","The proposed method belongs to the category of generalized multiaxial Neuber-type methods enabled by pointwise proportional evolution rules.","The algorithm numerically integrates J2 plasticity laws as a function of the finite element elastic response of the structure, to obtain full-field 3D elasto-plastic quantities for any proportionally applied loading.","Examples of the numerical capabilities of this algorithm are shown on a structure containing a distribution of pores, for monotonic and fatigue loading.","The approximation errors due to the proposed local plastic correction are also investigated.","As a second point of innovation, we show that the proposed local plastic correction can be accelerated when dealing with large-scale structures by employing a simple meta-model, with virtually no added errors.","Finally, we develop and investigate the merits of an additional deep-learning-based corrective layer to reduce approximations errors on a subset of structures for which full elasto-plastic FE simulations are performed, the solutions of which are subsequently used as training set for a Convolutional Neural Network algorithm designed to learn the error between full FE and plastic correction approximations."],"url":"http://arxiv.org/abs/2402.06313v1","category":"cs.CE"}
{"created":"2024-02-09 10:38:44","title":"An integrated heart-torso electromechanical model for the simulation of electrophysiogical outputs accounting for myocardial deformation","abstract":"When generating in-silico clinical electrophysiological outputs, such as electrocardiograms (ECGs) and body surface potential maps (BSPMs), mathematical models have relied on single physics, i.e. of the cardiac electrophysiology (EP), neglecting the role of the heart motion. Since the heart is the most powerful source of electrical activity in the human body, its motion dynamically shifts the position of the principal electrical sources in the torso, influencing electrical potential distribution and potentially altering the EP outputs. In this work, we propose a computational model for the simulation of ECGs and BSPMs by coupling a cardiac electromechanical model with a model that simulates the propagation of the EP signal in the torso, thanks to a flexible numerical approach, that simulates the torso domain deformation induced by the myocardial displacement. Our model accounts for the major mechano-electrical feedbacks, along with unidirectional displacement and potential couplings from the heart to the surrounding body. For the numerical discretization, we employ a versatile intergrid transfer operator that allows for the use of different Finite Element spaces to be used in the cardiac and torso domains. Our numerical results are obtained on a realistic 3D biventricular-torso geometry, and cover both cases of sinus rhythm and ventricular tachycardia (VT), solving both the electromechanical-torso model in dynamical domains, and the classical electrophysiology-torso model in static domains. By comparing standard 12-lead ECG and BSPMs, we highlight the non-negligible effects of the myocardial contraction on the EP-outputs, especially in pathological conditions, such as the VT.","sentences":["When generating in-silico clinical electrophysiological outputs, such as electrocardiograms (ECGs) and body surface potential maps (BSPMs), mathematical models have relied on single physics, i.e. of the cardiac electrophysiology (EP), neglecting the role of the heart motion.","Since the heart is the most powerful source of electrical activity in the human body, its motion dynamically shifts the position of the principal electrical sources in the torso, influencing electrical potential distribution and potentially altering the EP outputs.","In this work, we propose a computational model for the simulation of ECGs and BSPMs by coupling a cardiac electromechanical model with a model that simulates the propagation of the EP signal in the torso, thanks to a flexible numerical approach, that simulates the torso domain deformation induced by the myocardial displacement.","Our model accounts for the major mechano-electrical feedbacks, along with unidirectional displacement and potential couplings from the heart to the surrounding body.","For the numerical discretization, we employ a versatile intergrid transfer operator that allows for the use of different Finite Element spaces to be used in the cardiac and torso domains.","Our numerical results are obtained on a realistic 3D biventricular-torso geometry, and cover both cases of sinus rhythm and ventricular tachycardia (VT), solving both the electromechanical-torso model in dynamical domains, and the classical electrophysiology-torso model in static domains.","By comparing standard 12-lead ECG and BSPMs, we highlight the non-negligible effects of the myocardial contraction on the EP-outputs, especially in pathological conditions, such as the VT."],"url":"http://arxiv.org/abs/2402.06308v1","category":"math.NA"}
{"created":"2024-02-09 10:34:49","title":"The power of binary pulsars in testing Gauss-Bonnet gravity","abstract":"Binary pulsars are a powerful tool for probing strong gravity that still outperforms direct gravitational wave observations in a number of directions due to the remarkable accuracy of the pulsar timing. They can constrain very precisely the presence of additional charges of the orbiting neutron stars leading to new channels of energy and angular momentum loss, such as the scalar dipole radiation. In the present paper, we explore in detail the possibility of constraining different classes of scalar-Gauss-Bonnet gravity with binary pulsars. Additionally, the existing constraints related to the observed maximum mass of neutron stars are also updated. Interestingly, depending on the equation of state, the resulting limits on the theory coupling parameters can outperform the constraints coming from binary merger observations by up to a factor of 2 even for the so-called Einstein-dilaton-Gauss-Bonnet gravity where neutron stars are often underestimated as relevant theory probes. As an additional merit, precise Bayesian methods are compared with approximate approaches with the latter showing very good performance despite their simplicity.","sentences":["Binary pulsars are a powerful tool for probing strong gravity that still outperforms direct gravitational wave observations in a number of directions due to the remarkable accuracy of the pulsar timing.","They can constrain very precisely the presence of additional charges of the orbiting neutron stars leading to new channels of energy and angular momentum loss, such as the scalar dipole radiation.","In the present paper, we explore in detail the possibility of constraining different classes of scalar-Gauss-Bonnet gravity with binary pulsars.","Additionally, the existing constraints related to the observed maximum mass of neutron stars are also updated.","Interestingly, depending on the equation of state, the resulting limits on the theory coupling parameters can outperform the constraints coming from binary merger observations by up to a factor of 2 even for the so-called Einstein-dilaton-Gauss-Bonnet gravity where neutron stars are often underestimated as relevant theory probes.","As an additional merit, precise Bayesian methods are compared with approximate approaches with the latter showing very good performance despite their simplicity."],"url":"http://arxiv.org/abs/2402.06305v1","category":"gr-qc"}
{"created":"2024-02-09 10:34:01","title":"A New Approach to Voice Authenticity","abstract":"Voice faking, driven primarily by recent advances in text-to-speech (TTS) synthesis technology, poses significant societal challenges. Currently, the prevailing assumption is that unaltered human speech can be considered genuine, while fake speech comes from TTS synthesis. We argue that this binary distinction is oversimplified. For instance, altered playback speeds can be used for malicious purposes, like in the 'Drunken Nancy Pelosi' incident. Similarly, editing of audio clips can be done ethically, e.g., for brevity or summarization in news reporting or podcasts, but editing can also create misleading narratives. In this paper, we propose a conceptual shift away from the binary paradigm of audio being either 'fake' or 'real'. Instead, our focus is on pinpointing 'voice edits', which encompass traditional modifications like filters and cuts, as well as TTS synthesis and VC systems. We delineate 6 categories and curate a new challenge dataset rooted in the M-AILABS corpus, for which we present baseline detection systems. And most importantly, we argue that merely categorizing audio as fake or real is a dangerous over-simplification that will fail to move the field of speech technology forward.","sentences":["Voice faking, driven primarily by recent advances in text-to-speech (TTS) synthesis technology, poses significant societal challenges.","Currently, the prevailing assumption is that unaltered human speech can be considered genuine, while fake speech comes from TTS synthesis.","We argue that this binary distinction is oversimplified.","For instance, altered playback speeds can be used for malicious purposes, like in the 'Drunken Nancy Pelosi' incident.","Similarly, editing of audio clips can be done ethically, e.g., for brevity or summarization in news reporting or podcasts, but editing can also create misleading narratives.","In this paper, we propose a conceptual shift away from the binary paradigm of audio being either 'fake' or 'real'.","Instead, our focus is on pinpointing 'voice edits', which encompass traditional modifications like filters and cuts, as well as TTS synthesis and VC systems.","We delineate 6 categories and curate a new challenge dataset rooted in the M-AILABS corpus, for which we present baseline detection systems.","And most importantly, we argue that merely categorizing audio as fake or real is a dangerous over-simplification that will fail to move the field of speech technology forward."],"url":"http://arxiv.org/abs/2402.06304v1","category":"cs.SD"}
{"created":"2024-02-09 10:30:25","title":"Transversal matroids and the half plane property","abstract":"We focus on checking the validity of the half-plane property on two prominent classes of transversal matroids, namely lattice path matroids and bicircular matroids. We show that lattice path matroids satisfy the half-plane property. Subsequently, we show an explicit example of a bicircular matroid that is not a positroid and discuss the negative correlation properties of bases of transversal matroids. We prove that sparse paving matroids do not satisfy the Rayleigh property, which helps us gain new perspectives about conjectures on negative correlation in basis elements of matroids in general.","sentences":["We focus on checking the validity of the half-plane property on two prominent classes of transversal matroids, namely lattice path matroids and bicircular matroids.","We show that lattice path matroids satisfy the half-plane property.","Subsequently, we show an explicit example of a bicircular matroid that is not a positroid and discuss the negative correlation properties of bases of transversal matroids.","We prove that sparse paving matroids do not satisfy the Rayleigh property, which helps us gain new perspectives about conjectures on negative correlation in basis elements of matroids in general."],"url":"http://arxiv.org/abs/2402.06302v1","category":"math.CO"}
{"created":"2024-02-09 10:24:50","title":"Dynamics of the $N$-body system in energy-momentum squared gravity: Equations of motion to the first post-Newtonian order","abstract":"In the energy-momentum squared gravity (EMSG), the matter energy-momentum tensor is not conserved due to nonminimal interaction between the usual and modified matter fields. For this reason, the $N$-body acceleration may host the EMSG effects that can be probed at the solar scale by the perihelion shift of the planets and experimental tests of the Strong Equivalence Principle (SEP). To clarify this point, in this paper, we introduce the $N$-body equations of motion in the weak-field limit of the EMSG theory. To do so, the post-Newtonian (PN) hydrodynamic equations, the viral identities, as well as the corresponding equilibrium conditions are introduced in this theory. Armed with these relations, we derive the dynamics of the $N$-body system and its PN inter-body metric. It is shown that the EMSG theory is not ruled out by the classical test, the perihelion advance of Mercury, and the test of SEP. In other words, in the first PN order, it is not possible to constrain the free parameter of this theory and even distinguish it from GR using these local tests.","sentences":["In the energy-momentum squared gravity (EMSG), the matter energy-momentum tensor is not conserved due to nonminimal interaction between the usual and modified matter fields.","For this reason, the $N$-body acceleration may host the EMSG effects that can be probed at the solar scale by the perihelion shift of the planets and experimental tests of the Strong Equivalence Principle (SEP).","To clarify this point, in this paper, we introduce the $N$-body equations of motion in the weak-field limit of the EMSG theory.","To do so, the post-Newtonian (PN) hydrodynamic equations, the viral identities, as well as the corresponding equilibrium conditions are introduced in this theory.","Armed with these relations, we derive the dynamics of the $N$-body system and its PN inter-body metric.","It is shown that the EMSG theory is not ruled out by the classical test, the perihelion advance of Mercury, and the test of SEP.","In other words, in the first PN order, it is not possible to constrain the free parameter of this theory and even distinguish it from GR using these local tests."],"url":"http://arxiv.org/abs/2402.06300v1","category":"gr-qc"}
{"created":"2024-02-09 10:24:47","title":"A Functional Analysis Approach to Symbolic Regression","abstract":"Symbolic regression (SR) poses a significant challenge for randomized search heuristics due to its reliance on the synthesis of expressions for input-output mappings. Although traditional genetic programming (GP) algorithms have achieved success in various domains, they exhibit limited performance when tree-based representations are used for SR. To address these limitations, we introduce a novel SR approach called Fourier Tree Growing (FTG) that draws insights from functional analysis. This new perspective enables us to perform optimization directly in a different space, thus avoiding intricate symbolic expressions. Our proposed algorithm exhibits significant performance improvements over traditional GP methods on a range of classical one-dimensional benchmarking problems. To identify and explain limiting factors of GP and FTG, we perform experiments on a large-scale polynomials benchmark with high-order polynomials up to degree 100. To the best of the authors' knowledge, this work represents the pioneering application of functional analysis in addressing SR problems. The superior performance of the proposed algorithm and insights into the limitations of GP open the way for further advancing GP for SR and related areas of explainable machine learning.","sentences":["Symbolic regression (SR) poses a significant challenge for randomized search heuristics due to its reliance on the synthesis of expressions for input-output mappings.","Although traditional genetic programming (GP) algorithms have achieved success in various domains, they exhibit limited performance when tree-based representations are used for SR.","To address these limitations, we introduce a novel SR approach called Fourier Tree Growing (FTG) that draws insights from functional analysis.","This new perspective enables us to perform optimization directly in a different space, thus avoiding intricate symbolic expressions.","Our proposed algorithm exhibits significant performance improvements over traditional GP methods on a range of classical one-dimensional benchmarking problems.","To identify and explain limiting factors of GP and FTG, we perform experiments on a large-scale polynomials benchmark with high-order polynomials up to degree 100.","To the best of the authors' knowledge, this work represents the pioneering application of functional analysis in addressing SR problems.","The superior performance of the proposed algorithm and insights into the limitations of GP open the way for further advancing GP for SR and related areas of explainable machine learning."],"url":"http://arxiv.org/abs/2402.06299v1","category":"cs.NE"}
{"created":"2024-02-09 10:19:48","title":"Dynamic Q-planning for Online UAV Path Planning in Unknown and Complex Environments","abstract":"Unmanned Aerial Vehicles need an online path planning capability to move in high-risk missions in unknown and complex environments to complete them safely. However, many algorithms reported in the literature may not return reliable trajectories to solve online problems in these scenarios. The Q-Learning algorithm, a Reinforcement Learning Technique, can generate trajectories in real-time and has demonstrated fast and reliable results. This technique, however, has the disadvantage of defining the iteration number. If this value is not well defined, it will take a long time or not return an optimal trajectory. Therefore, we propose a method to dynamically choose the number of iterations to obtain the best performance of Q-Learning. The proposed method is compared to the Q-Learning algorithm with a fixed number of iterations, A*, Rapid-Exploring Random Tree, and Particle Swarm Optimization. As a result, the proposed Q-learning algorithm demonstrates the efficacy and reliability of online path planning with a dynamic number of iterations to carry out online missions in unknown and complex environments.","sentences":["Unmanned Aerial Vehicles need an online path planning capability to move in high-risk missions in unknown and complex environments to complete them safely.","However, many algorithms reported in the literature may not return reliable trajectories to solve online problems in these scenarios.","The Q-Learning algorithm, a Reinforcement Learning Technique, can generate trajectories in real-time and has demonstrated fast and reliable results.","This technique, however, has the disadvantage of defining the iteration number.","If this value is not well defined, it will take a long time or not return an optimal trajectory.","Therefore, we propose a method to dynamically choose the number of iterations to obtain the best performance of Q-Learning.","The proposed method is compared to the Q-Learning algorithm with a fixed number of iterations, A*, Rapid-Exploring Random Tree, and Particle Swarm Optimization.","As a result, the proposed Q-learning algorithm demonstrates the efficacy and reliability of online path planning with a dynamic number of iterations to carry out online missions in unknown and complex environments."],"url":"http://arxiv.org/abs/2402.06297v1","category":"cs.RO"}
{"created":"2024-02-09 10:19:22","title":"Capillary imbibition in lubricant coated channels","abstract":"Capillary imbibition underpins many processes of fundamental and applied relevance in fluid mechanics. A limitation to the flow is the coupling to the confining solid, which induces friction forces. Our work proposes a general theoretical framework for the modeling of the transport of liquids in lubricant impregnated surfaces. We show that for sufficiently small lubricant viscosity, dissipation entirely occurs in the lubricant layer, resulting in a linear growth of the advancing front. As a result, an external force gives rise to an exponential front growth. This new capacity to control multiphase flows sets new experimental challenges that can be determinant for micro and nanofluidic devices.","sentences":["Capillary imbibition underpins many processes of fundamental and applied relevance in fluid mechanics.","A limitation to the flow is the coupling to the confining solid, which induces friction forces.","Our work proposes a general theoretical framework for the modeling of the transport of liquids in lubricant impregnated surfaces.","We show that for sufficiently small lubricant viscosity, dissipation entirely occurs in the lubricant layer, resulting in a linear growth of the advancing front.","As a result, an external force gives rise to an exponential front growth.","This new capacity to control multiphase flows sets new experimental challenges that can be determinant for micro and nanofluidic devices."],"url":"http://arxiv.org/abs/2402.06296v1","category":"physics.flu-dyn"}
{"created":"2024-02-09 10:14:07","title":"Towards full control of molecular exciton energy transfer via FRET in DNA origami assemblies","abstract":"Controlling the flow of excitons between organic molecules holds immense promise for various applications, including energy conversion, spectroscopy, photocatalysis, sensing, and microscopy. DNA nanotechnology has shown promise in achieving this control by using synthetic DNA as a platform for positioning and, very recently, for also orienting organic dyes. In this study, the orientation of doubly-linked dyes in DNA origami structures was manipulated to control energy transfer. By controlling independently the orientation of single donor and acceptor molecules, the average energy transfer efficiency was doubled. This work demonstrates the potential of DNA nanotechnology for precise control of the excitonic energy transfer with implications for artificial light-harvesting antennas.","sentences":["Controlling the flow of excitons between organic molecules holds immense promise for various applications, including energy conversion, spectroscopy, photocatalysis, sensing, and microscopy.","DNA nanotechnology has shown promise in achieving this control by using synthetic DNA as a platform for positioning and, very recently, for also orienting organic dyes.","In this study, the orientation of doubly-linked dyes in DNA origami structures was manipulated to control energy transfer.","By controlling independently the orientation of single donor and acceptor molecules, the average energy transfer efficiency was doubled.","This work demonstrates the potential of DNA nanotechnology for precise control of the excitonic energy transfer with implications for artificial light-harvesting antennas."],"url":"http://arxiv.org/abs/2402.06292v1","category":"cond-mat.soft"}
{"created":"2024-02-09 09:54:01","title":"AI, Meet Human: Learning Paradigms for Hybrid Decision Making Systems","abstract":"Everyday we increasingly rely on machine learning models to automate and support high-stake tasks and decisions. This growing presence means that humans are now constantly interacting with machine learning-based systems, training and using models everyday. Several different techniques in computer science literature account for the human interaction with machine learning systems, but their classification is sparse and the goals varied. This survey proposes a taxonomy of Hybrid Decision Making Systems, providing both a conceptual and technical framework for understanding how current computer science literature models interaction between humans and machines.","sentences":["Everyday we increasingly rely on machine learning models to automate and support high-stake tasks and decisions.","This growing presence means that humans are now constantly interacting with machine learning-based systems, training and using models everyday.","Several different techniques in computer science literature account for the human interaction with machine learning systems, but their classification is sparse and the goals varied.","This survey proposes a taxonomy of Hybrid Decision Making Systems, providing both a conceptual and technical framework for understanding how current computer science literature models interaction between humans and machines."],"url":"http://arxiv.org/abs/2402.06287v1","category":"cs.LG"}
{"created":"2024-02-09 09:52:11","title":"Morphometry on the sphere: Cartesian and irreducible Minkowski tensors explained and implemented","abstract":"Minkowski tensors are comprehensive shape descriptors that robustly capture n-point information in complex random geometries and that have already been extensively applied in the Euclidean plane. Here, we devise a novel framework for Minkowski tensors on the sphere. We first advance the theory by introducing irreducible Minkowski tensors, which avoid the redundancies of previous representations. We, moreover, generalize Minkowski sky maps to the sphere, i.e., a concept of local anisotropy, which easily adjusts to masked data. We demonstrate the power of our new procedure by applying it to simulations and real data of the Cosmic Microwave Background, finding an anomalous region close to the well-known Cold Spot. The accompanying open-source software, litchi, used to generate these maps from data in the HEALPix-format is made publicly available to facilitate broader integration of Minkowski maps in other fields, such as fluid demixing, porous structures, or geosciences more generally.","sentences":["Minkowski tensors are comprehensive shape descriptors that robustly capture n-point information in complex random geometries and that have already been extensively applied in the Euclidean plane.","Here, we devise a novel framework for Minkowski tensors on the sphere.","We first advance the theory by introducing irreducible Minkowski tensors, which avoid the redundancies of previous representations.","We, moreover, generalize Minkowski sky maps to the sphere, i.e., a concept of local anisotropy, which easily adjusts to masked data.","We demonstrate the power of our new procedure by applying it to simulations and real data of the Cosmic Microwave Background, finding an anomalous region close to the well-known Cold Spot.","The accompanying open-source software, litchi, used to generate these maps from data in the HEALPix-format is made publicly available to facilitate broader integration of Minkowski maps in other fields, such as fluid demixing, porous structures, or geosciences more generally."],"url":"http://arxiv.org/abs/2402.06286v1","category":"astro-ph.IM"}
{"created":"2024-02-09 09:50:49","title":"Super-Realized Gain Huygens Antennas","abstract":"This study presents a superdirective antenna array specifically designed for the sub-6 5G generation frequency range, incorporating pioneering Huygens antenna elements. The optimized structure achieves a realized gain that surpasses Harrington's well-known maximum theoretical limit for antenna directivity, effectively addressing practical concerns related to ohmic and return losses. Additionally, the compact size of the proposed antenna array, as opposed to a uniform linear array, offers the potential to fabricate highly radiation-efficient, high-directivity antennas in a compact form.","sentences":["This study presents a superdirective antenna array specifically designed for the sub-6 5G generation frequency range, incorporating pioneering Huygens antenna elements.","The optimized structure achieves a realized gain that surpasses Harrington's well-known maximum theoretical limit for antenna directivity, effectively addressing practical concerns related to ohmic and return losses.","Additionally, the compact size of the proposed antenna array, as opposed to a uniform linear array, offers the potential to fabricate highly radiation-efficient, high-directivity antennas in a compact form."],"url":"http://arxiv.org/abs/2402.06285v1","category":"physics.app-ph"}
{"created":"2024-02-09 09:49:05","title":"Towards Chip-in-the-loop Spiking Neural Network Training via Metropolis-Hastings Sampling","abstract":"This paper studies the use of Metropolis-Hastings sampling for training Spiking Neural Network (SNN) hardware subject to strong unknown non-idealities, and compares the proposed approach to the common use of the backpropagation of error (backprop) algorithm and surrogate gradients, widely used to train SNNs in literature. Simulations are conducted within a chip-in-the-loop training context, where an SNN subject to unknown distortion must be trained to detect cancer from measurements, within a biomedical application context. Our results show that the proposed approach strongly outperforms the use of backprop by up to $27\\%$ higher accuracy when subject to strong hardware non-idealities. Furthermore, our results also show that the proposed approach outperforms backprop in terms of SNN generalization, needing $>10 \\times$ less training data for achieving effective accuracy. These findings make the proposed training approach well-suited for SNN implementations in analog subthreshold circuits and other emerging technologies where unknown hardware non-idealities can jeopardize backprop.","sentences":["This paper studies the use of Metropolis-Hastings sampling for training Spiking Neural Network (SNN) hardware subject to strong unknown non-idealities, and compares the proposed approach to the common use of the backpropagation of error (backprop) algorithm and surrogate gradients, widely used to train SNNs in literature.","Simulations are conducted within a chip-in-the-loop training context, where an SNN subject to unknown distortion must be trained to detect cancer from measurements, within a biomedical application context.","Our results show that the proposed approach strongly outperforms the use of backprop by up to $27\\%$ higher accuracy when subject to strong hardware non-idealities.","Furthermore, our results also show that the proposed approach outperforms backprop in terms of SNN generalization, needing $>10 \\times$ less training data for achieving effective accuracy.","These findings make the proposed training approach well-suited for SNN implementations in analog subthreshold circuits and other emerging technologies where unknown hardware non-idealities can jeopardize backprop."],"url":"http://arxiv.org/abs/2402.06284v1","category":"cs.NE"}
{"created":"2024-02-09 09:44:59","title":"Disorder-Induced Topological Transitions in a Multilayer Topological Insulator","abstract":"We examine the impact of non-magnetic disorder on the electronic states of a multilayer structure comprising layers of both topological and conventional band insulators. Employing the Burkov-Balents model with renormalized tunneling parameters, we generate phase diagrams correlating with disorder, demonstrating that non-magnetic disorder can induce transitions between distinct topological phases. The subsequent section of our investigation focuses on the scenario where disorder is unevenly distributed across layers, resulting in fluctuations of the interlayer tunneling parameter -- termed off-diagonal disorder. Furthermore, we determine the density of states employing the self-consistent single-site diagram technique, expanding the Green function in relation to the interlayer tunneling parameter (locator method). Our findings reveal that off-diagonal disorder engenders delocalized bulk states within the band gap. The emergence of these states may lead to the breakdown of the anomalous quantum Hall effect (AQHE) phase, a phenomenon that has garnered significant attention from researchers in the realm of topological heterostructures. Nonetheless, our results affirm the stability of the Weyl semimetal phase even under substantial off-diagonal disorder.","sentences":["We examine the impact of non-magnetic disorder on the electronic states of a multilayer structure comprising layers of both topological and conventional band insulators.","Employing the Burkov-Balents model with renormalized tunneling parameters, we generate phase diagrams correlating with disorder, demonstrating that non-magnetic disorder can induce transitions between distinct topological phases.","The subsequent section of our investigation focuses on the scenario where disorder is unevenly distributed across layers, resulting in fluctuations of the interlayer tunneling parameter -- termed off-diagonal disorder.","Furthermore, we determine the density of states employing the self-consistent single-site diagram technique, expanding the Green function in relation to the interlayer tunneling parameter (locator method).","Our findings reveal that off-diagonal disorder engenders delocalized bulk states within the band gap.","The emergence of these states may lead to the breakdown of the anomalous quantum Hall effect (AQHE) phase, a phenomenon that has garnered significant attention from researchers in the realm of topological heterostructures.","Nonetheless, our results affirm the stability of the Weyl semimetal phase even under substantial off-diagonal disorder."],"url":"http://arxiv.org/abs/2402.06280v1","category":"cond-mat.mes-hall"}
{"created":"2024-02-09 09:44:39","title":"Spectra of infinite Cayley graphs, examples with pure band spectra","abstract":"It is shown that there are groups $\\Gamma$ with finite generating sets $S$ such that the adjacency operator of the Cayley graph ${\\rm Cay}(\\Gamma,S)$ is a disjoint union of $N$ intervals, for arbitrarily large integers $N$.","sentences":["It is shown that there are groups $\\Gamma$ with finite generating sets $S$ such that the adjacency operator of the Cayley graph ${\\rm Cay}(\\Gamma,S)$ is a disjoint union of $N$ intervals, for arbitrarily large integers $N$."],"url":"http://arxiv.org/abs/2402.06279v1","category":"math.CO"}
{"created":"2024-02-09 09:41:26","title":"Controllable seismic velocity synthesis using generative diffusion models","abstract":"Accurate seismic velocity estimations are vital to understanding Earth's subsurface structures, assessing natural resources, and evaluating seismic hazards. Machine learning-based inversion algorithms have shown promising performance in regional (i.e., for exploration) and global velocity estimation, while their effectiveness hinges on access to large and diverse training datasets whose distributions generally cover the target solutions. Additionally, enhancing the precision and reliability of velocity estimation also requires incorporating prior information, e.g., geological classes, well logs, and subsurface structures, but current statistical or neural network-based methods are not flexible enough to handle such multi-modal information. To address both challenges, we propose to use conditional generative diffusion models for seismic velocity synthesis, in which we readily incorporate those priors. This approach enables the generation of seismic velocities that closely match the expected target distribution, offering datasets informed by both expert knowledge and measured data to support training for data-driven geophysical methods. We demonstrate the flexibility and effectiveness of our method through training diffusion models on the OpenFWI dataset under various conditions, including class labels, well logs, reflectivity images, as well as the combination of these priors. The performance of the approach under out-of-distribution conditions further underscores its generalization ability, showcasing its potential to provide tailored priors for velocity inverse problems and create specific training datasets for machine learning-based geophysical applications.","sentences":["Accurate seismic velocity estimations are vital to understanding Earth's subsurface structures, assessing natural resources, and evaluating seismic hazards.","Machine learning-based inversion algorithms have shown promising performance in regional (i.e., for exploration) and global velocity estimation, while their effectiveness hinges on access to large and diverse training datasets whose distributions generally cover the target solutions.","Additionally, enhancing the precision and reliability of velocity estimation also requires incorporating prior information, e.g., geological classes, well logs, and subsurface structures, but current statistical or neural network-based methods are not flexible enough to handle such multi-modal information.","To address both challenges, we propose to use conditional generative diffusion models for seismic velocity synthesis, in which we readily incorporate those priors.","This approach enables the generation of seismic velocities that closely match the expected target distribution, offering datasets informed by both expert knowledge and measured data to support training for data-driven geophysical methods.","We demonstrate the flexibility and effectiveness of our method through training diffusion models on the OpenFWI dataset under various conditions, including class labels, well logs, reflectivity images, as well as the combination of these priors.","The performance of the approach under out-of-distribution conditions further underscores its generalization ability, showcasing its potential to provide tailored priors for velocity inverse problems and create specific training datasets for machine learning-based geophysical applications."],"url":"http://arxiv.org/abs/2402.06277v1","category":"physics.geo-ph"}
{"created":"2024-02-09 09:40:33","title":"Safe Active Learning for Time-Series Modeling with Gaussian Processes","abstract":"Learning time-series models is useful for many applications, such as simulation and forecasting. In this study, we consider the problem of actively learning time-series models while taking given safety constraints into account. For time-series modeling we employ a Gaussian process with a nonlinear exogenous input structure. The proposed approach generates data appropriate for time series model learning, i.e. input and output trajectories, by dynamically exploring the input space. The approach parametrizes the input trajectory as consecutive trajectory sections, which are determined stepwise given safety requirements and past observations. We analyze the proposed algorithm and evaluate it empirically on a technical application. The results show the effectiveness of our approach in a realistic technical use case.","sentences":["Learning time-series models is useful for many applications, such as simulation and forecasting.","In this study, we consider the problem of actively learning time-series models while taking given safety constraints into account.","For time-series modeling we employ a Gaussian process with a nonlinear exogenous input structure.","The proposed approach generates data appropriate for time series model learning, i.e. input and output trajectories, by dynamically exploring the input space.","The approach parametrizes the input trajectory as consecutive trajectory sections, which are determined stepwise given safety requirements and past observations.","We analyze the proposed algorithm and evaluate it empirically on a technical application.","The results show the effectiveness of our approach in a realistic technical use case."],"url":"http://arxiv.org/abs/2402.06276v1","category":"cs.LG"}
{"created":"2024-02-09 09:39:34","title":"Characterization and examples of commutative isoartinian rings","abstract":"Noetherian rings have played a fundamental role in commutative algebra, algebraic number theory, and algebraic geometry. Along with their dual, Artinian rings, they have many generalizations, including the notions of isonoetherian and isoartinian rings. In this paper, we prove that the Krull dimension of every isoartinian ring is at most one. We then use this result to provide a characterization of isoartinian rings. Specifically, we prove that a ring $R$ is isoartinian if and only if $R$ is uniquely isomorphic to the direct product of a finite number of rings of the following types: (i) Artinian local rings; (ii) non-Noetherian isoartinian local rings with a nilpotent maximal ideal; (iii) non-field principal ideal domains; (iv) Noetherian isoartinian rings $A$ with $\\Min A$ being a singleton and $\\Min A \\subsetneq \\Ass A$; (v) non-Noetherian isoartinian rings $A$ with $\\Min A$ being a singleton and $\\Min A \\subsetneq \\Ass A$; (vi) non-Noetherian isoartinian rings $A$ with a unique element in $\\Min A$ that is not maximal, and $\\Min A=\\Ass A$. Several examples of these types of rings are also provided.","sentences":["Noetherian rings have played a fundamental role in commutative algebra, algebraic number theory, and algebraic geometry.","Along with their dual, Artinian rings, they have many generalizations, including the notions of isonoetherian and isoartinian rings.","In this paper, we prove that the Krull dimension of every isoartinian ring is at most one.","We then use this result to provide a characterization of isoartinian rings.","Specifically, we prove that a ring $R$ is isoartinian if and only if $R$ is uniquely isomorphic to the direct product of a finite number of rings of the following types: (i) Artinian local rings; (ii) non-Noetherian isoartinian local rings with a nilpotent maximal ideal; (iii) non-field principal ideal domains; (iv) Noetherian isoartinian rings $A$ with $\\Min A$ being a singleton and $\\Min A \\subsetneq \\Ass A$; (v) non-Noetherian isoartinian rings $A$ with $\\Min A$ being a singleton and $\\Min A \\subsetneq \\Ass A$; (vi) non-Noetherian isoartinian rings $A$ with a unique element in $\\Min A$ that is not maximal, and $\\Min A=\\Ass A$.","Several examples of these types of rings are also provided."],"url":"http://arxiv.org/abs/2402.06273v1","category":"math.AC"}
{"created":"2024-02-09 09:28:01","title":"Value function interference and greedy action selection in value-based multi-objective reinforcement learning","abstract":"Multi-objective reinforcement learning (MORL) algorithms extend conventional reinforcement learning (RL) to the more general case of problems with multiple, conflicting objectives, represented by vector-valued rewards. Widely-used scalar RL methods such as Q-learning can be modified to handle multiple objectives by (1) learning vector-valued value functions, and (2) performing action selection using a scalarisation or ordering operator which reflects the user's utility with respect to the different objectives. However, as we demonstrate here, if the user's utility function maps widely varying vector-values to similar levels of utility, this can lead to interference in the value-function learned by the agent, leading to convergence to sub-optimal policies. This will be most prevalent in stochastic environments when optimising for the Expected Scalarised Return criterion, but we present a simple example showing that interference can also arise in deterministic environments. We demonstrate empirically that avoiding the use of random tie-breaking when identifying greedy actions can ameliorate, but not fully overcome, the problems caused by value function interference.","sentences":["Multi-objective reinforcement learning (MORL) algorithms extend conventional reinforcement learning (RL) to the more general case of problems with multiple, conflicting objectives, represented by vector-valued rewards.","Widely-used scalar RL methods such as Q-learning can be modified to handle multiple objectives by (1) learning vector-valued value functions, and (2) performing action selection using a scalarisation or ordering operator which reflects the user's utility with respect to the different objectives.","However, as we demonstrate here, if the user's utility function maps widely varying vector-values to similar levels of utility, this can lead to interference in the value-function learned by the agent, leading to convergence to sub-optimal policies.","This will be most prevalent in stochastic environments when optimising for the Expected Scalarised Return criterion, but we present a simple example showing that interference can also arise in deterministic environments.","We demonstrate empirically that avoiding the use of random tie-breaking when identifying greedy actions can ameliorate, but not fully overcome, the problems caused by value function interference."],"url":"http://arxiv.org/abs/2402.06266v1","category":"cs.LG"}
{"created":"2024-02-09 09:25:18","title":"LLaVA-Docent: Instruction Tuning with Multimodal Large Language Model to Support Art Appreciation Education","abstract":"Art appreciation is vital in nurturing critical thinking and emotional intelligence among learners. However, traditional art appreciation education has often been hindered by limited access to art resources, especially for disadvantaged students, and an imbalanced emphasis on STEM subjects in mainstream education. In response to these challenges, recent technological advancements have paved the way for innovative solutions. This study explores the application of multi-modal large language models (MLLMs) in art appreciation education, focusing on developing LLaVA-Docent, a model that leverages these advancements. Our approach involved a comprehensive literature review and consultations with experts in the field, leading to developing a robust data framework. Utilizing this framework, we generated a virtual dialogue dataset that was leveraged by GPT-4. This dataset was instrumental in training the MLLM, named LLaVA-Docent. Six researchers conducted quantitative and qualitative evaluations of LLaVA-Docent to assess its effectiveness, benchmarking it against the GPT-4 model in a few-shot setting. The evaluation process revealed distinct strengths and weaknesses of the LLaVA-Docent model. Our findings highlight the efficacy of LLaVA-Docent in enhancing the accessibility and engagement of art appreciation education. By harnessing the potential of MLLMs, this study makes a significant contribution to the field of art education, proposing a novel methodology that reimagines the way art appreciation is taught and experienced.","sentences":["Art appreciation is vital in nurturing critical thinking and emotional intelligence among learners.","However, traditional art appreciation education has often been hindered by limited access to art resources, especially for disadvantaged students, and an imbalanced emphasis on STEM subjects in mainstream education.","In response to these challenges, recent technological advancements have paved the way for innovative solutions.","This study explores the application of multi-modal large language models (MLLMs) in art appreciation education, focusing on developing LLaVA-Docent, a model that leverages these advancements.","Our approach involved a comprehensive literature review and consultations with experts in the field, leading to developing a robust data framework.","Utilizing this framework, we generated a virtual dialogue dataset that was leveraged by GPT-4.","This dataset was instrumental in training the MLLM, named LLaVA-Docent.","Six researchers conducted quantitative and qualitative evaluations of LLaVA-Docent to assess its effectiveness, benchmarking it against the GPT-4 model in a few-shot setting.","The evaluation process revealed distinct strengths and weaknesses of the LLaVA-Docent model.","Our findings highlight the efficacy of LLaVA-Docent in enhancing the accessibility and engagement of art appreciation education.","By harnessing the potential of MLLMs, this study makes a significant contribution to the field of art education, proposing a novel methodology that reimagines the way art appreciation is taught and experienced."],"url":"http://arxiv.org/abs/2402.06264v1","category":"cs.AI"}
{"created":"2024-02-09 09:20:59","title":"On the Efficacy of Eviction Policy for Key-Value Constrained Generative Language Model Inference","abstract":"Despite the recent success associated with Large Language Models~(LLMs), they are notably cost-prohibitive to deploy in resource-constrained environments due to their excessive memory and computational demands. In addition to model parameters, the key-value cache is also stored in GPU memory, growing linearly with batch size and sequence length. As a remedy, recent works have proposed various eviction policies for maintaining the overhead of key-value cache under a given budget. This paper embarks on the efficacy of existing eviction policies in terms of \\textit{importance score calculation} and \\textit{eviction scope construction}. We identify the deficiency of prior policies in these two aspects and introduce RoCo, a \\underline{r}\\underline{o}bust \\underline{c}ache \\underline{o}mission policy based on temporal attention scores and robustness measures. Extensive experimentation spanning prefilling and auto-regressive decoding stages validates the superiority of RoCo. Finally, we release EasyKV, a versatile software package dedicated to user-friendly key-value constrained generative inference. Code available at \\url{https://github.com/DRSY/EasyKV}.","sentences":["Despite the recent success associated with Large Language Models~(LLMs), they are notably cost-prohibitive to deploy in resource-constrained environments due to their excessive memory and computational demands.","In addition to model parameters, the key-value cache is also stored in GPU memory, growing linearly with batch size and sequence length.","As a remedy, recent works have proposed various eviction policies for maintaining the overhead of key-value cache under a given budget.","This paper embarks on the efficacy of existing eviction policies in terms of \\textit{importance score calculation} and \\textit{eviction scope construction}.","We identify the deficiency of prior policies in these two aspects and introduce RoCo, a \\underline{r}\\underline{o}bust \\underline{c}ache \\underline{o}mission policy based on temporal attention scores and robustness measures.","Extensive experimentation spanning prefilling and auto-regressive decoding stages validates the superiority of RoCo.","Finally, we release EasyKV, a versatile software package dedicated to user-friendly key-value constrained generative inference.","Code available at \\url{https://github.com/DRSY/EasyKV}."],"url":"http://arxiv.org/abs/2402.06262v1","category":"cs.CL"}
{"created":"2024-02-09 09:17:19","title":"Vertex-minor universal graphs for generating entangled quantum subsystems","abstract":"We study the notion of $k$-stabilizer universal quantum state, that is, an $n$-qubit quantum state, such that it is possible to induce any stabilizer state on any $k$ qubits, by using only local operations and classical communications. These states generalize the notion of $k$-pairable states introduced by Bravyi et al., and can be studied from a combinatorial perspective using graph states and $k$-vertex-minor universal graphs. First, we demonstrate the existence of $k$-stabilizer universal graph states that are optimal in size with $n=\\Theta(k^2)$ qubits. We also provide parameters for which a random graph state on $\\Theta(k^2)$ qubits is $k$-stabilizer universal with high probability. Our second contribution consists of two explicit constructions of $k$-stabilizer universal graph states on $n = O(k^4)$ qubits. Both rely upon the incidence graph of the projective plane over a finite field $\\mathbb{F}_q$. This provides a major improvement over the previously known explicit construction of $k$-pairable graph states with $n = O(2^{3k})$, bringing forth a new and potentially powerful family of multipartite quantum resources.","sentences":["We study the notion of $k$-stabilizer universal quantum state, that is, an $n$-qubit quantum state, such that it is possible to induce any stabilizer state on any $k$ qubits, by using only local operations and classical communications.","These states generalize the notion of $k$-pairable states introduced by Bravyi et al., and can be studied from a combinatorial perspective using graph states and $k$-vertex-minor universal graphs.","First, we demonstrate the existence of $k$-stabilizer universal graph states that are optimal in size with $n=\\Theta(k^2)$ qubits.","We also provide parameters for which a random graph state on $\\Theta(k^2)$ qubits is $k$-stabilizer universal with high probability.","Our second contribution consists of two explicit constructions of $k$-stabilizer universal graph states on $n = O(k^4)$ qubits.","Both rely upon the incidence graph of the projective plane over a finite field $\\mathbb{F}_q$.","This provides a major improvement over the previously known explicit construction of $k$-pairable graph states with $n = O(2^{3k})$, bringing forth a new and potentially powerful family of multipartite quantum resources."],"url":"http://arxiv.org/abs/2402.06260v1","category":"quant-ph"}
{"created":"2024-02-09 09:16:53","title":"Diameter Reduction Via Flipping Arcs","abstract":"The diameter of a directed graph is a fundamental parameter defined as the maximum distance realized among the pairs of vertices. As graphs of small diameter are of interest in many applications, we study the following problem: for a given directed graph and a positive integer $d$, what is the minimum number of arc flips (also known as arc reversal) required to obtain a graph with diameter at most $d$? It is a generalization of the well-known problem \\textsc{Oriented Diameter}, first studied by Chv\\'atal and Thomassen. Here we investigate variants of the above problem, considering the number of flips and the target diameter as parameters. We prove that most of the related questions of this type are hard. Special cases of graphs are also considered, as planar and cactus graphs, where we give polynomial time algorithms.","sentences":["The diameter of a directed graph is a fundamental parameter defined as the maximum distance realized among the pairs of vertices.","As graphs of small diameter are of interest in many applications, we study the following problem: for a given directed graph and a positive integer $d$, what is the minimum number of arc flips (also known as arc reversal) required to obtain a graph with diameter at most $d$?","It is a generalization of the well-known problem \\textsc{Oriented Diameter}, first studied by Chv\\'atal and Thomassen.","Here we investigate variants of the above problem, considering the number of flips and the target diameter as parameters.","We prove that most of the related questions of this type are hard.","Special cases of graphs are also considered, as planar and cactus graphs, where we give polynomial time algorithms."],"url":"http://arxiv.org/abs/2402.06259v1","category":"math.CO"}
{"created":"2024-02-09 09:14:13","title":"Intermediate inflation in generalized non-minimal derivative coupling model","abstract":"In this work we consider intermediate inflation in context of the Generalized Non-Minimal Derivative Coupling (GNMDC) model. In this model, inflation is driven by a canonical scalar field, which is coupled not only to gravity but also to the derivative of the scalar field. GNMDC introduces new dynamics and features during the inflationary epoch. We find inflationary solutions with the power law scalar field for the power law coupling function and we find the inflaton potential that generate intermediate expansion of the scale factor. Also, we discuss background equations in the high friction limit and we obtain constraints on the parameters of our model. Furthermore, we investigate the cosmological perturbations in the slow roll approximation within the GNMDC model, and we compute the scalar and tensor spectral index and tensor-to-scalar ratio in the intermediate inflation. We also compare results of this model with the observational signatures that can be used to test this model in the cosmic microwave background radiation. Overall, we draw condition for inflaton potential that accelerated expansion continue during the slow roll inflation. Numerically we consider power spectrum and spectral index for scaler and tensor modes in intermediate inflation in the high friction limit. Moreover, based on Planck 2018 data, we find constraints on the parameters of the model. We show that intermediate inflation in GNMDC is successful in evaluation and explanation of the background and perturbational quantities of observational cosmology.","sentences":["In this work we consider intermediate inflation in context of the Generalized Non-Minimal Derivative Coupling (GNMDC) model.","In this model, inflation is driven by a canonical scalar field, which is coupled not only to gravity but also to the derivative of the scalar field.","GNMDC introduces new dynamics and features during the inflationary epoch.","We find inflationary solutions with the power law scalar field for the power law coupling function and we find the inflaton potential that generate intermediate expansion of the scale factor.","Also, we discuss background equations in the high friction limit and we obtain constraints on the parameters of our model.","Furthermore, we investigate the cosmological perturbations in the slow roll approximation within the GNMDC model, and we compute the scalar and tensor spectral index and tensor-to-scalar ratio in the intermediate inflation.","We also compare results of this model with the observational signatures that can be used to test this model in the cosmic microwave background radiation.","Overall, we draw condition for inflaton potential that accelerated expansion continue during the slow roll inflation.","Numerically we consider power spectrum and spectral index for scaler and tensor modes in intermediate inflation in the high friction limit.","Moreover, based on Planck 2018 data, we find constraints on the parameters of the model.","We show that intermediate inflation in GNMDC is successful in evaluation and explanation of the background and perturbational quantities of observational cosmology."],"url":"http://arxiv.org/abs/2402.06257v1","category":"hep-th"}
{"created":"2024-02-09 09:09:39","title":"Studious Bob Fight Back Against Jailbreaking via Prompt Adversarial Tuning","abstract":"Although Large Language Models (LLMs) have achieved tremendous success in various applications, they are also susceptible to certain prompts that can induce them to bypass built-in safety measures and provide dangerous or illegal content, a phenomenon known as jailbreak. To protect LLMs from producing harmful information, various defense strategies are proposed, with most focusing on content filtering or adversarial training of models. In this paper, we propose an approach named Prompt Adversarial Tuning (PAT) to train a defense control mechanism, which is then embedded as a prefix to user prompts to implement our defense strategy. We design a training process similar to adversarial training to achieve our optimized goal, alternating between updating attack and defense controls. To our knowledge, we are the first to implement defense from the perspective of prompt tuning. Once employed, our method will hardly impact the operational efficiency of LLMs. Experiments show that our method is effective in both black-box and white-box settings, reducing the success rate of advanced attacks to nearly 0 while maintaining the benign answer rate of 80% to simple benign questions. Our work might potentially chart a new perspective for future explorations in LLM security.","sentences":["Although Large Language Models (LLMs) have achieved tremendous success in various applications, they are also susceptible to certain prompts that can induce them to bypass built-in safety measures and provide dangerous or illegal content, a phenomenon known as jailbreak.","To protect LLMs from producing harmful information, various defense strategies are proposed, with most focusing on content filtering or adversarial training of models.","In this paper, we propose an approach named Prompt Adversarial Tuning (PAT) to train a defense control mechanism, which is then embedded as a prefix to user prompts to implement our defense strategy.","We design a training process similar to adversarial training to achieve our optimized goal, alternating between updating attack and defense controls.","To our knowledge, we are the first to implement defense from the perspective of prompt tuning.","Once employed, our method will hardly impact the operational efficiency of LLMs.","Experiments show that our method is effective in both black-box and white-box settings, reducing the success rate of advanced attacks to nearly 0 while maintaining the benign answer rate of 80% to simple benign questions.","Our work might potentially chart a new perspective for future explorations in LLM security."],"url":"http://arxiv.org/abs/2402.06255v1","category":"cs.LG"}
{"created":"2024-02-09 09:04:10","title":"Mizuno's rank three Nahm sums I: identities of index $(1,1,2)$","abstract":"Mizuno provided 19 examples of generalized rank three Nahm sums with symmetrizer $\\mathrm{diag}(1,1,2)$ which are conjecturally modular. We confirm their modularity by establishing Rogers--Ramanujan type identities of index $(1,1,2)$ for these examples. We first reduce these Nahm sums to some double sums or single sums, and then we use known results or apply the theory of Bailey pairs to prove the desired identities. Meanwhile, we generalize some triple sum identities to general multi-sum identities.","sentences":["Mizuno provided 19 examples of generalized rank three Nahm sums with symmetrizer $\\mathrm{diag}(1,1,2)$ which are conjecturally modular.","We confirm their modularity by establishing Rogers--Ramanujan type identities of index $(1,1,2)$ for these examples.","We first reduce these Nahm sums to some double sums or single sums, and then we use known results or apply the theory of Bailey pairs to prove the desired identities.","Meanwhile, we generalize some triple sum identities to general multi-sum identities."],"url":"http://arxiv.org/abs/2402.06253v1","category":"math.NT"}
{"created":"2024-02-09 08:40:41","title":"Delving into Parameter-Efficient Fine-Tuning in Code Change Learning: An Empirical Study","abstract":"Compared to Full-Model Fine-Tuning (FMFT), Parameter Efficient Fine-Tuning (PEFT) has demonstrated superior performance and lower computational overhead in several code understanding tasks, such as code summarization and code search. This advantage can be attributed to PEFT's ability to alleviate the catastrophic forgetting issue of Pre-trained Language Models (PLMs) by updating only a small number of parameters. As a result, PEFT effectively harnesses the pre-trained general-purpose knowledge for downstream tasks. However, existing studies primarily involve static code comprehension, aligning with the pre-training paradigm of recent PLMs and facilitating knowledge transfer, but they do not account for dynamic code changes. Thus, it remains unclear whether PEFT outperforms FMFT in task-specific adaptation for code-change-related tasks. To address this question, we examine two prevalent PEFT methods, namely Adapter Tuning (AT) and Low-Rank Adaptation (LoRA), and compare their performance with FMFT on five popular PLMs. Specifically, we evaluate their performance on two widely-studied code-change-related tasks: Just-In-Time Defect Prediction (JIT-DP) and Commit Message Generation (CMG). The results demonstrate that both AT and LoRA achieve state-of-the-art (SOTA) results in JIT-DP and exhibit comparable performances in CMG when compared to FMFT and other SOTA approaches. Furthermore, AT and LoRA exhibit superiority in cross-lingual and low-resource scenarios. We also conduct three probing tasks to explain the efficacy of PEFT techniques on JIT-DP and CMG tasks from both static and dynamic perspectives. The study indicates that PEFT, particularly through the use of AT and LoRA, offers promising advantages in code-change-related tasks, surpassing FMFT in certain aspects.","sentences":["Compared to Full-Model Fine-Tuning (FMFT), Parameter Efficient Fine-Tuning (PEFT) has demonstrated superior performance and lower computational overhead in several code understanding tasks, such as code summarization and code search.","This advantage can be attributed to PEFT's ability to alleviate the catastrophic forgetting issue of Pre-trained Language Models (PLMs) by updating only a small number of parameters.","As a result, PEFT effectively harnesses the pre-trained general-purpose knowledge for downstream tasks.","However, existing studies primarily involve static code comprehension, aligning with the pre-training paradigm of recent PLMs and facilitating knowledge transfer, but they do not account for dynamic code changes.","Thus, it remains unclear whether PEFT outperforms FMFT in task-specific adaptation for code-change-related tasks.","To address this question, we examine two prevalent PEFT methods, namely Adapter Tuning (AT) and Low-Rank Adaptation (LoRA), and compare their performance with FMFT on five popular PLMs.","Specifically, we evaluate their performance on two widely-studied code-change-related tasks: Just-In-Time Defect Prediction (JIT-DP) and Commit Message Generation (CMG).","The results demonstrate that both AT and LoRA achieve state-of-the-art (SOTA) results in JIT-DP and exhibit comparable performances in CMG when compared to FMFT and other SOTA approaches.","Furthermore, AT and LoRA exhibit superiority in cross-lingual and low-resource scenarios.","We also conduct three probing tasks to explain the efficacy of PEFT techniques on JIT-DP and CMG tasks from both static and dynamic perspectives.","The study indicates that PEFT, particularly through the use of AT and LoRA, offers promising advantages in code-change-related tasks, surpassing FMFT in certain aspects."],"url":"http://arxiv.org/abs/2402.06247v1","category":"cs.SE"}
{"created":"2024-02-09 08:24:18","title":"Quantum Automorphism Group of Direct Sum of Cuntz Algebras","abstract":"In 1998, Wang constructed an ergodic action of the compact quantum group $U_n^+$ (free unitary quantum group) on the Cuntz algebra $\\mathcal{O}_n$. Later, in 2018-2019, S. Joardar and A. Mandal showed that the quantum automorphism group of the Cuntz algebra $\\mathcal{O}_{n}$ (as a graph $C^*$-algebra) is $U_n^+$ in the category introduced by them. In this article, we explore the quantum symmetry of the direct sum of Cuntz algebras viewing them as a graph $C^*$-algebra in the category as mentioned before. It has been shown that the quantum automorphism group of the direct sum of non-isomorphic Cuntz algebras $\\{\\mathcal{O}_{n_i}\\}_{i=1}^{m}$ is ${U}_{n_1}^{+}*{U}_{n_2}^{+}* \\cdots *{U}_{n_m}^{+}$ for distinct $n_i$'s, i.e. if $ L_{n_i}$ (the graph contains $n_i$ loops based at a single vertex) is the underlying graph of $\\mathcal{O}_{n_i}$, then   \\begin{equation*}   Q_{\\tau}^{Lin}(\\sqcup_{i=1}^{m} ~ L_{n_i}) \\cong *_{i=1}^{m} ~~ Q_{\\tau}^{Lin}(L_{n_i}) \\cong {U}_{n_1}^{+}*{U}_{n_2}^{+}* \\cdots *{U}_{n_m}^{+}.   \\end{equation*}   Moreover, the quantum symmetry of the direct sum of $m$ copies of isomorphic Cuntz algebra $\\mathcal{O}_n$ (whose underlying graph is $L_n$) is $U_n^+ \\wr_* S_m^+,$ i.e.   \\begin{equation*}   Q_{\\tau}^{Lin}(\\sqcup_{i=1}^{m} ~ L_n) \\cong Q_{\\tau}^{Lin}(L_n) \\wr_* S_m^+ \\cong U_n^+ \\wr_* S_m^+.   \\end{equation*}   On the other hand, it is known that the quantum automorphism group of $m$ disjoint copies of a simple, connected graph $\\Gamma$ is isomorphic to the free wreath product of the quantum automorphism group of $\\Gamma$ with $S_m^+$. Though an analoguous result is true for $\\mathcal{O}_{n}$ (as a graph $C^*$-algebra), we have provided a counter-example to show that this result is not in general true for an arbitrary graph $C^*$-algebra.","sentences":["In 1998, Wang constructed an ergodic action of the compact quantum group $U_n^+$ (free unitary quantum group) on the Cuntz algebra $\\mathcal{O}_n$. Later, in 2018-2019, S. Joardar and A. Mandal showed that the quantum automorphism group of the Cuntz algebra $\\mathcal{O}_{n}$ (as a graph $C^*$-algebra) is $U_n^+$ in the category introduced by them.","In this article, we explore the quantum symmetry of the direct sum of Cuntz algebras viewing them as a graph $C^*$-algebra in the category as mentioned before.","It has been shown that the quantum automorphism group of the direct sum of non-isomorphic Cuntz algebras $\\{\\mathcal{O}_{n_i}\\}_{i=1}^{m}$ is ${U}_{n_1}^{+}*{U}_{n_2}^{+}* \\cdots *{U}_{n_m}^{+}$ for distinct $n_i$'s, i.e. if $ L_{n_i}$ (the graph contains $n_i$ loops based at a single vertex) is the underlying graph of $\\mathcal{O}_{n_i}$, then   \\begin{equation*}   Q_{\\tau}^{Lin}(\\sqcup_{i=1}^{m} ~ L_{n_i})","\\cong *_{i=1}^{m} ~~","Q_{\\tau}^{Lin}(L_{n_i})","\\cong {U}_{n_1}^{+}*{U}_{n_2}^{+}* \\cdots *{U}_{n_m}^{+}.   ","\\end{equation*}   Moreover, the quantum symmetry of the direct sum of $m$ copies of isomorphic Cuntz algebra $\\mathcal{O}_n$ (whose underlying graph is $L_n$) is $U_n^+ \\wr_* S_m^+,$ i.e.   \\begin{equation*}   Q_{\\tau}^{Lin}(\\sqcup_{i=1}^{m} ~ L_n) \\cong Q_{\\tau}^{Lin}(L_n) \\wr_*","S_m^+ \\cong U_n^+ \\wr_*","S_m^+.   ","\\end{equation*}   On the other hand, it is known that the quantum automorphism group of $m$ disjoint copies of a simple, connected graph $\\Gamma$ is isomorphic to the free wreath product of the quantum automorphism group of $\\Gamma$ with $S_m^+$. Though an analoguous result is true for $\\mathcal{O}_{n}$ (as a graph $C^*$-algebra), we have provided a counter-example to show that this result is not in general true for an arbitrary graph $C^*$-algebra."],"url":"http://arxiv.org/abs/2402.06241v1","category":"math.OA"}
{"created":"2024-02-09 18:56:21","title":"Taut smoothings of arcs and curves","abstract":"We study the geometric and combinatorial effect of smoothing an intersection point on a collection of curves or arcs on a surface, make progress towards answering the question of whether every taut curve has a taut smoothing, and answer the analogous question in full for taut arcs with fixed endpoints and for taut multi-curves and multi-arcs with at least two non-disjoint components. We deduce that for every Riemannian metric on a surface, the shortest properly immersed arcs with at least $k$ self-intersections have exactly $k$ self-intersections, and prove a partial monotonicity result for the marked length spectrum of curves on orientable surfaces.","sentences":["We study the geometric and combinatorial effect of smoothing an intersection point on a collection of curves or arcs on a surface, make progress towards answering the question of whether every taut curve has a taut smoothing, and answer the analogous question in full for taut arcs with fixed endpoints and for taut multi-curves and multi-arcs with at least two non-disjoint components.","We deduce that for every Riemannian metric on a surface, the shortest properly immersed arcs with at least $k$ self-intersections have exactly $k$ self-intersections, and prove a partial monotonicity result for the marked length spectrum of curves on orientable surfaces."],"url":"http://arxiv.org/abs/2402.06623v1","category":"math.GT"}
{"created":"2024-02-09 18:05:22","title":"Irreversible Monte Carlo algorithms for hard disk glasses: from event-chain to collective swaps","abstract":"Equilibrium sampling of the configuration space in disordered systems requires algorithms that bypass the glassy slowing down of the physical dynamics. Irreversible Monte Carlo algorithms breaking detailed balance successfully accelerate sampling in some systems. We first implement an irreversible event-chain Monte Carlo algorithm in a model of polydisperse hard disks. The effect of collective translational moves marginally affects the dynamics and results in a modest speedup that decreases with density. We then propose an irreversible algorithm performing collective particle swaps which outperforms all known Monte Carlo algorithms. We show that these collective swaps can also be used to prepare very dense jammed packings of disks.","sentences":["Equilibrium sampling of the configuration space in disordered systems requires algorithms that bypass the glassy slowing down of the physical dynamics.","Irreversible Monte Carlo algorithms breaking detailed balance successfully accelerate sampling in some systems.","We first implement an irreversible event-chain Monte Carlo algorithm in a model of polydisperse hard disks.","The effect of collective translational moves marginally affects the dynamics and results in a modest speedup that decreases with density.","We then propose an irreversible algorithm performing collective particle swaps which outperforms all known Monte Carlo algorithms.","We show that these collective swaps can also be used to prepare very dense jammed packings of disks."],"url":"http://arxiv.org/abs/2402.06585v1","category":"cond-mat.dis-nn"}
{"created":"2024-02-09 18:03:26","title":"Crossover From Individual to Collective Magnetism in Dense Nanoparticle Systems: Local Anisotropy Versus Dipolar Interactions","abstract":"Dense systems of magnetic nanoparticles may exhibit dipolar collective behavior. However, two fundamental questions remain unsolved: i) whether the transition temperature may be affected by the particle anisotropy or it is essentially determined by the intensity of the interparticle dipolar interactions, and ii) what is the minimum ratio of dipole-dipole interaction ($E_\\text{dd}$) to nanoparticle anisotropy ($K_{\\text{ef}}V$, anisotropy $\\times$ volume) energies necessary to crossover from individual to collective behavior. A series of particle assemblies with similarly intense dipolar interactions but widely varying anisotropy is studied. The $K_\\text{ef}$ is tuned through different degrees of cobalt-doping in maghemite nanoparticles, resulting in a variation of nearly an order of magnitude. All the bare particle compacts display collective behavior, except the one made with the highest anisotropy particles, which presents ``marginal'' features. Thus, a threshold of $K_{\\text{ef}} V/E_{\\text{dd}} \\approx 130$ to suppress collective behavior is derived, in good agreement with Monte Carlo simulations. This translates into a crossover value of $\\approx 1.7$ for the easily accessible parameter $T_\\text{MAX}$(interacting)$/T_\\text{MAX}$(non-interacting) (ratio of the peak temperatures of the zero-field-cooled magnetization curves of interacting and dilute particle systems), which is successfully tested against the literature to predict the individual-like$/$collective behavior of any given interacting particle assembly comprising relatively uniform particles.","sentences":["Dense systems of magnetic nanoparticles may exhibit dipolar collective behavior.","However, two fundamental questions remain unsolved: i) whether the transition temperature may be affected by the particle anisotropy or it is essentially determined by the intensity of the interparticle dipolar interactions, and ii) what is the minimum ratio of dipole-dipole interaction ($E_\\text{dd}$) to nanoparticle anisotropy ($K_{\\text{ef}}V$, anisotropy $\\times$ volume) energies necessary to crossover from individual to collective behavior.","A series of particle assemblies with similarly intense dipolar interactions but widely varying anisotropy is studied.","The $K_\\text{ef}$ is tuned through different degrees of cobalt-doping in maghemite nanoparticles, resulting in a variation of nearly an order of magnitude.","All the bare particle compacts display collective behavior, except the one made with the highest anisotropy particles, which presents ``marginal'' features.","Thus, a threshold of $K_{\\text{ef}} V/E_{\\text{dd}} \\approx 130$ to suppress collective behavior is derived, in good agreement with Monte Carlo simulations.","This translates into a crossover value of $\\approx 1.7$ for the easily accessible parameter $T_\\text{MAX}$(interacting)$/T_\\text{MAX}$(non-interacting) (ratio of the peak temperatures of the zero-field-cooled magnetization curves of interacting and dilute particle systems), which is successfully tested against the literature to predict the individual-like$/$collective behavior of any given interacting particle assembly comprising relatively uniform particles."],"url":"http://arxiv.org/abs/2402.06583v1","category":"cond-mat.mes-hall"}
{"created":"2024-02-09 17:19:05","title":"Video Annotator: A framework for efficiently building video classifiers using vision-language models and active learning","abstract":"High-quality and consistent annotations are fundamental to the successful development of robust machine learning models. Traditional data annotation methods are resource-intensive and inefficient, often leading to a reliance on third-party annotators who are not the domain experts. Hard samples, which are usually the most informative for model training, tend to be difficult to label accurately and consistently without business context. These can arise unpredictably during the annotation process, requiring a variable number of iterations and rounds of feedback, leading to unforeseen expenses and time commitments to guarantee quality.   We posit that more direct involvement of domain experts, using a human-in-the-loop system, can resolve many of these practical challenges. We propose a novel framework we call Video Annotator (VA) for annotating, managing, and iterating on video classification datasets. Our approach offers a new paradigm for an end-user-centered model development process, enhancing the efficiency, usability, and effectiveness of video classifiers. Uniquely, VA allows for a continuous annotation process, seamlessly integrating data collection and model training.   We leverage the zero-shot capabilities of vision-language foundation models combined with active learning techniques, and demonstrate that VA enables the efficient creation of high-quality models. VA achieves a median 6.8 point improvement in Average Precision relative to the most competitive baseline across a wide-ranging assortment of tasks. We release a dataset with 153k labels across 56 video understanding tasks annotated by three professional video editors using VA, and also release code to replicate our experiments at: http://github.com/netflix/videoannotator.","sentences":["High-quality and consistent annotations are fundamental to the successful development of robust machine learning models.","Traditional data annotation methods are resource-intensive and inefficient, often leading to a reliance on third-party annotators who are not the domain experts.","Hard samples, which are usually the most informative for model training, tend to be difficult to label accurately and consistently without business context.","These can arise unpredictably during the annotation process, requiring a variable number of iterations and rounds of feedback, leading to unforeseen expenses and time commitments to guarantee quality.   ","We posit that more direct involvement of domain experts, using a human-in-the-loop system, can resolve many of these practical challenges.","We propose a novel framework we call Video Annotator (VA) for annotating, managing, and iterating on video classification datasets.","Our approach offers a new paradigm for an end-user-centered model development process, enhancing the efficiency, usability, and effectiveness of video classifiers.","Uniquely, VA allows for a continuous annotation process, seamlessly integrating data collection and model training.   ","We leverage the zero-shot capabilities of vision-language foundation models combined with active learning techniques, and demonstrate that VA enables the efficient creation of high-quality models.","VA achieves a median 6.8 point improvement in Average Precision relative to the most competitive baseline across a wide-ranging assortment of tasks.","We release a dataset with 153k labels across 56 video understanding tasks annotated by three professional video editors using VA, and also release code to replicate our experiments at: http://github.com/netflix/videoannotator."],"url":"http://arxiv.org/abs/2402.06560v1","category":"cs.CV"}
{"created":"2024-02-09 17:01:22","title":"Axion Star Explosions and the Reionization History of the Universe","abstract":"Cosmological structure formation simulations of ultralight axion-like dark matter have shown that an axion star forms at the center of every dark matter halo in the Universe. These axion stars would then form in large numbers during the dark ages, $z \\lesssim 70$. Axion stars would represent the densest axion environments in the Universe, and as such they can trigger collective processes that cannot otherwise occur for axions in vacuum. In particular, even though the lifetime of individual sub-eV axions decaying into a pair of photons is much larger than the age of the Universe, axion stars can decay into photons on very short time scales due to parametric resonance. In this talk, based on arXiv:2302.10206 and arXiv:2301.09769, I will discuss the cosmological implications of such decays. We show that massive enough axion stars will decay into a large number of radio photons which will in turn lead to heating and ionization during the dark ages which is strongly constrained by Planck. As a result, we find that couplings $10^{-14}\\,{\\rm GeV}^{-1} \\lesssim g_{a\\gamma\\gamma} \\lesssim 10^{-10}\\,{\\rm GeV}^{-1}$ are excluded by Planck for $10^{-14}\\,{\\rm eV}\\lesssim m_a\\lesssim 10^{-8}\\,{\\rm eV}$ within our benchmark model of axion star abundance. We also highlight that future measurements of the 21 cm line can have sensitivity to couplings at least one order of magnitude smaller.","sentences":["Cosmological structure formation simulations of ultralight axion-like dark matter have shown that an axion star forms at the center of every dark matter halo in the Universe.","These axion stars would then form in large numbers during the dark ages, $z \\lesssim 70$. Axion stars would represent the densest axion environments in the Universe, and as such they can trigger collective processes that cannot otherwise occur for axions in vacuum.","In particular, even though the lifetime of individual sub-eV axions decaying into a pair of photons is much larger than the age of the Universe, axion stars can decay into photons on very short time scales due to parametric resonance.","In this talk, based on arXiv:2302.10206 and arXiv:2301.09769, I will discuss the cosmological implications of such decays.","We show that massive enough axion stars will decay into a large number of radio photons which will in turn lead to heating and ionization during the dark ages which is strongly constrained by Planck.","As a result, we find that couplings $10^{-14}\\,{\\rm GeV}^{-1} \\lesssim g_{a\\gamma\\gamma} \\lesssim 10^{-10}\\,{\\rm GeV}^{-1}$ are excluded by Planck for $10^{-14}\\,{\\rm eV}\\lesssim m_a\\lesssim 10^{-8}\\,{\\rm eV}$ within our benchmark model of axion star abundance.","We also highlight that future measurements of the 21 cm line can have sensitivity to couplings at least one order of magnitude smaller."],"url":"http://arxiv.org/abs/2402.06547v1","category":"hep-ph"}
{"created":"2024-02-09 16:19:58","title":"Long-lived collective Rydberg excitations in atomic gas achieved via ac-Stark lattice modulation","abstract":"Collective Rydberg excitations provide promising applications ranging from quantum information processing, and quantum computing to ultra-sensitive electrometry. However, their short lifetime is an immense obstacle in real-life scenarios. The state-of-the-art methods of prolonging the lifetime were only implemented for ground-state quantum memories and would require a redesign to effectively work on different atomic transitions. We propose a protocol for extending the Rydberg excitation lifetime, which in principle can freeze the spin-wave and completely cancel the effects of thermal dephasing. The protocol employs off-resonant ac-Stark lattice modulation of spin waves by interfering two laser beams on the atomic medium. Our implementation showed that the excitation lifetime can be extended by an order of magnitude, paving the way towards more complex protocols for collective Rydberg excitations.","sentences":["Collective Rydberg excitations provide promising applications ranging from quantum information processing, and quantum computing to ultra-sensitive electrometry.","However, their short lifetime is an immense obstacle in real-life scenarios.","The state-of-the-art methods of prolonging the lifetime were only implemented for ground-state quantum memories and would require a redesign to effectively work on different atomic transitions.","We propose a protocol for extending the Rydberg excitation lifetime, which in principle can freeze the spin-wave and completely cancel the effects of thermal dephasing.","The protocol employs off-resonant ac-Stark lattice modulation of spin waves by interfering two laser beams on the atomic medium.","Our implementation showed that the excitation lifetime can be extended by an order of magnitude, paving the way towards more complex protocols for collective Rydberg excitations."],"url":"http://arxiv.org/abs/2402.06513v1","category":"quant-ph"}
{"created":"2024-02-09 16:17:31","title":"Toward Building a Semantic Network Inventory for Model-Driven Telemetry","abstract":"Network telemetry based on data models is expected to become the standard mechanism for collecting operational data from network devices efficiently. But the wide variety of standard and proprietary data models along with the different implementations of telemetry protocols offered by network vendors, become a barrier when monitoring heterogeneous network infrastructures. To facilitate the integration and sharing of context information related to model-driven telemetry, this work proposes a semantic network inventory that integrates new information models specifically developed to capture context information in a vendor-agnostic fashion using current standards defined for context management. To automate the integration of this context information within the network inventory, a reference architecture is designed. Finally, a prototype of the solution is implemented and validated through a case study that illustrates how the network inventory can ease the operation of model-driven telemetry in multi-vendor networks.","sentences":["Network telemetry based on data models is expected to become the standard mechanism for collecting operational data from network devices efficiently.","But the wide variety of standard and proprietary data models along with the different implementations of telemetry protocols offered by network vendors, become a barrier when monitoring heterogeneous network infrastructures.","To facilitate the integration and sharing of context information related to model-driven telemetry, this work proposes a semantic network inventory that integrates new information models specifically developed to capture context information in a vendor-agnostic fashion using current standards defined for context management.","To automate the integration of this context information within the network inventory, a reference architecture is designed.","Finally, a prototype of the solution is implemented and validated through a case study that illustrates how the network inventory can ease the operation of model-driven telemetry in multi-vendor networks."],"url":"http://arxiv.org/abs/2402.06511v1","category":"cs.NI"}
{"created":"2024-02-09 14:57:47","title":"Competitive and Weighted Evolving Simplicial Complexes","abstract":"A simplex-based network is referred to as a higher-order network, in which describe that the interactions can include more than two nodes. This paper first proposes a competitive evolving model of higher-order networks. We notice the batch effect of low-dim simplices during the growth of such a network. We obtain an analytical expression for the distribution of higher-order degrees by employing the theory of Poisson processes and the mean field method and use computers to simulate higher-order networks of competitions. The established results indicate that the scale-free behavior for the (d-1)-dim simplex with respect to the d-order degree is controlled by the competitiveness factor. As the competitiveness increases, the d-order degree of the (d-1)-dim simplex is bent under the logarithmic coordinates. Second, by considering the weight changes of the neighboring simplices, as triggered by the selected simplex, a new weighted evolving model in higher-order networks is proposed. The results of the competitive evolving model of higher-order networks are used to analyze the weighted evolving model so that obtained are the analytical expressions of the higher-order degree distribution and higher-order strength density function of weighted higher-order networks. The outcomes of the simulation experiments are consistent with the theoretical analysis. Therefore, the weighted network belongs to the collection of competition networks.","sentences":["A simplex-based network is referred to as a higher-order network, in which describe that the interactions can include more than two nodes.","This paper first proposes a competitive evolving model of higher-order networks.","We notice the batch effect of low-dim simplices during the growth of such a network.","We obtain an analytical expression for the distribution of higher-order degrees by employing the theory of Poisson processes and the mean field method and use computers to simulate higher-order networks of competitions.","The established results indicate that the scale-free behavior for the (d-1)-dim simplex with respect to the d-order degree is controlled by the competitiveness factor.","As the competitiveness increases, the d-order degree of the (d-1)-dim simplex is bent under the logarithmic coordinates.","Second, by considering the weight changes of the neighboring simplices, as triggered by the selected simplex, a new weighted evolving model in higher-order networks is proposed.","The results of the competitive evolving model of higher-order networks are used to analyze the weighted evolving model so that obtained are the analytical expressions of the higher-order degree distribution and higher-order strength density function of weighted higher-order networks.","The outcomes of the simulation experiments are consistent with the theoretical analysis.","Therefore, the weighted network belongs to the collection of competition networks."],"url":"http://arxiv.org/abs/2402.06451v1","category":"physics.soc-ph"}
{"created":"2024-02-09 14:30:29","title":"Performance of the ATLAS forward proton Time-of-Flight detector in Run 2","abstract":"We present performance studies of the Time-of-Flight (ToF) subdetector of the ATLAS Forward Proton (AFP) detector at the LHC. Efficiencies and resolutions are measured using high-statistics data samples collected at low and moderate pile-up in 2017, the first year when the detectors were installed on both sides of the interaction region. While low efficiencies are observed, of the order of a few percent, the resolutions of the two ToF detectors measured individually are 21 ps and 28 ps, yielding an expected resolution of the longitudinal position of the interaction, $z_{vtx}$, in the central ATLAS detector of $5.3 \\pm 0.6$ mm. This is in agreement with the observed width of the distribution of the difference between $z_{vtx}$ measured independently by the central ATLAS tracker and by the ToF detector, of $6.0 \\pm 2.0$ mm.","sentences":["We present performance studies of the Time-of-Flight (ToF) subdetector of the ATLAS Forward Proton (AFP) detector at the LHC.","Efficiencies and resolutions are measured using high-statistics data samples collected at low and moderate pile-up in 2017, the first year when the detectors were installed on both sides of the interaction region.","While low efficiencies are observed, of the order of a few percent, the resolutions of the two ToF detectors measured individually are 21 ps and 28 ps, yielding an expected resolution of the longitudinal position of the interaction, $z_{vtx}$, in the central ATLAS detector of $5.3 \\pm 0.6$ mm.","This is in agreement with the observed width of the distribution of the difference between $z_{vtx}$ measured independently by the central ATLAS tracker and by the ToF detector, of $6.0 \\pm 2.0$ mm."],"url":"http://arxiv.org/abs/2402.06438v1","category":"physics.ins-det"}
{"created":"2024-02-09 14:13:30","title":"Determining Strain Components in a Diamond Waveguide from Zero-Field ODMR Spectra of NV$^{-}$ Center Ensembles","abstract":"The negatively charged nitrogen-vacancy (NV${}^-$) center in diamond has shown great potential in nanoscale sensing and quantum information processing due to its rich spin physics. An efficient coupling with light, providing strong luminescence, is crucial for realizing these applications. Laser-written waveguides in diamond promote NV${}^-$ creation and improve their coupling to light but at the same time induce strain in the crystal. The induced strain contributes to light guiding but also affects the energy levels of NV${}^-$ centers. We probe NV${}^-$ spin states experimentally with the commonly used zero-field optically detected magnetic resonance (ODMR). In our waveguides, the ODMR spectra are shifted, split, and consistently asymmetric, which we attribute to the impact of local strain. To understand these features, we model ensemble ODMR signals in the presence of strain. By fitting the model results to the experimentally collected ODMR data we determine the strain tensor components at different positions, thus determining the strain profile across the waveguide. We show that ODMR spectroscopy can be used as a strain imaging tool. The resulting strain within the waveguide is dominated by a compressive axial component transverse to the waveguide structure, with a smaller contribution from vertical and shear strain components.","sentences":["The negatively charged nitrogen-vacancy (NV${}^-$) center in diamond has shown great potential in nanoscale sensing and quantum information processing due to its rich spin physics.","An efficient coupling with light, providing strong luminescence, is crucial for realizing these applications.","Laser-written waveguides in diamond promote NV${}^-$ creation and improve their coupling to light but at the same time induce strain in the crystal.","The induced strain contributes to light guiding but also affects the energy levels of NV${}^-$ centers.","We probe NV${}^-$ spin states experimentally with the commonly used zero-field optically detected magnetic resonance (ODMR).","In our waveguides, the ODMR spectra are shifted, split, and consistently asymmetric, which we attribute to the impact of local strain.","To understand these features, we model ensemble ODMR signals in the presence of strain.","By fitting the model results to the experimentally collected ODMR data we determine the strain tensor components at different positions, thus determining the strain profile across the waveguide.","We show that ODMR spectroscopy can be used as a strain imaging tool.","The resulting strain within the waveguide is dominated by a compressive axial component transverse to the waveguide structure, with a smaller contribution from vertical and shear strain components."],"url":"http://arxiv.org/abs/2402.06422v1","category":"cond-mat.mes-hall"}
{"created":"2024-02-09 14:09:03","title":"What's in People's Digital File Collections?","abstract":"Thoughtfully designing services and rigorously testing software to support personal information management (PIM) requires understanding the relevant collections, but relatively little is known about what people keep in their file collections, especially personal collections. Complementing recent work on the structure of 348 file collections, we examine those collections' contents, how much content is duplicated, and how collections used for personal matters differ from those used for study and work. Though all collections contain many images, some intuitively common file types are surprisingly scarce. Personal collections contain more audio than others, knowledge workers' collections contain more text documents but far fewer folders, and IT collections exhibit unusual traits. Collection duplication is correlated to collections' structural traits, but surprisingly, not to collection age. We discuss our findings in light of prior works and provide implications for various kinds of information research.","sentences":["Thoughtfully designing services and rigorously testing software to support personal information management (PIM) requires understanding the relevant collections, but relatively little is known about what people keep in their file collections, especially personal collections.","Complementing recent work on the structure of 348 file collections, we examine those collections' contents, how much content is duplicated, and how collections used for personal matters differ from those used for study and work.","Though all collections contain many images, some intuitively common file types are surprisingly scarce.","Personal collections contain more audio than others, knowledge workers' collections contain more text documents but far fewer folders, and IT collections exhibit unusual traits.","Collection duplication is correlated to collections' structural traits, but surprisingly, not to collection age.","We discuss our findings in light of prior works and provide implications for various kinds of information research."],"url":"http://arxiv.org/abs/2402.06421v1","category":"cs.HC"}
{"created":"2024-02-09 13:58:33","title":"Improving the Worst-Case Bidirectional Communication Complexity for Nonconvex Distributed Optimization under Function Similarity","abstract":"Effective communication between the server and workers plays a key role in distributed optimization. In this paper, we focus on optimizing the server-to-worker communication, uncovering inefficiencies in prevalent downlink compression approaches. Considering first the pure setup where the uplink communication costs are negligible, we introduce MARINA-P, a novel method for downlink compression, employing a collection of correlated compressors. Theoretical analyses demonstrates that MARINA-P with permutation compressors can achieve a server-to-worker communication complexity improving with the number of workers, thus being provably superior to existing algorithms. We further show that MARINA-P can serve as a starting point for extensions such as methods supporting bidirectional compression. We introduce M3, a method combining MARINA-P with uplink compression and a momentum step, achieving bidirectional compression with provable improvements in total communication complexity as the number of workers increases. Theoretical findings align closely with empirical experiments, underscoring the efficiency of the proposed algorithms.","sentences":["Effective communication between the server and workers plays a key role in distributed optimization.","In this paper, we focus on optimizing the server-to-worker communication, uncovering inefficiencies in prevalent downlink compression approaches.","Considering first the pure setup where the uplink communication costs are negligible, we introduce MARINA-P, a novel method for downlink compression, employing a collection of correlated compressors.","Theoretical analyses demonstrates that MARINA-P with permutation compressors can achieve a server-to-worker communication complexity improving with the number of workers, thus being provably superior to existing algorithms.","We further show that MARINA-P can serve as a starting point for extensions such as methods supporting bidirectional compression.","We introduce M3, a method combining MARINA-P with uplink compression and a momentum step, achieving bidirectional compression with provable improvements in total communication complexity as the number of workers increases.","Theoretical findings align closely with empirical experiments, underscoring the efficiency of the proposed algorithms."],"url":"http://arxiv.org/abs/2402.06412v1","category":"math.OC"}
{"created":"2024-02-09 12:18:15","title":"Unambiguous discrimination of sequences of quantum states","abstract":"We consider the problem of determining the state of an unknown quantum sequence without error. The elements of the given sequence are drawn with equal probability from a known set of linearly independent pure quantum states with the property that their mutual inner products are all real and equal. This problem can be posed as an instance of unambiguous state discrimination where the states correspond to that of all possible sequences having the same length as the given one. We calculate the optimum probability by solving the optimality conditions of a semidefinite program. The optimum value is achievable by measuring individual members of the sequence, and no collective measurement is necessary.","sentences":["We consider the problem of determining the state of an unknown quantum sequence without error.","The elements of the given sequence are drawn with equal probability from a known set of linearly independent pure quantum states with the property that their mutual inner products are all real and equal.","This problem can be posed as an instance of unambiguous state discrimination where the states correspond to that of all possible sequences having the same length as the given one.","We calculate the optimum probability by solving the optimality conditions of a semidefinite program.","The optimum value is achievable by measuring individual members of the sequence, and no collective measurement is necessary."],"url":"http://arxiv.org/abs/2402.06365v1","category":"quant-ph"}
{"created":"2024-02-09 10:57:11","title":"The $ppp$ correlation function with a screened Coulomb potential","abstract":"The correlation function is a useful tool to study the interaction between hadrons. The theoretical description of this observable requires the knowledge of the scattering wave function, whose asymptotic part is distorted when two or more particles are charged. For a system of three (or more) particles, with more than two particles asymptotically free and at least two of them charged, the asymptotic part of the wave function is not known in a closed form. In the present study we introduce a screened Coulomb potential and analyze the impact of the screening radius on the correlation function. As we will show, when a sufficiently large screening radius is used, the correlation function results almost unchanged if compared to the case in which the unscreened Coulomb potential is used. This fact allows the use of free asymptotic matching conditions in the solution of the scattering equation simplifying noticeably the calculation of the correlation function. As an illustration we discuss the $pp$ and $ppp$ correlation functions.","sentences":["The correlation function is a useful tool to study the interaction between hadrons.","The theoretical description of this observable requires the knowledge of the scattering wave function, whose asymptotic part is distorted when two or more particles are charged.","For a system of three (or more) particles, with more than two particles asymptotically free and at least two of them charged, the asymptotic part of the wave function is not known in a closed form.","In the present study we introduce a screened Coulomb potential and analyze the impact of the screening radius on the correlation function.","As we will show, when a sufficiently large screening radius is used, the correlation function results almost unchanged if compared to the case in which the unscreened Coulomb potential is used.","This fact allows the use of free asymptotic matching conditions in the solution of the scattering equation simplifying noticeably the calculation of the correlation function.","As an illustration we discuss the $pp$ and $ppp$ correlation functions."],"url":"http://arxiv.org/abs/2402.06317v1","category":"nucl-th"}
{"created":"2024-02-09 10:16:58","title":"Multimodal Interpretable Data-Driven Models for Early Prediction of Antimicrobial Multidrug Resistance Using Multivariate Time-Series","abstract":"Electronic health records (EHR) is an inherently multimodal register of the patient's health status characterized by static data and multivariate time series (MTS). While MTS are a valuable tool for clinical prediction, their fusion with other data modalities can possibly result in more thorough insights and more accurate results. Deep neural networks (DNNs) have emerged as fundamental tools for identifying and defining underlying patterns in the healthcare domain. However, fundamental improvements in interpretability are needed for DNN models to be widely used in the clinical setting. In this study, we present an approach built on a collection of interpretable multimodal data-driven models that may anticipate and understand the emergence of antimicrobial multidrug resistance (AMR) germs in the intensive care unit (ICU) of the University Hospital of Fuenlabrada (Madrid, Spain). The profile and initial health status of the patient are modeled using static variables, while the evolution of the patient's health status during the ICU stay is modeled using several MTS, including mechanical ventilation and antibiotics intake. The multimodal DNNs models proposed in this paper include interpretable principles in addition to being effective at predicting AMR and providing an explainable prediction support system for AMR in the ICU. Furthermore, our proposed methodology based on multimodal models and interpretability schemes can be leveraged in additional clinical problems dealing with EHR data, broadening the impact and applicability of our results.","sentences":["Electronic health records (EHR) is an inherently multimodal register of the patient's health status characterized by static data and multivariate time series (MTS).","While MTS are a valuable tool for clinical prediction, their fusion with other data modalities can possibly result in more thorough insights and more accurate results.","Deep neural networks (DNNs) have emerged as fundamental tools for identifying and defining underlying patterns in the healthcare domain.","However, fundamental improvements in interpretability are needed for DNN models to be widely used in the clinical setting.","In this study, we present an approach built on a collection of interpretable multimodal data-driven models that may anticipate and understand the emergence of antimicrobial multidrug resistance (AMR) germs in the intensive care unit (ICU) of the University Hospital of Fuenlabrada (Madrid, Spain).","The profile and initial health status of the patient are modeled using static variables, while the evolution of the patient's health status during the ICU stay is modeled using several MTS, including mechanical ventilation and antibiotics intake.","The multimodal DNNs models proposed in this paper include interpretable principles in addition to being effective at predicting AMR and providing an explainable prediction support system for AMR in the ICU.","Furthermore, our proposed methodology based on multimodal models and interpretability schemes can be leveraged in additional clinical problems dealing with EHR data, broadening the impact and applicability of our results."],"url":"http://arxiv.org/abs/2402.06295v1","category":"cs.LG"}
{"created":"2024-02-09 10:16:39","title":"Complexity of Boolean automata networks under block-parallel update modes","abstract":"Boolean automata networks (aka Boolean networks) are space-time discrete dynamical systems, studied as a model of computation and as a representative model of natural phenomena. A collection of simple entities (the automata) update their 0-1 states according to local rules. The dynamics of the network is highly sensitive to update modes, i.e., to the schedule according to which the automata apply their local rule. A new family of update modes appeared recently, called block-parallel, which is dual to the well studied block-sequential. Although basic, it embeds the rich feature of update repetitions among a temporal updating period, allowing for atypical asymptotic behaviors. In this paper, we prove that it is able to breed complex computations, squashing almost all decision problems on the dynamics to the traditionally highest (for reachability questions) class PSPACE. Despite obtaining these complexity bounds for a broad set of local and global properties, we also highlight a surprising gap: bijectivity is still coNP.","sentences":["Boolean automata networks (aka Boolean networks) are space-time discrete dynamical systems, studied as a model of computation and as a representative model of natural phenomena.","A collection of simple entities (the automata) update their 0-1 states according to local rules.","The dynamics of the network is highly sensitive to update modes, i.e., to the schedule according to which the automata apply their local rule.","A new family of update modes appeared recently, called block-parallel, which is dual to the well studied block-sequential.","Although basic, it embeds the rich feature of update repetitions among a temporal updating period, allowing for atypical asymptotic behaviors.","In this paper, we prove that it is able to breed complex computations, squashing almost all decision problems on the dynamics to the traditionally highest (for reachability questions) class PSPACE.","Despite obtaining these complexity bounds for a broad set of local and global properties, we also highlight a surprising gap: bijectivity is still coNP."],"url":"http://arxiv.org/abs/2402.06294v1","category":"cs.DM"}
{"created":"2024-02-09 18:59:20","title":"Computing Optimal Commitments to Strategies and Outcome-Conditional Utility Transfers","abstract":"Prior work has studied the computational complexity of computing optimal strategies to commit to in Stackelberg or leadership games, where a leader commits to a strategy which is observed by one or more followers. We extend this setting to one where the leader can additionally commit to outcome-conditional utility transfers. We characterize the computational complexity of finding optimal strategies in normal-form and Bayesian games, giving a mix of efficient algorithms and NP-hardness results. Finally, we allow the leader to also commit to a signaling scheme which induces a correlated equilibrium. In this setting, optimal commitments can be found in polynomial time for arbitrarily many players.","sentences":["Prior work has studied the computational complexity of computing optimal strategies to commit to in Stackelberg or leadership games, where a leader commits to a strategy which is observed by one or more followers.","We extend this setting to one where the leader can additionally commit to outcome-conditional utility transfers.","We characterize the computational complexity of finding optimal strategies in normal-form and Bayesian games, giving a mix of efficient algorithms and NP-hardness results.","Finally, we allow the leader to also commit to a signaling scheme which induces a correlated equilibrium.","In this setting, optimal commitments can be found in polynomial time for arbitrarily many players."],"url":"http://arxiv.org/abs/2402.06626v1","category":"cs.GT"}
{"created":"2024-02-09 18:56:57","title":"Empirically Exploring How Novices Write Software Models in Alloy","abstract":"Writing declarative models has numerous benefits, ranging from automated reasoning and correction of design-level properties before systems are built, to automated testing and debugging of their implementations after they are built. Alloy is a declarative modeling language that is well-suited for verifying system designs. A key strength of Alloy is its scenario-finding toolset, the Analyzer, which allows users to explore all valid scenarios that adhere to the model's constraints up to a user-provided scope. However, even with visualized scenarios, it is difficult to write correct Alloy models. To address this, a growing body of work explores different techniques for debugging Alloy models. In order to develop and evaluate these techniques in an effective manor, this paper presents an empirical study of over 97,000 models written by novice users trying to learn Alloy. We investigate how users write both correct and incorrect models in order to produce a comprehensive benchmark for future use as well as a series of observations to guide debugging and educational efforts for Alloy model development.","sentences":["Writing declarative models has numerous benefits, ranging from automated reasoning and correction of design-level properties before systems are built, to automated testing and debugging of their implementations after they are built.","Alloy is a declarative modeling language that is well-suited for verifying system designs.","A key strength of Alloy is its scenario-finding toolset, the Analyzer, which allows users to explore all valid scenarios that adhere to the model's constraints up to a user-provided scope.","However, even with visualized scenarios, it is difficult to write correct Alloy models.","To address this, a growing body of work explores different techniques for debugging Alloy models.","In order to develop and evaluate these techniques in an effective manor, this paper presents an empirical study of over 97,000 models written by novice users trying to learn Alloy.","We investigate how users write both correct and incorrect models in order to produce a comprehensive benchmark for future use as well as a series of observations to guide debugging and educational efforts for Alloy model development."],"url":"http://arxiv.org/abs/2402.06624v1","category":"cs.SE"}
{"created":"2024-02-09 18:45:00","title":"The Complexity of Sequential Prediction in Dynamical Systems","abstract":"We study the problem of learning to predict the next state of a dynamical system when the underlying evolution function is unknown. Unlike previous work, we place no parametric assumptions on the dynamical system, and study the problem from a learning theory perspective. We define new combinatorial measures and dimensions and show that they quantify the optimal mistake and regret bounds in the realizable and agnostic setting respectively.","sentences":["We study the problem of learning to predict the next state of a dynamical system when the underlying evolution function is unknown.","Unlike previous work, we place no parametric assumptions on the dynamical system, and study the problem from a learning theory perspective.","We define new combinatorial measures and dimensions and show that they quantify the optimal mistake and regret bounds in the realizable and agnostic setting respectively."],"url":"http://arxiv.org/abs/2402.06614v1","category":"cs.LG"}
{"created":"2024-02-09 18:42:50","title":"Noncommutative point spaces of symbolic dynamical systems","abstract":"We study point modules of monomial algebras associated with symbolic dynamical systems, parametrized by proalgebraic varieties which 'linearize' the underlying dynamical systems. Faithful point modules correspond to transitive sub-systems, equivalently, to monomial algebras associated with infinite words. In particular, we prove that the space of point modules of every prime monomial algebra with Hilbert series $1/(1-t)^2$ -- which is thus thought of as a 'monomial $\\mathbb{P}^1$' -- is isomorphic to a union of a classical projective line with a Cantor set. While there is a continuum of monomial $\\mathbb{P}^1$'s with non-equivalent graded module categories, they all share isomorphic parametrizing spaces of point modules. In contrast, free algebras are geometrically rigid, and are characterized up to isomorphism from their spaces of point modules. Furthermore, we derive enumerative and ring-theoretic consequences from our analysis. In particular, we show that the formal power series counting the irreducible components of the moduli schemes of truncated point modules of finitely presented monomial algebras are rational functions, and classify isomorphisms and automorphisms of projectively simple monomial algebras.","sentences":["We study point modules of monomial algebras associated with symbolic dynamical systems, parametrized by proalgebraic varieties which 'linearize' the underlying dynamical systems.","Faithful point modules correspond to transitive sub-systems, equivalently, to monomial algebras associated with infinite words.","In particular, we prove that the space of point modules of every prime monomial algebra with Hilbert series $1/(1-t)^2$ -- which is thus thought of as a 'monomial $\\mathbb{P}^1$' -- is isomorphic to a union of a classical projective line with a Cantor set.","While there is a continuum of monomial $\\mathbb{P}^1$'s with non-equivalent graded module categories, they all share isomorphic parametrizing spaces of point modules.","In contrast, free algebras are geometrically rigid, and are characterized up to isomorphism from their spaces of point modules.","Furthermore, we derive enumerative and ring-theoretic consequences from our analysis.","In particular, we show that the formal power series counting the irreducible components of the moduli schemes of truncated point modules of finitely presented monomial algebras are rational functions, and classify isomorphisms and automorphisms of projectively simple monomial algebras."],"url":"http://arxiv.org/abs/2402.06612v1","category":"math.RA"}
{"created":"2024-02-09 18:39:29","title":"You Still See Me: How Data Protection Supports the Architecture of ML Surveillance","abstract":"Data forms the backbone of machine learning. Thus, data protection law has strong bearing on how ML systems are governed. Given that most requirements accompany the processing of personal data, organizations have an incentive to keep their data out of legal scope. Privacy-preserving techniques incentivized by data protection law -- data protection techniques -- constitute an important strategy for ML development because they are used to distill data until it potentially falls outside the scope of data protection laws.   In this paper, we examine the impact of a rhetoric that deems data wrapped in privacy-preserving techniques as data that is \"good-to-go\". We show how the application of data protection techniques in the development of ML systems -- from private set intersection as part of dataset curation to homomorphic encryption and federated learning as part of model computation to the framing of the privacy-utility trade-off as part of model updating -- can further support individual monitoring and data consolidation. With data accumulation at the core of how the ML pipeline is configured, we argue that data protection techniques are often instrumentalized in ways that support infrastructures of surveillance, rather than to protect individuals associated with data. Finally, we propose technology and policy strategies to evaluate data protection techniques in light of the protections they actually confer. We conclude by highlighting the role that security technologists might play in devising policies that combat surveillance ML technologies -- recommending the adversarial mindset inherent to the profession to more precisely articulate and prevent the use of \"privacy-preserving\" scaffoldings that support surveillance.","sentences":["Data forms the backbone of machine learning.","Thus, data protection law has strong bearing on how ML systems are governed.","Given that most requirements accompany the processing of personal data, organizations have an incentive to keep their data out of legal scope.","Privacy-preserving techniques incentivized by data protection law -- data protection techniques -- constitute an important strategy for ML development because they are used to distill data until it potentially falls outside the scope of data protection laws.   ","In this paper, we examine the impact of a rhetoric that deems data wrapped in privacy-preserving techniques as data that is \"good-to-go\".","We show how the application of data protection techniques in the development of ML systems -- from private set intersection as part of dataset curation to homomorphic encryption and federated learning as part of model computation to the framing of the privacy-utility trade-off as part of model updating -- can further support individual monitoring and data consolidation.","With data accumulation at the core of how the ML pipeline is configured, we argue that data protection techniques are often instrumentalized in ways that support infrastructures of surveillance, rather than to protect individuals associated with data.","Finally, we propose technology and policy strategies to evaluate data protection techniques in light of the protections they actually confer.","We conclude by highlighting the role that security technologists might play in devising policies that combat surveillance ML technologies -- recommending the adversarial mindset inherent to the profession to more precisely articulate and prevent the use of \"privacy-preserving\" scaffoldings that support surveillance."],"url":"http://arxiv.org/abs/2402.06609v1","category":"cs.CY"}
{"created":"2024-02-09 18:36:17","title":"Real-time Dynamics of the Schwinger Model as an Open Quantum System with Neural Density Operators","abstract":"Ab-initio simulations of multiple heavy quarks propagating in a Quark-Gluon Plasma are computationally difficult to perform due to the large dimension of the space of density matrices. This work develops machine learning algorithms to overcome this difficulty by approximating exact quantum states with neural network parametrisations, specifically Neural Density Operators. As a proof of principle demonstration in a QCD-like theory, the approach is applied to solve the Lindblad master equation in the 1+1d lattice Schwinger Model as an open quantum system. Neural Density Operators enable the study of in-medium dynamics on large lattice volumes, where multiple-string interactions and their effects on string-breaking and recombination phenomena can be studied. Thermal properties of the system at equilibrium can also be probed with these methods by variationally constructing the steady state of the Lindblad master equation. Scaling of this approach with system size is studied, and numerical demonstrations on up to 32 spatial lattice sites and with up to 3 interacting strings are performed.","sentences":["Ab-initio simulations of multiple heavy quarks propagating in a Quark-Gluon Plasma are computationally difficult to perform due to the large dimension of the space of density matrices.","This work develops machine learning algorithms to overcome this difficulty by approximating exact quantum states with neural network parametrisations, specifically Neural Density Operators.","As a proof of principle demonstration in a QCD-like theory, the approach is applied to solve the Lindblad master equation in the 1+1d lattice Schwinger Model as an open quantum system.","Neural Density Operators enable the study of in-medium dynamics on large lattice volumes, where multiple-string interactions and their effects on string-breaking and recombination phenomena can be studied.","Thermal properties of the system at equilibrium can also be probed with these methods by variationally constructing the steady state of the Lindblad master equation.","Scaling of this approach with system size is studied, and numerical demonstrations on up to 32 spatial lattice sites and with up to 3 interacting strings are performed."],"url":"http://arxiv.org/abs/2402.06607v1","category":"hep-ph"}
{"created":"2024-02-09 18:33:47","title":"Simulation of ion temperature gradient driven modes with 6D kinetic Vlasov code","abstract":"With the increase in computational capabilities over the last years it becomes possible to simulate more and more complex and accurate physical models. Gyrokinetic theory has been introduced in the 1960s and 1970s in the need of describing a plasma with more accurate models than fluid equations, but eliminating the complexity of the fast gyration about the magnetic field lines. Although results from current gyrokinetic computer simulations are in fair agreement with experimental results in core physics, crucial assumptions made in the derivation make it unreliable in regimes of higher fluctuations and stronger gradient, such as the tokamak edge. With our novel optimized and scalable semi-Lagrangian solver we are able to simulate ion-temperature gradient modes with the 6D kinetic model including the turbulent saturation. After thoroughly testing our simulation code against analytical computations and gyrokinetic simulations (with the gyrokinetic code GYRO), it has been possible to show first plasma properties that go beyond standard gyrokinetic simulations. This includes the explicit description of the complete perpendicular energy fluxes and the excitation of high frequency waves (around the Larmor frequency) in the nonlinear saturation phase.","sentences":["With the increase in computational capabilities over the last years it becomes possible to simulate more and more complex and accurate physical models.","Gyrokinetic theory has been introduced in the 1960s and 1970s in the need of describing a plasma with more accurate models than fluid equations, but eliminating the complexity of the fast gyration about the magnetic field lines.","Although results from current gyrokinetic computer simulations are in fair agreement with experimental results in core physics, crucial assumptions made in the derivation make it unreliable in regimes of higher fluctuations and stronger gradient, such as the tokamak edge.","With our novel optimized and scalable semi-Lagrangian solver we are able to simulate ion-temperature gradient modes with the 6D kinetic model including the turbulent saturation.","After thoroughly testing our simulation code against analytical computations and gyrokinetic simulations (with the gyrokinetic code GYRO), it has been possible to show first plasma properties that go beyond standard gyrokinetic simulations.","This includes the explicit description of the complete perpendicular energy fluxes and the excitation of high frequency waves (around the Larmor frequency) in the nonlinear saturation phase."],"url":"http://arxiv.org/abs/2402.06605v1","category":"physics.plasm-ph"}
{"created":"2024-02-09 18:23:16","title":"On the numerical controllability of the two-dimensional heat, Stokes and Navier-Stokes equations","abstract":"The aim of this work is to present some strategies to solve numerically controllability problems for the two-dimensional heat equation, the Stokes equations and the Navier-Stokes equations with Dirichlet boundary conditions. The main idea is to adapt the Fursikov-Imanuvilov formulation, see~[A.V. Fursikov, O.Yu. Imanuvilov: {\\it Controllability of Evolutions Equations,} Lectures Notes Series, Vol.~34, Seoul National University, 1996]; this approach has been followed recently for the one-dimensional heat equation by the first two authors. More precisely, we minimize over the class of admissible null controls a functional that involves weighted integrals of the state and the control, with weights that blow up near the final time. The associated optimality conditions can be viewed as a differential system in the three variables $x_1$, $x_2$ and $t$ that is second--order in time and fourth--order in space, completed with appropriate boundary conditions. We present several mixed formulations of the problems and, then, associated mixed finite element Lagrangian approximations that are relatively easy to handle. Finally, we exhibit some numerical experiments.","sentences":["The aim of this work is to present some strategies to solve numerically controllability problems for the two-dimensional heat equation, the Stokes equations and the Navier-Stokes equations with Dirichlet boundary conditions.","The main idea is to adapt the Fursikov-Imanuvilov formulation, see~[A.V. Fursikov, O.Yu.","Imanuvilov: {\\it Controllability of Evolutions Equations,} Lectures Notes Series, Vol.~34, Seoul National University, 1996]; this approach has been followed recently for the one-dimensional heat equation by the first two authors.","More precisely, we minimize over the class of admissible null controls a functional that involves weighted integrals of the state and the control, with weights that blow up near the final time.","The associated optimality conditions can be viewed as a differential system in the three variables $x_1$, $x_2$ and $t$ that is second--order in time and fourth--order in space, completed with appropriate boundary conditions.","We present several mixed formulations of the problems and, then, associated mixed finite element Lagrangian approximations that are relatively easy to handle.","Finally, we exhibit some numerical experiments."],"url":"http://arxiv.org/abs/2402.06601v1","category":"math.OC"}
{"created":"2024-02-09 18:21:05","title":"The impact of different unravelings in a monitored system of free fermions","abstract":"We consider a free-fermion chain undergoing dephasing, described by two different random-measurement protocols (unravelings): a quantum-state-diffusion and a quantum-jump one. Both protocols keep the state in a Slater-determinant form, allowing to address quite large system sizes. We find a bifurcation transition in the distribution of the measurement operators along the quantum trajectories, where it changes from unimodal to bimodal. The value of the measurement strength where such transition occurs is similar for the two unravelings, but the distributions and the transition have different properties reflecting the symmetries of the two measurement protocols. We also consider the scaling with the system size of the inverse participation ratio of the Slater-determinant components and find a power-law scaling that marks a multifractal behaviour, in both unravelings and for any nonvanishing measurement strength.","sentences":["We consider a free-fermion chain undergoing dephasing, described by two different random-measurement protocols (unravelings): a quantum-state-diffusion and a quantum-jump one.","Both protocols keep the state in a Slater-determinant form, allowing to address quite large system sizes.","We find a bifurcation transition in the distribution of the measurement operators along the quantum trajectories, where it changes from unimodal to bimodal.","The value of the measurement strength where such transition occurs is similar for the two unravelings, but the distributions and the transition have different properties reflecting the symmetries of the two measurement protocols.","We also consider the scaling with the system size of the inverse participation ratio of the Slater-determinant components and find a power-law scaling that marks a multifractal behaviour, in both unravelings and for any nonvanishing measurement strength."],"url":"http://arxiv.org/abs/2402.06597v1","category":"quant-ph"}
{"created":"2024-02-09 18:12:11","title":"Self-consistent context aware conformer transducer for speech recognition","abstract":"We propose a novel neural network architecture based on conformer transducer that adds contextual information flow to the ASR systems. Our method improves the accuracy of recognizing uncommon words while not harming the word error rate of regular words. We explore the uncommon words accuracy improvement when we use the new model and/or shallow fusion with context language model. We found that combination of both provides cumulative gain in uncommon words recognition accuracy.","sentences":["We propose a novel neural network architecture based on conformer transducer that adds contextual information flow to the ASR systems.","Our method improves the accuracy of recognizing uncommon words while not harming the word error rate of regular words.","We explore the uncommon words accuracy improvement when we use the new model and/or shallow fusion with context language model.","We found that combination of both provides cumulative gain in uncommon words recognition accuracy."],"url":"http://arxiv.org/abs/2402.06592v1","category":"cs.CL"}
{"created":"2024-02-09 18:10:05","title":"Modular Redesign of Mechatronic Systems: Formulation of Module Specifications Guaranteeing System Dynamics Specifications","abstract":"Complex mechatronic systems are typically composed of interconnected modules, often developed by independent teams. This development process challenges the verification of system specifications before all modules are integrated. To address this challenge, a modular redesign framework is proposed in this paper. Herein, first, allowed changes in the dynamics (represented by frequency response functions (FRFs)) of the redesigned system are defined with respect to the original system model, which already satisfies system specifications. Second, these allowed changes in the overall system dynamics (or system redesign specifications) are automatically translated to dynamics (FRF) specifications on module level that, when satisfied, guarantee overall system dynamics (FRF) specifications. This modularity in specification management supports local analysis and verification of module design changes, enabling design teams to work in parallel without the need to iteratively rebuild the system model to check fulfilment of system FRF specifications. A modular redesign process results that shortens time-to-market and decreases redesign costs. The framework's effectiveness is demonstrated through three examples of increasing complexity, highlighting its potential to enable modular mechatronic system (re)design.","sentences":["Complex mechatronic systems are typically composed of interconnected modules, often developed by independent teams.","This development process challenges the verification of system specifications before all modules are integrated.","To address this challenge, a modular redesign framework is proposed in this paper.","Herein, first, allowed changes in the dynamics (represented by frequency response functions (FRFs)) of the redesigned system are defined with respect to the original system model, which already satisfies system specifications.","Second, these allowed changes in the overall system dynamics (or system redesign specifications) are automatically translated to dynamics (FRF) specifications on module level that, when satisfied, guarantee overall system dynamics (FRF) specifications.","This modularity in specification management supports local analysis and verification of module design changes, enabling design teams to work in parallel without the need to iteratively rebuild the system model to check fulfilment of system FRF specifications.","A modular redesign process results that shortens time-to-market and decreases redesign costs.","The framework's effectiveness is demonstrated through three examples of increasing complexity, highlighting its potential to enable modular mechatronic system (re)design."],"url":"http://arxiv.org/abs/2402.06589v1","category":"eess.SY"}
{"created":"2024-02-09 18:07:30","title":"Precision Air Flow Control via EHD Actuator: A Co-simulation and Control Design Case Study","abstract":"A Dielectric Barrier Discharge (DBD) plasma actuator for controlling airflow is proposed. It consists of diverging and converging nozzles, two concentric cylinders and an actuator mounted in-between the two cylinders. The actuator employs electrohydrodynamic (EHD) body force to induce an air jet within the air gap between the two cylinders, effectively creating a suction area while passing through the diverging nozzle, due to the Coanda effect. While merging with the air stream inside the inner cylinder, the Coanda jet effectively enhances amplification of the airflow. The outflow rate is measured by a velocity sensor at the outlet and controlled by the plasma actuator. The control strategy is based on the Active Disturbance Rejection Control (ADRC) and compared to the baseline PID controller. The actuator was modelled by seamlessly linking two modeling platforms for a co-simulation study. The CFD simulation of the plasma and airflow was carried out in the COMSOL multi-physics commercial software, and the control was implemented in the Simulink. The DBD plasma model was based on the two-species model of discharge, and the electric body force, calculated from the plasma simulation, was used in the Navier-Stokes equation for the turbulent flow simulation. The plasma-air flow system was analyzed using the input (the actuator voltage) and output (the outlet flow rate) data for the control design. Finally, the performance of the system of air flow control device was tested and discussed in the co-simulation process.","sentences":["A Dielectric Barrier Discharge (DBD) plasma actuator for controlling airflow is proposed.","It consists of diverging and converging nozzles, two concentric cylinders and an actuator mounted in-between the two cylinders.","The actuator employs electrohydrodynamic (EHD) body force to induce an air jet within the air gap between the two cylinders, effectively creating a suction area while passing through the diverging nozzle, due to the Coanda effect.","While merging with the air stream inside the inner cylinder, the Coanda jet effectively enhances amplification of the airflow.","The outflow rate is measured by a velocity sensor at the outlet and controlled by the plasma actuator.","The control strategy is based on the Active Disturbance Rejection Control (ADRC) and compared to the baseline PID controller.","The actuator was modelled by seamlessly linking two modeling platforms for a co-simulation study.","The CFD simulation of the plasma and airflow was carried out in the COMSOL multi-physics commercial software, and the control was implemented in the Simulink.","The DBD plasma model was based on the two-species model of discharge, and the electric body force, calculated from the plasma simulation, was used in the Navier-Stokes equation for the turbulent flow simulation.","The plasma-air flow system was analyzed using the input (the actuator voltage) and output (the outlet flow rate) data for the control design.","Finally, the performance of the system of air flow control device was tested and discussed in the co-simulation process."],"url":"http://arxiv.org/abs/2402.06588v1","category":"physics.flu-dyn"}
{"created":"2024-02-09 17:50:40","title":"Value-based Resource Matching with Fairness Criteria: Application to Agricultural Water Trading","abstract":"Optimal allocation of agricultural water in the event of droughts is an important global problem. In addressing this problem, many aspects, including the welfare of farmers, the economy, and the environment, must be considered. Under this backdrop, our work focuses on several resource-matching problems accounting for agents with multi-crop portfolios, geographic constraints, and fairness. First, we address a matching problem where the goal is to maximize a welfare function in two-sided markets where buyers' requirements and sellers' supplies are represented by value functions that assign prices (or costs) to specified volumes of water. For the setting where the value functions satisfy certain monotonicity properties, we present an efficient algorithm that maximizes a social welfare function. When there are minimum water requirement constraints, we present a randomized algorithm which ensures that the constraints are satisfied in expectation. For a single seller--multiple buyers setting with fairness constraints, we design an efficient algorithm that maximizes the minimum level of satisfaction of any buyer. We also present computational complexity results that highlight the limits on the generalizability of our results. We evaluate the algorithms developed in our work with experiments on both real-world and synthetic data sets with respect to drought severity, value functions, and seniority of agents.","sentences":["Optimal allocation of agricultural water in the event of droughts is an important global problem.","In addressing this problem, many aspects, including the welfare of farmers, the economy, and the environment, must be considered.","Under this backdrop, our work focuses on several resource-matching problems accounting for agents with multi-crop portfolios, geographic constraints, and fairness.","First, we address a matching problem where the goal is to maximize a welfare function in two-sided markets where buyers' requirements and sellers' supplies are represented by value functions that assign prices (or costs) to specified volumes of water.","For the setting where the value functions satisfy certain monotonicity properties, we present an efficient algorithm that maximizes a social welfare function.","When there are minimum water requirement constraints, we present a randomized algorithm which ensures that the constraints are satisfied in expectation.","For a single seller--multiple buyers setting with fairness constraints, we design an efficient algorithm that maximizes the minimum level of satisfaction of any buyer.","We also present computational complexity results that highlight the limits on the generalizability of our results.","We evaluate the algorithms developed in our work with experiments on both real-world and synthetic data sets with respect to drought severity, value functions, and seniority of agents."],"url":"http://arxiv.org/abs/2402.06576v1","category":"cs.DS"}
{"created":"2024-02-09 17:45:49","title":"Exploring quantum criticality in a 4D quantum disordered system","abstract":"Phase transitions are prevalent throughout physics, spanning thermal phenomena like water boiling to magnetic transitions in solids. They encompass cosmological phase transitions in the early universe and the transition into a quark-gluon plasma in high-energy collisions. Quantum phase transitions, particularly intriguing, occur at temperatures near absolute zero and are driven by quantum fluctuations rather than thermal ones. The strength of the fluctuations is very sensitive to the dimensionality of the physical systems, which determines the existence and nature of phase transitions. Low-dimensional systems often exhibit suppression of phase transitions, while high-dimensional systems tend to exhibit mean-field-like behavior. The localization-delocalization Anderson transition stands out among quantum phase transitions, as it is thought to retain its non-mean-field character across all dimensions. This work marks the first observation and characterization of the Anderson transition in four dimensions using ultracold atoms as a quantum simulator with synthetic dimensions. We characterize the universal dynamics in the vicinity of the phase transition. We measure the critical exponents describing the scale-invariant properties of the critical dynamics, which are shown to obey Wegner's scaling law. Our work is the first experimental demonstration that the Anderson transition is not mean-field in dimension four.","sentences":["Phase transitions are prevalent throughout physics, spanning thermal phenomena like water boiling to magnetic transitions in solids.","They encompass cosmological phase transitions in the early universe and the transition into a quark-gluon plasma in high-energy collisions.","Quantum phase transitions, particularly intriguing, occur at temperatures near absolute zero and are driven by quantum fluctuations rather than thermal ones.","The strength of the fluctuations is very sensitive to the dimensionality of the physical systems, which determines the existence and nature of phase transitions.","Low-dimensional systems often exhibit suppression of phase transitions, while high-dimensional systems tend to exhibit mean-field-like behavior.","The localization-delocalization Anderson transition stands out among quantum phase transitions, as it is thought to retain its non-mean-field character across all dimensions.","This work marks the first observation and characterization of the Anderson transition in four dimensions using ultracold atoms as a quantum simulator with synthetic dimensions.","We characterize the universal dynamics in the vicinity of the phase transition.","We measure the critical exponents describing the scale-invariant properties of the critical dynamics, which are shown to obey Wegner's scaling law.","Our work is the first experimental demonstration that the Anderson transition is not mean-field in dimension four."],"url":"http://arxiv.org/abs/2402.06573v1","category":"cond-mat.dis-nn"}
{"created":"2024-02-09 17:10:12","title":"The Oberbeck--Boussinesq approximation and Rayleigh--Benard convection revisited","abstract":"We consider the Oberbeck--Boussinesq approximation driven by an inhomogeneous temperature distribution on the boundary of a bounded fluid domain. The relevant boundary conditions are perturbed by a non--local term arising in the incompressible limit of the Navier--Stokes--Fourier system. The long time behaviour of the resulting initial/boundary value problem is investigated.","sentences":["We consider the Oberbeck--Boussinesq approximation driven by an inhomogeneous temperature distribution on the boundary of a bounded fluid domain.","The relevant boundary conditions are perturbed by a non--local term arising in the incompressible limit of the Navier--Stokes--Fourier system.","The long time behaviour of the resulting initial/boundary value problem is investigated."],"url":"http://arxiv.org/abs/2402.06554v1","category":"math.AP"}
{"created":"2024-02-09 17:05:54","title":"The existence of arbitrary large number of non-$\\mathbb R$-covered Anosov flows on hyperbolic $3$-manifolds","abstract":"The purpose of this paper is to prove that, for every $n\\in \\mathbb N$, there exists a closed hyperbolic $3$-manifold $M$ which carries at least $n$ non-$\\mathbb R$-covered Anosov flows, that are pariwise non-orbitally equivalent. Due to a recent result by Fenley, such Anosov flows are quasi-geodesic. Hence, we get the existence of hyperbolic $3$-manifolds carrying many pairwise non-orbitally equivalent quasi-geodesic Anosov flows. In order to prove that the flows we construct are not orbitally equivalent, we prove that some patterns of the bi-foliation of the orbit space are not destroyed by Dehn-Fried surgeries, and yield to new dynamical invariants. We believe that those dynamical invariants could be used in a much wider context.","sentences":["The purpose of this paper is to prove that, for every $n\\in \\mathbb N$, there exists a closed hyperbolic $3$-manifold $M$ which carries at least $n$ non-$\\mathbb R$-covered Anosov flows, that are pariwise non-orbitally equivalent.","Due to a recent result by Fenley, such Anosov flows are quasi-geodesic.","Hence, we get the existence of hyperbolic $3$-manifolds carrying many pairwise non-orbitally equivalent quasi-geodesic Anosov flows.","In order to prove that the flows we construct are not orbitally equivalent, we prove that some patterns of the bi-foliation of the orbit space are not destroyed by Dehn-Fried surgeries, and yield to new dynamical invariants.","We believe that those dynamical invariants could be used in a much wider context."],"url":"http://arxiv.org/abs/2402.06551v1","category":"math.DS"}
{"created":"2024-02-09 16:57:31","title":"Improving forecasts of precipitation extremes over Northern and Central Italy using machine learning","abstract":"The accurate prediction of intense precipitation events is one of the main objectives of operational weather services. This task is even more relevant nowadays, with the rapid progression of global warming which intensifies these events. Numerical weather prediction models have improved continuously over time, providing uncertainty estimation with dynamical ensembles. However, direct precipitation forecasting is still challenging. Greater availability of machine learning tools paves the way to a hybrid forecasting approach, with the optimal combination of physical models, event statistics, and user-oriented post-processing. Here we describe a specific chain, based on a random forest pipeline, specialised in recognizing favourable synoptic conditions leading to precipitation extremes and subsequently classifying extremes into predefined types. The application focuses on Northern and Central Italy, taken as a testbed region, but is seamlessly extensible to other regions and timescales. The system is called MaLCoX (Machine Learning model predicting Conditions for eXtreme precipitation) and is running daily at the Italian regional weather service of ARPAE Emilia-Romagna. MalCoX has been trained with the ARCIS gridded high-resolution precipitation dataset as the target truth, using the last 20 years of the ECMWF re-forecast dataset as input predictors. We show that, with a long enough training period, the optimal blend of larger-scale information with direct model output improves the probabilistic forecast accuracy of extremes in the medium range. In addition, with specific methods, we provide a useful diagnostic to convey to forecasters the underlying physical storyline which makes a meteorological event extreme.","sentences":["The accurate prediction of intense precipitation events is one of the main objectives of operational weather services.","This task is even more relevant nowadays, with the rapid progression of global warming which intensifies these events.","Numerical weather prediction models have improved continuously over time, providing uncertainty estimation with dynamical ensembles.","However, direct precipitation forecasting is still challenging.","Greater availability of machine learning tools paves the way to a hybrid forecasting approach, with the optimal combination of physical models, event statistics, and user-oriented post-processing.","Here we describe a specific chain, based on a random forest pipeline, specialised in recognizing favourable synoptic conditions leading to precipitation extremes and subsequently classifying extremes into predefined types.","The application focuses on Northern and Central Italy, taken as a testbed region, but is seamlessly extensible to other regions and timescales.","The system is called MaLCoX (Machine Learning model predicting Conditions for eXtreme precipitation) and is running daily at the Italian regional weather service of ARPAE Emilia-Romagna.","MalCoX has been trained with the ARCIS gridded high-resolution precipitation dataset as the target truth, using the last 20 years of the ECMWF re-forecast dataset as input predictors.","We show that, with a long enough training period, the optimal blend of larger-scale information with direct model output improves the probabilistic forecast accuracy of extremes in the medium range.","In addition, with specific methods, we provide a useful diagnostic to convey to forecasters the underlying physical storyline which makes a meteorological event extreme."],"url":"http://arxiv.org/abs/2402.06542v1","category":"physics.ao-ph"}
{"created":"2024-02-09 16:51:01","title":"Feature Density Estimation for Out-of-Distribution Detection via Normalizing Flows","abstract":"Out-of-distribution (OOD) detection is a critical task for safe deployment of learning systems in the open world setting. In this work, we investigate the use of feature density estimation via normalizing flows for OOD detection and present a fully unsupervised approach which requires no exposure to OOD data, avoiding researcher bias in OOD sample selection. This is a post-hoc method which can be applied to any pretrained model, and involves training a lightweight auxiliary normalizing flow model to perform the out-of-distribution detection via density thresholding. Experiments on OOD detection in image classification show strong results for far-OOD data detection with only a single epoch of flow training, including 98.2% AUROC for ImageNet-1k vs. Textures, which exceeds the state of the art by 7.8%. We additionally explore the connection between the feature space distribution of the pretrained model and the performance of our method. Finally, we provide insights into training pitfalls that have plagued normalizing flows for use in OOD detection.","sentences":["Out-of-distribution (OOD) detection is a critical task for safe deployment of learning systems in the open world setting.","In this work, we investigate the use of feature density estimation via normalizing flows for OOD detection and present a fully unsupervised approach which requires no exposure to OOD data, avoiding researcher bias in OOD sample selection.","This is a post-hoc method which can be applied to any pretrained model, and involves training a lightweight auxiliary normalizing flow model to perform the out-of-distribution detection via density thresholding.","Experiments on OOD detection in image classification show strong results for far-OOD data detection with only a single epoch of flow training, including 98.2% AUROC for ImageNet-1k vs. Textures, which exceeds the state of the art by 7.8%.","We additionally explore the connection between the feature space distribution of the pretrained model and the performance of our method.","Finally, we provide insights into training pitfalls that have plagued normalizing flows for use in OOD detection."],"url":"http://arxiv.org/abs/2402.06537v1","category":"cs.CV"}
{"created":"2024-02-09 16:50:40","title":"Relative frequencies of constrained events in stochastic processes: An analytical approach","abstract":"The stochastic simulation algorithm (SSA) and the corresponding Monte Carlo (MC) method are among the most common approaches for studying stochastic processes. They rely on knowledge of interevent probability density functions (PDFs) and on information about dependencies between all possible events. Analytical representations of a PDF are difficult to specify in advance, in many real life applications. Knowing the shapes of PDFs, and using experimental data, different optimization schemes can be applied in order to evaluate probability density functions and, therefore, the properties of the studied system. Such methods, however, are computationally demanding, and often not feasible. We show that, in the case where experimentally accessed properties are directly related to the frequencies of events involved, it may be possible to replace the heavy Monte Carlo core of optimization schemes with an analytical solution. Such a replacement not only provides a more accurate estimation of the properties of the process, but also reduces the simulation time by a factor of order of the sample size (at least $\\approx 10^4$). The proposed analytical approach is valid for any choice of PDF. The accuracy, computational efficiency, and advantages of the method over MC procedures are demonstrated in the exactly solvable case and in the evaluation of branching fractions in controlled radical polymerization (CRP) of acrylic monomers. This polymerization can be modeled by a constrained stochastic process. Constrained systems are quite common, and this makes the method useful for various applications.","sentences":["The stochastic simulation algorithm (SSA) and the corresponding Monte Carlo (MC) method are among the most common approaches for studying stochastic processes.","They rely on knowledge of interevent probability density functions (PDFs) and on information about dependencies between all possible events.","Analytical representations of a PDF are difficult to specify in advance, in many real life applications.","Knowing the shapes of PDFs, and using experimental data, different optimization schemes can be applied in order to evaluate probability density functions and, therefore, the properties of the studied system.","Such methods, however, are computationally demanding, and often not feasible.","We show that, in the case where experimentally accessed properties are directly related to the frequencies of events involved, it may be possible to replace the heavy Monte Carlo core of optimization schemes with an analytical solution.","Such a replacement not only provides a more accurate estimation of the properties of the process, but also reduces the simulation time by a factor of order of the sample size (at least $\\approx 10^4$).","The proposed analytical approach is valid for any choice of PDF.","The accuracy, computational efficiency, and advantages of the method over MC procedures are demonstrated in the exactly solvable case and in the evaluation of branching fractions in controlled radical polymerization (CRP) of acrylic monomers.","This polymerization can be modeled by a constrained stochastic process.","Constrained systems are quite common, and this makes the method useful for various applications."],"url":"http://arxiv.org/abs/2402.06536v1","category":"stat.CO"}
{"created":"2024-02-09 16:34:49","title":"Reducing model complexity by means of the Optimal Scaling: Population Balance Model for latex particles morphology formation","abstract":"Rational computer-aided design of multiphase polymer materials is vital for rapid progress in many important applications, such as: diagnostic tests, drug delivery, coatings, additives for constructing materials, cosmetics, etc. Several property predictive models, including the prospective Population Balance Model for Latex Particles Morphology Formation (LPMF PBM), have already been developed for such materials. However, they lack computational efficiency, and the accurate prediction of materials' properties still remains a great challenge. To enhance performance of the LPMF PBM, we explore the feasibility of reducing its complexity through disregard of the aggregation terms of the model. The introduced nondimensionalization approach, which we call Optimal Scaling with Constraints, suggests a quantitative criterion for locating regions of slow and fast aggregation and helps to derive a family of dimensionless LPMF PBM of reduced complexity. The mathematical analysis of this new family is also provided. When compared with the original LPMF PBM, the resulting models demonstrate several orders of magnitude better computational efficiency.","sentences":["Rational computer-aided design of multiphase polymer materials is vital for rapid progress in many important applications, such as: diagnostic tests, drug delivery, coatings, additives for constructing materials, cosmetics, etc.","Several property predictive models, including the prospective Population Balance Model for Latex Particles Morphology Formation (LPMF PBM), have already been developed for such materials.","However, they lack computational efficiency, and the accurate prediction of materials' properties still remains a great challenge.","To enhance performance of the LPMF PBM, we explore the feasibility of reducing its complexity through disregard of the aggregation terms of the model.","The introduced nondimensionalization approach, which we call Optimal Scaling with Constraints, suggests a quantitative criterion for locating regions of slow and fast aggregation and helps to derive a family of dimensionless LPMF PBM of reduced complexity.","The mathematical analysis of this new family is also provided.","When compared with the original LPMF PBM, the resulting models demonstrate several orders of magnitude better computational efficiency."],"url":"http://arxiv.org/abs/2402.06522v1","category":"cond-mat.soft"}
{"created":"2024-02-09 16:32:40","title":"Accelerating Innovation in 6G Research: Real-Time Capable SDR System Architecture for Rapid Prototyping","abstract":"The next global mobile communication standard 6G strives to push the technological limits of radio frequency (RF) communication even further than its predecessors: Data rates beyond 100 Gbit/s, RF bandwidths above 1 GHz, and sub-millisecond latency necessitate very high performance development tools to enable the extent of innovation required for 6G's likely features. We propose a new SDR firmware and software architecture designed explicitly to meet these challenging requirements. It relies on Ethernet and commercial off-the-shelf network and server components to maximize flexibility and to reduce costs. We analyze state-of-the-art solutions (USRP X440 and other RFSoC-based systems), derive architectural design goals, explain resulting design decision in detail, and exemplify our architecture's implementation on the XCZU48DR RFSoC. Finally, we prove its performance via measurements and outline how the architecture surpasses the state-of-the-art with respect to sustained RF recording while maintaining high Ethernet bandwidth efficiency. Building a micro-Doppler radar example, we demonstrate its real-time and rapid application development capabilities.","sentences":["The next global mobile communication standard 6G strives to push the technological limits of radio frequency (RF) communication even further than its predecessors: Data rates beyond 100 Gbit/s, RF bandwidths above 1 GHz, and sub-millisecond latency necessitate very high performance development tools to enable the extent of innovation required for 6G's likely features.","We propose a new SDR firmware and software architecture designed explicitly to meet these challenging requirements.","It relies on Ethernet and commercial off-the-shelf network and server components to maximize flexibility and to reduce costs.","We analyze state-of-the-art solutions (USRP X440 and other RFSoC-based systems), derive architectural design goals, explain resulting design decision in detail, and exemplify our architecture's implementation on the XCZU48DR RFSoC. Finally, we prove its performance via measurements and outline how the architecture surpasses the state-of-the-art with respect to sustained RF recording while maintaining high Ethernet bandwidth efficiency.","Building a micro-Doppler radar example, we demonstrate its real-time and rapid application development capabilities."],"url":"http://arxiv.org/abs/2402.06520v1","category":"eess.SP"}
{"created":"2024-02-09 16:27:45","title":"HoneyDOC: An Efficient Honeypot Architecture Enabling All-Round Design","abstract":"Honeypots are designed to trap the attacker with the purpose of investigating its malicious behavior. Owing to the increasing variety and sophistication of cyber attacks, how to capture high-quality attack data has become a challenge in the context of honeypot area. All-round honeypots, which mean significant improvement in sensibility, countermeasure and stealth, are necessary to tackle the problem. In this paper, we propose a novel honeypot architecture termed HoneyDOC to support all-round honeypot design and implementation. Our HoneyDOC architecture clearly identifies three essential independent and collaborative modules, Decoy, Captor and Orchestrator. Based on the efficient architecture, a Software-Defined Networking (SDN) enabled honeypot system is designed, which supplies high programmability for technically sustaining the features for capturing high-quality data. A proof-of-concept system is implemented to validate its feasibility and effectiveness. The experimental results show the benefits by using the proposed architecture comparing to the previous honeypot solutions.","sentences":["Honeypots are designed to trap the attacker with the purpose of investigating its malicious behavior.","Owing to the increasing variety and sophistication of cyber attacks, how to capture high-quality attack data has become a challenge in the context of honeypot area.","All-round honeypots, which mean significant improvement in sensibility, countermeasure and stealth, are necessary to tackle the problem.","In this paper, we propose a novel honeypot architecture termed HoneyDOC to support all-round honeypot design and implementation.","Our HoneyDOC architecture clearly identifies three essential independent and collaborative modules, Decoy, Captor and Orchestrator.","Based on the efficient architecture, a Software-Defined Networking (SDN) enabled honeypot system is designed, which supplies high programmability for technically sustaining the features for capturing high-quality data.","A proof-of-concept system is implemented to validate its feasibility and effectiveness.","The experimental results show the benefits by using the proposed architecture comparing to the previous honeypot solutions."],"url":"http://arxiv.org/abs/2402.06516v1","category":"cs.CR"}
{"created":"2024-02-09 16:13:21","title":"Solving Complex Multi-UAV Mission Planning Problems using Multi-objective Genetic Algorithms","abstract":"Due to recent booming of UAVs technologies, these are being used in many fields involving complex tasks. Some of them involve a high risk to the vehicle driver, such as fire monitoring and rescue tasks, which make UAVs excellent for avoiding human risks. Mission Planning for UAVs is the process of planning the locations and actions (loading/dropping a load, taking videos/pictures, acquiring information) for the vehicles, typically over a time period. These vehicles are controlled from Ground Control Stations (GCSs) where human operators use rudimentary systems. This paper presents a new Multi-Objective Genetic Algorithm for solving complex Mission Planning Problems (MPP) involving a team of UAVs and a set of GCSs. A hybrid fitness function has been designed using a Constraint Satisfaction Problem (CSP) to check if solutions are valid and Pareto-based measures to look for optimal solutions. The algorithm has been tested on several datasets optimizing different variables of the mission, such as the makespan, the fuel consumption, distance, etc. Experimental results show that the new algorithm is able to obtain good solutions, however as the problem becomes more complex, the optimal solutions also become harder to find.","sentences":["Due to recent booming of UAVs technologies, these are being used in many fields involving complex tasks.","Some of them involve a high risk to the vehicle driver, such as fire monitoring and rescue tasks, which make UAVs excellent for avoiding human risks.","Mission Planning for UAVs is the process of planning the locations and actions (loading/dropping a load, taking videos/pictures, acquiring information) for the vehicles, typically over a time period.","These vehicles are controlled from Ground Control Stations (GCSs) where human operators use rudimentary systems.","This paper presents a new Multi-Objective Genetic Algorithm for solving complex Mission Planning Problems (MPP) involving a team of UAVs and a set of GCSs.","A hybrid fitness function has been designed using a Constraint Satisfaction Problem (CSP) to check if solutions are valid and Pareto-based measures to look for optimal solutions.","The algorithm has been tested on several datasets optimizing different variables of the mission, such as the makespan, the fuel consumption, distance, etc.","Experimental results show that the new algorithm is able to obtain good solutions, however as the problem becomes more complex, the optimal solutions also become harder to find."],"url":"http://arxiv.org/abs/2402.06504v1","category":"cs.NE"}
{"created":"2024-02-09 16:10:13","title":"BarlowTwins-CXR : Enhancing Chest X-Ray abnormality localization in heterogeneous data with cross-domain self-supervised learning","abstract":"Background: Chest X-ray imaging-based abnormality localization, essential in diagnosing various diseases, faces significant clinical challenges due to complex interpretations and the growing workload of radiologists. While recent advances in deep learning offer promising solutions, there is still a critical issue of domain inconsistency in cross-domain transfer learning, which hampers the efficiency and accuracy of diagnostic processes. This study aims to address the domain inconsistency problem and improve autonomic abnormality localization performance of heterogeneous chest X-ray image analysis, by developing a self-supervised learning strategy called \"BarlwoTwins-CXR\". Methods: We utilized two publicly available datasets: the NIH Chest X-ray Dataset and the VinDr-CXR. The BarlowTwins-CXR approach was conducted in a two-stage training process. Initially, self-supervised pre-training was performed using an adjusted Barlow Twins algorithm on the NIH dataset with a Resnet50 backbone pre-trained on ImageNet. This was followed by supervised fine-tuning on the VinDr-CXR dataset using Faster R-CNN with Feature Pyramid Network (FPN). Results: Our experiments showed a significant improvement in model performance with BarlowTwins-CXR. The approach achieved a 3% increase in mAP50 accuracy compared to traditional ImageNet pre-trained models. In addition, the Ablation CAM method revealed enhanced precision in localizing chest abnormalities. Conclusion: BarlowTwins-CXR significantly enhances the efficiency and accuracy of chest X-ray image-based abnormality localization, outperforming traditional transfer learning methods and effectively overcoming domain inconsistency in cross-domain scenarios. Our experiment results demonstrate the potential of using self-supervised learning to improve the generalizability of models in medical settings with limited amounts of heterogeneous data.","sentences":["Background: Chest X-ray imaging-based abnormality localization, essential in diagnosing various diseases, faces significant clinical challenges due to complex interpretations and the growing workload of radiologists.","While recent advances in deep learning offer promising solutions, there is still a critical issue of domain inconsistency in cross-domain transfer learning, which hampers the efficiency and accuracy of diagnostic processes.","This study aims to address the domain inconsistency problem and improve autonomic abnormality localization performance of heterogeneous chest X-ray image analysis, by developing a self-supervised learning strategy called \"BarlwoTwins-CXR\".","Methods: We utilized two publicly available datasets: the NIH Chest X-ray Dataset and the VinDr-CXR.","The BarlowTwins-CXR approach was conducted in a two-stage training process.","Initially, self-supervised pre-training was performed using an adjusted Barlow Twins algorithm on the NIH dataset with a Resnet50 backbone pre-trained on ImageNet.","This was followed by supervised fine-tuning on the VinDr-CXR dataset using Faster R-CNN with Feature Pyramid Network (FPN).","Results:","Our experiments showed a significant improvement in model performance with BarlowTwins-CXR.","The approach achieved a 3% increase in mAP50 accuracy compared to traditional ImageNet pre-trained models.","In addition, the Ablation CAM method revealed enhanced precision in localizing chest abnormalities.","Conclusion: BarlowTwins-CXR significantly enhances the efficiency and accuracy of chest X-ray image-based abnormality localization, outperforming traditional transfer learning methods and effectively overcoming domain inconsistency in cross-domain scenarios.","Our experiment results demonstrate the potential of using self-supervised learning to improve the generalizability of models in medical settings with limited amounts of heterogeneous data."],"url":"http://arxiv.org/abs/2402.06499v1","category":"cs.CV"}
{"created":"2024-02-09 16:08:16","title":"Iris-SAM: Iris Segmentation Using a Foundational Model","abstract":"Iris segmentation is a critical component of an iris biometric system and it involves extracting the annular iris region from an ocular image. In this work, we develop a pixel-level iris segmentation model from a foundational model, viz., Segment Anything Model (SAM), that has been successfully used for segmenting arbitrary objects. The primary contribution of this work lies in the integration of different loss functions during the fine-tuning of SAM on ocular images. In particular, the importance of Focal Loss is borne out in the fine-tuning process since it strategically addresses the class imbalance problem (i.e., iris versus non-iris pixels). Experiments on ND-IRIS-0405, CASIA-Iris-Interval-v3, and IIT-Delhi-Iris datasets convey the efficacy of the trained model for the task of iris segmentation. For instance, on the ND-IRIS-0405 dataset, an average segmentation accuracy of 99.58% was achieved, compared to the best baseline performance of 89.75%.","sentences":["Iris segmentation is a critical component of an iris biometric system and it involves extracting the annular iris region from an ocular image.","In this work, we develop a pixel-level iris segmentation model from a foundational model, viz., Segment Anything Model (SAM), that has been successfully used for segmenting arbitrary objects.","The primary contribution of this work lies in the integration of different loss functions during the fine-tuning of SAM on ocular images.","In particular, the importance of Focal Loss is borne out in the fine-tuning process since it strategically addresses the class imbalance problem (i.e., iris versus non-iris pixels).","Experiments on ND-IRIS-0405, CASIA-Iris-Interval-v3, and IIT-Delhi-Iris datasets convey the efficacy of the trained model for the task of iris segmentation.","For instance, on the ND-IRIS-0405 dataset, an average segmentation accuracy of 99.58% was achieved, compared to the best baseline performance of 89.75%."],"url":"http://arxiv.org/abs/2402.06497v1","category":"cs.CV"}
{"created":"2024-02-09 16:04:33","title":"Benchmarking ionization potentials from pCCD tailored coupled cluster models","abstract":"The ionization potential (IP) is an important parameter providing essential insights into the reactivity of chemical systems. IPs are also crucial for designing, optimizing, and understanding the functionality of modern technological devices. We recently showed that limiting the CC ansatz to the seniority-zero sector proves insufficient in predicting reliable and accurate ionization potentials within an IP equation-of-motion coupled-cluster formalism. Specifically, the absence of dynamic correlation in the seniority-zero pair coupled cluster doubles (pCCD) model led to unacceptably significant errors of approximately 1.5 eV. In this work, we aim to explore the impact of dynamical correlation and the choice of the molecular orbital basis (canonical vs. localized) in CC-type methods targeting 201 ionized states in 41 molecules. We focus on pCCD-based approaches as well as the conventional IP-EOM-CCD and IP-EOM-CCSD. Their performance is compared to the CCSDT equivalent and experimental reference data. Our statistical analysis reveals that all investigated frozen-pair coupled cluster methods exhibit similar performance, with differences in errors typically within chemical accuracy (1 kcal/mol or 0.05 eV). Notably, the effect of the molecular orbital basis, such as canonical Hartree-Fock or natural pCCD-optimized orbitals, on the IPs is marginal if dynamical correlation is accounted for. Our study suggests that triple excitations are crucial in achieving chemical accuracy in IPs when modeling electron detachment processes with pCCD-based methods.","sentences":["The ionization potential (IP) is an important parameter providing essential insights into the reactivity of chemical systems.","IPs are also crucial for designing, optimizing, and understanding the functionality of modern technological devices.","We recently showed that limiting the CC ansatz to the seniority-zero sector proves insufficient in predicting reliable and accurate ionization potentials within an IP equation-of-motion coupled-cluster formalism.","Specifically, the absence of dynamic correlation in the seniority-zero pair coupled cluster doubles (pCCD) model led to unacceptably significant errors of approximately 1.5 eV. In this work, we aim to explore the impact of dynamical correlation and the choice of the molecular orbital basis (canonical vs. localized) in CC-type methods targeting 201 ionized states in 41 molecules.","We focus on pCCD-based approaches as well as the conventional IP-EOM-CCD and IP-EOM-CCSD.","Their performance is compared to the CCSDT equivalent and experimental reference data.","Our statistical analysis reveals that all investigated frozen-pair coupled cluster methods exhibit similar performance, with differences in errors typically within chemical accuracy (1 kcal/mol or 0.05 eV).","Notably, the effect of the molecular orbital basis, such as canonical Hartree-Fock or natural pCCD-optimized orbitals, on the IPs is marginal if dynamical correlation is accounted for.","Our study suggests that triple excitations are crucial in achieving chemical accuracy in IPs when modeling electron detachment processes with pCCD-based methods."],"url":"http://arxiv.org/abs/2402.06496v1","category":"physics.chem-ph"}
{"created":"2024-02-09 15:56:39","title":"Deep Learning-Based Auto-Segmentation of Planning Target Volume for Total Marrow and Lymph Node Irradiation","abstract":"In order to optimize the radiotherapy delivery for cancer treatment, especially when dealing with complex treatments such as Total Marrow and Lymph Node Irradiation (TMLI), the accurate contouring of the Planning Target Volume (PTV) is crucial. Unfortunately, relying on manual contouring for such treatments is time-consuming and prone to errors. In this paper, we investigate the application of Deep Learning (DL) to automate the segmentation of the PTV in TMLI treatment, building upon previous work that introduced a solution to this problem based on a 2D U-Net model. We extend the previous research (i) by employing the nnU-Net framework to develop both 2D and 3D U-Net models and (ii) by evaluating the trained models on the PTV with the exclusion of bones, which consist mainly of lymp-nodes and represent the most challenging region of the target volume to segment. Our result show that the introduction of nnU-NET framework led to statistically significant improvement in the segmentation performance. In addition, the analysis on the PTV after the exclusion of bones showed that the models are quite robust also on the most challenging areas of the target volume. Overall, our study is a significant step forward in the application of DL in a complex radiotherapy treatment such as TMLI, offering a viable and scalable solution to increase the number of patients who can benefit from this treatment.","sentences":["In order to optimize the radiotherapy delivery for cancer treatment, especially when dealing with complex treatments such as Total Marrow and Lymph Node Irradiation (TMLI), the accurate contouring of the Planning Target Volume (PTV) is crucial.","Unfortunately, relying on manual contouring for such treatments is time-consuming and prone to errors.","In this paper, we investigate the application of Deep Learning (DL) to automate the segmentation of the PTV in TMLI treatment, building upon previous work that introduced a solution to this problem based on a 2D U-Net model.","We extend the previous research (i) by employing the nnU-Net framework to develop both 2D and 3D U-Net models and (ii) by evaluating the trained models on the PTV with the exclusion of bones, which consist mainly of lymp-nodes and represent the most challenging region of the target volume to segment.","Our result show that the introduction of nnU-NET framework led to statistically significant improvement in the segmentation performance.","In addition, the analysis on the PTV after the exclusion of bones showed that the models are quite robust also on the most challenging areas of the target volume.","Overall, our study is a significant step forward in the application of DL in a complex radiotherapy treatment such as TMLI, offering a viable and scalable solution to increase the number of patients who can benefit from this treatment."],"url":"http://arxiv.org/abs/2402.06494v1","category":"cs.CV"}
{"created":"2024-02-09 15:38:21","title":"Thermal transport of glasses via machine learning driven simulations","abstract":"Accessing the thermal transport properties of glasses is a major issue for the design of production strategies of glass industry, as well as for the plethora of applications and devices where glasses are employed. From the computational standpoint, the chemical and morphological complexity of glasses calls for atomistic simulations where the interatomic potentials are able to capture the variety of local environments, composition, and (dis)order that typically characterize glassy phases. Machine-learning potentials (MLPs) are emerging as a valid alternative to computationally expensive ab initio simulations, inevitably run on very small samples which cannot account for disorder at different scales, as well as to empirical force fields, fast but often reliable only in a narrow portion of the thermodynamic and composition phase diagrams. In this article, we make the point on the use of MLPs to compute the thermal conductivity of glasses, through a review of recent theoretical and computational tools and a series of numerical applications on vitreous silica and vitreous silicon, both pure and intercalated with lithium.","sentences":["Accessing the thermal transport properties of glasses is a major issue for the design of production strategies of glass industry, as well as for the plethora of applications and devices where glasses are employed.","From the computational standpoint, the chemical and morphological complexity of glasses calls for atomistic simulations where the interatomic potentials are able to capture the variety of local environments, composition, and (dis)order that typically characterize glassy phases.","Machine-learning potentials (MLPs) are emerging as a valid alternative to computationally expensive ab initio simulations, inevitably run on very small samples which cannot account for disorder at different scales, as well as to empirical force fields, fast but often reliable only in a narrow portion of the thermodynamic and composition phase diagrams.","In this article, we make the point on the use of MLPs to compute the thermal conductivity of glasses, through a review of recent theoretical and computational tools and a series of numerical applications on vitreous silica and vitreous silicon, both pure and intercalated with lithium."],"url":"http://arxiv.org/abs/2402.06479v1","category":"cond-mat.dis-nn"}
{"created":"2024-02-09 15:38:03","title":"Critical Graph of a Polynomial Quadratic Differential related to a Schr\u00f6dinger Equation with Cubic Oscillator : WKB Approach","abstract":"In this paper, we give a full description of the critical graph of the quadratic differential $\\varpi_{a,\\theta}$ defined on the Riemann sphere $\\widehat{% %TCIMACRO{\\U{2102} }% %BeginExpansion \\mathbb{C} %EndExpansion }$ by $\\varpi_{a,\\theta}=-e^{2i\\theta}\\left( z-a\\right) \\left( z^{2}-1\\right) dz^{2},$ where $\\theta\\in% %TCIMACRO{\\U{211d} }% %BeginExpansion \\mathbb{R} %EndExpansion ,$ and $a\\in% %TCIMACRO{\\U{2102} }% %BeginExpansion \\mathbb{C} %EndExpansion .$. We prove that the existence and the number of short trajectories of $\\varpi_{a,\\theta}$ depend on the location of $a$ in certain curves defined on the complex plane as the level sets of some harmonic functions. More focus will be to the cases $\\theta\\in\\left\\{ 0,\\pi/4\\right\\} .$ We investigate these classifications to study an inverse spectral problem related to the complex cubic oscillator for Schr\\\"{o}dinger equation.","sentences":["In this paper, we give a full description of the critical graph of the quadratic differential $\\varpi_{a,\\theta}$ defined on the Riemann sphere $\\widehat{% %TCIMACRO{\\U{2102} }%","%BeginExpansion \\mathbb{C} %EndExpansion }$ by $\\varpi_{a,\\theta}=-e^{2i\\theta}\\left( z-a\\right) \\left( z^{2}-1\\right) dz^{2},$ where $\\theta\\in% %TCIMACRO{\\U{211d} }% %BeginExpansion \\mathbb{R} %EndExpansion ,$ and $a\\in% %TCIMACRO{\\U{2102} }% %","BeginExpansion \\mathbb{C} %EndExpansion .$.","We prove that the existence and the number of short trajectories of $\\varpi_{a,\\theta}$ depend on the location of $a$ in certain curves defined on the complex plane as the level sets of some harmonic functions.","More focus will be to the cases $\\theta\\in\\left\\{ 0,\\pi/4\\right\\} .$","We investigate these classifications to study an inverse spectral problem related to the complex cubic oscillator for Schr\\\"{o}dinger equation."],"url":"http://arxiv.org/abs/2402.06478v1","category":"math.CA"}
{"created":"2024-02-09 15:37:30","title":"Semiclassical measures for complex hyperbolic quotients","abstract":"We study semiclassical measures for Laplacian eigenfunctions on compact complex hyperbolic quotients. Geodesic flows on these quotients are a model case of hyperbolic dynamical systems with different expansion/contraction rates in different directions. We show that the support of any semiclassical measure is either equal to the entire cosphere bundle or contains the cosphere bundle of a compact immersed totally geodesic complex submanifold.   The proof uses the one-dimensional fractal uncertainty principle of Bourgain-Dyatlov [arXiv:1612.09040] along the fast expanding/contracting directions, in a way similar to the work of Dyatlov-J\\'ez\\'equel [arXiv:2108.10463] in the toy model of quantum cat maps, together with a description of the closures of fast unstable/stable trajectories relying on Ratner theory.","sentences":["We study semiclassical measures for Laplacian eigenfunctions on compact complex hyperbolic quotients.","Geodesic flows on these quotients are a model case of hyperbolic dynamical systems with different expansion/contraction rates in different directions.","We show that the support of any semiclassical measure is either equal to the entire cosphere bundle or contains the cosphere bundle of a compact immersed totally geodesic complex submanifold.   ","The proof uses the one-dimensional fractal uncertainty principle of Bourgain-Dyatlov [arXiv:1612.09040] along the fast expanding/contracting directions, in a way similar to the work of Dyatlov-J\\'ez\\'equel","[arXiv:2108.10463] in the toy model of quantum cat maps, together with a description of the closures of fast unstable/stable trajectories relying on Ratner theory."],"url":"http://arxiv.org/abs/2402.06477v1","category":"math.AP"}
{"created":"2024-02-09 15:35:18","title":"Devolatilization of extrasolar planetesimals by 60Fe and 26Al heating","abstract":"Whilst the formation of Solar system planets is constrained by meteoritic evidence, the geophysical history of low-mass exoplanets is much less clear. The bulk composition and climate states of rocky exoplanets may vary significantly based on the composition and properties of the planetesimals they form from. An important factor influenced by planetesimal composition is water content, where the desiccation of accreting planetesimals impacts the final water content of the resultant planets. While the inner planets of the Solar system are comparatively water-poor, recent observational evidence from exoplanet bulk densities and planetary formation models suggest that rocky exoplanets engulfed by substantial layers of high-pressure ices or massive steam atmospheres could be widespread. Here we quantify variations in planetesimal desiccation due to potential fractionation of the two short-lived radioisotopes 26Al and 60Fe relevant for internal heating on planetary formation timescales. We focus on how order of magnitude variations in 60Fe can affect the water content of planetesimals, and how this may alter the formation of extrasolar ocean worlds. We find that heating by 26Al is the dominant cause of planetesimal heating in any Solar system analogue scenario, thus validating previous works focussing only on this radioisotope. However, 60Fe can become the primary heating source in the case of high levels of supernova enrichment in massive star-forming regions. These diverging scenarios can affect the formation pathways, bulk volatile budget, and climate diversity of low-mass exoplanets.","sentences":["Whilst the formation of Solar system planets is constrained by meteoritic evidence, the geophysical history of low-mass exoplanets is much less clear.","The bulk composition and climate states of rocky exoplanets may vary significantly based on the composition and properties of the planetesimals they form from.","An important factor influenced by planetesimal composition is water content, where the desiccation of accreting planetesimals impacts the final water content of the resultant planets.","While the inner planets of the Solar system are comparatively water-poor, recent observational evidence from exoplanet bulk densities and planetary formation models suggest that rocky exoplanets engulfed by substantial layers of high-pressure ices or massive steam atmospheres could be widespread.","Here we quantify variations in planetesimal desiccation due to potential fractionation of the two short-lived radioisotopes 26Al and 60Fe relevant for internal heating on planetary formation timescales.","We focus on how order of magnitude variations in 60Fe can affect the water content of planetesimals, and how this may alter the formation of extrasolar ocean worlds.","We find that heating by 26Al is the dominant cause of planetesimal heating in any Solar system analogue scenario, thus validating previous works focussing only on this radioisotope.","However, 60Fe can become the primary heating source in the case of high levels of supernova enrichment in massive star-forming regions.","These diverging scenarios can affect the formation pathways, bulk volatile budget, and climate diversity of low-mass exoplanets."],"url":"http://arxiv.org/abs/2402.06476v1","category":"astro-ph.EP"}
{"created":"2024-02-09 15:24:13","title":"Population Protocols for Exact Plurality Consensus -- How a small chance of failure helps to eliminate insignificant opinions","abstract":"We consider the \\emph{exact plurality consensus} problem for \\emph{population protocols}. Here, $n$ anonymous agents start each with one of $k$ opinions. Their goal is to agree on the initially most frequent opinion (the \\emph{plurality opinion}) via random, pairwise interactions. The case of $k = 2$ opinions is known as the \\emph{majority problem}. Recent breakthroughs led to an always correct, exact majority population protocol that is both time- and space-optimal, needing $O(\\log n)$ states per agent and, with high probability, $O(\\log n)$ time~[Doty, Eftekhari, Gasieniec, Severson, Stachowiak, and Uznanski; 2021]. We know that any always correct protocol requires $\\Omega(k^2)$ states, while the currently best protocol needs $O(k^{11})$ states~[Natale and Ramezani; 2019]. For ordered opinions, this can be improved to $O(k^6)$~[Gasieniec, Hamilton, Martin, Spirakis, and Stachowiak; 2016]. We design protocols for plurality consensus that beat the quadratic lower bound by allowing a negligible failure probability. While our protocols might fail, they identify the plurality opinion with high probability even if the bias is $1$. Our first protocol achieves this via $k-1$ tournaments in time $O(k \\cdot \\log n)$ using $O(k + \\log n)$ states. While it assumes an ordering on the opinions, we remove this restriction in our second protocol, at the cost of a slightly increased time $O(k \\cdot \\log n + \\log^2 n)$. By efficiently pruning insignificant opinions, our final protocol reduces the number of tournaments at the cost of a slightly increased state complexity $O(k \\cdot \\log\\log n + \\log n)$. This improves the time to $O(n / x_{\\max} \\cdot \\log n + \\log^2 n)$, where $x_{\\max}$ is the initial size of the plurality. Note that $n/x_{\\max}$ is at most $k$ and can be much smaller (e.g., in case of a large bias or if there are many small opinions).","sentences":["We consider the \\emph{exact plurality consensus} problem for \\emph{population protocols}.","Here, $n$ anonymous agents start each with one of $k$ opinions.","Their goal is to agree on the initially most frequent opinion (the \\emph{plurality opinion}) via random, pairwise interactions.","The case of $k = 2$ opinions is known as the \\emph{majority problem}.","Recent breakthroughs led to an always correct, exact majority population protocol that is both time- and space-optimal, needing $O(\\log n)$ states per agent and, with high probability, $O(\\log n)$ time~[Doty, Eftekhari, Gasieniec, Severson, Stachowiak, and Uznanski; 2021].","We know that any always correct protocol requires $\\Omega(k^2)$ states, while the currently best protocol needs $O(k^{11})$ states~[Natale and Ramezani; 2019].","For ordered opinions, this can be improved to $O(k^6)$~[Gasieniec, Hamilton, Martin, Spirakis, and Stachowiak; 2016].","We design protocols for plurality consensus that beat the quadratic lower bound by allowing a negligible failure probability.","While our protocols might fail, they identify the plurality opinion with high probability even if the bias is $1$. Our first protocol achieves this via $k-1$ tournaments in time $O(k \\cdot \\log n)$ using $O(k + \\log n)$ states.","While it assumes an ordering on the opinions, we remove this restriction in our second protocol, at the cost of a slightly increased time $O(k \\cdot \\log n + \\log^2","n)$. By efficiently pruning insignificant opinions, our final protocol reduces the number of tournaments at the cost of a slightly increased state complexity $O(k \\cdot \\log\\log n + \\log n)$. This improves the time to $O(n / x_{\\max} \\cdot \\log n + \\log^2 n)$, where $x_{\\max}$ is the initial size of the plurality.","Note that $n/x_{\\max}$ is at most $k$ and can be much smaller (e.g., in case of a large bias or if there are many small opinions)."],"url":"http://arxiv.org/abs/2402.06471v1","category":"cs.DC"}
{"created":"2024-02-09 15:22:46","title":"Deuterated Polystyrene -- Synthesis and uses for ultracold neutron bottles and the neutron EDM experiment","abstract":"The synthesis and application of deuterated polystyrene (dps) films is discussed. Ultracold neutron storage properties and the Fermi potential of dps films is measured with the result that Tstore=700 +/- 200 sec for dps in the bottle used and the Fermi potential is about 165neV. The behavior under application of high electric fields in vacuum is measured; the films are sufficiently stable to use in a neutron EDM bottle. Also, the relaxation rate of nuclear spin polarized 199Hg on dps films is measured giving a wall lifetime of 20 sec/cm mean free path, which should make the development of an Hg volume magnetometer possible.","sentences":["The synthesis and application of deuterated polystyrene (dps) films is discussed.","Ultracold neutron storage properties and the Fermi potential of dps films is measured with the result that Tstore=700 +/- 200 sec for dps in the bottle used and the Fermi potential is about 165neV.","The behavior under application of high electric fields in vacuum is measured; the films are sufficiently stable to use in a neutron EDM bottle.","Also, the relaxation rate of nuclear spin polarized 199Hg on dps films is measured giving a wall lifetime of 20 sec/cm mean free path, which should make the development of an Hg volume magnetometer possible."],"url":"http://arxiv.org/abs/2402.06469v1","category":"hep-ex"}
{"created":"2024-02-09 15:19:44","title":"Configuration models for random directed hypergraphs","abstract":"Many complex systems show non-pairwise interactions, which can be captured by hypergraphs. In this work, we establish configuration models in which both the vertex and the hyperarc degrees are preserved for different classes of directed hypergraphs (containing self-loops, degenerate hyperarcs and/or multiple hyperarcs). We propose an edge-swapping method to uniformly sample from these configuration models and prove that this method indeed samples uniformly from the classes with self-loops and multiple hyperarcs, and that the method does not sample uniformly from classes without self-loops, or with self-loops and degenerate hyperarcs but without multiple hyperarcs. We present a partial result on the class with self-loops, but without degenerate hyperarcs or multiple hyperarcs.","sentences":["Many complex systems show non-pairwise interactions, which can be captured by hypergraphs.","In this work, we establish configuration models in which both the vertex and the hyperarc degrees are preserved for different classes of directed hypergraphs (containing self-loops, degenerate hyperarcs and/or multiple hyperarcs).","We propose an edge-swapping method to uniformly sample from these configuration models and prove that this method indeed samples uniformly from the classes with self-loops and multiple hyperarcs, and that the method does not sample uniformly from classes without self-loops, or with self-loops and degenerate hyperarcs but without multiple hyperarcs.","We present a partial result on the class with self-loops, but without degenerate hyperarcs or multiple hyperarcs."],"url":"http://arxiv.org/abs/2402.06466v1","category":"math.CO"}
{"created":"2024-02-09 15:01:56","title":"Quantum Computing and Tensor Networks for Laminate Design: A Novel Approach to Stacking Sequence Retrieval","abstract":"As with many tasks in engineering, structural design frequently involves navigating complex and computationally expensive problems. A prime example is the weight optimization of laminated composite materials, which to this day remains a formidable task, due to an exponentially large configuration space and non-linear constraints. The rapidly developing field of quantum computation may offer novel approaches for addressing these intricate problems. However, before applying any quantum algorithm to a given problem, it must be translated into a form that is compatible with the underlying operations on a quantum computer. Our work specifically targets stacking sequence retrieval with lamination parameters. To adapt this problem for quantum computational methods, we map the possible stacking sequences onto a quantum state space. We further derive a linear operator, the Hamiltonian, within this state space that encapsulates the loss function inherent to the stacking sequence retrieval problem. Additionally, we demonstrate the incorporation of manufacturing constraints on stacking sequences as penalty terms in the Hamiltonian. This quantum representation is suitable for a variety of classical and quantum algorithms for finding the ground state of a quantum Hamiltonian. For a practical demonstration, we chose a classical tensor network algorithm, the DMRG algorithm, to numerically validate our approach. For this purpose, we derived a matrix product operator representation of the loss function Hamiltonian and the penalty terms. Numerical trials with this algorithm successfully yielded approximate solutions, while exhibiting a tradeoff between accuracy and runtime. Although this work primarily concentrates on quantum computation, the application of tensor network algorithms presents a novel quantum-inspired approach for stacking sequence retrieval.","sentences":["As with many tasks in engineering, structural design frequently involves navigating complex and computationally expensive problems.","A prime example is the weight optimization of laminated composite materials, which to this day remains a formidable task, due to an exponentially large configuration space and non-linear constraints.","The rapidly developing field of quantum computation may offer novel approaches for addressing these intricate problems.","However, before applying any quantum algorithm to a given problem, it must be translated into a form that is compatible with the underlying operations on a quantum computer.","Our work specifically targets stacking sequence retrieval with lamination parameters.","To adapt this problem for quantum computational methods, we map the possible stacking sequences onto a quantum state space.","We further derive a linear operator, the Hamiltonian, within this state space that encapsulates the loss function inherent to the stacking sequence retrieval problem.","Additionally, we demonstrate the incorporation of manufacturing constraints on stacking sequences as penalty terms in the Hamiltonian.","This quantum representation is suitable for a variety of classical and quantum algorithms for finding the ground state of a quantum Hamiltonian.","For a practical demonstration, we chose a classical tensor network algorithm, the DMRG algorithm, to numerically validate our approach.","For this purpose, we derived a matrix product operator representation of the loss function Hamiltonian and the penalty terms.","Numerical trials with this algorithm successfully yielded approximate solutions, while exhibiting a tradeoff between accuracy and runtime.","Although this work primarily concentrates on quantum computation, the application of tensor network algorithms presents a novel quantum-inspired approach for stacking sequence retrieval."],"url":"http://arxiv.org/abs/2402.06455v1","category":"quant-ph"}
{"created":"2024-02-09 15:00:50","title":"Emergent Fano-Feshbach resonance in two-band superconductors with an incipient quasi-flat band: Enhanced critical temperature evading particle-hole fluctuations","abstract":"In superconductivity, a surge of interests in enhancing $T_{\\rm c}$ is ever mounting, where a recent focus is toward multi-band superconductivity. In $T_{\\rm c}$ enhancements specific to two-band cases, especially around the Bardeen-Cooper-Schrieffer (BCS) to Bose-Einstein condensate (BEC) crossover considered here, we have to be careful about how quantum fluctuations affect the many-body states, i.e., particle-hole fluctuations suppressing the pairing for attractive interactions. Here we explore how to circumvent the suppression by examining multichannel pairing interactions in two-band systems. With the Gor'kov-Melik-Barkhudarov (GMB) formalism for particle-hole fluctuations in a continuous space, we look into the case of a deep dispersive band accompanied by an incipient heavy-mass (i.e., quasi-flat) band. We find that, while the GMB corrections usually suppress $T_{\\rm c}$ significantly, this in fact competes with the enhanced pairing arising from the heavy band, with the trade-off leading to a peaked structure in $T_{\\rm c}$ against the band-mass ratio when the heavy band is incipient. The system then plunges into a strong-coupling regime with the GMB screening vastly suppressed. This occurs prominently when the chemical potential approaches the bound state lurking just below the heavy band, which can be viewed as a Fano-Feshbach resonance, with its width governed by the pair-exchange interaction. The diagrammatic structure comprising particle-particle and particle-hole channels is heavily entangled, so that the emergent Fano-Feshbach resonance dominates all the channels, suggesting a universal feature in multiband superconductivity.","sentences":["In superconductivity, a surge of interests in enhancing $T_{\\rm c}$ is ever mounting, where a recent focus is toward multi-band superconductivity.","In $T_{\\rm c}$ enhancements specific to two-band cases, especially around the Bardeen-Cooper-Schrieffer (BCS) to Bose-Einstein condensate (BEC) crossover considered here, we have to be careful about how quantum fluctuations affect the many-body states, i.e., particle-hole fluctuations suppressing the pairing for attractive interactions.","Here we explore how to circumvent the suppression by examining multichannel pairing interactions in two-band systems.","With the Gor'kov-Melik-Barkhudarov (GMB) formalism for particle-hole fluctuations in a continuous space, we look into the case of a deep dispersive band accompanied by an incipient heavy-mass (i.e., quasi-flat) band.","We find that, while the GMB corrections usually suppress $T_{\\rm c}$ significantly, this in fact competes with the enhanced pairing arising from the heavy band, with the trade-off leading to a peaked structure in $T_{\\rm c}$ against the band-mass ratio when the heavy band is incipient.","The system then plunges into a strong-coupling regime with the GMB screening vastly suppressed.","This occurs prominently when the chemical potential approaches the bound state lurking just below the heavy band, which can be viewed as a Fano-Feshbach resonance, with its width governed by the pair-exchange interaction.","The diagrammatic structure comprising particle-particle and particle-hole channels is heavily entangled, so that the emergent Fano-Feshbach resonance dominates all the channels, suggesting a universal feature in multiband superconductivity."],"url":"http://arxiv.org/abs/2402.06454v1","category":"cond-mat.supr-con"}
{"created":"2024-02-09 14:51:25","title":"The EBLM project -- XIII. The absolute dynamical masses of the circumbinary planet host TOI-1338/BEBOP-1","abstract":"High-contrast eclipsing binaries with low mass M-dwarf secondaries are precise benchmark stars to build empirical mass-radius relationships for fully convective low-mass ($\\rm M_{*} < 0.35\\,M_{\\rm sun}$) dwarf stars. The contributed light of the M-dwarf in such binaries is usually much less than one~per~cent at optical wavelengths. This enables the detection of circumbinary planets from precise radial velocity measurements. High-resolution cross-correlation techniques are typically used to detect exoplanet atmospheres. One key aspect of these techniques is the post-processing, which includes the removal of telluric and spectral lines of the host star. We introduce the application of such techniques to optical high-resolution spectra of the circumbinary planet-host TOI-1338/BEBOP-1, turning it effectively into a double-lined eclipsing binary. By using simulations, we further explore the impact of post-processing techniques for high-contrast systems. We detect the M-dwarf secondary with a significance of 11-$\\sigma$ and measure absolute dynamical masses for both components. Compared to previous model-dependent mass measurements, we obtain a four times better precision. We further find that the post-processing results in negligible systematic impact on the radial velocity precision for TOI-1338/BEBOP-1 with more than $96.6\\,$per~cent (1-$\\sigma$) of the M-dwarf's signal being conserved. We show that these methods can be used to robustly measure dynamical masses of high-contrast single-lined binaries providing important benchmark stars for stellar evolution particularly near the bottom of the main sequence. We also demonstrate how to retrieve the phase curve of an exoplanet with high-resolution spectroscopy using our data.","sentences":["High-contrast eclipsing binaries with low mass M-dwarf secondaries are precise benchmark stars to build empirical mass-radius relationships for fully convective low-mass ($\\rm M_{*} < 0.35\\,M_{\\rm sun}$) dwarf stars.","The contributed light of the M-dwarf in such binaries is usually much less than one~per~cent at optical wavelengths.","This enables the detection of circumbinary planets from precise radial velocity measurements.","High-resolution cross-correlation techniques are typically used to detect exoplanet atmospheres.","One key aspect of these techniques is the post-processing, which includes the removal of telluric and spectral lines of the host star.","We introduce the application of such techniques to optical high-resolution spectra of the circumbinary planet-host TOI-1338/BEBOP-1, turning it effectively into a double-lined eclipsing binary.","By using simulations, we further explore the impact of post-processing techniques for high-contrast systems.","We detect the M-dwarf secondary with a significance of 11-$\\sigma$ and measure absolute dynamical masses for both components.","Compared to previous model-dependent mass measurements, we obtain a four times better precision.","We further find that the post-processing results in negligible systematic impact on the radial velocity precision for TOI-1338/BEBOP-1 with more than $96.6\\,$per~cent (1-$\\sigma$) of the M-dwarf's signal being conserved.","We show that these methods can be used to robustly measure dynamical masses of high-contrast single-lined binaries providing important benchmark stars for stellar evolution particularly near the bottom of the main sequence.","We also demonstrate how to retrieve the phase curve of an exoplanet with high-resolution spectroscopy using our data."],"url":"http://arxiv.org/abs/2402.06449v1","category":"astro-ph.EP"}
{"created":"2024-02-09 14:37:28","title":"Penrose method for Kuramoto model with inertia and noise","abstract":"Using the Penrose method of instability analysis, we consider the synchronization transition in the Kuramoto model with inertia and noise with all-to-all couplings. Analyzing the Penrose curves, we identify the appearance of cluster and chimera states in the presence of noise. We observe that noise can destroy chimera and biclusters states. The critical coupling describing bifurcation from incoherent to coherent state is found analytically. To confirm our propositions based on the Penrose method, we perform numerical simulations.","sentences":["Using the Penrose method of instability analysis, we consider the synchronization transition in the Kuramoto model with inertia and noise with all-to-all couplings.","Analyzing the Penrose curves, we identify the appearance of cluster and chimera states in the presence of noise.","We observe that noise can destroy chimera and biclusters states.","The critical coupling describing bifurcation from incoherent to coherent state is found analytically.","To confirm our propositions based on the Penrose method, we perform numerical simulations."],"url":"http://arxiv.org/abs/2402.06442v1","category":"nlin.AO"}
{"created":"2024-02-09 14:25:44","title":"Weak global attractor for the $3D$-Navier-Stokes equations via the globally modified Navier-Stokes equations","abstract":"In this paper we obtain the existence of a weak global attractor for the three-dimensional Navier-Stokes equations, that is, a weakly compact set with an invariance property, that uniformly attracts solutions, with respect to the weak topology, for initial data in bounded sets. To that end, we define this weak global attractor in terms of limits of solutions of the globally modified Navier-Stokes equations in the weak topology. We use the theory of semilinear parabolic equations and $\\epsilon$-regularity to obtain the local well posedness for the globally modified Navier-Stokes equations and the existence of a global attractor and its regularity.","sentences":["In this paper we obtain the existence of a weak global attractor for the three-dimensional Navier-Stokes equations, that is, a weakly compact set with an invariance property, that uniformly attracts solutions, with respect to the weak topology, for initial data in bounded sets.","To that end, we define this weak global attractor in terms of limits of solutions of the globally modified Navier-Stokes equations in the weak topology.","We use the theory of semilinear parabolic equations and $\\epsilon$-regularity to obtain the local well posedness for the globally modified Navier-Stokes equations and the existence of a global attractor and its regularity."],"url":"http://arxiv.org/abs/2402.06435v1","category":"math.AP"}
{"created":"2024-02-09 14:19:14","title":"Polyarc bounded complex interval arithmetic","abstract":"Complex interval arithmetic is a powerful tool for the analysis of computational errors. The naturally arising rectangular, polar, and circular (together called primitive) interval types are not closed under simple arithmetic operations and their use yields overly relaxed bounds. The later introduced polygonal type, on the other hand, allows for arbitrarily precise representaion of the above operations for a higher computational cost. We propose the polyarcular interval type as an effective extension of the previous types. The polyarcular interval can represent all primitive intervals and most of their arithmetic combinations precisely and has a approximation capability competing with that of the polygonal interval. In particular, in antenna tolerance analysis it can achieve perfect accuracy for lower computational cost then the polygonal type, which we show in a relevant case study. In this paper, we present a rigorous analysis of the arithmetic properties of all five interval types, involving a new algebro-geometric method of boundary analysis.","sentences":["Complex interval arithmetic is a powerful tool for the analysis of computational errors.","The naturally arising rectangular, polar, and circular (together called primitive) interval types are not closed under simple arithmetic operations and their use yields overly relaxed bounds.","The later introduced polygonal type, on the other hand, allows for arbitrarily precise representaion of the above operations for a higher computational cost.","We propose the polyarcular interval type as an effective extension of the previous types.","The polyarcular interval can represent all primitive intervals and most of their arithmetic combinations precisely and has a approximation capability competing with that of the polygonal interval.","In particular, in antenna tolerance analysis it can achieve perfect accuracy for lower computational cost then the polygonal type, which we show in a relevant case study.","In this paper, we present a rigorous analysis of the arithmetic properties of all five interval types, involving a new algebro-geometric method of boundary analysis."],"url":"http://arxiv.org/abs/2402.06430v1","category":"math.NA"}
{"created":"2024-02-09 14:16:29","title":"Smooth Transformation Models for Survival Analysis: A Tutorial Using R","abstract":"Over the last five decades, we have seen strong methodological advances in survival analysis, mainly in two separate strands: One strand is based on a parametric approach that assumes some response distribution. More prominent, however, is the strand of flexible methods which rely mainly on non-/semi-parametric estimation. As the methodological landscape continues to evolve, the task of navigating through the multitude of methods and identifying corresponding available software resources is becoming increasingly difficult. This task becomes particularly challenging in more complex scenarios, such as when dealing with interval-censored or clustered survival data, non-proportionality, or dependent censoring.   In this tutorial, we explore the potential of using smooth transformation models for survival analysis in the R system for statistical computing. These models provide a unified maximum likelihood framework that covers a range of survival models, including well-established ones such as the Weibull model and a fully parameterised version of the famous Cox proportional hazards model, as well as extensions to more complex scenarios. We explore smooth transformation models for non-proportional/crossing hazards, dependent censoring, clustered observations and extensions towards personalised medicine within this framework.   By fitting these models to survival data from a two-arm randomised controlled trial on rectal cancer therapy, we demonstrate how survival analysis tasks can be seamlessly navigated within the smooth transformation model framework in R. This is achieved by the implementation provided by the \"tram\" package and few related packages.","sentences":["Over the last five decades, we have seen strong methodological advances in survival analysis, mainly in two separate strands: One strand is based on a parametric approach that assumes some response distribution.","More prominent, however, is the strand of flexible methods which rely mainly on non-/semi-parametric estimation.","As the methodological landscape continues to evolve, the task of navigating through the multitude of methods and identifying corresponding available software resources is becoming increasingly difficult.","This task becomes particularly challenging in more complex scenarios, such as when dealing with interval-censored or clustered survival data, non-proportionality, or dependent censoring.   ","In this tutorial, we explore the potential of using smooth transformation models for survival analysis in the R system for statistical computing.","These models provide a unified maximum likelihood framework that covers a range of survival models, including well-established ones such as the Weibull model and a fully parameterised version of the famous Cox proportional hazards model, as well as extensions to more complex scenarios.","We explore smooth transformation models for non-proportional/crossing hazards, dependent censoring, clustered observations and extensions towards personalised medicine within this framework.   ","By fitting these models to survival data from a two-arm randomised controlled trial on rectal cancer therapy, we demonstrate how survival analysis tasks can be seamlessly navigated within the smooth transformation model framework in R. This is achieved by the implementation provided by the \"tram\" package and few related packages."],"url":"http://arxiv.org/abs/2402.06428v1","category":"stat.ME"}
{"created":"2024-02-09 14:14:25","title":"Structure-Preserving Discretization and Model Order Reduction of Boundary-Controlled 1D Port-Hamiltonian Systems","abstract":"This paper presents a methodology for the discretization and reduction of a class of one-dimensional Partial Differential Equations (PDEs) with inputs and outputs collocated at the spatial boundaries. The class of system that we consider is known as Boundary-Controlled Port-Hamiltonian Systems (BC-PHSs) and covers a wide class of Hyperbolic PDEs with a large type of boundary inputs and outputs. This is for instance the case of waves and beams with Neumann or Dirichlet boundary conditions at both sides and mixed boundary conditions. In addition, we recall the Loewner framework to reduce the discretized model. We show that if the initial PDE is {\\it passive}, the discretized model is also. Moreover, if the initial PDE is {\\it impedance energy preserving}, the discretized model is also. The {\\it passive} structure is also preserved in the reduced-order if the selected frequency data has positive real part. We use the one-dimensional wave equation and the Timoshenko beam as examples to show the versatility of the proposed approach.","sentences":["This paper presents a methodology for the discretization and reduction of a class of one-dimensional Partial Differential Equations (PDEs) with inputs and outputs collocated at the spatial boundaries.","The class of system that we consider is known as Boundary-Controlled Port-Hamiltonian Systems (BC-PHSs) and covers a wide class of Hyperbolic PDEs with a large type of boundary inputs and outputs.","This is for instance the case of waves and beams with Neumann or Dirichlet boundary conditions at both sides and mixed boundary conditions.","In addition, we recall the Loewner framework to reduce the discretized model.","We show that if the initial PDE is {\\it passive}, the discretized model is also.","Moreover, if the initial PDE is {\\it impedance energy preserving}, the discretized model is also.","The {\\it passive} structure is also preserved in the reduced-order if the selected frequency data has positive real part.","We use the one-dimensional wave equation and the Timoshenko beam as examples to show the versatility of the proposed approach."],"url":"http://arxiv.org/abs/2402.06425v1","category":"math.NA"}
{"created":"2024-02-09 14:08:01","title":"Radiationless Decay Spectrum of O 1s Double Core Holes in Liquid Water","abstract":"We present a combined experimental and theoretical investigation of the radiationless decay spectrum of an O 1s double core hole in liquid water. Our experiments were carried out using liquid-jet electron spectroscopy from cylindrical microjets of normal and deuterated water. The signal of the double-core-hole spectral fingerprints (hypersatellites) of liquid water was clearly identified, with an intensity ratio to Auger decay of singly charged O 1s of 0.0014(5). We observed a significant isotope effect between liquid H$_2$O and D$_2$O. For theoretical modeling, the Auger electron spectrum of the central water molecule in a water pentamer was calculated using an electronic-structure toolkit combined with molecular-dynamics simulations to capture the influence of molecular rearrangement on the ultra-short lifetime of the double core hole. We obtained the static and dynamic Auger spectra for H$_2$O, (H$_2$O)$_5$, D$_2$O, and (D$_2$O)$_5$, instantaneous Auger spectra at selected times after core-level ionization, and the symmetrized oxygen-hydrogen distance as a function of time after double core ionization for all four prototypical systems. We consider this observation of liquid-water double core holes as a new tool to study ultrafast nuclear dynamics.","sentences":["We present a combined experimental and theoretical investigation of the radiationless decay spectrum of an O 1s","double core hole in liquid water.","Our experiments were carried out using liquid-jet electron spectroscopy from cylindrical microjets of normal and deuterated water.","The signal of the double-core-hole spectral fingerprints (hypersatellites) of liquid water was clearly identified, with an intensity ratio to Auger decay of singly charged O 1s of 0.0014(5).","We observed a significant isotope effect between liquid H$_2$O and D$_2$O.","For theoretical modeling, the Auger electron spectrum of the central water molecule in a water pentamer was calculated using an electronic-structure toolkit combined with molecular-dynamics simulations to capture the influence of molecular rearrangement on the ultra-short lifetime of the double core hole.","We obtained the static and dynamic Auger spectra for H$_2$O, (H$_2$O)$_5$, D$_2$O, and (D$_2$O)$_5$, instantaneous Auger spectra at selected times after core-level ionization, and the symmetrized oxygen-hydrogen distance as a function of time after double core ionization for all four prototypical systems.","We consider this observation of liquid-water double core holes as a new tool to study ultrafast nuclear dynamics."],"url":"http://arxiv.org/abs/2402.06419v1","category":"physics.chem-ph"}
{"created":"2024-02-09 13:57:02","title":"Exploiting spatial diversity for increasing the robustness of sound source localization systems against reverberation","abstract":"Acoustic reverberation is one of the most relevant factors that hampers the localization of a sound source inside a room. To date, several approaches have been proposed to deal with it, but have not always been evaluated under realistic conditions. This paper proposes exploiting spatial diversity as an alternative approach to achieve robustness against reverberation. The theoretical arguments supporting this approach are first presented and later confirmed by means of simulation results and real measurements. Simulations are run for reverberation times up to 2 s, thus providing results with a wider range of validity than in other previous research works. It is concluded that the use of systems consisting of several, sufficiently separated, small arrays leads to the best results in reverberant environments. Some recommendations are given regarding the choice of the array sizes, the separation among them, and the way to combine SRP-PHAT maps obtained from diverse arrays.","sentences":["Acoustic reverberation is one of the most relevant factors that hampers the localization of a sound source inside a room.","To date, several approaches have been proposed to deal with it, but have not always been evaluated under realistic conditions.","This paper proposes exploiting spatial diversity as an alternative approach to achieve robustness against reverberation.","The theoretical arguments supporting this approach are first presented and later confirmed by means of simulation results and real measurements.","Simulations are run for reverberation times up to 2 s, thus providing results with a wider range of validity than in other previous research works.","It is concluded that the use of systems consisting of several, sufficiently separated, small arrays leads to the best results in reverberant environments.","Some recommendations are given regarding the choice of the array sizes, the separation among them, and the way to combine SRP-PHAT maps obtained from diverse arrays."],"url":"http://arxiv.org/abs/2402.06411v1","category":"cs.SD"}
{"created":"2024-02-09 13:45:29","title":"Summary of CKM 2023 Working Group 7: \"Mixing and CP violation in the D system: $x_D$, $y_D$, $|q/p|_D$, $\u03c6_D$, DCPV in $D$ decays\"","abstract":"We summarize the results of Working Group 7 at the 12th International Workshop on the CKM Unitarity Triangle (CKM 2023) which took place in Santiago de Compostela, Spain, 18--22 September 2023.","sentences":["We summarize the results of Working Group 7 at the 12th International Workshop on the CKM Unitarity Triangle (CKM 2023) which took place in Santiago de Compostela, Spain, 18--22 September 2023."],"url":"http://arxiv.org/abs/2402.06406v1","category":"hep-ph"}
{"created":"2024-02-09 13:32:15","title":"Differential inclusions, polycrystals and stability under lamination","abstract":"We study approximate solutions to a differential inclusion associated to a certain system of pdes in dimension three. The only datum is a set of three positive numbers identified with a positive definite diagonal matrix $S$. The average fields naturally belong to the convex hull of the set of points obtained by the triple $S$ and its permutations. We find a set of attainable average fields strictly contained in the convex hull and stable under lamination. The corresponding microgeometries are laminates of infinite rank which have an algebraic characterization that may be of independent interest. The original motivation comes from polycrystalline linearly conducting composites. As a by-product, our result establishes the optimality of a large class of microgeometries for the effective conductivity of such materials.","sentences":["We study approximate solutions to a differential inclusion associated to a certain system of pdes in dimension three.","The only datum is a set of three positive numbers identified with a positive definite diagonal matrix $S$. The average fields naturally belong to the convex hull of the set of points obtained by the triple $S$ and its permutations.","We find a set of attainable average fields strictly contained in the convex hull and stable under lamination.","The corresponding microgeometries are laminates of infinite rank which have an algebraic characterization that may be of independent interest.","The original motivation comes from polycrystalline linearly conducting composites.","As a by-product, our result establishes the optimality of a large class of microgeometries for the effective conductivity of such materials."],"url":"http://arxiv.org/abs/2402.06401v1","category":"math.AP"}
{"created":"2024-02-09 13:24:29","title":"A Statistical Model of Bursty Mixed Gaussian-impulsive Noise: Model and Parameter Estimation","abstract":"Non-Gaussian impulsive noise (IN) with memory exists in many practical applications. When it is mixed with white Gaussian noise (WGN), the resultant mixed noise will be bursty. The performance of communication systems will degrade significantly under bursty mixed noise if the bursty characteristic is ignored. A proper model for the bursty mixed noise and corresponding algorithms needs to be designed to obtain desirable performance but there is no such model reported to the best of our knowledge. The important problem is addressed in the two-part paper. In the first part, we propose a closed-form heavy-tailed multivariate probability density function (PDF) that to model the bursty mixed noise. This model is the weighted addition of gaussian distribution and student distribution. Then, we present the parameter estimation method based on the empirical characteristic function of the proposed model and analyze the performance of the parameter estimation. Numerical results show that our proposed bursty mixed noise model matches the measured bursty noise well. Meanwhile, the parameters of the proposed noise model can be accurately estimated in terms of mean square error (MSE).","sentences":["Non-Gaussian impulsive noise (IN) with memory exists in many practical applications.","When it is mixed with white Gaussian noise (WGN), the resultant mixed noise will be bursty.","The performance of communication systems will degrade significantly under bursty mixed noise if the bursty characteristic is ignored.","A proper model for the bursty mixed noise and corresponding algorithms needs to be designed to obtain desirable performance but there is no such model reported to the best of our knowledge.","The important problem is addressed in the two-part paper.","In the first part, we propose a closed-form heavy-tailed multivariate probability density function (PDF) that to model the bursty mixed noise.","This model is the weighted addition of gaussian distribution and student distribution.","Then, we present the parameter estimation method based on the empirical characteristic function of the proposed model and analyze the performance of the parameter estimation.","Numerical results show that our proposed bursty mixed noise model matches the measured bursty noise well.","Meanwhile, the parameters of the proposed noise model can be accurately estimated in terms of mean square error (MSE)."],"url":"http://arxiv.org/abs/2402.06395v1","category":"eess.SP"}
{"created":"2024-02-09 13:05:55","title":"pSTL-Bench: A Micro-Benchmark Suite for Assessing Scalability of C++ Parallel STL Implementations","abstract":"Since the advent of parallel algorithms in the C++17 Standard Template Library (STL), the STL has become a viable framework for creating performance-portable applications. Given multiple existing implementations of the parallel algorithms, a systematic, quantitative performance comparison is essential for choosing the appropriate implementation for a particular hardware configuration.   In this work, we introduce a specialized set of micro-benchmarks to assess the scalability of the parallel algorithms in the STL. By selecting different backends, our micro-benchmarks can be used on multi-core systems and GPUs.   Using the suite, in a case study on AMD and Intel CPUs and NVIDIA GPUs, we were able to identify substantial performance disparities among different implementations, including GCC+TBB, GCC+HPX, Intel's compiler with TBB, or NVIDIA's compiler with OpenMP and CUDA.","sentences":["Since the advent of parallel algorithms in the C++17 Standard Template Library (STL), the STL has become a viable framework for creating performance-portable applications.","Given multiple existing implementations of the parallel algorithms, a systematic, quantitative performance comparison is essential for choosing the appropriate implementation for a particular hardware configuration.   ","In this work, we introduce a specialized set of micro-benchmarks to assess the scalability of the parallel algorithms in the STL.","By selecting different backends, our micro-benchmarks can be used on multi-core systems and GPUs.   ","Using the suite, in a case study on AMD and Intel CPUs and NVIDIA GPUs, we were able to identify substantial performance disparities among different implementations, including GCC+TBB, GCC+HPX, Intel's compiler with TBB, or NVIDIA's compiler with OpenMP and CUDA."],"url":"http://arxiv.org/abs/2402.06384v1","category":"cs.DC"}
{"created":"2024-02-09 12:59:52","title":"A numerical algorithm for matrix spectral factorization on the real line","abstract":"In this paper, the Janashia-Lagvilava matrix spectral factorization algorithm, which is designed for power spectral density functions defined on the unit circle, is extended to the real line. The proposed algorithm can be used directly for continuous-time models","sentences":["In this paper, the Janashia-Lagvilava matrix spectral factorization algorithm, which is designed for power spectral density functions defined on the unit circle, is extended to the real line.","The proposed algorithm can be used directly for continuous-time models"],"url":"http://arxiv.org/abs/2402.06381v1","category":"math.CV"}
{"created":"2024-02-09 12:26:59","title":"Robust topological feature against non-Hermiticity in Jaynes-Cummings Model","abstract":"The Jaynes-Cummings Model (JCM) is a fundamental model and building block for light-matter interactions, quantum information and quantum computation. We analytically analyze the topological feature manifested by the JCM in the presence of non-Hermiticity which may be effectively induced by dissipation and decay rates. Indeed, the eigenstates of the JCM are topologically characterized by spin windings in two-dimensional plane. The non-Hermiticity tilts the spin winding plane and induces out-of-plane component, while the topological feature is maintained. In particular, besides the invariant spin texture nodes, we find a non-Hermiticity-induced reversal transition of the tilting angle and spin winding direction with a fractional phase gain at gap closing, a partially level-independent reversal transition without gap closing, and a completely level-independent super invariant point with untilted angle and also without gap closing. Our result demonstrates that the topological feature is robust against non-Hermiticity, which would be favorable in practical applications. On the other hand, one may conversely make use of the disadvantageous dissipation and decay rates to reverse the spin winding direction, which might add a control way for topological manipulation of quantum systems in light-matter interactions.","sentences":["The Jaynes-Cummings Model (JCM) is a fundamental model and building block for light-matter interactions, quantum information and quantum computation.","We analytically analyze the topological feature manifested by the JCM in the presence of non-Hermiticity which may be effectively induced by dissipation and decay rates.","Indeed, the eigenstates of the JCM are topologically characterized by spin windings in two-dimensional plane.","The non-Hermiticity tilts the spin winding plane and induces out-of-plane component, while the topological feature is maintained.","In particular, besides the invariant spin texture nodes, we find a non-Hermiticity-induced reversal transition of the tilting angle and spin winding direction with a fractional phase gain at gap closing, a partially level-independent reversal transition without gap closing, and a completely level-independent super invariant point with untilted angle and also without gap closing.","Our result demonstrates that the topological feature is robust against non-Hermiticity, which would be favorable in practical applications.","On the other hand, one may conversely make use of the disadvantageous dissipation and decay rates to reverse the spin winding direction, which might add a control way for topological manipulation of quantum systems in light-matter interactions."],"url":"http://arxiv.org/abs/2402.06370v1","category":"quant-ph"}
{"created":"2024-02-09 12:22:19","title":"Adaptive Downlink Localization and User Tracking in Near-Field and Far-Field: A Trade-Off Analysis","abstract":"This paper considers the problem of downlink localization and user equipments (UEs) tracking with an adaptive procedure for a range of distances. We provide the base station (BS) with two signaling schemes and the UEs with two localization algorithms, assuming far-field (FF) and near-field (NF) conditions, respectively. The proposed schemes employ different beam-sweep patterns, where their compatibility depends on the UE range. Consequently, the FF-NF distinction transcends the traditional definition. Our proposed NF scheme requires beam-focusing on specific spots and more transmissions are required to sweep the area. Instead, the FF scheme assumes distant UEs, and fewer beams are sufficient. We derive a low-complexity algorithm that exploits the FF channel model and highlight its practical benefits and the limitations. Also, we propose an iterative adaptive procedure, where the signaling scheme is depends on the expected accuracy-complexity trade-off. Multiple iterations introduce a tracking application, where the formed trajectory dictates the validity of our assumptions. Moreover, the range from the BS, where the FF signaling scheme can be successfully employed, is investigated. We show that the conventional Fraunhofer distance is not sufficient for adaptive localization and tracking algorithms in the mixed NF and FF environment.","sentences":["This paper considers the problem of downlink localization and user equipments (UEs) tracking with an adaptive procedure for a range of distances.","We provide the base station (BS) with two signaling schemes and the UEs with two localization algorithms, assuming far-field (FF) and near-field (NF) conditions, respectively.","The proposed schemes employ different beam-sweep patterns, where their compatibility depends on the UE range.","Consequently, the FF-NF distinction transcends the traditional definition.","Our proposed NF scheme requires beam-focusing on specific spots and more transmissions are required to sweep the area.","Instead, the FF scheme assumes distant UEs, and fewer beams are sufficient.","We derive a low-complexity algorithm that exploits the FF channel model and highlight its practical benefits and the limitations.","Also, we propose an iterative adaptive procedure, where the signaling scheme is depends on the expected accuracy-complexity trade-off.","Multiple iterations introduce a tracking application, where the formed trajectory dictates the validity of our assumptions.","Moreover, the range from the BS, where the FF signaling scheme can be successfully employed, is investigated.","We show that the conventional Fraunhofer distance is not sufficient for adaptive localization and tracking algorithms in the mixed NF and FF environment."],"url":"http://arxiv.org/abs/2402.06368v1","category":"cs.IT"}
{"created":"2024-02-09 12:14:18","title":"Plateau-Rayleigh instability of a soft layer coated on a rigid cylinder","abstract":"We study the Plateau-Rayleigh instability of a viscoelastic soft solid layer coated on a rigid cylinder i.e., a soft fibre with a rigid core. The onset of instability is examined using a linear stability analysis. We find that increasing the rigid cylinder radius reduce the growth rate of the fastest growing mode. For each rigid cylinder radius, a critical elastocapillary number is found below which all wavelengths of disturbances are stable. The critical value for a soft fibre with a thick rigid cylindrical core can be several orders of magnitudes larger than that for a totally soft fibre (no rigid core), which highlights the strong stabilizing effect of the rigid core on the system. Increasing the relaxation timescale of the viscoelastic material also slows down the growth of disturbance, but has no effect on the critical elastocapillary number. Interestingly, the wavelength of the fastest growing mode is independent of the rigid cylinder radius for the purely elastic case.","sentences":["We study the Plateau-Rayleigh instability of a viscoelastic soft solid layer coated on a rigid cylinder i.e., a soft fibre with a rigid core.","The onset of instability is examined using a linear stability analysis.","We find that increasing the rigid cylinder radius reduce the growth rate of the fastest growing mode.","For each rigid cylinder radius, a critical elastocapillary number is found below which all wavelengths of disturbances are stable.","The critical value for a soft fibre with a thick rigid cylindrical core can be several orders of magnitudes larger than that for a totally soft fibre (no rigid core), which highlights the strong stabilizing effect of the rigid core on the system.","Increasing the relaxation timescale of the viscoelastic material also slows down the growth of disturbance, but has no effect on the critical elastocapillary number.","Interestingly, the wavelength of the fastest growing mode is independent of the rigid cylinder radius for the purely elastic case."],"url":"http://arxiv.org/abs/2402.06362v1","category":"cond-mat.soft"}
{"created":"2024-02-09 11:56:44","title":"SWITCH: An Exemplar for Evaluating Self-Adaptive ML-Enabled Systems","abstract":"Addressing runtime uncertainties in Machine Learning-Enabled Systems (MLS) is crucial for maintaining Quality of Service (QoS). The Machine Learning Model Balancer is a concept that addresses these uncertainties by facilitating dynamic ML model switching, showing promise in improving QoS in MLS. Leveraging this concept, this paper introduces SWITCH, an exemplar developed to enhance self-adaptive capabilities in such systems through dynamic model switching in runtime. SWITCH is designed as a comprehensive web service catering to a broad range of ML scenarios, with its implementation demonstrated through an object detection use case. SWITCH provides researchers with a flexible platform to apply and evaluate their ML model switching strategies, aiming to enhance QoS in MLS. SWITCH features advanced input handling, real-time data processing, and logging for adaptation metrics supplemented with an interactive real-time dashboard for enhancing system observability. This paper details SWITCH's architecture, self-adaptation strategies through ML model switching, and its empirical validation through a case study, illustrating its potential to improve QoS in MLS. By enabling a hands-on approach to explore adaptive behaviors in ML systems, SWITCH contributes a valuable tool to the SEAMS community for research into self-adaptive mechanisms for MLS and their practical applications.","sentences":["Addressing runtime uncertainties in Machine Learning-Enabled Systems (MLS) is crucial for maintaining Quality of Service (QoS).","The Machine Learning Model Balancer is a concept that addresses these uncertainties by facilitating dynamic ML model switching, showing promise in improving QoS in MLS.","Leveraging this concept, this paper introduces SWITCH, an exemplar developed to enhance self-adaptive capabilities in such systems through dynamic model switching in runtime.","SWITCH is designed as a comprehensive web service catering to a broad range of ML scenarios, with its implementation demonstrated through an object detection use case.","SWITCH provides researchers with a flexible platform to apply and evaluate their ML model switching strategies, aiming to enhance QoS in MLS.","SWITCH features advanced input handling, real-time data processing, and logging for adaptation metrics supplemented with an interactive real-time dashboard for enhancing system observability.","This paper details SWITCH's architecture, self-adaptation strategies through ML model switching, and its empirical validation through a case study, illustrating its potential to improve QoS in MLS.","By enabling a hands-on approach to explore adaptive behaviors in ML systems, SWITCH contributes a valuable tool to the SEAMS community for research into self-adaptive mechanisms for MLS and their practical applications."],"url":"http://arxiv.org/abs/2402.06351v1","category":"cs.SE"}
{"created":"2024-02-09 11:53:39","title":"Hot phonon effects on high-field transport in 2DEG GaN","abstract":"The effects of confinement on electron transport in GaN have been studied via an ensemble Monte-Carlo code. Excellent agreement is obtained with experimental data from the literature up to moderate fields. In agreement with experimental results, negative-differential-conductivity is not observed in velocity-field curves. The reasons for this are discussed in detail. The dynamics of the non-equilibrium confined electron-LO phonon system is studied via a bulk phonon spectrum. In contrast to the bulk electron case hot or non-equilibrium phonons do not play a significant role in determining the transport properties. This is explained via the energy and momentum conservation rules for the polar optical phonon scattering. In addition, impact ionization is shown to be insignificant for the applied fields considered.","sentences":["The effects of confinement on electron transport in GaN have been studied via an ensemble Monte-Carlo code.","Excellent agreement is obtained with experimental data from the literature up to moderate fields.","In agreement with experimental results, negative-differential-conductivity is not observed in velocity-field curves.","The reasons for this are discussed in detail.","The dynamics of the non-equilibrium confined electron-LO phonon system is studied via a bulk phonon spectrum.","In contrast to the bulk electron case hot or non-equilibrium phonons do not play a significant role in determining the transport properties.","This is explained via the energy and momentum conservation rules for the polar optical phonon scattering.","In addition, impact ionization is shown to be insignificant for the applied fields considered."],"url":"http://arxiv.org/abs/2402.06349v1","category":"physics.comp-ph"}
{"created":"2024-02-09 11:34:16","title":"RareBench: Can LLMs Serve as Rare Diseases Specialists?","abstract":"Generalist Large Language Models (LLMs), such as GPT-4, have shown considerable promise in various domains, including medical diagnosis. Rare diseases, affecting approximately 300 million people worldwide, often have unsatisfactory clinical diagnosis rates primarily due to a lack of experienced physicians and the complexity of differentiating among many rare diseases. In this context, recent news such as \"ChatGPT correctly diagnosed a 4-year-old's rare disease after 17 doctors failed\" underscore LLMs' potential, yet underexplored, role in clinically diagnosing rare diseases. To bridge this research gap, we introduce RareBench, a pioneering benchmark designed to systematically evaluate the capabilities of LLMs on 4 critical dimensions within the realm of rare diseases. Meanwhile, we have compiled the largest open-source dataset on rare disease patients, establishing a benchmark for future studies in this domain. To facilitate differential diagnosis of rare diseases, we develop a dynamic few-shot prompt methodology, leveraging a comprehensive rare disease knowledge graph synthesized from multiple knowledge bases, significantly enhancing LLMs' diagnostic performance. Moreover, we present an exhaustive comparative study of GPT-4's diagnostic capabilities against those of specialist physicians. Our experimental findings underscore the promising potential of integrating LLMs into the clinical diagnostic process for rare diseases. This paves the way for exciting possibilities in future advancements in this field.","sentences":["Generalist Large Language Models (LLMs), such as GPT-4, have shown considerable promise in various domains, including medical diagnosis.","Rare diseases, affecting approximately 300 million people worldwide, often have unsatisfactory clinical diagnosis rates primarily due to a lack of experienced physicians and the complexity of differentiating among many rare diseases.","In this context, recent news such as \"ChatGPT correctly diagnosed a 4-year-old's rare disease after 17 doctors failed\" underscore LLMs' potential, yet underexplored, role in clinically diagnosing rare diseases.","To bridge this research gap, we introduce RareBench, a pioneering benchmark designed to systematically evaluate the capabilities of LLMs on 4 critical dimensions within the realm of rare diseases.","Meanwhile, we have compiled the largest open-source dataset on rare disease patients, establishing a benchmark for future studies in this domain.","To facilitate differential diagnosis of rare diseases, we develop a dynamic few-shot prompt methodology, leveraging a comprehensive rare disease knowledge graph synthesized from multiple knowledge bases, significantly enhancing LLMs' diagnostic performance.","Moreover, we present an exhaustive comparative study of GPT-4's diagnostic capabilities against those of specialist physicians.","Our experimental findings underscore the promising potential of integrating LLMs into the clinical diagnostic process for rare diseases.","This paves the way for exciting possibilities in future advancements in this field."],"url":"http://arxiv.org/abs/2402.06341v1","category":"cs.CL"}
{"created":"2024-02-09 11:25:17","title":"Local exact controllability to the trajectories of the convective Brinkman-Forchheimer equations","abstract":"In this article, we discuss the local exact controllability to trajectories of the following convective Brinkman-Forchheimer (CBF) equations (or damped Navier-Stokes equations) defined in a bounded domain $\\Omega   \\subset\\mathbb{R}^d$ ($d=2,3$) with smooth boundary:   \\begin{align*}   \\frac{\\partial\\boldsymbol{u}}{\\partial t}-\\mu \\Delta\\boldsymbol{u}+(\\boldsymbol{u}\\cdot\\nabla)\\boldsymbol{u}+\\alpha\\boldsymbol{u}+\\beta|\\boldsymbol{u}|^{2}\\boldsymbol{u}+\\nabla p=\\boldsymbol{f}+\\boldsymbol{\\vartheta}, \\ \\ \\ \\nabla\\cdot\\boldsymbol{u}=0,   \\end{align*}   where the control $\\boldsymbol{\\vartheta}$ is distributed in a subdomain $\\omega \\subset \\Omega$, and the parameters $\\alpha,\\beta,\\mu>0$ are constants. We first present global Carleman estimates and observability inequality for the adjoint problem of a linearized version of CBF equations by using a global Carleman estimate for the Stokes system. This allows us to obtain its null controllability at any time $T>0$. We then use the inverse mapping theorem to deduce local results concerning the exact controllability to the trajectories of CBF equations.","sentences":["In this article, we discuss the local exact controllability to trajectories of the following convective Brinkman-Forchheimer (CBF) equations (or damped Navier-Stokes equations) defined in a bounded domain $\\Omega   \\subset\\mathbb{R}^d$ ($d=2,3$) with smooth boundary:   \\begin{align*}   \\frac{\\partial\\boldsymbol{u}}{\\partial t}-\\mu \\Delta\\boldsymbol{u}+(\\boldsymbol{u}\\cdot\\nabla)\\boldsymbol{u}+\\alpha\\boldsymbol{u}+\\beta|\\boldsymbol{u}|^{2}\\boldsymbol{u}+\\nabla p=\\boldsymbol{f}+\\boldsymbol{\\vartheta}, \\ \\ \\ \\nabla\\cdot\\boldsymbol{u}=0,   \\end{align*}   where the control $\\boldsymbol{\\vartheta}$ is distributed in a subdomain $\\omega \\subset \\Omega$, and the parameters $\\alpha,\\beta,\\mu>0$ are constants.","We first present global Carleman estimates and observability inequality for the adjoint problem of a linearized version of CBF equations by using a global Carleman estimate for the Stokes system.","This allows us to obtain its null controllability at any time $T>0$. We then use the inverse mapping theorem to deduce local results concerning the exact controllability to the trajectories of CBF equations."],"url":"http://arxiv.org/abs/2402.06335v1","category":"math.AP"}
{"created":"2024-02-09 11:15:49","title":"Taking Class Imbalance Into Account in Open Set Recognition Evaluation","abstract":"In recent years Deep Neural Network-based systems are not only increasing in popularity but also receive growing user trust. However, due to the closed-world assumption of such systems, they cannot recognize samples from unknown classes and often induce an incorrect label with high confidence. Presented work looks at the evaluation of methods for Open Set Recognition, focusing on the impact of class imbalance, especially in the dichotomy between known and unknown samples. As an outcome of problem analysis, we present a set of guidelines for evaluation of methods in this field.","sentences":["In recent years Deep Neural Network-based systems are not only increasing in popularity but also receive growing user trust.","However, due to the closed-world assumption of such systems, they cannot recognize samples from unknown classes and often induce an incorrect label with high confidence.","Presented work looks at the evaluation of methods for Open Set Recognition, focusing on the impact of class imbalance, especially in the dichotomy between known and unknown samples.","As an outcome of problem analysis, we present a set of guidelines for evaluation of methods in this field."],"url":"http://arxiv.org/abs/2402.06331v1","category":"cs.LG"}
{"created":"2024-02-09 11:02:40","title":"Stable factorization of the Calder\u00f3n problem via the Born approximation","abstract":"In this article we prove the existence of the Born approximation in the context of the radial Calder\\'on problem for Schr\\\"odinger operators. This is the inverse problem of recovering a radial potential on the unit ball from the knowledge of the Dirichlet-to-Neumann map (DtN map from now on) of the corresponding Schr\\\"odinger operator. The Born approximation naturally appears as the linear component of a factorization of the Calder\\'on problem; we show that the non-linear part, obtaining the potential from the Born approximation, enjoys several interesting properties. First, this map is local, in the sense that knowledge of the Born approximation in a neighborhood of the boundary is equivalent to knowledge of the potential in the same neighborhood, and, second, it is H\\\"older stable. This shows in particular that the ill-posedness of the Calder\\'on problem arises solely from the linear step, which consists in computing the Born approximation from the DtN map by solving a Hausdorff moment problem. Moreover, we present an effective algorithm to compute the potential from the Born approximation and show a result on reconstruction of singularities. Finally, we use the Born approximation to obtain a partial characterization of the set of DtN maps for radial potentials. The proofs of these results do not make use of Complex Geometric Optics solutions or its analogues; they are based on results on inverse spectral theory for Schr\\\"odinger operators on the half-line, in particular on the concept of $A$-amplitude introduced by Barry Simon.","sentences":["In this article we prove the existence of the Born approximation in the context of the radial Calder\\'on problem for Schr\\\"odinger operators.","This is the inverse problem of recovering a radial potential on the unit ball from the knowledge of the Dirichlet-to-Neumann map (DtN map from now on) of the corresponding Schr\\\"odinger operator.","The Born approximation naturally appears as the linear component of a factorization of the Calder\\'on problem; we show that the non-linear part, obtaining the potential from the Born approximation, enjoys several interesting properties.","First, this map is local, in the sense that knowledge of the Born approximation in a neighborhood of the boundary is equivalent to knowledge of the potential in the same neighborhood, and, second, it is H\\\"older stable.","This shows in particular that the ill-posedness of the Calder\\'on problem arises solely from the linear step, which consists in computing the Born approximation from the DtN map by solving a Hausdorff moment problem.","Moreover, we present an effective algorithm to compute the potential from the Born approximation and show a result on reconstruction of singularities.","Finally, we use the Born approximation to obtain a partial characterization of the set of DtN maps for radial potentials.","The proofs of these results do not make use of Complex Geometric Optics solutions or its analogues; they are based on results on inverse spectral theory for Schr\\\"odinger operators on the half-line, in particular on the concept of $A$-amplitude introduced by Barry Simon."],"url":"http://arxiv.org/abs/2402.06321v1","category":"math.AP"}
{"created":"2024-02-09 10:36:14","title":"Uniform local null control of the Leray-$\u03b1$ model","abstract":"This paper deals with the distributed and boundary controllability of the so called Leray-$\\alpha$ model. This is a regularized variant of the Navier-Stokes system ($\\alpha$ is a small positive parameter) that can also be viewed as a model for turbulent flows. We prove that the Leray-$\\alpha$ equations are locally null controllable, with controls bounded independently of $\\alpha$. We also prove that, if the initial data are sufficiently small, the controls converge as $\\alpha \\to 0^+$ to a null control of the Navier-Stokes equations. We also discuss some other related questions, such as global null controllability, local and global exact controllability to the trajectories, etc.","sentences":["This paper deals with the distributed and boundary controllability of the so called Leray-$\\alpha$ model.","This is a regularized variant of the Navier-Stokes system ($\\alpha$ is a small positive parameter) that can also be viewed as a model for turbulent flows.","We prove that the Leray-$\\alpha$ equations are locally null controllable, with controls bounded independently of $\\alpha$. We also prove that, if the initial data are sufficiently small, the controls converge as $\\alpha \\to 0^+$ to a null control of the Navier-Stokes equations.","We also discuss some other related questions, such as global null controllability, local and global exact controllability to the trajectories, etc."],"url":"http://arxiv.org/abs/2402.06307v1","category":"math.OC"}
{"created":"2024-02-09 10:10:28","title":"Provably Safe Finite-Time Guidance for Marine Vehicles","abstract":"We consider a new control strategy for marine navigation, equipped with finite-time convergence characteristics. We provide mathematical guarantees for waypoint reaching and obstacle avoidance for different encounter scenarios, by deriving conditions under which (i) convergence to waypoint and (ii) safe obstacle avoidance is achieved while (iii) satisfying input constraints. We propose a predefined-time heading control to enforce ship heading error convergence and waypoint reaching in finite time. Using this as a building block, we develop a provably safe algorithm for safe waypoint navigation by strategically and automatically introducing intermediate virtual waypoints. Using Imazu problems as benchmarks, we show that the proposed method is better than other existing strategies such as Velocity Obstacle Avoidance and biased Line-of-Sight methods, in terms of the safe distance between the ship and the obstacles, cross track error, control effort, waypoint reaching time and ship path length.","sentences":["We consider a new control strategy for marine navigation, equipped with finite-time convergence characteristics.","We provide mathematical guarantees for waypoint reaching and obstacle avoidance for different encounter scenarios, by deriving conditions under which (i) convergence to waypoint and (ii) safe obstacle avoidance is achieved while (iii) satisfying input constraints.","We propose a predefined-time heading control to enforce ship heading error convergence and waypoint reaching in finite time.","Using this as a building block, we develop a provably safe algorithm for safe waypoint navigation by strategically and automatically introducing intermediate virtual waypoints.","Using Imazu problems as benchmarks, we show that the proposed method is better than other existing strategies such as Velocity Obstacle Avoidance and biased Line-of-Sight methods, in terms of the safe distance between the ship and the obstacles, cross track error, control effort, waypoint reaching time and ship path length."],"url":"http://arxiv.org/abs/2402.06291v1","category":"eess.SY"}
{"created":"2024-02-09 09:34:58","title":"On the control of some coupled systems of the Boussinesq kind with few controls","abstract":"This paper is devoted to prove the local exact controllability to the trajectories for a coupled system, of the Boussinesq kind, with a reduced number of controls. In the state system, the unknowns are the velocity field and pressure of the fluid $(y, p)$, the temperature $\\theta$ and an additional variable $c$ that can be viewed as the concentration of a contaminant solute. We prove several results, that essentially show that it is sufficient to act locally in space on the equations satisfied by $\\theta$ and $c$.","sentences":["This paper is devoted to prove the local exact controllability to the trajectories for a coupled system, of the Boussinesq kind, with a reduced number of controls.","In the state system, the unknowns are the velocity field and pressure of the fluid $(y, p)$, the temperature $\\theta$ and an additional variable $c$ that can be viewed as the concentration of a contaminant solute.","We prove several results, that essentially show that it is sufficient to act locally in space on the equations satisfied by $\\theta$ and $c$."],"url":"http://arxiv.org/abs/2402.06269v1","category":"math.OC"}
{"created":"2024-02-09 09:30:00","title":"Efficient initialization of fluxonium qubits based on auxiliary energy levels","abstract":"Fast and high-fidelity qubit initialization is crucial for low-frequency qubits such as fluxonium, and in applications of many quantum algorithms and quantum error correction codes. In a circuit quantum electrodynamics system, the initialization is typically achieved by transferring the state between the qubit and a short-lived cavity through microwave driving, also known as the sideband cooling process in atomic system. Constrained by the selection rules from the parity symmetry of the wavefunctions, the sideband transitions are only enabled by multi-photon processes which requires multi-tone or strong driving. Leveraging the flux-tunability of fluxonium, we circumvent this limitation by breaking flux symmetry to enable an interaction between a non-computational qubit transition and the cavity excitation. With single-tone sideband driving, we realize qubit initialization with a fidelity exceeding 99% within a duration of 300 ns, robust against the variation of control parameters. Furthermore, we show that our initialization scheme has a built-in benefit in simultaneously removing the second-excited state population of the qubit, and can be easily incorporated into a large-scale fluxonium processor.","sentences":["Fast and high-fidelity qubit initialization is crucial for low-frequency qubits such as fluxonium, and in applications of many quantum algorithms and quantum error correction codes.","In a circuit quantum electrodynamics system, the initialization is typically achieved by transferring the state between the qubit and a short-lived cavity through microwave driving, also known as the sideband cooling process in atomic system.","Constrained by the selection rules from the parity symmetry of the wavefunctions, the sideband transitions are only enabled by multi-photon processes which requires multi-tone or strong driving.","Leveraging the flux-tunability of fluxonium, we circumvent this limitation by breaking flux symmetry to enable an interaction between a non-computational qubit transition and the cavity excitation.","With single-tone sideband driving, we realize qubit initialization with a fidelity exceeding 99% within a duration of 300 ns, robust against the variation of control parameters.","Furthermore, we show that our initialization scheme has a built-in benefit in simultaneously removing the second-excited state population of the qubit, and can be easily incorporated into a large-scale fluxonium processor."],"url":"http://arxiv.org/abs/2402.06267v1","category":"quant-ph"}
{"created":"2024-02-09 09:27:19","title":"Rational Design of Molybdenum Transition-Metal subnanoclusters catalysts with Particle Swarm Optimization","abstract":"The development of novel sub-nanometer clusters (SNCs) catalysts with superior catalytic performance depends on the precise control of clusters' atomistic sizes, shapes, and accurate deposition onto surfaces. Recent advancements in manufacturing and characterization techniques have paved the way for the production and atomic resolution characterization of transition-metal SNCs catalysts, positioning them as a promising new class of materials for this application. Nevertheless, the intrinsic complexity of the adsorption process complicates the ability to achieve an atomistic understanding of the most relevant structure-reactivity relationships hampering the rational design of novel catalytic materials. In most cases, existing computational approaches rely on just a few structures to conclude clusters' reactivity thereby neglecting the complexity of the existing energy landscapes thus leading to insufficient sampling and, most likely, unreliable predictions. Moreover, modelling of the actual experimental procedure that is responsible for the deposition of SNCs on surfaces is often not done even though in some cases this procedure may enhance the significance of certain (e.g., metastable) adsorption geometries. This study proposes a novel approach that utilizes particle swarm optimization (PSO) method, in conjunction with ab-initio calculations, to predict the most relevant SNCs structures on a surface in beam experiments, and consequently their reactivity. To illustrate the main steps of our approach, we consider the deposition of Molybdenum SNC of 6 Mo atoms on a free-standing graphene surface, as well as their catalytic properties concerning the CO molecule dissociation reaction. This study demonstrates the feasibility of the PSO technique for studying catalyst transition-metal SNCs and establishes a reliable procedure for performing theoretical rational design predictions.","sentences":["The development of novel sub-nanometer clusters (SNCs) catalysts with superior catalytic performance depends on the precise control of clusters' atomistic sizes, shapes, and accurate deposition onto surfaces.","Recent advancements in manufacturing and characterization techniques have paved the way for the production and atomic resolution characterization of transition-metal SNCs catalysts, positioning them as a promising new class of materials for this application.","Nevertheless, the intrinsic complexity of the adsorption process complicates the ability to achieve an atomistic understanding of the most relevant structure-reactivity relationships hampering the rational design of novel catalytic materials.","In most cases, existing computational approaches rely on just a few structures to conclude clusters' reactivity thereby neglecting the complexity of the existing energy landscapes thus leading to insufficient sampling and, most likely, unreliable predictions.","Moreover, modelling of the actual experimental procedure that is responsible for the deposition of SNCs on surfaces is often not done even though in some cases this procedure may enhance the significance of certain (e.g., metastable) adsorption geometries.","This study proposes a novel approach that utilizes particle swarm optimization (PSO) method, in conjunction with ab-initio calculations, to predict the most relevant SNCs structures on a surface in beam experiments, and consequently their reactivity.","To illustrate the main steps of our approach, we consider the deposition of Molybdenum SNC of 6 Mo atoms on a free-standing graphene surface, as well as their catalytic properties concerning the CO molecule dissociation reaction.","This study demonstrates the feasibility of the PSO technique for studying catalyst transition-metal SNCs and establishes a reliable procedure for performing theoretical rational design predictions."],"url":"http://arxiv.org/abs/2402.06265v1","category":"cond-mat.mtrl-sci"}
{"created":"2024-02-09 09:24:42","title":"ASAP-MPC: An Asynchronous Update Scheme for Online Motion Planning with Nonlinear Model Predictive Control","abstract":"This paper presents a Nonlinear Model Predictive Control (NMPC) scheme targeted at motion planning for mechatronic motion systems, such as drones and mobile platforms. NMPC-based motion planning typically requires low computation times to be able to provide control inputs at the required rate for system stability, disturbance rejection, and overall performance. Although there exist various ways in literature to reduce the solution times in NMPC, such times may not be low enough to allow real-time implementations. This paper presents ASAP-MPC, an approach to handle varying, sometimes restrictively large, solution times with an asynchronous update scheme, always allowing for full convergence and real-time execution. The NMPC algorithm is combined with a linear state feedback controller tracking the optimised trajectories for improved robustness against possible disturbances and plant-model mismatch. ASAP-MPC seamlessly merges trajectories, resulting from subsequent NMPC solutions, providing a smooth and continuous overall trajectory for the motion system. This frameworks applicability to embedded applications is shown on two different experiment setups where a state-of-the-art method fails: a quadcopter flying through a cluttered environment in hardware-in-the-loop simulation and a scale model truck-trailer manoeuvring in a structured lab environment.","sentences":["This paper presents a Nonlinear Model Predictive Control (NMPC) scheme targeted at motion planning for mechatronic motion systems, such as drones and mobile platforms.","NMPC-based motion planning typically requires low computation times to be able to provide control inputs at the required rate for system stability, disturbance rejection, and overall performance.","Although there exist various ways in literature to reduce the solution times in NMPC, such times may not be low enough to allow real-time implementations.","This paper presents ASAP-MPC, an approach to handle varying, sometimes restrictively large, solution times with an asynchronous update scheme, always allowing for full convergence and real-time execution.","The NMPC algorithm is combined with a linear state feedback controller tracking the optimised trajectories for improved robustness against possible disturbances and plant-model mismatch.","ASAP-MPC seamlessly merges trajectories, resulting from subsequent NMPC solutions, providing a smooth and continuous overall trajectory for the motion system.","This frameworks applicability to embedded applications is shown on two different experiment setups where a state-of-the-art method fails: a quadcopter flying through a cluttered environment in hardware-in-the-loop simulation and a scale model truck-trailer manoeuvring in a structured lab environment."],"url":"http://arxiv.org/abs/2402.06263v1","category":"cs.RO"}
{"created":"2024-02-09 09:15:08","title":"Level attraction in a quasi-closed cavity","abstract":"We provide a comprehensive analytical description of the effective coupling associated with an antiresonance within a hybrid system comprised of a quasi-closed photonic cavity and a ferrimagnetic material. Whilst so-called level attraction between a resonant system inside an open cavity is well understood, the physical underpinnings of this phenomena within quasi-closed cavities have remained elusive. Leveraging the input-output theory, we successfully differentiate between the repulsive and attractive aspects of this coupling. Our proposed model demonstrates that by understanding the phase-jump at the resonances and the studied antiresonance, we can predict the nature of the effective coupling of the antiresonance for a given position of the ferrimagnet in the cavity.","sentences":["We provide a comprehensive analytical description of the effective coupling associated with an antiresonance within a hybrid system comprised of a quasi-closed photonic cavity and a ferrimagnetic material.","Whilst so-called level attraction between a resonant system inside an open cavity is well understood, the physical underpinnings of this phenomena within quasi-closed cavities have remained elusive.","Leveraging the input-output theory, we successfully differentiate between the repulsive and attractive aspects of this coupling.","Our proposed model demonstrates that by understanding the phase-jump at the resonances and the studied antiresonance, we can predict the nature of the effective coupling of the antiresonance for a given position of the ferrimagnet in the cavity."],"url":"http://arxiv.org/abs/2402.06258v1","category":"quant-ph"}
{"created":"2024-02-09 09:13:55","title":"Bayesian Committee Machine Potential for Isothermal-Isobaric Molecular Dynamics Simulations","abstract":"In recent advancements in material simulations, the utilization of Sparse Gaussian Process Regression (SGPR)-based machine learning potentials (MLPs) has proven to be highly successful in diverse applications such as catalysis, batteries, and solar cells. In the context of isothermal and isobaric molecular dynamics simulations, achieving precise pressure estimates is crucial for an accurate understanding of the system behavior under constant pressure conditions. In this study, we introduce a novel kernel function designed for estimating the virial term, a critical component for pressure calculations in materials simulations. Our study reveals that the inclusion of a virial prediction in the kernel function leads to significantly improved accuracy in calculating the stress of a system. We present a kernel-based ML potential that can be estimated via the Bayesian Committee Machine without the need for additional training. This improvement allows us to calculate the melting temperature of ice through Isobaric-Isenthalpy $NpH$ molecular dynamics simulations of ice-liquid coexisting phases, employing the BCM potential.","sentences":["In recent advancements in material simulations, the utilization of Sparse Gaussian Process Regression (SGPR)-based machine learning potentials (MLPs) has proven to be highly successful in diverse applications such as catalysis, batteries, and solar cells.","In the context of isothermal and isobaric molecular dynamics simulations, achieving precise pressure estimates is crucial for an accurate understanding of the system behavior under constant pressure conditions.","In this study, we introduce a novel kernel function designed for estimating the virial term, a critical component for pressure calculations in materials simulations.","Our study reveals that the inclusion of a virial prediction in the kernel function leads to significantly improved accuracy in calculating the stress of a system.","We present a kernel-based ML potential that can be estimated via the Bayesian Committee Machine without the need for additional training.","This improvement allows us to calculate the melting temperature of ice through Isobaric-Isenthalpy $NpH$ molecular dynamics simulations of ice-liquid coexisting phases, employing the BCM potential."],"url":"http://arxiv.org/abs/2402.06256v1","category":"cond-mat.soft"}
{"created":"2024-02-09 09:05:32","title":"Quasi van der Waals Epitaxial Growth of GaAsSb Nanowires on Graphitic Substrate for Photonic Applications","abstract":"III-V semiconductor nanowires are considered promising building blocks for advanced photonic devices. One of the key advantages is that the lattice mismatch can easily be accommodated in 1D structures, resulting in superior heteroepitaxial quality compared to thin films. However, few reports break the limitation of using bulk crystalline materials as substrates for epitaxial growth of high-quality photonic 1D components, making monolithic integration of III-V components on arbitrary substrates challenging. In this work, we show that the growth of self-catalyzed GaAsSb nanowires on graphitic substrates can be promoted by creating step edges of monolayer thickness on kish graphite before the growth. By further alternating the deposition sequence of the group-III element Al and the group-V elements As and Sb, it was found that triangular crystallites form when Al is deposited first. This indicates that the surface binding energy between the graphitic surface and the III-V nucleus profoundly influences the epitaxial growth of III-V materials on graphitic surfaces. Using the optimized growth recipe with an AlAsSb buffer nuclei, vertical [111]-oriented GaAsSb/GaAs nanowires with GaAsSb-based multiple axial superlattices were grown on exfoliated graphite, which was attached to a (001) AlAs/GaAs distributed Bragg reflector (DBR) using the simple Scotch tape method. Fabry-P\\'{e}rot resonance modes were observed under optical excitation at room temperature, indicating a successful monolithic integration with optical feedback from the DBR system. These results demonstrate the great potential for flexible integration of high-efficiency III-V nanowire photonic devices on arbitrary photonic platforms using a 2D material buffer layer, e.g., graphene, without breaking the orientation registry.","sentences":["III-V semiconductor nanowires are considered promising building blocks for advanced photonic devices.","One of the key advantages is that the lattice mismatch can easily be accommodated in 1D structures, resulting in superior heteroepitaxial quality compared to thin films.","However, few reports break the limitation of using bulk crystalline materials as substrates for epitaxial growth of high-quality photonic 1D components, making monolithic integration of III-V components on arbitrary substrates challenging.","In this work, we show that the growth of self-catalyzed GaAsSb nanowires on graphitic substrates can be promoted by creating step edges of monolayer thickness on kish graphite before the growth.","By further alternating the deposition sequence of the group-III element Al and the group-V elements As and Sb, it was found that triangular crystallites form when Al is deposited first.","This indicates that the surface binding energy between the graphitic surface and the III-V nucleus profoundly influences the epitaxial growth of III-V materials on graphitic surfaces.","Using the optimized growth recipe with an AlAsSb buffer nuclei, vertical [111]-oriented GaAsSb/GaAs nanowires with GaAsSb-based multiple axial superlattices were grown on exfoliated graphite, which was attached to a (001) AlAs/GaAs distributed Bragg reflector (DBR) using the simple Scotch tape method.","Fabry-P\\'{e}rot resonance modes were observed under optical excitation at room temperature, indicating a successful monolithic integration with optical feedback from the DBR system.","These results demonstrate the great potential for flexible integration of high-efficiency III-V nanowire photonic devices on arbitrary photonic platforms using a 2D material buffer layer, e.g., graphene, without breaking the orientation registry."],"url":"http://arxiv.org/abs/2402.06254v1","category":"cond-mat.mes-hall"}
{"created":"2024-02-09 08:59:37","title":"Insomnia Identification via Electroencephalography","abstract":"Insomnia is a serious sleep disorder caused by abnormal or excessive neural activity in the brain. An estimated 50 million people worldwide are thought to be affected by this condition, which is the second most severe neurological disease after stroke. In order to ensure a quick recovery, an early and accurate diagnosis of insomnia enables more effective drug and treatment administration. This study proposes a method that uses deep learning to automatically identify patients with insomnia. A set of optimal features are extracted from spectral and temporal domains, including the relative power of {\\sigma}, \\b{eta} and {\\gamma} bands, the total power, the absolute slow wave power, the power ratios of {\\theta}, {\\alpha}, {\\gamma}, \\b{eta}, {\\theta}/{\\alpha}, {\\theta}/\\b{eta}, {\\alpha}/{\\gamma} and {\\alpha}/\\b{eta}, mean, zero crossing rate, mobility, complexity, sleep efficiency and total sleep time, to accurately quantify the differences between insomnia patients and healthy subjects and develops a 1D CNN model for the classification process. With the experiments use Fp2 and C4 EEG channels with 50 insomnia patients and 50 healthy subjects, the proposed model arrives 99.34% accuracy without sleep stage annotation. Using the features only from a single channel, the study proposes a smart solution for insomnia patients which allows machine learning to be to simplify current sleep monitoring hardware and improve in-home ambulatory monitoring.","sentences":["Insomnia is a serious sleep disorder caused by abnormal or excessive neural activity in the brain.","An estimated 50 million people worldwide are thought to be affected by this condition, which is the second most severe neurological disease after stroke.","In order to ensure a quick recovery, an early and accurate diagnosis of insomnia enables more effective drug and treatment administration.","This study proposes a method that uses deep learning to automatically identify patients with insomnia.","A set of optimal features are extracted from spectral and temporal domains, including the relative power of {\\sigma}, \\b{eta} and {\\gamma} bands, the total power, the absolute slow wave power, the power ratios of {\\theta}, {\\alpha}, {\\gamma}, \\b{eta}, {\\theta}/{\\alpha}, {\\theta}/\\b{eta}, {\\alpha}/{\\gamma} and {\\alpha}/\\b{eta}, mean, zero crossing rate, mobility, complexity, sleep efficiency and total sleep time, to accurately quantify the differences between insomnia patients and healthy subjects and develops a 1D CNN model for the classification process.","With the experiments use Fp2 and C4 EEG channels with 50 insomnia patients and 50 healthy subjects, the proposed model arrives 99.34% accuracy without sleep stage annotation.","Using the features only from a single channel, the study proposes a smart solution for insomnia patients which allows machine learning to be to simplify current sleep monitoring hardware and improve in-home ambulatory monitoring."],"url":"http://arxiv.org/abs/2402.06251v1","category":"cs.CV"}
{"created":"2024-02-09 08:57:36","title":"An experimental study: RF Fingerprinting of Bluetooth devices","abstract":"This paper presents an experimental study on radio frequency (RF) fingerprinting of Bluetooth Classic devices. Our research aims to provide a practical evaluation of the possibilities for RF fingerprinting of everyday Bluetooth connected devices that may cause privacy risks. We have built an experimental setup for recording Bluetooth connection in a radio frequency isolated environment using commercially available SDR (software defined radio) systems, extracted fingerprints of the Bluetooth radio data in the form of carrier frequency offset and scaling factor from 6 different devices, and performed k-nearest neighbors (kNN) classification achieving 84\\% accuracy. The experiment demonstrates that no matter what privacy measures are being taken in the protocol layer, the physical layer leaks significant information about the device to unauthorized listeners. In the context of the ever-growing Bluetooth device market, this research serves as a clarion call for device manufacturers, regulators, and end-users to acknowledge the privacy risks posed by RF fingerprinting and lays a foundation for more sizeable Bluetooth fingerprinting analysis research.","sentences":["This paper presents an experimental study on radio frequency (RF) fingerprinting of Bluetooth Classic devices.","Our research aims to provide a practical evaluation of the possibilities for RF fingerprinting of everyday","Bluetooth connected devices that may cause privacy risks.","We have built an experimental setup for recording Bluetooth connection in a radio frequency isolated environment using commercially available SDR (software defined radio) systems, extracted fingerprints of the Bluetooth radio data in the form of carrier frequency offset and scaling factor from 6 different devices, and performed k-nearest neighbors (kNN) classification achieving 84\\% accuracy.","The experiment demonstrates that no matter what privacy measures are being taken in the protocol layer, the physical layer leaks significant information about the device to unauthorized listeners.","In the context of the ever-growing Bluetooth device market, this research serves as a clarion call for device manufacturers, regulators, and end-users to acknowledge the privacy risks posed by RF fingerprinting and lays a foundation for more sizeable Bluetooth fingerprinting analysis research."],"url":"http://arxiv.org/abs/2402.06250v1","category":"eess.SP"}
{"created":"2024-02-09 08:52:47","title":"Anomaly Unveiled: Securing Image Classification against Adversarial Patch Attacks","abstract":"Adversarial patch attacks pose a significant threat to the practical deployment of deep learning systems. However, existing research primarily focuses on image pre-processing defenses, which often result in reduced classification accuracy for clean images and fail to effectively counter physically feasible attacks. In this paper, we investigate the behavior of adversarial patches as anomalies within the distribution of image information and leverage this insight to develop a robust defense strategy. Our proposed defense mechanism utilizes a clustering-based technique called DBSCAN to isolate anomalous image segments, which is carried out by a three-stage pipeline consisting of Segmenting, Isolating, and Blocking phases to identify and mitigate adversarial noise. Upon identifying adversarial components, we neutralize them by replacing them with the mean pixel value, surpassing alternative replacement options. Our model-agnostic defense mechanism is evaluated across multiple models and datasets, demonstrating its effectiveness in countering various adversarial patch attacks in image classification tasks. Our proposed approach significantly improves accuracy, increasing from 38.8\\% without the defense to 67.1\\% with the defense against LaVAN and GoogleAp attacks, surpassing prominent state-of-the-art methods such as LGS (53.86\\%) and Jujutsu (60\\%)","sentences":["Adversarial patch attacks pose a significant threat to the practical deployment of deep learning systems.","However, existing research primarily focuses on image pre-processing defenses, which often result in reduced classification accuracy for clean images and fail to effectively counter physically feasible attacks.","In this paper, we investigate the behavior of adversarial patches as anomalies within the distribution of image information and leverage this insight to develop a robust defense strategy.","Our proposed defense mechanism utilizes a clustering-based technique called DBSCAN to isolate anomalous image segments, which is carried out by a three-stage pipeline consisting of Segmenting, Isolating, and Blocking phases to identify and mitigate adversarial noise.","Upon identifying adversarial components, we neutralize them by replacing them with the mean pixel value, surpassing alternative replacement options.","Our model-agnostic defense mechanism is evaluated across multiple models and datasets, demonstrating its effectiveness in countering various adversarial patch attacks in image classification tasks.","Our proposed approach significantly improves accuracy, increasing from 38.8\\% without the defense to 67.1\\% with the defense against LaVAN and GoogleAp attacks, surpassing prominent state-of-the-art methods such as LGS (53.86\\%) and Jujutsu (60\\%)"],"url":"http://arxiv.org/abs/2402.06249v1","category":"cs.CV"}
{"created":"2024-02-09 08:50:03","title":"Distinct pressure evolution of superconductivity and charge-density-wave in kagome superconductor CsV$_3$Sb$_5$ thin flakes","abstract":"It is intriguing to explore the coexistence and (or) competition between charge-density-wave (CDW) and superconductivity (SC) in many correlated electron systems, such as cuprates, organic superconductors and dichacolgenides. Among them, the recently discovered $\\mathbb{Z} _2$ topological kagome metals AV$_3$Sb$_5$ (A=K, Rb, Cs) serve as an ideal platform to study the intricate relation between them. Here, we report the electrical resistance measurements on CsV$_3$Sb$_5$ thin flakes ($\\approx$ 60 nm) under hydrostatic pressure up to 2.12 GPa to compare its pressure phase diagram of CDW and SC with its bulk form. Even though the CDW transition temperature (T$_{CDW}$) in CsV$_3$Sb$_5$ thin flakes is still monotonically suppressed under pressure and totally vanishes at P$_2$=1.83 GPa similar to the bulk, the superconducting transition temperature (T$_c$) shows an initial decrease and consequent increase up to its maximum $\\sim$ 8.03 K at P$_2$, in sharp contrast with the M-shaped double domes in the bulk CsV$_3$Sb$_5$. Our results suggest the important role of reduced dimensionality on the CDW state and its interplay with the SC, offering a new perspective to explore the exotic nature of CsV$_3$Sb$_5$.","sentences":["It is intriguing to explore the coexistence and (or) competition between charge-density-wave (CDW) and superconductivity (SC) in many correlated electron systems, such as cuprates, organic superconductors and dichacolgenides.","Among them, the recently discovered $\\mathbb{Z} _2$ topological kagome metals AV$_3$Sb$_5$ (A=K, Rb, Cs) serve as an ideal platform to study the intricate relation between them.","Here, we report the electrical resistance measurements on CsV$_3$Sb$_5$ thin flakes ($\\approx$ 60 nm) under hydrostatic pressure up to 2.12 GPa to compare its pressure phase diagram of CDW and SC with its bulk form.","Even though the CDW transition temperature (T$_{CDW}$) in CsV$_3$Sb$_5$ thin flakes is still monotonically suppressed under pressure and totally vanishes at P$_2$=1.83 GPa similar to the bulk, the superconducting transition temperature (T$_c$) shows an initial decrease and consequent increase up to its maximum $\\sim$ 8.03 K at P$_2$, in sharp contrast with the M-shaped double domes in the bulk CsV$_3$Sb$_5$.","Our results suggest the important role of reduced dimensionality on the CDW state and its interplay with the SC, offering a new perspective to explore the exotic nature of CsV$_3$Sb$_5$."],"url":"http://arxiv.org/abs/2402.06248v1","category":"cond-mat.supr-con"}
{"created":"2024-02-09 08:39:00","title":"Astigmatic Speckle-learned OAM Shift Keying and OAM Multiplexing","abstract":"Orbital angular momentum (OAM)-carrying beams have gained significant attention in recent years due to their unique properties and potential to improve spectral efficiency and data transmission rates in optical communication systems. However, fully exploiting the capabilities of the entire OAM mode spectrum remains challenging. The emergence of AI-driven OAM mode identification has revolutionized the demultiplexing process within optical communication channels. OAM beams with different orders are orthogonal, allowing each beam to serve as a distinct signal carrier. Combining multiple OAM beams can effectively enhance channel capacity. In this paper, we adopt speckle-learned demultiplexing to demultiplex OAM beams via its speckle pattern that is more resilient to alignment and noise. However, the use of only non-intensity degenerate beams limits the utilization of multiplexing resources. This approach aims to fully leverage the full spectrum of OAM beams by introducing astigmatism in far-field speckle patterns using a tilted spherical convex lens. We then conduct a comprehensive analysis of two innovative information encoding techniques: OAM shift keying and OAM multiplexing. We successfully demonstrate an optical communication link encoded using both OAM shift keying and OAM multiplexing, followed by accurate decoding via speckle-learned demultiplexing.","sentences":["Orbital angular momentum (OAM)-carrying beams have gained significant attention in recent years due to their unique properties and potential to improve spectral efficiency and data transmission rates in optical communication systems.","However, fully exploiting the capabilities of the entire OAM mode spectrum remains challenging.","The emergence of AI-driven OAM mode identification has revolutionized the demultiplexing process within optical communication channels.","OAM beams with different orders are orthogonal, allowing each beam to serve as a distinct signal carrier.","Combining multiple OAM beams can effectively enhance channel capacity.","In this paper, we adopt speckle-learned demultiplexing to demultiplex OAM beams via its speckle pattern that is more resilient to alignment and noise.","However, the use of only non-intensity degenerate beams limits the utilization of multiplexing resources.","This approach aims to fully leverage the full spectrum of OAM beams by introducing astigmatism in far-field speckle patterns using a tilted spherical convex lens.","We then conduct a comprehensive analysis of two innovative information encoding techniques: OAM shift keying and OAM multiplexing.","We successfully demonstrate an optical communication link encoded using both OAM shift keying and OAM multiplexing, followed by accurate decoding via speckle-learned demultiplexing."],"url":"http://arxiv.org/abs/2402.06245v1","category":"physics.optics"}
{"created":"2024-02-09 18:59:46","title":"Stellar populations of massive early-type galaxies observed by MUSE","abstract":"Stellar population studies of massive early-type galaxies (ETGs) suggest that the stellar initial mass function may not be universal. In particular, the centres of ETGs seem to contain an excess of low-mass dwarf stars compared to our own Galaxy. Through high resolution MUSE IFU data, we carry out a detailed study of the stellar populations of eight massive ETGs. We use full spectrum fitting to determine ages, element abundances, and IMF slopes for spatially binned spectra. We measure flat gradients in age and [Mg/Fe] ratio, as well as negative gradients in metallicity and [Na/Fe]. We detect IMF gradients in some galaxies, with the centres hosting bottom-heavy IMFs and mass excess factors between 1.5-2.5 compared to a Kroupa IMF. The IMF slope below 0.5~M$_\\odot$ varies for our galaxy sample between 1-2.8, with negative radial gradients, while the IMF slope between 0.5-1~M$_\\odot$ has a steep value of $\\sim$3 with mildly positive gradients for most galaxies. For M87, we find excellent agreement with the dynamical M/L as a function of radius. For the other galaxies, we find systematically higher M/L from stellar populations compared to orbit-based dynamical analysis of the same data. This discrepancy increases with NaI strength, suggesting a combination of calibration issues of this line and correlated uncertainties.","sentences":["Stellar population studies of massive early-type galaxies (ETGs) suggest that the stellar initial mass function may not be universal.","In particular, the centres of ETGs seem to contain an excess of low-mass dwarf stars compared to our own Galaxy.","Through high resolution MUSE IFU data, we carry out a detailed study of the stellar populations of eight massive ETGs.","We use full spectrum fitting to determine ages, element abundances, and IMF slopes for spatially binned spectra.","We measure flat gradients in age and [Mg/Fe] ratio, as well as negative gradients in metallicity and [Na/Fe].","We detect IMF gradients in some galaxies, with the centres hosting bottom-heavy IMFs and mass excess factors between 1.5-2.5 compared to a Kroupa IMF.","The IMF slope below 0.5~M$_\\odot$ varies for our galaxy sample between 1-2.8, with negative radial gradients, while the IMF slope between 0.5-1~M$_\\odot$ has a steep value of $\\sim$3 with mildly positive gradients for most galaxies.","For M87, we find excellent agreement with the dynamical M/L as a function of radius.","For the other galaxies, we find systematically higher M/L from stellar populations compared to orbit-based dynamical analysis of the same data.","This discrepancy increases with NaI strength, suggesting a combination of calibration issues of this line and correlated uncertainties."],"url":"http://arxiv.org/abs/2402.06628v1","category":"astro-ph.GA"}
{"created":"2024-02-09 18:42:30","title":"Image-based Deep Learning for the time-dependent prediction of fresh concrete properties","abstract":"Increasing the degree of digitisation and automation in the concrete production process can play a crucial role in reducing the CO$_2$ emissions that are associated with the production of concrete. In this paper, a method is presented that makes it possible to predict the properties of fresh concrete during the mixing process based on stereoscopic image sequences of the concretes flow behaviour. A Convolutional Neural Network (CNN) is used for the prediction, which receives the images supported by information on the mix design as input. In addition, the network receives temporal information in the form of the time difference between the time at which the images are taken and the time at which the reference values of the concretes are carried out. With this temporal information, the network implicitly learns the time-dependent behaviour of the concretes properties. The network predicts the slump flow diameter, the yield stress and the plastic viscosity. The time-dependent prediction potentially opens up the pathway to determine the temporal development of the fresh concrete properties already during mixing. This provides a huge advantage for the concrete industry. As a result, countermeasures can be taken in a timely manner. It is shown that an approach based on depth and optical flow images, supported by information of the mix design, achieves the best results.","sentences":["Increasing the degree of digitisation and automation in the concrete production process can play a crucial role in reducing the CO$_2$ emissions that are associated with the production of concrete.","In this paper, a method is presented that makes it possible to predict the properties of fresh concrete during the mixing process based on stereoscopic image sequences of the concretes flow behaviour.","A Convolutional Neural Network (CNN) is used for the prediction, which receives the images supported by information on the mix design as input.","In addition, the network receives temporal information in the form of the time difference between the time at which the images are taken and the time at which the reference values of the concretes are carried out.","With this temporal information, the network implicitly learns the time-dependent behaviour of the concretes properties.","The network predicts the slump flow diameter, the yield stress and the plastic viscosity.","The time-dependent prediction potentially opens up the pathway to determine the temporal development of the fresh concrete properties already during mixing.","This provides a huge advantage for the concrete industry.","As a result, countermeasures can be taken in a timely manner.","It is shown that an approach based on depth and optical flow images, supported by information of the mix design, achieves the best results."],"url":"http://arxiv.org/abs/2402.06611v1","category":"cs.CV"}
{"created":"2024-02-09 18:41:17","title":"Equi-affine minimal-degree moving frames for polynomial curves","abstract":"We develop a theory and an algorithm for constructing minimal-degree polynomial moving frames for polynomial curves in an affine space. The algorithm is equivariant under volume-preserving affine transformations of the ambient space and the parameter shifts. We show that any matrix-completion algorithm can be turned into an equivariant moving frame algorithm via an equivariantization procedure that we develop. We prove that if a matrix-completion algorithm is of minimal degree then so is the resulting equivariant moving frame algorithm. We propose a novel minimal-degree matrix-completion algorithm, complementing the existing body of literature on this topic.","sentences":["We develop a theory and an algorithm for constructing minimal-degree polynomial moving frames for polynomial curves in an affine space.","The algorithm is equivariant under volume-preserving affine transformations of the ambient space and the parameter shifts.","We show that any matrix-completion algorithm can be turned into an equivariant moving frame algorithm via an equivariantization procedure that we develop.","We prove that if a matrix-completion algorithm is of minimal degree then so is the resulting equivariant moving frame algorithm.","We propose a novel minimal-degree matrix-completion algorithm, complementing the existing body of literature on this topic."],"url":"http://arxiv.org/abs/2402.06610v1","category":"math.AG"}
{"created":"2024-02-09 17:55:01","title":"SAE: Single Architecture Ensemble Neural Networks","abstract":"Ensembles of separate neural networks (NNs) have shown superior accuracy and confidence calibration over single NN across tasks. Recent methods compress ensembles within a single network via early exits or multi-input multi-output frameworks. However, the landscape of these methods is fragmented thus far, making it difficult to choose the right approach for a given task. Furthermore, the algorithmic performance of these methods is behind the ensemble of separate NNs and requires extensive architecture tuning. We propose a novel methodology unifying these approaches into a Single Architecture Ensemble (SAE). Our method learns the optimal number and depth of exits per ensemble input in a single NN. This enables the SAE framework to flexibly tailor its configuration for a given architecture or application. We evaluate SAEs on image classification and regression across various network architecture types and sizes. We demonstrate competitive accuracy or confidence calibration to baselines while reducing the compute operations or parameter count by up to $1.5{\\sim}3.7\\times$.","sentences":["Ensembles of separate neural networks (NNs) have shown superior accuracy and confidence calibration over single NN across tasks.","Recent methods compress ensembles within a single network via early exits or multi-input multi-output frameworks.","However, the landscape of these methods is fragmented thus far, making it difficult to choose the right approach for a given task.","Furthermore, the algorithmic performance of these methods is behind the ensemble of separate NNs and requires extensive architecture tuning.","We propose a novel methodology unifying these approaches into a Single Architecture Ensemble (SAE).","Our method learns the optimal number and depth of exits per ensemble input in a single NN.","This enables the SAE framework to flexibly tailor its configuration for a given architecture or application.","We evaluate SAEs on image classification and regression across various network architecture types and sizes.","We demonstrate competitive accuracy or confidence calibration to baselines while reducing the compute operations or parameter count by up to $1.5{\\sim}3.7\\times$."],"url":"http://arxiv.org/abs/2402.06580v1","category":"cs.LG"}
{"created":"2024-02-09 16:52:39","title":"An Exercise in Tournament Design: When Some Matches Must Be Scheduled","abstract":"Single-elimination (SE) tournaments are a popular format used in competitive environments and decision making. Algorithms for SE tournament manipulation have been an active topic of research in recent years. In this paper, we initiate the algorithmic study of a novel variant of SE tournament manipulation that aims to model the fact that certain matchups are highly desired in a sporting context, incentivizing an organizer to manipulate the bracket to make such matchups take place. We obtain both hardness and tractability results. We show that while the problem of computing a bracket enforcing a given set of matches in an SE tournament is NP-hard, there are natural restrictions that lead to polynomial-time solvability. In particular, we show polynomial-time solvability if there is a linear ordering on the ability of players with only a constant number of exceptions where a player with lower ability beats a player with higher ability.","sentences":["Single-elimination (SE) tournaments are a popular format used in competitive environments and decision making.","Algorithms for SE tournament manipulation have been an active topic of research in recent years.","In this paper, we initiate the algorithmic study of a novel variant of SE tournament manipulation that aims to model the fact that certain matchups are highly desired in a sporting context, incentivizing an organizer to manipulate the bracket to make such matchups take place.","We obtain both hardness and tractability results.","We show that while the problem of computing a bracket enforcing a given set of matches in an SE tournament is NP-hard, there are natural restrictions that lead to polynomial-time solvability.","In particular, we show polynomial-time solvability if there is a linear ordering on the ability of players with only a constant number of exceptions where a player with lower ability beats a player with higher ability."],"url":"http://arxiv.org/abs/2402.06538v1","category":"cs.DS"}
{"created":"2024-02-09 16:47:08","title":"Control of autoresonant plasma beat-wave wakefield excitation","abstract":"Autoresonant phase-locking of the plasma wakefield to the beat frequency of two driving lasers offers advantages over conventional wakefield acceleration methods, since it requires less demanding laser parameters and is robust to variations in the target plasma density. Here, we investigate the kinetic and nonlinear processes that come into play during autoresonant plasma beat-wave acceleration of electrons, their impact on the field amplitude of the accelerating structure, and on acceleration efficiency. Particle-in-Cell simulations show that the process depends on the plasma density in a non-trivial way but can be reliably modeled under specific conditions. Beside recovering previous fluid results in the deeply underdense plasma limit, we demonstrate that robust field excitation can be achieved within a fully kinetic self-consistent modeling. By adjusting the laser properties, we can amplify the electric field to the desired level, up to wave-breaking, and efficiently accelerate particles; we provide suggestions for optimized laser and plasma parameters. This versatile and efficient acceleration scheme, producing electrons from tens to hundreds of MeV energies, holds promise for a wide range of applications in research industry and medicine.","sentences":["Autoresonant phase-locking of the plasma wakefield to the beat frequency of two driving lasers offers advantages over conventional wakefield acceleration methods, since it requires less demanding laser parameters and is robust to variations in the target plasma density.","Here, we investigate the kinetic and nonlinear processes that come into play during autoresonant plasma beat-wave acceleration of electrons, their impact on the field amplitude of the accelerating structure, and on acceleration efficiency.","Particle-in-Cell simulations show that the process depends on the plasma density in a non-trivial way but can be reliably modeled under specific conditions.","Beside recovering previous fluid results in the deeply underdense plasma limit, we demonstrate that robust field excitation can be achieved within a fully kinetic self-consistent modeling.","By adjusting the laser properties, we can amplify the electric field to the desired level, up to wave-breaking, and efficiently accelerate particles; we provide suggestions for optimized laser and plasma parameters.","This versatile and efficient acceleration scheme, producing electrons from tens to hundreds of MeV energies, holds promise for a wide range of applications in research industry and medicine."],"url":"http://arxiv.org/abs/2402.06534v1","category":"physics.plasm-ph"}
{"created":"2024-02-09 16:37:08","title":"Flexible infinite-width graph convolutional networks and the importance of representation learning","abstract":"A common theoretical approach to understanding neural networks is to take an infinite-width limit, at which point the outputs become Gaussian process (GP) distributed. This is known as a neural network Gaussian process (NNGP). However, the NNGP kernel is fixed, and tunable only through a small number of hyperparameters, eliminating any possibility of representation learning. This contrasts with finite-width NNs, which are often believed to perform well precisely because they are able to learn representations. Thus in simplifying NNs to make them theoretically tractable, NNGPs may eliminate precisely what makes them work well (representation learning). This motivated us to understand whether representation learning is necessary in a range of graph classification tasks. We develop a precise tool for this task, the graph convolutional deep kernel machine. This is very similar to an NNGP, in that it is an infinite width limit and uses kernels, but comes with a `knob' to control the amount of representation learning. We found that representation learning is necessary (in the sense that it gives dramatic performance improvements) in graph classification tasks and heterophilous node classification tasks, but not in homophilous node classification tasks.","sentences":["A common theoretical approach to understanding neural networks is to take an infinite-width limit, at which point the outputs become Gaussian process (GP) distributed.","This is known as a neural network Gaussian process (NNGP).","However, the NNGP kernel is fixed, and tunable only through a small number of hyperparameters, eliminating any possibility of representation learning.","This contrasts with finite-width NNs, which are often believed to perform well precisely because they are able to learn representations.","Thus in simplifying NNs to make them theoretically tractable, NNGPs may eliminate precisely what makes them work well (representation learning).","This motivated us to understand whether representation learning is necessary in a range of graph classification tasks.","We develop a precise tool for this task, the graph convolutional deep kernel machine.","This is very similar to an NNGP, in that it is an infinite width limit and uses kernels, but comes with a `knob' to control the amount of representation learning.","We found that representation learning is necessary (in the sense that it gives dramatic performance improvements) in graph classification tasks and heterophilous node classification tasks, but not in homophilous node classification tasks."],"url":"http://arxiv.org/abs/2402.06525v1","category":"stat.ML"}
{"created":"2024-02-09 16:36:27","title":"Isochrone fitting of Galactic globular clusters -- V. NGC6397 and NGC6809 (M55)","abstract":"We fit various colour-magnitude diagrams (CMDs) of the Galactic globular clusters NGC\\,6397 and NGC\\,6809 (M55) by isochrones from the Dartmouth Stellar Evolution Database (DSED) and Bag of Stellar Tracks and Isochrones (BaSTI) for $\\alpha$-enhanced [$\\alpha$/Fe]$=+0.4$. For the CMDs, we use data sets from {\\it HST}, {\\it Gaia}, VISTA, and other sources utilizing 32 and 23 photometric filters for NGC\\,6397 and NGC\\,6809, respectively, from the ultraviolet to mid-infrared. We obtain the following characteristics for NGC\\,6397 and NGC\\,6809, respectively: metallicities [Fe/H]$=-1.84\\pm0.02\\pm0.1$ and $-1.78\\pm0.02\\pm0.1$ (statistic and systematic uncertainties); distances $2.45\\pm0.02\\pm0.06$ and $5.24\\pm0.02\\pm0.18$ kpc; ages $12.9\\pm0.1\\pm0.8$ and $13.0\\pm0.1\\pm0.8$ Gyr; reddenings $E(B-V)=0.178\\pm0.006\\pm0.01$ and $0.118\\pm0.004\\pm0.01$ mag; extinctions $A_\\mathrm{V}=0.59\\pm0.01\\pm0.02$ and $0.37\\pm0.01\\pm0.04$ mag; extinction-to-reddening ratio $R_\\mathrm{V}=3.32^{+0.32}_{-0.28}$ and $3.16^{+0.66}_{-0.56}$. Our estimates agree with most estimates from the literature. BaSTI gives systematically higher [Fe/H] and lower reddenings than DSED. Despite nearly the same metallicity, age, and helium enrichment, these clusters show a considerable horizontal branch (HB) morphology difference, which must therefore be described by another parameter. This parameter must predominantly explain why the least massive HB stars (0.58-0.63 solar masses) are only found within NGC 6809. Probably they have been lost by the core-collapse cluster NGC\\,6397 during its dynamical evolution and mass segregation. In contrast, NGC\\,6809 has a very low central concentration and, hence, did not undergo this process.","sentences":["We fit various colour-magnitude diagrams (CMDs) of the Galactic globular clusters NGC\\,6397","and NGC\\,6809 (M55) by isochrones from the Dartmouth Stellar Evolution Database (DSED) and Bag of Stellar Tracks and Isochrones (BaSTI) for $\\alpha$-enhanced [$\\alpha$/Fe]$=+0.4$. For the CMDs, we use data sets from {\\it HST}, {\\it Gaia}, VISTA, and other sources utilizing 32 and 23 photometric filters for NGC\\,6397 and NGC\\,6809, respectively, from the ultraviolet to mid-infrared.","We obtain the following characteristics for NGC\\,6397 and NGC\\,6809, respectively: metallicities [Fe/H]$=-1.84\\pm0.02\\pm0.1$ and $-1.78\\pm0.02\\pm0.1$ (statistic and systematic uncertainties); distances $2.45\\pm0.02\\pm0.06$ and $5.24\\pm0.02\\pm0.18$ kpc; ages $12.9\\pm0.1\\pm0.8$ and $13.0\\pm0.1\\pm0.8$ Gyr; reddenings $E(B-V)=0.178\\pm0.006\\pm0.01$ and $0.118\\pm0.004\\pm0.01$ mag; extinctions $A_\\mathrm{V}=0.59\\pm0.01\\pm0.02$ and $0.37\\pm0.01\\pm0.04$ mag; extinction-to-reddening ratio $R_\\mathrm{V}=3.32^{+0.32}_{-0.28}$ and $3.16^{+0.66}_{-0.56}$. Our estimates agree with most estimates from the literature.","BaSTI gives systematically higher [Fe/H] and lower reddenings than DSED.","Despite nearly the same metallicity, age, and helium enrichment, these clusters show a considerable horizontal branch (HB) morphology difference, which must therefore be described by another parameter.","This parameter must predominantly explain why the least massive HB stars (0.58-0.63 solar masses) are only found within NGC 6809.","Probably they have been lost by the core-collapse cluster NGC\\,6397","during its dynamical evolution and mass segregation.","In contrast, NGC\\,6809 has a very low central concentration and, hence, did not undergo this process."],"url":"http://arxiv.org/abs/2402.06524v1","category":"astro-ph.GA"}
{"created":"2024-02-09 16:30:25","title":"UV Irradiation Facility for Solar Effects Simulations","abstract":"We describe an experimental setup developed aiming to irradiate samples under UV radiation for accelerated test for solar effects according to the relevant ECSS-ESA standards. This facility has been already used for projects belonging to large space programs (Cosmic Vision, Artes) for simulations up to 3500 equivalent sun hours. In particular, we detail the calculation of the UV dose delivered by Sun, the calibration of the detectors, the spatial distribution of the UV radiation on samples, the remote control of both samples temperature and lamp radiation, the samples heat dissipation and operation in a helium atmosphere.","sentences":["We describe an experimental setup developed aiming to irradiate samples under UV radiation for accelerated test for solar effects according to the relevant ECSS-ESA standards.","This facility has been already used for projects belonging to large space programs (Cosmic Vision, Artes) for simulations up to 3500 equivalent sun hours.","In particular, we detail the calculation of the UV dose delivered by Sun, the calibration of the detectors, the spatial distribution of the UV radiation on samples, the remote control of both samples temperature and lamp radiation, the samples heat dissipation and operation in a helium atmosphere."],"url":"http://arxiv.org/abs/2402.06517v1","category":"hep-ex"}
{"created":"2024-02-09 16:23:54","title":"The Decisive Power of Indecision: Low-Variance Risk-Limiting Audits and Election Contestation via Marginal Mark Recording","abstract":"Risk-limiting audits (RLAs) are the established techniques for verifying large elections. While they provide rigorous guarantees of correctness, widespread adoption has been impeded by both efficiency concerns and the fact they offer statistical, rather than absolute, conclusions. We define new families of audits that help to address these issues. Our new audits are enabled by revisiting the standard notion of a cast-vote record so that it can declare multiple possible mark interpretations rather than a single decision; this can reflect the presence of ambiguous marks, which appear regularly on hand-marked ballots. We show that this simple expedient can offer significant efficiency improvements with only minor changes to existing auditing infrastructure. We establish that these \"Bayesian\" comparison audits are indeed risk-limiting in the formal sense of (Fuller, Harrison, and Russell, 2022). We then define a new type of post-election audit we call a contested audit. These call for each candidate to provide a cast-vote record table advancing their own claim to victory. We prove that these audits offer remarkable sample efficiency: they guarantee negligible risk with only a constant number of ballot inspections. This is a first for an audit with provable soundness. These results are formulated in a game-based security model that specify quantitative soundness and completeness guarantees. Finally, we observe that these audits provide a direct means to handle contestation of election results affirmed by conventional RLAs.","sentences":["Risk-limiting audits (RLAs) are the established techniques for verifying large elections.","While they provide rigorous guarantees of correctness, widespread adoption has been impeded by both efficiency concerns and the fact they offer statistical, rather than absolute, conclusions.","We define new families of audits that help to address these issues.","Our new audits are enabled by revisiting the standard notion of a cast-vote record so that it can declare multiple possible mark interpretations rather than a single decision; this can reflect the presence of ambiguous marks, which appear regularly on hand-marked ballots.","We show that this simple expedient can offer significant efficiency improvements with only minor changes to existing auditing infrastructure.","We establish that these \"Bayesian\" comparison audits are indeed risk-limiting in the formal sense of (Fuller, Harrison, and Russell, 2022).","We then define a new type of post-election audit we call a contested audit.","These call for each candidate to provide a cast-vote record table advancing their own claim to victory.","We prove that these audits offer remarkable sample efficiency: they guarantee negligible risk with only a constant number of ballot inspections.","This is a first for an audit with provable soundness.","These results are formulated in a game-based security model that specify quantitative soundness and completeness guarantees.","Finally, we observe that these audits provide a direct means to handle contestation of election results affirmed by conventional RLAs."],"url":"http://arxiv.org/abs/2402.06515v1","category":"cs.CR"}
{"created":"2024-02-09 15:41:14","title":"Exact continuous relaxations of l0-regularized criteria with non-quadratic data terms","abstract":"We propose a new class of exact continuous relaxations of l0-regularized criteria involving non-quadratic data terms such as the Kullback-Leibler divergence and the logistic regression, possibly combined with an l2 regularization. We first prove the existence of global minimizers for such problems and characterize their local minimizers.Then, we propose the l0 Bregman Relaxation (B-rex), a continuous approximation of the l0 pseudo-norm defined in terms of suitable Bregman distances, which leads to an exact continuous relaxations of the original l0-regularized problem in the sense that it does not alter its set of global minimizers and reduces the non-convexity by eliminating certain local minimizers. Both features make the relaxed problem more amenable to be solved by standard non-convex optimization algorithms. In this spirit, we consider the proximal gradient algorithm and provide explicit computation of proximal points for the B-rex penalty in several cases. Finally, we report a set of numerical results illustrating the geometrical behavior of the proposed B-rex penalty for different choices of the underlying Bregman distance, its relation with convex envelopes, as well as its exact relaxation properties in 1D/2D and higher dimensions.","sentences":["We propose a new class of exact continuous relaxations of l0-regularized criteria involving non-quadratic data terms such as the Kullback-Leibler divergence and the logistic regression, possibly combined with an l2 regularization.","We first prove the existence of global minimizers for such problems and characterize their local minimizers.","Then, we propose the l0 Bregman Relaxation (B-rex), a continuous approximation of the l0 pseudo-norm defined in terms of suitable Bregman distances, which leads to an exact continuous relaxations of the original l0-regularized problem in the sense that it does not alter its set of global minimizers and reduces the non-convexity by eliminating certain local minimizers.","Both features make the relaxed problem more amenable to be solved by standard non-convex optimization algorithms.","In this spirit, we consider the proximal gradient algorithm and provide explicit computation of proximal points for the B-rex penalty in several cases.","Finally, we report a set of numerical results illustrating the geometrical behavior of the proposed B-rex penalty for different choices of the underlying Bregman distance, its relation with convex envelopes, as well as its exact relaxation properties in 1D/2D and higher dimensions."],"url":"http://arxiv.org/abs/2402.06483v1","category":"math.OC"}
{"created":"2024-02-09 15:28:25","title":"New Interstellar Extinction Maps Based on Gaia and Other Sky Surveys","abstract":"We present new three-dimensional (3D) interstellar extinction maps in the $V$ and Gaia $G$ filters within 2 kpc of the Sun, a 3D differential extinction (dust spatial distribution density) map along the lines of sight in the same space, a 3D map of variations in the ratio of the extinctions in the $V$ and Gaia $G$ filters within 800 pc of the Sun, and a 2D map of total Galactic extinction through the entire dust half-layer from the Sun to extragalactic space for Galactic latitudes $|b|>13^{\\circ}$. The 3D maps have a transverse resolution from 3.6 to 11.6 pc and a radial resolution of 50 pc. The 2D map has an angular resolution of 6.1 arcmin. We have produced these maps based on the Gaia DR3 parallaxes and Gaia, Pan-STARRS1, SkyMapper, 2MASS, and WISE photometry for nearly 100 million stars. We have paid special attention to the space within 200 pc of the Sun and high Galactic latitudes as regions where the extinction estimates have had a large relative uncertainty so far. Our maps estimate the extinction within the Galactic dust layer from the Sun to an extended object or through the entire dust half-layer from the Sun to extragalactic space with a precision $\\sigma(A_\\mathrm{V})=0.06$ mag. This gives a high relative precision of extinction estimates even at high Galactic latitudes, where, according to our estimates, the median total Galactic extinction through the entire dust half-layer from the Sun to extragalactic objects is $A_\\mathrm{V}=0.12\\pm0.06$ mag. We have shown that the presented maps are among the best ones in data amount, space size, resolution, precision, and other properties.","sentences":["We present new three-dimensional (3D) interstellar extinction maps in the $V$ and Gaia $G$ filters within 2 kpc of the Sun, a 3D differential extinction (dust spatial distribution density) map along the lines of sight in the same space, a 3D map of variations in the ratio of the extinctions in the $V$ and Gaia $G$ filters within 800 pc of the Sun, and a 2D map of total Galactic extinction through the entire dust half-layer from the Sun to extragalactic space for Galactic latitudes $|b|>13^{\\circ}$. The 3D maps have a transverse resolution from 3.6 to 11.6 pc and a radial resolution of 50 pc.","The 2D map has an angular resolution of 6.1 arcmin.","We have produced these maps based on the Gaia DR3 parallaxes and Gaia, Pan-STARRS1, SkyMapper, 2MASS, and WISE photometry for nearly 100 million stars.","We have paid special attention to the space within 200 pc of the Sun and high Galactic latitudes as regions where the extinction estimates have had a large relative uncertainty so far.","Our maps estimate the extinction within the Galactic dust layer from the Sun to an extended object or through the entire dust half-layer from the Sun to extragalactic space with a precision $\\sigma(A_\\mathrm{V})=0.06$ mag.","This gives a high relative precision of extinction estimates even at high Galactic latitudes, where, according to our estimates, the median total Galactic extinction through the entire dust half-layer from the Sun to extragalactic objects is $A_\\mathrm{V}=0.12\\pm0.06$ mag.","We have shown that the presented maps are among the best ones in data amount, space size, resolution, precision, and other properties."],"url":"http://arxiv.org/abs/2402.06474v1","category":"astro-ph.GA"}
{"created":"2024-02-09 15:17:36","title":"Penning-trap measurement of the $Q$-value of the electron capture in $^{163}\\mathrm{Ho}$ for the determination of the electron neutrino mass","abstract":"The investigation of the absolute scale of the effective neutrino mass remains challenging due to the exclusively weak interaction of neutrinos with all known particles in the standard model of particle physics. Currently, the most precise and least model-dependent upper limit on the electron antineutrino mass is set by the KATRIN experiment from the analysis of the tritium \\b{eta}-decay. Another promising approach is the electron capture in $^{163}\\mathrm{Ho}$, which is under investigation using microcalorimetry within the ECHo and HOLMES collab orations. An independently measured Q-value of this process is vital for the assessment of systematic uncertainties in the neutrino mass determination. Here, we report a direct, independent determination of this $Q$-value by measuring the free-space cyclotron frequency ratio of highly charged ions of $^{163}\\mathrm{Ho}$ and $^{163}\\mathrm{Dy}$ in the Penning trap experiment \\textsc{Pentatrap}. Combining this ratio with atomic physics calculations of the electronic binding energies yields a $Q$-value of $2863.2(0.6)\\,\\mathrm{eV}/c^{2}$ - a more than 50-fold improvement over the state-of-the-art. This will enable the determination of the electron neutrino mass on a sub-eV level from the analysis of the electron capture in $^{163}\\mathrm{Ho}$.","sentences":["The investigation of the absolute scale of the effective neutrino mass remains challenging due to the exclusively weak interaction of neutrinos with all known particles in the standard model of particle physics.","Currently, the most precise and least model-dependent upper limit on the electron antineutrino mass is set by the KATRIN experiment from the analysis of the tritium \\b{eta}-decay.","Another promising approach is the electron capture in $^{163}\\mathrm{Ho}$, which is under investigation using microcalorimetry within the ECHo and HOLMES collab orations.","An independently measured Q-value of this process is vital for the assessment of systematic uncertainties in the neutrino mass determination.","Here, we report a direct, independent determination of this $Q$-value by measuring the free-space cyclotron frequency ratio of highly charged ions of $^{163}\\mathrm{Ho}$ and $^{163}\\mathrm{Dy}$ in the Penning trap experiment \\textsc{Pentatrap}.","Combining this ratio with atomic physics calculations of the electronic binding energies yields a $Q$-value of $2863.2(0.6)\\,\\mathrm{eV}/c^{2}$ - a more than 50-fold improvement over the state-of-the-art.","This will enable the determination of the electron neutrino mass on a sub-eV level from the analysis of the electron capture in $^{163}\\mathrm{Ho}$."],"url":"http://arxiv.org/abs/2402.06464v1","category":"nucl-ex"}
{"created":"2024-02-09 14:58:07","title":"An Algorithmic Framework for Constructing Multiple Decision Trees by Evaluating Their Combination Performance Throughout the Construction Process","abstract":"Predictions using a combination of decision trees are known to be effective in machine learning. Typical ideas for constructing a combination of decision trees for prediction are bagging and boosting. Bagging independently constructs decision trees without evaluating their combination performance and averages them afterward. Boosting constructs decision trees sequentially, only evaluating a combination performance of a new decision tree and the fixed past decision trees at each step. Therefore, neither method directly constructs nor evaluates a combination of decision trees for the final prediction. When the final prediction is based on a combination of decision trees, it is natural to evaluate the appropriateness of the combination when constructing them. In this study, we propose a new algorithmic framework that constructs decision trees simultaneously and evaluates their combination performance throughout the construction process. Our framework repeats two procedures. In the first procedure, we construct new candidates of combinations of decision trees to find a proper combination of decision trees. In the second procedure, we evaluate each combination performance of decision trees under some criteria and select a better combination. To confirm the performance of the proposed framework, we perform experiments on synthetic and benchmark data.","sentences":["Predictions using a combination of decision trees are known to be effective in machine learning.","Typical ideas for constructing a combination of decision trees for prediction are bagging and boosting.","Bagging independently constructs decision trees without evaluating their combination performance and averages them afterward.","Boosting constructs decision trees sequentially, only evaluating a combination performance of a new decision tree and the fixed past decision trees at each step.","Therefore, neither method directly constructs nor evaluates a combination of decision trees for the final prediction.","When the final prediction is based on a combination of decision trees, it is natural to evaluate the appropriateness of the combination when constructing them.","In this study, we propose a new algorithmic framework that constructs decision trees simultaneously and evaluates their combination performance throughout the construction process.","Our framework repeats two procedures.","In the first procedure, we construct new candidates of combinations of decision trees to find a proper combination of decision trees.","In the second procedure, we evaluate each combination performance of decision trees under some criteria and select a better combination.","To confirm the performance of the proposed framework, we perform experiments on synthetic and benchmark data."],"url":"http://arxiv.org/abs/2402.06452v1","category":"cs.LG"}
{"created":"2024-02-09 14:53:34","title":"Superconductivity in La$_4$Ni$_3$O$_{10}$ Under Pressure","abstract":"Recently, signature of superconductivity (SC) in the trilayer compound La$_{4}$Ni$_3$O$_{10}$ has ignited significant interest. In this study, we propose a trilayer $E_g$ orbital $t$-$J_{\\parallel}$-$J_{\\perp}$ model to gain insights into the superconducting behavior in this material. In the strong coupling limit, each layer is described by a $t$-$J_{\\parallel}$ model with intra-layer exchange $J_{\\parallel}$, while electrons can hop between layers and interact through inter-layer exchange $J_{\\perp}$. Notably, the inner-layer $3d_{z^2}$-orbital electrons exhibit the potential to form bonding bands with those in the upper or lower layer. The superconducting behavior is predominantly driven by the $3d_{z^2}$ orbital, resulting in an intra-layer extended $s$-wave pairing in the outer layers, along with an inter-layer pairing. Furthermore, electron doping tends to enhance the superconductivity, while hole doping suppresses it. These findings shed light on the intriguing SC of La$_{4}$Ni$_3$O$_{10}$ and its response to charge doping.","sentences":["Recently, signature of superconductivity (SC) in the trilayer compound La$_{4}$Ni$_3$O$_{10}$ has ignited significant interest.","In this study, we propose a trilayer $E_g$ orbital $t$-$J_{\\parallel}$-$J_{\\perp}$ model to gain insights into the superconducting behavior in this material.","In the strong coupling limit, each layer is described by a $t$-$J_{\\parallel}$ model with intra-layer exchange $J_{\\parallel}$, while electrons can hop between layers and interact through inter-layer exchange $J_{\\perp}$. Notably, the inner-layer $3d_{z^2}$-orbital electrons exhibit the potential to form bonding bands with those in the upper or lower layer.","The superconducting behavior is predominantly driven by the $3d_{z^2}$ orbital, resulting in an intra-layer extended $s$-wave pairing in the outer layers, along with an inter-layer pairing.","Furthermore, electron doping tends to enhance the superconductivity, while hole doping suppresses it.","These findings shed light on the intriguing SC of La$_{4}$Ni$_3$O$_{10}$ and its response to charge doping."],"url":"http://arxiv.org/abs/2402.06450v1","category":"cond-mat.supr-con"}
{"created":"2024-02-09 14:20:22","title":"BaMn$_2$P$_2$: Highest magnetic ordering temperature 122-pnictide compound","abstract":"We report the growth of high-quality single crystals of ThCr$_2$Si$_2$-type tetragonal BaMn$_2$P$_2$ and investigation of its structural, electrical transport, thermal and magnetic properties. Our results of basal plane electrical resistivity and heat capacity measurements show that the compound has an insulating ground state with a small band gap. Anisotropic susceptibility $\\chi_{ab,c}(T)$ data infer a collinear local-moment N\\'eel-type antiferromagnetic (AFM) ground state below the ordering temperature $T_{\\rm N} = 795(15)$~K, which is highest among all the ThCr$_2$Si$_2$- and CaAl$_2$Si$_2$-type 122-pnictide compounds reported so far suggesting that the strength of magnetic exchange interactions is strongest in this material. The magnetic transition temperatures of BaMn$_2$$Pn_{2}$ ($Pn$ = P, As, Sb, Bi) compounds exhibit a monotonic decrease with the increase of tetragonal unit cell parameters $a$ and $c$, suggesting a strong dependence of the strength of the decisive magnetic exchange interactions on the separation between the localized spins residing on the Mn-ions. The observed monotonic increase of both $\\chi_{ab}$ and $\\chi_{c}$ for $T > T_{\\rm N}$ suggests that short-range dynamic quasi-two dimensional AFM correlations persist above the $T_{\\rm N}$ up to the highest temperature of the measurements. The large $T_{\\rm N}$ of BaMn$_2$P$_2$ demands for systematic hole-doping studies on this material as similar investigations on related BaMn$_2$As$_{2}$ with $T_{\\rm N} = 618$~K have led to the discovery of an outstanding ground state where AFM of localized Mn-spins and itinerant half-metallic ferromagnetism with $T_{\\rm c} \\approx 100$~K originating from the doped holes coexist together.","sentences":["We report the growth of high-quality single crystals of ThCr$_2$Si$_2$-type tetragonal BaMn$_2$P$_2$ and investigation of its structural, electrical transport, thermal and magnetic properties.","Our results of basal plane electrical resistivity and heat capacity measurements show that the compound has an insulating ground state with a small band gap.","Anisotropic susceptibility $\\chi_{ab,c}(T)$ data infer a collinear local-moment N\\'eel-type antiferromagnetic (AFM) ground state below the ordering temperature $T_{\\rm N} = 795(15)$~K, which is highest among all the ThCr$_2$Si$_2$- and CaAl$_2$Si$_2$-type 122-pnictide compounds reported so far suggesting that the strength of magnetic exchange interactions is strongest in this material.","The magnetic transition temperatures of BaMn$_2$$Pn_{2}$ ($Pn$ = P, As, Sb, Bi) compounds exhibit a monotonic decrease with the increase of tetragonal unit cell parameters $a$ and $c$, suggesting a strong dependence of the strength of the decisive magnetic exchange interactions on the separation between the localized spins residing on the Mn-ions.","The observed monotonic increase of both $\\chi_{ab}$ and $\\chi_{c}$ for $T >","T_{\\rm N}$ suggests that short-range dynamic quasi-two dimensional AFM correlations persist above the $T_{\\rm N}$ up to the highest temperature of the measurements.","The large $T_{\\rm N}$ of BaMn$_2$P$_2$ demands for systematic hole-doping studies on this material as similar investigations on related BaMn$_2$As$_{2}$ with $T_{\\rm N} = 618$~K have led to the discovery of an outstanding ground state where AFM of localized Mn-spins and itinerant half-metallic ferromagnetism with $T_{\\rm c} \\approx 100$~K originating from the doped holes coexist together."],"url":"http://arxiv.org/abs/2402.06432v1","category":"cond-mat.str-el"}
{"created":"2024-02-09 14:20:14","title":"The van Trees inequality in the spirit of Hajek and Le Cam","abstract":"We work out a version of the van Trees inequality in a Hajek--Le Cam spirit, i.e., under minimal assumptions that, in particular, involve no direct pointwise regularity assumptions on densities but rather almost-everywhere differentiability in quadratic mean of the model. Surprisingly, it suffices that the latter differentiability holds along canonical directions -- not along all directions. Also, we identify a (slightly stronger) version of the van Trees inequality as a very instance of a Cramer--Rao bound, i.e., the van Trees inequality is not just a Bayesian analog of the Cramer--Rao bound. We provide, as an illustration, an elementary proof of the local asymptotic minimax theorem for quadratic loss functions, again assuming differentiability in quadratic mean only along canonical directions.","sentences":["We work out a version of the van Trees inequality in a Hajek--Le Cam spirit, i.e., under minimal assumptions that, in particular, involve no direct pointwise regularity assumptions on densities but rather almost-everywhere differentiability in quadratic mean of the model.","Surprisingly, it suffices that the latter differentiability holds along canonical directions -- not along all directions.","Also, we identify a (slightly stronger) version of the van Trees inequality as a very instance of a Cramer--Rao bound, i.e., the van Trees inequality is not just a Bayesian analog of the Cramer--Rao bound.","We provide, as an illustration, an elementary proof of the local asymptotic minimax theorem for quadratic loss functions, again assuming differentiability in quadratic mean only along canonical directions."],"url":"http://arxiv.org/abs/2402.06431v1","category":"math.ST"}
{"created":"2024-02-09 14:18:38","title":"Exact a posteriori error control for variational problems via convex duality and explicit flux reconstruction","abstract":"A posteriori error estimates are an important tool to bound discretization errors in terms of computable quantities avoiding regularity conditions that are often difficult to establish. For non-linear and non-differentiable problems, problems involving jumping coefficients, and finite element methods using anisotropic triangulations, such estimates often involve large factors, leading to sub-optimal error estimates. By making use of convex duality arguments, exact and explicit error representations are derived that avoid such effects.","sentences":["A posteriori error estimates are an important tool to bound discretization errors in terms of computable quantities avoiding regularity conditions that are often difficult to establish.","For non-linear and non-differentiable problems, problems involving jumping coefficients, and finite element methods using anisotropic triangulations, such estimates often involve large factors, leading to sub-optimal error estimates.","By making use of convex duality arguments, exact and explicit error representations are derived that avoid such effects."],"url":"http://arxiv.org/abs/2402.06429v1","category":"math.NA"}
{"created":"2024-02-09 14:15:07","title":"Random multiplicative functions and typical size of character in short intervals","abstract":"We examine the conditions under which the sum of random multiplicative functions in short intervals, given by $\\sum_{x<n \\leqslant x+y} f(n)$, exhibits the phenomenon of \\textit{better than square-root cancellation}. We establish that the point at which the square-root cancellation diminishes significantly is approximately when the ratio $\\log\\big(\\frac{x}{y}\\big)$ is around $\\sqrt{\\log\\log x}$. By modeling characters by random multiplicative functions, we give a sharp bound of $\\frac{1}{r-1}\\sum_{\\chi \\!\\!\\!\\mod r} \\big|\\sum_{x<n\\leqslant x+y}\\chi(n)\\big|$, where $r$ is a large prime and $x+y\\leqslant r $. This extends the result of Harper \\cite{Harper_charac}.","sentences":["We examine the conditions under which the sum of random multiplicative functions in short intervals, given by $\\sum_{x<n \\leqslant x+y} f(n)$, exhibits the phenomenon of \\textit{better than square-root cancellation}.","We establish that the point at which the square-root cancellation diminishes significantly is approximately when the ratio $\\log\\big(\\frac{x}{y}\\big)$ is around $\\sqrt{\\log\\log x}$.","By modeling characters by random multiplicative functions, we give a sharp bound of $\\frac{1}{r-1}\\sum_{\\chi \\!\\!\\!\\mod r} \\big|\\sum_{x<n\\leqslant x+y}\\chi(n)\\big|$, where $r$ is a large prime and $x+y\\leqslant r $.","This extends the result of Harper \\cite{Harper_charac}."],"url":"http://arxiv.org/abs/2402.06426v1","category":"math.NT"}
{"created":"2024-02-09 13:08:21","title":"Boosting-Based Sequential Meta-Tree Ensemble Construction for Improved Decision Trees","abstract":"A decision tree is one of the most popular approaches in machine learning fields. However, it suffers from the problem of overfitting caused by overly deepened trees. Then, a meta-tree is recently proposed. It solves the problem of overfitting caused by overly deepened trees. Moreover, the meta-tree guarantees statistical optimality based on Bayes decision theory. Therefore, the meta-tree is expected to perform better than the decision tree. In contrast to a single decision tree, it is known that ensembles of decision trees, which are typically constructed boosting algorithms, are more effective in improving predictive performance. Thus, it is expected that ensembles of meta-trees are more effective in improving predictive performance than a single meta-tree, and there are no previous studies that construct multiple meta-trees in boosting. Therefore, in this study, we propose a method to construct multiple meta-trees using a boosting approach. Through experiments with synthetic and benchmark datasets, we conduct a performance comparison between the proposed methods and the conventional methods using ensembles of decision trees. Furthermore, while ensembles of decision trees can cause overfitting as well as a single decision tree, experiments confirmed that ensembles of meta-trees can prevent overfitting due to the tree depth.","sentences":["A decision tree is one of the most popular approaches in machine learning fields.","However, it suffers from the problem of overfitting caused by overly deepened trees.","Then, a meta-tree is recently proposed.","It solves the problem of overfitting caused by overly deepened trees.","Moreover, the meta-tree guarantees statistical optimality based on Bayes decision theory.","Therefore, the meta-tree is expected to perform better than the decision tree.","In contrast to a single decision tree, it is known that ensembles of decision trees, which are typically constructed boosting algorithms, are more effective in improving predictive performance.","Thus, it is expected that ensembles of meta-trees are more effective in improving predictive performance than a single meta-tree, and there are no previous studies that construct multiple meta-trees in boosting.","Therefore, in this study, we propose a method to construct multiple meta-trees using a boosting approach.","Through experiments with synthetic and benchmark datasets, we conduct a performance comparison between the proposed methods and the conventional methods using ensembles of decision trees.","Furthermore, while ensembles of decision trees can cause overfitting as well as a single decision tree, experiments confirmed that ensembles of meta-trees can prevent overfitting due to the tree depth."],"url":"http://arxiv.org/abs/2402.06386v1","category":"stat.ML"}
{"created":"2024-02-09 13:00:27","title":"Robust Rao-type tests for step-stress accelerated life-tests under interval-monitoring and Weibull lifetime distributions","abstract":"Many products in engineering are highly reliable with large mean lifetimes to failure. Performing lifetests under normal operations conditions would thus require long experimentation times and high experimentation costs. Alternatively, accelerated lifetests shorten the experimentation time by running the tests at higher than normal stress conditions, thus inducing more failures. Additionally, a log-linear regression model can be used to relate the lifetime distribution of the product to the level of stress it experiences. After estimating the parameters of this relationship, results can be extrapolated to normal operating conditions. On the other hand, censored data is common in reliability analysis. Interval-censored data arise when continuous inspection is difficult or infeasible due to technical or budgetary constraints. In this paper, we develop robust restricted estimators based on the density power divergence for step-stress accelerated life-tests under Weibull distributions with interval-censored data. We present theoretical asymptotic properties of the estimators and develop robust Rao-type test statistics based on the proposed robust estimators for testing composite null hypothesis on the model parameters.","sentences":["Many products in engineering are highly reliable with large mean lifetimes to failure.","Performing lifetests under normal operations conditions would thus require long experimentation times and high experimentation costs.","Alternatively, accelerated lifetests shorten the experimentation time by running the tests at higher than normal stress conditions, thus inducing more failures.","Additionally, a log-linear regression model can be used to relate the lifetime distribution of the product to the level of stress it experiences.","After estimating the parameters of this relationship, results can be extrapolated to normal operating conditions.","On the other hand, censored data is common in reliability analysis.","Interval-censored data arise when continuous inspection is difficult or infeasible due to technical or budgetary constraints.","In this paper, we develop robust restricted estimators based on the density power divergence for step-stress accelerated life-tests under Weibull distributions with interval-censored data.","We present theoretical asymptotic properties of the estimators and develop robust Rao-type test statistics based on the proposed robust estimators for testing composite null hypothesis on the model parameters."],"url":"http://arxiv.org/abs/2402.06382v1","category":"stat.ME"}
{"created":"2024-02-09 12:54:56","title":"FD-Vision Mamba for Endoscopic Exposure Correction","abstract":"In endoscopic imaging, the recorded images are prone to exposure abnormalities, so maintaining high-quality images is important to assist healthcare professionals in performing decision-making. To overcome this issue, We design a frequency-domain based network, called FD-Vision Mamba (FDVM-Net), which achieves high-quality image exposure correction by reconstructing the frequency domain of endoscopic images. Specifically, inspired by the State Space Sequence Models (SSMs), we develop a C-SSM block that integrates the local feature extraction ability of the convolutional layer with the ability of the SSM to capture long-range dependencies. A two-path network is built using C-SSM as the basic function cell, and these two paths deal with the phase and amplitude information of the image, respectively. Finally, a degraded endoscopic image is reconstructed by FDVM-Net to obtain a high-quality clear image. Extensive experimental results demonstrate that our method achieves state-of-the-art results in terms of speed and accuracy, and it is noteworthy that our method can enhance endoscopic images of arbitrary resolution. The URL of the code is \\url{https://github.com/zzr-idam/FDVM-Net}.","sentences":["In endoscopic imaging, the recorded images are prone to exposure abnormalities, so maintaining high-quality images is important to assist healthcare professionals in performing decision-making.","To overcome this issue, We design a frequency-domain based network, called FD-Vision Mamba (FDVM-Net), which achieves high-quality image exposure correction by reconstructing the frequency domain of endoscopic images.","Specifically, inspired by the State Space Sequence Models (SSMs), we develop a C-SSM block that integrates the local feature extraction ability of the convolutional layer with the ability of the SSM to capture long-range dependencies.","A two-path network is built using C-SSM as the basic function cell, and these two paths deal with the phase and amplitude information of the image, respectively.","Finally, a degraded endoscopic image is reconstructed by FDVM-Net to obtain a high-quality clear image.","Extensive experimental results demonstrate that our method achieves state-of-the-art results in terms of speed and accuracy, and it is noteworthy that our method can enhance endoscopic images of arbitrary resolution.","The URL of the code is \\url{https://github.com/zzr-idam/FDVM-Net}."],"url":"http://arxiv.org/abs/2402.06378v1","category":"cs.CV"}
{"created":"2024-02-09 12:39:54","title":"The long-term steady motion of Saturn's Hexagon and the stability of its enclosed jet-stream under seasonal changes","abstract":"We investigate the long-term motion of Saturn's North-Pole Hexagon and the structure of its associated eastward jet, using Cassini ISS and ground-based images from 2008 to 2014. We show that both are persistent features that have survived the long polar night, the jet profile remaining essentially unchanged. During those years the hexagon vertices showed a steady rotation period of 10 hr 39 min 23.01 $\\pm$ 0.01 s. Analysis of Voyager 1 and 2 (1980-1981) and HST and ground-based (1990-91) images shows a period shorter by 3.5s, due to the presence at the time of a large anticyclone. We interpret the hexagon as a manifestation of a vertically trapped Rossby wave on the polar jet and, because of their survival and unchanged properties under the strong seasonal variations in insolation, we propose that both hexagon and jet are deep-rooted atmospheric features that could reveal the true rotation of the planet Saturn.","sentences":["We investigate the long-term motion of Saturn's North-Pole Hexagon and the structure of its associated eastward jet, using Cassini ISS and ground-based images from 2008 to 2014.","We show that both are persistent features that have survived the long polar night, the jet profile remaining essentially unchanged.","During those years the hexagon vertices showed a steady rotation period of 10 hr 39 min 23.01 $\\pm$ 0.01 s. Analysis of Voyager 1 and 2 (1980-1981) and HST and ground-based (1990-91) images shows a period shorter by 3.5s, due to the presence at the time of a large anticyclone.","We interpret the hexagon as a manifestation of a vertically trapped Rossby wave on the polar jet and, because of their survival and unchanged properties under the strong seasonal variations in insolation, we propose that both hexagon and jet are deep-rooted atmospheric features that could reveal the true rotation of the planet Saturn."],"url":"http://arxiv.org/abs/2402.06371v1","category":"astro-ph.EP"}
{"created":"2024-02-09 12:19:06","title":"TEE4EHR: Transformer Event Encoder for Better Representation Learning in Electronic Health Records","abstract":"Irregular sampling of time series in electronic health records (EHRs) is one of the main challenges for developing machine learning models. Additionally, the pattern of missing data in certain clinical variables is not at random but depends on the decisions of clinicians and the state of the patient. Point process is a mathematical framework for analyzing event sequence data that is consistent with irregular sampling patterns. Our model, TEE4EHR, is a transformer event encoder (TEE) with point process loss that encodes the pattern of laboratory tests in EHRs. The utility of our TEE has been investigated in a variety of benchmark event sequence datasets. Additionally, we conduct experiments on two real-world EHR databases to provide a more comprehensive evaluation of our model. Firstly, in a self-supervised learning approach, the TEE is jointly learned with an existing attention-based deep neural network which gives superior performance in negative log-likelihood and future event prediction. Besides, we propose an algorithm for aggregating attention weights that can reveal the interaction between the events. Secondly, we transfer and freeze the learned TEE to the downstream task for the outcome prediction, where it outperforms state-of-the-art models for handling irregularly sampled time series. Furthermore, our results demonstrate that our approach can improve representation learning in EHRs and can be useful for clinical prediction tasks.","sentences":["Irregular sampling of time series in electronic health records (EHRs) is one of the main challenges for developing machine learning models.","Additionally, the pattern of missing data in certain clinical variables is not at random but depends on the decisions of clinicians and the state of the patient.","Point process is a mathematical framework for analyzing event sequence data that is consistent with irregular sampling patterns.","Our model, TEE4EHR, is a transformer event encoder (TEE) with point process loss that encodes the pattern of laboratory tests in EHRs.","The utility of our TEE has been investigated in a variety of benchmark event sequence datasets.","Additionally, we conduct experiments on two real-world EHR databases to provide a more comprehensive evaluation of our model.","Firstly, in a self-supervised learning approach, the TEE is jointly learned with an existing attention-based deep neural network which gives superior performance in negative log-likelihood and future event prediction.","Besides, we propose an algorithm for aggregating attention weights that can reveal the interaction between the events.","Secondly, we transfer and freeze the learned TEE to the downstream task for the outcome prediction, where it outperforms state-of-the-art models for handling irregularly sampled time series.","Furthermore, our results demonstrate that our approach can improve representation learning in EHRs and can be useful for clinical prediction tasks."],"url":"http://arxiv.org/abs/2402.06367v1","category":"cs.LG"}
{"created":"2024-02-09 11:22:08","title":"InternLM-Math: Open Math Large Language Models Toward Verifiable Reasoning","abstract":"The math abilities of large language models can represent their abstract reasoning ability. In this paper, we introduce and open-source our math reasoning LLMs InternLM-Math which is continue pre-trained from InternLM2. We unify chain-of-thought reasoning, reward modeling, formal reasoning, data augmentation, and code interpreter in a unified seq2seq format and supervise our model to be a versatile math reasoner, verifier, prover, and augmenter. These abilities can be used to develop the next math LLMs or self-iteration. InternLM-Math obtains open-sourced state-of-the-art performance under the setting of in-context learning, supervised fine-tuning, and code-assisted reasoning in various informal and formal benchmarks including GSM8K, MATH, Hungary math exam, MathBench-ZH, and MiniF2F. Our pre-trained model achieves 30.3 on the MiniF2F test set without fine-tuning. We further explore how to use LEAN to solve math problems and study its performance under the setting of multi-task learning which shows the possibility of using LEAN as a unified platform for solving and proving in math. Our models, codes, and data are released at \\url{https://github.com/InternLM/InternLM-Math}.","sentences":["The math abilities of large language models can represent their abstract reasoning ability.","In this paper, we introduce and open-source our math reasoning LLMs InternLM-Math which is continue pre-trained from InternLM2.","We unify chain-of-thought reasoning, reward modeling, formal reasoning, data augmentation, and code interpreter in a unified seq2seq format and supervise our model to be a versatile math reasoner, verifier, prover, and augmenter.","These abilities can be used to develop the next math LLMs or self-iteration.","InternLM-Math obtains open-sourced state-of-the-art performance under the setting of in-context learning, supervised fine-tuning, and code-assisted reasoning in various informal and formal benchmarks including GSM8K, MATH, Hungary math exam, MathBench-ZH, and MiniF2F. Our pre-trained model achieves 30.3 on the MiniF2F test set without fine-tuning.","We further explore how to use LEAN to solve math problems and study its performance under the setting of multi-task learning which shows the possibility of using LEAN as a unified platform for solving and proving in math.","Our models, codes, and data are released at \\url{https://github.com/InternLM/InternLM-Math}."],"url":"http://arxiv.org/abs/2402.06332v1","category":"cs.CL"}
{"created":"2024-02-09 11:04:57","title":"The Effect of Haptic Guidance during Robotic-assisted Motor Training is Modulated by Personality Traits","abstract":"The provision of robotic assistance during motor training has proven to be effective in enhancing motor learning in some healthy trainee groups as well as patients. Personalizing such robotic assistance can help further improve motor (re)learning outcomes and cater better to the trainee's needs and desires. However, the development of personalized haptic assistance is hindered by the lack of understanding of the link between the trainee's personality and the effects of haptic guidance during human-robot interaction. To address this gap, we ran an experiment with 42 healthy participants who trained with a robotic device to control a virtual pendulum to hit incoming targets either with or without haptic guidance. We found that certain personal traits affected how users adapt and interact with the guidance during training. In particular, those participants with an 'Achiever gaming style' performed better and applied lower interaction forces to the robotic device than the average participant as the training progressed. Conversely, participants with the 'Free spirit game style' increased the interaction force in the course of training. We also found an interaction between some personal characteristics and haptic guidance. Specifically, participants with a higher 'Transformation of challenge' trait exhibited poorer performance during training while receiving haptic guidance compared to an average participant receiving haptic guidance. Furthermore, individuals with an external Locus of Control tended to increase their interaction force with the device, deviating from the pattern observed in an average participant under the same guidance. These findings suggest that individual characteristics may play a crucial role in the effectiveness of haptic guidance training strategies.","sentences":["The provision of robotic assistance during motor training has proven to be effective in enhancing motor learning in some healthy trainee groups as well as patients.","Personalizing such robotic assistance can help further improve motor (re)learning outcomes and cater better to the trainee's needs and desires.","However, the development of personalized haptic assistance is hindered by the lack of understanding of the link between the trainee's personality and the effects of haptic guidance during human-robot interaction.","To address this gap, we ran an experiment with 42 healthy participants who trained with a robotic device to control a virtual pendulum to hit incoming targets either with or without haptic guidance.","We found that certain personal traits affected how users adapt and interact with the guidance during training.","In particular, those participants with an 'Achiever gaming style' performed better and applied lower interaction forces to the robotic device than the average participant as the training progressed.","Conversely, participants with the 'Free spirit game style' increased the interaction force in the course of training.","We also found an interaction between some personal characteristics and haptic guidance.","Specifically, participants with a higher 'Transformation of challenge' trait exhibited poorer performance during training while receiving haptic guidance compared to an average participant receiving haptic guidance.","Furthermore, individuals with an external Locus of Control tended to increase their interaction force with the device, deviating from the pattern observed in an average participant under the same guidance.","These findings suggest that individual characteristics may play a crucial role in the effectiveness of haptic guidance training strategies."],"url":"http://arxiv.org/abs/2402.06325v1","category":"cs.RO"}
{"created":"2024-02-09 10:00:00","title":"On the Feasibility of Battery-Less LoRaWAN Communications using Energy Harvesting","abstract":"From the outset, batteries have been the main power source for the Internet of Things (IoT). However, replacing and disposing of billions of dead batteries per year is costly in terms of maintenance and ecologically irresponsible. Since batteries are one of the greatest threats to a sustainable IoT, battery-less devices are the solution to this problem. These devices run on long-lived capacitors charged using various forms of energy harvesting, which results in intermittent on-off device behaviour. In this work, we model this intermittent battery-less behaviour for LoRaWAN devices. This model allows us to characterize the performance with the aim to determine under which conditions a LoRaWAN device can work without batteries, and how its parameters should be configured. Results show that the reliability directly depends on device configurations (i.e., capacitor size, turn-on voltage threshold), application behaviour (i.e., transmission interval, packet size) and environmental conditions (i.e., energy harvesting rate).","sentences":["From the outset, batteries have been the main power source for the Internet of Things (IoT).","However, replacing and disposing of billions of dead batteries per year is costly in terms of maintenance and ecologically irresponsible.","Since batteries are one of the greatest threats to a sustainable IoT, battery-less devices are the solution to this problem.","These devices run on long-lived capacitors charged using various forms of energy harvesting, which results in intermittent on-off device behaviour.","In this work, we model this intermittent battery-less behaviour for LoRaWAN devices.","This model allows us to characterize the performance with the aim to determine under which conditions a LoRaWAN device can work without batteries, and how its parameters should be configured.","Results show that the reliability directly depends on device configurations (i.e., capacitor size, turn-on voltage threshold), application behaviour (i.e., transmission interval, packet size) and environmental conditions (i.e., energy harvesting rate)."],"url":"http://arxiv.org/abs/2402.06290v1","category":"cs.NI"}
{"created":"2024-02-09 09:48:38","title":"Retrieve, Merge, Predict: Augmenting Tables with Data Lakes","abstract":"We present an in-depth analysis of data discovery in data lakes, focusing on table augmentation for given machine learning tasks. We analyze alternative methods used in the three main steps: retrieving joinable tables, merging information, and predicting with the resultant table. As data lakes, the paper uses YADL (Yet Another Data Lake) -- a novel dataset we developed as a tool for benchmarking this data discovery task -- and Open Data US, a well-referenced real data lake. Through systematic exploration on both lakes, our study outlines the importance of accurately retrieving join candidates and the efficiency of simple merging methods. We report new insights on the benefits of existing solutions and on their limitations, aiming at guiding future research in this space.","sentences":["We present an in-depth analysis of data discovery in data lakes, focusing on table augmentation for given machine learning tasks.","We analyze alternative methods used in the three main steps: retrieving joinable tables, merging information, and predicting with the resultant table.","As data lakes, the paper uses YADL (Yet Another Data Lake) -- a novel dataset we developed as a tool for benchmarking this data discovery task -- and Open Data US, a well-referenced real data lake.","Through systematic exploration on both lakes, our study outlines the importance of accurately retrieving join candidates and the efficiency of simple merging methods.","We report new insights on the benefits of existing solutions and on their limitations, aiming at guiding future research in this space."],"url":"http://arxiv.org/abs/2402.06282v1","category":"cs.DB"}
{"created":"2024-02-09 09:40:12","title":"Neural SPH: Improved Neural Modeling of Lagrangian Fluid Dynamics","abstract":"Smoothed particle hydrodynamics (SPH) is omnipresent in modern engineering and scientific disciplines. SPH is a class of Lagrangian schemes that discretize fluid dynamics via finite material points that are tracked through the evolving velocity field. Due to the particle-like nature of the simulation, graph neural networks (GNNs) have emerged as appealing and successful surrogates. However, the practical utility of such GNN-based simulators relies on their ability to faithfully model physics, providing accurate and stable predictions over long time horizons - which is a notoriously hard problem. In this work, we identify particle clustering originating from tensile instabilities as one of the primary pitfalls. Based on these insights, we enhance both training and rollout inference of state-of-the-art GNN-based simulators with varying components from standard SPH solvers, including pressure, viscous, and external force components. All neural SPH-enhanced simulators achieve better performance, often by orders of magnitude, than the baseline GNNs, allowing for significantly longer rollouts and significantly better physics modeling. Code available under (https://github.com/tumaer/neuralsph).","sentences":["Smoothed particle hydrodynamics (SPH) is omnipresent in modern engineering and scientific disciplines.","SPH is a class of Lagrangian schemes that discretize fluid dynamics via finite material points that are tracked through the evolving velocity field.","Due to the particle-like nature of the simulation, graph neural networks (GNNs) have emerged as appealing and successful surrogates.","However, the practical utility of such GNN-based simulators relies on their ability to faithfully model physics, providing accurate and stable predictions over long time horizons - which is a notoriously hard problem.","In this work, we identify particle clustering originating from tensile instabilities as one of the primary pitfalls.","Based on these insights, we enhance both training and rollout inference of state-of-the-art GNN-based simulators with varying components from standard SPH solvers, including pressure, viscous, and external force components.","All neural SPH-enhanced simulators achieve better performance, often by orders of magnitude, than the baseline GNNs, allowing for significantly longer rollouts and significantly better physics modeling.","Code available under (https://github.com/tumaer/neuralsph)."],"url":"http://arxiv.org/abs/2402.06275v1","category":"physics.flu-dyn"}
{"created":"2024-02-09 09:37:28","title":"Adaptive proximal gradient methods are universal without approximation","abstract":"We show that adaptive proximal gradient methods for convex problems are not restricted to traditional Lipschitzian assumptions. Our analysis reveals that a class of linesearch-free methods is still convergent under mere local H\\\"older gradient continuity, covering in particular continuously differentiable semi-algebraic functions. To mitigate the lack of local Lipschitz continuity, popular approaches revolve around $\\varepsilon$-oracles and/or linesearch procedures. In contrast, we exploit plain H\\\"older inequalities not entailing any approximation, all while retaining the linesearch-free nature of adaptive schemes. Furthermore, we prove full sequence convergence without prior knowledge of local H\\\"older constants nor of the order of H\\\"older continuity. In numerical experiments we present comparisons to baseline methods on diverse tasks from machine learning covering both the locally and the globally H\\\"older setting.","sentences":["We show that adaptive proximal gradient methods for convex problems are not restricted to traditional Lipschitzian assumptions.","Our analysis reveals that a class of linesearch-free methods is still convergent under mere local H\\\"older gradient continuity, covering in particular continuously differentiable semi-algebraic functions.","To mitigate the lack of local Lipschitz continuity, popular approaches revolve around $\\varepsilon$-oracles and/or linesearch procedures.","In contrast, we exploit plain H\\\"older inequalities not entailing any approximation, all while retaining the linesearch-free nature of adaptive schemes.","Furthermore, we prove full sequence convergence without prior knowledge of local H\\\"older constants nor of the order of H\\\"older continuity.","In numerical experiments we present comparisons to baseline methods on diverse tasks from machine learning covering both the locally and the globally H\\\"older setting."],"url":"http://arxiv.org/abs/2402.06271v1","category":"math.OC"}
{"created":"2024-02-09 09:04:04","title":"Lipschitz bounds for nonuniformly elliptic integral functionals in the plane","abstract":"We study local regularity properties of local minimizer of scalar integral functionals with controlled $(p,q)$-growth in the two-dimensional plane. We establish Lipschitz continuity for local minimizer under the condition $1<p\\leq q<\\infty$ with $q<3p$ which improve upon the classical results valid in the regime $q<2p$. Along the way, we establish an $L^\\infty$-$L^2$-estimate for solutions of linear uniformly elliptic equations in the plane which is optimal with respect to the ellipticity contrast of the coefficients.","sentences":["We study local regularity properties of local minimizer of scalar integral functionals with controlled $(p,q)$-growth in the two-dimensional plane.","We establish Lipschitz continuity for local minimizer under the condition $1<p\\leq q<\\infty$ with $q<3p$ which improve upon the classical results valid in the regime $q<2p$. Along the way, we establish an $L^\\infty$-$L^2$-estimate for solutions of linear uniformly elliptic equations in the plane which is optimal with respect to the ellipticity contrast of the coefficients."],"url":"http://arxiv.org/abs/2402.06252v1","category":"math.AP"}
{"created":"2024-02-09 08:33:48","title":"Quantifying and Enhancing Multi-modal Robustness with Modality Preference","abstract":"Multi-modal models have shown a promising capability to effectively integrate information from various sources, yet meanwhile, they are found vulnerable to pervasive perturbations, such as uni-modal attacks and missing conditions. To counter these perturbations, robust multi-modal representations are highly expected, which are positioned well away from the discriminative multi-modal decision boundary. In this paper, different from conventional empirical studies, we focus on a commonly used joint multi-modal framework and theoretically discover that larger uni-modal representation margins and more reliable integration for modalities are essential components for achieving higher robustness. This discovery can further explain the limitation of multi-modal robustness and the phenomenon that multi-modal models are often vulnerable to attacks on the specific modality. Moreover, our analysis reveals how the widespread issue, that the model has different preferences for modalities, limits the multi-modal robustness by influencing the essential components and could lead to attacks on the specific modality highly effective. Inspired by our theoretical finding, we introduce a training procedure called Certifiable Robust Multi-modal Training (CRMT), which can alleviate this influence from modality preference and explicitly regulate essential components to significantly improve robustness in a certifiable manner. Our method demonstrates substantial improvements in performance and robustness compared with existing methods. Furthermore, our training procedure can be easily extended to enhance other robust training strategies, highlighting its credibility and flexibility.","sentences":["Multi-modal models have shown a promising capability to effectively integrate information from various sources, yet meanwhile, they are found vulnerable to pervasive perturbations, such as uni-modal attacks and missing conditions.","To counter these perturbations, robust multi-modal representations are highly expected, which are positioned well away from the discriminative multi-modal decision boundary.","In this paper, different from conventional empirical studies, we focus on a commonly used joint multi-modal framework and theoretically discover that larger uni-modal representation margins and more reliable integration for modalities are essential components for achieving higher robustness.","This discovery can further explain the limitation of multi-modal robustness and the phenomenon that multi-modal models are often vulnerable to attacks on the specific modality.","Moreover, our analysis reveals how the widespread issue, that the model has different preferences for modalities, limits the multi-modal robustness by influencing the essential components and could lead to attacks on the specific modality highly effective.","Inspired by our theoretical finding, we introduce a training procedure called Certifiable Robust Multi-modal Training (CRMT), which can alleviate this influence from modality preference and explicitly regulate essential components to significantly improve robustness in a certifiable manner.","Our method demonstrates substantial improvements in performance and robustness compared with existing methods.","Furthermore, our training procedure can be easily extended to enhance other robust training strategies, highlighting its credibility and flexibility."],"url":"http://arxiv.org/abs/2402.06244v1","category":"cs.CV"}
{"created":"2024-02-09 08:25:31","title":"Determining Stellar Elemental Abundances from DESI Spectra with the Data-Driven Payne","abstract":"Stellar abundances for a large number of stars are key information for the study of Galactic formation history. Large spectroscopic surveys such as DESI and LAMOST take median-to-low resolution ($R\\lesssim5000$) spectra in the full optical wavelength range for millions of stars. However, line blending effect in these spectra causes great challenges for the elemental abundances determination. Here we employ the DD-PAYNE, a data-driven method regularised by differential spectra from stellar physical models, to the DESI EDR spectra for stellar abundance determination. Our implementation delivers 15 labels, including effective temperature $T_{\\rm eff}$, surface gravity $\\log g$, microturbulence velocity $v_{\\rm mic}$, and abundances for 12 individual elements, namely C, N, O, Mg, Al, Si, Ca, Ti, Cr, Mn, Fe, Ni. Given a spectral signal-to-noise ratio of 100 per pixel, internal precision of the label estimates are about 20 K for $T_{\\rm eff}$, 0.05 dex for $\\log~g$, and 0.05 dex for most elemental abundances. These results are agree with theoretical limits from the Cr\\'amer-Rao bound calculation within a factor of two. The Gaia-Enceladus-Sausage that contributes the majority of the accreted halo stars are discernible from the disk and in-situ halo populations in the resultant [Mg/Fe]-[Fe/H] and [Al/Fe]-[Fe/H] abundance spaces. We also provide distance and orbital parameters for the sample stars, which spread a distance out to $\\sim$100 kpc. The DESI sample has a significant higher fraction of distant (or metal-poor) stars than other existed spectroscopic surveys, making it a powerful data set to study the Galactic outskirts. The catalog is publicly available.","sentences":["Stellar abundances for a large number of stars are key information for the study of Galactic formation history.","Large spectroscopic surveys such as DESI and LAMOST take median-to-low resolution ($R\\lesssim5000$) spectra in the full optical wavelength range for millions of stars.","However, line blending effect in these spectra causes great challenges for the elemental abundances determination.","Here we employ the DD-PAYNE, a data-driven method regularised by differential spectra from stellar physical models, to the DESI EDR spectra for stellar abundance determination.","Our implementation delivers 15 labels, including effective temperature $T_{\\rm eff}$, surface gravity $\\log g$, microturbulence velocity $v_{\\rm mic}$, and abundances for 12 individual elements, namely C, N, O, Mg, Al, Si, Ca, Ti, Cr, Mn, Fe, Ni.","Given a spectral signal-to-noise ratio of 100 per pixel, internal precision of the label estimates are about 20 K for $T_{\\rm eff}$, 0.05 dex for $\\log~g$, and 0.05 dex for most elemental abundances.","These results are agree with theoretical limits from the Cr\\'amer-Rao bound calculation within a factor of two.","The Gaia-Enceladus-Sausage that contributes the majority of the accreted halo stars are discernible from the disk and in-situ halo populations in the resultant [Mg/Fe]-[Fe/H] and [Al/Fe]-[Fe/H] abundance spaces.","We also provide distance and orbital parameters for the sample stars, which spread a distance out to $\\sim$100 kpc.","The DESI sample has a significant higher fraction of distant (or metal-poor) stars than other existed spectroscopic surveys, making it a powerful data set to study the Galactic outskirts.","The catalog is publicly available."],"url":"http://arxiv.org/abs/2402.06242v1","category":"astro-ph.GA"}
{"created":"2024-02-09 16:18:38","title":"Multimodal Clinical Trial Outcome Prediction with Large Language Models","abstract":"The clinical trial is a pivotal and costly process, often spanning multiple years and requiring substantial financial resources. Therefore, the development of clinical trial outcome prediction models aims to exclude drugs likely to fail and holds the potential for significant cost savings. Recent data-driven attempts leverage deep learning methods to integrate multimodal data for predicting clinical trial outcomes. However, these approaches rely on manually designed modal-specific encoders, which limits both the extensibility to adapt new modalities and the ability to discern similar information patterns across different modalities. To address these issues, we propose a multimodal mixture-of-experts (LIFTED) approach for clinical trial outcome prediction. Specifically, LIFTED unifies different modality data by transforming them into natural language descriptions. Then, LIFTED constructs unified noise-resilient encoders to extract information from modal-specific language descriptions. Subsequently, a sparse Mixture-of-Experts framework is employed to further refine the representations, enabling LIFTED to identify similar information patterns across different modalities and extract more consistent representations from those patterns using the same expert model. Finally, a mixture-of-experts module is further employed to dynamically integrate different modality representations for prediction, which gives LIFTED the ability to automatically weigh different modalities and pay more attention to critical information. The experiments demonstrate that LIFTED significantly enhances performance in predicting clinical trial outcomes across all three phases compared to the best baseline, showcasing the effectiveness of our proposed key components.","sentences":["The clinical trial is a pivotal and costly process, often spanning multiple years and requiring substantial financial resources.","Therefore, the development of clinical trial outcome prediction models aims to exclude drugs likely to fail and holds the potential for significant cost savings.","Recent data-driven attempts leverage deep learning methods to integrate multimodal data for predicting clinical trial outcomes.","However, these approaches rely on manually designed modal-specific encoders, which limits both the extensibility to adapt new modalities and the ability to discern similar information patterns across different modalities.","To address these issues, we propose a multimodal mixture-of-experts (LIFTED) approach for clinical trial outcome prediction.","Specifically, LIFTED unifies different modality data by transforming them into natural language descriptions.","Then, LIFTED constructs unified noise-resilient encoders to extract information from modal-specific language descriptions.","Subsequently, a sparse Mixture-of-Experts framework is employed to further refine the representations, enabling LIFTED to identify similar information patterns across different modalities and extract more consistent representations from those patterns using the same expert model.","Finally, a mixture-of-experts module is further employed to dynamically integrate different modality representations for prediction, which gives LIFTED the ability to automatically weigh different modalities and pay more attention to critical information.","The experiments demonstrate that LIFTED significantly enhances performance in predicting clinical trial outcomes across all three phases compared to the best baseline, showcasing the effectiveness of our proposed key components."],"url":"http://arxiv.org/abs/2402.06512v1","category":"cs.LG"}
{"created":"2024-02-09 15:53:19","title":"Sparse-grid Discontinuous Galerkin Methods for the Vlasov-Poisson-Lenard-Bernstein Model","abstract":"Sparse-grid methods have recently gained interest in reducing the computational cost of solving high-dimensional kinetic equations. In this paper, we construct adaptive and hybrid sparse-grid methods for the Vlasov-Poisson-Lenard-Bernstein (VPLB) model. This model has applications to plasma physics and is simulated in two reduced geometries: a 0x3v space homogeneous geometry and a 1x3v slab geometry. We use the discontinuous Galerkin (DG) method as a base discretization due to its high-order accuracy and ability to preserve important structural properties of partial differential equations. We utilize a multiwavelet basis expansion to determine the sparse-grid basis and the adaptive mesh criteria. We analyze the proposed sparse-grid methods on a suite of three test problems by computing the savings afforded by sparse-grids in comparison to standard solutions of the DG method. The results are obtained using the adaptive sparse-grid discretization library ASGarD.","sentences":["Sparse-grid methods have recently gained interest in reducing the computational cost of solving high-dimensional kinetic equations.","In this paper, we construct adaptive and hybrid sparse-grid methods for the Vlasov-Poisson-Lenard-Bernstein (VPLB) model.","This model has applications to plasma physics and is simulated in two reduced geometries: a 0x3v space homogeneous geometry and a 1x3v slab geometry.","We use the discontinuous Galerkin (DG) method as a base discretization due to its high-order accuracy and ability to preserve important structural properties of partial differential equations.","We utilize a multiwavelet basis expansion to determine the sparse-grid basis and the adaptive mesh criteria.","We analyze the proposed sparse-grid methods on a suite of three test problems by computing the savings afforded by sparse-grids in comparison to standard solutions of the DG method.","The results are obtained using the adaptive sparse-grid discretization library ASGarD."],"url":"http://arxiv.org/abs/2402.06493v1","category":"math.NA"}
{"created":"2024-02-09 15:41:04","title":"DASH Adaptation Algorithm Based on Adaptive Forgetting Factor Estimation","abstract":"The wide adoption of multimedia service capable mobile devices, the availability of better networks with higher bandwidths, and the availability of platforms offering digital content has led to an increasing popularity of multimedia streaming services. However, multimedia streaming services can be subject to different factors that affect the quality perceived by the users, such as service interruptions or quality oscillations due to changing network conditions, particularly in mobile networks. Dynamic Adaptive Streaming over HTTP (DASH), leverages the use of content-distribution networks and the capabilities of the multimedia devices to allow multimedia players to dynamically adapt the quality of the media streaming to the available bandwidth and the device characteristics. While many elements of DASH are standardized, the algorithms providing the dynamic adaptation of the streaming are not. The adaptation is often based on the estimation of the throughput or a buffer control mechanism. In this paper, we present a new throughput estimation adaptation algorithm based on a statistical method named Adaptive Forgetting Factor (AFF). Using this method, the adaptation logic is able to react appropriately to the different conditions of different types of networks. A set of experiments with different traffic profiles show that the proposed algorithm improves video quality performance in both wired and wireless environments.","sentences":["The wide adoption of multimedia service capable mobile devices, the availability of better networks with higher bandwidths, and the availability of platforms offering digital content has led to an increasing popularity of multimedia streaming services.","However, multimedia streaming services can be subject to different factors that affect the quality perceived by the users, such as service interruptions or quality oscillations due to changing network conditions, particularly in mobile networks.","Dynamic Adaptive Streaming over HTTP (DASH), leverages the use of content-distribution networks and the capabilities of the multimedia devices to allow multimedia players to dynamically adapt the quality of the media streaming to the available bandwidth and the device characteristics.","While many elements of DASH are standardized, the algorithms providing the dynamic adaptation of the streaming are not.","The adaptation is often based on the estimation of the throughput or a buffer control mechanism.","In this paper, we present a new throughput estimation adaptation algorithm based on a statistical method named Adaptive Forgetting Factor (AFF).","Using this method, the adaptation logic is able to react appropriately to the different conditions of different types of networks.","A set of experiments with different traffic profiles show that the proposed algorithm improves video quality performance in both wired and wireless environments."],"url":"http://arxiv.org/abs/2402.06482v1","category":"cs.NI"}
{"created":"2024-02-09 14:29:31","title":"Design of a 5G Multimedia Broadcast Application Function Supporting Adaptive Error Recovery","abstract":"The demand for mobile multimedia streaming services has been steadily growing in recent years. Mobile multimedia broadcasting addresses the shortage of radio resources but introduces a network error recovery problem. Retransmitting multimedia segments that are not correctly broadcast can cause service disruptions and increased service latency, affecting the quality of experience perceived by end users. With the advent of networking paradigms based on virtualization technologies, mobile networks have been enabled with more flexibility and agility to deploy innovative services that improve the utilization of available network resources. This paper discusses how mobile multimedia broadcast services can be designed to prevent service degradation by using the computing capabilities provided by multiaccess edge computing (MEC) platforms in the context of a 5G network architecture. An experimental platform has been developed to evaluate the feasibility of a MEC application to provide adaptive error recovery for multimedia broadcast services. The results of the experiments carried out show that the proposal provides a flexible mechanism that can be deployed at the network edge to lower the impact of transmission errors on latency and service disruptions.","sentences":["The demand for mobile multimedia streaming services has been steadily growing in recent years.","Mobile multimedia broadcasting addresses the shortage of radio resources but introduces a network error recovery problem.","Retransmitting multimedia segments that are not correctly broadcast can cause service disruptions and increased service latency, affecting the quality of experience perceived by end users.","With the advent of networking paradigms based on virtualization technologies, mobile networks have been enabled with more flexibility and agility to deploy innovative services that improve the utilization of available network resources.","This paper discusses how mobile multimedia broadcast services can be designed to prevent service degradation by using the computing capabilities provided by multiaccess edge computing (MEC) platforms in the context of a 5G network architecture.","An experimental platform has been developed to evaluate the feasibility of a MEC application to provide adaptive error recovery for multimedia broadcast services.","The results of the experiments carried out show that the proposal provides a flexible mechanism that can be deployed at the network edge to lower the impact of transmission errors on latency and service disruptions."],"url":"http://arxiv.org/abs/2402.06437v1","category":"cs.MM"}
{"created":"2024-02-09 14:16:20","title":"Quantum thermodynamics with a single superconducting vortex","abstract":"We demonstrate complete control over dynamics of a single superconducting vortex in a nanostructure which we coin the Single Vortex Box (SVB). Our device allows us to trap the vortex in a field-cooled aluminum nanosquare and expel it on demand with a nanosecond pulse of electrical current. We read-out the vortex state of the box by testing the switching current of the adjacent Dayem nanobridge. Using the time-resolving nanothermometry we measure 4$\\cdot$10$^{-19}\\,$J as the amount of the dissipated heat (which is the energy of a single red photon) in the elementary process of the vortex expulsion, and monitor the following thermal relaxation of the device. The measured heat is equal to the energy required to annihilate all Cooper pairs on the way of the moving vortex. Our design and measuring protocol are convenient for studying the stochastic mechanism of the vortex escape from current-driven superconducting nanowires, which has its roots either in thermal or quantum fluctuations, similar to ones widely studied in Josephson junctions or magnetic nanoclusters and molecules. Our experiment enlightens the thermodynamics of the absorption process in the superconducting nanowire single-photon detectors, in which vortices are perceived to be essential for a formation of a detectable hot spot. The demonstrated opportunity to manipulate a single superconducting vortex reliably in a confined geometry comprises in fact a proof-of-concept of a nanoscale non-volatile memory cell with sub-nanosecond write and read operations, which offers compatibility with quantum processors based either on superconducting qubits or rapid single flux quantum circuits.","sentences":["We demonstrate complete control over dynamics of a single superconducting vortex in a nanostructure which we coin the Single Vortex Box (SVB).","Our device allows us to trap the vortex in a field-cooled aluminum nanosquare and expel it on demand with a nanosecond pulse of electrical current.","We read-out the vortex state of the box by testing the switching current of the adjacent Dayem nanobridge.","Using the time-resolving nanothermometry we measure 4$\\cdot$10$^{-19}\\,$J as the amount of the dissipated heat (which is the energy of a single red photon) in the elementary process of the vortex expulsion, and monitor the following thermal relaxation of the device.","The measured heat is equal to the energy required to annihilate all Cooper pairs on the way of the moving vortex.","Our design and measuring protocol are convenient for studying the stochastic mechanism of the vortex escape from current-driven superconducting nanowires, which has its roots either in thermal or quantum fluctuations, similar to ones widely studied in Josephson junctions or magnetic nanoclusters and molecules.","Our experiment enlightens the thermodynamics of the absorption process in the superconducting nanowire single-photon detectors, in which vortices are perceived to be essential for a formation of a detectable hot spot.","The demonstrated opportunity to manipulate a single superconducting vortex reliably in a confined geometry comprises in fact a proof-of-concept of a nanoscale non-volatile memory cell with sub-nanosecond write and read operations, which offers compatibility with quantum processors based either on superconducting qubits or rapid single flux quantum circuits."],"url":"http://arxiv.org/abs/2402.06427v1","category":"cond-mat.supr-con"}
{"created":"2024-02-09 11:40:56","title":"Wetting ridge dissipation at large deformations","abstract":"Liquid drops slide more slowly over soft, deformable substrates than over rigid solids. This phenomenon can be attributed to the viscoelastic dissipation induced by the moving wetting ridge, which inhibits a rapid motion, and is called \"viscoelastic braking\". Experiments on soft dynamical wetting have thus far been modelled using linear theory, assuming small deformations, which captures the essential scaling laws. Quantitatively, however, some important disparities have suggested the importance of large deformations induced by the sliding drops. Here we compute the dissipation occurring below a contact line moving at constant velocity over a viscoelastic substrate, for the first time explicitly accounting for large deformations. It is found that linear theory becomes inaccurate especially for thin layers, and we discuss our findings in the light of recent experiments.","sentences":["Liquid drops slide more slowly over soft, deformable substrates than over rigid solids.","This phenomenon can be attributed to the viscoelastic dissipation induced by the moving wetting ridge, which inhibits a rapid motion, and is called \"viscoelastic braking\".","Experiments on soft dynamical wetting have thus far been modelled using linear theory, assuming small deformations, which captures the essential scaling laws.","Quantitatively, however, some important disparities have suggested the importance of large deformations induced by the sliding drops.","Here we compute the dissipation occurring below a contact line moving at constant velocity over a viscoelastic substrate, for the first time explicitly accounting for large deformations.","It is found that linear theory becomes inaccurate especially for thin layers, and we discuss our findings in the light of recent experiments."],"url":"http://arxiv.org/abs/2402.06344v1","category":"cond-mat.soft"}
{"created":"2024-02-09 09:41:55","title":"Wellposedness of the electron MHD without resistivity for large perturbations of the uniform magnetic field","abstract":"We prove the local wellposedness of the Cauchy problems for the electron magnetohydrodynamics equations (E-MHD) without resistivity for possibly large perturbations of nonzero uniform magnetic fields. While the local wellposedness problem for (E-MHD) has been extensively studied in the presence of resistivity (which provides dissipative effects), this seems to be the first such result without resistivity. (E-MHD) is a fluid description of plasma in small scales where the motion of electrons relative to ions is significant. Mathematically, it is a quasilinear dispersive equation with nondegenerate but nonelliptic second-order principal term. Our result significantly improves upon the straightforward adaptation of the classical work of Kenig--Ponce--Rolvung--Vega on the quasilinear ultrahyperbolic Schr\\\"odinger equations, as the regularity and decay assumptions on the initial data are greatly weakened to the level analogous to the recent work of Marzuola--Metcalfe--Tataru in the case of elliptic principal term.   A key ingredient of our proof is a simple observation about the relationship between the size of a symbol and the operator norm of its quantization as a pseudodifferential operator when restricted to high frequencies. This allows us to localize the (non-classical) pseudodifferential renormalization operator considered by Kenig--Ponce--Rolvung--Vega, and produce instead a classical pseudodifferential renormalization operator. We furthermore incorporate the function space framework of Marzuola--Metcalfe--Tataru to the present case of nonelliptic principal term.","sentences":["We prove the local wellposedness of the Cauchy problems for the electron magnetohydrodynamics equations (E-MHD) without resistivity for possibly large perturbations of nonzero uniform magnetic fields.","While the local wellposedness problem for (E-MHD) has been extensively studied in the presence of resistivity (which provides dissipative effects), this seems to be the first such result without resistivity.","(E-MHD) is a fluid description of plasma in small scales where the motion of electrons relative to ions is significant.","Mathematically, it is a quasilinear dispersive equation with nondegenerate but nonelliptic second-order principal term.","Our result significantly improves upon the straightforward adaptation of the classical work of Kenig--Ponce--Rolvung--Vega on the quasilinear ultrahyperbolic Schr\\\"odinger equations, as the regularity and decay assumptions on the initial data are greatly weakened to the level analogous to the recent work of Marzuola--Metcalfe--Tataru in the case of elliptic principal term.   ","A key ingredient of our proof is a simple observation about the relationship between the size of a symbol and the operator norm of its quantization as a pseudodifferential operator when restricted to high frequencies.","This allows us to localize the (non-classical) pseudodifferential renormalization operator considered by Kenig--Ponce--Rolvung--Vega, and produce instead a classical pseudodifferential renormalization operator.","We furthermore incorporate the function space framework of Marzuola--Metcalfe--Tataru to the present case of nonelliptic principal term."],"url":"http://arxiv.org/abs/2402.06278v1","category":"math.AP"}
{"created":"2024-02-09 18:51:11","title":"Polynomial parametrisation of the canonical iterates to the solution of $-\u03b3g'= g^{-1}$","abstract":"The iterates $h_0,h_1,h_2,\\dotsc$ constructed in [6] and converging to the (only) solution $g=h\\colon[0,1]\\to[0,1]$ of the iterative differential equation $-\\gamma g'= g^{-1}$, $\\gamma>0$, are parametrised by polynomials over $\\Bbb Q$, and the corresponding constant $\\gamma=\\kappa\\approx0.278877$ is estimated by rational numbers.","sentences":["The iterates $h_0,h_1,h_2,\\dotsc$ constructed in [6] and converging to the (only) solution $g=h\\colon[0,1]\\to[0,1]$ of the iterative differential equation $-\\gamma g'= g^{-1}$, $\\gamma>0$, are parametrised by polynomials over $\\Bbb Q$, and the corresponding constant $\\gamma=\\kappa\\approx0.278877$ is estimated by rational numbers."],"url":"http://arxiv.org/abs/2402.06618v1","category":"math.CO"}
{"created":"2024-02-09 18:16:44","title":"Damping of density oscillations from bulk viscosity in quark matter","abstract":"We study the damping of density oscillations in the quark matter phase that might occur in compact stars. To this end we compute the bulk viscosity and the associated damping time in three-flavor quark matter, considering both nonleptonic and semileptonic electroweak processes. We use two different equations of state of quark matter, more precisely, the MIT bag model and perturbative QCD, including the leading order corrections in the strong coupling constant. We analyze the dependence of our results on the density, temperature and value of strange quark mass in each case. We then find that the maximum of the bulk viscosity is in the range of temperature from 0.01 to 0.1 MeV for frequencies around 1 kHz, while the associated minimal damping times of the density oscillations at those temperatures might be in the range of few to hundreds milliseconds. Our results suggest that bulk viscous damping might be relevant in the post-merger phase after the collision of two neutron stars if deconfined matter is achieved in the process.","sentences":["We study the damping of density oscillations in the quark matter phase that might occur in compact stars.","To this end we compute the bulk viscosity and the associated damping time in three-flavor quark matter, considering both nonleptonic and semileptonic electroweak processes.","We use two different equations of state of quark matter, more precisely, the MIT bag model and perturbative QCD, including the leading order corrections in the strong coupling constant.","We analyze the dependence of our results on the density, temperature and value of strange quark mass in each case.","We then find that the maximum of the bulk viscosity is in the range of temperature from 0.01 to 0.1 MeV for frequencies around 1 kHz, while the associated minimal damping times of the density oscillations at those temperatures might be in the range of few to hundreds milliseconds.","Our results suggest that bulk viscous damping might be relevant in the post-merger phase after the collision of two neutron stars if deconfined matter is achieved in the process."],"url":"http://arxiv.org/abs/2402.06595v1","category":"hep-ph"}
{"created":"2024-02-09 17:36:03","title":"On primitive integer solutions of the Diophantine equation $x^3\\pm y^3=a^k\\pm b^k$","abstract":"In this note we consider the title Diophantine equation from both theoretical as well as experimental point of view. In particular, we prove that for $k=4, 6$ and each choice of the signs our equation has infinitely many co-prime positive integer solutions. For $k=5, 7$ and all choices of the signs we computed all co-prime positive integer solutions $(x, y, a, b)$ satisfying the condition $\\op{max}\\{a, b\\}\\leq 50000$.","sentences":["In this note we consider the title Diophantine equation from both theoretical as well as experimental point of view.","In particular, we prove that for $k=4, 6$ and each choice of the signs our equation has infinitely many co-prime positive integer solutions.","For $k=5, 7$ and all choices of the signs we computed all co-prime positive integer solutions $(x, y, a, b)$ satisfying the condition $\\op{max}\\{a, b\\}\\leq 50000$."],"url":"http://arxiv.org/abs/2402.06567v1","category":"math.NT"}
{"created":"2024-02-09 17:31:03","title":"A Review on the Analysis and Optimal Control of Chemotaxis-Consumption Models","abstract":"In the present review we focus on the chemotaxis-consumption model $\\partial_t u - \\Delta u = - \\nabla \\cdot (u \\nabla v)$ and $\\partial_t v - \\Delta v = - u^s v$ in $(0,T) \\times \\Omega$, for any fixed $s \\geq 1$, endowed with isolated boundary conditions and nonnegative initial conditions, where $(u,v)$ model cell density and chemical signal concentration. Our objective is to present an overview of the related literature and latest results on the aforementioned model concerning the following three distinct research lines we have obtained in [12,24-26]: the mathematical analysis, the numerical analysis and the related optimal control theory with a bilinear control acting on the chemical equation.","sentences":["In the present review we focus on the chemotaxis-consumption model $\\partial_t u - \\Delta u = - \\nabla \\cdot (u \\nabla v)$ and $\\partial_t v - \\Delta v = - u^s v$ in $(0,T) \\times \\Omega$, for any fixed $s \\geq 1$, endowed with isolated boundary conditions and nonnegative initial conditions, where $(u,v)$ model cell density and chemical signal concentration.","Our objective is to present an overview of the related literature and latest results on the aforementioned model concerning the following three distinct research lines we have obtained in [12,24-26]: the mathematical analysis, the numerical analysis and the related optimal control theory with a bilinear control acting on the chemical equation."],"url":"http://arxiv.org/abs/2402.06564v1","category":"math.AP"}
{"created":"2024-02-09 17:03:26","title":"Self Supervised Learning for Improved Calibrationless Radial MRI with NLINV-Net","abstract":"Purpose: To develop a neural network architecture for improved calibrationless reconstruction of radial data when no ground truth is available for training. Methods: NLINV-Net is a model-based neural network architecture that directly estimates images and coil sensitivities from (radial) k-space data via non-linear inversion (NLINV). Combined with a training strategy using self-supervision via data undersampling (SSDU), it can be used for imaging problems where no ground truth reconstructions are available. We validated the method for (1) real-time cardiac imaging and (2) single-shot subspace-based quantitative T1 mapping. Furthermore, region-optimized virtual (ROVir) coils were used to suppress artifacts stemming from outside the FoV and to focus the k-space based SSDU loss on the region of interest. NLINV-Net based reconstructions were compared with conventional NLINV and PI-CS (parallel imaging + compressed sensing) reconstruction and the effect of the region-optimized virtual coils and the type of training loss was evaluated qualitatively. Results: NLINV-Net based reconstructions contain significantly less noise than the NLINV-based counterpart. ROVir coils effectively suppress streakings which are not suppressed by the neural networks while the ROVir-based focussed loss leads to visually sharper time series for the movement of the myocardial wall in cardiac real-time imaging. For quantitative imaging, T1-maps reconstructed using NLINV-Net show similar quality as PI-CS reconstructions, but NLINV-Net does not require slice-specific tuning of the regularization parameter. Conclusion: NLINV-Net is a versatile tool for calibrationless imaging which can be used in challenging imaging scenarios where a ground truth is not available.","sentences":["Purpose: To develop a neural network architecture for improved calibrationless reconstruction of radial data when no ground truth is available for training.","Methods: NLINV-Net is a model-based neural network architecture that directly estimates images and coil sensitivities from (radial) k-space data via non-linear inversion (NLINV).","Combined with a training strategy using self-supervision via data undersampling (SSDU), it can be used for imaging problems where no ground truth reconstructions are available.","We validated the method for (1) real-time cardiac imaging and (2) single-shot subspace-based quantitative T1 mapping.","Furthermore, region-optimized virtual (ROVir) coils were used to suppress artifacts stemming from outside the FoV and to focus the k-space based SSDU loss on the region of interest.","NLINV-Net based reconstructions were compared with conventional NLINV and PI-CS (parallel imaging + compressed sensing) reconstruction and the effect of the region-optimized virtual coils and the type of training loss was evaluated qualitatively.","Results: NLINV-Net based reconstructions contain significantly less noise than the NLINV-based counterpart.","ROVir coils effectively suppress streakings which are not suppressed by the neural networks while the ROVir-based focussed loss leads to visually sharper time series for the movement of the myocardial wall in cardiac real-time imaging.","For quantitative imaging, T1-maps reconstructed using NLINV-Net show similar quality as PI-CS reconstructions, but NLINV-Net does not require slice-specific tuning of the regularization parameter.","Conclusion: NLINV-Net is a versatile tool for calibrationless imaging which can be used in challenging imaging scenarios where a ground truth is not available."],"url":"http://arxiv.org/abs/2402.06550v1","category":"physics.med-ph"}
{"created":"2024-02-09 16:31:51","title":"Topological strings and Higgsing trees","abstract":"6-dimensional superconformal field theories are exotic and fascinating. They emerge from compactifications of F-theory on Calabi-Yau elliptic fibrations, which grants them a rich array of dualities with various other formulations of string and M-theory. In this thesis, we consider extended families of elliptic fibrations, giving rise to 6d theories connected by Higgs transitions. These families not only encompass the moduli space of a specific manifold but also include other manifolds with different topologies.   Our investigation focuses on rank 1 6D superconformal field theories from two distinct angles. In Chapter 4, we employ modularity, which arises from the holomorphic anomaly equations, to compute the topological string partition function in terms of Jacobi modular forms. We also provide a prescription for obtaining the topological partition function of a Higgsed theory from its parent. Through this approach, we can explain numerous symmetry enhancements that we observed in our study.   On the other hand, in Chapter 5, we explore the 2D soliton of the 6D theory, the non-critical string. The elliptic genus of this non-critical string coincides with a part of the topological string partition function. By carefully studying this non-critical string, we propose an ansatz for the elliptic genera expressed in terms of characters of the associated current algebras. We present compelling evidence supporting the validity of this ansatz and unveil novel closed form expressions for the elliptic genera of these non-critical strings.   Through these investigations, we hope to shed light on the intriguing world of 6D superconformal field theories and uncover new insights into their remarkable properties and connections.","sentences":["6-dimensional superconformal field theories are exotic and fascinating.","They emerge from compactifications of F-theory on Calabi-Yau elliptic fibrations, which grants them a rich array of dualities with various other formulations of string and M-theory.","In this thesis, we consider extended families of elliptic fibrations, giving rise to 6d theories connected by Higgs transitions.","These families not only encompass the moduli space of a specific manifold but also include other manifolds with different topologies.   ","Our investigation focuses on rank 1 6D superconformal field theories from two distinct angles.","In Chapter 4, we employ modularity, which arises from the holomorphic anomaly equations, to compute the topological string partition function in terms of Jacobi modular forms.","We also provide a prescription for obtaining the topological partition function of a Higgsed theory from its parent.","Through this approach, we can explain numerous symmetry enhancements that we observed in our study.   ","On the other hand, in Chapter 5, we explore the 2D soliton of the 6D theory, the non-critical string.","The elliptic genus of this non-critical string coincides with a part of the topological string partition function.","By carefully studying this non-critical string, we propose an ansatz for the elliptic genera expressed in terms of characters of the associated current algebras.","We present compelling evidence supporting the validity of this ansatz and unveil novel closed form expressions for the elliptic genera of these non-critical strings.   ","Through these investigations, we hope to shed light on the intriguing world of 6D superconformal field theories and uncover new insights into their remarkable properties and connections."],"url":"http://arxiv.org/abs/2402.06519v1","category":"hep-th"}
{"created":"2024-02-09 16:31:41","title":"Dynamic swarms regulate the morphology and distribution of soft membrane domains","abstract":"We study the dynamic structure of lipid domain inclusions embedded within a phase-separated reconstituted lipid bilayer in contact with a swarming flow of gliding filamentous actin. Passive circular domains transition into highly-deformed morphologies that continuously elongate, rotate, and pinch off into smaller fragments, leading to a dynamic steady state with approximately 23x speed up in the relaxation of the intermediate scattering function compared to passive membrane domains driven by purely thermal forces. To corroborate experimental results, we develop a phase-field model of the lipid domains with two-way coupling to the Toner-Tu equations. We report phase domains that become entrained in the chaotic eddy patterns, with oscillating waves of domains that correlate with the dominant wavelengths of the Toner-Tu flow fields.","sentences":["We study the dynamic structure of lipid domain inclusions embedded within a phase-separated reconstituted lipid bilayer in contact with a swarming flow of gliding filamentous actin.","Passive circular domains transition into highly-deformed morphologies that continuously elongate, rotate, and pinch off into smaller fragments, leading to a dynamic steady state with approximately 23x speed up in the relaxation of the intermediate scattering function compared to passive membrane domains driven by purely thermal forces.","To corroborate experimental results, we develop a phase-field model of the lipid domains with two-way coupling to the Toner-Tu equations.","We report phase domains that become entrained in the chaotic eddy patterns, with oscillating waves of domains that correlate with the dominant wavelengths of the Toner-Tu flow fields."],"url":"http://arxiv.org/abs/2402.06518v1","category":"cond-mat.soft"}
{"created":"2024-02-09 16:14:48","title":"Non-Conforming Finite Element Method For Constrained Dirichlet Boundary Control Problem","abstract":"This article examines the Dirichlet boundary control problem governed by the Poisson equation, where the control variables are square integrable functions defined on the boundary of a two dimensional bounded, convex, polygonal domain. It employs an ultra weak formulation and utilizes Crouzeix-Raviart finite elements to discretize the state variable, while employing piecewise constants for the control variable discretization. The study demonstrates that the energy norm of an enriched discrete optimal control is uniformly bounded with respect to the discretization parameter. Furthermore, it establishes an optimal order a priori error estimate for the control variable.","sentences":["This article examines the Dirichlet boundary control problem governed by the Poisson equation, where the control variables are square integrable functions defined on the boundary of a two dimensional bounded, convex, polygonal domain.","It employs an ultra weak formulation and utilizes Crouzeix-Raviart finite elements to discretize the state variable, while employing piecewise constants for the control variable discretization.","The study demonstrates that the energy norm of an enriched discrete optimal control is uniformly bounded with respect to the discretization parameter.","Furthermore, it establishes an optimal order a priori error estimate for the control variable."],"url":"http://arxiv.org/abs/2402.06507v1","category":"math.OC"}
{"created":"2024-02-09 15:42:53","title":"On the equivalence of distributional and synthetic Ricci curvature lower bounds","abstract":"The goal of the paper is to prove the equivalence of distributional and synthetic Ricci curvature lower bounds for a weighted Riemannian manifold with continuous metric tensor having Christoffel symbols in $L^2_{{\\rm loc}}$, and with weight in $C^0\\cap W^{1,2}_{{\\rm loc}}$. The regularity assumptions are sharp, in the sense that they are minimal in order to define the distributional Ricci curvature tensor.","sentences":["The goal of the paper is to prove the equivalence of distributional and synthetic Ricci curvature lower bounds for a weighted Riemannian manifold with continuous metric tensor having Christoffel symbols in $L^2_{{\\rm loc}}$, and with weight in $C^0\\cap W^{1,2}_{{\\rm loc}}$.","The regularity assumptions are sharp, in the sense that they are minimal in order to define the distributional Ricci curvature tensor."],"url":"http://arxiv.org/abs/2402.06486v1","category":"math.DG"}
{"created":"2024-02-09 15:00:42","title":"Optical realization of magneto-intersubband oscillations","abstract":"We report on the optical realization of the magneto-intersubband oscillations that have been measured in the sub-terahertz transmittance of a GaAs quantum well with two subbands occupied. Following their dc analogue, the oscillations are periodic in the inverse magnetic field with the period governed by the subband gap. Their magnitude and polarization dependence accurately follow the presented simplified version of the dynamic magneto-intersubband oscillations equation that naturally combines dc magneto-intersabband oscillations with microwave-induced resistance oscillations (MIRO). Simultaneously measured photoresistance also reveals its strong sensitivity to the sign of the circular polarization, proving the used theoretical modeling.","sentences":["We report on the optical realization of the magneto-intersubband oscillations that have been measured in the sub-terahertz transmittance of a GaAs quantum well with two subbands occupied.","Following their dc analogue, the oscillations are periodic in the inverse magnetic field with the period governed by the subband gap.","Their magnitude and polarization dependence accurately follow the presented simplified version of the dynamic magneto-intersubband oscillations equation that naturally combines dc magneto-intersabband oscillations with microwave-induced resistance oscillations (MIRO).","Simultaneously measured photoresistance also reveals its strong sensitivity to the sign of the circular polarization, proving the used theoretical modeling."],"url":"http://arxiv.org/abs/2402.06453v1","category":"cond-mat.mes-hall"}
{"created":"2024-02-09 14:50:25","title":"Optimal rigidity estimates for maps of a compact Riemannian manifold to itself","abstract":"Let $M$ be a smooth, compact, connected, oriented Riemannian manifold, and let $\\imath: M \\to \\mathbb R^d$ be an isometric embedding. We show that a Sobolev map $f: M \\to M$ which has the property that the differential $df(q)$ is close to the set $SO(T_q M, T_{f(q)} M)$ of orientation preserving isometries (in an $L^p$ sense) is already $W^{1,p}$ close to a global isometry of $M$. More precisely we prove for $p \\in (1,\\infty)$ the optimal linear estimate $$\\inf_{\\phi \\in \\mathrm{Isom}_+(M)} \\| \\imath \\circ f - \\imath \\circ \\phi\\|_{W^{1,p}}^p \\le C E_p(f)$$ where $$ E_p(f) := \\int_M {\\rm dist}^p(df(q), SO(T_q M, T_{f(q)} M)) \\, d{\\rm vol}_M$$ and where $\\mathrm{Isom}_+(M)$ denotes the group of orientation preserving isometries of $M$.   This extends the Euclidean rigidity estimate of Friesecke-James-M\\\"uller [Comm. Pure Appl. Math. {\\bf 55} (2002), 1461--1506] to Riemannian manifolds. It also extends the Riemannian stability result of Kupferman-Maor-Shachar [Arch. Ration. Mech. Anal. {\\bf 231} (2019), 367--408] for sequences of maps with $E_p(f_k) \\to 0$ to an optimal quantitative estimate.   The proof relies on the weak   Riemannian Piola identity of Kupferman-Maor-Shachar, a uniform $C^{1,\\alpha}$ approximation through the harmonic map heat flow, and a linearization argument which reduces the estimate to the well-known Riemannian version of Korn's inequality.","sentences":["Let $M$ be a smooth, compact, connected, oriented Riemannian manifold, and let $\\imath: M \\to \\mathbb R^d$ be an isometric embedding.","We show that a Sobolev map $f: M \\to M$ which has the property that the differential $df(q)$ is close to the set $SO(T_q M, T_{f(q)} M)$ of orientation preserving isometries (in an $L^p$ sense) is already $W^{1,p}$ close to a global isometry of $M$. More precisely we prove for $p \\in (1,\\infty)$ the optimal linear estimate $$\\inf_{\\phi \\in \\mathrm{Isom}_+(M)} \\| \\imath \\circ f - \\imath \\circ \\phi\\|_{W^{1,p}}^p \\le C E_p(f)$$ where $$ E_p(f) :","= \\int_M {\\rm dist}^p(df(q), SO(T_q M, T_{f(q)} M))","\\, d{\\rm vol}_M$$ and where $\\mathrm{Isom}_+(M)$ denotes the group of orientation preserving isometries of $M$.   This extends the Euclidean rigidity estimate of Friesecke-James-M\\\"uller","[Comm.","Pure Appl.","Math. {\\bf 55} (2002), 1461--1506] to Riemannian manifolds.","It also extends the Riemannian stability result of Kupferman-Maor-Shachar [Arch.","Ration.","Mech.","Anal.","{\\bf 231} (2019), 367--408] for sequences of maps with $E_p(f_k) \\to 0$ to an optimal quantitative estimate.   ","The proof relies on the weak   Riemannian Piola identity of Kupferman-Maor-Shachar, a uniform $C^{1,\\alpha}$ approximation through the harmonic map heat flow, and a linearization argument which reduces the estimate to the well-known Riemannian version of Korn's inequality."],"url":"http://arxiv.org/abs/2402.06448v1","category":"math.AP"}
{"created":"2024-02-09 14:46:50","title":"The Deep Equilibrium Algorithmic Reasoner","abstract":"Recent work on neural algorithmic reasoning has demonstrated that graph neural networks (GNNs) could learn to execute classical algorithms. Doing so, however, has always used a recurrent architecture, where each iteration of the GNN aligns with an algorithm's iteration. Since an algorithm's solution is often an equilibrium, we conjecture and empirically validate that one can train a network to solve algorithmic problems by directly finding the equilibrium. Note that this does not require matching each GNN iteration with a step of the algorithm.","sentences":["Recent work on neural algorithmic reasoning has demonstrated that graph neural networks (GNNs) could learn to execute classical algorithms.","Doing so, however, has always used a recurrent architecture, where each iteration of the GNN aligns with an algorithm's iteration.","Since an algorithm's solution is often an equilibrium, we conjecture and empirically validate that one can train a network to solve algorithmic problems by directly finding the equilibrium.","Note that this does not require matching each GNN iteration with a step of the algorithm."],"url":"http://arxiv.org/abs/2402.06445v1","category":"cs.LG"}
{"created":"2024-02-09 14:34:28","title":"Incorporating Taylor Series and Recursive Structure in Neural Networks for Time Series Prediction","abstract":"Time series analysis is relevant in various disciplines such as physics, biology, chemistry, and finance. In this paper, we present a novel neural network architecture that integrates elements from ResNet structures, while introducing the innovative incorporation of the Taylor series framework. This approach demonstrates notable enhancements in test accuracy across many of the baseline datasets investigated. Furthermore, we extend our method to incorporate a recursive step, which leads to even further improvements in test accuracy. Our findings underscore the potential of our proposed model to significantly advance time series analysis methodologies, offering promising avenues for future research and application.","sentences":["Time series analysis is relevant in various disciplines such as physics, biology, chemistry, and finance.","In this paper, we present a novel neural network architecture that integrates elements from ResNet structures, while introducing the innovative incorporation of the Taylor series framework.","This approach demonstrates notable enhancements in test accuracy across many of the baseline datasets investigated.","Furthermore, we extend our method to incorporate a recursive step, which leads to even further improvements in test accuracy.","Our findings underscore the potential of our proposed model to significantly advance time series analysis methodologies, offering promising avenues for future research and application."],"url":"http://arxiv.org/abs/2402.06441v1","category":"cs.LG"}
{"created":"2024-02-09 13:31:46","title":"Dynamics near the origin of the long range scattering for the one-dimensional Schrodinger equation","abstract":"We consider the cubic Schrodinger equation on the line, for which the scattering theory requires modifications due to long range effects. We revisit the construction of the modified wave operator, and recall the construction of its inverse, in order to describe the asymptotic behavior of these operators near the origin. At leading order, these operators, whose definition includes a nonlinear modification in the phase compared to the linear dynamics, correspond to the identity. We compute explicitly the first corrector in the asymptotic expansion, and justify this expansion by error estimates.","sentences":["We consider the cubic Schrodinger equation on the line, for which the scattering theory requires modifications due to long range effects.","We revisit the construction of the modified wave operator, and recall the construction of its inverse, in order to describe the asymptotic behavior of these operators near the origin.","At leading order, these operators, whose definition includes a nonlinear modification in the phase compared to the linear dynamics, correspond to the identity.","We compute explicitly the first corrector in the asymptotic expansion, and justify this expansion by error estimates."],"url":"http://arxiv.org/abs/2402.06400v1","category":"math.AP"}
{"created":"2024-02-09 12:07:06","title":"The SpongeNet Attack: Sponge Weight Poisoning of Deep Neural Networks","abstract":"Sponge attacks aim to increase the energy consumption and computation time of neural networks deployed on hardware accelerators. Existing sponge attacks can be performed during inference via sponge examples or during training via Sponge Poisoning. Sponge examples leverage perturbations added to the model's input to increase energy and latency, while Sponge Poisoning alters the objective function of a model to induce inference-time energy/latency effects.   In this work, we propose a novel sponge attack called SpongeNet. SpongeNet is the first sponge attack that is performed directly on the parameters of a pre-trained model. Our experiments show that SpongeNet can successfully increase the energy consumption of vision models with fewer samples required than Sponge Poisoning. Our experiments indicate that poisoning defenses are ineffective if not adjusted specifically for the defense against Sponge Poisoning (i.e., they decrease batch normalization bias values). Our work shows that SpongeNet is more effective on StarGAN than the state-of-the-art. Additionally, SpongeNet is stealthier than the previous Sponge Poisoning attack as it does not require significant changes in the victim model's weights. Our experiments indicate that the SpongeNet attack can be performed even when an attacker has access to only 1% of the entire dataset and reach up to 11% energy increase.","sentences":["Sponge attacks aim to increase the energy consumption and computation time of neural networks deployed on hardware accelerators.","Existing sponge attacks can be performed during inference via sponge examples or during training via Sponge Poisoning.","Sponge examples leverage perturbations added to the model's input to increase energy and latency, while Sponge Poisoning alters the objective function of a model to induce inference-time energy/latency effects.   ","In this work, we propose a novel sponge attack called SpongeNet.","SpongeNet is the first sponge attack that is performed directly on the parameters of a pre-trained model.","Our experiments show that SpongeNet can successfully increase the energy consumption of vision models with fewer samples required than Sponge Poisoning.","Our experiments indicate that poisoning defenses are ineffective if not adjusted specifically for the defense against Sponge Poisoning (i.e., they decrease batch normalization bias values).","Our work shows that SpongeNet is more effective on StarGAN than the state-of-the-art.","Additionally, SpongeNet is stealthier than the previous Sponge Poisoning attack as it does not require significant changes in the victim model's weights.","Our experiments indicate that the SpongeNet attack can be performed even when an attacker has access to only 1% of the entire dataset and reach up to 11% energy increase."],"url":"http://arxiv.org/abs/2402.06357v1","category":"cs.CR"}
{"created":"2024-02-09 11:34:39","title":"Promoting Target Data in Context-aware Neural Machine Translation","abstract":"Standard context-aware neural machine translation (NMT) typically relies on parallel document-level data, exploiting both source and target contexts. Concatenation-based approaches in particular, still a strong baseline for document-level NMT, prepend source and/or target context sentences to the sentences to be translated, with model variants that exploit equal amounts of source and target data on each side achieving state-of-the-art results. In this work, we investigate whether target data should be further promoted within standard concatenation-based approaches, as most document-level phenomena rely on information that is present on the target language side. We evaluate novel concatenation-based variants where the target context is prepended to the source language, either in isolation or in combination with the source context. Experimental results in English-Russian and Basque-Spanish show that including target context in the source leads to large improvements on target language phenomena. On source-dependent phenomena, using only target language context in the source achieves parity with state-of-the-art concatenation approaches, or slightly underperforms, whereas combining source and target context on the source side leads to significant gains across the board.","sentences":["Standard context-aware neural machine translation (NMT) typically relies on parallel document-level data, exploiting both source and target contexts.","Concatenation-based approaches in particular, still a strong baseline for document-level NMT, prepend source and/or target context sentences to the sentences to be translated, with model variants that exploit equal amounts of source and target data on each side achieving state-of-the-art results.","In this work, we investigate whether target data should be further promoted within standard concatenation-based approaches, as most document-level phenomena rely on information that is present on the target language side.","We evaluate novel concatenation-based variants where the target context is prepended to the source language, either in isolation or in combination with the source context.","Experimental results in English-Russian and Basque-Spanish show that including target context in the source leads to large improvements on target language phenomena.","On source-dependent phenomena, using only target language context in the source achieves parity with state-of-the-art concatenation approaches, or slightly underperforms, whereas combining source and target context on the source side leads to significant gains across the board."],"url":"http://arxiv.org/abs/2402.06342v1","category":"cs.CL"}
{"created":"2024-02-09 11:08:01","title":"An It\u00f4-Wentzell formula for the fractional Brownian motion","abstract":"We prove an It\\^o-Wentzell formula for the fractional Brownian motion. As an application we derive an existence and uniqueness result for a class of stochastic differential equations driven by this stochastic process.","sentences":["We prove an It\\^o-Wentzell formula for the fractional Brownian motion.","As an application we derive an existence and uniqueness result for a class of stochastic differential equations driven by this stochastic process."],"url":"http://arxiv.org/abs/2402.06328v1","category":"math.PR"}
{"created":"2024-02-09 10:39:17","title":"Fractional nonlinear heat equations and characterizations of some function spaces in terms of fractional Gauss-Weierstrass semi-groups","abstract":"We present a new proof of the caloric smoothing related to the fractional Gauss-Weierstrass semi-group in Triebel-Lizorkin spaces. This property will be used to prove existence and uniqueness of mild and strong solutions of the Cauchy problem for a fractional nonlinear heat equation.","sentences":["We present a new proof of the caloric smoothing related to the fractional Gauss-Weierstrass semi-group in Triebel-Lizorkin spaces.","This property will be used to prove existence and uniqueness of mild and strong solutions of the Cauchy problem for a fractional nonlinear heat equation."],"url":"http://arxiv.org/abs/2402.06309v1","category":"math.AP"}
{"created":"2024-02-09 10:27:18","title":"On the control of the Burgers-alpha model","abstract":"This work is devoted to prove the local null controllability of the Burgers-$\\alpha$ model. The state is the solution to a regularized Burgers equation, where the transport term is of the form $zy_x$, $z=(Id-\\alpha^2\\frac{\\partial^2}{\\partial x^2})^{-1}y$ and $\\alpha>0$ is a small parameter. We also prove some results concerning the behavior of the null controls and associated states as $\\alpha\\to 0^+$.","sentences":["This work is devoted to prove the local null controllability of the Burgers-$\\alpha$ model.","The state is the solution to a regularized Burgers equation, where the transport term is of the form $zy_x$, $z=(Id-\\alpha^2\\frac{\\partial^2}{\\partial x^2})^{-1}y$ and $\\alpha>0$ is a small parameter.","We also prove some results concerning the behavior of the null controls and associated states as $\\alpha\\to 0^+$."],"url":"http://arxiv.org/abs/2402.06301v1","category":"math.OC"}
{"created":"2024-02-09 09:20:47","title":"Energy-based PINNs for solving coupled field problems: concepts and application to the optimal design of an induction heater","abstract":"Physics-informed neural networks (PINNs) are neural networks (NNs) that directly encode model equations, like Partial Differential Equations (PDEs), in the network itself. While most of the PINN algorithms in the literature minimize the local residual of the governing equations, there are energy-based approaches that take a different path by minimizing the variational energy of the model. We show that in the case of the steady thermal equation weakly coupled to magnetic equation, the energy-based approach displays multiple advantages compared to the standard residual-based PINN: it is more computationally efficient, it requires a lower order of derivatives to compute, and it involves less hyperparameters. The analyzed benchmark problem is the optimal design of an inductor for the controlled heating of a graphite plate. The optimized device is designed involving a multi-physics problem: a time-harmonic magnetic problem and a steady thermal problem. For the former, a deep neural network solving the direct problem is supervisedly trained on Finite Element Analysis (FEA) data. In turn, the solution of the latter relies on a hypernetwork that takes as input the inductor geometry parameters and outputs the model weights of an energy-based PINN (or ePINN). Eventually, the ePINN predicts the temperature field within the graphite plate.","sentences":["Physics-informed neural networks (PINNs) are neural networks (NNs) that directly encode model equations, like Partial Differential Equations (PDEs), in the network itself.","While most of the PINN algorithms in the literature minimize the local residual of the governing equations, there are energy-based approaches that take a different path by minimizing the variational energy of the model.","We show that in the case of the steady thermal equation weakly coupled to magnetic equation, the energy-based approach displays multiple advantages compared to the standard residual-based PINN: it is more computationally efficient, it requires a lower order of derivatives to compute, and it involves less hyperparameters.","The analyzed benchmark problem is the optimal design of an inductor for the controlled heating of a graphite plate.","The optimized device is designed involving a multi-physics problem: a time-harmonic magnetic problem and a steady thermal problem.","For the former, a deep neural network solving the direct problem is supervisedly trained on Finite Element Analysis (FEA) data.","In turn, the solution of the latter relies on a hypernetwork that takes as input the inductor geometry parameters and outputs the model weights of an energy-based PINN (or ePINN).","Eventually, the ePINN predicts the temperature field within the graphite plate."],"url":"http://arxiv.org/abs/2402.06261v1","category":"cs.CE"}
{"created":"2024-02-09 08:40:33","title":"Data-driven Joint Detection and Localization of Acoustic Reflectors","abstract":"Room geometry inference algorithms rely on the localization of acoustic reflectors to identify boundary surfaces of an enclosure. Rooms with highly absorptive walls or walls at large distances from the measurement setup pose challenges for such algorithms. As it is not always possible to localize all walls, we present a data-driven method to jointly detect and localize acoustic reflectors that correspond to nearby and/or reflective walls. A multi-branch convolutional recurrent neural network is employed for this purpose. The network's input consists of a time-domain acoustic beamforming map, obtained via Radon transform from multi-channel room impulse responses. A modified loss function is proposed that forces the network to pay more attention to walls that can be estimated with a small error. Simulation results show that the proposed method can detect nearby and/or reflective walls and improve the localization performance for the detected walls.","sentences":["Room geometry inference algorithms rely on the localization of acoustic reflectors to identify boundary surfaces of an enclosure.","Rooms with highly absorptive walls or walls at large distances from the measurement setup pose challenges for such algorithms.","As it is not always possible to localize all walls, we present a data-driven method to jointly detect and localize acoustic reflectors that correspond to nearby and/or reflective walls.","A multi-branch convolutional recurrent neural network is employed for this purpose.","The network's input consists of a time-domain acoustic beamforming map, obtained via Radon transform from multi-channel room impulse responses.","A modified loss function is proposed that forces the network to pay more attention to walls that can be estimated with a small error.","Simulation results show that the proposed method can detect nearby and/or reflective walls and improve the localization performance for the detected walls."],"url":"http://arxiv.org/abs/2402.06246v1","category":"eess.AS"}
{"created":"2024-02-09 18:01:15","title":"More than the Sum of Its Parts: Ensembling Backbone Networks for Few-Shot Segmentation","abstract":"Semantic segmentation is a key prerequisite to robust image understanding for applications in \\acrlong{ai} and Robotics. \\acrlong{fss}, in particular, concerns the extension and optimization of traditional segmentation methods in challenging conditions where limited training examples are available. A predominant approach in \\acrlong{fss} is to rely on a single backbone for visual feature extraction. Choosing which backbone to leverage is a deciding factor contributing to the overall performance. In this work, we interrogate on whether fusing features from different backbones can improve the ability of \\acrlong{fss} models to capture richer visual features. To tackle this question, we propose and compare two ensembling techniques-Independent Voting and Feature Fusion. Among the available \\acrlong{fss} methods, we implement the proposed ensembling techniques on PANet. The module dedicated to predicting segmentation masks from the backbone embeddings in PANet avoids trainable parameters, creating a controlled `in vitro' setting for isolating the impact of different ensembling strategies. Leveraging the complementary strengths of different backbones, our approach outperforms the original single-backbone PANet across standard benchmarks even in challenging one-shot learning scenarios. Specifically, it achieved a performance improvement of +7.37\\% on PASCAL-5\\textsuperscript{i} and of +10.68\\% on COCO-20\\textsuperscript{i} in the top-performing scenario where three backbones are combined. These results, together with the qualitative inspection of the predicted subject masks, suggest that relying on multiple backbones in PANet leads to a more comprehensive feature representation, thus expediting the successful application of \\acrlong{fss} methods in challenging, data-scarce environments.","sentences":["Semantic segmentation is a key prerequisite to robust image understanding for applications in \\acrlong{ai} and Robotics.","\\acrlong{fss}, in particular, concerns the extension and optimization of traditional segmentation methods in challenging conditions where limited training examples are available.","A predominant approach in \\acrlong{fss} is to rely on a single backbone for visual feature extraction.","Choosing which backbone to leverage is a deciding factor contributing to the overall performance.","In this work, we interrogate on whether fusing features from different backbones can improve the ability of \\acrlong{fss} models to capture richer visual features.","To tackle this question, we propose and compare two ensembling techniques-Independent Voting and Feature Fusion.","Among the available \\acrlong{fss} methods, we implement the proposed ensembling techniques on PANet.","The module dedicated to predicting segmentation masks from the backbone embeddings in PANet avoids trainable parameters, creating a controlled `in vitro' setting for isolating the impact of different ensembling strategies.","Leveraging the complementary strengths of different backbones, our approach outperforms the original single-backbone PANet across standard benchmarks even in challenging one-shot learning scenarios.","Specifically, it achieved a performance improvement of +7.37\\% on PASCAL-5\\textsuperscript{i} and of +10.68\\% on COCO-20\\textsuperscript{i} in the top-performing scenario where three backbones are combined.","These results, together with the qualitative inspection of the predicted subject masks, suggest that relying on multiple backbones in PANet leads to a more comprehensive feature representation, thus expediting the successful application of \\acrlong{fss} methods in challenging, data-scarce environments."],"url":"http://arxiv.org/abs/2402.06581v1","category":"cs.CV"}
{"created":"2024-02-09 17:21:04","title":"Mitigating topological freezing using out-of-equilibrium simulations","abstract":"Motivated by the recently-established connection between Jarzynski's equality and the theoretical framework of Stochastic Normalizing Flows, we investigate a protocol relying on out-of-equilibrium lattice Monte Carlo simulations to mitigate the infamous computational problem of topological freezing. We test our proposal on $2d$ $\\mathrm{CP}^{N-1}$ models and compare our results with those obtained adopting the Parallel Tempering on Boundary Conditions proposed by M. Hasenbusch, obtaining comparable performances. Our work thus sets the stage for future applications combining our Monte Carlo setup with machine learning techniques.","sentences":["Motivated by the recently-established connection between Jarzynski's equality and the theoretical framework of Stochastic Normalizing Flows, we investigate a protocol relying on out-of-equilibrium lattice Monte Carlo simulations to mitigate the infamous computational problem of topological freezing.","We test our proposal on $2d$ $\\mathrm{CP}^{N-1}$ models and compare our results with those obtained adopting the Parallel Tempering on Boundary Conditions proposed by M. Hasenbusch, obtaining comparable performances.","Our work thus sets the stage for future applications combining our Monte Carlo setup with machine learning techniques."],"url":"http://arxiv.org/abs/2402.06561v1","category":"hep-lat"}
{"created":"2024-02-09 16:49:13","title":"Bandit Convex Optimisation","abstract":"Bandit convex optimisation is a fundamental framework for studying zeroth-order convex optimisation. These notes cover the many tools used for this problem, including cutting plane methods, interior point methods, continuous exponential weights, gradient descent and online Newton step. The nuances between the many assumptions and setups are explained. Although there is not much truly new here, some existing tools are applied in novel ways to obtain new algorithms. A few bounds are improved in minor ways.","sentences":["Bandit convex optimisation is a fundamental framework for studying zeroth-order convex optimisation.","These notes cover the many tools used for this problem, including cutting plane methods, interior point methods, continuous exponential weights, gradient descent and online Newton step.","The nuances between the many assumptions and setups are explained.","Although there is not much truly new here, some existing tools are applied in novel ways to obtain new algorithms.","A few bounds are improved in minor ways."],"url":"http://arxiv.org/abs/2402.06535v1","category":"math.OC"}
{"created":"2024-02-09 16:43:34","title":"Transferring facade labels between point clouds with semantic octrees while considering change detection","abstract":"Point clouds and high-resolution 3D data have become increasingly important in various fields, including surveying, construction, and virtual reality. However, simply having this data is not enough; to extract useful information, semantic labeling is crucial. In this context, we propose a method to transfer annotations from a labeled to an unlabeled point cloud using an octree structure. The structure also analyses changes between the point clouds. Our experiments confirm that our method effectively transfers annotations while addressing changes. The primary contribution of this project is the development of the method for automatic label transfer between two different point clouds that represent the same real-world object. The proposed method can be of great importance for data-driven deep learning algorithms as it can also allow circumventing stochastic transfer learning by deterministic label transfer between datasets depicting the same objects.","sentences":["Point clouds and high-resolution 3D data have become increasingly important in various fields, including surveying, construction, and virtual reality.","However, simply having this data is not enough; to extract useful information, semantic labeling is crucial.","In this context, we propose a method to transfer annotations from a labeled to an unlabeled point cloud using an octree structure.","The structure also analyses changes between the point clouds.","Our experiments confirm that our method effectively transfers annotations while addressing changes.","The primary contribution of this project is the development of the method for automatic label transfer between two different point clouds that represent the same real-world object.","The proposed method can be of great importance for data-driven deep learning algorithms as it can also allow circumventing stochastic transfer learning by deterministic label transfer between datasets depicting the same objects."],"url":"http://arxiv.org/abs/2402.06531v1","category":"cs.CV"}
{"created":"2024-02-09 16:34:28","title":"Reconstructing facade details using MLS point clouds and Bag-of-Words approach","abstract":"In the reconstruction of fa\\c{c}ade elements, the identification of specific object types remains challenging and is often circumvented by rectangularity assumptions or the use of bounding boxes. We propose a new approach for the reconstruction of 3D fa\\c{c}ade details. We combine MLS point clouds and a pre-defined 3D model library using a BoW concept, which we augment by incorporating semi-global features. We conduct experiments on the models superimposed with random noise and on the TUM-FA\\c{C}ADE dataset. Our method demonstrates promising results, improving the conventional BoW approach. It holds the potential to be utilized for more realistic facade reconstruction without rectangularity assumptions, which can be used in applications such as testing automated driving functions or estimating fa\\c{c}ade solar potential.","sentences":["In the reconstruction of fa\\c{c}ade elements, the identification of specific object types remains challenging and is often circumvented by rectangularity assumptions or the use of bounding boxes.","We propose a new approach for the reconstruction of 3D fa\\c{c}ade details.","We combine MLS point clouds and a pre-defined 3D model library using a BoW concept, which we augment by incorporating semi-global features.","We conduct experiments on the models superimposed with random noise and on the TUM-FA\\c{C}ADE dataset.","Our method demonstrates promising results, improving the conventional BoW approach.","It holds the potential to be utilized for more realistic facade reconstruction without rectangularity assumptions, which can be used in applications such as testing automated driving functions or estimating fa\\c{c}ade solar potential."],"url":"http://arxiv.org/abs/2402.06521v1","category":"cs.CV"}
{"created":"2024-02-09 13:07:22","title":"Maia: A Real-time Non-Verbal Chat for Human-AI Interaction","abstract":"Face-to-face communication modeling in computer vision is an area of research focusing on developing algorithms that can recognize and analyze non-verbal cues and behaviors during face-to-face interactions. We propose an alternative to text chats for Human-AI interaction, based on non-verbal visual communication only, using facial expressions and head movements that mirror, but also improvise over the human user, to efficiently engage with the users, and capture their attention in a low-cost and real-time fashion. Our goal is to track and analyze facial expressions, and other non-verbal cues in real-time, and use this information to build models that can predict and understand human behavior. We offer three different complementary approaches, based on retrieval, statistical, and deep learning techniques. We provide human as well as automatic evaluations and discuss the advantages and disadvantages of each direction.","sentences":["Face-to-face communication modeling in computer vision is an area of research focusing on developing algorithms that can recognize and analyze non-verbal cues and behaviors during face-to-face interactions.","We propose an alternative to text chats for Human-AI interaction, based on non-verbal visual communication only, using facial expressions and head movements that mirror, but also improvise over the human user, to efficiently engage with the users, and capture their attention in a low-cost and real-time fashion.","Our goal is to track and analyze facial expressions, and other non-verbal cues in real-time, and use this information to build models that can predict and understand human behavior.","We offer three different complementary approaches, based on retrieval, statistical, and deep learning techniques.","We provide human as well as automatic evaluations and discuss the advantages and disadvantages of each direction."],"url":"http://arxiv.org/abs/2402.06385v1","category":"cs.CV"}
{"created":"2024-02-09 12:58:36","title":"Optimal estimation of Gaussian (poly)trees","abstract":"We develop optimal algorithms for learning undirected Gaussian trees and directed Gaussian polytrees from data. We consider both problems of distribution learning (i.e. in KL distance) and structure learning (i.e. exact recovery). The first approach is based on the Chow-Liu algorithm, and learns an optimal tree-structured distribution efficiently. The second approach is a modification of the PC algorithm for polytrees that uses partial correlation as a conditional independence tester for constraint-based structure learning. We derive explicit finite-sample guarantees for both approaches, and show that both approaches are optimal by deriving matching lower bounds. Additionally, we conduct numerical experiments to compare the performance of various algorithms, providing further insights and empirical evidence.","sentences":["We develop optimal algorithms for learning undirected Gaussian trees and directed Gaussian polytrees from data.","We consider both problems of distribution learning (i.e. in KL distance) and structure learning (i.e. exact recovery).","The first approach is based on the Chow-Liu algorithm, and learns an optimal tree-structured distribution efficiently.","The second approach is a modification of the PC algorithm for polytrees that uses partial correlation as a conditional independence tester for constraint-based structure learning.","We derive explicit finite-sample guarantees for both approaches, and show that both approaches are optimal by deriving matching lower bounds.","Additionally, we conduct numerical experiments to compare the performance of various algorithms, providing further insights and empirical evidence."],"url":"http://arxiv.org/abs/2402.06380v1","category":"cs.LG"}
{"created":"2024-02-09 12:56:16","title":"Learning using privileged information for segmenting tumors on digital mammograms","abstract":"Limited amount of data and data sharing restrictions, due to GDPR compliance, constitute two common factors leading to reduced availability and accessibility when referring to medical data. To tackle these issues, we introduce the technique of Learning Using Privileged Information. Aiming to substantiate the idea, we attempt to build a robust model that improves the segmentation quality of tumors on digital mammograms, by gaining privileged information knowledge during the training procedure. Towards this direction, a baseline model, called student, is trained on patches extracted from the original mammograms, while an auxiliary model with the same architecture, called teacher, is trained on the corresponding enhanced patches accessing, in this way, privileged information. We repeat the student training procedure by providing the assistance of the teacher model this time. According to the experimental results, it seems that the proposed methodology performs better in the most of the cases and it can achieve 10% higher F1 score in comparison with the baseline.","sentences":["Limited amount of data and data sharing restrictions, due to GDPR compliance, constitute two common factors leading to reduced availability and accessibility when referring to medical data.","To tackle these issues, we introduce the technique of Learning Using Privileged Information.","Aiming to substantiate the idea, we attempt to build a robust model that improves the segmentation quality of tumors on digital mammograms, by gaining privileged information knowledge during the training procedure.","Towards this direction, a baseline model, called student, is trained on patches extracted from the original mammograms, while an auxiliary model with the same architecture, called teacher, is trained on the corresponding enhanced patches accessing, in this way, privileged information.","We repeat the student training procedure by providing the assistance of the teacher model this time.","According to the experimental results, it seems that the proposed methodology performs better in the most of the cases and it can achieve 10% higher F1 score in comparison with the baseline."],"url":"http://arxiv.org/abs/2402.06379v1","category":"cs.CV"}
{"created":"2024-02-09 11:09:52","title":"Continual Learning on Graphs: A Survey","abstract":"Recently, continual graph learning has been increasingly adopted for diverse graph-structured data processing tasks in non-stationary environments. Despite its promising learning capability, current studies on continual graph learning mainly focus on mitigating the catastrophic forgetting problem while ignoring continuous performance improvement. To bridge this gap, this article aims to provide a comprehensive survey of recent efforts on continual graph learning. Specifically, we introduce a new taxonomy of continual graph learning from the perspective of overcoming catastrophic forgetting. Moreover, we systematically analyze the challenges of applying these continual graph learning methods in improving performance continuously and then discuss the possible solutions. Finally, we present open issues and future directions pertaining to the development of continual graph learning and discuss how they impact continuous performance improvement.","sentences":["Recently, continual graph learning has been increasingly adopted for diverse graph-structured data processing tasks in non-stationary environments.","Despite its promising learning capability, current studies on continual graph learning mainly focus on mitigating the catastrophic forgetting problem while ignoring continuous performance improvement.","To bridge this gap, this article aims to provide a comprehensive survey of recent efforts on continual graph learning.","Specifically, we introduce a new taxonomy of continual graph learning from the perspective of overcoming catastrophic forgetting.","Moreover, we systematically analyze the challenges of applying these continual graph learning methods in improving performance continuously and then discuss the possible solutions.","Finally, we present open issues and future directions pertaining to the development of continual graph learning and discuss how they impact continuous performance improvement."],"url":"http://arxiv.org/abs/2402.06330v1","category":"cs.LG"}
{"created":"2024-02-09 10:14:18","title":"Probabilistic Forecasting of Irregular Time Series via Conditional Flows","abstract":"Probabilistic forecasting of irregularly sampled multivariate time series with missing values is an important problem in many fields, including health care, astronomy, and climate. State-of-the-art methods for the task estimate only marginal distributions of observations in single channels and at single timepoints, assuming a fixed-shape parametric distribution. In this work, we propose a novel model, ProFITi, for probabilistic forecasting of irregularly sampled time series with missing values using conditional normalizing flows. The model learns joint distributions over the future values of the time series conditioned on past observations and queried channels and times, without assuming any fixed shape of the underlying distribution. As model components, we introduce a novel invertible triangular attention layer and an invertible non-linear activation function on and onto the whole real line. We conduct extensive experiments on four datasets and demonstrate that the proposed model provides $4$ times higher likelihood over the previously best model.","sentences":["Probabilistic forecasting of irregularly sampled multivariate time series with missing values is an important problem in many fields, including health care, astronomy, and climate.","State-of-the-art methods for the task estimate only marginal distributions of observations in single channels and at single timepoints, assuming a fixed-shape parametric distribution.","In this work, we propose a novel model, ProFITi, for probabilistic forecasting of irregularly sampled time series with missing values using conditional normalizing flows.","The model learns joint distributions over the future values of the time series conditioned on past observations and queried channels and times, without assuming any fixed shape of the underlying distribution.","As model components, we introduce a novel invertible triangular attention layer and an invertible non-linear activation function on and onto the whole real line.","We conduct extensive experiments on four datasets and demonstrate that the proposed model provides $4$ times higher likelihood over the previously best model."],"url":"http://arxiv.org/abs/2402.06293v1","category":"cs.LG"}
{"created":"2024-02-09 09:58:35","title":"Evaluating Membership Inference Attacks and Defenses in Federated Learning","abstract":"Membership Inference Attacks (MIAs) pose a growing threat to privacy preservation in federated learning. The semi-honest attacker, e.g., the server, may determine whether a particular sample belongs to a target client according to the observed model information. This paper conducts an evaluation of existing MIAs and corresponding defense strategies. Our evaluation on MIAs reveals two important findings about the trend of MIAs. Firstly, combining model information from multiple communication rounds (Multi-temporal) enhances the overall effectiveness of MIAs compared to utilizing model information from a single epoch. Secondly, incorporating models from non-target clients (Multi-spatial) significantly improves the effectiveness of MIAs, particularly when the clients' data is homogeneous. This highlights the importance of considering the temporal and spatial model information in MIAs. Next, we assess the effectiveness via privacy-utility tradeoff for two type defense mechanisms against MIAs: Gradient Perturbation and Data Replacement. Our results demonstrate that Data Replacement mechanisms achieve a more optimal balance between preserving privacy and maintaining model utility. Therefore, we recommend the adoption of Data Replacement methods as a defense strategy against MIAs. Our code is available in https://github.com/Liar-Mask/FedMIA.","sentences":["Membership Inference Attacks (MIAs) pose a growing threat to privacy preservation in federated learning.","The semi-honest attacker, e.g., the server, may determine whether a particular sample belongs to a target client according to the observed model information.","This paper conducts an evaluation of existing MIAs and corresponding defense strategies.","Our evaluation on MIAs reveals two important findings about the trend of MIAs.","Firstly, combining model information from multiple communication rounds (Multi-temporal) enhances the overall effectiveness of MIAs compared to utilizing model information from a single epoch.","Secondly, incorporating models from non-target clients (Multi-spatial) significantly improves the effectiveness of MIAs, particularly when the clients' data is homogeneous.","This highlights the importance of considering the temporal and spatial model information in MIAs.","Next, we assess the effectiveness via privacy-utility tradeoff for two type defense mechanisms against MIAs: Gradient Perturbation and Data Replacement.","Our results demonstrate that Data Replacement mechanisms achieve a more optimal balance between preserving privacy and maintaining model utility.","Therefore, we recommend the adoption of Data Replacement methods as a defense strategy against MIAs.","Our code is available in https://github.com/Liar-Mask/FedMIA."],"url":"http://arxiv.org/abs/2402.06289v1","category":"cs.LG"}
{"created":"2024-02-09 09:34:36","title":"YAMLE: Yet Another Machine Learning Environment","abstract":"YAMLE: Yet Another Machine Learning Environment is an open-source framework that facilitates rapid prototyping and experimentation with machine learning (ML) models and methods. The key motivation is to reduce repetitive work when implementing new approaches and improve reproducibility in ML research. YAMLE includes a command-line interface and integrations with popular and well-maintained PyTorch-based libraries to streamline training, hyperparameter optimisation, and logging. The ambition for YAMLE is to grow into a shared ecosystem where researchers and practitioners can quickly build on and compare existing implementations. Find it at: https://github.com/martinferianc/yamle.","sentences":["YAMLE:","Yet Another Machine Learning Environment is an open-source framework that facilitates rapid prototyping and experimentation with machine learning (ML) models and methods.","The key motivation is to reduce repetitive work when implementing new approaches and improve reproducibility in ML research.","YAMLE includes a command-line interface and integrations with popular and well-maintained PyTorch-based libraries to streamline training, hyperparameter optimisation, and logging.","The ambition for YAMLE is to grow into a shared ecosystem where researchers and practitioners can quickly build on and compare existing implementations.","Find it at: https://github.com/martinferianc/yamle."],"url":"http://arxiv.org/abs/2402.06268v1","category":"cs.LG"}
{"created":"2024-02-09 18:29:38","title":"Hamiltonicity of expanders: optimal bounds and applications","abstract":"An $n$-vertex graph $G$ is a $C$-expander if $|N(X)|\\geq C|X|$ for every $X\\subseteq V(G)$ with $|X|< n/2C$ and there is an edge between every two disjoint sets of at least $n/2C$ vertices. We show that there is some constant $C>0$ for which every $C$-expander is Hamiltonian. In particular, this implies the well known conjecture of Krivelevich and Sudakov from 2003 on Hamilton cycles in $(n,d,\\lambda)$-graphs. This completes a long line of research on the Hamiltonicity of sparse graphs, and has many applications, including to the Hamiltonicity of random Cayley graphs.","sentences":["An $n$-vertex graph $G$ is a $C$-expander if $|N(X)|\\geq C|X|$ for every $X\\subseteq V(G)$ with $|X|< n/2C$","and there is an edge between every two disjoint sets of at least $n/2C$ vertices.","We show that there is some constant $C>0$ for which every $C$-expander is Hamiltonian.","In particular, this implies the well known conjecture of Krivelevich and Sudakov from 2003 on Hamilton cycles in $(n,d,\\lambda)$-graphs.","This completes a long line of research on the Hamiltonicity of sparse graphs, and has many applications, including to the Hamiltonicity of random Cayley graphs."],"url":"http://arxiv.org/abs/2402.06603v1","category":"math.CO"}
{"created":"2024-02-09 18:01:45","title":"Fundamental limits of metrology at thermal equilibrium","abstract":"We consider the estimation of an unknown parameter $\\theta$ through a quantum probe at thermal equilibrium. The probe is assumed to be in a Gibbs state according to its Hamiltonian $H_\\theta$, which is divided in a parameter-encoding term $H^P_\\theta$ and an additional, parameter-independent, control $H^C$. Given a fixed encoding, we find the maximal Quantum Fisher Information attainable via arbitrary $H^C$, which provides a fundamental bound on the measurement precision. Our bounds show that: (i) assuming full control of $H^C$, quantum non-commutativity does not offer any fundamental advantage in the estimation of $\\theta$; (ii) an exponential quantum advantage arises at low temperatures if $H^C$ is constrained to have a spectral gap; (iii) in the case of locally-encoded parameters, the optimal sensitivity presents a Heisenberg-like $N^2$-scaling in terms of the number of particles of the probe, which can be reached with local measurements. We apply our results to paradigmatic spin chain models, showing that these fundamental limits can be approached using local two-body interactions. Our results set the fundamental limits and optimal control for metrology with thermal and ground state probes, including probes at the verge of criticality.","sentences":["We consider the estimation of an unknown parameter $\\theta$ through a quantum probe at thermal equilibrium.","The probe is assumed to be in a Gibbs state according to its Hamiltonian $H_\\theta$, which is divided in a parameter-encoding term $H^P_\\theta$ and an additional, parameter-independent, control $H^C$. Given a fixed encoding, we find the maximal Quantum Fisher Information attainable via arbitrary $H^C$, which provides a fundamental bound on the measurement precision.","Our bounds show that: (i) assuming full control of $H^C$, quantum non-commutativity does not offer any fundamental advantage in the estimation of $\\theta$; (ii) an exponential quantum advantage arises at low temperatures if $H^C$ is constrained to have a spectral gap; (iii) in the case of locally-encoded parameters, the optimal sensitivity presents a Heisenberg-like $N^2$-scaling in terms of the number of particles of the probe, which can be reached with local measurements.","We apply our results to paradigmatic spin chain models, showing that these fundamental limits can be approached using local two-body interactions.","Our results set the fundamental limits and optimal control for metrology with thermal and ground state probes, including probes at the verge of criticality."],"url":"http://arxiv.org/abs/2402.06582v1","category":"quant-ph"}
{"created":"2024-02-09 17:50:26","title":"Modeling Microstrip Antenna","abstract":"In this work, a rectangular microstrip antenna with inset is designed, simulated and optimized. In the optimization process the patch is deformed, it new antenna present a amorphous patch. The optimization process was conducted with Genetic Algorithm (GA), S11 parameters was obtained with full wave Finite-Differences Time-Domain (FDTD-3D), and the initial configuration (design) was obtained with line transmission and cavite method.","sentences":["In this work, a rectangular microstrip antenna with inset is designed, simulated and optimized.","In the optimization process the patch is deformed, it new antenna present a amorphous patch.","The optimization process was conducted with Genetic Algorithm (GA), S11 parameters was obtained with full wave Finite-Differences Time-Domain (FDTD-3D), and the initial configuration (design) was obtained with line transmission and cavite method."],"url":"http://arxiv.org/abs/2402.06575v1","category":"math.NA"}
{"created":"2024-02-09 17:00:37","title":"Evaluating the impact of items and cooperation in inventory models with exemptable ordering costs","abstract":"In this paper we introduce and analyse, from a game theoretical perspective, several multi-agent or multi-item continuous review inventory models in which the buyers are exempted from ordering costs if the price of their orders is greater than or equal to a certain amount. For all models we obtain the optimal ordering policy. We first analyse a simple model with one firm and one item. Then, we study a model with one firm and several items, for which we design a procedure based on cooperative game theory to evaluate the impact of each item on the total cost. Then, we deal with a model with several firms and one item for each firm, for which we characterise a rule to allocate the total cost among the firms in a coalitionally stable way. Finally, we discuss a model with several firms and several items, for which we characterise a rule to allocate the total cost among the firms in a coalitionally stable way and to evaluate the impact of each item on the cost that would be payable to each firm when using the allocation rule. All the concepts and results of this article are illustrated using data from a case study.","sentences":["In this paper we introduce and analyse, from a game theoretical perspective, several multi-agent or multi-item continuous review inventory models in which the buyers are exempted from ordering costs if the price of their orders is greater than or equal to a certain amount.","For all models we obtain the optimal ordering policy.","We first analyse a simple model with one firm and one item.","Then, we study a model with one firm and several items, for which we design a procedure based on cooperative game theory to evaluate the impact of each item on the total cost.","Then, we deal with a model with several firms and one item for each firm, for which we characterise a rule to allocate the total cost among the firms in a coalitionally stable way.","Finally, we discuss a model with several firms and several items, for which we characterise a rule to allocate the total cost among the firms in a coalitionally stable way and to evaluate the impact of each item on the cost that would be payable to each firm when using the allocation rule.","All the concepts and results of this article are illustrated using data from a case study."],"url":"http://arxiv.org/abs/2402.06545v1","category":"cs.GT"}
{"created":"2024-02-09 11:48:33","title":"Exact Solutions to the Maxmin Problem max ||Ax|| Subject to ||Bx||<= 1","abstract":"In this manuscript we provide an exact solution to the maxmin problem max ||Ax|| subject to ||Bx||<= 1, where A and B are real matrices. This problem comes from a remodeling of max ||Ax|| subject to min ||Bx||, because the latter problem has no solution. Our mathematical method comes from the Abstract Operator Theory, whose strong machinery allows us to reduce the first problem to max parallel to Cx parallel to subject to parallel to x parallel to <= 1, which can be solved exactly by relying on supporting vectors. Finally, as appendices, we provide two applications of our solution: first, we construct a truly optimal minimum stored-energy Transcranian Magnetic Stimulation (TMS) coil, and second, we find an optimal geolocation involving statistical variables","sentences":["In this manuscript we provide an exact solution to the maxmin problem max ||Ax|| subject to ||Bx||<= 1, where A and B are real matrices.","This problem comes from a remodeling of max ||Ax|| subject to min ||Bx||, because the latter problem has no solution.","Our mathematical method comes from the Abstract Operator Theory, whose strong machinery allows us to reduce the first problem to max parallel to Cx parallel to subject to parallel to x parallel to <= 1, which can be solved exactly by relying on supporting vectors.","Finally, as appendices, we provide two applications of our solution: first, we construct a truly optimal minimum stored-energy Transcranian Magnetic Stimulation (TMS) coil, and second, we find an optimal geolocation involving statistical variables"],"url":"http://arxiv.org/abs/2402.06345v1","category":"math.FA"}
{"created":"2024-02-09 11:31:34","title":"Ubiquitous order-disorder transition in the Mn antisite sublattice of the (MnBi$_2$Te$_4$)(Bi$_2$Te$_3$)$_n$ magnetic topological insulators","abstract":"Magnetic topological insulators (TIs) herald a wealth of applications in spin-based technologies, relying on the novel quantum phenomena provided by their topological properties. Particularly promising is the (MnBi$_2$Te$_4$)(Bi$_2$Te$_3$)$_n$ layered family of established intrinsic magnetic TIs that can flexibly realize various magnetic orders and topological states. High tunability of this material platform is enabled by manganese-pnictogen intermixing, whose amounts and distribution patterns are controlled by synthetic conditions. Positive implication of the strong intermixing in MnSb$_2$Te$_4$ is the interlayer exchange coupling switching from antiferromagnetic to ferromagnetic, and the increasing magnetic critical temperature. On the other side, intermixing also implies atomic disorder which may be detrimental for applications. Here, we employ nuclear magnetic resonance and muon spin spectroscopy, sensitive local probe techniques, to scrutinize the impact of the intermixing on the magnetic properties of (MnBi$_2$Te$_4$)(Bi$_2$Te$_3$)$_n$ and MnSb$_2$Te$_4$. Our measurements not only confirm the opposite alignment between the Mn magnetic moments on native sites and antisites in the ground state of MnSb$_2$Te$_4$, but for the first time directly show the same alignment in (MnBi$_2$Te$_4$)(Bi$_2$Te$_3$)$_n$ with n = 0, 1 and 2. Moreover, for all compounds, we find the static magnetic moment of the Mn antisite sublattice to disappear well below the intrinsic magnetic transition temperature, leaving a homogeneous magnetic structure undisturbed by the intermixing. Our findings provide a microscopic understanding of the crucial role played by Mn-Bi intermixing in (MnBi$_2$Te$_4$)(Bi$_2$Te$_3$)$_n$ and offer pathways to optimizing the magnetic gap in its surface states.","sentences":["Magnetic topological insulators (TIs) herald a wealth of applications in spin-based technologies, relying on the novel quantum phenomena provided by their topological properties.","Particularly promising is the (MnBi$_2$Te$_4$)(Bi$_2$Te$_3$)$_n$ layered family of established intrinsic magnetic TIs that can flexibly realize various magnetic orders and topological states.","High tunability of this material platform is enabled by manganese-pnictogen intermixing, whose amounts and distribution patterns are controlled by synthetic conditions.","Positive implication of the strong intermixing in MnSb$_2$Te$_4$ is the interlayer exchange coupling switching from antiferromagnetic to ferromagnetic, and the increasing magnetic critical temperature.","On the other side, intermixing also implies atomic disorder which may be detrimental for applications.","Here, we employ nuclear magnetic resonance and muon spin spectroscopy, sensitive local probe techniques, to scrutinize the impact of the intermixing on the magnetic properties of (MnBi$_2$Te$_4$)(Bi$_2$Te$_3$)$_n$ and MnSb$_2$Te$_4$. Our measurements not only confirm the opposite alignment between the Mn magnetic moments on native sites and antisites in the ground state of MnSb$_2$Te$_4$, but for the first time directly show the same alignment in (MnBi$_2$Te$_4$)(Bi$_2$Te$_3$)$_n$ with n","= 0, 1 and 2.","Moreover, for all compounds, we find the static magnetic moment of the Mn antisite sublattice to disappear well below the intrinsic magnetic transition temperature, leaving a homogeneous magnetic structure undisturbed by the intermixing.","Our findings provide a microscopic understanding of the crucial role played by Mn-Bi intermixing in (MnBi$_2$Te$_4$)(Bi$_2$Te$_3$)$_n$ and offer pathways to optimizing the magnetic gap in its surface states."],"url":"http://arxiv.org/abs/2402.06340v1","category":"cond-mat.mtrl-sci"}
{"created":"2024-02-09 11:22:12","title":"An application of power indices for the family of weighted majority games in partition function form","abstract":"Based on Holler (1982) and Armijos-Toro et al. (2021) we propose two power indices to measure the influence of the players in the class of weighted majority games in partition function form. We compare these new power indices with their original versions on the class of games in characteristic function form. Finally, we use both pairs of power indices for games in partition function form to study the distribution of power in the National Assembly of Ecuador that emerged after the elections of February 7, 2021.","sentences":["Based on Holler (1982) and Armijos-Toro et al. (2021) we propose two power indices to measure the influence of the players in the class of weighted majority games in partition function form.","We compare these new power indices with their original versions on the class of games in characteristic function form.","Finally, we use both pairs of power indices for games in partition function form to study the distribution of power in the National Assembly of Ecuador that emerged after the elections of February 7, 2021."],"url":"http://arxiv.org/abs/2402.06333v1","category":"cs.GT"}
{"created":"2024-02-09 11:00:38","title":"Energy efficiency optimization of task-parallel codes on asymmetric architectures","abstract":"We present a family of policies that, integrated within a runtime task scheduler (Nanox), pursue the goal of improving the energy efficiency of task-parallel executions with no intervention from the programmer. The proposed policies tackle the problem by modifying the core operating frequency via DVFS mechanisms, or by enabling/disabling the mapping of tasks to specific cores at selected execution points, depending on the internal status of the scheduler. Experimental results on an asymmetric SoC (Exynos 5422) and for a specific operation (Cholesky factorization) reveal gains up to 29% in terms of energy efficiency and considerable reductions in average power.","sentences":["We present a family of policies that, integrated within a runtime task scheduler (Nanox), pursue the goal of improving the energy efficiency of task-parallel executions with no intervention from the programmer.","The proposed policies tackle the problem by modifying the core operating frequency via DVFS mechanisms, or by enabling/disabling the mapping of tasks to specific cores at selected execution points, depending on the internal status of the scheduler.","Experimental results on an asymmetric SoC (Exynos 5422) and for a specific operation (Cholesky factorization) reveal gains up to 29% in terms of energy efficiency and considerable reductions in average power."],"url":"http://arxiv.org/abs/2402.06319v1","category":"cs.DC"}
{"created":"2024-02-09 10:40:41","title":"Mixed finite elements for the Gross-Pitaevskii eigenvalue problem: a priori error analysis and guaranteed lower energy bound","abstract":"We establish an a priori error analysis for the lowest-order Raviart-Thomas finite element discretisation of the nonlinear Gross-Pitaevskii eigenvalue problem. Optimal convergence rates are obtained for the primal and dual variables as well as for the eigenvalue and energy approximations. In contrast to conformal approaches, which naturally imply upper energy bounds, the proposed mixed discretisation provides a guaranteed and asymptotically exact lower bound for the ground state energy. The theoretical results are illustrated by a series of numerical experiments.","sentences":["We establish an a priori error analysis for the lowest-order Raviart-Thomas finite element discretisation of the nonlinear Gross-Pitaevskii eigenvalue problem.","Optimal convergence rates are obtained for the primal and dual variables as well as for the eigenvalue and energy approximations.","In contrast to conformal approaches, which naturally imply upper energy bounds, the proposed mixed discretisation provides a guaranteed and asymptotically exact lower bound for the ground state energy.","The theoretical results are illustrated by a series of numerical experiments."],"url":"http://arxiv.org/abs/2402.06311v1","category":"math.NA"}
{"created":"2024-02-09 10:23:07","title":"Mergeable weighted majority games and characterizations of some power indices","abstract":"In this paper, we introduce a notion of mergeable weighted majority games with the aim of providing the first characterization of the Colomer-Mart\\'inez power index (Colomer and Mart\\'inez in J Theor Polit 7(1):41-63, 1995). Furthermore, we define and characterize a new power index for the family of weighted majority games that combines ideas of the Public Good (Holler in Polit Stud 30(2):262-271, 1982) and Colomer-Mart\\'inez power indices. Finally, we analyze the National Assembly of Ecuador using these and some other well-known power indices.","sentences":["In this paper, we introduce a notion of mergeable weighted majority games with the aim of providing the first characterization of the Colomer-Mart\\'inez power index (Colomer and Mart\\'inez in J Theor Polit 7(1):41-63, 1995).","Furthermore, we define and characterize a new power index for the family of weighted majority games that combines ideas of the Public Good (Holler in Polit Stud 30(2):262-271, 1982) and Colomer-Mart\\'inez power indices.","Finally, we analyze the National Assembly of Ecuador using these and some other well-known power indices."],"url":"http://arxiv.org/abs/2402.06298v1","category":"cs.GT"}
{"created":"2024-02-09 09:48:59","title":"Wave optical model for tomographic volumetric additive manufacturing","abstract":"Tomographic Volumetric Additive Manufacturing (TVAM) allows printing of mesoscopic objects within seconds or minutes. Tomographic patterns are illuminated onto a rotating glass vial which contains a photosensitive resin. Current pattern optimization is based on a ray optical assumption which ultimately leads to limited resolution around $20\\mu\\textrm{m}$ and varying throughout the volume of the 3D object. In this work, we introduce a rigorous wave-based optical amplitude optimization scheme for TVAM which shows that high-resolution printing is theoretically possible over the full volume. The wave optical optimization approach is based on an efficient angular spectrum method of plane waves with custom written memory efficient gradients and allows for optimization of realistic volumes for TVAM such as $(100\\mu\\textrm{m})^3$ or $(10\\textrm{mm})^3$ with $550^3$ voxels and 600 angles. Our simulations show that ray-optics start to produce artifacts when the desired features are $20\\mu\\textrm{m}$ and below and more importantly, the amplitude modulated TVAM can reach micrometer features when optimizing the patterns using a full wave model.","sentences":["Tomographic Volumetric Additive Manufacturing (TVAM) allows printing of mesoscopic objects within seconds or minutes.","Tomographic patterns are illuminated onto a rotating glass vial which contains a photosensitive resin.","Current pattern optimization is based on a ray optical assumption which ultimately leads to limited resolution around $20\\mu\\textrm{m}$ and varying throughout the volume of the 3D object.","In this work, we introduce a rigorous wave-based optical amplitude optimization scheme for TVAM which shows that high-resolution printing is theoretically possible over the full volume.","The wave optical optimization approach is based on an efficient angular spectrum method of plane waves with custom written memory efficient gradients and allows for optimization of realistic volumes for TVAM such as $(100\\mu\\textrm{m})^3$ or $(10\\textrm{mm})^3$ with $550^3$ voxels and 600 angles.","Our simulations show that ray-optics start to produce artifacts when the desired features are $20\\mu\\textrm{m}$ and below and more importantly, the amplitude modulated TVAM can reach micrometer features when optimizing the patterns using a full wave model."],"url":"http://arxiv.org/abs/2402.06283v1","category":"physics.optics"}
{"created":"2024-02-09 09:46:28","title":"An Optimization Framework for Resource Allocation in Virtual Sensor Networks","abstract":"We propose an optimization framework to perform resource allocation in virtual sensor networks. Sensor network virtualization is a promising paradigm to improve flexibility of wireless sensor networks which allows to dynamically assign physical resources to multiple stakeholder applications. The proposed optimization framework aims at maximizing the total number of applications which can share a common physical network, while accounting for the distinguishing characteristics and limitations of the wireless sensor environment (limited storage, limited processing power, limited bandwidth, tight energy consumption requirements). The proposed framework is finally applied to realistic network topologies to assess the gain involved in letting multiple applications share a common physical network with respect to one-application, one-network vertical design approaches.","sentences":["We propose an optimization framework to perform resource allocation in virtual sensor networks.","Sensor network virtualization is a promising paradigm to improve flexibility of wireless sensor networks which allows to dynamically assign physical resources to multiple stakeholder applications.","The proposed optimization framework aims at maximizing the total number of applications which can share a common physical network, while accounting for the distinguishing characteristics and limitations of the wireless sensor environment (limited storage, limited processing power, limited bandwidth, tight energy consumption requirements).","The proposed framework is finally applied to realistic network topologies to assess the gain involved in letting multiple applications share a common physical network with respect to one-application, one-network vertical design approaches."],"url":"http://arxiv.org/abs/2402.06281v1","category":"cs.NI"}
