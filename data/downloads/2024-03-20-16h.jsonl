{"created":"2024-03-18 12:08:01","title":"Generalized Multi-Source Inference for Text Conditioned Music Diffusion Models","abstract":"Multi-Source Diffusion Models (MSDM) allow for compositional musical generation tasks: generating a set of coherent sources, creating accompaniments, and performing source separation. Despite their versatility, they require estimating the joint distribution over the sources, necessitating pre-separated musical data, which is rarely available, and fixing the number and type of sources at training time. This paper generalizes MSDM to arbitrary time-domain diffusion models conditioned on text embeddings. These models do not require separated data as they are trained on mixtures, can parameterize an arbitrary number of sources, and allow for rich semantic control. We propose an inference procedure enabling the coherent generation of sources and accompaniments. Additionally, we adapt the Dirac separator of MSDM to perform source separation. We experiment with diffusion models trained on Slakh2100 and MTG-Jamendo, showcasing competitive generation and separation results in a relaxed data setting.","sentences":["Multi-Source Diffusion Models (MSDM) allow for compositional musical generation tasks: generating a set of coherent sources, creating accompaniments, and performing source separation.","Despite their versatility, they require estimating the joint distribution over the sources, necessitating pre-separated musical data, which is rarely available, and fixing the number and type of sources at training time.","This paper generalizes MSDM to arbitrary time-domain diffusion models conditioned on text embeddings.","These models do not require separated data as they are trained on mixtures, can parameterize an arbitrary number of sources, and allow for rich semantic control.","We propose an inference procedure enabling the coherent generation of sources and accompaniments.","Additionally, we adapt the Dirac separator of MSDM to perform source separation.","We experiment with diffusion models trained on Slakh2100 and MTG-Jamendo, showcasing competitive generation and separation results in a relaxed data setting."],"url":"http://arxiv.org/abs/2403.11706v1","category":"cs.SD"}
{"created":"2024-03-18 12:06:31","title":"Sharp phase transitions in high-dimensional changepoint detection","abstract":"We study a hypothesis testing problem in the context of high-dimensional changepoint detection. Given a matrix $X \\in \\mathbb{R}^{p \\times n}$ with independent Gaussian entries, the goal is to determine whether or not a sparse, non-null fraction of rows in $X$ exhibits a shift in mean at a common index between $1$ and $n$. We focus on three aspects of this problem: the sparsity of non-null rows, the presence of a single, common changepoint in the non-null rows, and the signal strength associated with the changepoint. Within an asymptotic regime relating the data dimensions $n$ and $p$ to the signal sparsity and strength, we characterize the information-theoretic limits of the testing problem by a formula that determines whether the sum of Type I and II errors tends to zero or is bounded away from zero. The formula, called the \\emph{detection boundary}, is a curve that separates the parameter space into a detectable region and an undetectable region. We show that a Berk--Jones type test statistic can detect the presence of a sparse non-null fraction of rows, and does so adaptively throughout the detectable region. Conversely, within the undetectable region, no test is able to consistently distinguish the signal from noise.","sentences":["We study a hypothesis testing problem in the context of high-dimensional changepoint detection.","Given a matrix $X \\in \\mathbb{R}^{p \\times n}$ with independent Gaussian entries, the goal is to determine whether or not a sparse, non-null fraction of rows in $X$ exhibits a shift in mean at a common index between $1$ and $n$. We focus on three aspects of this problem: the sparsity of non-null rows, the presence of a single, common changepoint in the non-null rows, and the signal strength associated with the changepoint.","Within an asymptotic regime relating the data dimensions $n$ and $p$ to the signal sparsity and strength, we characterize the information-theoretic limits of the testing problem by a formula that determines whether the sum of Type I and II errors tends to zero or is bounded away from zero.","The formula, called the \\emph{detection boundary}, is a curve that separates the parameter space into a detectable region and an undetectable region.","We show that a Berk--Jones type test statistic can detect the presence of a sparse non-null fraction of rows, and does so adaptively throughout the detectable region.","Conversely, within the undetectable region, no test is able to consistently distinguish the signal from noise."],"url":"http://arxiv.org/abs/2403.11704v1","category":"math.ST"}
{"created":"2024-03-18 12:04:11","title":"LLaVA-UHD: an LMM Perceiving Any Aspect Ratio and High-Resolution Images","abstract":"Visual encoding constitutes the basis of large multimodal models (LMMs) in understanding the visual world. Conventional LMMs process images in fixed sizes and limited resolutions, while recent explorations in this direction are limited in adaptivity, efficiency, and even correctness. In this work, we first take GPT-4V and LLaVA-1.5 as representative examples and expose systematic flaws rooted in their visual encoding strategy. To address the challenges, we present LLaVA-UHD, a large multimodal model that can efficiently perceive images in any aspect ratio and high resolution. LLaVA-UHD includes three key components: (1) An image modularization strategy that divides native-resolution images into smaller variable-sized slices for efficient and extensible encoding, (2) a compression module that further condenses image tokens from visual encoders, and (3) a spatial schema to organize slice tokens for LLMs. Comprehensive experiments show that LLaVA-UHD outperforms established LMMs trained with 2-3 orders of magnitude more data on 9 benchmarks. Notably, our model built on LLaVA-1.5 336x336 supports 6 times larger (i.e., 672x1088) resolution images using only 94% inference computation, and achieves 6.4 accuracy improvement on TextVQA. Moreover, the model can be efficiently trained in academic settings, within 23 hours on 8 A100 GPUs (vs. 26 hours of LLaVA-1.5). We make the data and code publicly available at https://github.com/thunlp/LLaVA-UHD.","sentences":["Visual encoding constitutes the basis of large multimodal models (LMMs) in understanding the visual world.","Conventional LMMs process images in fixed sizes and limited resolutions, while recent explorations in this direction are limited in adaptivity, efficiency, and even correctness.","In this work, we first take GPT-4V and LLaVA-1.5 as representative examples and expose systematic flaws rooted in their visual encoding strategy.","To address the challenges, we present LLaVA-UHD, a large multimodal model that can efficiently perceive images in any aspect ratio and high resolution.","LLaVA-UHD includes three key components: (1) An image modularization strategy that divides native-resolution images into smaller variable-sized slices for efficient and extensible encoding, (2) a compression module that further condenses image tokens from visual encoders, and (3) a spatial schema to organize slice tokens for LLMs.","Comprehensive experiments show that LLaVA-UHD outperforms established LMMs trained with 2-3 orders of magnitude more data on 9 benchmarks.","Notably, our model built on LLaVA-1.5 336x336 supports 6 times larger (i.e., 672x1088) resolution images using only 94% inference computation, and achieves 6.4 accuracy improvement on TextVQA.","Moreover, the model can be efficiently trained in academic settings, within 23 hours on 8 A100 GPUs (vs. 26 hours of LLaVA-1.5).","We make the data and code publicly available at https://github.com/thunlp/LLaVA-UHD."],"url":"http://arxiv.org/abs/2403.11703v1","category":"cs.CV"}
{"created":"2024-03-18 11:56:32","title":"A Spatial-Temporal Progressive Fusion Network for Breast Lesion Segmentation in Ultrasound Videos","abstract":"Ultrasound video-based breast lesion segmentation provides a valuable assistance in early breast lesion detection and treatment. However, existing works mainly focus on lesion segmentation based on ultrasound breast images which usually can not be adapted well to obtain desirable results on ultrasound videos. The main challenge for ultrasound video-based breast lesion segmentation is how to exploit the lesion cues of both intra-frame and inter-frame simultaneously. To address this problem, we propose a novel Spatial-Temporal Progressive Fusion Network (STPFNet) for video based breast lesion segmentation problem. The main aspects of the proposed STPFNet are threefold. First, we propose to adopt a unified network architecture to capture both spatial dependences within each ultrasound frame and temporal correlations between different frames together for ultrasound data representation. Second, we propose a new fusion module, termed Multi-Scale Feature Fusion (MSFF), to fuse spatial and temporal cues together for lesion detection. MSFF can help to determine the boundary contour of lesion region to overcome the issue of lesion boundary blurring. Third, we propose to exploit the segmentation result of previous frame as the prior knowledge to suppress the noisy background and learn more robust representation. In particular, we introduce a new publicly available ultrasound video breast lesion segmentation dataset, termed UVBLS200, which is specifically dedicated to breast lesion segmentation. It contains 200 videos, including 80 videos of benign lesions and 120 videos of malignant lesions. Experiments on the proposed dataset demonstrate that the proposed STPFNet achieves better breast lesion detection performance than state-of-the-art methods.","sentences":["Ultrasound video-based breast lesion segmentation provides a valuable assistance in early breast lesion detection and treatment.","However, existing works mainly focus on lesion segmentation based on ultrasound breast images which usually can not be adapted well to obtain desirable results on ultrasound videos.","The main challenge for ultrasound video-based breast lesion segmentation is how to exploit the lesion cues of both intra-frame and inter-frame simultaneously.","To address this problem, we propose a novel Spatial-Temporal Progressive Fusion Network (STPFNet) for video based breast lesion segmentation problem.","The main aspects of the proposed STPFNet are threefold.","First, we propose to adopt a unified network architecture to capture both spatial dependences within each ultrasound frame and temporal correlations between different frames together for ultrasound data representation.","Second, we propose a new fusion module, termed Multi-Scale Feature Fusion (MSFF), to fuse spatial and temporal cues together for lesion detection.","MSFF can help to determine the boundary contour of lesion region to overcome the issue of lesion boundary blurring.","Third, we propose to exploit the segmentation result of previous frame as the prior knowledge to suppress the noisy background and learn more robust representation.","In particular, we introduce a new publicly available ultrasound video breast lesion segmentation dataset, termed UVBLS200, which is specifically dedicated to breast lesion segmentation.","It contains 200 videos, including 80 videos of benign lesions and 120 videos of malignant lesions.","Experiments on the proposed dataset demonstrate that the proposed STPFNet achieves better breast lesion detection performance than state-of-the-art methods."],"url":"http://arxiv.org/abs/2403.11699v1","category":"eess.IV"}
{"created":"2024-03-18 11:41:55","title":"TTT-KD: Test-Time Training for 3D Semantic Segmentation through Knowledge Distillation from Foundation Models","abstract":"Test-Time Training (TTT) proposes to adapt a pre-trained network to changing data distributions on-the-fly. In this work, we propose the first TTT method for 3D semantic segmentation, TTT-KD, which models Knowledge Distillation (KD) from foundation models (e.g. DINOv2) as a self-supervised objective for adaptation to distribution shifts at test-time. Given access to paired image-pointcloud (2D-3D) data, we first optimize a 3D segmentation backbone for the main task of semantic segmentation using the pointclouds and the task of 2D $\\to$ 3D KD by using an off-the-shelf 2D pre-trained foundation model. At test-time, our TTT-KD updates the 3D segmentation backbone for each test sample, by using the self-supervised task of knowledge distillation, before performing the final prediction. Extensive evaluations on multiple indoor and outdoor 3D segmentation benchmarks show the utility of TTT-KD, as it improves performance for both in-distribution (ID) and out-of-distribution (ODO) test datasets. We achieve a gain of up to 13% mIoU (7% on average) when the train and test distributions are similar and up to 45% (20% on average) when adapting to OOD test samples.","sentences":["Test-Time Training (TTT) proposes to adapt a pre-trained network to changing data distributions on-the-fly.","In this work, we propose the first TTT method for 3D semantic segmentation, TTT-KD, which models Knowledge Distillation (KD) from foundation models (e.g. DINOv2) as a self-supervised objective for adaptation to distribution shifts at test-time.","Given access to paired image-pointcloud (2D-3D) data, we first optimize a 3D segmentation backbone for the main task of semantic segmentation using the pointclouds and the task of 2D $\\to$ 3D KD by using an off-the-shelf 2D pre-trained foundation model.","At test-time, our TTT-KD updates the 3D segmentation backbone for each test sample, by using the self-supervised task of knowledge distillation, before performing the final prediction.","Extensive evaluations on multiple indoor and outdoor 3D segmentation benchmarks show the utility of TTT-KD, as it improves performance for both in-distribution (ID) and out-of-distribution (ODO) test datasets.","We achieve a gain of up to 13% mIoU (7% on average) when the train and test distributions are similar and up to 45% (20% on average) when adapting to OOD test samples."],"url":"http://arxiv.org/abs/2403.11691v1","category":"cs.CV"}
{"created":"2024-03-18 10:35:15","title":"Diffusion-Based Environment-Aware Trajectory Prediction","abstract":"The ability to predict the future trajectories of traffic participants is crucial for the safe and efficient operation of autonomous vehicles. In this paper, a diffusion-based generative model for multi-agent trajectory prediction is proposed. The model is capable of capturing the complex interactions between traffic participants and the environment, accurately learning the multimodal nature of the data. The effectiveness of the approach is assessed on large-scale datasets of real-world traffic scenarios, showing that our model outperforms several well-established methods in terms of prediction accuracy. By the incorporation of differential motion constraints on the model output, we illustrate that our model is capable of generating a diverse set of realistic future trajectories. Through the use of an interaction-aware guidance signal, we further demonstrate that the model can be adapted to predict the behavior of less cooperative agents, emphasizing its practical applicability under uncertain traffic conditions.","sentences":["The ability to predict the future trajectories of traffic participants is crucial for the safe and efficient operation of autonomous vehicles.","In this paper, a diffusion-based generative model for multi-agent trajectory prediction is proposed.","The model is capable of capturing the complex interactions between traffic participants and the environment, accurately learning the multimodal nature of the data.","The effectiveness of the approach is assessed on large-scale datasets of real-world traffic scenarios, showing that our model outperforms several well-established methods in terms of prediction accuracy.","By the incorporation of differential motion constraints on the model output, we illustrate that our model is capable of generating a diverse set of realistic future trajectories.","Through the use of an interaction-aware guidance signal, we further demonstrate that the model can be adapted to predict the behavior of less cooperative agents, emphasizing its practical applicability under uncertain traffic conditions."],"url":"http://arxiv.org/abs/2403.11643v1","category":"cs.CV"}
{"created":"2024-03-18 10:34:40","title":"Guiding the generation of counterfactual explanations through temporal background knowledge for Predictive Process Monitoring","abstract":"Counterfactual explanations suggest what should be different in the input instance to change the outcome of an AI system. When dealing with counterfactual explanations in the field of Predictive Process Monitoring, however, control flow relationships among events have to be carefully considered. A counterfactual, indeed, should not violate control flow relationships among activities (temporal background knowledege). Within the field of Explainability in Predictive Process Monitoring, there have been a series of works regarding counterfactual explanations for outcome-based predictions. However, none of them consider the inclusion of temporal background knowledge when generating these counterfactuals. In this work, we adapt state-of-the-art techniques for counterfactual generation in the domain of XAI that are based on genetic algorithms to consider a series of temporal constraints at runtime. We assume that this temporal background knowledge is given, and we adapt the fitness function, as well as the crossover and mutation operators, to maintain the satisfaction of the constraints. The proposed methods are evaluated with respect to state-of-the-art genetic algorithms for counterfactual generation and the results are presented. We showcase that the inclusion of temporal background knowledge allows the generation of counterfactuals more conformant to the temporal background knowledge, without however losing in terms of the counterfactual traditional quality metrics.","sentences":["Counterfactual explanations suggest what should be different in the input instance to change the outcome of an AI system.","When dealing with counterfactual explanations in the field of Predictive Process Monitoring, however, control flow relationships among events have to be carefully considered.","A counterfactual, indeed, should not violate control flow relationships among activities (temporal background knowledege).","Within the field of Explainability in Predictive Process Monitoring, there have been a series of works regarding counterfactual explanations for outcome-based predictions.","However, none of them consider the inclusion of temporal background knowledge when generating these counterfactuals.","In this work, we adapt state-of-the-art techniques for counterfactual generation in the domain of XAI that are based on genetic algorithms to consider a series of temporal constraints at runtime.","We assume that this temporal background knowledge is given, and we adapt the fitness function, as well as the crossover and mutation operators, to maintain the satisfaction of the constraints.","The proposed methods are evaluated with respect to state-of-the-art genetic algorithms for counterfactual generation and the results are presented.","We showcase that the inclusion of temporal background knowledge allows the generation of counterfactuals more conformant to the temporal background knowledge, without however losing in terms of the counterfactual traditional quality metrics."],"url":"http://arxiv.org/abs/2403.11642v1","category":"cs.AI"}
{"created":"2024-03-18 10:32:51","title":"Arc2Face: A Foundation Model of Human Faces","abstract":"This paper presents Arc2Face, an identity-conditioned face foundation model, which, given the ArcFace embedding of a person, can generate diverse photo-realistic images with an unparalleled degree of face similarity than existing models. Despite previous attempts to decode face recognition features into detailed images, we find that common high-resolution datasets (e.g. FFHQ) lack sufficient identities to reconstruct any subject. To that end, we meticulously upsample a significant portion of the WebFace42M database, the largest public dataset for face recognition (FR). Arc2Face builds upon a pretrained Stable Diffusion model, yet adapts it to the task of ID-to-face generation, conditioned solely on ID vectors. Deviating from recent works that combine ID with text embeddings for zero-shot personalization of text-to-image models, we emphasize on the compactness of FR features, which can fully capture the essence of the human face, as opposed to hand-crafted prompts. Crucially, text-augmented models struggle to decouple identity and text, usually necessitating some description of the given face to achieve satisfactory similarity. Arc2Face, however, only needs the discriminative features of ArcFace to guide the generation, offering a robust prior for a plethora of tasks where ID consistency is of paramount importance. As an example, we train a FR model on synthetic images from our model and achieve superior performance to existing synthetic datasets.","sentences":["This paper presents Arc2Face, an identity-conditioned face foundation model, which, given the ArcFace embedding of a person, can generate diverse photo-realistic images with an unparalleled degree of face similarity than existing models.","Despite previous attempts to decode face recognition features into detailed images, we find that common high-resolution datasets (e.g. FFHQ) lack sufficient identities to reconstruct any subject.","To that end, we meticulously upsample a significant portion of the WebFace42M database, the largest public dataset for face recognition (FR). Arc2Face","builds upon a pretrained Stable Diffusion model, yet adapts it to the task of ID-to-face generation, conditioned solely on ID vectors.","Deviating from recent works that combine ID with text embeddings for zero-shot personalization of text-to-image models, we emphasize on the compactness of FR features, which can fully capture the essence of the human face, as opposed to hand-crafted prompts.","Crucially, text-augmented models struggle to decouple identity and text, usually necessitating some description of the given face to achieve satisfactory similarity.","Arc2Face, however, only needs the discriminative features of ArcFace to guide the generation, offering a robust prior for a plethora of tasks where ID consistency is of paramount importance.","As an example, we train a FR model on synthetic images from our model and achieve superior performance to existing synthetic datasets."],"url":"http://arxiv.org/abs/2403.11641v1","category":"cs.CV"}
{"created":"2024-03-18 10:23:59","title":"Quasinormal Modes of Near-Extremal Electric and Magnetic Black Branes","abstract":"Gauge-gravity duality provides a robust mathematical framework for studying the behavior of strongly coupled non-abelian plasmas both near and far away from thermodynamic equilibrium. In particular, their near-equilibrium transport coefficients such as viscosity, conductivity, diffusion constants, etc. can be determined from poles of the retarded Green's function which are the dissipative eigenmodes i.e., the quasinormal modes (QNMs) of the dual gravitational field equations. The AdS5/CFT4 correspondence admits the description of a strongly coupled $\\mathcal{N}$= 4 Supersymmetric Yang Mills (SYM) plasma at non-zero temperature as a dual AdS5 black brane geometry. We demonstrate the application of pseudospectral methods to solving the dual Einstein field equations using the example of homogenous isotropization in $\\mathcal{N}$= 4 SYM plasma far from equilibrium. Using this framework, we also compute the quasinormal modes of electrically (Reissner-Nordstrom) and magnetically charged AdS5 black branes for the case of vanishing spatial momenta. The near-extremal behavior of these QNMs is analyzed for both types of black branes.","sentences":["Gauge-gravity duality provides a robust mathematical framework for studying the behavior of strongly coupled non-abelian plasmas both near and far away from thermodynamic equilibrium.","In particular, their near-equilibrium transport coefficients such as viscosity, conductivity, diffusion constants, etc. can be determined from poles of the retarded Green's function which are the dissipative eigenmodes i.e., the quasinormal modes (QNMs) of the dual gravitational field equations.","The AdS5/CFT4 correspondence admits the description of a strongly coupled $\\mathcal{N}$= 4 Supersymmetric Yang Mills (SYM) plasma at non-zero temperature as a dual AdS5 black brane geometry.","We demonstrate the application of pseudospectral methods to solving the dual Einstein field equations using the example of homogenous isotropization in $\\mathcal{N}$= 4 SYM plasma far from equilibrium.","Using this framework, we also compute the quasinormal modes of electrically (Reissner-Nordstrom) and magnetically charged AdS5 black branes for the case of vanishing spatial momenta.","The near-extremal behavior of these QNMs is analyzed for both types of black branes."],"url":"http://arxiv.org/abs/2403.11640v1","category":"hep-th"}
{"created":"2024-03-18 10:18:29","title":"A restricted additive smoother for finite cell flow problems","abstract":"In this work, we propose an adaptive geometric multigrid method for the solution of large-scale finite cell flow problems. The finite cell method seeks to circumvent the need for a boundary-conforming mesh through the embedding of the physical domain in a regular background mesh. As a result of the intersection between the physical domain and the background computational mesh, the resultant systems of equations are typically numerically ill-conditioned, rendering the appropriate treatment of cutcells a crucial aspect of the solver. To this end, we propose a smoother operator with favorable parallel properties and discuss its memory footprint and parallelization aspects. We propose three cache policies that offer a balance between cached and on-the-fly computation and discuss the optimization opportunities offered by the smoother operator. It is shown that the smoother operator, on account of its additive nature, can be replicated in parallel exactly with little communication overhead, which offers a major advantage in parallel settings as the geometric multigrid solver is consequently independent of the number of processes. The convergence and scalability of the geometric multigrid method is studied using numerical examples. It is shown that the iteration count of the solver remains bounded independent of the problem size and depth of the grid hierarchy. The solver is shown to obtain excellent weak and strong scaling using numerical benchmarks with more than 665 million degrees of freedom. The presented geometric multigrid solver is, therefore, an attractive option for the solution of large-scale finite cell problems in massively parallel high-performance computing environments.","sentences":["In this work, we propose an adaptive geometric multigrid method for the solution of large-scale finite cell flow problems.","The finite cell method seeks to circumvent the need for a boundary-conforming mesh through the embedding of the physical domain in a regular background mesh.","As a result of the intersection between the physical domain and the background computational mesh, the resultant systems of equations are typically numerically ill-conditioned, rendering the appropriate treatment of cutcells a crucial aspect of the solver.","To this end, we propose a smoother operator with favorable parallel properties and discuss its memory footprint and parallelization aspects.","We propose three cache policies that offer a balance between cached and on-the-fly computation and discuss the optimization opportunities offered by the smoother operator.","It is shown that the smoother operator, on account of its additive nature, can be replicated in parallel exactly with little communication overhead, which offers a major advantage in parallel settings as the geometric multigrid solver is consequently independent of the number of processes.","The convergence and scalability of the geometric multigrid method is studied using numerical examples.","It is shown that the iteration count of the solver remains bounded independent of the problem size and depth of the grid hierarchy.","The solver is shown to obtain excellent weak and strong scaling using numerical benchmarks with more than 665 million degrees of freedom.","The presented geometric multigrid solver is, therefore, an attractive option for the solution of large-scale finite cell problems in massively parallel high-performance computing environments."],"url":"http://arxiv.org/abs/2403.11636v1","category":"math.NA"}
{"created":"2024-03-18 10:09:28","title":"Compositional Kronecker Context Optimization for Vision-Language Models","abstract":"Context Optimization (CoOp) has emerged as a simple yet effective technique for adapting CLIP-like vision-language models to downstream image recognition tasks. Nevertheless, learning compact context with satisfactory base-to-new, domain and cross-task generalization ability while adapting to new tasks is still a challenge. To tackle such a challenge, we propose a lightweight yet generalizable approach termed Compositional Kronecker Context Optimization (CK-CoOp). Technically, the prompt's context words in CK-CoOp are learnable vectors, which are crafted by linearly combining base vectors sourced from a dictionary. These base vectors consist of a non-learnable component obtained by quantizing the weights in the token embedding layer, and a learnable component constructed by applying Kronecker product on several learnable tiny matrices. Intuitively, the compositional structure mitigates the risk of overfitting on training data by remembering more pre-trained knowledge. Meantime, the Kronecker product breaks the non-learnable restrictions of the dictionary, thereby enhancing representation ability with minimal additional parameters. Extensive experiments confirm that CK-CoOp achieves state-of-the-art performance under base-to-new, domain and cross-task generalization evaluation, but also has the metrics of fewer learnable parameters and efficient training and inference speed.","sentences":["Context Optimization (CoOp) has emerged as a simple yet effective technique for adapting CLIP-like vision-language models to downstream image recognition tasks.","Nevertheless, learning compact context with satisfactory base-to-new, domain and cross-task generalization ability while adapting to new tasks is still a challenge.","To tackle such a challenge, we propose a lightweight yet generalizable approach termed Compositional Kronecker Context Optimization (CK-CoOp).","Technically, the prompt's context words in CK-CoOp are learnable vectors, which are crafted by linearly combining base vectors sourced from a dictionary.","These base vectors consist of a non-learnable component obtained by quantizing the weights in the token embedding layer, and a learnable component constructed by applying Kronecker product on several learnable tiny matrices.","Intuitively, the compositional structure mitigates the risk of overfitting on training data by remembering more pre-trained knowledge.","Meantime, the Kronecker product breaks the non-learnable restrictions of the dictionary, thereby enhancing representation ability with minimal additional parameters.","Extensive experiments confirm that CK-CoOp achieves state-of-the-art performance under base-to-new, domain and cross-task generalization evaluation, but also has the metrics of fewer learnable parameters and efficient training and inference speed."],"url":"http://arxiv.org/abs/2403.11631v1","category":"cs.CV"}
{"created":"2024-03-18 09:58:52","title":"LoRA-Composer: Leveraging Low-Rank Adaptation for Multi-Concept Customization in Training-Free Diffusion Models","abstract":"Customization generation techniques have significantly advanced the synthesis of specific concepts across varied contexts. Multi-concept customization emerges as the challenging task within this domain. Existing approaches often rely on training a Low-Rank Adaptations (LoRA) fusion matrix of multiple LoRA to merge various concepts into a single image. However, we identify this straightforward method faces two major challenges: 1) concept confusion, which occurs when the model cannot preserve distinct individual characteristics, and 2) concept vanishing, where the model fails to generate the intended subjects. To address these issues, we introduce LoRA-Composer, a training-free framework designed for seamlessly integrating multiple LoRAs, thereby enhancing the harmony among different concepts within generated images. LoRA-Composer addresses concept vanishing through Concept Injection Constraints, enhancing concept visibility via an expanded cross-attention mechanism. To combat concept confusion, Concept Isolation Constraints are introduced, refining the self-attention computation. Furthermore, Latent Re-initialization is proposed to effectively stimulate concept-specific latent within designated regions. Our extensive testing showcases a notable enhancement in LoRA-Composer's performance compared to standard baselines, especially when eliminating the image-based conditions like canny edge or pose estimations. Code is released at https://github.com/Young98CN/LoRA\\_Composer.","sentences":["Customization generation techniques have significantly advanced the synthesis of specific concepts across varied contexts.","Multi-concept customization emerges as the challenging task within this domain.","Existing approaches often rely on training a Low-Rank Adaptations (LoRA) fusion matrix of multiple LoRA to merge various concepts into a single image.","However, we identify this straightforward method faces two major challenges: 1) concept confusion, which occurs when the model cannot preserve distinct individual characteristics, and 2) concept vanishing, where the model fails to generate the intended subjects.","To address these issues, we introduce LoRA-Composer, a training-free framework designed for seamlessly integrating multiple LoRAs, thereby enhancing the harmony among different concepts within generated images.","LoRA-Composer addresses concept vanishing through Concept Injection Constraints, enhancing concept visibility via an expanded cross-attention mechanism.","To combat concept confusion, Concept Isolation Constraints are introduced, refining the self-attention computation.","Furthermore, Latent Re-initialization is proposed to effectively stimulate concept-specific latent within designated regions.","Our extensive testing showcases a notable enhancement in LoRA-Composer's performance compared to standard baselines, especially when eliminating the image-based conditions like canny edge or pose estimations.","Code is released at https://github.com/Young98CN/LoRA\\_Composer."],"url":"http://arxiv.org/abs/2403.11627v1","category":"cs.CV"}
{"created":"2024-03-18 09:50:05","title":"Frontier-Based Exploration for Multi-Robot Rendezvous in Communication-Restricted Unknown Environments","abstract":"Multi-robot rendezvous and exploration are fundamental challenges in the domain of mobile robotic systems. This paper addresses multi-robot rendezvous within an initially unknown environment where communication is only possible after the rendezvous. Traditionally, exploration has been focused on rapidly mapping the environment, often leading to suboptimal rendezvous performance in later stages. We adapt a standard frontier-based exploration technique to integrate exploration and rendezvous into a unified strategy, with a mechanism that allows robots to re-visit previously explored regions thus enhancing rendezvous opportunities. We validate our approach in 3D realistic simulations using ROS, showcasing its effectiveness in achieving faster rendezvous times compared to exploration strategies.","sentences":["Multi-robot rendezvous and exploration are fundamental challenges in the domain of mobile robotic systems.","This paper addresses multi-robot rendezvous within an initially unknown environment where communication is only possible after the rendezvous.","Traditionally, exploration has been focused on rapidly mapping the environment, often leading to suboptimal rendezvous performance in later stages.","We adapt a standard frontier-based exploration technique to integrate exploration and rendezvous into a unified strategy, with a mechanism that allows robots to re-visit previously explored regions thus enhancing rendezvous opportunities.","We validate our approach in 3D realistic simulations using ROS, showcasing its effectiveness in achieving faster rendezvous times compared to exploration strategies."],"url":"http://arxiv.org/abs/2403.11617v1","category":"cs.RO"}
{"created":"2024-03-18 08:55:48","title":"OurDB: Ouroboric Domain Bridging for Multi-Target Domain Adaptive Semantic Segmentation","abstract":"Multi-target domain adaptation (MTDA) for semantic segmentation poses a significant challenge, as it involves multiple target domains with varying distributions. The goal of MTDA is to minimize the domain discrepancies among a single source and multi-target domains, aiming to train a single model that excels across all target domains. Previous MTDA approaches typically employ multiple teacher architectures, where each teacher specializes in one target domain to simplify the task. However, these architectures hinder the student model from fully assimilating comprehensive knowledge from all target-specific teachers and escalate training costs with increasing target domains. In this paper, we propose an ouroboric domain bridging (OurDB) framework, offering an efficient solution to the MTDA problem using a single teacher architecture. This framework dynamically cycles through multiple target domains, aligning each domain individually to restrain the biased alignment problem, and utilizes Fisher information to minimize the forgetting of knowledge from previous target domains. We also propose a context-guided class-wise mixup (CGMix) that leverages contextual information tailored to diverse target contexts in MTDA. Experimental evaluations conducted on four urban driving datasets (i.e., GTA5, Cityscapes, IDD, and Mapillary) demonstrate the superiority of our method over existing state-of-the-art approaches.","sentences":["Multi-target domain adaptation (MTDA) for semantic segmentation poses a significant challenge, as it involves multiple target domains with varying distributions.","The goal of MTDA is to minimize the domain discrepancies among a single source and multi-target domains, aiming to train a single model that excels across all target domains.","Previous MTDA approaches typically employ multiple teacher architectures, where each teacher specializes in one target domain to simplify the task.","However, these architectures hinder the student model from fully assimilating comprehensive knowledge from all target-specific teachers and escalate training costs with increasing target domains.","In this paper, we propose an ouroboric domain bridging (OurDB) framework, offering an efficient solution to the MTDA problem using a single teacher architecture.","This framework dynamically cycles through multiple target domains, aligning each domain individually to restrain the biased alignment problem, and utilizes Fisher information to minimize the forgetting of knowledge from previous target domains.","We also propose a context-guided class-wise mixup (CGMix) that leverages contextual information tailored to diverse target contexts in MTDA.","Experimental evaluations conducted on four urban driving datasets (i.e., GTA5, Cityscapes, IDD, and Mapillary) demonstrate the superiority of our method over existing state-of-the-art approaches."],"url":"http://arxiv.org/abs/2403.11582v1","category":"cs.CV"}
{"created":"2024-03-18 08:53:04","title":"AdaMER-CTC: Connectionist Temporal Classification with Adaptive Maximum Entropy Regularization for Automatic Speech Recognition","abstract":"In Automatic Speech Recognition (ASR) systems, a recurring obstacle is the generation of narrowly focused output distributions. This phenomenon emerges as a side effect of Connectionist Temporal Classification (CTC), a robust sequence learning tool that utilizes dynamic programming for sequence mapping. While earlier efforts have tried to combine the CTC loss with an entropy maximization regularization term to mitigate this issue, they employed a constant weighting term on the regularization during the training, which we find may not be optimal. In this work, we introduce Adaptive Maximum Entropy Regularization (AdaMER), a technique that can modulate the impact of entropy regularization throughout the training process. This approach not only refines ASR model training but ensures that as training proceeds, predictions display the desired model confidence.","sentences":["In Automatic Speech Recognition (ASR) systems, a recurring obstacle is the generation of narrowly focused output distributions.","This phenomenon emerges as a side effect of Connectionist Temporal Classification (CTC), a robust sequence learning tool that utilizes dynamic programming for sequence mapping.","While earlier efforts have tried to combine the CTC loss with an entropy maximization regularization term to mitigate this issue, they employed a constant weighting term on the regularization during the training, which we find may not be optimal.","In this work, we introduce Adaptive Maximum Entropy Regularization (AdaMER), a technique that can modulate the impact of entropy regularization throughout the training process.","This approach not only refines ASR model training but ensures that as training proceeds, predictions display the desired model confidence."],"url":"http://arxiv.org/abs/2403.11578v1","category":"eess.AS"}
{"created":"2024-03-18 08:41:36","title":"R2SNet: Scalable Domain Adaptation for Object Detection in Cloud-Based Robots Ecosystems via Proposal Refinement","abstract":"We introduce a novel approach for scalable domain adaptation in cloud robotics scenarios where robots rely on third-party AI inference services powered by large pre-trained deep neural networks. Our method is based on a downstream proposal-refinement stage running locally on the robots, exploiting a new lightweight DNN architecture, R2SNet. This architecture aims to mitigate performance degradation from domain shifts by adapting the object detection process to the target environment, focusing on relabeling, rescoring, and suppression of bounding-box proposals. Our method allows for local execution on robots, addressing the scalability challenges of domain adaptation without incurring significant computational costs. Real-world results on mobile service robots performing door detection show the effectiveness of the proposed method in achieving scalable domain adaptation.","sentences":["We introduce a novel approach for scalable domain adaptation in cloud robotics scenarios where robots rely on third-party AI inference services powered by large pre-trained deep neural networks.","Our method is based on a downstream proposal-refinement stage running locally on the robots, exploiting a new lightweight DNN architecture, R2SNet.","This architecture aims to mitigate performance degradation from domain shifts by adapting the object detection process to the target environment, focusing on relabeling, rescoring, and suppression of bounding-box proposals.","Our method allows for local execution on robots, addressing the scalability challenges of domain adaptation without incurring significant computational costs.","Real-world results on mobile service robots performing door detection show the effectiveness of the proposed method in achieving scalable domain adaptation."],"url":"http://arxiv.org/abs/2403.11567v1","category":"cs.RO"}
{"created":"2024-03-18 08:33:56","title":"Advancing Neuromorphic Computing: Mixed-Signal Design Techniques Leveraging Brain Code Units and Fundamental Code Units","abstract":"This paper introduces a groundbreaking digital neuromorphic architecture that innovatively integrates Brain Code Unit (BCU) and Fundamental Code Unit (FCU) using mixedsignal design methodologies. Leveraging open-source datasets and the latest advances in materials science, our research focuses on enhancing the computational efficiency, accuracy, and adaptability of neuromorphic systems. The core of our approach lies in harmonizing the precision and scalability of digital systems with the robustness and energy efficiency of analog processing. Through experimentation, we demonstrate the effectiveness of our system across various metrics. The BCU achieved an accuracy of 88.0% and a power efficiency of 20.0 GOP/s/W, while the FCU recorded an accuracy of 86.5% and a power efficiency of 18.5 GOP/s/W. Our mixed-signal design approach significantly improved latency and throughput, achieving a latency as low as 0.75 ms and throughput up to 213 TOP/s. These results firmly establish the potential of our architecture in neuromorphic computing, providing a solid foundation for future developments in this domain. Our study underscores the feasibility of mixedsignal neuromorphic systems and their promise in advancing the field, particularly in applications requiring high efficiency and adaptability","sentences":["This paper introduces a groundbreaking digital neuromorphic architecture that innovatively integrates Brain Code Unit (BCU) and Fundamental Code Unit (FCU) using mixedsignal design methodologies.","Leveraging open-source datasets and the latest advances in materials science, our research focuses on enhancing the computational efficiency, accuracy, and adaptability of neuromorphic systems.","The core of our approach lies in harmonizing the precision and scalability of digital systems with the robustness and energy efficiency of analog processing.","Through experimentation, we demonstrate the effectiveness of our system across various metrics.","The BCU achieved an accuracy of 88.0% and a power efficiency of 20.0 GOP/s/W, while the FCU recorded an accuracy of 86.5% and a power efficiency of 18.5 GOP/s/W. Our mixed-signal design approach significantly improved latency and throughput, achieving a latency as low as 0.75 ms and throughput up to 213 TOP/s. These results firmly establish the potential of our architecture in neuromorphic computing, providing a solid foundation for future developments in this domain.","Our study underscores the feasibility of mixedsignal neuromorphic systems and their promise in advancing the field, particularly in applications requiring high efficiency and adaptability"],"url":"http://arxiv.org/abs/2403.11563v1","category":"cs.AR"}
{"created":"2024-03-18 08:18:33","title":"Distributed Adaptive Gradient Algorithm with Gradient Tracking for Stochastic Non-Convex Optimization","abstract":"This paper considers a distributed stochastic non-convex optimization problem, where the nodes in a network cooperatively minimize a sum of $L$-smooth local cost functions with sparse gradients. By adaptively adjusting the stepsizes according to the historical (possibly sparse) gradients, a distributed adaptive gradient algorithm is proposed, in which a gradient tracking estimator is used to handle the heterogeneity between different local cost functions. We establish an upper bound on the optimality gap, which indicates that our proposed algorithm can reach a first-order stationary solution dependent on the upper bound on the variance of the stochastic gradients. Finally, numerical examples are presented to illustrate the effectiveness of the algorithm.","sentences":["This paper considers a distributed stochastic non-convex optimization problem, where the nodes in a network cooperatively minimize a sum of $L$-smooth local cost functions with sparse gradients.","By adaptively adjusting the stepsizes according to the historical (possibly sparse) gradients, a distributed adaptive gradient algorithm is proposed, in which a gradient tracking estimator is used to handle the heterogeneity between different local cost functions.","We establish an upper bound on the optimality gap, which indicates that our proposed algorithm can reach a first-order stationary solution dependent on the upper bound on the variance of the stochastic gradients.","Finally, numerical examples are presented to illustrate the effectiveness of the algorithm."],"url":"http://arxiv.org/abs/2403.11557v1","category":"math.OC"}
{"created":"2024-03-18 08:00:23","title":"Boosting Continual Learning of Vision-Language Models via Mixture-of-Experts Adapters","abstract":"Continual learning can empower vision-language models to continuously acquire new knowledge, without the need for access to the entire historical dataset. However, mitigating the performance degradation in large-scale models is non-trivial due to (i) parameter shifts throughout lifelong learning and (ii) significant computational burdens associated with full-model tuning. In this work, we present a parameter-efficient continual learning framework to alleviate long-term forgetting in incremental learning with vision-language models. Our approach involves the dynamic expansion of a pre-trained CLIP model, through the integration of Mixture-of-Experts (MoE) adapters in response to new tasks. To preserve the zero-shot recognition capability of vision-language models, we further introduce a Distribution Discriminative Auto-Selector (DDAS) that automatically routes in-distribution and out-of-distribution inputs to the MoE Adapter and the original CLIP, respectively. Through extensive experiments across various settings, our proposed method consistently outperforms previous state-of-the-art approaches while concurrently reducing parameter training burdens by 60%. Our code locates at https://github.com/JiazuoYu/MoE-Adapters4CL","sentences":["Continual learning can empower vision-language models to continuously acquire new knowledge, without the need for access to the entire historical dataset.","However, mitigating the performance degradation in large-scale models is non-trivial due to (i) parameter shifts throughout lifelong learning and (ii) significant computational burdens associated with full-model tuning.","In this work, we present a parameter-efficient continual learning framework to alleviate long-term forgetting in incremental learning with vision-language models.","Our approach involves the dynamic expansion of a pre-trained CLIP model, through the integration of Mixture-of-Experts (MoE) adapters in response to new tasks.","To preserve the zero-shot recognition capability of vision-language models, we further introduce a Distribution Discriminative Auto-Selector (DDAS) that automatically routes in-distribution and out-of-distribution inputs to the MoE Adapter and the original CLIP, respectively.","Through extensive experiments across various settings, our proposed method consistently outperforms previous state-of-the-art approaches while concurrently reducing parameter training burdens by 60%.","Our code locates at https://github.com/JiazuoYu/MoE-Adapters4CL"],"url":"http://arxiv.org/abs/2403.11549v1","category":"cs.CV"}
{"created":"2024-03-18 07:56:49","title":"First-order factors of linear Mahler operators","abstract":"We develop and compare two algorithms for computing first-order right-hand factors in the ring of linear Mahler operators$\\ell_r M^r + \\dots + \\ell_1 M + \\ell_0$where $\\ell_0, \\dots, \\ell_r$ are polynomials in~$x$ and $Mx = x^b M$ for some integer $b \\geq 2$. In other words, we give algorithms for finding all formal infinite product solutions of linear functional equations$\\ell_r(x) f(x^{b^r}) + \\dots + \\ell_1(x) f(x^b) + \\ell_0(x) f(x) = 0$. The first of our algorithms is adapted from Petkov\\v{s}ek's classical algorithm forthe analogous problem in the case of linear recurrences. The second one proceeds by computing a basis of generalized power series solutions of the functional equation and by using Hermite-Pad{\\'e} approximants to detect those linear combinations of the solutions that correspond to first-order factors. We present implementations of both algorithms and discuss their use in combination with criteria from the literature to prove the differential transcendence of power series solutions of Mahler equations.","sentences":["We develop and compare two algorithms for computing first-order right-hand factors in the ring of linear Mahler operators$\\ell_r M^r + \\dots + \\ell_1 M + \\ell_0$where $\\ell_0, \\dots, \\ell_r$ are polynomials in~$x$ and $Mx = x^b M$ for some integer $b \\geq 2$.","In other words, we give algorithms for finding all formal infinite product solutions of linear functional equations$\\ell_r(x) f(x^{b^r})","+","\\dots + \\ell_1(x) f(x^b)","+ \\ell_0(x) f(x)","= 0$.","The first of our algorithms is adapted from Petkov\\v{s}ek's classical algorithm forthe analogous problem in the case of linear recurrences.","The second one proceeds by computing a basis of generalized power series solutions of the functional equation and by using Hermite-Pad{\\'e} approximants to detect those linear combinations of the solutions that correspond to first-order factors.","We present implementations of both algorithms and discuss their use in combination with criteria from the literature to prove the differential transcendence of power series solutions of Mahler equations."],"url":"http://arxiv.org/abs/2403.11545v1","category":"cs.SC"}
{"created":"2024-03-18 07:51:22","title":"Hierarchical Spatial Proximity Reasoning for Vision-and-Language Navigation","abstract":"Most Vision-and-Language Navigation (VLN) algorithms tend to make decision errors, primarily due to a lack of visual common sense and insufficient reasoning capabilities. To address this issue, this paper proposes a Hierarchical Spatial Proximity Reasoning (HSPR) model. Firstly, we design a Scene Understanding Auxiliary Task (SUAT) to assist the agent in constructing a knowledge base of hierarchical spatial proximity for reasoning navigation. Specifically, this task utilizes panoramic views and object features to identify regions in the navigation environment and uncover the adjacency relationships between regions, objects, and region-object pairs. Secondly, we dynamically construct a semantic topological map through agent-environment interactions and propose a Multi-step Reasoning Navigation Algorithm (MRNA) based on the map. This algorithm continuously plans various feasible paths from one region to another, utilizing the constructed proximity knowledge base, enabling more efficient exploration. Additionally, we introduce a Proximity Adaptive Attention Module (PAAM) and Residual Fusion Method (RFM) to enable the model to obtain more accurate navigation decision confidence. Finally, we conduct experiments on publicly available datasets including REVERIE, SOON, R2R, and R4R to validate the effectiveness of the proposed approach.","sentences":["Most Vision-and-Language Navigation (VLN) algorithms tend to make decision errors, primarily due to a lack of visual common sense and insufficient reasoning capabilities.","To address this issue, this paper proposes a Hierarchical Spatial Proximity Reasoning (HSPR) model.","Firstly, we design a Scene Understanding Auxiliary Task (SUAT) to assist the agent in constructing a knowledge base of hierarchical spatial proximity for reasoning navigation.","Specifically, this task utilizes panoramic views and object features to identify regions in the navigation environment and uncover the adjacency relationships between regions, objects, and region-object pairs.","Secondly, we dynamically construct a semantic topological map through agent-environment interactions and propose a Multi-step Reasoning Navigation Algorithm (MRNA) based on the map.","This algorithm continuously plans various feasible paths from one region to another, utilizing the constructed proximity knowledge base, enabling more efficient exploration.","Additionally, we introduce a Proximity Adaptive Attention Module (PAAM) and Residual Fusion Method (RFM) to enable the model to obtain more accurate navigation decision confidence.","Finally, we conduct experiments on publicly available datasets including REVERIE, SOON, R2R, and R4R to validate the effectiveness of the proposed approach."],"url":"http://arxiv.org/abs/2403.11541v1","category":"cs.CV"}
{"created":"2024-03-18 06:59:23","title":"Measurement-Based Quantum Approximate Optimization","abstract":"Parameterized quantum circuits are attractive candidates for potential quantum advantage in the near term and beyond. At the same time, as quantum computing hardware not only continues to improve but also begins to incorporate new features such as mid-circuit measurement and adaptive control, opportunities arise for innovative algorithmic paradigms. In this work we focus on measurement-based quantum computing protocols for approximate optimization, in particular related to quantum alternating operator ans\\\"atze (QAOA), a popular quantum circuit model approach to combinatorial optimization. For the construction and analysis of our measurement-based protocols we demonstrate that diagrammatic approaches, specifically ZX-calculus and its extensions, are effective for adapting such algorithms to the measurement-based setting. In particular we derive measurement patterns for applying QAOA to the broad and important class of QUBO problems. We further outline how for constrained optimization, hard problem constraints may be directly incorporated into our protocol to guarantee the feasibility of the solution found and avoid the need for dealing with penalties. Finally we discuss the resource requirements and tradeoffs of our approach to that of more traditional quantum circuits.","sentences":["Parameterized quantum circuits are attractive candidates for potential quantum advantage in the near term and beyond.","At the same time, as quantum computing hardware not only continues to improve but also begins to incorporate new features such as mid-circuit measurement and adaptive control, opportunities arise for innovative algorithmic paradigms.","In this work we focus on measurement-based quantum computing protocols for approximate optimization, in particular related to quantum alternating operator ans\\\"atze (QAOA), a popular quantum circuit model approach to combinatorial optimization.","For the construction and analysis of our measurement-based protocols we demonstrate that diagrammatic approaches, specifically ZX-calculus and its extensions, are effective for adapting such algorithms to the measurement-based setting.","In particular we derive measurement patterns for applying QAOA to the broad and important class of QUBO problems.","We further outline how for constrained optimization, hard problem constraints may be directly incorporated into our protocol to guarantee the feasibility of the solution found and avoid the need for dealing with penalties.","Finally we discuss the resource requirements and tradeoffs of our approach to that of more traditional quantum circuits."],"url":"http://arxiv.org/abs/2403.11514v1","category":"quant-ph"}
{"created":"2024-03-18 06:54:38","title":"Visual Preference Inference: An Image Sequence-Based Preference Reasoning in Tabletop Object Manipulation","abstract":"In robotic object manipulation, human preferences can often be influenced by the visual attributes of objects, such as color and shape. These properties play a crucial role in operating a robot to interact with objects and align with human intention. In this paper, we focus on the problem of inferring underlying human preferences from a sequence of raw visual observations in tabletop manipulation environments with a variety of object types, named Visual Preference Inference (VPI). To facilitate visual reasoning in the context of manipulation, we introduce the Chain-of-Visual-Residuals (CoVR) method. CoVR employs a prompting mechanism that describes the difference between the consecutive images (i.e., visual residuals) and incorporates such texts with a sequence of images to infer the user's preference. This approach significantly enhances the ability to understand and adapt to dynamic changes in its visual environment during manipulation tasks. Furthermore, we incorporate such texts along with a sequence of images to infer the user's preferences. Our method outperforms baseline methods in terms of extracting human preferences from visual sequences in both simulation and real-world environments. Code and videos are available at: \\href{https://joonhyung-lee.github.io/vpi/}{https://joonhyung-lee.github.io/vpi/}","sentences":["In robotic object manipulation, human preferences can often be influenced by the visual attributes of objects, such as color and shape.","These properties play a crucial role in operating a robot to interact with objects and align with human intention.","In this paper, we focus on the problem of inferring underlying human preferences from a sequence of raw visual observations in tabletop manipulation environments with a variety of object types, named Visual Preference Inference (VPI).","To facilitate visual reasoning in the context of manipulation, we introduce the Chain-of-Visual-Residuals (CoVR) method.","CoVR employs a prompting mechanism that describes the difference between the consecutive images (i.e., visual residuals) and incorporates such texts with a sequence of images to infer the user's preference.","This approach significantly enhances the ability to understand and adapt to dynamic changes in its visual environment during manipulation tasks.","Furthermore, we incorporate such texts along with a sequence of images to infer the user's preferences.","Our method outperforms baseline methods in terms of extracting human preferences from visual sequences in both simulation and real-world environments.","Code and videos are available at: \\href{https://joonhyung-lee.github.io/vpi/}{https://joonhyung-lee.github.io/vpi/}"],"url":"http://arxiv.org/abs/2403.11513v1","category":"cs.RO"}
{"created":"2024-03-18 06:42:38","title":"Sim-to-Real Grasp Detection with Global-to-Local RGB-D Adaptation","abstract":"This paper focuses on the sim-to-real issue of RGB-D grasp detection and formulates it as a domain adaptation problem. In this case, we present a global-to-local method to address hybrid domain gaps in RGB and depth data and insufficient multi-modal feature alignment. First, a self-supervised rotation pre-training strategy is adopted to deliver robust initialization for RGB and depth networks. We then propose a global-to-local alignment pipeline with individual global domain classifiers for scene features of RGB and depth images as well as a local one specifically working for grasp features in the two modalities. In particular, we propose a grasp prototype adaptation module, which aims to facilitate fine-grained local feature alignment by dynamically updating and matching the grasp prototypes from the simulation and real-world scenarios throughout the training process. Due to such designs, the proposed method substantially reduces the domain shift and thus leads to consistent performance improvements. Extensive experiments are conducted on the GraspNet-Planar benchmark and physical environment, and superior results are achieved which demonstrate the effectiveness of our method.","sentences":["This paper focuses on the sim-to-real issue of RGB-D grasp detection and formulates it as a domain adaptation problem.","In this case, we present a global-to-local method to address hybrid domain gaps in RGB and depth data and insufficient multi-modal feature alignment.","First, a self-supervised rotation pre-training strategy is adopted to deliver robust initialization for RGB and depth networks.","We then propose a global-to-local alignment pipeline with individual global domain classifiers for scene features of RGB and depth images as well as a local one specifically working for grasp features in the two modalities.","In particular, we propose a grasp prototype adaptation module, which aims to facilitate fine-grained local feature alignment by dynamically updating and matching the grasp prototypes from the simulation and real-world scenarios throughout the training process.","Due to such designs, the proposed method substantially reduces the domain shift and thus leads to consistent performance improvements.","Extensive experiments are conducted on the GraspNet-Planar benchmark and physical environment, and superior results are achieved which demonstrate the effectiveness of our method."],"url":"http://arxiv.org/abs/2403.11511v1","category":"cs.RO"}
{"created":"2024-03-18 06:25:41","title":"Circle Representation for Medical Instance Object Segmentation","abstract":"Recently, circle representation has been introduced for medical imaging, designed specifically to enhance the detection of instance objects that are spherically shaped (e.g., cells, glomeruli, and nuclei). Given its outstanding effectiveness in instance detection, it is compelling to consider the application of circle representation for segmenting instance medical objects. In this study, we introduce CircleSnake, a simple end-to-end segmentation approach that utilizes circle contour deformation for segmenting ball-shaped medical objects at the instance level. The innovation of CircleSnake lies in these three areas: (1) It substitutes the complex bounding box-to-octagon contour transformation with a more consistent and rotation-invariant bounding circle-to-circle contour adaptation. This adaptation specifically targets ball-shaped medical objects. (2) The circle representation employed in CircleSnake significantly reduces the degrees of freedom to two, compared to eight in the octagon representation. This reduction enhances both the robustness of the segmentation performance and the rotational consistency of the method. (3) CircleSnake is the first end-to-end deep instance segmentation pipeline to incorporate circle representation, encompassing consistent circle detection, circle contour proposal, and circular convolution in a unified framework. This integration is achieved through the novel application of circular graph convolution within the context of circle detection and instance segmentation. In practical applications, such as the detection of glomeruli, nuclei, and eosinophils in pathological images, CircleSnake has demonstrated superior performance and greater rotation invariance when compared to benchmarks. The code has been made publicly available: https://github.com/hrlblab/CircleSnake.","sentences":["Recently, circle representation has been introduced for medical imaging, designed specifically to enhance the detection of instance objects that are spherically shaped (e.g., cells, glomeruli, and nuclei).","Given its outstanding effectiveness in instance detection, it is compelling to consider the application of circle representation for segmenting instance medical objects.","In this study, we introduce CircleSnake, a simple end-to-end segmentation approach that utilizes circle contour deformation for segmenting ball-shaped medical objects at the instance level.","The innovation of CircleSnake lies in these three areas: (1) It substitutes the complex bounding box-to-octagon contour transformation with a more consistent and rotation-invariant bounding circle-to-circle contour adaptation.","This adaptation specifically targets ball-shaped medical objects.","(2) The circle representation employed in CircleSnake significantly reduces the degrees of freedom to two, compared to eight in the octagon representation.","This reduction enhances both the robustness of the segmentation performance and the rotational consistency of the method.","(3) CircleSnake is the first end-to-end deep instance segmentation pipeline to incorporate circle representation, encompassing consistent circle detection, circle contour proposal, and circular convolution in a unified framework.","This integration is achieved through the novel application of circular graph convolution within the context of circle detection and instance segmentation.","In practical applications, such as the detection of glomeruli, nuclei, and eosinophils in pathological images, CircleSnake has demonstrated superior performance and greater rotation invariance when compared to benchmarks.","The code has been made publicly available: https://github.com/hrlblab/CircleSnake."],"url":"http://arxiv.org/abs/2403.11507v1","category":"cs.CV"}
{"created":"2024-03-18 06:20:49","title":"Covid-19 detection from CT scans using EfficientNet and Attention mechanism","abstract":"Manual diagnosis and analysis of COVID-19 through the examination of lung Computed Tomography (CT) scan images by physicians tends to result in inefficiency, especially with high patient volumes and numerous images per patient. We address the need for automation by developing a deep learning model-based pipeline for COVID-19 detection from CT scan images of the lungs. The Domain adaptation, Explainability, and Fairness in AI for Medical Image Analysis Workshop and COVID-19 Diagnosis Competition (DEF-AI-MIA COV19D) provides an opportunity to assess our designed pipeline for COVID-19 detection from CT scan images. The proposed pipeline incorporates EfficientNet with an Attention mechanism with a pre-processing step. Our pipeline outperforms last year's teams on the validation set of the competition dataset.","sentences":["Manual diagnosis and analysis of COVID-19 through the examination of lung Computed Tomography (CT) scan images by physicians tends to result in inefficiency, especially with high patient volumes and numerous images per patient.","We address the need for automation by developing a deep learning model-based pipeline for COVID-19 detection from CT scan images of the lungs.","The Domain adaptation, Explainability, and Fairness in AI for Medical Image Analysis Workshop and COVID-19 Diagnosis Competition (DEF-AI-MIA COV19D) provides an opportunity to assess our designed pipeline for COVID-19 detection from CT scan images.","The proposed pipeline incorporates EfficientNet with an Attention mechanism with a pre-processing step.","Our pipeline outperforms last year's teams on the validation set of the competition dataset."],"url":"http://arxiv.org/abs/2403.11505v1","category":"eess.IV"}
{"created":"2024-03-18 06:19:37","title":"MLVICX: Multi-Level Variance-Covariance Exploration for Chest X-ray Self-Supervised Representation Learning","abstract":"Self-supervised learning (SSL) is potentially useful in reducing the need for manual annotation and making deep learning models accessible for medical image analysis tasks. By leveraging the representations learned from unlabeled data, self-supervised models perform well on tasks that require little to no fine-tuning. However, for medical images, like chest X-rays, which are characterized by complex anatomical structures and diverse clinical conditions, there arises a need for representation learning techniques that can encode fine-grained details while preserving the broader contextual information. In this context, we introduce MLVICX (Multi-Level Variance-Covariance Exploration for Chest X-ray Self-Supervised Representation Learning), an approach to capture rich representations in the form of embeddings from chest X-ray images. Central to our approach is a novel multi-level variance and covariance exploration strategy that empowers the model to detect diagnostically meaningful patterns while reducing redundancy effectively. By enhancing the variance and covariance of the learned embeddings, MLVICX promotes the retention of critical medical insights by adapting both global and local contextual details. We demonstrate the performance of MLVICX in advancing self-supervised chest X-ray representation learning through comprehensive experiments. The performance enhancements we observe across various downstream tasks highlight the significance of the proposed approach in enhancing the utility of chest X-ray embeddings for precision medical diagnosis and comprehensive image analysis. For pertaining, we used the NIH-Chest X-ray dataset, while for downstream tasks, we utilized NIH-Chest X-ray, Vinbig-CXR, RSNA pneumonia, and SIIM-ACR Pneumothorax datasets. Overall, we observe more than 3% performance gains over SOTA SSL approaches in various downstream tasks.","sentences":["Self-supervised learning (SSL) is potentially useful in reducing the need for manual annotation and making deep learning models accessible for medical image analysis tasks.","By leveraging the representations learned from unlabeled data, self-supervised models perform well on tasks that require little to no fine-tuning.","However, for medical images, like chest X-rays, which are characterized by complex anatomical structures and diverse clinical conditions, there arises a need for representation learning techniques that can encode fine-grained details while preserving the broader contextual information.","In this context, we introduce MLVICX (Multi-Level Variance-Covariance Exploration for Chest X-ray Self-Supervised Representation Learning), an approach to capture rich representations in the form of embeddings from chest X-ray images.","Central to our approach is a novel multi-level variance and covariance exploration strategy that empowers the model to detect diagnostically meaningful patterns while reducing redundancy effectively.","By enhancing the variance and covariance of the learned embeddings, MLVICX promotes the retention of critical medical insights by adapting both global and local contextual details.","We demonstrate the performance of MLVICX in advancing self-supervised chest X-ray representation learning through comprehensive experiments.","The performance enhancements we observe across various downstream tasks highlight the significance of the proposed approach in enhancing the utility of chest X-ray embeddings for precision medical diagnosis and comprehensive image analysis.","For pertaining, we used the NIH-Chest X-ray dataset, while for downstream tasks, we utilized NIH-Chest X-ray, Vinbig-CXR, RSNA pneumonia, and SIIM-ACR Pneumothorax datasets.","Overall, we observe more than 3% performance gains over SOTA SSL approaches in various downstream tasks."],"url":"http://arxiv.org/abs/2403.11504v1","category":"eess.IV"}
{"created":"2024-03-18 06:12:17","title":"The role of Ohmic dissipation of internal currents on Hot Jupiter radii","abstract":"The inflated radii observed in hundreds of Hot Jupiters represent a long-standing open issue. The observed correlation between radii and irradiation strength, and the occasional extreme cases, nearly double the size of Jupiter, remain without a comprehensive quantitative explanation. In this investigation, we delve into this issue within the framework of Ohmic dissipation, one of the most promising mechanisms for explaining the radius anomaly. Using the evolutionary code MESA, we simulate the evolution of irradiated giant planets, spanning the range 1 to 8 Jupiter masses, incorporating an internal source of Ohmic dissipation located beneath the radiative-convective boundary. Our modeling is based on physical parameters, and accounts for the approximated conductivity and the evolution of the magnetic fields, utilizing widely-used scaling laws. We compute the radius evolution across a spectrum of masses and equilibrium temperatures, considering varying amounts of Ohmic dissipation, calculated with the internal conductivity profile and an effective parametrization of the currents, based on the typical radius of curvature of the field lines. Our analysis reveals that this internal Ohmic dissipation can broadly reproduce the range of observed radii using values of radius of curvature up to about one order of magnitude lower than what we estimate from the Juno measurements of the Jovian magnetosphere and from MHD dynamo simulations presented herein. The observed trend with equilibrium temperature can be explained if the highly-irradiated planets have more intense and more small-scale magnetic fields. This suggests the possibility of an interplay between atmospherically induced currents and the interior, via turbulence, in agreement with recent box simulations of turbulent MHD in atmospheric columns.","sentences":["The inflated radii observed in hundreds of Hot Jupiters represent a long-standing open issue.","The observed correlation between radii and irradiation strength, and the occasional extreme cases, nearly double the size of Jupiter, remain without a comprehensive quantitative explanation.","In this investigation, we delve into this issue within the framework of Ohmic dissipation, one of the most promising mechanisms for explaining the radius anomaly.","Using the evolutionary code MESA, we simulate the evolution of irradiated giant planets, spanning the range 1 to 8 Jupiter masses, incorporating an internal source of Ohmic dissipation located beneath the radiative-convective boundary.","Our modeling is based on physical parameters, and accounts for the approximated conductivity and the evolution of the magnetic fields, utilizing widely-used scaling laws.","We compute the radius evolution across a spectrum of masses and equilibrium temperatures, considering varying amounts of Ohmic dissipation, calculated with the internal conductivity profile and an effective parametrization of the currents, based on the typical radius of curvature of the field lines.","Our analysis reveals that this internal Ohmic dissipation can broadly reproduce the range of observed radii using values of radius of curvature up to about one order of magnitude lower than what we estimate from the Juno measurements of the Jovian magnetosphere and from MHD dynamo simulations presented herein.","The observed trend with equilibrium temperature can be explained if the highly-irradiated planets have more intense and more small-scale magnetic fields.","This suggests the possibility of an interplay between atmospherically induced currents and the interior, via turbulence, in agreement with recent box simulations of turbulent MHD in atmospheric columns."],"url":"http://arxiv.org/abs/2403.11501v1","category":"astro-ph.EP"}
{"created":"2024-03-18 06:07:45","title":"Domain Adaptation Using Pseudo Labels for COVID-19 Detection","abstract":"In response to the need for rapid and accurate COVID-19 diagnosis during the global pandemic, we present a two-stage framework that leverages pseudo labels for domain adaptation to enhance the detection of COVID-19 from CT scans. By utilizing annotated data from one domain and non-annotated data from another, the model overcomes the challenge of data scarcity and variability, common in emergent health crises. The innovative approach of generating pseudo labels enables the model to iteratively refine its learning process, thereby improving its accuracy and adaptability across different hospitals and medical centres. Experimental results on COV19-CT-DB database showcase the model's potential to achieve high diagnostic precision, significantly contributing to efficient patient management and alleviating the strain on healthcare systems. Our method achieves 0.92 Macro F1 Score on the validation set of Covid-19 domain adaptation challenge.","sentences":["In response to the need for rapid and accurate COVID-19 diagnosis during the global pandemic, we present a two-stage framework that leverages pseudo labels for domain adaptation to enhance the detection of COVID-19 from CT scans.","By utilizing annotated data from one domain and non-annotated data from another, the model overcomes the challenge of data scarcity and variability, common in emergent health crises.","The innovative approach of generating pseudo labels enables the model to iteratively refine its learning process, thereby improving its accuracy and adaptability across different hospitals and medical centres.","Experimental results on COV19-CT-DB database showcase the model's potential to achieve high diagnostic precision, significantly contributing to efficient patient management and alleviating the strain on healthcare systems.","Our method achieves 0.92 Macro F1 Score on the validation set of Covid-19 domain adaptation challenge."],"url":"http://arxiv.org/abs/2403.11498v1","category":"eess.IV"}
{"created":"2024-03-18 05:49:45","title":"Uncertainty-Calibrated Test-Time Model Adaptation without Forgetting","abstract":"Test-time adaptation (TTA) seeks to tackle potential distribution shifts between training and test data by adapting a given model w.r.t. any test sample. Although recent TTA has shown promising performance, we still face two key challenges: 1) prior methods perform backpropagation for each test sample, resulting in unbearable optimization costs to many applications; 2) while existing TTA can significantly improve the test performance on out-of-distribution data, they often suffer from severe performance degradation on in-distribution data after TTA (known as forgetting). To this end, we have proposed an Efficient Anti-Forgetting Test-Time Adaptation (EATA) method which develops an active sample selection criterion to identify reliable and non-redundant samples for test-time entropy minimization. To alleviate forgetting, EATA introduces a Fisher regularizer estimated from test samples to constrain important model parameters from drastic changes. However, in EATA, the adopted entropy loss consistently assigns higher confidence to predictions even for samples that are underlying uncertain, leading to overconfident predictions. To tackle this, we further propose EATA with Calibration (EATA-C) to separately exploit the reducible model uncertainty and the inherent data uncertainty for calibrated TTA. Specifically, we measure the model uncertainty by the divergence between predictions from the full network and its sub-networks, on which we propose a divergence loss to encourage consistent predictions instead of overconfident ones. To further recalibrate prediction confidence, we utilize the disagreement among predicted labels as an indicator of the data uncertainty, and then devise a min-max entropy regularizer to selectively increase and decrease prediction confidence for different samples. Experiments on image classification and semantic segmentation verify the effectiveness of our methods.","sentences":["Test-time adaptation (TTA) seeks to tackle potential distribution shifts between training and test data by adapting a given model w.r.t.","any test sample.","Although recent TTA has shown promising performance, we still face two key challenges: 1) prior methods perform backpropagation for each test sample, resulting in unbearable optimization costs to many applications; 2) while existing TTA can significantly improve the test performance on out-of-distribution data, they often suffer from severe performance degradation on in-distribution data after TTA (known as forgetting).","To this end, we have proposed an Efficient Anti-Forgetting Test-Time Adaptation (EATA) method which develops an active sample selection criterion to identify reliable and non-redundant samples for test-time entropy minimization.","To alleviate forgetting, EATA introduces a Fisher regularizer estimated from test samples to constrain important model parameters from drastic changes.","However, in EATA, the adopted entropy loss consistently assigns higher confidence to predictions even for samples that are underlying uncertain, leading to overconfident predictions.","To tackle this, we further propose EATA with Calibration (EATA-C) to separately exploit the reducible model uncertainty and the inherent data uncertainty for calibrated TTA.","Specifically, we measure the model uncertainty by the divergence between predictions from the full network and its sub-networks, on which we propose a divergence loss to encourage consistent predictions instead of overconfident ones.","To further recalibrate prediction confidence, we utilize the disagreement among predicted labels as an indicator of the data uncertainty, and then devise a min-max entropy regularizer to selectively increase and decrease prediction confidence for different samples.","Experiments on image classification and semantic segmentation verify the effectiveness of our methods."],"url":"http://arxiv.org/abs/2403.11491v1","category":"cs.LG"}
{"created":"2024-03-18 04:42:24","title":"Tight minimum degree conditions for apex-outerplanar minors and subdivisions in graphs and digraphs","abstract":"Motivated by Hadwiger's conjecture and related problems for list-coloring, we study graphs $H$ for which every graph with minimum degree at least $|V(H)|-1$ contains $H$ as a minor. We prove that a large class of apex-outerplanar graphs satisfies this property. Our result gives the first examples of such graphs whose vertex cover numbers are significantly larger than half of the number of its vertices, which breaks a barrier for attacking related coloring problems via extremal functions, and recovers all known such graphs that have arbitrarily large maximum degree. Our proof can be adapted to directed graphs to show that if $\\vec H$ is the digraph obtained from a directed cycle or an in-arborescence by adding an apex source, then every digraph with minimum out-degree $|V(\\vec H)|-1$ contains $\\vec H$ as a subdivision or a butterfly minor respectively. These results provide the optimal upper bound for the chromatic number and dichromatic number of graphs and digraphs that do not contain the aforementioned graphs or digraphs as a minor, butterfly minor and a subdivision, respectively. Special cases of our results solve an open problem of Aboulker, Cohen, Havet, Lochet, Moura and Thomass\\'{e} and strengthen results of Gishboliner, Steiner and Szab\\'{o}.","sentences":["Motivated by Hadwiger's conjecture and related problems for list-coloring, we study graphs $H$ for which every graph with minimum degree at least $|V(H)|-1$ contains $H$ as a minor.","We prove that a large class of apex-outerplanar graphs satisfies this property.","Our result gives the first examples of such graphs whose vertex cover numbers are significantly larger than half of the number of its vertices, which breaks a barrier for attacking related coloring problems via extremal functions, and recovers all known such graphs that have arbitrarily large maximum degree.","Our proof can be adapted to directed graphs to show that if $\\vec H$ is the digraph obtained from a directed cycle or an in-arborescence by adding an apex source, then every digraph with minimum out-degree $|V(\\vec H)|-1$ contains $\\vec H$ as a subdivision or a butterfly minor respectively.","These results provide the optimal upper bound for the chromatic number and dichromatic number of graphs and digraphs that do not contain the aforementioned graphs or digraphs as a minor, butterfly minor and a subdivision, respectively.","Special cases of our results solve an open problem of Aboulker, Cohen, Havet, Lochet, Moura and Thomass\\'{e} and strengthen results of Gishboliner, Steiner and Szab\\'{o}."],"url":"http://arxiv.org/abs/2403.11470v1","category":"math.CO"}
{"created":"2024-03-18 04:20:16","title":"ALDM-Grasping: Diffusion-aided Zero-Shot Sim-to-Real Transfer for Robot Grasping","abstract":"To tackle the \"reality gap\" encountered in Sim-to-Real transfer, this study proposes a diffusion-based framework that minimizes inconsistencies in grasping actions between the simulation settings and realistic environments. The process begins by training an adversarial supervision layout-to-image diffusion model(ALDM). Then, leverage the ALDM approach to enhance the simulation environment, rendering it with photorealistic fidelity, thereby optimizing robotic grasp task training. Experimental results indicate this framework outperforms existing models in both success rates and adaptability to new environments through improvements in the accuracy and reliability of visual grasping actions under a variety of conditions. Specifically, it achieves a 75\\% success rate in grasping tasks under plain backgrounds and maintains a 65\\% success rate in more complex scenarios. This performance demonstrates this framework excels at generating controlled image content based on text descriptions, identifying object grasp points, and demonstrating zero-shot learning in complex, unseen scenarios.","sentences":["To tackle the \"reality gap\" encountered in Sim-to-Real transfer, this study proposes a diffusion-based framework that minimizes inconsistencies in grasping actions between the simulation settings and realistic environments.","The process begins by training an adversarial supervision layout-to-image diffusion model(ALDM).","Then, leverage the ALDM approach to enhance the simulation environment, rendering it with photorealistic fidelity, thereby optimizing robotic grasp task training.","Experimental results indicate this framework outperforms existing models in both success rates and adaptability to new environments through improvements in the accuracy and reliability of visual grasping actions under a variety of conditions.","Specifically, it achieves a 75\\% success rate in grasping tasks under plain backgrounds and maintains a 65\\% success rate in more complex scenarios.","This performance demonstrates this framework excels at generating controlled image content based on text descriptions, identifying object grasp points, and demonstrating zero-shot learning in complex, unseen scenarios."],"url":"http://arxiv.org/abs/2403.11459v1","category":"cs.RO"}
{"created":"2024-03-18 04:01:26","title":"Bridging 3D Gaussian and Mesh for Freeview Video Rendering","abstract":"This is only a preview version of GauMesh. Recently, primitive-based rendering has been proven to achieve convincing results in solving the problem of modeling and rendering the 3D dynamic scene from 2D images. Despite this, in the context of novel view synthesis, each type of primitive has its inherent defects in terms of representation ability. It is difficult to exploit the mesh to depict the fuzzy geometry. Meanwhile, the point-based splatting (e.g. the 3D Gaussian Splatting) method usually produces artifacts or blurry pixels in the area with smooth geometry and sharp textures. As a result, it is difficult, even not impossible, to represent the complex and dynamic scene with a single type of primitive. To this end, we propose a novel approach, GauMesh, to bridge the 3D Gaussian and Mesh for modeling and rendering the dynamic scenes. Given a sequence of tracked mesh as initialization, our goal is to simultaneously optimize the mesh geometry, color texture, opacity maps, a set of 3D Gaussians, and the deformation field. At a specific time, we perform $\\alpha$-blending on the RGB and opacity values based on the merged and re-ordered z-buffers from mesh and 3D Gaussian rasterizations. This produces the final rendering, which is supervised by the ground-truth image. Experiments demonstrate that our approach adapts the appropriate type of primitives to represent the different parts of the dynamic scene and outperforms all the baseline methods in both quantitative and qualitative comparisons without losing render speed.","sentences":["This is only a preview version of GauMesh.","Recently, primitive-based rendering has been proven to achieve convincing results in solving the problem of modeling and rendering the 3D dynamic scene from 2D images.","Despite this, in the context of novel view synthesis, each type of primitive has its inherent defects in terms of representation ability.","It is difficult to exploit the mesh to depict the fuzzy geometry.","Meanwhile, the point-based splatting (e.g. the 3D Gaussian Splatting) method usually produces artifacts or blurry pixels in the area with smooth geometry and sharp textures.","As a result, it is difficult, even not impossible, to represent the complex and dynamic scene with a single type of primitive.","To this end, we propose a novel approach, GauMesh, to bridge the 3D Gaussian and Mesh for modeling and rendering the dynamic scenes.","Given a sequence of tracked mesh as initialization, our goal is to simultaneously optimize the mesh geometry, color texture, opacity maps, a set of 3D Gaussians, and the deformation field.","At a specific time, we perform $\\alpha$-blending on the RGB and opacity values based on the merged and re-ordered z-buffers from mesh and 3D Gaussian rasterizations.","This produces the final rendering, which is supervised by the ground-truth image.","Experiments demonstrate that our approach adapts the appropriate type of primitives to represent the different parts of the dynamic scene and outperforms all the baseline methods in both quantitative and qualitative comparisons without losing render speed."],"url":"http://arxiv.org/abs/2403.11453v1","category":"cs.GR"}
{"created":"2024-03-18 03:10:36","title":"InsCL: A Data-efficient Continual Learning Paradigm for Fine-tuning Large Language Models with Instructions","abstract":"Instruction tuning effectively optimizes Large Language Models (LLMs) for downstream tasks. Due to the changing environment in real-life applications, LLMs necessitate continual task-specific adaptation without catastrophic forgetting. Considering the heavy computational cost, replay-based Continual Learning (CL) methods are the simplest and most widely used for LLMs to address the forgetting issue. However, traditional replay-based methods do not fully utilize instructions to customize the replay strategy. In this work, we propose a novel paradigm called Instruction-based Continual Learning (InsCL). InsCL dynamically replays previous data based on task similarity, calculated by Wasserstein Distance with instructions. Moreover, we further introduce an Instruction Information Metric (InsInfo) to quantify the complexity and diversity of instructions. According to InsInfo, InsCL guides the replay process more inclined to high-quality data. We conduct extensive experiments over 16 tasks with different training orders, observing consistent performance improvements of InsCL. When all tasks have been trained, InsCL achieves performance gains of 3.0 Relative Gain compared with Random Replay, and 27.96 Relative Gain compared with No Replay.","sentences":["Instruction tuning effectively optimizes Large Language Models (LLMs) for downstream tasks.","Due to the changing environment in real-life applications, LLMs necessitate continual task-specific adaptation without catastrophic forgetting.","Considering the heavy computational cost, replay-based Continual Learning (CL) methods are the simplest and most widely used for LLMs to address the forgetting issue.","However, traditional replay-based methods do not fully utilize instructions to customize the replay strategy.","In this work, we propose a novel paradigm called Instruction-based Continual Learning (InsCL).","InsCL dynamically replays previous data based on task similarity, calculated by Wasserstein Distance with instructions.","Moreover, we further introduce an Instruction Information Metric (InsInfo) to quantify the complexity and diversity of instructions.","According to InsInfo, InsCL guides the replay process more inclined to high-quality data.","We conduct extensive experiments over 16 tasks with different training orders, observing consistent performance improvements of InsCL.","When all tasks have been trained, InsCL achieves performance gains of 3.0 Relative Gain compared with Random Replay, and 27.96 Relative Gain compared with No Replay."],"url":"http://arxiv.org/abs/2403.11435v1","category":"cs.CL"}
{"created":"2024-03-18 02:19:15","title":"Solar chromospheric heating by magnetohydrodynamic waves: dependence on magnetic field inclination","abstract":"A proposed mechanism for solar chromospheric heating is that magnetohydrodynamic waves propagate upward along magnetic field lines and dissipate their energy in the chromosphere. In particular, compressible magneto-acoustic waves may contribute to the heating. Theoretically, the components below the cutoff frequency cannot propagate into the chromosphere; however, the cutoff frequency depends on the inclination of the magnetic field lines. In this study, using high temporal cadence spectral data of IRIS and Hinode SOT spectropolarimeter (SP) in plages, we investigated the dependence of the low-frequency waves on magnetic-field properties and quantitatively estimated the amount of energy dissipation in the chromosphere. The following results were obtained: (a) The amount of energy dissipated by the low-frequency component (3--6 mHz) increases with the field inclination below 40 degrees, whereas it is decreased as a function of the field inclination above 40 degrees. (b) The amount of the energy is enhanced toward $10^4 W/m^2$, which is the energy required for heating in the chromospheric plage regions, when the magnetic field is higher than 600 G and inclined more than 40 degree. (c) In the photosphere, the low-frequency component has much more power in the magnetic field inclined more and weaker than 400 G. The results suggest that the observed low-frequency components can bring the energy along the magnetic field lines and that only a specific range of the field inclination angles and field strength may allow the low-frequency component to bring the sufficient amount of the energy into the chromosphere.","sentences":["A proposed mechanism for solar chromospheric heating is that magnetohydrodynamic waves propagate upward along magnetic field lines and dissipate their energy in the chromosphere.","In particular, compressible magneto-acoustic waves may contribute to the heating.","Theoretically, the components below the cutoff frequency cannot propagate into the chromosphere; however, the cutoff frequency depends on the inclination of the magnetic field lines.","In this study, using high temporal cadence spectral data of IRIS and Hinode SOT spectropolarimeter (SP) in plages, we investigated the dependence of the low-frequency waves on magnetic-field properties and quantitatively estimated the amount of energy dissipation in the chromosphere.","The following results were obtained: (a) The amount of energy dissipated by the low-frequency component (3--6 mHz) increases with the field inclination below 40 degrees, whereas it is decreased as a function of the field inclination above 40 degrees.","(b) The amount of the energy is enhanced toward $10^4 W/m^2$, which is the energy required for heating in the chromospheric plage regions, when the magnetic field is higher than 600 G and inclined more than 40 degree.","(c) In the photosphere, the low-frequency component has much more power in the magnetic field inclined more and weaker than 400 G.","The results suggest that the observed low-frequency components can bring the energy along the magnetic field lines and that only a specific range of the field inclination angles and field strength may allow the low-frequency component to bring the sufficient amount of the energy into the chromosphere."],"url":"http://arxiv.org/abs/2403.11419v1","category":"astro-ph.SR"}
{"created":"2024-03-18 02:11:34","title":"Positioning Using Wireless Networks: Applications, Recent Progress and Future Challenges","abstract":"Positioning has recently received considerable attention as a key enabler in emerging applications such as extended reality, unmanned aerial vehicles and smart environments. These applications require both data communication and high-precision positioning, and thus they are particularly well-suited to be offered in wireless networks (WNs). The purpose of this paper is to provide a comprehensive overview of existing works and new trends in the field of positioning techniques from both the academic and industrial perspectives. The paper provides a comprehensive overview of positioning in WNs, covering the background, applications, measurements, state-of-the-art technologies and future challenges. The paper outlines the applications of positioning from the perspectives of public facilities, enterprises and individual users. We investigate the key performance indicators and measurements of positioning systems, followed by the review of the key enabler techniques such as artificial intelligence/large models and adaptive systems. Next, we discuss a number of typical wireless positioning technologies. We extend our overview beyond the academic progress, to include the standardization efforts, and finally, we provide insight into the challenges that remain. The comprehensive overview of exisitng efforts and new trends in the field of positioning from both the academic and industrial communities would be a useful reference to researchers in the field.","sentences":["Positioning has recently received considerable attention as a key enabler in emerging applications such as extended reality, unmanned aerial vehicles and smart environments.","These applications require both data communication and high-precision positioning, and thus they are particularly well-suited to be offered in wireless networks (WNs).","The purpose of this paper is to provide a comprehensive overview of existing works and new trends in the field of positioning techniques from both the academic and industrial perspectives.","The paper provides a comprehensive overview of positioning in WNs, covering the background, applications, measurements, state-of-the-art technologies and future challenges.","The paper outlines the applications of positioning from the perspectives of public facilities, enterprises and individual users.","We investigate the key performance indicators and measurements of positioning systems, followed by the review of the key enabler techniques such as artificial intelligence/large models and adaptive systems.","Next, we discuss a number of typical wireless positioning technologies.","We extend our overview beyond the academic progress, to include the standardization efforts, and finally, we provide insight into the challenges that remain.","The comprehensive overview of exisitng efforts and new trends in the field of positioning from both the academic and industrial communities would be a useful reference to researchers in the field."],"url":"http://arxiv.org/abs/2403.11417v1","category":"eess.SP"}
{"created":"2024-03-18 01:20:38","title":"Embracing the Generative AI Revolution: Advancing Tertiary Education in Cybersecurity with GPT","abstract":"The rapid advancement of generative Artificial Intelligence (AI) technologies, particularly Generative Pre-trained Transformer (GPT) models such as ChatGPT, has the potential to significantly impact cybersecurity. In this study, we investigated the impact of GPTs, specifically ChatGPT, on tertiary education in cybersecurity, and provided recommendations for universities to adapt their curricula to meet the evolving needs of the industry. Our research highlighted the importance of understanding the alignment between GPT's ``mental model'' and human cognition, as well as the enhancement of GPT capabilities to human skills based on Bloom's taxonomy. By analyzing current educational practices and the alignment of curricula with industry requirements, we concluded that universities providing practical degrees like cybersecurity should align closely with industry demand and embrace the inevitable generative AI revolution, while applying stringent ethics oversight to safeguard responsible GPT usage. We proposed a set of recommendations focused on updating university curricula, promoting agility within universities, fostering collaboration between academia, industry, and policymakers, and evaluating and assessing educational outcomes.","sentences":["The rapid advancement of generative Artificial Intelligence (AI) technologies, particularly Generative Pre-trained Transformer (GPT) models such as ChatGPT, has the potential to significantly impact cybersecurity.","In this study, we investigated the impact of GPTs, specifically ChatGPT, on tertiary education in cybersecurity, and provided recommendations for universities to adapt their curricula to meet the evolving needs of the industry.","Our research highlighted the importance of understanding the alignment between GPT's ``mental model'' and human cognition, as well as the enhancement of GPT capabilities to human skills based on Bloom's taxonomy.","By analyzing current educational practices and the alignment of curricula with industry requirements, we concluded that universities providing practical degrees like cybersecurity should align closely with industry demand and embrace the inevitable generative AI revolution, while applying stringent ethics oversight to safeguard responsible GPT usage.","We proposed a set of recommendations focused on updating university curricula, promoting agility within universities, fostering collaboration between academia, industry, and policymakers, and evaluating and assessing educational outcomes."],"url":"http://arxiv.org/abs/2403.11402v1","category":"cs.CY"}
{"created":"2024-03-18 01:13:39","title":"Cloaking Transition of Droplets on Lubricated Brushes","abstract":"We study the equilibrium properties and the wetting behavior of a simple liquid on a polymer brush, with and without presence of lubricant by multibody Dissipative Particle Dynamics simulations. The lubricant is modelled as a polymeric liquid consisting of short chains that are chemically identical to the brush polymers. We investigate the behavior of the brush in terms of the grafting density and the amount of lubricant present. Regarding the wetting behavior, we study a sessile droplet on top of the brush. The droplet consists of non-bonded particles that form a dense phase. Our model and choice of parameters result in the formation of a wetting ridge and in the cloaking of the droplet by the lubricant, i.e. the lubricant chains creep up onto the droplet and eventually cover its surface completely. Cloaking is a phenomenon that is observed experimentally and is of integral importance to the dynamics of sliding droplets. We quantify the cloaking in terms of its thickness, which increases with the amount of lubricant present. The analysis reveals a well-defined transition point where the cloaking sets in. We propose a thermodynamic theory to explain this behavior. In addition we investigate the dependence of the contact angles on the size of the droplet and the possible effect of line tension. We quantify the variation of the contact angle with the curvature of the contact line on a lubricant free brush and find a negative value for the line tension. Finally we investigate the effect of cloaking/lubrication on the contact angles and the wetting ridge. We find that lubrication and cloaking reduce the contact angles by a couple of degrees. The effect on the wetting ridge is a reduction in the extension of the brush chains near the three phase contact line, an effect that was also observed in experiments of droplets on crosslinked gels.","sentences":["We study the equilibrium properties and the wetting behavior of a simple liquid on a polymer brush, with and without presence of lubricant by multibody Dissipative Particle Dynamics simulations.","The lubricant is modelled as a polymeric liquid consisting of short chains that are chemically identical to the brush polymers.","We investigate the behavior of the brush in terms of the grafting density and the amount of lubricant present.","Regarding the wetting behavior, we study a sessile droplet on top of the brush.","The droplet consists of non-bonded particles that form a dense phase.","Our model and choice of parameters result in the formation of a wetting ridge and in the cloaking of the droplet by the lubricant, i.e. the lubricant chains creep up onto the droplet and eventually cover its surface completely.","Cloaking is a phenomenon that is observed experimentally and is of integral importance to the dynamics of sliding droplets.","We quantify the cloaking in terms of its thickness, which increases with the amount of lubricant present.","The analysis reveals a well-defined transition point where the cloaking sets in.","We propose a thermodynamic theory to explain this behavior.","In addition we investigate the dependence of the contact angles on the size of the droplet and the possible effect of line tension.","We quantify the variation of the contact angle with the curvature of the contact line on a lubricant free brush and find a negative value for the line tension.","Finally we investigate the effect of cloaking/lubrication on the contact angles and the wetting ridge.","We find that lubrication and cloaking reduce the contact angles by a couple of degrees.","The effect on the wetting ridge is a reduction in the extension of the brush chains near the three phase contact line, an effect that was also observed in experiments of droplets on crosslinked gels."],"url":"http://arxiv.org/abs/2403.11398v1","category":"cond-mat.soft"}
{"created":"2024-03-18 00:19:52","title":"On the Benefits of GPU Sample-Based Stochastic Predictive Controllers for Legged Locomotion","abstract":"Quadrupedal robots excel in mobility, navigating complex terrains with agility. However, their complex control systems present challenges that are still far from being fully addressed. In this paper, we introduce the use of Sample-Based Stochastic control strategies for quadrupedal robots, as an alternative to traditional optimal control laws. We show that Sample-Based Stochastic methods, supported by GPU acceleration, can be effectively applied to real quadruped robots. In particular, in this work, we focus on achieving gait frequency adaptation, a notable challenge in quadrupedal locomotion for gradient-based methods. To validate the effectiveness of Sample-Based Stochastic controllers we test two distinct approaches for quadrupedal robots and compare them against a conventional gradient-based Model Predictive Control system. Our findings, validated both in simulation and on a real 21Kg Aliengo quadruped, demonstrate that our method is on par with a traditional Model Predictive Control strategy when the robot is subject to zero or moderate disturbance, while it surpasses gradient-based methods in handling sustained external disturbances, thanks to the straightforward gait adaptation strategy that is possible to achieve within their formulation.","sentences":["Quadrupedal robots excel in mobility, navigating complex terrains with agility.","However, their complex control systems present challenges that are still far from being fully addressed.","In this paper, we introduce the use of Sample-Based Stochastic control strategies for quadrupedal robots, as an alternative to traditional optimal control laws.","We show that Sample-Based Stochastic methods, supported by GPU acceleration, can be effectively applied to real quadruped robots.","In particular, in this work, we focus on achieving gait frequency adaptation, a notable challenge in quadrupedal locomotion for gradient-based methods.","To validate the effectiveness of Sample-Based Stochastic controllers we test two distinct approaches for quadrupedal robots and compare them against a conventional gradient-based Model Predictive Control system.","Our findings, validated both in simulation and on a real 21Kg Aliengo quadruped, demonstrate that our method is on par with a traditional Model Predictive Control strategy when the robot is subject to zero or moderate disturbance, while it surpasses gradient-based methods in handling sustained external disturbances, thanks to the straightforward gait adaptation strategy that is possible to achieve within their formulation."],"url":"http://arxiv.org/abs/2403.11383v1","category":"cs.RO"}
{"created":"2024-03-18 00:13:43","title":"Can LLM-Augmented autonomous agents cooperate?, An evaluation of their cooperative capabilities through Melting Pot","abstract":"As the field of AI continues to evolve, a significant dimension of this progression is the development of Large Language Models and their potential to enhance multi-agent artificial intelligence systems. This paper explores the cooperative capabilities of Large Language Model-augmented Autonomous Agents (LAAs) using the well-known Meltin Pot environments along with reference models such as GPT4 and GPT3.5. Preliminary results suggest that while these agents demonstrate a propensity for cooperation, they still struggle with effective collaboration in given environments, emphasizing the need for more robust architectures. The study's contributions include an abstraction layer to adapt Melting Pot game scenarios for LLMs, the implementation of a reusable architecture for LLM-mediated agent development - which includes short and long-term memories and different cognitive modules, and the evaluation of cooperation capabilities using a set of metrics tied to the Melting Pot's \"Commons Harvest\" game. The paper closes, by discussing the limitations of the current architectural framework and the potential of a new set of modules that fosters better cooperation among LAAs.","sentences":["As the field of AI continues to evolve, a significant dimension of this progression is the development of Large Language Models and their potential to enhance multi-agent artificial intelligence systems.","This paper explores the cooperative capabilities of Large Language Model-augmented Autonomous Agents (LAAs) using the well-known Meltin Pot environments along with reference models such as GPT4 and GPT3.5.","Preliminary results suggest that while these agents demonstrate a propensity for cooperation, they still struggle with effective collaboration in given environments, emphasizing the need for more robust architectures.","The study's contributions include an abstraction layer to adapt Melting Pot game scenarios for LLMs, the implementation of a reusable architecture for LLM-mediated agent development - which includes short and long-term memories and different cognitive modules, and the evaluation of cooperation capabilities using a set of metrics tied to the Melting Pot's \"Commons Harvest\" game.","The paper closes, by discussing the limitations of the current architectural framework and the potential of a new set of modules that fosters better cooperation among LAAs."],"url":"http://arxiv.org/abs/2403.11381v1","category":"cs.AI"}
{"created":"2024-03-18 00:02:48","title":"Path-GPTOmic: A Balanced Multi-modal Learning Framework for Survival Outcome Prediction","abstract":"For predicting cancer survival outcomes, standard approaches in clinical research are often based on two main modalities: pathology images for observing cell morphology features, and genomic (e.g., bulk RNA-seq) for quantifying gene expressions. However, existing pathology-genomic multi-modal algorithms face significant challenges: (1) Valuable biological insights regarding genes and gene-gene interactions are frequently overlooked; (2) one modality often dominates the optimization process, causing inadequate training for the other modality. In this paper, we introduce a new multi-modal ``Path-GPTOmic\" framework for cancer survival outcome prediction. First, to extract valuable biological insights, we regulate the embedding space of a foundation model, scGPT, initially trained on single-cell RNA-seq data, making it adaptable for bulk RNA-seq data. Second, to address the imbalance-between-modalities problem, we propose a gradient modulation mechanism tailored to the Cox partial likelihood loss for survival prediction. The contributions of the modalities are dynamically monitored and adjusted during the training process, encouraging that both modalities are sufficiently trained. Evaluated on two TCGA(The Cancer Genome Atlas) datasets, our model achieves substantially improved survival prediction accuracy.","sentences":["For predicting cancer survival outcomes, standard approaches in clinical research are often based on two main modalities: pathology images for observing cell morphology features, and genomic (e.g., bulk RNA-seq) for quantifying gene expressions.","However, existing pathology-genomic multi-modal algorithms face significant challenges: (1) Valuable biological insights regarding genes and gene-gene interactions are frequently overlooked; (2) one modality often dominates the optimization process, causing inadequate training for the other modality.","In this paper, we introduce a new multi-modal ``Path-GPTOmic\" framework for cancer survival outcome prediction.","First, to extract valuable biological insights, we regulate the embedding space of a foundation model, scGPT, initially trained on single-cell RNA-seq data, making it adaptable for bulk RNA-seq data.","Second, to address the imbalance-between-modalities problem, we propose a gradient modulation mechanism tailored to the Cox partial likelihood loss for survival prediction.","The contributions of the modalities are dynamically monitored and adjusted during the training process, encouraging that both modalities are sufficiently trained.","Evaluated on two TCGA(The Cancer Genome Atlas) datasets, our model achieves substantially improved survival prediction accuracy."],"url":"http://arxiv.org/abs/2403.11375v1","category":"cs.CV"}
{"created":"2024-03-17 23:44:20","title":"Reconstruct before Query: Continual Missing Modality Learning with Decomposed Prompt Collaboration","abstract":"Pre-trained large multi-modal models (LMMs) exploit fine-tuning to adapt diverse user applications. Nevertheless, fine-tuning may face challenges due to deactivated sensors (e.g., cameras turned off for privacy or technical issues), yielding modality-incomplete data and leading to inconsistency in training data and the data for inference. Additionally, continuous training leads to catastrophic forgetting, diluting the knowledge in pre-trained LMMs. To overcome these challenges, we introduce a novel task, Continual Missing Modality Learning (CMML), to investigate how models can generalize when data of certain modalities is missing during continual fine-tuning. Our preliminary benchmarks reveal that existing methods suffer from a significant performance drop in CMML, even with the aid of advanced continual learning techniques. Therefore, we devise a framework termed Reconstruct before Query (RebQ). It decomposes prompts into modality-specific ones and breaks them into components stored in pools accessible via a key-query mechanism, which facilitates ParameterEfficient Fine-Tuning and enhances knowledge transferability for subsequent tasks. Meanwhile, our RebQ leverages extensive multi-modal knowledge from pre-trained LMMs to reconstruct the data of missing modality. Comprehensive experiments demonstrate that RebQ effectively reconstructs the missing modality information and retains pre-trained knowledge. Specifically, compared with the baseline, RebQ improves average precision from 20.00 to 50.92 and decreases average forgetting from 75.95 to 8.56. Code and datasets are available on https://github.com/Tree-Shu-Zhao/RebQ.pytorch","sentences":["Pre-trained large multi-modal models (LMMs) exploit fine-tuning to adapt diverse user applications.","Nevertheless, fine-tuning may face challenges due to deactivated sensors (e.g., cameras turned off for privacy or technical issues), yielding modality-incomplete data and leading to inconsistency in training data and the data for inference.","Additionally, continuous training leads to catastrophic forgetting, diluting the knowledge in pre-trained LMMs.","To overcome these challenges, we introduce a novel task, Continual Missing Modality Learning (CMML), to investigate how models can generalize when data of certain modalities is missing during continual fine-tuning.","Our preliminary benchmarks reveal that existing methods suffer from a significant performance drop in CMML, even with the aid of advanced continual learning techniques.","Therefore, we devise a framework termed Reconstruct before Query (RebQ).","It decomposes prompts into modality-specific ones and breaks them into components stored in pools accessible via a key-query mechanism, which facilitates ParameterEfficient Fine-Tuning and enhances knowledge transferability for subsequent tasks.","Meanwhile, our RebQ leverages extensive multi-modal knowledge from pre-trained LMMs to reconstruct the data of missing modality.","Comprehensive experiments demonstrate that RebQ effectively reconstructs the missing modality information and retains pre-trained knowledge.","Specifically, compared with the baseline, RebQ improves average precision from 20.00 to 50.92 and decreases average forgetting from 75.95 to 8.56.","Code and datasets are available on https://github.com/Tree-Shu-Zhao/RebQ.pytorch"],"url":"http://arxiv.org/abs/2403.11373v1","category":"cs.CV"}
{"created":"2024-03-17 23:38:18","title":"Approximations of the quasi-local Bartnik mass in general relativity","abstract":"In this study, we employ eth-operators and spin-weighted spherical harmonics to express the ADM mass of a static space-time based on the mean values of its components over a a radius-$r$ sphere. While initially derived for standard spherical coordinates, we showcase its adaptability by demonstrating its usefulness in expressing a quasilocal mass; specifically, the Bartnik mass, of an almost round 2D-hypersurface in terms of some specific boundary conditions. Additionally, we utilize this formulation to propose a deep learning methodology for numerically constructing static metrics that incorporate 2D-hypersurfaces with specified Bartnik mass.","sentences":["In this study, we employ eth-operators and spin-weighted spherical harmonics to express the ADM mass of a static space-time based on the mean values of its components over a a radius-$r$ sphere.","While initially derived for standard spherical coordinates, we showcase its adaptability by demonstrating its usefulness in expressing a quasilocal mass; specifically, the Bartnik mass, of an almost round 2D-hypersurface in terms of some specific boundary conditions.","Additionally, we utilize this formulation to propose a deep learning methodology for numerically constructing static metrics that incorporate 2D-hypersurfaces with specified Bartnik mass."],"url":"http://arxiv.org/abs/2403.11372v1","category":"gr-qc"}
{"created":"2024-03-17 23:29:41","title":"V2X-DGW: Domain Generalization for Multi-agent Perception under Adverse Weather Conditions","abstract":"Current LiDAR-based Vehicle-to-Everything (V2X) multi-agent perception systems have shown the significant success on 3D object detection. While these models perform well in the trained clean weather, they struggle in unseen adverse weather conditions with the real-world domain gap. In this paper, we propose a domain generalization approach, named V2X-DGW, for LiDAR-based 3D object detection on multi-agent perception system under adverse weather conditions. Not only in the clean weather does our research aim to ensure favorable multi-agent performance, but also in the unseen adverse weather conditions by learning only on the clean weather data. To advance research in this area, we have simulated the impact of three prevalent adverse weather conditions on two widely-used multi-agent datasets, resulting in the creation of two novel benchmark datasets: OPV2V-w and V2XSet-w.   To this end, we first introduce the Adaptive Weather Augmentation (AWA) to mimic the unseen adverse weather conditions, and then propose two alignments for generalizable representation learning: Trust-region Weather-invariant Alignment (TWA) and Agent-aware Contrastive Alignment (ACA). Extensive experimental results demonstrate that our V2X-DGW achieved improvements in the unseen adverse weather conditions.","sentences":["Current LiDAR-based Vehicle-to-Everything (V2X) multi-agent perception systems have shown the significant success on 3D object detection.","While these models perform well in the trained clean weather, they struggle in unseen adverse weather conditions with the real-world domain gap.","In this paper, we propose a domain generalization approach, named V2X-DGW, for LiDAR-based 3D object detection on multi-agent perception system under adverse weather conditions.","Not only in the clean weather does our research aim to ensure favorable multi-agent performance, but also in the unseen adverse weather conditions by learning only on the clean weather data.","To advance research in this area, we have simulated the impact of three prevalent adverse weather conditions on two widely-used multi-agent datasets, resulting in the creation of two novel benchmark datasets: OPV2V-w and V2XSet-w.   ","To this end, we first introduce the Adaptive Weather Augmentation (AWA) to mimic the unseen adverse weather conditions, and then propose two alignments for generalizable representation learning: Trust-region Weather-invariant Alignment (TWA) and Agent-aware Contrastive Alignment (ACA).","Extensive experimental results demonstrate that our V2X-DGW achieved improvements in the unseen adverse weather conditions."],"url":"http://arxiv.org/abs/2403.11371v1","category":"cs.CV"}
{"created":"2024-03-17 23:06:12","title":"3DGS-ReLoc: 3D Gaussian Splatting for Map Representation and Visual ReLocalization","abstract":"This paper presents a novel system designed for 3D mapping and visual relocalization using 3D Gaussian Splatting. Our proposed method uses LiDAR and camera data to create accurate and visually plausible representations of the environment. By leveraging LiDAR data to initiate the training of the 3D Gaussian Splatting map, our system constructs maps that are both detailed and geometrically accurate. To mitigate excessive GPU memory usage and facilitate rapid spatial queries, we employ a combination of a 2D voxel map and a KD-tree. This preparation makes our method well-suited for visual localization tasks, enabling efficient identification of correspondences between the query image and the rendered image from the Gaussian Splatting map via normalized cross-correlation (NCC). Additionally, we refine the camera pose of the query image using feature-based matching and the Perspective-n-Point (PnP) technique. The effectiveness, adaptability, and precision of our system are demonstrated through extensive evaluation on the KITTI360 dataset.","sentences":["This paper presents a novel system designed for 3D mapping and visual relocalization using 3D Gaussian Splatting.","Our proposed method uses LiDAR and camera data to create accurate and visually plausible representations of the environment.","By leveraging LiDAR data to initiate the training of the 3D Gaussian Splatting map, our system constructs maps that are both detailed and geometrically accurate.","To mitigate excessive GPU memory usage and facilitate rapid spatial queries, we employ a combination of a 2D voxel map and a KD-tree.","This preparation makes our method well-suited for visual localization tasks, enabling efficient identification of correspondences between the query image and the rendered image from the Gaussian Splatting map via normalized cross-correlation (NCC).","Additionally, we refine the camera pose of the query image using feature-based matching and the Perspective-n-Point (PnP) technique.","The effectiveness, adaptability, and precision of our system are demonstrated through extensive evaluation on the KITTI360 dataset."],"url":"http://arxiv.org/abs/2403.11367v1","category":"cs.CV"}
{"created":"2024-03-17 20:44:38","title":"Ensembling and Test Augmentation for Covid-19 Detection and Covid-19 Domain Adaptation from 3D CT-Scans","abstract":"Since the emergence of Covid-19 in late 2019, medical image analysis using artificial intelligence (AI) has emerged as a crucial research area, particularly with the utility of CT-scan imaging for disease diagnosis. This paper contributes to the 4th COV19D competition, focusing on Covid-19 Detection and Covid-19 Domain Adaptation Challenges. Our approach centers on lung segmentation and Covid-19 infection segmentation employing the recent CNN-based segmentation architecture PDAtt-Unet, which simultaneously segments lung regions and infections. Departing from traditional methods, we concatenate the input slice (grayscale) with segmented lung and infection, generating three input channels akin to color channels. Additionally, we employ three 3D CNN backbones Customized Hybrid-DeCoVNet, along with pretrained 3D-Resnet-18 and 3D-Resnet-50 models to train Covid-19 recognition for both challenges. Furthermore, we explore ensemble approaches and testing augmentation to enhance performance. Comparison with baseline results underscores the substantial efficiency of our approach, with a significant margin in terms of F1-score (14 %). This study advances the field by presenting a comprehensive methodology for accurate Covid-19 detection and adaptation, leveraging cutting-edge AI techniques in medical image analysis.","sentences":["Since the emergence of Covid-19 in late 2019, medical image analysis using artificial intelligence (AI) has emerged as a crucial research area, particularly with the utility of CT-scan imaging for disease diagnosis.","This paper contributes to the 4th COV19D competition, focusing on Covid-19 Detection and Covid-19 Domain Adaptation Challenges.","Our approach centers on lung segmentation and Covid-19 infection segmentation employing the recent CNN-based segmentation architecture PDAtt-Unet, which simultaneously segments lung regions and infections.","Departing from traditional methods, we concatenate the input slice (grayscale) with segmented lung and infection, generating three input channels akin to color channels.","Additionally, we employ three 3D CNN backbones Customized Hybrid-DeCoVNet, along with pretrained 3D-Resnet-18 and 3D-Resnet-50 models to train Covid-19 recognition for both challenges.","Furthermore, we explore ensemble approaches and testing augmentation to enhance performance.","Comparison with baseline results underscores the substantial efficiency of our approach, with a significant margin in terms of F1-score (14 %).","This study advances the field by presenting a comprehensive methodology for accurate Covid-19 detection and adaptation, leveraging cutting-edge AI techniques in medical image analysis."],"url":"http://arxiv.org/abs/2403.11338v1","category":"eess.IV"}
{"created":"2024-03-17 20:23:06","title":"Potential of Domain Adaptation in Machine Learning in Ecology and Hydrology to Improve Model Extrapolability","abstract":"Due to the heterogeneity of the global distribution of ecological and hydrological ground-truth observations, machine learning models can have limited adaptability when applied to unknown locations, which is referred to as weak extrapolability. Domain adaptation techniques have been widely used in machine learning domains such as image classification, which can improve the model generalization ability by adjusting the difference or inconsistency of the domain distribution between the training and test sets. However, this approach has rarely been used explicitly in machine learning models in ecology and hydrology at the global scale, although these models have often been questioned due to geographic extrapolability issues. This paper briefly describes the shortcomings of current machine learning models of ecology and hydrology in terms of the global representativeness of the distribution of observations and the resulting limitations of the lack of extrapolability and suggests that future related modelling efforts should consider the use of domain adaptation techniques to improve extrapolability.","sentences":["Due to the heterogeneity of the global distribution of ecological and hydrological ground-truth observations, machine learning models can have limited adaptability when applied to unknown locations, which is referred to as weak extrapolability.","Domain adaptation techniques have been widely used in machine learning domains such as image classification, which can improve the model generalization ability by adjusting the difference or inconsistency of the domain distribution between the training and test sets.","However, this approach has rarely been used explicitly in machine learning models in ecology and hydrology at the global scale, although these models have often been questioned due to geographic extrapolability issues.","This paper briefly describes the shortcomings of current machine learning models of ecology and hydrology in terms of the global representativeness of the distribution of observations and the resulting limitations of the lack of extrapolability and suggests that future related modelling efforts should consider the use of domain adaptation techniques to improve extrapolability."],"url":"http://arxiv.org/abs/2403.11331v1","category":"physics.geo-ph"}
{"created":"2024-03-17 19:58:35","title":"Diffusion and Multi-Domain Adaptation Methods for Eosinophil Segmentation","abstract":"Eosinophilic Esophagitis (EoE) represents a challenging condition for medical providers today. The cause is currently unknown, the impact on a patient's daily life is significant, and it is increasing in prevalence. Traditional approaches for medical image diagnosis such as standard deep learning algorithms are limited by the relatively small amount of data and difficulty in generalization. As a response, two methods have arisen that seem to perform well: Diffusion and Multi-Domain methods with current research efforts favoring diffusion methods. For the EoE dataset, we discovered that a Multi-Domain Adversarial Network outperformed a Diffusion based method with a FID of 42.56 compared to 50.65. Future work with diffusion methods should include a comparison with Multi-Domain adaptation methods to ensure that the best performance is achieved.","sentences":["Eosinophilic Esophagitis (EoE) represents a challenging condition for medical providers today.","The cause is currently unknown, the impact on a patient's daily life is significant, and it is increasing in prevalence.","Traditional approaches for medical image diagnosis such as standard deep learning algorithms are limited by the relatively small amount of data and difficulty in generalization.","As a response, two methods have arisen that seem to perform well: Diffusion and Multi-Domain methods with current research efforts favoring diffusion methods.","For the EoE dataset, we discovered that a Multi-Domain Adversarial Network outperformed a Diffusion based method with a FID of 42.56 compared to 50.65.","Future work with diffusion methods should include a comparison with Multi-Domain adaptation methods to ensure that the best performance is achieved."],"url":"http://arxiv.org/abs/2403.11323v1","category":"eess.IV"}
{"created":"2024-03-17 19:54:16","title":"StateFlow: Enhancing LLM Task-Solving through State-Driven Workflows","abstract":"It is a notable trend to use Large Language Models (LLMs) to tackle complex tasks, e.g., tasks that require a sequence of actions and dynamic interaction with tools and environments. In this paper, we propose StateFlow, a novel LLM-based task-solving paradigm that conceptualizes complex task-solving processes backed by LLMs as state machines. With proper construction of states and definition of state transitions, StateFlow grounds the progress of task-solving, ensuring clear tracking and management of LLMs' responses throughout the task-solving process. Within each state, StateFlow allows execution of a series of actions, involving not only the generation of LLM's responses guided by a specific prompt, but also the utilization of external tools as needed. State transitions are controlled by specific rules or decisions made by the LLM, allowing for a dynamic and adaptive progression through the task's pre-defined StateFlow model. Evaluations on the InterCode SQL and Bash benchmarks show that StateFlow significantly enhances LLMs' efficiency.","sentences":["It is a notable trend to use Large Language Models (LLMs) to tackle complex tasks, e.g., tasks that require a sequence of actions and dynamic interaction with tools and environments.","In this paper, we propose StateFlow, a novel LLM-based task-solving paradigm that conceptualizes complex task-solving processes backed by LLMs as state machines.","With proper construction of states and definition of state transitions, StateFlow grounds the progress of task-solving, ensuring clear tracking and management of LLMs' responses throughout the task-solving process.","Within each state, StateFlow allows execution of a series of actions, involving not only the generation of LLM's responses guided by a specific prompt, but also the utilization of external tools as needed.","State transitions are controlled by specific rules or decisions made by the LLM, allowing for a dynamic and adaptive progression through the task's pre-defined StateFlow model.","Evaluations on the InterCode SQL and Bash benchmarks show that StateFlow significantly enhances LLMs' efficiency."],"url":"http://arxiv.org/abs/2403.11322v1","category":"cs.CL"}
{"created":"2024-03-17 17:41:01","title":"Pattern-Based Peephole Optimizations with Java JIT Tests","abstract":"We present JOG, a framework that facilitates developing Java JIT peephole optimizations alongside JIT tests. JOG enables developers to write a pattern, in Java itself, that specifies desired code transformations by writing code before and after the optimization, as well as any necessary preconditions. Such patterns can be written in the same way that tests of the optimization are already written in OpenJDK. JOG translates each pattern into C/C++ code that can be integrated as a JIT optimization pass. JOG also generates Java tests for optimizations from patterns. Furthermore, JOG can automatically detect possible shadow relation between a pair of optimizations where the effect of the shadowed optimization is overridden by another. Our evaluation shows that JOG makes it easier to write readable JIT optimizations alongside tests without decreasing the effectiveness of JIT optimizations. We wrote 162 patterns, including 68 existing optimizations in OpenJDK, 92 new optimizations adapted from LLVM, and two new optimizations that we proposed. We opened eight pull requests (PRs) for OpenJDK, including six for new optimizations, one on removing shadowed optimizations, and one for newly generated JIT tests; seven PRs have already been integrated into the master branch of OpenJDK.","sentences":["We present JOG, a framework that facilitates developing Java JIT peephole optimizations alongside JIT tests.","JOG enables developers to write a pattern, in Java itself, that specifies desired code transformations by writing code before and after the optimization, as well as any necessary preconditions.","Such patterns can be written in the same way that tests of the optimization are already written in OpenJDK.","JOG translates each pattern into C/C++ code that can be integrated as a JIT optimization pass.","JOG also generates Java tests for optimizations from patterns.","Furthermore, JOG can automatically detect possible shadow relation between a pair of optimizations where the effect of the shadowed optimization is overridden by another.","Our evaluation shows that JOG makes it easier to write readable JIT optimizations alongside tests without decreasing the effectiveness of JIT optimizations.","We wrote 162 patterns, including 68 existing optimizations in OpenJDK, 92 new optimizations adapted from LLVM, and two new optimizations that we proposed.","We opened eight pull requests (PRs) for OpenJDK, including six for new optimizations, one on removing shadowed optimizations, and one for newly generated JIT tests; seven PRs have already been integrated into the master branch of OpenJDK."],"url":"http://arxiv.org/abs/2403.11283v1","category":"cs.SE"}
{"created":"2024-03-17 16:25:25","title":"Stylized Face Sketch Extraction via Generative Prior with Limited Data","abstract":"Facial sketches are both a concise way of showing the identity of a person and a means to express artistic intention. While a few techniques have recently emerged that allow sketches to be extracted in different styles, they typically rely on a large amount of data that is difficult to obtain. Here, we propose StyleSketch, a method for extracting high-resolution stylized sketches from a face image. Using the rich semantics of the deep features from a pretrained StyleGAN, we are able to train a sketch generator with 16 pairs of face and the corresponding sketch images. The sketch generator utilizes part-based losses with two-stage learning for fast convergence during training for high-quality sketch extraction. Through a set of comparisons, we show that StyleSketch outperforms existing state-of-the-art sketch extraction methods and few-shot image adaptation methods for the task of extracting high-resolution abstract face sketches. We further demonstrate the versatility of StyleSketch by extending its use to other domains and explore the possibility of semantic editing. The project page can be found in https://kwanyun.github.io/stylesketch_project.","sentences":["Facial sketches are both a concise way of showing the identity of a person and a means to express artistic intention.","While a few techniques have recently emerged that allow sketches to be extracted in different styles, they typically rely on a large amount of data that is difficult to obtain.","Here, we propose StyleSketch, a method for extracting high-resolution stylized sketches from a face image.","Using the rich semantics of the deep features from a pretrained StyleGAN, we are able to train a sketch generator with 16 pairs of face and the corresponding sketch images.","The sketch generator utilizes part-based losses with two-stage learning for fast convergence during training for high-quality sketch extraction.","Through a set of comparisons, we show that StyleSketch outperforms existing state-of-the-art sketch extraction methods and few-shot image adaptation methods for the task of extracting high-resolution abstract face sketches.","We further demonstrate the versatility of StyleSketch by extending its use to other domains and explore the possibility of semantic editing.","The project page can be found in https://kwanyun.github.io/stylesketch_project."],"url":"http://arxiv.org/abs/2403.11263v1","category":"cs.CV"}
{"created":"2024-03-17 16:24:07","title":"A Lie Group Approach to Riemannian Batch Normalization","abstract":"Manifold-valued measurements exist in numerous applications within computer vision and machine learning. Recent studies have extended Deep Neural Networks (DNNs) to manifolds, and concomitantly, normalization techniques have also been adapted to several manifolds, referred to as Riemannian normalization. Nonetheless, most of the existing Riemannian normalization methods have been derived in an ad hoc manner and only apply to specific manifolds. This paper establishes a unified framework for Riemannian Batch Normalization (RBN) techniques on Lie groups. Our framework offers the theoretical guarantee of controlling both the Riemannian mean and variance. Empirically, we focus on Symmetric Positive Definite (SPD) manifolds, which possess three distinct types of Lie group structures. Using the deformation concept, we generalize the existing Lie groups on SPD manifolds into three families of parameterized Lie groups. Specific normalization layers induced by these Lie groups are then proposed for SPD neural networks. We demonstrate the effectiveness of our approach through three sets of experiments: radar recognition, human action recognition, and electroencephalography (EEG) classification. The code is available at https://github.com/GitZH-Chen/LieBN.git.","sentences":["Manifold-valued measurements exist in numerous applications within computer vision and machine learning.","Recent studies have extended Deep Neural Networks (DNNs) to manifolds, and concomitantly, normalization techniques have also been adapted to several manifolds, referred to as Riemannian normalization.","Nonetheless, most of the existing Riemannian normalization methods have been derived in an ad hoc manner and only apply to specific manifolds.","This paper establishes a unified framework for Riemannian Batch Normalization (RBN) techniques on Lie groups.","Our framework offers the theoretical guarantee of controlling both the Riemannian mean and variance.","Empirically, we focus on Symmetric Positive Definite (SPD) manifolds, which possess three distinct types of Lie group structures.","Using the deformation concept, we generalize the existing Lie groups on SPD manifolds into three families of parameterized Lie groups.","Specific normalization layers induced by these Lie groups are then proposed for SPD neural networks.","We demonstrate the effectiveness of our approach through three sets of experiments: radar recognition, human action recognition, and electroencephalography (EEG) classification.","The code is available at https://github.com/GitZH-Chen/LieBN.git."],"url":"http://arxiv.org/abs/2403.11261v1","category":"cs.LG"}
