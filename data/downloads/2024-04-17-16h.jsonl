{"created":"2024-04-15 12:53:48","title":"Can We Break Free from Strong Data Augmentations in Self-Supervised Learning?","abstract":"Self-supervised learning (SSL) has emerged as a promising solution for addressing the challenge of limited labeled data in deep neural networks (DNNs), offering scalability potential. However, the impact of design dependencies within the SSL framework remains insufficiently investigated. In this study, we comprehensively explore SSL behavior across a spectrum of augmentations, revealing their crucial role in shaping SSL model performance and learning mechanisms. Leveraging these insights, we propose a novel learning approach that integrates prior knowledge, with the aim of curtailing the need for extensive data augmentations and thereby amplifying the efficacy of learned representations. Notably, our findings underscore that SSL models imbued with prior knowledge exhibit reduced texture bias, diminished reliance on shortcuts and augmentations, and improved robustness against both natural and adversarial corruptions. These findings not only illuminate a new direction in SSL research, but also pave the way for enhancing DNN performance while concurrently alleviating the imperative for intensive data augmentation, thereby enhancing scalability and real-world problem-solving capabilities.","sentences":["Self-supervised learning (SSL) has emerged as a promising solution for addressing the challenge of limited labeled data in deep neural networks (DNNs), offering scalability potential.","However, the impact of design dependencies within the SSL framework remains insufficiently investigated.","In this study, we comprehensively explore SSL behavior across a spectrum of augmentations, revealing their crucial role in shaping SSL model performance and learning mechanisms.","Leveraging these insights, we propose a novel learning approach that integrates prior knowledge, with the aim of curtailing the need for extensive data augmentations and thereby amplifying the efficacy of learned representations.","Notably, our findings underscore that SSL models imbued with prior knowledge exhibit reduced texture bias, diminished reliance on shortcuts and augmentations, and improved robustness against both natural and adversarial corruptions.","These findings not only illuminate a new direction in SSL research, but also pave the way for enhancing DNN performance while concurrently alleviating the imperative for intensive data augmentation, thereby enhancing scalability and real-world problem-solving capabilities."],"url":"http://arxiv.org/abs/2404.09752v1","category":"cs.CV"}
{"created":"2024-04-15 12:50:44","title":"LetsGo: Large-Scale Garage Modeling and Rendering via LiDAR-Assisted Gaussian Primitives","abstract":"Large garages are ubiquitous yet intricate scenes in our daily lives, posing challenges characterized by monotonous colors, repetitive patterns, reflective surfaces, and transparent vehicle glass. Conventional Structure from Motion (SfM) methods for camera pose estimation and 3D reconstruction fail in these environments due to poor correspondence construction. To address these challenges, this paper introduces LetsGo, a LiDAR-assisted Gaussian splatting approach for large-scale garage modeling and rendering. We develop a handheld scanner, Polar, equipped with IMU, LiDAR, and a fisheye camera, to facilitate accurate LiDAR and image data scanning. With this Polar device, we present a GarageWorld dataset consisting of five expansive garage scenes with diverse geometric structures and will release the dataset to the community for further research. We demonstrate that the collected LiDAR point cloud by the Polar device enhances a suite of 3D Gaussian splatting algorithms for garage scene modeling and rendering. We also propose a novel depth regularizer for 3D Gaussian splatting algorithm training, effectively eliminating floating artifacts in rendered images, and a lightweight Level of Detail (LOD) Gaussian renderer for real-time viewing on web-based devices. Additionally, we explore a hybrid representation that combines the advantages of traditional mesh in depicting simple geometry and colors (e.g., walls and the ground) with modern 3D Gaussian representations capturing complex details and high-frequency textures. This strategy achieves an optimal balance between memory performance and rendering quality. Experimental results on our dataset, along with ScanNet++ and KITTI-360, demonstrate the superiority of our method in rendering quality and resource efficiency.","sentences":["Large garages are ubiquitous yet intricate scenes in our daily lives, posing challenges characterized by monotonous colors, repetitive patterns, reflective surfaces, and transparent vehicle glass.","Conventional Structure from Motion (SfM) methods for camera pose estimation and 3D reconstruction fail in these environments due to poor correspondence construction.","To address these challenges, this paper introduces LetsGo, a LiDAR-assisted Gaussian splatting approach for large-scale garage modeling and rendering.","We develop a handheld scanner, Polar, equipped with IMU, LiDAR, and a fisheye camera, to facilitate accurate LiDAR and image data scanning.","With this Polar device, we present a GarageWorld dataset consisting of five expansive garage scenes with diverse geometric structures and will release the dataset to the community for further research.","We demonstrate that the collected LiDAR point cloud by the Polar device enhances a suite of 3D Gaussian splatting algorithms for garage scene modeling and rendering.","We also propose a novel depth regularizer for 3D Gaussian splatting algorithm training, effectively eliminating floating artifacts in rendered images, and a lightweight Level of Detail (LOD) Gaussian renderer for real-time viewing on web-based devices.","Additionally, we explore a hybrid representation that combines the advantages of traditional mesh in depicting simple geometry and colors (e.g., walls and the ground) with modern 3D Gaussian representations capturing complex details and high-frequency textures.","This strategy achieves an optimal balance between memory performance and rendering quality.","Experimental results on our dataset, along with ScanNet++ and KITTI-360, demonstrate the superiority of our method in rendering quality and resource efficiency."],"url":"http://arxiv.org/abs/2404.09748v1","category":"cs.CV"}
{"created":"2024-04-15 12:40:12","title":"AMPCliff: quantitative definition and benchmarking of activity cliffs in antimicrobial peptides","abstract":"Activity cliff (AC) is a phenomenon that a pair of similar molecules differ by a small structural alternation but exhibit a large difference in their biochemical activities. The AC of small molecules has been extensively investigated but limited knowledge is accumulated about the AC phenomenon in peptides with canonical amino acids. This study introduces a quantitative definition and benchmarking framework AMPCliff for the AC phenomenon in antimicrobial peptides (AMPs) composed by canonical amino acids. A comprehensive analysis of the existing AMP dataset reveals a significant prevalence of AC within AMPs. AMPCliff quantifies the activities of AMPs by the metric minimum inhibitory concentration (MIC), and defines 0.9 as the minimum threshold for the normalized BLOSUM62 similarity score between a pair of aligned peptides with at least two-fold MIC changes. This study establishes a benchmark dataset of paired AMPs in Staphylococcus aureus from the publicly available AMP dataset GRAMPA, and conducts a rigorous procedure to evaluate various AMP AC prediction models, including nine machine learning, four deep learning algorithms, four masked language models, and four generative language models. Our analysis reveals that these models are capable of detecting AMP AC events and the pre-trained protein language ESM2 model demonstrates superior performance across the evaluations. The predictive performance of AMP activity cliffs remains to be further improved, considering that ESM2 with 33 layers only achieves the Spearman correlation coefficient=0.50 for the regression task of the MIC values on the benchmark dataset. Source code and additional resources are available at https://www.healthinformaticslab.org/supp/ or https://github.com/Kewei2023/AMPCliff-generation.","sentences":["Activity cliff (AC) is a phenomenon that a pair of similar molecules differ by a small structural alternation but exhibit a large difference in their biochemical activities.","The AC of small molecules has been extensively investigated but limited knowledge is accumulated about the AC phenomenon in peptides with canonical amino acids.","This study introduces a quantitative definition and benchmarking framework AMPCliff for the AC phenomenon in antimicrobial peptides (AMPs) composed by canonical amino acids.","A comprehensive analysis of the existing AMP dataset reveals a significant prevalence of AC within AMPs.","AMPCliff quantifies the activities of AMPs by the metric minimum inhibitory concentration (MIC), and defines 0.9 as the minimum threshold for the normalized BLOSUM62 similarity score between a pair of aligned peptides with at least two-fold MIC changes.","This study establishes a benchmark dataset of paired AMPs in Staphylococcus aureus from the publicly available AMP dataset GRAMPA, and conducts a rigorous procedure to evaluate various AMP AC prediction models, including nine machine learning, four deep learning algorithms, four masked language models, and four generative language models.","Our analysis reveals that these models are capable of detecting AMP AC events and the pre-trained protein language ESM2 model demonstrates superior performance across the evaluations.","The predictive performance of AMP activity cliffs remains to be further improved, considering that ESM2 with 33 layers only achieves the Spearman correlation coefficient=0.50 for the regression task of the MIC values on the benchmark dataset.","Source code and additional resources are available at https://www.healthinformaticslab.org/supp/ or https://github.com/Kewei2023/AMPCliff-generation."],"url":"http://arxiv.org/abs/2404.09738v1","category":"q-bio.BM"}
{"created":"2024-04-15 12:25:41","title":"VFLGAN: Vertical Federated Learning-based Generative Adversarial Network for Vertically Partitioned Data Publication","abstract":"In the current artificial intelligence (AI) era, the scale and quality of the dataset play a crucial role in training a high-quality AI model. However, good data is not a free lunch and is always hard to access due to privacy regulations like the General Data Protection Regulation (GDPR). A potential solution is to release a synthetic dataset with a similar distribution to that of the private dataset. Nevertheless, in some scenarios, it has been found that the attributes needed to train an AI model belong to different parties, and they cannot share the raw data for synthetic data publication due to privacy regulations. In PETS 2023, Xue et al. proposed the first generative adversary network-based model, VertiGAN, for vertically partitioned data publication. However, after thoroughly investigating, we found that VertiGAN is less effective in preserving the correlation among the attributes of different parties. This article proposes a Vertical Federated Learning-based Generative Adversarial Network, VFLGAN, for vertically partitioned data publication to address the above issues. Our experimental results show that compared with VertiGAN, VFLGAN significantly improves the quality of synthetic data. Taking the MNIST dataset as an example, the quality of the synthetic dataset generated by VFLGAN is 3.2 times better than that generated by VertiGAN w.r.t. the Fr\\'echet Distance. We also designed a more efficient and effective Gaussian mechanism for the proposed VFLGAN to provide the synthetic dataset with a differential privacy guarantee. On the other hand, differential privacy only gives the upper bound of the worst-case privacy guarantee. This article also proposes a practical auditing scheme that applies membership inference attacks to estimate privacy leakage through the synthetic dataset.","sentences":["In the current artificial intelligence (AI) era, the scale and quality of the dataset play a crucial role in training a high-quality AI model.","However, good data is not a free lunch and is always hard to access due to privacy regulations like the General Data Protection Regulation (GDPR).","A potential solution is to release a synthetic dataset with a similar distribution to that of the private dataset.","Nevertheless, in some scenarios, it has been found that the attributes needed to train an AI model belong to different parties, and they cannot share the raw data for synthetic data publication due to privacy regulations.","In PETS 2023, Xue et al. proposed the first generative adversary network-based model, VertiGAN, for vertically partitioned data publication.","However, after thoroughly investigating, we found that VertiGAN is less effective in preserving the correlation among the attributes of different parties.","This article proposes a Vertical Federated Learning-based Generative Adversarial Network, VFLGAN, for vertically partitioned data publication to address the above issues.","Our experimental results show that compared with VertiGAN, VFLGAN significantly improves the quality of synthetic data.","Taking the MNIST dataset as an example, the quality of the synthetic dataset generated by VFLGAN is 3.2 times better than that generated by VertiGAN w.r.t.","the Fr\\'echet Distance.","We also designed a more efficient and effective Gaussian mechanism for the proposed VFLGAN to provide the synthetic dataset with a differential privacy guarantee.","On the other hand, differential privacy only gives the upper bound of the worst-case privacy guarantee.","This article also proposes a practical auditing scheme that applies membership inference attacks to estimate privacy leakage through the synthetic dataset."],"url":"http://arxiv.org/abs/2404.09722v1","category":"cs.LG"}
{"created":"2024-04-15 12:20:09","title":"Unveiling Imitation Learning: Exploring the Impact of Data Falsity to Large Language Model","abstract":"Many recent studies endeavor to improve open-source language models through imitation learning, and re-training on the synthetic instruction data from state-of-the-art proprietary models like ChatGPT and GPT-4. However, the innate nature of synthetic data inherently contains noisy data, giving rise to a substantial presence of low-quality data replete with erroneous responses, and flawed reasoning. Although we intuitively grasp the potential harm of noisy data, we lack a quantitative understanding of its impact. To this end, this paper explores the correlation between the degree of noise and its impact on language models through instruction tuning. We first introduce the Falsity-Controllable (FACO) dataset, which comprises pairs of true answers with corresponding reasoning, as well as false pairs to manually control the falsity ratio of the dataset.Through our extensive experiments, we found multiple intriguing findings of the correlation between the factuality of the dataset and instruction tuning: Specifically, we verified falsity of the instruction is highly relevant to various benchmark scores. Moreover, when LLMs are trained with false instructions, they learn to lie and generate fake unfaithful answers, even though they know the correct answer for the user request. Additionally, we noted that once the language model is trained with a dataset contaminated by noise, restoring its original performance is possible, but it failed to reach full performance.","sentences":["Many recent studies endeavor to improve open-source language models through imitation learning, and re-training on the synthetic instruction data from state-of-the-art proprietary models like ChatGPT and GPT-4.","However, the innate nature of synthetic data inherently contains noisy data, giving rise to a substantial presence of low-quality data replete with erroneous responses, and flawed reasoning.","Although we intuitively grasp the potential harm of noisy data, we lack a quantitative understanding of its impact.","To this end, this paper explores the correlation between the degree of noise and its impact on language models through instruction tuning.","We first introduce the Falsity-Controllable (FACO) dataset, which comprises pairs of true answers with corresponding reasoning, as well as false pairs to manually control the falsity ratio of the dataset.","Through our extensive experiments, we found multiple intriguing findings of the correlation between the factuality of the dataset and instruction tuning: Specifically, we verified falsity of the instruction is highly relevant to various benchmark scores.","Moreover, when LLMs are trained with false instructions, they learn to lie and generate fake unfaithful answers, even though they know the correct answer for the user request.","Additionally, we noted that once the language model is trained with a dataset contaminated by noise, restoring its original performance is possible, but it failed to reach full performance."],"url":"http://arxiv.org/abs/2404.09717v1","category":"cs.CL"}
{"created":"2024-04-15 12:18:09","title":"Higher Replay Ratio Empowers Sample-Efficient Multi-Agent Reinforcement Learning","abstract":"One of the notorious issues for Reinforcement Learning (RL) is poor sample efficiency. Compared to single agent RL, the sample efficiency for Multi-Agent Reinforcement Learning (MARL) is more challenging because of its inherent partial observability, non-stationary training, and enormous strategy space. Although much effort has been devoted to developing new methods and enhancing sample efficiency, we look at the widely used episodic training mechanism. In each training step, tens of frames are collected, but only one gradient step is made. We argue that this episodic training could be a source of poor sample efficiency. To better exploit the data already collected, we propose to increase the frequency of the gradient updates per environment interaction (a.k.a. Replay Ratio or Update-To-Data ratio). To show its generality, we evaluate $3$ MARL methods on $6$ SMAC tasks. The empirical results validate that a higher replay ratio significantly improves the sample efficiency for MARL algorithms. The codes to reimplement the results presented in this paper are open-sourced at https://anonymous.4open.science/r/rr_for_MARL-0D83/.","sentences":["One of the notorious issues for Reinforcement Learning (RL) is poor sample efficiency.","Compared to single agent RL, the sample efficiency for Multi-Agent Reinforcement Learning (MARL) is more challenging because of its inherent partial observability, non-stationary training, and enormous strategy space.","Although much effort has been devoted to developing new methods and enhancing sample efficiency, we look at the widely used episodic training mechanism.","In each training step, tens of frames are collected, but only one gradient step is made.","We argue that this episodic training could be a source of poor sample efficiency.","To better exploit the data already collected, we propose to increase the frequency of the gradient updates per environment interaction (a.k.a. Replay Ratio or Update-To-Data ratio).","To show its generality, we evaluate $3$ MARL methods on $6$ SMAC tasks.","The empirical results validate that a higher replay ratio significantly improves the sample efficiency for MARL algorithms.","The codes to reimplement the results presented in this paper are open-sourced at https://anonymous.4open.science/r/rr_for_MARL-0D83/."],"url":"http://arxiv.org/abs/2404.09715v1","category":"cs.LG"}
{"created":"2024-04-15 12:06:00","title":"Adaptive Patching for High-resolution Image Segmentation with Transformers","abstract":"Attention-based models are proliferating in the space of image analytics, including segmentation. The standard method of feeding images to transformer encoders is to divide the images into patches and then feed the patches to the model as a linear sequence of tokens. For high-resolution images, e.g. microscopic pathology images, the quadratic compute and memory cost prohibits the use of an attention-based model, if we are to use smaller patch sizes that are favorable in segmentation. The solution is to either use custom complex multi-resolution models or approximate attention schemes. We take inspiration from Adapative Mesh Refinement (AMR) methods in HPC by adaptively patching the images, as a pre-processing step, based on the image details to reduce the number of patches being fed to the model, by orders of magnitude. This method has a negligible overhead, and works seamlessly with any attention-based model, i.e. it is a pre-processing step that can be adopted by any attention-based model without friction. We demonstrate superior segmentation quality over SoTA segmentation models for real-world pathology datasets while gaining a geomean speedup of $6.9\\times$ for resolutions up to $64K^2$, on up to $2,048$ GPUs.","sentences":["Attention-based models are proliferating in the space of image analytics, including segmentation.","The standard method of feeding images to transformer encoders is to divide the images into patches and then feed the patches to the model as a linear sequence of tokens.","For high-resolution images, e.g. microscopic pathology images, the quadratic compute and memory cost prohibits the use of an attention-based model, if we are to use smaller patch sizes that are favorable in segmentation.","The solution is to either use custom complex multi-resolution models or approximate attention schemes.","We take inspiration from Adapative Mesh Refinement (AMR) methods in HPC by adaptively patching the images, as a pre-processing step, based on the image details to reduce the number of patches being fed to the model, by orders of magnitude.","This method has a negligible overhead, and works seamlessly with any attention-based model, i.e. it is a pre-processing step that can be adopted by any attention-based model without friction.","We demonstrate superior segmentation quality over SoTA segmentation models for real-world pathology datasets while gaining a geomean speedup of $6.9\\times$ for resolutions up to $64K^2$, on up to $2,048$ GPUs."],"url":"http://arxiv.org/abs/2404.09707v1","category":"cs.CV"}
{"created":"2024-04-15 12:01:42","title":"AI Competitions and Benchmarks: Dataset Development","abstract":"Machine learning is now used in many applications thanks to its ability to predict, generate, or discover patterns from large quantities of data. However, the process of collecting and transforming data for practical use is intricate. Even in today's digital era, where substantial data is generated daily, it is uncommon for it to be readily usable; most often, it necessitates meticulous manual data preparation. The haste in developing new models can frequently result in various shortcomings, potentially posing risks when deployed in real-world scenarios (eg social discrimination, critical failures), leading to the failure or substantial escalation of costs in AI-based projects. This chapter provides a comprehensive overview of established methodological tools, enriched by our practical experience, in the development of datasets for machine learning. Initially, we develop the tasks involved in dataset development and offer insights into their effective management (including requirements, design, implementation, evaluation, distribution, and maintenance). Then, we provide more details about the implementation process which includes data collection, transformation, and quality evaluation. Finally, we address practical considerations regarding dataset distribution and maintenance.","sentences":["Machine learning is now used in many applications thanks to its ability to predict, generate, or discover patterns from large quantities of data.","However, the process of collecting and transforming data for practical use is intricate.","Even in today's digital era, where substantial data is generated daily, it is uncommon for it to be readily usable; most often, it necessitates meticulous manual data preparation.","The haste in developing new models can frequently result in various shortcomings, potentially posing risks when deployed in real-world scenarios (eg social discrimination, critical failures), leading to the failure or substantial escalation of costs in AI-based projects.","This chapter provides a comprehensive overview of established methodological tools, enriched by our practical experience, in the development of datasets for machine learning.","Initially, we develop the tasks involved in dataset development and offer insights into their effective management (including requirements, design, implementation, evaluation, distribution, and maintenance).","Then, we provide more details about the implementation process which includes data collection, transformation, and quality evaluation.","Finally, we address practical considerations regarding dataset distribution and maintenance."],"url":"http://arxiv.org/abs/2404.09703v1","category":"cs.LG"}
{"created":"2024-04-15 11:59:45","title":"Generative AI for Game Theory-based Mobile Networking","abstract":"With the continuous advancement of network technology, various emerging complex networking optimization problems opened up a wide range of applications utilizating of game theory. However, since game theory is a mathematical framework, game theory-based solutions often require the experience and knowledge of human experts. Recently, the remarkable advantages exhibited by generative artificial intelligence (GAI) have gained widespread attention. In this article, we propose a novel GAI-enabled game theory solution that combines the powerful reasoning and generation capabilities of GAI to the design and optimization of mobile networking. Specifically, we first outline the game theory and key technologies of GAI, and then explore the advantages of combining GAI with game theory. Then, we briefly review the advantages and limitations of existing research and demonstrate the potential application values of GAI applied to game theory in mobile networking. Subsequently, we develop a game theory framework enabled by large language models (LLMs) to realize this combination, and demonstrate the effectiveness of the proposed framework through a case study in secured UAV networks. Finally, we provide several directions for future extensions.","sentences":["With the continuous advancement of network technology, various emerging complex networking optimization problems opened up a wide range of applications utilizating of game theory.","However, since game theory is a mathematical framework, game theory-based solutions often require the experience and knowledge of human experts.","Recently, the remarkable advantages exhibited by generative artificial intelligence (GAI) have gained widespread attention.","In this article, we propose a novel GAI-enabled game theory solution that combines the powerful reasoning and generation capabilities of GAI to the design and optimization of mobile networking.","Specifically, we first outline the game theory and key technologies of GAI, and then explore the advantages of combining GAI with game theory.","Then, we briefly review the advantages and limitations of existing research and demonstrate the potential application values of GAI applied to game theory in mobile networking.","Subsequently, we develop a game theory framework enabled by large language models (LLMs) to realize this combination, and demonstrate the effectiveness of the proposed framework through a case study in secured UAV networks.","Finally, we provide several directions for future extensions."],"url":"http://arxiv.org/abs/2404.09699v1","category":"cs.GT"}
{"created":"2024-04-15 11:54:27","title":"Are Large Language Models Reliable Argument Quality Annotators?","abstract":"Evaluating the quality of arguments is a crucial aspect of any system leveraging argument mining. However, it is a challenge to obtain reliable and consistent annotations regarding argument quality, as this usually requires domain-specific expertise of the annotators. Even among experts, the assessment of argument quality is often inconsistent due to the inherent subjectivity of this task. In this paper, we study the potential of using state-of-the-art large language models (LLMs) as proxies for argument quality annotators. To assess the capability of LLMs in this regard, we analyze the agreement between model, human expert, and human novice annotators based on an established taxonomy of argument quality dimensions. Our findings highlight that LLMs can produce consistent annotations, with a moderately high agreement with human experts across most of the quality dimensions. Moreover, we show that using LLMs as additional annotators can significantly improve the agreement between annotators. These results suggest that LLMs can serve as a valuable tool for automated argument quality assessment, thus streamlining and accelerating the evaluation of large argument datasets.","sentences":["Evaluating the quality of arguments is a crucial aspect of any system leveraging argument mining.","However, it is a challenge to obtain reliable and consistent annotations regarding argument quality, as this usually requires domain-specific expertise of the annotators.","Even among experts, the assessment of argument quality is often inconsistent due to the inherent subjectivity of this task.","In this paper, we study the potential of using state-of-the-art large language models (LLMs) as proxies for argument quality annotators.","To assess the capability of LLMs in this regard, we analyze the agreement between model, human expert, and human novice annotators based on an established taxonomy of argument quality dimensions.","Our findings highlight that LLMs can produce consistent annotations, with a moderately high agreement with human experts across most of the quality dimensions.","Moreover, we show that using LLMs as additional annotators can significantly improve the agreement between annotators.","These results suggest that LLMs can serve as a valuable tool for automated argument quality assessment, thus streamlining and accelerating the evaluation of large argument datasets."],"url":"http://arxiv.org/abs/2404.09696v1","category":"cs.CL"}
{"created":"2024-04-15 11:53:22","title":"LoRAP: Transformer Sub-Layers Deserve Differentiated Structured Compression for Large Language Models","abstract":"Large language models (LLMs) show excellent performance in difficult tasks, but they often require massive memories and computational resources. How to reduce the parameter scale of LLMs has become research hotspots. In this study, we make an important observation that the multi-head self-attention (MHA) sub-layer of Transformer exhibits noticeable low-rank structure, while the feed-forward network (FFN) sub-layer does not. With this regard, we design a mixed compression model, which organically combines Low-Rank matrix approximation And structured Pruning (LoRAP). For the MHA sub-layer, we propose an input activation weighted singular value decomposition method to strengthen the low-rank characteristic. Furthermore, we discover that the weight matrices in MHA sub-layer have different low-rank degrees. Thus, a novel parameter allocation scheme according to the discrepancy of low-rank degrees is devised. For the FFN sub-layer, we propose a gradient-free structured channel pruning method. During the pruning, we get an interesting finding that the least important 1% of parameter actually play a vital role in model performance. Extensive evaluations on zero-shot perplexity and zero-shot task classification indicate that our proposal is superior to previous structured compression rivals under multiple compression ratios.","sentences":["Large language models (LLMs) show excellent performance in difficult tasks, but they often require massive memories and computational resources.","How to reduce the parameter scale of LLMs has become research hotspots.","In this study, we make an important observation that the multi-head self-attention (MHA) sub-layer of Transformer exhibits noticeable low-rank structure, while the feed-forward network (FFN) sub-layer does not.","With this regard, we design a mixed compression model, which organically combines Low-Rank matrix approximation And structured Pruning (LoRAP).","For the MHA sub-layer, we propose an input activation weighted singular value decomposition method to strengthen the low-rank characteristic.","Furthermore, we discover that the weight matrices in MHA sub-layer have different low-rank degrees.","Thus, a novel parameter allocation scheme according to the discrepancy of low-rank degrees is devised.","For the FFN sub-layer, we propose a gradient-free structured channel pruning method.","During the pruning, we get an interesting finding that the least important 1% of parameter actually play a vital role in model performance.","Extensive evaluations on zero-shot perplexity and zero-shot task classification indicate that our proposal is superior to previous structured compression rivals under multiple compression ratios."],"url":"http://arxiv.org/abs/2404.09695v1","category":"cs.LG"}
{"created":"2024-04-15 11:46:24","title":"XoFTR: Cross-modal Feature Matching Transformer","abstract":"We introduce, XoFTR, a cross-modal cross-view method for local feature matching between thermal infrared (TIR) and visible images. Unlike visible images, TIR images are less susceptible to adverse lighting and weather conditions but present difficulties in matching due to significant texture and intensity differences. Current hand-crafted and learning-based methods for visible-TIR matching fall short in handling viewpoint, scale, and texture diversities. To address this, XoFTR incorporates masked image modeling pre-training and fine-tuning with pseudo-thermal image augmentation to handle the modality differences. Additionally, we introduce a refined matching pipeline that adjusts for scale discrepancies and enhances match reliability through sub-pixel level refinement. To validate our approach, we collect a comprehensive visible-thermal dataset, and show that our method outperforms existing methods on many benchmarks.","sentences":["We introduce, XoFTR, a cross-modal cross-view method for local feature matching between thermal infrared (TIR) and visible images.","Unlike visible images, TIR images are less susceptible to adverse lighting and weather conditions but present difficulties in matching due to significant texture and intensity differences.","Current hand-crafted and learning-based methods for visible-TIR matching fall short in handling viewpoint, scale, and texture diversities.","To address this, XoFTR incorporates masked image modeling pre-training and fine-tuning with pseudo-thermal image augmentation to handle the modality differences.","Additionally, we introduce a refined matching pipeline that adjusts for scale discrepancies and enhances match reliability through sub-pixel level refinement.","To validate our approach, we collect a comprehensive visible-thermal dataset, and show that our method outperforms existing methods on many benchmarks."],"url":"http://arxiv.org/abs/2404.09692v1","category":"cs.CV"}
{"created":"2024-04-15 11:45:30","title":"Harnessing GPT-4V(ision) for Insurance: A Preliminary Exploration","abstract":"The emergence of Large Multimodal Models (LMMs) marks a significant milestone in the development of artificial intelligence. Insurance, as a vast and complex discipline, involves a wide variety of data forms in its operational processes, including text, images, and videos, thereby giving rise to diverse multimodal tasks. Despite this, there has been limited systematic exploration of multimodal tasks specific to insurance, nor a thorough investigation into how LMMs can address these challenges. In this paper, we explore GPT-4V's capabilities in the insurance domain. We categorize multimodal tasks by focusing primarily on visual aspects based on types of insurance (e.g., auto, household/commercial property, health, and agricultural insurance) and insurance stages (e.g., risk assessment, risk monitoring, and claims processing). Our experiment reveals that GPT-4V exhibits remarkable abilities in insurance-related tasks, demonstrating not only a robust understanding of multimodal content in the insurance domain but also a comprehensive knowledge of insurance scenarios. However, there are notable shortcomings: GPT-4V struggles with detailed risk rating and loss assessment, suffers from hallucination in image understanding, and shows variable support for different languages. Through this work, we aim to bridge the insurance domain with cutting-edge LMM technology, facilitate interdisciplinary exchange and development, and provide a foundation for the continued advancement and evolution of future research endeavors.","sentences":["The emergence of Large Multimodal Models (LMMs) marks a significant milestone in the development of artificial intelligence.","Insurance, as a vast and complex discipline, involves a wide variety of data forms in its operational processes, including text, images, and videos, thereby giving rise to diverse multimodal tasks.","Despite this, there has been limited systematic exploration of multimodal tasks specific to insurance, nor a thorough investigation into how LMMs can address these challenges.","In this paper, we explore GPT-4V's capabilities in the insurance domain.","We categorize multimodal tasks by focusing primarily on visual aspects based on types of insurance (e.g., auto, household/commercial property, health, and agricultural insurance) and insurance stages (e.g., risk assessment, risk monitoring, and claims processing).","Our experiment reveals that GPT-4V exhibits remarkable abilities in insurance-related tasks, demonstrating not only a robust understanding of multimodal content in the insurance domain but also a comprehensive knowledge of insurance scenarios.","However, there are notable shortcomings: GPT-4V struggles with detailed risk rating and loss assessment, suffers from hallucination in image understanding, and shows variable support for different languages.","Through this work, we aim to bridge the insurance domain with cutting-edge LMM technology, facilitate interdisciplinary exchange and development, and provide a foundation for the continued advancement and evolution of future research endeavors."],"url":"http://arxiv.org/abs/2404.09690v1","category":"cs.CV"}
{"created":"2024-04-15 11:37:47","title":"Plus Strategies are Exponentially Slower for Planted Optima of Random Height","abstract":"We compare the $(1,\\lambda)$-EA and the $(1 + \\lambda)$-EA on the recently introduced benchmark DisOM, which is the OneMax function with randomly planted local optima. Previous work showed that if all local optima have the same relative height, then the plus strategy never loses more than a factor $O(n\\log n)$ compared to the comma strategy. Here we show that even small random fluctuations in the heights of the local optima have a devastating effect for the plus strategy and lead to super-polynomial runtimes. On the other hand, due to their ability to escape local optima, comma strategies are unaffected by the height of the local optima and remain efficient. Our results hold for a broad class of possible distortions and show that the plus strategy, but not the comma strategy, is generally deceived by sparse unstructured fluctuations of a smooth landscape.","sentences":["We compare the $(1,\\lambda)$-EA and the $(1 + \\lambda)$-EA on the recently introduced benchmark DisOM, which is the OneMax function with randomly planted local optima.","Previous work showed that if all local optima have the same relative height, then the plus strategy never loses more than a factor $O(n\\log n)$ compared to the comma strategy.","Here we show that even small random fluctuations in the heights of the local optima have a devastating effect for the plus strategy and lead to super-polynomial runtimes.","On the other hand, due to their ability to escape local optima, comma strategies are unaffected by the height of the local optima and remain efficient.","Our results hold for a broad class of possible distortions and show that the plus strategy, but not the comma strategy, is generally deceived by sparse unstructured fluctuations of a smooth landscape."],"url":"http://arxiv.org/abs/2404.09687v1","category":"cs.NE"}
{"created":"2024-04-15 11:36:58","title":"Bridging the Gap: Advancements in Technology to Support Dementia Care -- A Scoping Review","abstract":"Dementia has serious consequences for the daily life of the person affected due to the decline in the their cognitive, behavioral and functional abilities. Caring for people living with dementia can be challenging and distressing. Innovative solutions are becoming essential to enrich the lives of those impacted and alleviate caregiver burdens. This scoping review, spanning literature from 2010 to July 2023 in the field of Human-Computer Interaction (HCI), offers a comprehensive look at how interactive technology contributes to dementia care. Emphasizing technology's role in addressing the unique needs of people with dementia (PwD) and their caregivers, this review encompasses assistive devices, mobile applications, sensors, and GPS tracking. Delving into challenges encountered in clinical and home-care settings, it succinctly outlines the influence of cutting-edge technologies, such as wearables, virtual reality, robots, and artificial intelligence, in supporting individuals with dementia and their caregivers. We categorize current dementia-related technologies into six groups based on their intended use and function: 1) daily life monitoring, 2) daily life support, 3) social interaction and communication, 4) well-being enhancement, 5) cognitive support, and 6) caregiver support.","sentences":["Dementia has serious consequences for the daily life of the person affected due to the decline in the their cognitive, behavioral and functional abilities.","Caring for people living with dementia can be challenging and distressing.","Innovative solutions are becoming essential to enrich the lives of those impacted and alleviate caregiver burdens.","This scoping review, spanning literature from 2010 to July 2023 in the field of Human-Computer Interaction (HCI), offers a comprehensive look at how interactive technology contributes to dementia care.","Emphasizing technology's role in addressing the unique needs of people with dementia (PwD) and their caregivers, this review encompasses assistive devices, mobile applications, sensors, and GPS tracking.","Delving into challenges encountered in clinical and home-care settings, it succinctly outlines the influence of cutting-edge technologies, such as wearables, virtual reality, robots, and artificial intelligence, in supporting individuals with dementia and their caregivers.","We categorize current dementia-related technologies into six groups based on their intended use and function: 1) daily life monitoring, 2) daily life support, 3) social interaction and communication, 4) well-being enhancement, 5) cognitive support, and 6) caregiver support."],"url":"http://arxiv.org/abs/2404.09685v1","category":"cs.HC"}
{"created":"2024-04-15 11:36:10","title":"Multi-News+: Cost-efficient Dataset Cleansing via LLM-based Data Annotation","abstract":"The quality of the dataset is crucial for ensuring optimal performance and reliability of downstream task models. However, datasets often contain noisy data inadvertently included during the construction process. Numerous attempts have been made to correct this issue through human annotators. However, hiring and managing human annotators is expensive and time-consuming. As an alternative, recent studies are exploring the use of large language models (LLMs) for data annotation.   In this study, we present a case study that extends the application of LLM-based data annotation to enhance the quality of existing datasets through a cleansing strategy. Specifically, we leverage approaches such as chain-of-thought (CoT) and majority voting to imitate human annotation and classify unrelated documents from the Multi-News dataset, which is widely used for the multi-document summarization task. Through our proposed cleansing method, we introduce an enhanced Multi-News+. By employing LLMs for data cleansing, we demonstrate an efficient and effective approach to improving dataset quality without relying on expensive human annotation efforts.","sentences":["The quality of the dataset is crucial for ensuring optimal performance and reliability of downstream task models.","However, datasets often contain noisy data inadvertently included during the construction process.","Numerous attempts have been made to correct this issue through human annotators.","However, hiring and managing human annotators is expensive and time-consuming.","As an alternative, recent studies are exploring the use of large language models (LLMs) for data annotation.   ","In this study, we present a case study that extends the application of LLM-based data annotation to enhance the quality of existing datasets through a cleansing strategy.","Specifically, we leverage approaches such as chain-of-thought (CoT) and majority voting to imitate human annotation and classify unrelated documents from the Multi-News dataset, which is widely used for the multi-document summarization task.","Through our proposed cleansing method, we introduce an enhanced Multi-News+.","By employing LLMs for data cleansing, we demonstrate an efficient and effective approach to improving dataset quality without relying on expensive human annotation efforts."],"url":"http://arxiv.org/abs/2404.09682v1","category":"cs.CL"}
{"created":"2024-04-15 10:59:13","title":"Cluster analysis of the Roma-BZCAT blazars","abstract":"Based on the collected multiwavelength data, namely in the radio (NVSS, FIRST, RATAN-600), IR (WISE), optical (Pan-STARRS), UV (GALEX), and X-ray (ROSAT, Swift-XRT) ranges, we have performed a cluster analysis for the blazars of the Roma-BZCAT catalog. Using two machine learning methods, namely a combination of PCA with k-means clustering and Kohonen's self-organizing maps, we have constructed an independent classification of the blazars (five classes) and compared the classes with the known Roma-BZCAT classification (FSRQs, BL Lacs, galaxy-dominated BL Lacs, and blazars of an uncertain type) as well as with the high synchrotron peaked blazars (HSP) from the 3HSP catalog and blazars from the TeVCat catalog. The obtained groups demonstrate concordance with the BL Lac/FSRQ classification along with a continuous character of the change in the properties. The group of HSP blazars stands out against the overall distribution. We examine the characteristics of the five groups and demonstrate distinctions in their spectral energy distribution shapes. The effectiveness of the clustering technique for objective analysis of multiparametric arrays of experimental data is demonstrated.","sentences":["Based on the collected multiwavelength data, namely in the radio (NVSS, FIRST, RATAN-600), IR (WISE), optical (Pan-STARRS), UV (GALEX), and X-ray (ROSAT, Swift-XRT) ranges, we have performed a cluster analysis for the blazars of the Roma-BZCAT catalog.","Using two machine learning methods, namely a combination of PCA with k-means clustering and Kohonen's self-organizing maps, we have constructed an independent classification of the blazars (five classes) and compared the classes with the known Roma-BZCAT classification (FSRQs, BL Lacs, galaxy-dominated BL Lacs, and blazars of an uncertain type) as well as with the high synchrotron peaked blazars (HSP) from the 3HSP catalog and blazars from the TeVCat catalog.","The obtained groups demonstrate concordance with the BL Lac/FSRQ classification along with a continuous character of the change in the properties.","The group of HSP blazars stands out against the overall distribution.","We examine the characteristics of the five groups and demonstrate distinctions in their spectral energy distribution shapes.","The effectiveness of the clustering technique for objective analysis of multiparametric arrays of experimental data is demonstrated."],"url":"http://arxiv.org/abs/2404.09667v1","category":"astro-ph.GA"}
{"created":"2024-04-15 10:45:12","title":"Sampling for Model Predictive Trajectory Planning in Autonomous Driving using Normalizing Flows","abstract":"Alongside optimization-based planners, sampling-based approaches are often used in trajectory planning for autonomous driving due to their simplicity. Model predictive path integral control is a framework that builds upon optimization principles while incorporating stochastic sampling of input trajectories. This paper investigates several sampling approaches for trajectory generation. In this context, normalizing flows originating from the field of variational inference are considered for the generation of sampling distributions, as they model transformations of simple to more complex distributions. Accordingly, learning-based normalizing flow models are trained for a more efficient exploration of the input domain for the task at hand. The developed algorithm and the proposed sampling distributions are evaluated in two simulation scenarios.","sentences":["Alongside optimization-based planners, sampling-based approaches are often used in trajectory planning for autonomous driving due to their simplicity.","Model predictive path integral control is a framework that builds upon optimization principles while incorporating stochastic sampling of input trajectories.","This paper investigates several sampling approaches for trajectory generation.","In this context, normalizing flows originating from the field of variational inference are considered for the generation of sampling distributions, as they model transformations of simple to more complex distributions.","Accordingly, learning-based normalizing flow models are trained for a more efficient exploration of the input domain for the task at hand.","The developed algorithm and the proposed sampling distributions are evaluated in two simulation scenarios."],"url":"http://arxiv.org/abs/2404.09657v1","category":"cs.RO"}
{"created":"2024-04-15 10:33:39","title":"Monitoring Second-Order Hyperproperties","abstract":"Hyperproperties express the relationship between multiple executions of a system. This is needed in many AI-related fields, such as knowledge representation and planning, to capture system properties related to knowledge, information flow, and privacy. In this paper, we study the monitoring of complex hyperproperties at runtime. Previous work in this area has either focused on the simpler problem of monitoring trace properties (which are sets of traces, while hyperproperties are sets of sets of traces) or on monitoring first-order hyperproperties, which are expressible in temporal logics with first-order quantification over traces, such as HyperLTL. We present the first monitoring algorithm for the much more expressive class of second-order hyperproperties. Second-order hyperproperties include system properties like common knowledge, which cannot be expressed in first-order logics like HyperLTL.   We introduce Hyper$^2$LTL$_f$, a temporal logic over finite traces that allows for second-order quantification over sets of traces. We study the monitoring problem in two fundamental execution models: (1) the parallel model, where a fixed number of traces is monitored in parallel, and (2) the sequential model, where an unbounded number of traces is observed sequentially, one trace after the other. For the parallel model, we show that the monitoring of the second-order hyperproperties of Hyper$^2$LTL$_f$ can be reduced to monitoring first-order hyperproperties. For the sequential model, we present a monitoring algorithm that handles second-order quantification efficiently, exploiting optimizations based on the monotonicity of subformulas, graph-based storing of executions, and fixpoint hashing. We present experimental results from a range of benchmarks, including examples from common knowledge and planning.","sentences":["Hyperproperties express the relationship between multiple executions of a system.","This is needed in many AI-related fields, such as knowledge representation and planning, to capture system properties related to knowledge, information flow, and privacy.","In this paper, we study the monitoring of complex hyperproperties at runtime.","Previous work in this area has either focused on the simpler problem of monitoring trace properties (which are sets of traces, while hyperproperties are sets of sets of traces) or on monitoring first-order hyperproperties, which are expressible in temporal logics with first-order quantification over traces, such as HyperLTL.","We present the first monitoring algorithm for the much more expressive class of second-order hyperproperties.","Second-order hyperproperties include system properties like common knowledge, which cannot be expressed in first-order logics like HyperLTL.   ","We introduce Hyper$^2$LTL$_f$, a temporal logic over finite traces that allows for second-order quantification over sets of traces.","We study the monitoring problem in two fundamental execution models: (1) the parallel model, where a fixed number of traces is monitored in parallel, and (2) the sequential model, where an unbounded number of traces is observed sequentially, one trace after the other.","For the parallel model, we show that the monitoring of the second-order hyperproperties of Hyper$^2$LTL$_f$ can be reduced to monitoring first-order hyperproperties.","For the sequential model, we present a monitoring algorithm that handles second-order quantification efficiently, exploiting optimizations based on the monotonicity of subformulas, graph-based storing of executions, and fixpoint hashing.","We present experimental results from a range of benchmarks, including examples from common knowledge and planning."],"url":"http://arxiv.org/abs/2404.09652v1","category":"cs.LO"}
{"created":"2024-04-15 10:31:41","title":"Writhe invariants of 3-regular spatial graphs","abstract":"We give a necessary condition for two diagrams of $3$-regular spatial graphs with the same underlying abstract graph $G$ to represent isotopic spatial graphs. The test works by reading off the writhes of the knot diagrams coming from a collection of cycles in $G$ in each diagram, and checking whether the writhe tuples differ by an element in the image of a certain map of $\\mathbb{Z}$-modules determined by $G$. We exemplify by using our result to distinguish, for each $n \\ge 3$, all elements in a certain infinite family of embeddings of the M\\\"obius ladder $\\mathrm{M}_n$ into $\\mathbb{R}^3$ . We also connect these writhe tuples to a classical invariant of spatial graphs due to Wu and Taniyama.","sentences":["We give a necessary condition for two diagrams of $3$-regular spatial graphs with the same underlying abstract graph $G$ to represent isotopic spatial graphs.","The test works by reading off the writhes of the knot diagrams coming from a collection of cycles in $G$ in each diagram, and checking whether the writhe tuples differ by an element in the image of a certain map of $\\mathbb{Z}$-modules determined by $G$. We exemplify by using our result to distinguish, for each $n \\ge 3$, all elements in a certain infinite family of embeddings of the M\\\"obius ladder $\\mathrm{M}_n$ into $\\mathbb{R}^3$ .","We also connect these writhe tuples to a classical invariant of spatial graphs due to Wu and Taniyama."],"url":"http://arxiv.org/abs/2404.09649v1","category":"math.GT"}
{"created":"2024-04-15 10:24:32","title":"Real-world Instance-specific Image Goal Navigation for Service Robots: Bridging the Domain Gap with Contrastive Learning","abstract":"Improving instance-specific image goal navigation (InstanceImageNav), which locates the identical object in a real-world environment from a query image, is essential for robotic systems to assist users in finding desired objects. The challenge lies in the domain gap between low-quality images observed by the moving robot, characterized by motion blur and low-resolution, and high-quality query images provided by the user. Such domain gaps could significantly reduce the task success rate but have not been the focus of previous work. To address this, we propose a novel method called Few-shot Cross-quality Instance-aware Adaptation (CrossIA), which employs contrastive learning with an instance classifier to align features between massive low- and few high-quality images. This approach effectively reduces the domain gap by bringing the latent representations of cross-quality images closer on an instance basis. Additionally, the system integrates an object image collection with a pre-trained deblurring model to enhance the observed image quality. Our method fine-tunes the SimSiam model, pre-trained on ImageNet, using CrossIA. We evaluated our method's effectiveness through an InstanceImageNav task with 20 different types of instances, where the robot identifies the same instance in a real-world environment as a high-quality query image. Our experiments showed that our method improves the task success rate by up to three times compared to the baseline, a conventional approach based on SuperGlue. These findings highlight the potential of leveraging contrastive learning and image enhancement techniques to bridge the domain gap and improve object localization in robotic applications. The project website is https://emergentsystemlabstudent.github.io/DomainBridgingNav/.","sentences":["Improving instance-specific image goal navigation (InstanceImageNav), which locates the identical object in a real-world environment from a query image, is essential for robotic systems to assist users in finding desired objects.","The challenge lies in the domain gap between low-quality images observed by the moving robot, characterized by motion blur and low-resolution, and high-quality query images provided by the user.","Such domain gaps could significantly reduce the task success rate but have not been the focus of previous work.","To address this, we propose a novel method called Few-shot Cross-quality Instance-aware Adaptation (CrossIA), which employs contrastive learning with an instance classifier to align features between massive low- and few high-quality images.","This approach effectively reduces the domain gap by bringing the latent representations of cross-quality images closer on an instance basis.","Additionally, the system integrates an object image collection with a pre-trained deblurring model to enhance the observed image quality.","Our method fine-tunes the SimSiam model, pre-trained on ImageNet, using CrossIA.","We evaluated our method's effectiveness through an InstanceImageNav task with 20 different types of instances, where the robot identifies the same instance in a real-world environment as a high-quality query image.","Our experiments showed that our method improves the task success rate by up to three times compared to the baseline, a conventional approach based on SuperGlue.","These findings highlight the potential of leveraging contrastive learning and image enhancement techniques to bridge the domain gap and improve object localization in robotic applications.","The project website is https://emergentsystemlabstudent.github.io/DomainBridgingNav/."],"url":"http://arxiv.org/abs/2404.09645v1","category":"cs.RO"}
{"created":"2024-04-15 10:13:05","title":"climber++: Pivot-Based Approximate Similarity Search over Big Data Series","abstract":"The generation and collection of big data series are becoming an integral part of many emerging applications in sciences, IoT, finance, and web applications among several others. The terabyte-scale of data series has motivated recent efforts to design fully distributed techniques for supporting operations such as approximate kNN similarity search, which is a building block operation in most analytics services on data series. Unfortunately, these techniques are heavily geared towards achieving scalability at the cost of sacrificing the results' accuracy. State-of-the-art systems report accuracy below 10% and 40%, respectively, which is not practical for many real-world applications. In this paper, we investigate the root problems in these existing techniques that limit their ability to achieve better a trade-off between scalability and accuracy. Then, we propose a framework, called CLIMBER, that encompasses a novel feature extraction mechanism, indexing scheme, and query processing algorithms for supporting approximate similarity search in big data series. For CLIMBER, we propose a new loss-resistant dual representation composed of rank-sensitive and ranking-insensitive signatures capturing data series objects. Based on this representation, we devise a distributed two-level index structure supported by an efficient data partitioning scheme. Our similarity metrics tailored for this dual representation enables meaningful comparison and distance evaluation between the rank-sensitive and ranking-insensitive signatures. Finally, we propose two efficient query processing algorithms, CLIMBER-kNN and CLIMBER-kNN-Adaptive, for answering approximate kNN similarity queries. Our experimental study on real-world and benchmark datasets demonstrates that CLIMBER, unlike existing techniques, features results' accuracy above 80% while retaining the desired scalability to terabytes of data.","sentences":["The generation and collection of big data series are becoming an integral part of many emerging applications in sciences, IoT, finance, and web applications among several others.","The terabyte-scale of data series has motivated recent efforts to design fully distributed techniques for supporting operations such as approximate kNN similarity search, which is a building block operation in most analytics services on data series.","Unfortunately, these techniques are heavily geared towards achieving scalability at the cost of sacrificing the results' accuracy.","State-of-the-art systems report accuracy below 10% and 40%, respectively, which is not practical for many real-world applications.","In this paper, we investigate the root problems in these existing techniques that limit their ability to achieve better a trade-off between scalability and accuracy.","Then, we propose a framework, called CLIMBER, that encompasses a novel feature extraction mechanism, indexing scheme, and query processing algorithms for supporting approximate similarity search in big data series.","For CLIMBER, we propose a new loss-resistant dual representation composed of rank-sensitive and ranking-insensitive signatures capturing data series objects.","Based on this representation, we devise a distributed two-level index structure supported by an efficient data partitioning scheme.","Our similarity metrics tailored for this dual representation enables meaningful comparison and distance evaluation between the rank-sensitive and ranking-insensitive signatures.","Finally, we propose two efficient query processing algorithms, CLIMBER-kNN and CLIMBER-kNN-Adaptive, for answering approximate kNN similarity queries.","Our experimental study on real-world and benchmark datasets demonstrates that CLIMBER, unlike existing techniques, features results' accuracy above 80% while retaining the desired scalability to terabytes of data."],"url":"http://arxiv.org/abs/2404.09637v1","category":"cs.DB"}
{"created":"2024-04-15 10:12:33","title":"All-in-one simulation-based inference","abstract":"Amortized Bayesian inference trains neural networks to solve stochastic inference problems using model simulations, thereby making it possible to rapidly perform Bayesian inference for any newly observed data. However, current simulation-based amortized inference methods are simulation-hungry and inflexible: They require the specification of a fixed parametric prior, simulator, and inference tasks ahead of time. Here, we present a new amortized inference method -- the Simformer -- which overcomes these limitations. By training a probabilistic diffusion model with transformer architectures, the Simformer outperforms current state-of-the-art amortized inference approaches on benchmark tasks and is substantially more flexible: It can be applied to models with function-valued parameters, it can handle inference scenarios with missing or unstructured data, and it can sample arbitrary conditionals of the joint distribution of parameters and data, including both posterior and likelihood. We showcase the performance and flexibility of the Simformer on simulators from ecology, epidemiology, and neuroscience, and demonstrate that it opens up new possibilities and application domains for amortized Bayesian inference on simulation-based models.","sentences":["Amortized Bayesian inference trains neural networks to solve stochastic inference problems using model simulations, thereby making it possible to rapidly perform Bayesian inference for any newly observed data.","However, current simulation-based amortized inference methods are simulation-hungry and inflexible: They require the specification of a fixed parametric prior, simulator, and inference tasks ahead of time.","Here, we present a new amortized inference method -- the Simformer -- which overcomes these limitations.","By training a probabilistic diffusion model with transformer architectures, the Simformer outperforms current state-of-the-art amortized inference approaches on benchmark tasks and is substantially more flexible: It can be applied to models with function-valued parameters, it can handle inference scenarios with missing or unstructured data, and it can sample arbitrary conditionals of the joint distribution of parameters and data, including both posterior and likelihood.","We showcase the performance and flexibility of the Simformer on simulators from ecology, epidemiology, and neuroscience, and demonstrate that it opens up new possibilities and application domains for amortized Bayesian inference on simulation-based models."],"url":"http://arxiv.org/abs/2404.09636v1","category":"cs.LG"}
{"created":"2024-04-15 10:01:43","title":"Action Model Learning with Guarantees","abstract":"This paper studies the problem of action model learning with full observability. Following the learning by search paradigm by Mitchell, we develop a theory for action model learning based on version spaces that interprets the task as search for hypothesis that are consistent with the learning examples. Our theoretical findings are instantiated in an online algorithm that maintains a compact representation of all solutions of the problem. Among these range of solutions, we bring attention to actions models approximating the actual transition system from below (sound models) and from above (complete models). We show how to manipulate the output of our learning algorithm to build deterministic and non-deterministic formulations of the sound and complete models and prove that, given enough examples, both formulations converge into the very same true model. Our experiments reveal their usefulness over a range of planning domains.","sentences":["This paper studies the problem of action model learning with full observability.","Following the learning by search paradigm by Mitchell, we develop a theory for action model learning based on version spaces that interprets the task as search for hypothesis that are consistent with the learning examples.","Our theoretical findings are instantiated in an online algorithm that maintains a compact representation of all solutions of the problem.","Among these range of solutions, we bring attention to actions models approximating the actual transition system from below (sound models) and from above (complete models).","We show how to manipulate the output of our learning algorithm to build deterministic and non-deterministic formulations of the sound and complete models and prove that, given enough examples, both formulations converge into the very same true model.","Our experiments reveal their usefulness over a range of planning domains."],"url":"http://arxiv.org/abs/2404.09631v1","category":"cs.AI"}
{"created":"2024-04-15 09:56:36","title":"Privacy-Preserving Intrusion Detection using Convolutional Neural Networks","abstract":"Privacy-preserving analytics is designed to protect valuable assets. A common service provision involves the input data from the client and the model on the analyst's side. The importance of the privacy preservation is fuelled by legal obligations and intellectual property concerns. We explore the use case of a model owner providing an analytic service on customer's private data. No information about the data shall be revealed to the analyst and no information about the model shall be leaked to the customer. Current methods involve costs: accuracy deterioration and computational complexity. The complexity, in turn, results in a longer processing time, increased requirement on computing resources, and involves data communication between the client and the server. In order to deploy such service architecture, we need to evaluate the optimal setting that fits the constraints. And that is what this paper addresses. In this work, we enhance an attack detection system based on Convolutional Neural Networks with privacy-preserving technology based on PriMIA framework that is initially designed for medical data.","sentences":["Privacy-preserving analytics is designed to protect valuable assets.","A common service provision involves the input data from the client and the model on the analyst's side.","The importance of the privacy preservation is fuelled by legal obligations and intellectual property concerns.","We explore the use case of a model owner providing an analytic service on customer's private data.","No information about the data shall be revealed to the analyst and no information about the model shall be leaked to the customer.","Current methods involve costs: accuracy deterioration and computational complexity.","The complexity, in turn, results in a longer processing time, increased requirement on computing resources, and involves data communication between the client and the server.","In order to deploy such service architecture, we need to evaluate the optimal setting that fits the constraints.","And that is what this paper addresses.","In this work, we enhance an attack detection system based on Convolutional Neural Networks with privacy-preserving technology based on PriMIA framework that is initially designed for medical data."],"url":"http://arxiv.org/abs/2404.09625v1","category":"cs.CR"}
{"created":"2024-04-15 12:54:31","title":"Personalized Collaborative Fine-Tuning for On-Device Large Language Models","abstract":"We explore on-device self-supervised collaborative fine-tuning of large language models with limited local data availability. Taking inspiration from the collaborative learning community, we introduce three distinct trust-weighted gradient aggregation schemes: weight similarity-based, prediction similarity-based and validation performance-based. To minimize communication overhead, we integrate Low-Rank Adaptation (LoRA) and only exchange LoRA weight updates. Our protocols, driven by prediction and performance metrics, surpass both FedAvg and local fine-tuning methods, which is particularly evident in realistic scenarios with more diverse local data distributions. The results underscore the effectiveness of our approach in addressing heterogeneity and scarcity within local datasets.","sentences":["We explore on-device self-supervised collaborative fine-tuning of large language models with limited local data availability.","Taking inspiration from the collaborative learning community, we introduce three distinct trust-weighted gradient aggregation schemes: weight similarity-based, prediction similarity-based and validation performance-based.","To minimize communication overhead, we integrate Low-Rank Adaptation (LoRA) and only exchange LoRA weight updates.","Our protocols, driven by prediction and performance metrics, surpass both FedAvg and local fine-tuning methods, which is particularly evident in realistic scenarios with more diverse local data distributions.","The results underscore the effectiveness of our approach in addressing heterogeneity and scarcity within local datasets."],"url":"http://arxiv.org/abs/2404.09753v1","category":"cs.CL"}
{"created":"2024-04-15 12:37:26","title":"FSRT: Facial Scene Representation Transformer for Face Reenactment from Factorized Appearance, Head-pose, and Facial Expression Features","abstract":"The task of face reenactment is to transfer the head motion and facial expressions from a driving video to the appearance of a source image, which may be of a different person (cross-reenactment). Most existing methods are CNN-based and estimate optical flow from the source image to the current driving frame, which is then inpainted and refined to produce the output animation. We propose a transformer-based encoder for computing a set-latent representation of the source image(s). We then predict the output color of a query pixel using a transformer-based decoder, which is conditioned with keypoints and a facial expression vector extracted from the driving frame. Latent representations of the source person are learned in a self-supervised manner that factorize their appearance, head pose, and facial expressions. Thus, they are perfectly suited for cross-reenactment. In contrast to most related work, our method naturally extends to multiple source images and can thus adapt to person-specific facial dynamics. We also propose data augmentation and regularization schemes that are necessary to prevent overfitting and support generalizability of the learned representations. We evaluated our approach in a randomized user study. The results indicate superior performance compared to the state-of-the-art in terms of motion transfer quality and temporal consistency.","sentences":["The task of face reenactment is to transfer the head motion and facial expressions from a driving video to the appearance of a source image, which may be of a different person (cross-reenactment).","Most existing methods are CNN-based and estimate optical flow from the source image to the current driving frame, which is then inpainted and refined to produce the output animation.","We propose a transformer-based encoder for computing a set-latent representation of the source image(s).","We then predict the output color of a query pixel using a transformer-based decoder, which is conditioned with keypoints and a facial expression vector extracted from the driving frame.","Latent representations of the source person are learned in a self-supervised manner that factorize their appearance, head pose, and facial expressions.","Thus, they are perfectly suited for cross-reenactment.","In contrast to most related work, our method naturally extends to multiple source images and can thus adapt to person-specific facial dynamics.","We also propose data augmentation and regularization schemes that are necessary to prevent overfitting and support generalizability of the learned representations.","We evaluated our approach in a randomized user study.","The results indicate superior performance compared to the state-of-the-art in terms of motion transfer quality and temporal consistency."],"url":"http://arxiv.org/abs/2404.09736v1","category":"cs.CV"}
{"created":"2024-04-15 12:27:20","title":"Nonparametric density estimation for the small jumps of L\u00e9vy processes","abstract":"We consider the problem of estimating the density of the process associated with the small jumps of a pure jump L\\'evy process, possibly of infinite variation, from discrete observations of one trajectory. The interest of such a question lies on the observation that even when the L\\'evy measure is known, the density of the increments of the small jumps of the process cannot be computed. We discuss results both from low and high frequency observations. In a low frequency setting, assuming the L\\'evy density associated with the jumps larger than $\\varepsilon\\in (0,1]$ in absolute value is known, a spectral estimator relying on the convolution structure of the problem achieves minimax parametric rates of convergence with respect to the integrated $L_2$ loss, up to a logarithmic factor. In a high frequency setting, we remove the assumption on the knowledge of the L\\'evy measure of the large jumps and show that the rate of convergence depends both on the sampling scheme and on the behaviour of the L\\'evy measure in a neighborhood of zero. We show that the rate we find is minimax up to a log-factor. An adaptive penalized procedure is studied to select the cutoff parameter. These results are extended to encompass the case where a Brownian component is present in the L\\'evy process. Furthermore, we illustrate the performances of our procedures through an extensive simulation study.","sentences":["We consider the problem of estimating the density of the process associated with the small jumps of a pure jump L\\'evy process, possibly of infinite variation, from discrete observations of one trajectory.","The interest of such a question lies on the observation that even when the L\\'evy measure is known, the density of the increments of the small jumps of the process cannot be computed.","We discuss results both from low and high frequency observations.","In a low frequency setting, assuming the L\\'evy density associated with the jumps larger than $\\varepsilon\\in (0,1]$ in absolute value is known, a spectral estimator relying on the convolution structure of the problem achieves minimax parametric rates of convergence with respect to the integrated $L_2$ loss, up to a logarithmic factor.","In a high frequency setting, we remove the assumption on the knowledge of the L\\'evy measure of the large jumps and show that the rate of convergence depends both on the sampling scheme and on the behaviour of the L\\'evy measure in a neighborhood of zero.","We show that the rate we find is minimax up to a log-factor.","An adaptive penalized procedure is studied to select the cutoff parameter.","These results are extended to encompass the case where a Brownian component is present in the L\\'evy process.","Furthermore, we illustrate the performances of our procedures through an extensive simulation study."],"url":"http://arxiv.org/abs/2404.09725v1","category":"math.ST"}
{"created":"2024-04-15 12:08:44","title":"Scenario-Adaptive Fine-Grained Personalization Network: Tailoring User Behavior Representation to the Scenario Context","abstract":"Existing methods often adjust representations adaptively only after aggregating user behavior sequences. This coarse-grained approach to re-weighting the entire user sequence hampers the model's ability to accurately model the user interest migration across different scenarios. To enhance the model's capacity to capture user interests from historical behavior sequences in each scenario, we develop a ranking framework named the Scenario-Adaptive Fine-Grained Personalization Network (SFPNet), which designs a kind of fine-grained method for multi-scenario personalized recommendations. Specifically, SFPNet comprises a series of blocks named as Scenario-Tailoring Block, stacked sequentially. Each block initially deploys a parameter personalization unit to integrate scenario information at a coarse-grained level by redefining fundamental features. Subsequently, we consolidate scenario-adaptively adjusted feature representations to serve as context information. By employing residual connection, we incorporate this context into the representation of each historical behavior, allowing for context-aware fine-grained customization of the behavior representations at the scenario-level, which in turn supports scenario-aware user interest modeling.","sentences":["Existing methods often adjust representations adaptively only after aggregating user behavior sequences.","This coarse-grained approach to re-weighting the entire user sequence hampers the model's ability to accurately model the user interest migration across different scenarios.","To enhance the model's capacity to capture user interests from historical behavior sequences in each scenario, we develop a ranking framework named the Scenario-Adaptive Fine-Grained Personalization Network (SFPNet), which designs a kind of fine-grained method for multi-scenario personalized recommendations.","Specifically, SFPNet comprises a series of blocks named as Scenario-Tailoring Block, stacked sequentially.","Each block initially deploys a parameter personalization unit to integrate scenario information at a coarse-grained level by redefining fundamental features.","Subsequently, we consolidate scenario-adaptively adjusted feature representations to serve as context information.","By employing residual connection, we incorporate this context into the representation of each historical behavior, allowing for context-aware fine-grained customization of the behavior representations at the scenario-level, which in turn supports scenario-aware user interest modeling."],"url":"http://arxiv.org/abs/2404.09709v1","category":"cs.IR"}
{"created":"2024-04-15 12:04:24","title":"Adaptive integration of history variables in constrained mixture models for organ-scale growth and remodeling","abstract":"In the last decades, many computational models have been developed to predict soft tissue growth and remodeling (G&R). The constrained mixture theory describes fundamental mechanobiological processes in soft tissue G&R and has been widely adopted in cardiovascular models of G&R. However, even after two decades of work, large organ-scale models are rare, mainly due to high computational costs (model evaluation and memory consumption), especially in long-range simulations. We propose two strategies to adaptively integrate history variables in constrained mixture models to enable large organ-scale simulations of G&R. Both strategies exploit that the influence of deposited tissue on the current mixture decreases over time through degradation. One strategy is independent of external loading, allowing the estimation of the computational resources ahead of the simulation. The other adapts the history snapshots based on the local mechanobiological environment so that the additional integration errors can be controlled and kept negligibly small, even in G&R scenarios with severe perturbations. We analyze the adaptively integrated constrained mixture model on a tissue patch for a parameter study and show the performance under different G&R scenarios. To confirm that adaptive strategies enable large organ-scale examples, we show simulations of different hypertension conditions with a real-world example of a biventricular heart discretized with a finite element mesh. In our example, adaptive integrations sped up simulations by a factor of three and reduced memory requirements to one-sixth. The reduction of the computational costs gets even more pronounced for simulations over longer periods. Adaptive integration of the history variables allows studying more finely resolved models and longer G&R periods while computational costs are drastically reduced and largely constant in time.","sentences":["In the last decades, many computational models have been developed to predict soft tissue growth and remodeling (G&R).","The constrained mixture theory describes fundamental mechanobiological processes in soft tissue G&R and has been widely adopted in cardiovascular models of G&R.","However, even after two decades of work, large organ-scale models are rare, mainly due to high computational costs (model evaluation and memory consumption), especially in long-range simulations.","We propose two strategies to adaptively integrate history variables in constrained mixture models to enable large organ-scale simulations of G&R.","Both strategies exploit that the influence of deposited tissue on the current mixture decreases over time through degradation.","One strategy is independent of external loading, allowing the estimation of the computational resources ahead of the simulation.","The other adapts the history snapshots based on the local mechanobiological environment so that the additional integration errors can be controlled and kept negligibly small, even in G&R scenarios with severe perturbations.","We analyze the adaptively integrated constrained mixture model on a tissue patch for a parameter study and show the performance under different G&R scenarios.","To confirm that adaptive strategies enable large organ-scale examples, we show simulations of different hypertension conditions with a real-world example of a biventricular heart discretized with a finite element mesh.","In our example, adaptive integrations sped up simulations by a factor of three and reduced memory requirements to one-sixth.","The reduction of the computational costs gets even more pronounced for simulations over longer periods.","Adaptive integration of the history variables allows studying more finely resolved models and longer G&R periods while computational costs are drastically reduced and largely constant in time."],"url":"http://arxiv.org/abs/2404.09706v1","category":"q-bio.TO"}
{"created":"2024-04-15 11:20:44","title":"AntDT: A Self-Adaptive Distributed Training Framework for Leader and Straggler Nodes","abstract":"Many distributed training techniques like Parameter Server and AllReduce have been proposed to take advantage of the increasingly large data and rich features. However, stragglers frequently occur in distributed training due to resource contention and hardware heterogeneity, which significantly hampers the training efficiency. Previous works only address part of the stragglers and could not adaptively solve various stragglers in practice. Additionally, it is challenging to use a systematic framework to address all stragglers because different stragglers require diverse data allocation and fault-tolerance mechanisms. Therefore, this paper proposes a unified distributed training framework called AntDT (Ant Distributed Training Framework) to adaptively solve the straggler problems. Firstly, the framework consists of four components, including the Stateful Dynamic Data Sharding service, Monitor, Controller, and Agent. These components work collaboratively to efficiently distribute workloads and provide a range of pre-defined straggler mitigation methods with fault tolerance, thereby hiding messy details of data allocation and fault handling. Secondly, the framework provides a high degree of flexibility, allowing for the customization of straggler mitigation solutions based on the specific circumstances of the cluster. Leveraging this flexibility, we introduce two straggler mitigation solutions, namely AntDT-ND for non-dedicated clusters and AntDT-DD for dedicated clusters, as practical examples to resolve various types of stragglers at Ant Group. Justified by our comprehensive experiments and industrial deployment statistics, AntDT outperforms other SOTA methods more than 3x in terms of training efficiency. Additionally, in Alipay's homepage recommendation scenario, using AntDT reduces the training duration of the ranking model from 27.8 hours to just 5.4 hours.","sentences":["Many distributed training techniques like Parameter Server and AllReduce have been proposed to take advantage of the increasingly large data and rich features.","However, stragglers frequently occur in distributed training due to resource contention and hardware heterogeneity, which significantly hampers the training efficiency.","Previous works only address part of the stragglers and could not adaptively solve various stragglers in practice.","Additionally, it is challenging to use a systematic framework to address all stragglers because different stragglers require diverse data allocation and fault-tolerance mechanisms.","Therefore, this paper proposes a unified distributed training framework called AntDT (Ant Distributed Training Framework) to adaptively solve the straggler problems.","Firstly, the framework consists of four components, including the Stateful Dynamic Data Sharding service, Monitor, Controller, and Agent.","These components work collaboratively to efficiently distribute workloads and provide a range of pre-defined straggler mitigation methods with fault tolerance, thereby hiding messy details of data allocation and fault handling.","Secondly, the framework provides a high degree of flexibility, allowing for the customization of straggler mitigation solutions based on the specific circumstances of the cluster.","Leveraging this flexibility, we introduce two straggler mitigation solutions, namely AntDT-ND for non-dedicated clusters and AntDT-DD for dedicated clusters, as practical examples to resolve various types of stragglers at Ant Group.","Justified by our comprehensive experiments and industrial deployment statistics, AntDT outperforms other SOTA methods more than 3x in terms of training efficiency.","Additionally, in Alipay's homepage recommendation scenario, using AntDT reduces the training duration of the ranking model from 27.8 hours to just 5.4 hours."],"url":"http://arxiv.org/abs/2404.09679v1","category":"cs.DC"}
{"created":"2024-04-15 10:47:59","title":"Reconstructing Curves from Sparse Samples on Riemannian Manifolds","abstract":"Reconstructing 2D curves from sample points has long been a critical challenge in computer graphics, finding essential applications in vector graphics. The design and editing of curves on surfaces has only recently begun to receive attention, primarily relying on human assistance, and where not, limited by very strict sampling conditions. In this work, we formally improve on the state-of-the-art requirements and introduce an innovative algorithm capable of reconstructing closed curves directly on surfaces from a given sparse set of sample points. We extend and adapt a state-of-the-art planar curve reconstruction method to the realm of surfaces while dealing with the challenges arising from working on non-Euclidean domains. We demonstrate the robustness of our method by reconstructing multiple curves on various surface meshes. We explore novel potential applications of our approach, allowing for automated reconstruction of curves on Riemannian manifolds.","sentences":["Reconstructing 2D curves from sample points has long been a critical challenge in computer graphics, finding essential applications in vector graphics.","The design and editing of curves on surfaces has only recently begun to receive attention, primarily relying on human assistance, and where not, limited by very strict sampling conditions.","In this work, we formally improve on the state-of-the-art requirements and introduce an innovative algorithm capable of reconstructing closed curves directly on surfaces from a given sparse set of sample points.","We extend and adapt a state-of-the-art planar curve reconstruction method to the realm of surfaces while dealing with the challenges arising from working on non-Euclidean domains.","We demonstrate the robustness of our method by reconstructing multiple curves on various surface meshes.","We explore novel potential applications of our approach, allowing for automated reconstruction of curves on Riemannian manifolds."],"url":"http://arxiv.org/abs/2404.09661v1","category":"cs.CG"}
{"created":"2024-04-15 10:42:22","title":"Do LLMs Understand Visual Anomalies? Uncovering LLM Capabilities in Zero-shot Anomaly Detection","abstract":"Large vision-language models (LVLMs) are markedly proficient in deriving visual representations guided by natural language. Recent explorations have utilized LVLMs to tackle zero-shot visual anomaly detection (VAD) challenges by pairing images with textual descriptions indicative of normal and abnormal conditions, referred to as anomaly prompts. However, existing approaches depend on static anomaly prompts that are prone to cross-semantic ambiguity, and prioritize global image-level representations over crucial local pixel-level image-to-text alignment that is necessary for accurate anomaly localization. In this paper, we present ALFA, a training-free approach designed to address these challenges via a unified model. We propose a run-time prompt adaptation strategy, which first generates informative anomaly prompts to leverage the capabilities of a large language model (LLM). This strategy is enhanced by a contextual scoring mechanism for per-image anomaly prompt adaptation and cross-semantic ambiguity mitigation. We further introduce a novel fine-grained aligner to fuse local pixel-level semantics for precise anomaly localization, by projecting the image-text alignment from global to local semantic spaces. Extensive evaluations on the challenging MVTec and VisA datasets confirm ALFA's effectiveness in harnessing the language potential for zero-shot VAD, achieving significant PRO improvements of 12.1% on MVTec AD and 8.9% on VisA compared to state-of-the-art zero-shot VAD approaches.","sentences":["Large vision-language models (LVLMs) are markedly proficient in deriving visual representations guided by natural language.","Recent explorations have utilized LVLMs to tackle zero-shot visual anomaly detection (VAD) challenges by pairing images with textual descriptions indicative of normal and abnormal conditions, referred to as anomaly prompts.","However, existing approaches depend on static anomaly prompts that are prone to cross-semantic ambiguity, and prioritize global image-level representations over crucial local pixel-level image-to-text alignment that is necessary for accurate anomaly localization.","In this paper, we present ALFA, a training-free approach designed to address these challenges via a unified model.","We propose a run-time prompt adaptation strategy, which first generates informative anomaly prompts to leverage the capabilities of a large language model (LLM).","This strategy is enhanced by a contextual scoring mechanism for per-image anomaly prompt adaptation and cross-semantic ambiguity mitigation.","We further introduce a novel fine-grained aligner to fuse local pixel-level semantics for precise anomaly localization, by projecting the image-text alignment from global to local semantic spaces.","Extensive evaluations on the challenging MVTec and VisA datasets confirm ALFA's effectiveness in harnessing the language potential for zero-shot VAD, achieving significant PRO improvements of 12.1% on MVTec AD and 8.9% on VisA compared to state-of-the-art zero-shot VAD approaches."],"url":"http://arxiv.org/abs/2404.09654v1","category":"cs.CV"}
{"created":"2024-04-15 10:34:22","title":"Stiffness-Tuneable Limb Segment with Flexible Spine for Malleable Robots","abstract":"Robotic arms built from stiffness-adjustable, continuously bending segments serially connected with revolute joints have the ability to change their mechanical architecture and workspace, thus allowing high flexibility and adaptation to different tasks with less than six degrees of freedom, a concept that we call malleable robots. Known stiffening mechanisms may be used to implement suitable links for these novel robotic manipulators; however, these solutions usually show a reduced performance when bending due to structural deformation. By including an inner support structure this deformation can be minimised, resulting in an increased stiffening performance. This paper presents a new multi-material spine-inspired flexible structure for providing support in stiffness-controllable layer-jamming-based robotic links of large diameter. The proposed spine mechanism is highly movable with type and range of motions that match those of a robotic link using solely layer jamming, whilst maintaining a hollow and light structure. The mechanics and design of the flexible spine are explored, and a prototype of a link utilising it is developed and compared with limb segments based on granular jamming and layer jamming without support structure. Results of experiments verify the advantages of the proposed design, demonstrating that it maintains a constant central diameter across bending angles and presents an improvement of more than 203% of resisting force at 180 degrees.","sentences":["Robotic arms built from stiffness-adjustable, continuously bending segments serially connected with revolute joints have the ability to change their mechanical architecture and workspace, thus allowing high flexibility and adaptation to different tasks with less than six degrees of freedom, a concept that we call malleable robots.","Known stiffening mechanisms may be used to implement suitable links for these novel robotic manipulators; however, these solutions usually show a reduced performance when bending due to structural deformation.","By including an inner support structure this deformation can be minimised, resulting in an increased stiffening performance.","This paper presents a new multi-material spine-inspired flexible structure for providing support in stiffness-controllable layer-jamming-based robotic links of large diameter.","The proposed spine mechanism is highly movable with type and range of motions that match those of a robotic link using solely layer jamming, whilst maintaining a hollow and light structure.","The mechanics and design of the flexible spine are explored, and a prototype of a link utilising it is developed and compared with limb segments based on granular jamming and layer jamming without support structure.","Results of experiments verify the advantages of the proposed design, demonstrating that it maintains a constant central diameter across bending angles and presents an improvement of more than 203% of resisting force at 180 degrees."],"url":"http://arxiv.org/abs/2404.09653v1","category":"cs.RO"}
{"created":"2024-04-15 10:20:51","title":"Multiple single-photon generations in three-level atoms coupled to cavity with non-Markovian effects","abstract":"In this paper, we show how to generate the multiple single-photon wavepackets of arbitrary temporal shape from an optical cavity coupled with $N$ three-level atoms driven by a driving field in the non-Markovian regime. We derive an exact analytical expression of the optimal driving field for generating such wavepackets, which depends on two detunings of the cavity and driving field with respect to the three-level atoms. The cavity we used consists of two mirrors facing each other, where one is perfect and the other exists the dissipation (one-sided cavity), which couples with the corresponding non-Markovian input-output fields. If the first single-photon wavepacket generated by the Markovian system is the same as the non-Markovian case, the Markovian system cannot generate the same multiple single-photon wavepackets as the non-Markovian one when the spectral widths of the other environments taking values different from the spectral width of the first environment, while setting the equal spectral widths for the different environments can generate this. The generated multiple different single-photon wavepackets are not independent of each other, which satisfy certain relations with non-Markovian spectral parameters. We analyse the transition from Markovian to non-Markovian regimes and compare the differences between them, where the cavity interacts simultaneously with the multiple non-Markovian environments. Finally, we extend the above results to a general non-Markovian quantum network involving many cavities coupled with driven three-level atoms.","sentences":["In this paper, we show how to generate the multiple single-photon wavepackets of arbitrary temporal shape from an optical cavity coupled with $N$ three-level atoms driven by a driving field in the non-Markovian regime.","We derive an exact analytical expression of the optimal driving field for generating such wavepackets, which depends on two detunings of the cavity and driving field with respect to the three-level atoms.","The cavity we used consists of two mirrors facing each other, where one is perfect and the other exists the dissipation (one-sided cavity), which couples with the corresponding non-Markovian input-output fields.","If the first single-photon wavepacket generated by the Markovian system is the same as the non-Markovian case, the Markovian system cannot generate the same multiple single-photon wavepackets as the non-Markovian one when the spectral widths of the other environments taking values different from the spectral width of the first environment, while setting the equal spectral widths for the different environments can generate this.","The generated multiple different single-photon wavepackets are not independent of each other, which satisfy certain relations with non-Markovian spectral parameters.","We analyse the transition from Markovian to non-Markovian regimes and compare the differences between them, where the cavity interacts simultaneously with the multiple non-Markovian environments.","Finally, we extend the above results to a general non-Markovian quantum network involving many cavities coupled with driven three-level atoms."],"url":"http://arxiv.org/abs/2404.09641v1","category":"quant-ph"}
{"created":"2024-04-15 09:46:12","title":"Safeguarding adaptive methods: global convergence of Barzilai-Borwein and other stepsize choices","abstract":"Leveraging on recent advancements on adaptive methods for convex minimization problems, this paper provides a linesearch-free proximal gradient framework for globalizing the convergence of popular stepsize choices such as Barzilai-Borwein and one-dimensional Anderson acceleration. This framework can cope with problems in which the gradient of the differentiable function is merely locally H\\\"older continuous. Our analysis not only encompasses but also refines existing results upon which it builds. The theory is corroborated by numerical evidence that showcases the synergetic interplay between fast stepsize selections and adaptive methods.","sentences":["Leveraging on recent advancements on adaptive methods for convex minimization problems, this paper provides a linesearch-free proximal gradient framework for globalizing the convergence of popular stepsize choices such as Barzilai-Borwein and one-dimensional Anderson acceleration.","This framework can cope with problems in which the gradient of the differentiable function is merely locally H\\\"older continuous.","Our analysis not only encompasses but also refines existing results upon which it builds.","The theory is corroborated by numerical evidence that showcases the synergetic interplay between fast stepsize selections and adaptive methods."],"url":"http://arxiv.org/abs/2404.09617v1","category":"math.OC"}
{"created":"2024-04-15 09:32:12","title":"LoRA Dropout as a Sparsity Regularizer for Overfitting Control","abstract":"Parameter-efficient fine-tuning methods, represented by LoRA, play an essential role in adapting large-scale pre-trained models to downstream tasks. However, fine-tuning LoRA-series models also faces the risk of overfitting on the training dataset, and yet there's still a lack of theoretical guidance and practical mechanism to control overfitting on LoRA-based PEFT methods. In this paper, we propose a LoRA Dropout mechanism for the LoRA-based methods by introducing random noises to the learnable low-rank matrices and increasing parameter sparsity. We then demonstrate the theoretical mechanism of our LoRA Dropout mechanism from the perspective of sparsity regularization by providing a generalization error bound under this framework. Theoretical results show that appropriate sparsity would help tighten the gap between empirical and generalization risks and thereby control overfitting. Furthermore, based on the LoRA Dropout framework, we introduce a test-time ensemble strategy and provide theoretical evidence demonstrating that the ensemble method can further compress the error bound, and lead to better performance during inference time. Extensive experiments on various NLP tasks provide practical validations of the effectiveness of our LoRA Dropout framework in improving model accuracy and calibration.","sentences":["Parameter-efficient fine-tuning methods, represented by LoRA, play an essential role in adapting large-scale pre-trained models to downstream tasks.","However, fine-tuning LoRA-series models also faces the risk of overfitting on the training dataset, and yet there's still a lack of theoretical guidance and practical mechanism to control overfitting on LoRA-based PEFT methods.","In this paper, we propose a LoRA Dropout mechanism for the LoRA-based methods by introducing random noises to the learnable low-rank matrices and increasing parameter sparsity.","We then demonstrate the theoretical mechanism of our LoRA Dropout mechanism from the perspective of sparsity regularization by providing a generalization error bound under this framework.","Theoretical results show that appropriate sparsity would help tighten the gap between empirical and generalization risks and thereby control overfitting.","Furthermore, based on the LoRA Dropout framework, we introduce a test-time ensemble strategy and provide theoretical evidence demonstrating that the ensemble method can further compress the error bound, and lead to better performance during inference time.","Extensive experiments on various NLP tasks provide practical validations of the effectiveness of our LoRA Dropout framework in improving model accuracy and calibration."],"url":"http://arxiv.org/abs/2404.09610v1","category":"cs.LG"}
{"created":"2024-04-15 09:26:33","title":"A Self-feedback Knowledge Elicitation Approach for Chemical Reaction Predictions","abstract":"The task of chemical reaction predictions (CRPs) plays a pivotal role in advancing drug discovery and material science. However, its effectiveness is constrained by the vast and uncertain chemical reaction space and challenges in capturing reaction selectivity, particularly due to existing methods' limitations in exploiting the data's inherent knowledge. To address these challenges, we introduce a data-curated self-feedback knowledge elicitation approach. This method starts from iterative optimization of molecular representations and facilitates the extraction of knowledge on chemical reaction types (RTs). Then, we employ adaptive prompt learning to infuse the prior knowledge into the large language model (LLM). As a result, we achieve significant enhancements: a 14.2% increase in retrosynthesis prediction accuracy, a 74.2% rise in reagent prediction accuracy, and an expansion in the model's capability for handling multi-task chemical reactions. This research offers a novel paradigm for knowledge elicitation in scientific research and showcases the untapped potential of LLMs in CRPs.","sentences":["The task of chemical reaction predictions (CRPs) plays a pivotal role in advancing drug discovery and material science.","However, its effectiveness is constrained by the vast and uncertain chemical reaction space and challenges in capturing reaction selectivity, particularly due to existing methods' limitations in exploiting the data's inherent knowledge.","To address these challenges, we introduce a data-curated self-feedback knowledge elicitation approach.","This method starts from iterative optimization of molecular representations and facilitates the extraction of knowledge on chemical reaction types (RTs).","Then, we employ adaptive prompt learning to infuse the prior knowledge into the large language model (LLM).","As a result, we achieve significant enhancements: a 14.2% increase in retrosynthesis prediction accuracy, a 74.2% rise in reagent prediction accuracy, and an expansion in the model's capability for handling multi-task chemical reactions.","This research offers a novel paradigm for knowledge elicitation in scientific research and showcases the untapped potential of LLMs in CRPs."],"url":"http://arxiv.org/abs/2404.09606v1","category":"cs.LG"}
{"created":"2024-04-15 08:42:39","title":"The metric for matrix degenerate Kato square root operators","abstract":"We prove a Kato square root estimate with anisotropically degenerate matrix coefficients. We do so by doing the harmonic analysis using an auxiliary Riemannian metric adapted to the operator. We also derive $L^2$-solvability estimates for boundary value problems for divergence form elliptic equations with matrix degenerate coefficients. Main tools are chain rules and Piola transformations for fields in matrix weighted $L^2$ spaces, under $W^{1,1}$ homeomorphism.","sentences":["We prove a Kato square root estimate with anisotropically degenerate matrix coefficients.","We do so by doing the harmonic analysis using an auxiliary Riemannian metric adapted to the operator.","We also derive $L^2$-solvability estimates for boundary value problems for divergence form elliptic equations with matrix degenerate coefficients.","Main tools are chain rules and Piola transformations for fields in matrix weighted $L^2$ spaces, under $W^{1,1}$ homeomorphism."],"url":"http://arxiv.org/abs/2404.09580v1","category":"math.AP"}
{"created":"2024-04-15 08:32:18","title":"The revenge of BiSeNet: Efficient Multi-Task Image Segmentation","abstract":"Recent advancements in image segmentation have focused on enhancing the efficiency of the models to meet the demands of real-time applications, especially on edge devices. However, existing research has primarily concentrated on single-task settings, especially on semantic segmentation, leading to redundant efforts and specialized architectures for different tasks. To address this limitation, we propose a novel architecture for efficient multi-task image segmentation, capable of handling various segmentation tasks without sacrificing efficiency or accuracy. We introduce BiSeNetFormer, that leverages the efficiency of two-stream semantic segmentation architectures and it extends them into a mask classification framework. Our approach maintains the efficient spatial and context paths to capture detailed and semantic information, respectively, while leveraging an efficient transformed-based segmentation head that computes the binary masks and class probabilities. By seamlessly supporting multiple tasks, namely semantic and panoptic segmentation, BiSeNetFormer offers a versatile solution for multi-task segmentation. We evaluate our approach on popular datasets, Cityscapes and ADE20K, demonstrating impressive inference speeds while maintaining competitive accuracy compared to state-of-the-art architectures. Our results indicate that BiSeNetFormer represents a significant advancement towards fast, efficient, and multi-task segmentation networks, bridging the gap between model efficiency and task adaptability.","sentences":["Recent advancements in image segmentation have focused on enhancing the efficiency of the models to meet the demands of real-time applications, especially on edge devices.","However, existing research has primarily concentrated on single-task settings, especially on semantic segmentation, leading to redundant efforts and specialized architectures for different tasks.","To address this limitation, we propose a novel architecture for efficient multi-task image segmentation, capable of handling various segmentation tasks without sacrificing efficiency or accuracy.","We introduce BiSeNetFormer, that leverages the efficiency of two-stream semantic segmentation architectures and it extends them into a mask classification framework.","Our approach maintains the efficient spatial and context paths to capture detailed and semantic information, respectively, while leveraging an efficient transformed-based segmentation head that computes the binary masks and class probabilities.","By seamlessly supporting multiple tasks, namely semantic and panoptic segmentation, BiSeNetFormer offers a versatile solution for multi-task segmentation.","We evaluate our approach on popular datasets, Cityscapes and ADE20K, demonstrating impressive inference speeds while maintaining competitive accuracy compared to state-of-the-art architectures.","Our results indicate that BiSeNetFormer represents a significant advancement towards fast, efficient, and multi-task segmentation networks, bridging the gap between model efficiency and task adaptability."],"url":"http://arxiv.org/abs/2404.09570v1","category":"cs.CV"}
{"created":"2024-04-15 08:29:24","title":"A competitive game optimization algorithm for Unmanned Aerial Vehicle path planning","abstract":"To solve the Unmanned Aerial Vehicle (UAV) path planning problem, a meta-heuristic optimization algorithm called competitive game optimizer (CGO) is proposed. In the CGO model, three phases of exploration and exploitation, and candidate replacement, are established, corresponding to the player's search for supplies and combat, and the movement toward a safe zone. In the algorithm exploration phase, Levy flight is introduced to improve the global convergence of the algorithm. The encounter probability which adaptively changes with the number of iterations is also introduced in the CGO. The balance between exploration and exploitation of solution space of optimization problem is realized, and each step is described and modeled mathematically. The performance of the CGO was evaluated on a set of 41 test functions taken from CEC2017 and CEC2022. It was then compared with eight widely recognized meta-heuristic optimization algorithms. The simulation results demonstrate that the proposed algorithm successfully achieves a balanced trade-off between exploration and exploitation, showcasing remarkable advantages when compared to seven classical algorithms. In addition, in order to further verify the effectiveness of the CGO, the CGO is applied to 8 practical engineering design problems and UAV path planning, and the results show that the CGO has strong performance in dealing with these practical optimization problems, and has a good application prospect.","sentences":["To solve the Unmanned Aerial Vehicle (UAV) path planning problem, a meta-heuristic optimization algorithm called competitive game optimizer (CGO) is proposed.","In the CGO model, three phases of exploration and exploitation, and candidate replacement, are established, corresponding to the player's search for supplies and combat, and the movement toward a safe zone.","In the algorithm exploration phase, Levy flight is introduced to improve the global convergence of the algorithm.","The encounter probability which adaptively changes with the number of iterations is also introduced in the CGO.","The balance between exploration and exploitation of solution space of optimization problem is realized, and each step is described and modeled mathematically.","The performance of the CGO was evaluated on a set of 41 test functions taken from CEC2017 and CEC2022.","It was then compared with eight widely recognized meta-heuristic optimization algorithms.","The simulation results demonstrate that the proposed algorithm successfully achieves a balanced trade-off between exploration and exploitation, showcasing remarkable advantages when compared to seven classical algorithms.","In addition, in order to further verify the effectiveness of the CGO, the CGO is applied to 8 practical engineering design problems and UAV path planning, and the results show that the CGO has strong performance in dealing with these practical optimization problems, and has a good application prospect."],"url":"http://arxiv.org/abs/2404.09567v1","category":"eess.SY"}
{"created":"2024-04-15 08:28:46","title":"Moving horizon estimation for nonlinear systems with time-varying parameters","abstract":"We propose a moving horizon estimation scheme for estimating the states and time-varying parameters of nonlinear systems. We consider the case where observability of the parameters depends on the excitation of the system and may be absent during operation, with the parameter dynamics fulfilling a weak incremental bounded-energy bounded-state property to ensure boundedness of the estimation error (with respect to the disturbance energy). The proposed estimation scheme involves a standard quadratic cost function with an adaptive regularization term depending on the current parameter observability. We develop robustness guarantees for the overall estimation error that are valid for all times, and that improve the more often the parameters are detected to be observable during operation. The theoretical results are illustrated by a simulation example.","sentences":["We propose a moving horizon estimation scheme for estimating the states and time-varying parameters of nonlinear systems.","We consider the case where observability of the parameters depends on the excitation of the system and may be absent during operation, with the parameter dynamics fulfilling a weak incremental bounded-energy bounded-state property to ensure boundedness of the estimation error (with respect to the disturbance energy).","The proposed estimation scheme involves a standard quadratic cost function with an adaptive regularization term depending on the current parameter observability.","We develop robustness guarantees for the overall estimation error that are valid for all times, and that improve the more often the parameters are detected to be observable during operation.","The theoretical results are illustrated by a simulation example."],"url":"http://arxiv.org/abs/2404.09566v1","category":"eess.SY"}
{"created":"2024-04-15 08:18:16","title":"Explainable Generative AI (GenXAI): A Survey, Conceptualization, and Research Agenda","abstract":"Generative AI (GenAI) marked a shift from AI being able to recognize to AI being able to generate solutions for a wide variety of tasks. As the generated solutions and applications become increasingly more complex and multi-faceted, novel needs, objectives, and possibilities have emerged for explainability (XAI). In this work, we elaborate on why XAI has gained importance with the rise of GenAI and its challenges for explainability research. We also unveil novel and emerging desiderata that explanations should fulfill, covering aspects such as verifiability, interactivity, security, and cost. To this end, we focus on surveying existing works. Furthermore, we provide a taxonomy of relevant dimensions that allows us to better characterize existing XAI mechanisms and methods for GenAI. We discuss different avenues to ensure XAI, from training data to prompting. Our paper offers a short but concise technical background of GenAI for non-technical readers, focusing on text and images to better understand novel or adapted XAI techniques for GenAI. However, due to the vast array of works on GenAI, we decided to forego detailed aspects of XAI related to evaluation and usage of explanations. As such, the manuscript interests both technically oriented people and other disciplines, such as social scientists and information systems researchers. Our research roadmap provides more than ten directions for future investigation.","sentences":["Generative AI (GenAI) marked a shift from AI being able to recognize to AI being able to generate solutions for a wide variety of tasks.","As the generated solutions and applications become increasingly more complex and multi-faceted, novel needs, objectives, and possibilities have emerged for explainability (XAI).","In this work, we elaborate on why XAI has gained importance with the rise of GenAI and its challenges for explainability research.","We also unveil novel and emerging desiderata that explanations should fulfill, covering aspects such as verifiability, interactivity, security, and cost.","To this end, we focus on surveying existing works.","Furthermore, we provide a taxonomy of relevant dimensions that allows us to better characterize existing XAI mechanisms and methods for GenAI.","We discuss different avenues to ensure XAI, from training data to prompting.","Our paper offers a short but concise technical background of GenAI for non-technical readers, focusing on text and images to better understand novel or adapted XAI techniques for GenAI.","However, due to the vast array of works on GenAI, we decided to forego detailed aspects of XAI related to evaluation and usage of explanations.","As such, the manuscript interests both technically oriented people and other disciplines, such as social scientists and information systems researchers.","Our research roadmap provides more than ten directions for future investigation."],"url":"http://arxiv.org/abs/2404.09554v1","category":"cs.AI"}
{"created":"2024-04-15 08:11:21","title":"GNNavigator: Towards Adaptive Training of Graph Neural Networks via Automatic Guideline Exploration","abstract":"Graph Neural Networks (GNNs) succeed significantly in many applications recently. However, balancing GNNs training runtime cost, memory consumption, and attainable accuracy for various applications is non-trivial. Previous training methodologies suffer from inferior adaptability and lack a unified training optimization solution. To address the problem, this work proposes GNNavigator, an adaptive GNN training configuration optimization framework. GNNavigator meets diverse GNN application requirements due to our unified software-hardware co-abstraction, proposed GNNs training performance model, and practical design space exploration solution. Experimental results show that GNNavigator can achieve up to 3.1x speedup and 44.9% peak memory reduction with comparable accuracy to state-of-the-art approaches.","sentences":["Graph Neural Networks (GNNs) succeed significantly in many applications recently.","However, balancing GNNs training runtime cost, memory consumption, and attainable accuracy for various applications is non-trivial.","Previous training methodologies suffer from inferior adaptability and lack a unified training optimization solution.","To address the problem, this work proposes GNNavigator, an adaptive GNN training configuration optimization framework.","GNNavigator meets diverse GNN application requirements due to our unified software-hardware co-abstraction, proposed GNNs training performance model, and practical design space exploration solution.","Experimental results show that GNNavigator can achieve up to 3.1x speedup and 44.9% peak memory reduction with comparable accuracy to state-of-the-art approaches."],"url":"http://arxiv.org/abs/2404.09544v1","category":"cs.LG"}
{"created":"2024-04-15 07:51:29","title":"Oblique-MERF: Revisiting and Improving MERF for Oblique Photography","abstract":"Neural implicit fields have established a new paradigm for scene representation, with subsequent work achieving high-quality real-time rendering. However, reconstructing 3D scenes from oblique aerial photography presents unique challenges, such as varying spatial scale distributions and a constrained range of tilt angles, often resulting in high memory consumption and reduced rendering quality at extrapolated viewpoints. In this paper, we enhance MERF to accommodate these data characteristics by introducing an innovative adaptive occupancy plane optimized during the volume rendering process and a smoothness regularization term for view-dependent color to address these issues. Our approach, termed Oblique-MERF, surpasses state-of-the-art real-time methods by approximately 0.7 dB, reduces VRAM usage by about 40%, and achieves higher rendering frame rates with more realistic rendering outcomes across most viewpoints.","sentences":["Neural implicit fields have established a new paradigm for scene representation, with subsequent work achieving high-quality real-time rendering.","However, reconstructing 3D scenes from oblique aerial photography presents unique challenges, such as varying spatial scale distributions and a constrained range of tilt angles, often resulting in high memory consumption and reduced rendering quality at extrapolated viewpoints.","In this paper, we enhance MERF to accommodate these data characteristics by introducing an innovative adaptive occupancy plane optimized during the volume rendering process and a smoothness regularization term for view-dependent color to address these issues.","Our approach, termed Oblique-MERF, surpasses state-of-the-art real-time methods by approximately 0.7 dB, reduces VRAM usage by about 40%, and achieves higher rendering frame rates with more realistic rendering outcomes across most viewpoints."],"url":"http://arxiv.org/abs/2404.09531v1","category":"cs.CV"}
{"created":"2024-04-15 07:50:15","title":"RanLayNet: A Dataset for Document Layout Detection used for Domain Adaptation and Generalization","abstract":"Large ground-truth datasets and recent advances in deep learning techniques have been useful for layout detection. However, because of the restricted layout diversity of these datasets, training on them requires a sizable number of annotated instances, which is both expensive and time-consuming. As a result, differences between the source and target domains may significantly impact how well these models function. To solve this problem, domain adaptation approaches have been developed that use a small quantity of labeled data to adjust the model to the target domain. In this research, we introduced a synthetic document dataset called RanLayNet, enriched with automatically assigned labels denoting spatial positions, ranges, and types of layout elements. The primary aim of this endeavor is to develop a versatile dataset capable of training models with robustness and adaptability to diverse document formats. Through empirical experimentation, we demonstrate that a deep layout identification model trained on our dataset exhibits enhanced performance compared to a model trained solely on actual documents. Moreover, we conduct a comparative analysis by fine-tuning inference models using both PubLayNet and IIIT-AR-13K datasets on the Doclaynet dataset. Our findings emphasize that models enriched with our dataset are optimal for tasks such as achieving 0.398 and 0.588 mAP95 score in the scientific document domain for the TABLE class.","sentences":["Large ground-truth datasets and recent advances in deep learning techniques have been useful for layout detection.","However, because of the restricted layout diversity of these datasets, training on them requires a sizable number of annotated instances, which is both expensive and time-consuming.","As a result, differences between the source and target domains may significantly impact how well these models function.","To solve this problem, domain adaptation approaches have been developed that use a small quantity of labeled data to adjust the model to the target domain.","In this research, we introduced a synthetic document dataset called RanLayNet, enriched with automatically assigned labels denoting spatial positions, ranges, and types of layout elements.","The primary aim of this endeavor is to develop a versatile dataset capable of training models with robustness and adaptability to diverse document formats.","Through empirical experimentation, we demonstrate that a deep layout identification model trained on our dataset exhibits enhanced performance compared to a model trained solely on actual documents.","Moreover, we conduct a comparative analysis by fine-tuning inference models using both PubLayNet and IIIT-AR-13K datasets on the Doclaynet dataset.","Our findings emphasize that models enriched with our dataset are optimal for tasks such as achieving 0.398 and 0.588 mAP95 score in the scientific document domain for the TABLE class."],"url":"http://arxiv.org/abs/2404.09530v1","category":"cs.CV"}
{"created":"2024-04-15 07:45:04","title":"LoongServe: Efficiently Serving Long-context Large Language Models with Elastic Sequence Parallelism","abstract":"The context window of large language models (LLMs) is rapidly increasing, leading to a huge variance in resource usage between different requests as well as between different phases of the same request. Restricted by static parallelism strategies, existing LLM serving systems cannot efficiently utilize the underlying resources to serve variable-length requests in different phases. To address this problem, we propose a new parallelism paradigm, elastic sequence parallelism (ESP), to elastically adapt to the variance between different requests and phases. Based on ESP, we design and build LoongServe, an LLM serving system that (1) improves computation efficiency by elastically adjusting the degree of parallelism in real-time, (2) improves communication efficiency by reducing key-value cache migration overhead and overlapping partial decoding communication with computation, and (3) improves GPU memory efficiency by reducing key-value cache fragmentation across instances. Our evaluation under diverse real-world datasets shows that LoongServe improves the maximum throughput by up to 3.85$\\times$ compared to the chunked prefill and 5.81$\\times$ compared to the prefill-decoding disaggregation.","sentences":["The context window of large language models (LLMs) is rapidly increasing, leading to a huge variance in resource usage between different requests as well as between different phases of the same request.","Restricted by static parallelism strategies, existing LLM serving systems cannot efficiently utilize the underlying resources to serve variable-length requests in different phases.","To address this problem, we propose a new parallelism paradigm, elastic sequence parallelism (ESP), to elastically adapt to the variance between different requests and phases.","Based on ESP, we design and build LoongServe, an LLM serving system that (1) improves computation efficiency by elastically adjusting the degree of parallelism in real-time, (2) improves communication efficiency by reducing key-value cache migration overhead and overlapping partial decoding communication with computation, and (3) improves GPU memory efficiency by reducing key-value cache fragmentation across instances.","Our evaluation under diverse real-world datasets shows that LoongServe improves the maximum throughput by up to 3.85$\\times$ compared to the chunked prefill and 5.81$\\times$ compared to the prefill-decoding disaggregation."],"url":"http://arxiv.org/abs/2404.09526v1","category":"cs.DC"}
{"created":"2024-04-15 07:31:48","title":"Inferring Behavior-Specific Context Improves Zero-Shot Generalization in Reinforcement Learning","abstract":"In this work, we address the challenge of zero-shot generalization (ZSG) in Reinforcement Learning (RL), where agents must adapt to entirely novel environments without additional training. We argue that understanding and utilizing contextual cues, such as the gravity level of the environment, is critical for robust generalization, and we propose to integrate the learning of context representations directly with policy learning. Our algorithm demonstrates improved generalization on various simulated domains, outperforming prior context-learning techniques in zero-shot settings. By jointly learning policy and context, our method acquires behavior-specific context representations, enabling adaptation to unseen environments and marks progress towards reinforcement learning systems that generalize across diverse real-world tasks. Our code and experiments are available at https://github.com/tidiane-camaret/contextual_rl_zero_shot.","sentences":["In this work, we address the challenge of zero-shot generalization (ZSG) in Reinforcement Learning (RL), where agents must adapt to entirely novel environments without additional training.","We argue that understanding and utilizing contextual cues, such as the gravity level of the environment, is critical for robust generalization, and we propose to integrate the learning of context representations directly with policy learning.","Our algorithm demonstrates improved generalization on various simulated domains, outperforming prior context-learning techniques in zero-shot settings.","By jointly learning policy and context, our method acquires behavior-specific context representations, enabling adaptation to unseen environments and marks progress towards reinforcement learning systems that generalize across diverse real-world tasks.","Our code and experiments are available at https://github.com/tidiane-camaret/contextual_rl_zero_shot."],"url":"http://arxiv.org/abs/2404.09521v1","category":"cs.LG"}
{"created":"2024-04-15 07:15:39","title":"Magic Clothing: Controllable Garment-Driven Image Synthesis","abstract":"We propose Magic Clothing, a latent diffusion model (LDM)-based network architecture for an unexplored garment-driven image synthesis task. Aiming at generating customized characters wearing the target garments with diverse text prompts, the image controllability is the most critical issue, i.e., to preserve the garment details and maintain faithfulness to the text prompts. To this end, we introduce a garment extractor to capture the detailed garment features, and employ self-attention fusion to incorporate them into the pretrained LDMs, ensuring that the garment details remain unchanged on the target character. Then, we leverage the joint classifier-free guidance to balance the control of garment features and text prompts over the generated results. Meanwhile, the proposed garment extractor is a plug-in module applicable to various finetuned LDMs, and it can be combined with other extensions like ControlNet and IP-Adapter to enhance the diversity and controllability of the generated characters. Furthermore, we design Matched-Points-LPIPS (MP-LPIPS), a robust metric for evaluating the consistency of the target image to the source garment. Extensive experiments demonstrate that our Magic Clothing achieves state-of-the-art results under various conditional controls for garment-driven image synthesis. Our source code is available at https://github.com/ShineChen1024/MagicClothing.","sentences":["We propose Magic Clothing, a latent diffusion model (LDM)-based network architecture for an unexplored garment-driven image synthesis task.","Aiming at generating customized characters wearing the target garments with diverse text prompts, the image controllability is the most critical issue, i.e., to preserve the garment details and maintain faithfulness to the text prompts.","To this end, we introduce a garment extractor to capture the detailed garment features, and employ self-attention fusion to incorporate them into the pretrained LDMs, ensuring that the garment details remain unchanged on the target character.","Then, we leverage the joint classifier-free guidance to balance the control of garment features and text prompts over the generated results.","Meanwhile, the proposed garment extractor is a plug-in module applicable to various finetuned LDMs, and it can be combined with other extensions like ControlNet and IP-Adapter to enhance the diversity and controllability of the generated characters.","Furthermore, we design Matched-Points-LPIPS (MP-LPIPS), a robust metric for evaluating the consistency of the target image to the source garment.","Extensive experiments demonstrate that our Magic Clothing achieves state-of-the-art results under various conditional controls for garment-driven image synthesis.","Our source code is available at https://github.com/ShineChen1024/MagicClothing."],"url":"http://arxiv.org/abs/2404.09512v1","category":"cs.CV"}
{"created":"2024-04-15 06:50:58","title":"Learning Tracking Representations from Single Point Annotations","abstract":"Existing deep trackers are typically trained with largescale video frames with annotated bounding boxes. However, these bounding boxes are expensive and time-consuming to annotate, in particular for large scale datasets. In this paper, we propose to learn tracking representations from single point annotations (i.e., 4.5x faster to annotate than the traditional bounding box) in a weakly supervised manner. Specifically, we propose a soft contrastive learning (SoCL) framework that incorporates target objectness prior into end-to-end contrastive learning. Our SoCL consists of adaptive positive and negative sample generation, which is memory-efficient and effective for learning tracking representations. We apply the learned representation of SoCL to visual tracking and show that our method can 1) achieve better performance than the fully supervised baseline trained with box annotations under the same annotation time cost; 2) achieve comparable performance of the fully supervised baseline by using the same number of training frames and meanwhile reducing annotation time cost by 78% and total fees by 85%; 3) be robust to annotation noise.","sentences":["Existing deep trackers are typically trained with largescale video frames with annotated bounding boxes.","However, these bounding boxes are expensive and time-consuming to annotate, in particular for large scale datasets.","In this paper, we propose to learn tracking representations from single point annotations (i.e., 4.5x faster to annotate than the traditional bounding box) in a weakly supervised manner.","Specifically, we propose a soft contrastive learning (SoCL) framework that incorporates target objectness prior into end-to-end contrastive learning.","Our SoCL consists of adaptive positive and negative sample generation, which is memory-efficient and effective for learning tracking representations.","We apply the learned representation of SoCL to visual tracking and show that our method can 1) achieve better performance than the fully supervised baseline trained with box annotations under the same annotation time cost; 2) achieve comparable performance of the fully supervised baseline by using the same number of training frames and meanwhile reducing annotation time cost by 78% and total fees by 85%; 3) be robust to annotation noise."],"url":"http://arxiv.org/abs/2404.09504v1","category":"cs.CV"}
{"created":"2024-04-15 05:14:52","title":"PRIME: A CyberGIS Platform for Resilience Inference Measurement and Enhancement","abstract":"In an era of increased climatic disasters, there is an urgent need to develop reliable frameworks and tools for evaluating and improving community resilience to climatic hazards at multiple geographical and temporal scales. Defining and quantifying resilience in the social domain is relatively subjective due to the intricate interplay of socioeconomic factors with disaster resilience. Meanwhile, there is a lack of computationally rigorous, user-friendly tools that can support customized resilience assessment considering local conditions. This study aims to address these gaps through the power of CyberGIS with three objectives: 1) To develop an empirically validated disaster resilience model - Customized Resilience Inference Measurement designed for multi-scale community resilience assessment and influential socioeconomic factors identification, 2) To implement a Platform for Resilience Inference Measurement and Enhancement module in the CyberGISX platform backed by high-performance computing, 3) To demonstrate the utility of PRIME through a representative study. CRIM generates vulnerability, adaptability, and overall resilience scores derived from empirical hazard parameters. Computationally intensive Machine Learning methods are employed to explain the intricate relationships between these scores and socioeconomic driving factors. PRIME provides a web-based notebook interface guiding users to select study areas, configure parameters, calculate and geo-visualize resilience scores, and interpret socioeconomic factors shaping resilience capacities. A representative study showcases the efficiency of the platform while explaining how the visual results obtained may be interpreted. The essence of this work lies in its comprehensive architecture that encapsulates the requisite data, analytical and geo-visualization functions, and ML models for resilience assessment.","sentences":["In an era of increased climatic disasters, there is an urgent need to develop reliable frameworks and tools for evaluating and improving community resilience to climatic hazards at multiple geographical and temporal scales.","Defining and quantifying resilience in the social domain is relatively subjective due to the intricate interplay of socioeconomic factors with disaster resilience.","Meanwhile, there is a lack of computationally rigorous, user-friendly tools that can support customized resilience assessment considering local conditions.","This study aims to address these gaps through the power of CyberGIS with three objectives: 1) To develop an empirically validated disaster resilience model - Customized Resilience Inference Measurement designed for multi-scale community resilience assessment and influential socioeconomic factors identification, 2) To implement a Platform for Resilience Inference Measurement and Enhancement module in the CyberGISX platform backed by high-performance computing, 3) To demonstrate the utility of PRIME through a representative study.","CRIM generates vulnerability, adaptability, and overall resilience scores derived from empirical hazard parameters.","Computationally intensive Machine Learning methods are employed to explain the intricate relationships between these scores and socioeconomic driving factors.","PRIME provides a web-based notebook interface guiding users to select study areas, configure parameters, calculate and geo-visualize resilience scores, and interpret socioeconomic factors shaping resilience capacities.","A representative study showcases the efficiency of the platform while explaining how the visual results obtained may be interpreted.","The essence of this work lies in its comprehensive architecture that encapsulates the requisite data, analytical and geo-visualization functions, and ML models for resilience assessment."],"url":"http://arxiv.org/abs/2404.09463v1","category":"cs.LG"}
{"created":"2024-04-15 04:29:24","title":"Crooked indifferentiability of the Feistel Construction","abstract":"The Feistel construction is a fundamental technique for building pseudorandom permutations and block ciphers. This paper shows that a simple adaptation of the construction is resistant, even to algorithm substitution attacks -- that is, adversarial subversion -- of the component round functions. Specifically, we establish that a Feistel-based construction with more than $2000n/\\log(1/\\epsilon)$ rounds can transform a subverted random function -- which disagrees with the original one at a small fraction (denoted by $\\epsilon$) of inputs -- into an object that is \\emph{crooked-indifferentiable} from a random permutation, even if the adversary is aware of all the randomness used in the transformation. We also provide a lower bound showing that the construction cannot use fewer than $2n/\\log(1/\\epsilon)$ rounds to achieve crooked-indifferentiable security.","sentences":["The Feistel construction is a fundamental technique for building pseudorandom permutations and block ciphers.","This paper shows that a simple adaptation of the construction is resistant, even to algorithm substitution attacks -- that is, adversarial subversion -- of the component round functions.","Specifically, we establish that a Feistel-based construction with more than $2000n/\\log(1/\\epsilon)$ rounds can transform a subverted random function -- which disagrees with the original one at a small fraction (denoted by $\\epsilon$) of inputs -- into an object that is \\emph{crooked-indifferentiable} from a random permutation, even if the adversary is aware of all the randomness used in the transformation.","We also provide a lower bound showing that the construction cannot use fewer than $2n/\\log(1/\\epsilon)$ rounds to achieve crooked-indifferentiable security."],"url":"http://arxiv.org/abs/2404.09450v1","category":"cs.CR"}
{"created":"2024-04-15 04:20:01","title":"kNN-CLIP: Retrieval Enables Training-Free Segmentation on Continually Expanding Large Vocabularies","abstract":"Rapid advancements in continual segmentation have yet to bridge the gap of scaling to large continually expanding vocabularies under compute-constrained scenarios. We discover that traditional continual training leads to catastrophic forgetting under compute constraints, unable to outperform zero-shot segmentation methods. We introduce a novel strategy for semantic and panoptic segmentation with zero forgetting, capable of adapting to continually growing vocabularies without the need for retraining or large memory costs. Our training-free approach, kNN-CLIP, leverages a database of instance embeddings to enable open-vocabulary segmentation approaches to continually expand their vocabulary on any given domain with a single-pass through data, while only storing embeddings minimizing both compute and memory costs. This method achieves state-of-the-art mIoU performance across large-vocabulary semantic and panoptic segmentation datasets. We hope kNN-CLIP represents a step forward in enabling more efficient and adaptable continual segmentation, paving the way for advances in real-world large-vocabulary continual segmentation methods.","sentences":["Rapid advancements in continual segmentation have yet to bridge the gap of scaling to large continually expanding vocabularies under compute-constrained scenarios.","We discover that traditional continual training leads to catastrophic forgetting under compute constraints, unable to outperform zero-shot segmentation methods.","We introduce a novel strategy for semantic and panoptic segmentation with zero forgetting, capable of adapting to continually growing vocabularies without the need for retraining or large memory costs.","Our training-free approach, kNN-CLIP, leverages a database of instance embeddings to enable open-vocabulary segmentation approaches to continually expand their vocabulary on any given domain with a single-pass through data, while only storing embeddings minimizing both compute and memory costs.","This method achieves state-of-the-art mIoU performance across large-vocabulary semantic and panoptic segmentation datasets.","We hope kNN-CLIP represents a step forward in enabling more efficient and adaptable continual segmentation, paving the way for advances in real-world large-vocabulary continual segmentation methods."],"url":"http://arxiv.org/abs/2404.09447v1","category":"cs.CV"}
{"created":"2024-04-15 01:55:25","title":"$L^2$-based stability of blowup with log correction for semilinear heat equation","abstract":"We propose an alternative proof of the classical result of type-I blowup with log correction for the semilinear equation. Compared with previous proofs, we use a novel idea of enforcing stable normalizations for perturbation around the approximate profile and establish a weighted $H^k$ stability, thereby avoiding the use of a topological argument and the analysis of a linearized spectrum. Therefore, this approach can be adopted even if we only have a numerical profile and do not have explicit information on the spectrum of its linearized operator. This result generalizes the $L^2$-based stability argument to blowups that are not exactly self-similar and can be adapted to higher dimensions. Numerical results corroborate the effectiveness of our normalization, even in the large perturbation regime beyond our theoretical setting.","sentences":["We propose an alternative proof of the classical result of type-I blowup with log correction for the semilinear equation.","Compared with previous proofs, we use a novel idea of enforcing stable normalizations for perturbation around the approximate profile and establish a weighted $H^k$ stability, thereby avoiding the use of a topological argument and the analysis of a linearized spectrum.","Therefore, this approach can be adopted even if we only have a numerical profile and do not have explicit information on the spectrum of its linearized operator.","This result generalizes the $L^2$-based stability argument to blowups that are not exactly self-similar and can be adapted to higher dimensions.","Numerical results corroborate the effectiveness of our normalization, even in the large perturbation regime beyond our theoretical setting."],"url":"http://arxiv.org/abs/2404.09410v1","category":"math.AP"}
{"created":"2024-04-15 00:19:23","title":"Magnon-Skyrmion Hybrid Quantum Systems: Tailoring Interactions via Magnons","abstract":"Coherent and dissipative interactions between different quantum systems are essential for the construction of hybrid quantum systems and the investigation of novel quantum phenomena. Here, we propose and analyze a magnon-skyrmion hybrid quantum system, consisting of a micromagnet and nearby magnetic skyrmions. We predict a strong coupling mechanism between the magnonic mode of the micromagnet and the quantized helicity degree of freedom of the skyrmion. We show that with this hybrid setup it is possible to induce magnon-mediated nonreciprocal interactions and responses between distant skyrmion qubits or between skyrmion qubits and other quantum systems like superconducting qubits. This work provides a quantum platform for the investigation of diverse quantum effects and quantum information processing with magnetic microstructures.","sentences":["Coherent and dissipative interactions between different quantum systems are essential for the construction of hybrid quantum systems and the investigation of novel quantum phenomena.","Here, we propose and analyze a magnon-skyrmion hybrid quantum system, consisting of a micromagnet and nearby magnetic skyrmions.","We predict a strong coupling mechanism between the magnonic mode of the micromagnet and the quantized helicity degree of freedom of the skyrmion.","We show that with this hybrid setup it is possible to induce magnon-mediated nonreciprocal interactions and responses between distant skyrmion qubits or between skyrmion qubits and other quantum systems like superconducting qubits.","This work provides a quantum platform for the investigation of diverse quantum effects and quantum information processing with magnetic microstructures."],"url":"http://arxiv.org/abs/2404.09388v1","category":"quant-ph"}
{"created":"2024-04-14 23:38:55","title":"The effects of finite electron inertia on helicity-barrier-mediated turbulence","abstract":"Understanding the partitioning of turbulent energy between ions and electrons in weakly collisional plasmas is crucial for the accurate interpretation of observations and modelling of various astrophysical phenomena. Many such plasmas are \"imbalanced\", wherein the large-scale energy input is dominated by Alfv\\'enic fluctuations propagating in a single direction. In this paper, we demonstrate that when strongly-magnetised plasma turbulence is imbalanced, nonlinear conservation laws imply the existence of a critical value of the electron plasma beta that separates two dramatically different types of turbulence in parameter space. For betas below the critical value, the free energy injected on the largest scales is able to undergo a familiar Kolmogorov-type cascade to small scales where it is dissipated, heating electrons. For betas above the critical value, the system forms a \"helicity barrier\" that prevents the cascade from proceeding past the ion Larmor radius, causing the majority of the injected free energy to be deposited into ion heating. Physically, the helicity barrier results from the inability of the system to adjust to the disparity between the perpendicular-wavenumber scalings of the free energy and generalised helicity below the ion Larmor radius; restoring finite electron inertia can annul, or even reverse, this disparity, giving rise to the aforementioned critical beta. We relate this physics to the \"dynamic phase alignment\" mechanism, and characterise various other important features of the helicity barrier, including the nature of the nonlinear wavenumber-space fluxes, dissipation rates, and energy spectra. The existence of such a critical beta has important implications for heating, as it suggests that the dominant recipient of the turbulent energy -- ions or electrons -- can depend sensitively on the characteristics of the plasma at large scales.","sentences":["Understanding the partitioning of turbulent energy between ions and electrons in weakly collisional plasmas is crucial for the accurate interpretation of observations and modelling of various astrophysical phenomena.","Many such plasmas are \"imbalanced\", wherein the large-scale energy input is dominated by Alfv\\'enic fluctuations propagating in a single direction.","In this paper, we demonstrate that when strongly-magnetised plasma turbulence is imbalanced, nonlinear conservation laws imply the existence of a critical value of the electron plasma beta that separates two dramatically different types of turbulence in parameter space.","For betas below the critical value, the free energy injected on the largest scales is able to undergo a familiar Kolmogorov-type cascade to small scales where it is dissipated, heating electrons.","For betas above the critical value, the system forms a \"helicity barrier\" that prevents the cascade from proceeding past the ion Larmor radius, causing the majority of the injected free energy to be deposited into ion heating.","Physically, the helicity barrier results from the inability of the system to adjust to the disparity between the perpendicular-wavenumber scalings of the free energy and generalised helicity below the ion Larmor radius; restoring finite electron inertia can annul, or even reverse, this disparity, giving rise to the aforementioned critical beta.","We relate this physics to the \"dynamic phase alignment\" mechanism, and characterise various other important features of the helicity barrier, including the nature of the nonlinear wavenumber-space fluxes, dissipation rates, and energy spectra.","The existence of such a critical beta has important implications for heating, as it suggests that the dominant recipient of the turbulent energy -- ions or electrons -- can depend sensitively on the characteristics of the plasma at large scales."],"url":"http://arxiv.org/abs/2404.09380v1","category":"physics.plasm-ph"}
{"created":"2024-04-14 22:04:55","title":"Entangled nematic disclinations using multi-particle collision dynamics","abstract":"Colloids dispersed in nematic liquid crystals form topological composites in which colloid-associated defects mediate interactions while adhering to fundamental topological constraints. Better realising the promise of such materials requires numerical methods that model nematic inclusions in dynamic and complex scenarios. We employ a mesoscale approach for simulating colloids as mobile surfaces embedded in a fluctuating nematohydrodynamic medium to study the kinetics of colloidal entanglement. In addition to reproducing far-field interactions, topological properties of disclination loops are resolved to reveal their metastable states and topological transitions during relaxation towards ground state. The intrinsic hydrodynamic fluctuations distinguish formerly unexplored far-from-equilibrium disclination states, including configurations with localised positive winding profiles. The adaptability and precision of this numerical approach offers promising avenues for studying the dynamics of colloids and topological defects in designed and out-of-equilibrium situations.","sentences":["Colloids dispersed in nematic liquid crystals form topological composites in which colloid-associated defects mediate interactions while adhering to fundamental topological constraints.","Better realising the promise of such materials requires numerical methods that model nematic inclusions in dynamic and complex scenarios.","We employ a mesoscale approach for simulating colloids as mobile surfaces embedded in a fluctuating nematohydrodynamic medium to study the kinetics of colloidal entanglement.","In addition to reproducing far-field interactions, topological properties of disclination loops are resolved to reveal their metastable states and topological transitions during relaxation towards ground state.","The intrinsic hydrodynamic fluctuations distinguish formerly unexplored far-from-equilibrium disclination states, including configurations with localised positive winding profiles.","The adaptability and precision of this numerical approach offers promising avenues for studying the dynamics of colloids and topological defects in designed and out-of-equilibrium situations."],"url":"http://arxiv.org/abs/2404.09368v1","category":"cond-mat.soft"}
{"created":"2024-04-14 20:24:13","title":"Extrapolation via Sawyer-type inequalities","abstract":"We present a multi-variable extension of Rubio de Francia's restricted weak-type extrapolation theory that does not involve Rubio de Francia's iteration algorithm; instead, we rely on the following Sawyer-type inequality for the weighted Hardy-Littlewood maximal operator $M_u$:   $$ \\left \\Vert \\frac{M_u (fv)}{v} \\right \\Vert_{L^{1,\\infty}(uv)} \\leq C_{u,v} \\Vert f \\Vert_{L^1(uv)}, \\quad u, \\, uv \\in A_{\\infty}. $$   Our approach can be adapted to recover weak-type $A_{\\vec P}$ extrapolation schemes, including an endpoint result that falls outside the classical theory.   Among the applications of our work, we highlight extending outside the Banach range the well-known equivalence between restricted weak-type and weak-type for characteristic functions, and obtaining mixed and restricted weak-type bounds with $A_{p}^{\\mathcal R}$ weights for relevant families of multi-variable operators, addressing the lack in the literature of these types of estimates. We also reveal several standalone properties of the class $A_{p}^{\\mathcal R}$.","sentences":["We present a multi-variable extension of Rubio de Francia's restricted weak-type extrapolation theory that does not involve Rubio de Francia's iteration algorithm; instead, we rely on the following Sawyer-type inequality for the weighted Hardy-Littlewood maximal operator $M_u$:   $$ \\left \\Vert \\frac{M_u","(fv)}{v} \\right \\Vert_{L^{1,\\infty}(uv)} \\leq C_{u,v} \\Vert f \\Vert_{L^1(uv)}, \\quad u, \\, uv \\in A_{\\infty}.","$$   Our approach can be adapted to recover weak-type $A_{\\vec P}$ extrapolation schemes, including an endpoint result that falls outside the classical theory.   ","Among the applications of our work, we highlight extending outside the Banach range the well-known equivalence between restricted weak-type and weak-type for characteristic functions, and obtaining mixed and restricted weak-type bounds with $A_{p}^{\\mathcal R}$ weights for relevant families of multi-variable operators, addressing the lack in the literature of these types of estimates.","We also reveal several standalone properties of the class $A_{p}^{\\mathcal R}$."],"url":"http://arxiv.org/abs/2404.09351v1","category":"math.FA"}
{"created":"2024-04-14 19:45:47","title":"Towards Practical Tool Usage for Continually Learning LLMs","abstract":"Large language models (LLMs) show an innate skill for solving language based tasks. But insights have suggested an inability to adjust for information or task-solving skills becoming outdated, as their knowledge, stored directly within their parameters, remains static in time. Tool use helps by offloading work to systems that the LLM can access through an interface, but LLMs that use them still must adapt to nonstationary environments for prolonged use, as new tools can emerge and existing tools can change. Nevertheless, tools require less specialized knowledge, therefore we hypothesize they are better suited for continual learning (CL) as they rely less on parametric memory for solving tasks and instead focus on learning when to apply pre-defined tools. To verify this, we develop a synthetic benchmark and follow this by aggregating existing NLP tasks to form a more realistic testing scenario. While we demonstrate scaling model size is not a solution, regardless of tool usage, continual learning techniques can enable tool LLMs to both adapt faster while forgetting less, highlighting their potential as continual learners.","sentences":["Large language models (LLMs) show an innate skill for solving language based tasks.","But insights have suggested an inability to adjust for information or task-solving skills becoming outdated, as their knowledge, stored directly within their parameters, remains static in time.","Tool use helps by offloading work to systems that the LLM can access through an interface, but LLMs that use them still must adapt to nonstationary environments for prolonged use, as new tools can emerge and existing tools can change.","Nevertheless, tools require less specialized knowledge, therefore we hypothesize they are better suited for continual learning (CL) as they rely less on parametric memory for solving tasks and instead focus on learning when to apply pre-defined tools.","To verify this, we develop a synthetic benchmark and follow this by aggregating existing NLP tasks to form a more realistic testing scenario.","While we demonstrate scaling model size is not a solution, regardless of tool usage, continual learning techniques can enable tool LLMs to both adapt faster while forgetting less, highlighting their potential as continual learners."],"url":"http://arxiv.org/abs/2404.09339v1","category":"cs.CL"}
{"created":"2024-04-14 18:57:38","title":"Weight Copy and Low-Rank Adaptation for Few-Shot Distillation of Vision Transformers","abstract":"Few-shot knowledge distillation recently emerged as a viable approach to harness the knowledge of large-scale pre-trained models, using limited data and computational resources. In this paper, we propose a novel few-shot feature distillation approach for vision transformers. Our approach is based on two key steps. Leveraging the fact that vision transformers have a consistent depth-wise structure, we first copy the weights from intermittent layers of existing pre-trained vision transformers (teachers) into shallower architectures (students), where the intermittence factor controls the complexity of the student transformer with respect to its teacher. Next, we employ an enhanced version of Low-Rank Adaptation (LoRA) to distill knowledge into the student in a few-shot scenario, aiming to recover the information processing carried out by the skipped teacher layers. We present comprehensive experiments with supervised and self-supervised transformers as teachers, on five data sets from various domains, including natural, medical and satellite images. The empirical results confirm the superiority of our approach over competitive baselines. Moreover, the ablation results demonstrate the usefulness of each component of the proposed pipeline.","sentences":["Few-shot knowledge distillation recently emerged as a viable approach to harness the knowledge of large-scale pre-trained models, using limited data and computational resources.","In this paper, we propose a novel few-shot feature distillation approach for vision transformers.","Our approach is based on two key steps.","Leveraging the fact that vision transformers have a consistent depth-wise structure, we first copy the weights from intermittent layers of existing pre-trained vision transformers (teachers) into shallower architectures (students), where the intermittence factor controls the complexity of the student transformer with respect to its teacher.","Next, we employ an enhanced version of Low-Rank Adaptation (LoRA) to distill knowledge into the student in a few-shot scenario, aiming to recover the information processing carried out by the skipped teacher layers.","We present comprehensive experiments with supervised and self-supervised transformers as teachers, on five data sets from various domains, including natural, medical and satellite images.","The empirical results confirm the superiority of our approach over competitive baselines.","Moreover, the ablation results demonstrate the usefulness of each component of the proposed pipeline."],"url":"http://arxiv.org/abs/2404.09326v1","category":"cs.CV"}
{"created":"2024-04-14 18:51:50","title":"Correlated Mean Field Imitation Learning","abstract":"We investigate multi-agent imitation learning (IL) within the framework of mean field games (MFGs), considering the presence of time-varying correlated signals. Existing MFG IL algorithms assume demonstrations are sampled from Mean Field Nash Equilibria (MFNE), limiting their adaptability to real-world scenarios. For example, in the traffic network equilibrium influenced by public routing recommendations, recommendations introduce time-varying correlated signals into the game, not captured by MFNE and other existing correlated equilibrium concepts. To address this gap, we propose Adaptive Mean Field Correlated Equilibrium (AMFCE), a general equilibrium incorporating time-varying correlated signals. We establish the existence of AMFCE under mild conditions and prove that MFNE is a subclass of AMFCE. We further propose Correlated Mean Field Imitation Learning (CMFIL), a novel IL framework designed to recover the AMFCE, accompanied by a theoretical guarantee on the quality of the recovered policy. Experimental results, including a real-world traffic flow prediction problem, demonstrate the superiority of CMFIL over state-of-the-art IL baselines, highlighting the potential of CMFIL in understanding large population behavior under correlated signals.","sentences":["We investigate multi-agent imitation learning (IL) within the framework of mean field games (MFGs), considering the presence of time-varying correlated signals.","Existing MFG IL algorithms assume demonstrations are sampled from Mean Field Nash Equilibria (MFNE), limiting their adaptability to real-world scenarios.","For example, in the traffic network equilibrium influenced by public routing recommendations, recommendations introduce time-varying correlated signals into the game, not captured by MFNE and other existing correlated equilibrium concepts.","To address this gap, we propose Adaptive Mean Field Correlated Equilibrium (AMFCE), a general equilibrium incorporating time-varying correlated signals.","We establish the existence of AMFCE under mild conditions and prove that MFNE is a subclass of AMFCE.","We further propose Correlated Mean Field Imitation Learning (CMFIL), a novel IL framework designed to recover the AMFCE, accompanied by a theoretical guarantee on the quality of the recovered policy.","Experimental results, including a real-world traffic flow prediction problem, demonstrate the superiority of CMFIL over state-of-the-art IL baselines, highlighting the potential of CMFIL in understanding large population behavior under correlated signals."],"url":"http://arxiv.org/abs/2404.09324v1","category":"cs.MA"}
{"created":"2024-04-14 17:59:08","title":"Exclusive-or encoded algebraic structure for efficient quantum dynamics","abstract":"We propose a formalism that captures the algebraic structure of many-body two-level quantum systems, and directly motivates an efficient numerical method. This formalism is based on the binary representation of the enumeration-indices of the elements of the corresponding Lie algebra. The action of arbitrarily large elements of that algebra reduces to a few bit-wise exclusive-or operations. This formalism naturally produces sparse representations of many-body density operators, the size of which we control through a dynamic truncation method. We demonstrate how this formalism applies to real-time evolution, dissipative Lindblad action, imaginary-time evolution, and projective measurement processes. We find that this approach to calculating quantum dynamics scales close to linearly with the number of non-zero components in the density operator. We refer to this exclusive-or represented quantum algebra as ORQA. As a proof of concept, we provide a numerical demonstration of this formalism by simulating quantum annealing processes for the maximum independent set problem for up to 22 two-level systems.","sentences":["We propose a formalism that captures the algebraic structure of many-body two-level quantum systems, and directly motivates an efficient numerical method.","This formalism is based on the binary representation of the enumeration-indices of the elements of the corresponding Lie algebra.","The action of arbitrarily large elements of that algebra reduces to a few bit-wise exclusive-or operations.","This formalism naturally produces sparse representations of many-body density operators, the size of which we control through a dynamic truncation method.","We demonstrate how this formalism applies to real-time evolution, dissipative Lindblad action, imaginary-time evolution, and projective measurement processes.","We find that this approach to calculating quantum dynamics scales close to linearly with the number of non-zero components in the density operator.","We refer to this exclusive-or represented quantum algebra as ORQA.","As a proof of concept, we provide a numerical demonstration of this formalism by simulating quantum annealing processes for the maximum independent set problem for up to 22 two-level systems."],"url":"http://arxiv.org/abs/2404.09312v1","category":"cond-mat.other"}
{"created":"2024-04-15 12:51:51","title":"Layered Uploading for Quantum Convolutional Neural Networks","abstract":"Continuing our analysis of quantum machine learning applied to our use-case of malware detection, we investigate the potential of quantum convolutional neural networks. More precisely, we propose a new architecture where data is uploaded all along the quantum circuit. This allows us to use more features from the data, hence giving to the algorithm more information, without having to increase the number of qubits that we use for the quantum circuit. This approach is motivated by the fact that we do not always have great amounts of data, and that quantum computers are currently restricted in their number of logical qubits.","sentences":["Continuing our analysis of quantum machine learning applied to our use-case of malware detection, we investigate the potential of quantum convolutional neural networks.","More precisely, we propose a new architecture where data is uploaded all along the quantum circuit.","This allows us to use more features from the data, hence giving to the algorithm more information, without having to increase the number of qubits that we use for the quantum circuit.","This approach is motivated by the fact that we do not always have great amounts of data, and that quantum computers are currently restricted in their number of logical qubits."],"url":"http://arxiv.org/abs/2404.09750v1","category":"quant-ph"}
{"created":"2024-04-15 12:51:03","title":"Connectivity in Symmetric Semi-Algebraic Sets","abstract":"Semi-algebraic set is a subset of the real space defined by polynomial equations and inequalities. In this paper, we consider the problem of deciding whether two given points in a semi-algebraic set are connected. We restrict to the case when all equations and inequalities are invariant under the action of the symmetric group and their degrees at most $d<n$, where $n$ is the number of variables. Additionally, we assume that the two points are in the same fundamental domain of the action of the symmetric group, by assuming that the coordinates of two given points are sorted in non-decreasing order. We construct and analyze an algorithm that solves this problem, by taking advantage of the group action, and has a complexity being polynomial in $n$.","sentences":["Semi-algebraic set is a subset of the real space defined by polynomial equations and inequalities.","In this paper, we consider the problem of deciding whether two given points in a semi-algebraic set are connected.","We restrict to the case when all equations and inequalities are invariant under the action of the symmetric group and their degrees at most $d<n$, where $n$ is the number of variables.","Additionally, we assume that the two points are in the same fundamental domain of the action of the symmetric group, by assuming that the coordinates of two given points are sorted in non-decreasing order.","We construct and analyze an algorithm that solves this problem, by taking advantage of the group action, and has a complexity being polynomial in $n$."],"url":"http://arxiv.org/abs/2404.09749v1","category":"cs.SC"}
{"created":"2024-04-15 12:47:23","title":"Gradient descent for unbounded convex functions on Hadamard manifolds and its applications to scaling problems","abstract":"In this paper, we study asymptotic behaviors of continuous-time and discrete-time gradient flows of a ``lower-unbounded\" convex function $f$ on a Hadamard manifold $M$, particularly, their convergence properties to the boundary $M^{\\infty}$ at infinity of $M$. We establish a duality theorem that the infimum of the gradient-norm $\\|\\nabla f(x)\\|$ of $f$ over $M$ is equal to the supremum of the negative of the recession function $f^{\\infty}$ of $f$ over the boundary $M^{\\infty}$, provided the infimum is positive. Further, the infimum and the supremum are obtained by the limits of the gradient flows of $f$, Our results feature convex-optimization ingredients of the moment-weight inequality for reductive group actions by Georgoulas, Robbin, and Salamon,and are applied to noncommutative optimization by B\\\"urgisser et al. FOCS 2019. We show that the gradient descent of the Kempf-Ness function for an unstable orbit converges to a 1-parameter subgroup in the Hilbert-Mumford criterion, and the associated moment-map sequence converges to the mimimum-norm point of the moment polytope. We show further refinements for operator scaling -- the left-right action on a matrix tuple $A= (A_1,A_2,\\ldots,A_N)$. We characterize the gradient-flow limit of operator scaling via a vector-space generalization of the classical Dulmage-Mendelsohn decomposition of a bipartite graph. Also, for a special case of $N = 2$, we reveal that this limit determines the Kronecker canonical form of matrix pencils $s A_1+A_2$.","sentences":["In this paper, we study asymptotic behaviors of continuous-time and discrete-time gradient flows of a ``lower-unbounded\" convex function $f$ on a Hadamard manifold $M$, particularly, their convergence properties to the boundary $M^{\\infty}$ at infinity of $M$. We establish a duality theorem that the infimum of the gradient-norm $\\|\\nabla f(x)\\|$ of $f$ over $M$ is equal to the supremum of the negative of the recession function $f^{\\infty}$ of $f$ over the boundary $M^{\\infty}$, provided the infimum is positive.","Further, the infimum and the supremum are obtained by the limits of the gradient flows of $f$, Our results feature convex-optimization ingredients of the moment-weight inequality for reductive group actions by Georgoulas, Robbin, and Salamon,and are applied to noncommutative optimization by B\\\"urgisser et al. FOCS 2019.","We show that the gradient descent of the Kempf-Ness function for an unstable orbit converges to a 1-parameter subgroup in the Hilbert-Mumford criterion, and the associated moment-map sequence converges to the mimimum-norm point of the moment polytope.","We show further refinements for operator scaling -- the left-right action on a matrix tuple $A= (A_1,A_2,\\ldots,A_N)$. We characterize the gradient-flow limit of operator scaling via a vector-space generalization of the classical Dulmage-Mendelsohn decomposition of a bipartite graph.","Also, for a special case of $N = 2$, we reveal that this limit determines the Kronecker canonical form of matrix pencils $s A_1+A_2$."],"url":"http://arxiv.org/abs/2404.09746v1","category":"math.OC"}
{"created":"2024-04-15 12:50:15","title":"Optimizing Off-Axis Fields for Vector Magnetometry with Point Defects","abstract":"Vector magnetometry is an essential tool in characterizing the distribution of currents and magnetization in a broad range of systems. Point defect sensors, like the nitrogen vacancy (NV) center in diamond, have demonstrated impressive sensitivity and spatial resolution for detecting these fields. Measuring the vector field at a single point in space using single defects, however, remains an outstanding challenge. We demonstrate that careful optimization of the static bias field can enable simultaneous measurement of multiple magnetic field components with enhanced sensitivity by leveraging the nonlinear Zeeman shift from transverse magnetic fields. This work quantifies the trade-off between the increased frequency shift from second-order Zeeman effects with decreasing contrast as off-axis field components increase, demonstrating the measurement of multiple components of the magnetic field from an exemplar antiferromagnet with a complex magnetic texture.","sentences":["Vector magnetometry is an essential tool in characterizing the distribution of currents and magnetization in a broad range of systems.","Point defect sensors, like the nitrogen vacancy (NV) center in diamond, have demonstrated impressive sensitivity and spatial resolution for detecting these fields.","Measuring the vector field at a single point in space using single defects, however, remains an outstanding challenge.","We demonstrate that careful optimization of the static bias field can enable simultaneous measurement of multiple magnetic field components with enhanced sensitivity by leveraging the nonlinear Zeeman shift from transverse magnetic fields.","This work quantifies the trade-off between the increased frequency shift from second-order Zeeman effects with decreasing contrast as off-axis field components increase, demonstrating the measurement of multiple components of the magnetic field from an exemplar antiferromagnet with a complex magnetic texture."],"url":"http://arxiv.org/abs/2404.09747v1","category":"cond-mat.mes-hall"}
{"created":"2024-04-15 12:34:51","title":"Weighted Sum-Rate Maximization for Movable Antenna-Enhanced Wireless Networks","abstract":"This letter investigates the weighted sum rate maximization problem in movable antenna (MA)-enhanced systems. To reduce the computational complexity, we transform it into a more tractable weighted minimum mean square error (WMMSE) problem well-suited for MA. We then adopt the WMMSE algorithm and majorization-minimization algorithm to optimize the beamforming and antenna positions, respectively. Moreover, we propose a planar movement mode, which constrains each MA to a specified area, we obtain a low-complexity closed-form solution. Numerical results demonstrate that the MA-enhanced system outperforms the conventional system. Besides, the computation time for the planar movement mode is reduced by approximately 30\\% at a little performance expense.","sentences":["This letter investigates the weighted sum rate maximization problem in movable antenna (MA)-enhanced systems.","To reduce the computational complexity, we transform it into a more tractable weighted minimum mean square error (WMMSE) problem well-suited for MA.","We then adopt the WMMSE algorithm and majorization-minimization algorithm to optimize the beamforming and antenna positions, respectively.","Moreover, we propose a planar movement mode, which constrains each MA to a specified area, we obtain a low-complexity closed-form solution.","Numerical results demonstrate that the MA-enhanced system outperforms the conventional system.","Besides, the computation time for the planar movement mode is reduced by approximately 30\\% at a little performance expense."],"url":"http://arxiv.org/abs/2404.09734v1","category":"cs.IT"}
{"created":"2024-04-15 12:26:37","title":"Minimal Autocorrelation in Hybrid Monte Carlo simulations using Exact Fourier Acceleration","abstract":"The hybrid Monte Carlo (HMC) algorithm is a ubiquitous method in computational physics with applications ranging from condensed matter to lattice QCD and beyond. However, HMC simulations often suffer from long autocorrelation times, severely reducing their efficiency. In this work two of the main sources of autocorrelations are identified and eliminated. The first source is the sampling of the canonical momenta from a sub-optimal normal distribution, the second is a badly chosen trajectory length. Analytic solutions to both problems are presented and implemented in the exact Fourier acceleration (EFA) method. It completely removes autocorrelations for near-harmonic potentials and consistently yields (close-to-) optimal results for numerical simulations of the Su-Schrieffer-Heeger and the Ising models as well as in lattice gauge theory, in some cases reducing the autocorrelation by multiple orders of magnitude. EFA is advantageous for and easily applicable to any HMC simulation of an action that includes a quadratic part.","sentences":["The hybrid Monte Carlo (HMC) algorithm is a ubiquitous method in computational physics with applications ranging from condensed matter to lattice QCD and beyond.","However, HMC simulations often suffer from long autocorrelation times, severely reducing their efficiency.","In this work two of the main sources of autocorrelations are identified and eliminated.","The first source is the sampling of the canonical momenta from a sub-optimal normal distribution, the second is a badly chosen trajectory length.","Analytic solutions to both problems are presented and implemented in the exact Fourier acceleration (EFA) method.","It completely removes autocorrelations for near-harmonic potentials and consistently yields (close-to-) optimal results for numerical simulations of the Su-Schrieffer-Heeger and the Ising models as well as in lattice gauge theory, in some cases reducing the autocorrelation by multiple orders of magnitude.","EFA is advantageous for and easily applicable to any HMC simulation of an action that includes a quadratic part."],"url":"http://arxiv.org/abs/2404.09723v1","category":"hep-lat"}
{"created":"2024-04-15 12:25:11","title":"Offshore power and hydrogen networks for Europe's North Sea","abstract":"The European North Sea has a vast renewable energy potential and can be a powerhouse for Europe's energy transition. However, currently there is uncertainty about how much offshore wind energy can be integrated, whether offshore grids should be meshed and to what extent offshore hydrogen should play a role. To address these questions, we use the open-source energy system optimization model PyPSA-Eur to model a European carbon-neutral sector-coupled energy system in high spatial and temporal resolution. We let the model endogenously decide how much offshore wind is deployed and which infrastructure is used to integrate the offshore wind. We find that with point-to-point connections like we have today, 310 GW offshore wind can be integrated in the North Sea. However, if we allow meshed networks and hydrogen, we find that this can be raised to 420 GW with cost savings up to 15 billion euros per year. Furthermore, we only observe significant amounts of up to 75 GW of floating wind turbines in the North Sea if we have offshore hydrogen production. Generally, the model opts for offshore wind integration through a mix of both electricity and hydrogen infrastructure. However, the bulk of the offshore energy is transported as hydrogen, which is twice as much as the amount transported as electricity. Moreover, we find that the offshore power network is mainly used for offshore wind integration, with only a small portion used for inter-country transmission.","sentences":["The European North Sea has a vast renewable energy potential and can be a powerhouse for Europe's energy transition.","However, currently there is uncertainty about how much offshore wind energy can be integrated, whether offshore grids should be meshed and to what extent offshore hydrogen should play a role.","To address these questions, we use the open-source energy system optimization model PyPSA-Eur to model a European carbon-neutral sector-coupled energy system in high spatial and temporal resolution.","We let the model endogenously decide how much offshore wind is deployed and which infrastructure is used to integrate the offshore wind.","We find that with point-to-point connections like we have today, 310 GW offshore wind can be integrated in the North Sea.","However, if we allow meshed networks and hydrogen, we find that this can be raised to 420 GW with cost savings up to 15 billion euros per year.","Furthermore, we only observe significant amounts of up to 75 GW of floating wind turbines in the North Sea if we have offshore hydrogen production.","Generally, the model opts for offshore wind integration through a mix of both electricity and hydrogen infrastructure.","However, the bulk of the offshore energy is transported as hydrogen, which is twice as much as the amount transported as electricity.","Moreover, we find that the offshore power network is mainly used for offshore wind integration, with only a small portion used for inter-country transmission."],"url":"http://arxiv.org/abs/2404.09721v1","category":"physics.soc-ph"}
{"created":"2024-04-15 12:18:09","title":"Optimal Cut-Point Estimation for functional digital biomarkers: Application to Continuous Glucose Monitoring","abstract":"Establish optimal cut points plays a crucial role in epidemiology and biomarker discovery, enabling the development of effective and practical clinical decision criteria. While there is extensive literature to define optimal cut off over scalar biomarkers, there is a notable lack of general methodologies for analyzing statistical objects in more complex spaces of functions and graphs, which are increasingly relevant in digital health applications. This paper proposes a new general methodology to define optimal cut points for random objects in separable Hilbert spaces. The paper is motivated by the need for creating new clinical rules for diabetes mellitus disease, exploiting the functional information of a continuous diabetes monitor (CGM) as a digital biomarker. More specifically, we provide the functional cut off to identify diabetes cases with CGM information based on glucose distributional functional representations.","sentences":["Establish optimal cut points plays a crucial role in epidemiology and biomarker discovery, enabling the development of effective and practical clinical decision criteria.","While there is extensive literature to define optimal cut off over scalar biomarkers, there is a notable lack of general methodologies for analyzing statistical objects in more complex spaces of functions and graphs, which are increasingly relevant in digital health applications.","This paper proposes a new general methodology to define optimal cut points for random objects in separable Hilbert spaces.","The paper is motivated by the need for creating new clinical rules for diabetes mellitus disease, exploiting the functional information of a continuous diabetes monitor (CGM) as a digital biomarker.","More specifically, we provide the functional cut off to identify diabetes cases with CGM information based on glucose distributional functional representations."],"url":"http://arxiv.org/abs/2404.09716v1","category":"stat.ME"}
{"created":"2024-04-15 12:12:25","title":"Online Multi-level Aggregation with Delays and Stochastic Arrivals","abstract":"This paper presents a new research direction for online Multi-Level Aggregation (MLA) with delays. In this problem, we are given an edge-weighted rooted tree $T$, and we have to serve a sequence of requests arriving at its vertices in an online manner. Each request $r$ is characterized by two parameters: its arrival time $t(r)$ and location $l(r)$ (a vertex). Once a request $r$ arrives, we can either serve it immediately or postpone this action until any time $t > t(r)$. We can serve several pending requests at the same time, and the service cost of a service corresponds to the weight of the subtree that contains all the requests served and the root of $T$. Postponing the service of a request $r$ to time $t > t(r)$ generates an additional delay cost of $t - t(r)$. The goal is to serve all requests in an online manner such that the total cost (i.e., the total sum of service and delay costs) is minimized. The current best algorithm for this problem achieves a competitive ratio of $O(d^2)$ (Azar and Touitou, FOCS'19), where $d$ denotes the depth of the tree.   Here, we consider a stochastic version of MLA where the requests follow a Poisson arrival process. We present a deterministic online algorithm which achieves a constant ratio of expectations, meaning that the ratio between the expected costs of the solution generated by our algorithm and the optimal offline solution is bounded by a constant. Our algorithm is obtained by carefully combining two strategies. In the first one, we plan periodic oblivious visits to the subset of frequent vertices, whereas in the second one, we greedily serve the pending requests in the remaining vertices. This problem is complex enough to demonstrate a very rare phenomenon that ``single-minded\" or ``sample-average\" strategies are not enough in stochastic optimization.","sentences":["This paper presents a new research direction for online Multi-Level Aggregation (MLA) with delays.","In this problem, we are given an edge-weighted rooted tree $T$, and we have to serve a sequence of requests arriving at its vertices in an online manner.","Each request $r$ is characterized by two parameters: its arrival time $t(r)$ and location $l(r)$ (a vertex).","Once a request $r$ arrives, we can either serve it immediately or postpone this action until any time $t > t(r)$. We can serve several pending requests at the same time, and the service cost of a service corresponds to the weight of the subtree that contains all the requests served and the root of $T$. Postponing the service of a request $r$ to time $t >","t(r)$ generates an additional delay cost of $t - t(r)$. The goal is to serve all requests in an online manner such that the total cost (i.e., the total sum of service and delay costs) is minimized.","The current best algorithm for this problem achieves a competitive ratio of $O(d^2)$ (Azar and Touitou, FOCS'19), where $d$ denotes the depth of the tree.   ","Here, we consider a stochastic version of MLA where the requests follow a Poisson arrival process.","We present a deterministic online algorithm which achieves a constant ratio of expectations, meaning that the ratio between the expected costs of the solution generated by our algorithm and the optimal offline solution is bounded by a constant.","Our algorithm is obtained by carefully combining two strategies.","In the first one, we plan periodic oblivious visits to the subset of frequent vertices, whereas in the second one, we greedily serve the pending requests in the remaining vertices.","This problem is complex enough to demonstrate a very rare phenomenon that ``single-minded\" or ``sample-average\" strategies are not enough in stochastic optimization."],"url":"http://arxiv.org/abs/2404.09711v1","category":"cs.DS"}
{"created":"2024-04-15 12:10:07","title":"Nonconvergence of a sum-of-squares hierarchy for global polynomial optimization based on push-forward measures","abstract":"Let $\\mathbf{X} \\subseteq \\mathbb{R}^n$ be a closed set, and consider the problem of computing the minimum $f_{\\min}$ of a polynomial $f$ on $\\mathbf{X}$. Given a measure $\\mu$ supported on $\\mathbf{X}$, Lasserre (SIAM J. Optim. 21(3), 2011) proposes a decreasing sequence of upper bounds on $f_{\\min}$, each of which may be computed by solving a semidefinite program. When $\\mathbf{X}$ is compact, these bounds converge to $f_{\\min}$ under minor assumptions on $\\mu$. Later, Lasserre (Math. Program. 190, 2020) introduces a related, but far more economical sequence of upper bounds which rely on the push-forward measure of $\\mu$ by $f$. While these new bounds are weaker a priori, they actually achieve similar asymptotic convergence rates on compact sets. In this work, we show that no such free lunch exists in the non-compact setting. While convergence of the standard bounds to $f_{\\min}$ is guaranteed when $\\mathbf{X} = \\mathbb{R}^n$ and $\\mu$ is a Gaussian distribution, we prove that the bounds relying on the push-forward measure fail to converge to $f_{\\min}$ in that setting already for polynomials of degree $6$.","sentences":["Let $\\mathbf{X} \\subseteq \\mathbb{R}^n$ be a closed set, and consider the problem of computing the minimum $f_{\\min}$ of a polynomial $f$ on $\\mathbf{X}$. Given a measure $\\mu$ supported on $\\mathbf{X}$, Lasserre (SIAM J. Optim. 21(3), 2011) proposes a decreasing sequence of upper bounds on $f_{\\min}$, each of which may be computed by solving a semidefinite program.","When $\\mathbf{X}$ is compact, these bounds converge to $f_{\\min}$ under minor assumptions on $\\mu$. Later, Lasserre (Math. Program.","190, 2020) introduces a related, but far more economical sequence of upper bounds which rely on the push-forward measure of $\\mu$ by $f$. While these new bounds are weaker a priori, they actually achieve similar asymptotic convergence rates on compact sets.","In this work, we show that no such free lunch exists in the non-compact setting.","While convergence of the standard bounds to $f_{\\min}$ is guaranteed when $\\mathbf{X} = \\mathbb{R}^n$ and $\\mu$ is a Gaussian distribution, we prove that the bounds relying on the push-forward measure fail to converge to $f_{\\min}$ in that setting already for polynomials of degree $6$."],"url":"http://arxiv.org/abs/2404.09710v1","category":"math.OC"}
{"created":"2024-04-15 12:01:35","title":"Higher-order Sobolev embeddings into spaces of Campanato and Morrey type","abstract":"Necessary and sufficient conditions are offered for Sobolev type spaces built on rearrangement-invariant spaces to be continuously embedded into (generalized) Campanato and Morrey spaces on open subsets of the $n$-dimensional Euclidean space. As a consequence, the optimal target and domain spaces in the relevant embeddings are identified. Our general criteria are implemented to derive sharp embeddings in the class of Orlicz-Sobolev spaces.","sentences":["Necessary and sufficient conditions are offered for Sobolev type spaces built on rearrangement-invariant spaces to be continuously embedded into (generalized)","Campanato and Morrey spaces on open subsets of the $n$-dimensional Euclidean space.","As a consequence, the optimal target and domain spaces in the relevant embeddings are identified.","Our general criteria are implemented to derive sharp embeddings in the class of Orlicz-Sobolev spaces."],"url":"http://arxiv.org/abs/2404.09702v1","category":"math.FA"}
{"created":"2024-04-15 11:51:20","title":"MAM-STM: A software for autonomous control of single moieties towards specific surface positions","abstract":"In this publication we introduce MAM-STM, a software to autonomously manipulate arbitrary moieties towards specific positions on a metal surface utilizing the tip of a scanning tunneling microscope (STM). Finding the optimal manipulation parameters for a specific moiety is challenging and time consuming, even for human experts. MAM-STM combines autonomous data acquisition with a sophisticated Q-learning implementation to determine the optimal bias voltage, the z-approach distance, and the tip position relative to the moiety. This then allows to arrange single molecules and atoms at will. In this work, we provide a tutorial based on a simulated response to offer a comprehensive explanation on how to use and customize MAM-STM. Additionally, we assess the performance of the machine learning algorithm by benchmarking it within a simulated stochastic environment.","sentences":["In this publication we introduce MAM-STM, a software to autonomously manipulate arbitrary moieties towards specific positions on a metal surface utilizing the tip of a scanning tunneling microscope (STM).","Finding the optimal manipulation parameters for a specific moiety is challenging and time consuming, even for human experts.","MAM-STM combines autonomous data acquisition with a sophisticated Q-learning implementation to determine the optimal bias voltage, the z-approach distance, and the tip position relative to the moiety.","This then allows to arrange single molecules and atoms at will.","In this work, we provide a tutorial based on a simulated response to offer a comprehensive explanation on how to use and customize MAM-STM.","Additionally, we assess the performance of the machine learning algorithm by benchmarking it within a simulated stochastic environment."],"url":"http://arxiv.org/abs/2404.09694v1","category":"physics.app-ph"}
{"created":"2024-04-15 11:37:40","title":"AntBatchInfer: Elastic Batch Inference in the Kubernetes Cluster","abstract":"Offline batch inference is a common task in the industry for deep learning applications, but it can be challenging to ensure stability and performance when dealing with large amounts of data and complicated inference pipelines. This paper demonstrated AntBatchInfer, an elastic batch inference framework, which is specially optimized for the non-dedicated cluster. AntBatchInfer addresses these challenges by providing multi-level fault-tolerant capabilities, enabling the stable execution of versatile and long-running inference tasks. It also improves inference efficiency by pipelining, intra-node, and inter-node scaling. It further optimizes the performance in complicated multiple-model batch inference scenarios. Through extensive experiments and real-world statistics, we demonstrate the superiority of our framework in terms of stability and efficiency. In the experiment, it outperforms the baseline by at least $2\\times$ and $6\\times$ in the single-model or multiple-model batch inference. Also, it is widely used at Ant Group, with thousands of daily jobs from various scenarios, including DLRM, CV, and NLP, which proves its practicability in the industry.","sentences":["Offline batch inference is a common task in the industry for deep learning applications, but it can be challenging to ensure stability and performance when dealing with large amounts of data and complicated inference pipelines.","This paper demonstrated AntBatchInfer, an elastic batch inference framework, which is specially optimized for the non-dedicated cluster.","AntBatchInfer addresses these challenges by providing multi-level fault-tolerant capabilities, enabling the stable execution of versatile and long-running inference tasks.","It also improves inference efficiency by pipelining, intra-node, and inter-node scaling.","It further optimizes the performance in complicated multiple-model batch inference scenarios.","Through extensive experiments and real-world statistics, we demonstrate the superiority of our framework in terms of stability and efficiency.","In the experiment, it outperforms the baseline by at least $2\\times$ and $6\\times$ in the single-model or multiple-model batch inference.","Also, it is widely used at Ant Group, with thousands of daily jobs from various scenarios, including DLRM, CV, and NLP, which proves its practicability in the industry."],"url":"http://arxiv.org/abs/2404.09686v1","category":"cs.LG"}
{"created":"2024-04-15 11:36:38","title":"Testing trajectory-based determinism via time probability distributions","abstract":"It is notorious that quantum mechanics (QM) cannot predict well-defined values for all physical quantities. Less well-known, however, is the fact that QM is unable to furnish probabilistic predictions even in emblematic scenarios such as the double-slit experiment. In contrast, equipped with postulate trajectories, Bohmian mechanics (BM) has inherited more predictive power. It follows that, contrary to common belief, QM and BM are not just different interpretations but distinct theories. This work formalizes the aforementioned assertions and illustrates them through three case studies: (i) free particle, (ii) free fall under a uniform gravitational field, and (iii) the double-slit experiment. Specifically, we introduce a prescription for constructing a flight-time probability distribution within generic trajectory-equipped theories. We then apply our formalism to BM and derive probability distributions that are unreachable by QM. Our results can, in principle, be tested against real experiments, thereby assessing the validity of Bohmian trajectories.","sentences":["It is notorious that quantum mechanics (QM) cannot predict well-defined values for all physical quantities.","Less well-known, however, is the fact that QM is unable to furnish probabilistic predictions even in emblematic scenarios such as the double-slit experiment.","In contrast, equipped with postulate trajectories, Bohmian mechanics (BM) has inherited more predictive power.","It follows that, contrary to common belief, QM and BM are not just different interpretations but distinct theories.","This work formalizes the aforementioned assertions and illustrates them through three case studies: (i) free particle, (ii) free fall under a uniform gravitational field, and (iii) the double-slit experiment.","Specifically, we introduce a prescription for constructing a flight-time probability distribution within generic trajectory-equipped theories.","We then apply our formalism to BM and derive probability distributions that are unreachable by QM.","Our results can, in principle, be tested against real experiments, thereby assessing the validity of Bohmian trajectories."],"url":"http://arxiv.org/abs/2404.09684v1","category":"quant-ph"}
{"created":"2024-04-15 11:14:25","title":"A Generic Trajectory Planning Method for Constrained All-Wheel-Steering Robots","abstract":"This paper presents a trajectory planning method for wheeled robots with fixed steering axes while the steering angle of each wheel is constrained. In the past, All-Wheel-Steering(AWS) robots, incorporating modes such as rotation-free translation maneuvers, in-situ rotational maneuvers, and proportional steering, exhibited inefficient performance due to time-consuming mode switches. This inefficiency arises from wheel rotation constraints and inter-wheel cooperation requirements. The direct application of a holonomic moving strategy can lead to significant slip angles or even structural failure. Additionally, the limited steering range of AWS wheeled robots exacerbates nonlinearity issues, thereby complicating control processes. To address these challenges, we developed a novel planning method termed Constrained AWS(C-AWS), which integrates second-order discrete search with predictive control techniques. Experimental results demonstrate that our method adeptly generates feasible and smooth trajectories for C-AWS while adhering to steering angle constraints.","sentences":["This paper presents a trajectory planning method for wheeled robots with fixed steering axes while the steering angle of each wheel is constrained.","In the past, All-Wheel-Steering(AWS) robots, incorporating modes such as rotation-free translation maneuvers, in-situ rotational maneuvers, and proportional steering, exhibited inefficient performance due to time-consuming mode switches.","This inefficiency arises from wheel rotation constraints and inter-wheel cooperation requirements.","The direct application of a holonomic moving strategy can lead to significant slip angles or even structural failure.","Additionally, the limited steering range of AWS wheeled robots exacerbates nonlinearity issues, thereby complicating control processes.","To address these challenges, we developed a novel planning method termed Constrained AWS(C-AWS), which integrates second-order discrete search with predictive control techniques.","Experimental results demonstrate that our method adeptly generates feasible and smooth trajectories for C-AWS while adhering to steering angle constraints."],"url":"http://arxiv.org/abs/2404.09677v2","category":"cs.RO"}
{"created":"2024-04-15 10:44:31","title":"Learn Your Reference Model for Real Good Alignment","abstract":"The complexity of the alignment problem stems from the fact that existing methods are unstable. Researchers continuously invent various tricks to address this shortcoming. For instance, in the fundamental Reinforcement Learning From Human Feedback (RLHF) technique of Language Model alignment, in addition to reward maximization, the Kullback-Leibler divergence between the trainable policy and the SFT policy is minimized. This addition prevents the model from being overfitted to the Reward Model (RM) and generating texts that are out-of-domain for the RM. The Direct Preference Optimization (DPO) method reformulates the optimization task of RLHF and eliminates the Reward Model while tacitly maintaining the requirement for the policy to be close to the SFT policy. In our paper, we argue that this implicit limitation in the DPO method leads to sub-optimal results. We propose a new method called Trust Region DPO (TR-DPO), which updates the reference policy during training. With such a straightforward update, we demonstrate the effectiveness of TR-DPO against DPO on the Anthropic HH and TLDR datasets. We show that TR-DPO outperforms DPO by up to 19%, measured by automatic evaluation with GPT-4. The new alignment approach that we propose allows us to improve the quality of models across several parameters at once, such as coherence, correctness, level of detail, helpfulness, and harmlessness.","sentences":["The complexity of the alignment problem stems from the fact that existing methods are unstable.","Researchers continuously invent various tricks to address this shortcoming.","For instance, in the fundamental Reinforcement Learning From Human Feedback (RLHF) technique of Language Model alignment, in addition to reward maximization, the Kullback-Leibler divergence between the trainable policy and the SFT policy is minimized.","This addition prevents the model from being overfitted to the Reward Model (RM) and generating texts that are out-of-domain for the RM.","The Direct Preference Optimization (DPO) method reformulates the optimization task of RLHF and eliminates the Reward Model while tacitly maintaining the requirement for the policy to be close to the SFT policy.","In our paper, we argue that this implicit limitation in the DPO method leads to sub-optimal results.","We propose a new method called Trust Region DPO (TR-DPO), which updates the reference policy during training.","With such a straightforward update, we demonstrate the effectiveness of TR-DPO against DPO on the Anthropic HH and TLDR datasets.","We show that TR-DPO outperforms DPO by up to 19%, measured by automatic evaluation with GPT-4.","The new alignment approach that we propose allows us to improve the quality of models across several parameters at once, such as coherence, correctness, level of detail, helpfulness, and harmlessness."],"url":"http://arxiv.org/abs/2404.09656v1","category":"cs.LG"}
{"created":"2024-04-15 10:04:15","title":"Bridging Vision and Language Spaces with Assignment Prediction","abstract":"This paper introduces VLAP, a novel approach that bridges pretrained vision models and large language models (LLMs) to make frozen LLMs understand the visual world. VLAP transforms the embedding space of pretrained vision models into the LLMs' word embedding space using a single linear layer for efficient and general-purpose visual and language understanding. Specifically, we harness well-established word embeddings to bridge two modality embedding spaces. The visual and text representations are simultaneously assigned to a set of word embeddings within pretrained LLMs by formulating the assigning procedure as an optimal transport problem. We predict the assignment of one modality from the representation of another modality data, enforcing consistent assignments for paired multimodal data. This allows vision and language representations to contain the same information, grounding the frozen LLMs' word embedding space in visual data. Moreover, a robust semantic taxonomy of LLMs can be preserved with visual data since the LLMs interpret and reason linguistic information from correlations between word embeddings. Experimental results show that VLAP achieves substantial improvements over the previous linear transformation-based approaches across a range of vision-language tasks, including image captioning, visual question answering, and cross-modal retrieval. We also demonstrate the learned visual representations hold a semantic taxonomy of LLMs, making visual semantic arithmetic possible.","sentences":["This paper introduces VLAP, a novel approach that bridges pretrained vision models and large language models (LLMs) to make frozen LLMs understand the visual world.","VLAP transforms the embedding space of pretrained vision models into the LLMs' word embedding space using a single linear layer for efficient and general-purpose visual and language understanding.","Specifically, we harness well-established word embeddings to bridge two modality embedding spaces.","The visual and text representations are simultaneously assigned to a set of word embeddings within pretrained LLMs by formulating the assigning procedure as an optimal transport problem.","We predict the assignment of one modality from the representation of another modality data, enforcing consistent assignments for paired multimodal data.","This allows vision and language representations to contain the same information, grounding the frozen LLMs' word embedding space in visual data.","Moreover, a robust semantic taxonomy of LLMs can be preserved with visual data since the LLMs interpret and reason linguistic information from correlations between word embeddings.","Experimental results show that VLAP achieves substantial improvements over the previous linear transformation-based approaches across a range of vision-language tasks, including image captioning, visual question answering, and cross-modal retrieval.","We also demonstrate the learned visual representations hold a semantic taxonomy of LLMs, making visual semantic arithmetic possible."],"url":"http://arxiv.org/abs/2404.09632v1","category":"cs.CV"}
{"created":"2024-04-15 10:00:41","title":"Optimal design of ride-pooling as on-demand feeder services","abstract":"The technology-enabled ride-pooling (RP) is designed as an on-demand feeder service to connect remote areas to transit terminals (or activity centers). We propose the so-called ``hold-dispatch'' operation strategy, which imposes a target number of shared rides (termed the ride-pooling size) for each vehicle to enhance RP's transportation efficiency. Analytical models are formulated at the planning level to estimate the costs of the RP operator and the patrons. Accordingly, the design problem is constructed to minimize the total system cost concerning the system layout (i.e., in terms of service zone partitioning), resource deployment (i.e., fleet size), and operational decision (i.e., ride-pooling size). The proposed models admit spatial heterogeneity arising from the non-uniformity of demand distributions and service locations, and can furnish heterogeneous designs. Closed-form formulas for the optimal zoning and fleet size are developed, which unveil fundamental insights regarding the impacts of key operating factors (e.g., demand density and distance to the terminal). Extensive numerical experiments demonstrate (i) the effectiveness of heterogeneous service designs and (ii) the advantage of the proposed RP service with hold-dispatch strategy over alternative designs studied in the literature, i.e., RP with a ``quick-dispatch'' strategy and flexible-route transit, in a wide range of operating scenarios. These findings can assist transportation network companies and transit agencies in successfully integrating RP and transit services.","sentences":["The technology-enabled ride-pooling (RP) is designed as an on-demand feeder service to connect remote areas to transit terminals (or activity centers).","We propose the so-called ``hold-dispatch'' operation strategy, which imposes a target number of shared rides (termed the ride-pooling size) for each vehicle to enhance RP's transportation efficiency.","Analytical models are formulated at the planning level to estimate the costs of the RP operator and the patrons.","Accordingly, the design problem is constructed to minimize the total system cost concerning the system layout (i.e., in terms of service zone partitioning), resource deployment (i.e., fleet size), and operational decision (i.e., ride-pooling size).","The proposed models admit spatial heterogeneity arising from the non-uniformity of demand distributions and service locations, and can furnish heterogeneous designs.","Closed-form formulas for the optimal zoning and fleet size are developed, which unveil fundamental insights regarding the impacts of key operating factors (e.g., demand density and distance to the terminal).","Extensive numerical experiments demonstrate (i) the effectiveness of heterogeneous service designs and (ii) the advantage of the proposed RP service with hold-dispatch strategy over alternative designs studied in the literature, i.e., RP with a ``quick-dispatch'' strategy and flexible-route transit, in a wide range of operating scenarios.","These findings can assist transportation network companies and transit agencies in successfully integrating RP and transit services."],"url":"http://arxiv.org/abs/2404.09630v1","category":"physics.soc-ph"}
{"created":"2024-04-15 10:00:35","title":"Quantifying fair income distribution in Thailand","abstract":"Given a vast concern about high income inequality in Thailand as opposed to empirical findings around the world showing people's preference for fair income inequality over unfair income equality, it is therefore important to examine whether inequality in income distribution in Thailand over the past three decades is fair, and what fair inequality in income distribution in Thailand should be. To quantitatively measure fair income distribution, this study employs the fairness benchmarks that are derived from the distributions of athletes' salaries in professional sports which satisfy the concepts of distributive justice and procedural justice, the no-envy principle of fair allocation, and the general consensus or the international norm criterion of a meaningful benchmark. By using the data on quintile income shares and the income Gini index of Thailand from the National Social and Economic Development Council, this study finds that, throughout the period from 1988 to 2021, the Thai income earners in the bottom 20%, the second 20%, and the top 20% receive income shares more than the fair shares whereas those in the third 20% and the fourth 20% receive income shares less than the fair shares. Provided that there are infinite combinations of quintile income shares that can have the same value of income Gini index but only one of them is regarded as fair, this study demonstrates the use of fairness benchmarks as a practical guideline for designing policies with an aim to achieve fair income distribution in Thailand. Moreover, a comparative analysis is conducted by employing the method for estimating optimal (fair) income distribution representing feasible income equality in order to provide an alternative recommendation on what optimal (fair) income distribution characterizing feasible income equality in Thailand should be.","sentences":["Given a vast concern about high income inequality in Thailand as opposed to empirical findings around the world showing people's preference for fair income inequality over unfair income equality, it is therefore important to examine whether inequality in income distribution in Thailand over the past three decades is fair, and what fair inequality in income distribution in Thailand should be.","To quantitatively measure fair income distribution, this study employs the fairness benchmarks that are derived from the distributions of athletes' salaries in professional sports which satisfy the concepts of distributive justice and procedural justice, the no-envy principle of fair allocation, and the general consensus or the international norm criterion of a meaningful benchmark.","By using the data on quintile income shares and the income Gini index of Thailand from the National Social and Economic Development Council, this study finds that, throughout the period from 1988 to 2021, the Thai income earners in the bottom 20%, the second 20%, and the top 20% receive income shares more than the fair shares whereas those in the third 20% and the fourth 20% receive income shares less than the fair shares.","Provided that there are infinite combinations of quintile income shares that can have the same value of income Gini index but only one of them is regarded as fair, this study demonstrates the use of fairness benchmarks as a practical guideline for designing policies with an aim to achieve fair income distribution in Thailand.","Moreover, a comparative analysis is conducted by employing the method for estimating optimal (fair) income distribution representing feasible income equality in order to provide an alternative recommendation on what optimal (fair) income distribution characterizing feasible income equality in Thailand should be."],"url":"http://arxiv.org/abs/2404.09629v1","category":"econ.GN"}
