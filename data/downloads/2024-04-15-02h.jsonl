{"created":"2024-04-12 17:58:04","title":"Probing the 3D Awareness of Visual Foundation Models","abstract":"Recent advances in large-scale pretraining have yielded visual foundation models with strong capabilities. Not only can recent models generalize to arbitrary images for their training task, their intermediate representations are useful for other visual tasks such as detection and segmentation. Given that such models can classify, delineate, and localize objects in 2D, we ask whether they also represent their 3D structure? In this work, we analyze the 3D awareness of visual foundation models. We posit that 3D awareness implies that representations (1) encode the 3D structure of the scene and (2) consistently represent the surface across views. We conduct a series of experiments using task-specific probes and zero-shot inference procedures on frozen features. Our experiments reveal several limitations of the current models. Our code and analysis can be found at https://github.com/mbanani/probe3d.","sentences":["Recent advances in large-scale pretraining have yielded visual foundation models with strong capabilities.","Not only can recent models generalize to arbitrary images for their training task, their intermediate representations are useful for other visual tasks such as detection and segmentation.","Given that such models can classify, delineate, and localize objects in 2D, we ask whether they also represent their 3D structure?","In this work, we analyze the 3D awareness of visual foundation models.","We posit that 3D awareness implies that representations (1) encode the 3D structure of the scene and (2) consistently represent the surface across views.","We conduct a series of experiments using task-specific probes and zero-shot inference procedures on frozen features.","Our experiments reveal several limitations of the current models.","Our code and analysis can be found at https://github.com/mbanani/probe3d."],"url":"http://arxiv.org/abs/2404.08636v1","category":"cs.CV"}
{"created":"2024-04-12 17:56:05","title":"Transport properties in non-Fermi liquid phases of nodal-point semimetals","abstract":"In this review, we survey the current progress in computing transport properties in semimetals which harbour non-Fermi liquid phases. We first discuss the widely used Kubo formalism, which can be applied to the effective theory describing the stable non-Fermi liquid pase obtained via a renormalization group procedure and, hence, is applicable for temperatures close to zero (e.g., optical conductivity). For finite temperature regimes, which apply to the computations of the generalized dc conductivity tensors, we elucidate the memory matrix approach. This approach is based on an effective hydrodynamic description of the system, and is especially suited for tackling transport calculations in strongly-interacting quantum field theories, because it does not rely on the existence of long-lived quasiparticles. As a concrete example, we apply these two approaches to find the response of the so-called Luttinger-Abrikosov-Benelavskii phase of isotropic three-dimensional Luttinger semimetals, which arise under the effects of long-ranged (unscreened) Coulomb interactions, with the chemical potential fine-tuned to cut exactly the nodal point. In particular, we focus on the electric conductivity tensors, thermal and thermoelectric response, Raman response, free energy, entropy density, and shear viscosity.","sentences":["In this review, we survey the current progress in computing transport properties in semimetals which harbour non-Fermi liquid phases.","We first discuss the widely used Kubo formalism, which can be applied to the effective theory describing the stable non-Fermi liquid pase obtained via a renormalization group procedure and, hence, is applicable for temperatures close to zero (e.g., optical conductivity).","For finite temperature regimes, which apply to the computations of the generalized dc conductivity tensors, we elucidate the memory matrix approach.","This approach is based on an effective hydrodynamic description of the system, and is especially suited for tackling transport calculations in strongly-interacting quantum field theories, because it does not rely on the existence of long-lived quasiparticles.","As a concrete example, we apply these two approaches to find the response of the so-called Luttinger-Abrikosov-Benelavskii phase of isotropic three-dimensional Luttinger semimetals, which arise under the effects of long-ranged (unscreened) Coulomb interactions, with the chemical potential fine-tuned to cut exactly the nodal point.","In particular, we focus on the electric conductivity tensors, thermal and thermoelectric response, Raman response, free energy, entropy density, and shear viscosity."],"url":"http://arxiv.org/abs/2404.08635v1","category":"cond-mat.str-el"}
{"created":"2024-04-12 17:53:34","title":"Pre-training Small Base LMs with Fewer Tokens","abstract":"We study the effectiveness of a simple approach to develop a small base language model (LM) starting from an existing large base LM: first inherit a few transformer blocks from the larger LM, and then train this smaller model on a very small subset (0.1\\%) of the raw pretraining data of the larger model. We call our simple recipe Inheritune and first demonstrate it for building a small base LM with 1.5B parameters using 1B tokens (and a starting few layers of larger LM of 3B parameters); we do this using a single A6000 GPU for less than half a day. Across 9 diverse evaluation datasets as well as the MMLU benchmark, the resulting model compares favorably to publicly available base models of 1B-2B size, some of which have been trained using 50-1000 times more tokens.   We investigate Inheritune in a slightly different setting where we train small LMs utilizing larger LMs and their full pre-training dataset. Here we show that smaller LMs trained utilizing some of the layers of GPT2-medium (355M) and GPT-2-large (770M) can effectively match the val loss of their bigger counterparts when trained from scratch for the same number of training steps on OpenWebText dataset with 9B tokens. We analyze our recipe with extensive experiments and demonstrate it efficacy on diverse settings. Our code is available at https://github.com/sanyalsunny111/LLM-Inheritune.","sentences":["We study the effectiveness of a simple approach to develop a small base language model (LM) starting from an existing large base LM: first inherit a few transformer blocks from the larger LM, and then train this smaller model on a very small subset (0.1\\%) of the raw pretraining data of the larger model.","We call our simple recipe Inheritune and first demonstrate it for building a small base LM with 1.5B parameters using 1B tokens (and a starting few layers of larger LM of 3B parameters); we do this using a single A6000 GPU for less than half a day.","Across 9 diverse evaluation datasets as well as the MMLU benchmark, the resulting model compares favorably to publicly available base models of 1B-2B size, some of which have been trained using 50-1000 times more tokens.   ","We investigate Inheritune in a slightly different setting where we train small LMs utilizing larger LMs and their full pre-training dataset.","Here we show that smaller LMs trained utilizing some of the layers of GPT2-medium (355M) and GPT-2-large (770M) can effectively match the val loss of their bigger counterparts when trained from scratch for the same number of training steps on OpenWebText dataset with 9B tokens.","We analyze our recipe with extensive experiments and demonstrate it efficacy on diverse settings.","Our code is available at https://github.com/sanyalsunny111/LLM-Inheritune."],"url":"http://arxiv.org/abs/2404.08634v1","category":"cs.CL"}
{"created":"2024-04-12 17:51:07","title":"Does DESI 2024 Confirm $\u039b$CDM?","abstract":"We demonstrate that a $\\sim 2 \\sigma$ discrepancy with the Planck-$\\Lambda$CDM cosmology in DESI Luminous Red Galaxy (LRG) data at $z_{\\textrm{eff}} = 0.51$ translates into an unexpectedly large $\\Omega_m$ value, $\\Omega_m = 0.668^{+0.180}_{-0.169}$. We independently confirm that this anomaly drives the preference for $w_0 > -1$ in DESI data confronted to the $w_0 w_a$CDM model. We show that redshift bins of DESI constraints allow $\\Omega_m$ to wiggle at the $\\sim 2 \\sigma$ level with increasing effective redshift in the $\\Lambda$CDM model. Given that LRG data at $z_{\\textrm{eff}} = 0.51$ is at odds with Type Ia supernovae in overlapping redshifts, we expect that this anomaly will decrease in statistical significance with future DESI data releases leaving an increasing $\\Omega_m$ trend with effective redshift at higher redshifts. We estimate the significance of the latter in DESI data at $\\sim 1.8 \\sigma$ and comment on how it dovetails with independent observations. It is imperative to understand what makes DESI LRG data at $z_{\\textrm{eff}} = 0.51$ an outlier when it comes to $\\Omega_m$ determinations.","sentences":["We demonstrate that a $\\sim 2 \\sigma$ discrepancy with the Planck-$\\Lambda$CDM cosmology in DESI Luminous Red Galaxy (LRG) data at $z_{\\textrm{eff}} = 0.51$ translates into an unexpectedly large $\\Omega_m$ value, $\\Omega_m = 0.668^{+0.180}_{-0.169}$. We independently confirm that this anomaly drives the preference for $w_0 > -1$ in DESI data confronted to the $w_0 w_a$CDM model.","We show that redshift bins of DESI constraints allow $\\Omega_m$ to wiggle at the $\\sim 2 \\sigma$ level with increasing effective redshift in the $\\Lambda$CDM model.","Given that LRG data at $z_{\\textrm{eff}} = 0.51$ is at odds with Type Ia supernovae in overlapping redshifts, we expect that this anomaly will decrease in statistical significance with future DESI data releases leaving an increasing $\\Omega_m$ trend with effective redshift at higher redshifts.","We estimate the significance of the latter in DESI data at $\\sim 1.8 \\sigma$ and comment on how it dovetails with independent observations.","It is imperative to understand what makes DESI LRG data at $z_{\\textrm{eff}} = 0.51$ an outlier when it comes to $\\Omega_m$ determinations."],"url":"http://arxiv.org/abs/2404.08633v1","category":"astro-ph.CO"}
{"created":"2024-04-12 17:51:04","title":"Advancing aortic stenosis assessment: validation of fluid-structure interaction models against 4D flow MRI data","abstract":"Systematic in vivo validations of computational models of the aortic valve remain scarce, despite successful validation against in vitro data. Utilizing a combination of computed tomography and 4D flow magnetic resonance imaging data, we developed patient-specific fluid-structure interaction models of the aortic valve immersed in the aorta for five patients in the pre-transcatheter aortic valve replacement configuration. Incorporating also an in vitro setup of the valve, our computational models are subjected to rigorous validation against 4D flow measurements. Our results demonstrate the models' capacity to accurately replicate flow dynamics within established ranges of uncertainties mainly arising from 4D flow noise. In addition, we illustrate how computational models can serve as valuable cross-checks to reduce noise and erratic behaviour of in vivo data. This study represents a significant step towards integrating in silico technologies into real clinical contexts, providing a robust framework for improving aortic stenosis diagnosis and the design of next-generation aortic valve bioprostheses.","sentences":["Systematic in vivo validations of computational models of the aortic valve remain scarce, despite successful validation against in vitro data.","Utilizing a combination of computed tomography and 4D flow magnetic resonance imaging data, we developed patient-specific fluid-structure interaction models of the aortic valve immersed in the aorta for five patients in the pre-transcatheter aortic valve replacement configuration.","Incorporating also an in vitro setup of the valve, our computational models are subjected to rigorous validation against 4D flow measurements.","Our results demonstrate the models' capacity to accurately replicate flow dynamics within established ranges of uncertainties mainly arising from 4D flow noise.","In addition, we illustrate how computational models can serve as valuable cross-checks to reduce noise and erratic behaviour of in vivo data.","This study represents a significant step towards integrating in silico technologies into real clinical contexts, providing a robust framework for improving aortic stenosis diagnosis and the design of next-generation aortic valve bioprostheses."],"url":"http://arxiv.org/abs/2404.08632v1","category":"physics.flu-dyn"}
{"created":"2024-04-12 17:50:40","title":"FCert: Certifiably Robust Few-Shot Classification in the Era of Foundation Models","abstract":"Few-shot classification with foundation models (e.g., CLIP, DINOv2, PaLM-2) enables users to build an accurate classifier with a few labeled training samples (called support samples) for a classification task. However, an attacker could perform data poisoning attacks by manipulating some support samples such that the classifier makes the attacker-desired, arbitrary prediction for a testing input. Empirical defenses cannot provide formal robustness guarantees, leading to a cat-and-mouse game between the attacker and defender. Existing certified defenses are designed for traditional supervised learning, resulting in sub-optimal performance when extended to few-shot classification. In our work, we propose FCert, the first certified defense against data poisoning attacks to few-shot classification. We show our FCert provably predicts the same label for a testing input under arbitrary data poisoning attacks when the total number of poisoned support samples is bounded. We perform extensive experiments on benchmark few-shot classification datasets with foundation models released by OpenAI, Meta, and Google in both vision and text domains. Our experimental results show our FCert: 1) maintains classification accuracy without attacks, 2) outperforms existing state-of-the-art certified defenses for data poisoning attacks, and 3) is efficient and general.","sentences":["Few-shot classification with foundation models (e.g., CLIP, DINOv2, PaLM-2) enables users to build an accurate classifier with a few labeled training samples (called support samples) for a classification task.","However, an attacker could perform data poisoning attacks by manipulating some support samples such that the classifier makes the attacker-desired, arbitrary prediction for a testing input.","Empirical defenses cannot provide formal robustness guarantees, leading to a cat-and-mouse game between the attacker and defender.","Existing certified defenses are designed for traditional supervised learning, resulting in sub-optimal performance when extended to few-shot classification.","In our work, we propose FCert, the first certified defense against data poisoning attacks to few-shot classification.","We show our FCert provably predicts the same label for a testing input under arbitrary data poisoning attacks when the total number of poisoned support samples is bounded.","We perform extensive experiments on benchmark few-shot classification datasets with foundation models released by OpenAI, Meta, and Google in both vision and text domains.","Our experimental results show our FCert: 1) maintains classification accuracy without attacks, 2) outperforms existing state-of-the-art certified defenses for data poisoning attacks, and 3) is efficient and general."],"url":"http://arxiv.org/abs/2404.08631v1","category":"cs.CR"}
{"created":"2024-04-12 17:48:18","title":"A Conceptual Framework for Conversational Search and Recommendation: Conceptualizing Agent-Human Interactions During the Conversational Search Process","abstract":"The conversational search task aims to enable a user to resolve information needs via natural language dialogue with an agent. In this paper, we aim to develop a conceptual framework of the actions and intents of users and agents explaining how these actions enable the user to explore the search space and resolve their information need. We outline the different actions and intents, before discussing key decision points in the conversation where the agent needs to decide how to steer the conversational search process to a successful and/or satisfactory conclusion. Essentially, this paper provides a conceptualization of the conversational search process between an agent and user, which provides a framework and a starting point for research, development and evaluation of conversational search agents.","sentences":["The conversational search task aims to enable a user to resolve information needs via natural language dialogue with an agent.","In this paper, we aim to develop a conceptual framework of the actions and intents of users and agents explaining how these actions enable the user to explore the search space and resolve their information need.","We outline the different actions and intents, before discussing key decision points in the conversation where the agent needs to decide how to steer the conversational search process to a successful and/or satisfactory conclusion.","Essentially, this paper provides a conceptualization of the conversational search process between an agent and user, which provides a framework and a starting point for research, development and evaluation of conversational search agents."],"url":"http://arxiv.org/abs/2404.08630v1","category":"cs.IR"}
{"created":"2024-04-12 17:41:05","title":"Is ChatGPT Transforming Academics' Writing Style?","abstract":"Based on one million arXiv papers submitted from May 2018 to January 2024, we assess the textual density of ChatGPT's writing style in their abstracts by means of a statistical analysis of word frequency changes. Our model is calibrated and validated on a mixture of real abstracts and ChatGPT-modified abstracts (simulated data) after a careful noise analysis. We find that ChatGPT is having an increasing impact on arXiv abstracts, especially in the field of computer science, where the fraction of ChatGPT-revised abstracts is estimated to be approximately 35%, if we take the output of one of the simplest prompts, \"revise the following sentences\", as a baseline. We conclude with an analysis of both positive and negative aspects of the penetration of ChatGPT into academics' writing style.","sentences":["Based on one million arXiv papers submitted from May 2018 to January 2024, we assess the textual density of ChatGPT's writing style in their abstracts by means of a statistical analysis of word frequency changes.","Our model is calibrated and validated on a mixture of real abstracts and ChatGPT-modified abstracts (simulated data) after a careful noise analysis.","We find that ChatGPT is having an increasing impact on arXiv abstracts, especially in the field of computer science, where the fraction of ChatGPT-revised abstracts is estimated to be approximately 35%, if we take the output of one of the simplest prompts, \"revise the following sentences\", as a baseline.","We conclude with an analysis of both positive and negative aspects of the penetration of ChatGPT into academics' writing style."],"url":"http://arxiv.org/abs/2404.08627v1","category":"cs.CL"}
{"created":"2024-04-12 17:32:14","title":"Natural disasters and social entrepreneurship: An attention-based view","abstract":"Drawing on the attention based view, this study explores the joint effects of natural disaster intensity at the country level with personal attributes in terms of gender, human capital, and fear of failure on the likelihood to enter social entrepreneurship. Using data on 107,386 observations across 30 countries, we find that natural disaster intensity has a positive effect on individuals likelihood to engage in social entrepreneurship. In addition, the effect of natural disaster intensity is greater for males, individuals lacking human capital, and those who fear failure. Our study helps elaborate on the antecedents of social entrepreneurship and extends the consequences of natural disasters to entrepreneurship at the individual level.","sentences":["Drawing on the attention based view, this study explores the joint effects of natural disaster intensity at the country level with personal attributes in terms of gender, human capital, and fear of failure on the likelihood to enter social entrepreneurship.","Using data on 107,386 observations across 30 countries, we find that natural disaster intensity has a positive effect on individuals likelihood to engage in social entrepreneurship.","In addition, the effect of natural disaster intensity is greater for males, individuals lacking human capital, and those who fear failure.","Our study helps elaborate on the antecedents of social entrepreneurship and extends the consequences of natural disasters to entrepreneurship at the individual level."],"url":"http://arxiv.org/abs/2404.08620v1","category":"econ.GN"}
{"created":"2024-04-12 17:27:54","title":"Synthetic Dataset Creation and Fine-Tuning of Transformer Models for Question Answering in Serbian","abstract":"In this paper, we focus on generating a synthetic question answering (QA) dataset using an adapted Translate-Align-Retrieve method. Using this method, we created the largest Serbian QA dataset of more than 87K samples, which we name SQuAD-sr. To acknowledge the script duality in Serbian, we generated both Cyrillic and Latin versions of the dataset. We investigate the dataset quality and use it to fine-tune several pre-trained QA models. Best results were obtained by fine-tuning the BERTi\\'c model on our Latin SQuAD-sr dataset, achieving 73.91% Exact Match and 82.97% F1 score on the benchmark XQuAD dataset, which we translated into Serbian for the purpose of evaluation. The results show that our model exceeds zero-shot baselines, but fails to go beyond human performance. We note the advantage of using a monolingual pre-trained model over multilingual, as well as the performance increase gained by using Latin over Cyrillic. By performing additional analysis, we show that questions about numeric values or dates are more likely to be answered correctly than other types of questions. Finally, we conclude that SQuAD-sr is of sufficient quality for fine-tuning a Serbian QA model, in the absence of a manually crafted and annotated dataset.","sentences":["In this paper, we focus on generating a synthetic question answering (QA) dataset using an adapted Translate-Align-Retrieve method.","Using this method, we created the largest Serbian QA dataset of more than 87K samples, which we name SQuAD-sr.","To acknowledge the script duality in Serbian, we generated both Cyrillic and Latin versions of the dataset.","We investigate the dataset quality and use it to fine-tune several pre-trained QA models.","Best results were obtained by fine-tuning the BERTi\\'c model on our Latin SQuAD-sr dataset, achieving 73.91% Exact Match and 82.97% F1 score on the benchmark XQuAD dataset, which we translated into Serbian for the purpose of evaluation.","The results show that our model exceeds zero-shot baselines, but fails to go beyond human performance.","We note the advantage of using a monolingual pre-trained model over multilingual, as well as the performance increase gained by using Latin over Cyrillic.","By performing additional analysis, we show that questions about numeric values or dates are more likely to be answered correctly than other types of questions.","Finally, we conclude that SQuAD-sr is of sufficient quality for fine-tuning a Serbian QA model, in the absence of a manually crafted and annotated dataset."],"url":"http://arxiv.org/abs/2404.08617v1","category":"cs.CL"}
{"created":"2024-04-12 17:23:57","title":"Exploring the borderline between stable mass transfer and mergers in close binary evolution","abstract":"The majority of massive stars reside in binary systems, which are expected to experience mass transfer during their evolution. However, so far the conditions under which mass transfer leads to a common envelope, and thus possibly to a merging of both stars, are not well understood. Main uncertainties arise from the possible swelling of the mass gainer, and from angular momentum loss from the binary system, during non-conservative mass transfer. We have computed a dense grid of detailed models of stars accreting mass at constant rates, to determine their radius increase due to their thermal disequilibrium. While we find that models with faster than thermal timescale accretion generally expand, this expansion remains quite limited in the intermediate mass regime even for accretion rates which exceed the thermal timescale accretion rate by a factor of 100. Our models of massive accretion stars expand to extreme radii under those conditions. When the accretion rate exceed the Eddington accretion rate, our models expand dynamically. We have derived analytical fits to the radius evolution of our models and a prescription for the borderline between stable mass transfer and mergers for arbitrary accretion efficiencies. We then apply our results to grids of binary models adopting various constant mass transfer efficiencies and angular momentum budgets. We find that the former parameter has the stronger effect on the outcome of the Roche lobe overflow. Our results are consistent with detailed binary evolution models, and often lead to a smaller initial parameter space for stable mass transfer than other recipes in the literature. We use this method to investigate the origin of the Wolf-Rayet stars with O star companions in the Small Magellanic Cloud, and find that the efficiency of the mass transfer process which lead to the formation of the Wolf-Rayet star was likely below 50%.","sentences":["The majority of massive stars reside in binary systems, which are expected to experience mass transfer during their evolution.","However, so far the conditions under which mass transfer leads to a common envelope, and thus possibly to a merging of both stars, are not well understood.","Main uncertainties arise from the possible swelling of the mass gainer, and from angular momentum loss from the binary system, during non-conservative mass transfer.","We have computed a dense grid of detailed models of stars accreting mass at constant rates, to determine their radius increase due to their thermal disequilibrium.","While we find that models with faster than thermal timescale accretion generally expand, this expansion remains quite limited in the intermediate mass regime even for accretion rates which exceed the thermal timescale accretion rate by a factor of 100.","Our models of massive accretion stars expand to extreme radii under those conditions.","When the accretion rate exceed the Eddington accretion rate, our models expand dynamically.","We have derived analytical fits to the radius evolution of our models and a prescription for the borderline between stable mass transfer and mergers for arbitrary accretion efficiencies.","We then apply our results to grids of binary models adopting various constant mass transfer efficiencies and angular momentum budgets.","We find that the former parameter has the stronger effect on the outcome of the Roche lobe overflow.","Our results are consistent with detailed binary evolution models, and often lead to a smaller initial parameter space for stable mass transfer than other recipes in the literature.","We use this method to investigate the origin of the Wolf-Rayet stars with O star companions in the Small Magellanic Cloud, and find that the efficiency of the mass transfer process which lead to the formation of the Wolf-Rayet star was likely below 50%."],"url":"http://arxiv.org/abs/2404.08615v1","category":"astro-ph.SR"}
{"created":"2024-04-12 17:22:29","title":"Using Explainable AI and Transfer Learning to understand and predict the maintenance of Atlantic blocking with limited observational data","abstract":"Blocking events are an important cause of extreme weather, especially long-lasting blocking events that trap weather systems in place. The duration of blocking events is, however, underestimated in climate models. Explainable Artificial Intelligence are a class of data analysis methods that can help identify physical causes of prolonged blocking events and diagnose model deficiencies. We demonstrate this approach on an idealized quasigeostrophic model developed by Marshall and Molteni (1993). We train a convolutional neural network (CNN), and subsequently, build a sparse predictive model for the persistence of Atlantic blocking, conditioned on an initial high-pressure anomaly. Shapley Additive ExPlanation (SHAP) analysis reveals that high-pressure anomalies in the American Southeast and North Atlantic, separated by a trough over Atlantic Canada, contribute significantly to prediction of sustained blocking events in the Atlantic region. This agrees with previous work that identified precursors in the same regions via wave train analysis. When we apply the same CNN to blockings in the ERA5 atmospheric reanalysis, there is insufficient data to accurately predict persistent blocks. We partially overcome this limitation by pre-training the CNN on the plentiful data of the Marshall-Molteni model, and then using Transfer Learning to achieve better predictions than direct training. SHAP analysis before and after transfer learning allows a comparison between the predictive features in the reanalysis and the quasigeostrophic model, quantifying dynamical biases in the idealized model. This work demonstrates the potential for machine learning methods to extract meaningful precursors of extreme weather events and achieve better prediction using limited observational data.","sentences":["Blocking events are an important cause of extreme weather, especially long-lasting blocking events that trap weather systems in place.","The duration of blocking events is, however, underestimated in climate models.","Explainable Artificial Intelligence are a class of data analysis methods that can help identify physical causes of prolonged blocking events and diagnose model deficiencies.","We demonstrate this approach on an idealized quasigeostrophic model developed by Marshall and Molteni (1993).","We train a convolutional neural network (CNN), and subsequently, build a sparse predictive model for the persistence of Atlantic blocking, conditioned on an initial high-pressure anomaly.","Shapley Additive ExPlanation (SHAP) analysis reveals that high-pressure anomalies in the American Southeast and North Atlantic, separated by a trough over Atlantic Canada, contribute significantly to prediction of sustained blocking events in the Atlantic region.","This agrees with previous work that identified precursors in the same regions via wave train analysis.","When we apply the same CNN to blockings in the ERA5 atmospheric reanalysis, there is insufficient data to accurately predict persistent blocks.","We partially overcome this limitation by pre-training the CNN on the plentiful data of the Marshall-Molteni model, and then using Transfer Learning to achieve better predictions than direct training.","SHAP analysis before and after transfer learning allows a comparison between the predictive features in the reanalysis and the quasigeostrophic model, quantifying dynamical biases in the idealized model.","This work demonstrates the potential for machine learning methods to extract meaningful precursors of extreme weather events and achieve better prediction using limited observational data."],"url":"http://arxiv.org/abs/2404.08613v1","category":"physics.ao-ph"}
{"created":"2024-04-12 17:20:57","title":"Automatic Quantification of Serial PET/CT Images for Pediatric Hodgkin Lymphoma Patients Using a Longitudinally-Aware Segmentation Network","abstract":"$\\textbf{Purpose}$: Automatic quantification of longitudinal changes in PET scans for lymphoma patients has proven challenging, as residual disease in interim-therapy scans is often subtle and difficult to detect. Our goal was to develop a longitudinally-aware segmentation network (LAS-Net) that can quantify serial PET/CT images for pediatric Hodgkin lymphoma patients. $\\textbf{Materials and Methods}$: This retrospective study included baseline (PET1) and interim (PET2) PET/CT images from 297 patients enrolled in two Children's Oncology Group clinical trials (AHOD1331 and AHOD0831). LAS-Net incorporates longitudinal cross-attention, allowing relevant features from PET1 to inform the analysis of PET2. Model performance was evaluated using Dice coefficients for PET1 and detection F1 scores for PET2. Additionally, we extracted and compared quantitative PET metrics, including metabolic tumor volume (MTV) and total lesion glycolysis (TLG) in PET1, as well as qPET and $\\Delta$SUVmax in PET2, against physician measurements. We quantified their agreement using Spearman's $\\rho$ correlations and employed bootstrap resampling for statistical analysis. $\\textbf{Results}$: LAS-Net detected residual lymphoma in PET2 with an F1 score of 0.606 (precision/recall: 0.615/0.600), outperforming all comparator methods (P<0.01). For baseline segmentation, LAS-Net achieved a mean Dice score of 0.772. In PET quantification, LAS-Net's measurements of qPET, $\\Delta$SUVmax, MTV and TLG were strongly correlated with physician measurements, with Spearman's $\\rho$ of 0.78, 0.80, 0.93 and 0.96, respectively. The performance remained high, with a slight decrease, in an external testing cohort. $\\textbf{Conclusion}$: LAS-Net achieved high performance in quantifying PET metrics across serial scans, highlighting the value of longitudinal awareness in evaluating multi-time-point imaging datasets.","sentences":["$\\textbf{Purpose}$: Automatic quantification of longitudinal changes in PET scans for lymphoma patients has proven challenging, as residual disease in interim-therapy scans is often subtle and difficult to detect.","Our goal was to develop a longitudinally-aware segmentation network (LAS-Net) that can quantify serial PET/CT images for pediatric Hodgkin lymphoma patients.","$\\textbf{Materials and Methods}$: This retrospective study included baseline (PET1) and interim (PET2) PET/CT images from 297 patients enrolled in two Children's Oncology Group clinical trials (AHOD1331 and AHOD0831).","LAS-Net incorporates longitudinal cross-attention, allowing relevant features from PET1 to inform the analysis of PET2.","Model performance was evaluated using Dice coefficients for PET1 and detection F1 scores for PET2.","Additionally, we extracted and compared quantitative PET metrics, including metabolic tumor volume (MTV) and total lesion glycolysis (TLG) in PET1, as well as qPET and $\\Delta$SUVmax in PET2, against physician measurements.","We quantified their agreement using Spearman's $\\rho$ correlations and employed bootstrap resampling for statistical analysis.","$\\textbf{Results}$: LAS-Net detected residual lymphoma in PET2 with an F1 score of 0.606 (precision/recall: 0.615/0.600), outperforming all comparator methods (P<0.01).","For baseline segmentation, LAS-Net achieved a mean Dice score of 0.772.","In PET quantification, LAS-Net's measurements of qPET, $\\Delta$SUVmax, MTV and TLG were strongly correlated with physician measurements, with Spearman's $\\rho$ of 0.78, 0.80, 0.93 and 0.96, respectively.","The performance remained high, with a slight decrease, in an external testing cohort.","$\\textbf{Conclusion}$: LAS-Net achieved high performance in quantifying PET metrics across serial scans, highlighting the value of longitudinal awareness in evaluating multi-time-point imaging datasets."],"url":"http://arxiv.org/abs/2404.08611v1","category":"cs.CV"}
{"created":"2024-04-12 17:04:23","title":"Bilinear Hardy inequalities on metric measure spaces","abstract":"In this paper, we discuss the Hardy inequality with bilinear operators on general metric measure spaces. We give the characterization of weights for the bilinear Hardy inequality to hold on general metric measure spaces having polar decompositions. We also provide several examples of the results, finding conditions on the weights for integral Hardy inequalities on homogeneous Lie groups, as well as on hyperbolic spaces and more generally on Cartan-Hadamard manifolds.","sentences":["In this paper, we discuss the Hardy inequality with bilinear operators on general metric measure spaces.","We give the characterization of weights for the bilinear Hardy inequality to hold on general metric measure spaces having polar decompositions.","We also provide several examples of the results, finding conditions on the weights for integral Hardy inequalities on homogeneous Lie groups, as well as on hyperbolic spaces and more generally on Cartan-Hadamard manifolds."],"url":"http://arxiv.org/abs/2404.08604v1","category":"math.FA"}
{"created":"2024-04-12 17:02:56","title":"Training-free Boost for Open-Vocabulary Object Detection with Confidence Aggregation","abstract":"Open-vocabulary object detection (OVOD) aims at localizing and recognizing visual objects from novel classes unseen at the training time. Whereas, empirical studies reveal that advanced detectors generally assign lower scores to those novel instances, which are inadvertently suppressed during inference by commonly adopted greedy strategies like Non-Maximum Suppression (NMS), leading to sub-optimal detection performance for novel classes. This paper systematically investigates this problem with the commonly-adopted two-stage OVOD paradigm. Specifically, in the region-proposal stage, proposals that contain novel instances showcase lower objectness scores, since they are treated as background proposals during the training phase. Meanwhile, in the object-classification stage, novel objects share lower region-text similarities (i.e., classification scores) due to the biased visual-language alignment by seen training samples. To alleviate this problem, this paper introduces two advanced measures to adjust confidence scores and conserve erroneously dismissed objects: (1) a class-agnostic localization quality estimate via overlap degree of region/object proposals, and (2) a text-guided visual similarity estimate with proxy prototypes for novel classes. Integrated with adjusting techniques specifically designed for the region-proposal and object-classification stages, this paper derives the aggregated confidence estimate for the open-vocabulary object detection paradigm (AggDet). Our AggDet is a generic and training-free post-processing scheme, which consistently bolsters open-vocabulary detectors across model scales and architecture designs. For instance, AggDet receives 3.3% and 1.5% gains on OV-COCO and OV-LVIS benchmarks respectively, without any training cost.","sentences":["Open-vocabulary object detection (OVOD) aims at localizing and recognizing visual objects from novel classes unseen at the training time.","Whereas, empirical studies reveal that advanced detectors generally assign lower scores to those novel instances, which are inadvertently suppressed during inference by commonly adopted greedy strategies like Non-Maximum Suppression (NMS), leading to sub-optimal detection performance for novel classes.","This paper systematically investigates this problem with the commonly-adopted two-stage OVOD paradigm.","Specifically, in the region-proposal stage, proposals that contain novel instances showcase lower objectness scores, since they are treated as background proposals during the training phase.","Meanwhile, in the object-classification stage, novel objects share lower region-text similarities (i.e., classification scores) due to the biased visual-language alignment by seen training samples.","To alleviate this problem, this paper introduces two advanced measures to adjust confidence scores and conserve erroneously dismissed objects: (1) a class-agnostic localization quality estimate via overlap degree of region/object proposals, and (2) a text-guided visual similarity estimate with proxy prototypes for novel classes.","Integrated with adjusting techniques specifically designed for the region-proposal and object-classification stages, this paper derives the aggregated confidence estimate for the open-vocabulary object detection paradigm (AggDet).","Our AggDet is a generic and training-free post-processing scheme, which consistently bolsters open-vocabulary detectors across model scales and architecture designs.","For instance, AggDet receives 3.3% and 1.5% gains on OV-COCO and OV-LVIS benchmarks respectively, without any training cost."],"url":"http://arxiv.org/abs/2404.08603v1","category":"cs.CV"}
{"created":"2024-04-12 16:55:08","title":"Generating Synthetic Time Series Data for Cyber-Physical Systems","abstract":"Data augmentation is an important facilitator of deep learning applications in the time series domain. A gap is identified in the literature, demonstrating sparse exploration of the transformer, the dominant sequence model, for data augmentation in time series. A architecture hybridizing several successful priors is put forth and tested using a powerful time domain similarity metric. Results suggest the challenge of this domain, and several valuable directions for future work.","sentences":["Data augmentation is an important facilitator of deep learning applications in the time series domain.","A gap is identified in the literature, demonstrating sparse exploration of the transformer, the dominant sequence model, for data augmentation in time series.","A architecture hybridizing several successful priors is put forth and tested using a powerful time domain similarity metric.","Results suggest the challenge of this domain, and several valuable directions for future work."],"url":"http://arxiv.org/abs/2404.08601v1","category":"cs.LG"}
{"created":"2024-04-12 16:53:03","title":"Next-to-next-to-leading order event generation for Z-boson production in association with a bottom-quark pair","abstract":"We consider the production of a Z boson decaying to leptons in association with a bottom-quark pair in hadronic collisions. For the first time, we compute predictions at next-to-next-to-leading order (NNLO) in QCD, and we combine them with the all-orders radiative corrections from a parton-shower simulation (NNLO+PS). Our method represents the first approach to NNLO+PS event generation applicable to processes featuring a colour singlet and a heavy-quark pair in the final state. The novel two-loop corrections are computed for massless bottom quarks, and the leading mass corrections are restored through a small-mass expansion. The calculation is carried out in the four-flavour scheme, and we find that the sizeable NNLO QCD corrections lift the long-standing tension between lower-order predictions in four- and five-flavour schemes. Our predictions are compared to a CMS measurement for Z boson plus b-jet production, achieving an excellent description of the data.","sentences":["We consider the production of a Z boson decaying to leptons in association with a bottom-quark pair in hadronic collisions.","For the first time, we compute predictions at next-to-next-to-leading order (NNLO) in QCD, and we combine them with the all-orders radiative corrections from a parton-shower simulation (NNLO+PS).","Our method represents the first approach to NNLO+PS event generation applicable to processes featuring a colour singlet and a heavy-quark pair in the final state.","The novel two-loop corrections are computed for massless bottom quarks, and the leading mass corrections are restored through a small-mass expansion.","The calculation is carried out in the four-flavour scheme, and we find that the sizeable NNLO QCD corrections lift the long-standing tension between lower-order predictions in four- and five-flavour schemes.","Our predictions are compared to a CMS measurement for Z boson plus b-jet production, achieving an excellent description of the data."],"url":"http://arxiv.org/abs/2404.08598v1","category":"hep-ph"}
{"created":"2024-04-12 16:38:48","title":"Improving Referring Image Segmentation using Vision-Aware Text Features","abstract":"Referring image segmentation is a challenging task that involves generating pixel-wise segmentation masks based on natural language descriptions. Existing methods have relied mostly on visual features to generate the segmentation masks while treating text features as supporting components. This over-reliance on visual features can lead to suboptimal results, especially in complex scenarios where text prompts are ambiguous or context-dependent. To overcome these challenges, we present a novel framework VATEX to improve referring image segmentation by enhancing object and context understanding with Vision-Aware Text Feature. Our method involves using CLIP to derive a CLIP Prior that integrates an object-centric visual heatmap with text description, which can be used as the initial query in DETR-based architecture for the segmentation task. Furthermore, by observing that there are multiple ways to describe an instance in an image, we enforce feature similarity between text variations referring to the same visual input by two components: a novel Contextual Multimodal Decoder that turns text embeddings into vision-aware text features, and a Meaning Consistency Constraint to ensure further the coherent and consistent interpretation of language expressions with the context understanding obtained from the image. Our method achieves a significant performance improvement on three benchmark datasets RefCOCO, RefCOCO+ and G-Ref. Code is available at: https://nero1342.github.io/VATEX\\_RIS.","sentences":["Referring image segmentation is a challenging task that involves generating pixel-wise segmentation masks based on natural language descriptions.","Existing methods have relied mostly on visual features to generate the segmentation masks while treating text features as supporting components.","This over-reliance on visual features can lead to suboptimal results, especially in complex scenarios where text prompts are ambiguous or context-dependent.","To overcome these challenges, we present a novel framework VATEX to improve referring image segmentation by enhancing object and context understanding with Vision-Aware Text Feature.","Our method involves using CLIP to derive a CLIP Prior that integrates an object-centric visual heatmap with text description, which can be used as the initial query in DETR-based architecture for the segmentation task.","Furthermore, by observing that there are multiple ways to describe an instance in an image, we enforce feature similarity between text variations referring to the same visual input by two components: a novel Contextual Multimodal Decoder that turns text embeddings into vision-aware text features, and a Meaning Consistency Constraint to ensure further the coherent and consistent interpretation of language expressions with the context understanding obtained from the image.","Our method achieves a significant performance improvement on three benchmark datasets RefCOCO, RefCOCO+ and G-Ref.","Code is available at: https://nero1342.github.io/VATEX\\_RIS."],"url":"http://arxiv.org/abs/2404.08590v1","category":"cs.CV"}
{"created":"2024-04-12 16:35:23","title":"Enhancing Visual Question Answering through Question-Driven Image Captions as Prompts","abstract":"Visual question answering (VQA) is known as an AI-complete task as it requires understanding, reasoning, and inferring about the vision and the language content. Over the past few years, numerous neural architectures have been suggested for the VQA problem. However, achieving success in zero-shot VQA remains a challenge due to its requirement for advanced generalization and reasoning skills. This study explores the impact of incorporating image captioning as an intermediary process within the VQA pipeline. Specifically, we explore the efficacy of utilizing image captions instead of images and leveraging large language models (LLMs) to establish a zero-shot setting. Since image captioning is the most crucial step in this process, we compare the impact of state-of-the-art image captioning models on VQA performance across various question types in terms of structure and semantics. We propose a straightforward and efficient question-driven image captioning approach within this pipeline to transfer contextual information into the question-answering (QA) model. This method involves extracting keywords from the question, generating a caption for each image-question pair using the keywords, and incorporating the question-driven caption into the LLM prompt. We evaluate the efficacy of using general-purpose and question-driven image captions in the VQA pipeline. Our study highlights the potential of employing image captions and harnessing the capabilities of LLMs to achieve competitive performance on GQA under the zero-shot setting. Our code is available at \\url{https://github.com/ovguyo/captions-in-VQA}.","sentences":["Visual question answering (VQA) is known as an AI-complete task as it requires understanding, reasoning, and inferring about the vision and the language content.","Over the past few years, numerous neural architectures have been suggested for the VQA problem.","However, achieving success in zero-shot VQA remains a challenge due to its requirement for advanced generalization and reasoning skills.","This study explores the impact of incorporating image captioning as an intermediary process within the VQA pipeline.","Specifically, we explore the efficacy of utilizing image captions instead of images and leveraging large language models (LLMs) to establish a zero-shot setting.","Since image captioning is the most crucial step in this process, we compare the impact of state-of-the-art image captioning models on VQA performance across various question types in terms of structure and semantics.","We propose a straightforward and efficient question-driven image captioning approach within this pipeline to transfer contextual information into the question-answering (QA) model.","This method involves extracting keywords from the question, generating a caption for each image-question pair using the keywords, and incorporating the question-driven caption into the LLM prompt.","We evaluate the efficacy of using general-purpose and question-driven image captions in the VQA pipeline.","Our study highlights the potential of employing image captions and harnessing the capabilities of LLMs to achieve competitive performance on GQA under the zero-shot setting.","Our code is available at \\url{https://github.com/ovguyo/captions-in-VQA}."],"url":"http://arxiv.org/abs/2404.08589v1","category":"cs.CV"}
{"created":"2024-04-12 16:34:20","title":"Efficient Sensors Selection for Traffic Flow Monitoring: An Overview of Model-Based Techniques leveraging Network Observability","abstract":"The emergence of 6G-enabled Internet of Vehicles (IoV) promises to revolutionize mobility and connectivity, integrating vehicles into a mobile Internet-of-Things (IoT)-oriented wireless sensor network (WSN). 5G technologies and mobile edge computing further support this vision by facilitating real-time connectivity and empowering massive access to the Internet. In this context, IoT-oriented WSNs play a crucial role in intelligent transportation systems, offering affordable alternatives for traffic monitoring and management. This paper's contribution is twofold: (i) surveying state-of-the-art model-based techniques for efficient sensor selection in traffic flow monitoring, emphasizing challenges of sensor placement; and (ii) advocating for data-driven methodologies to enhance sensor deployment efficacy and traffic modeling accuracy. Further considerations underscore the importance of data-driven approaches for adaptive transportation systems aligned with the IoV paradigm.","sentences":["The emergence of 6G-enabled Internet of Vehicles (IoV) promises to revolutionize mobility and connectivity, integrating vehicles into a mobile Internet-of-Things (IoT)-oriented wireless sensor network (WSN).","5G technologies and mobile edge computing further support this vision by facilitating real-time connectivity and empowering massive access to the Internet.","In this context, IoT-oriented WSNs play a crucial role in intelligent transportation systems, offering affordable alternatives for traffic monitoring and management.","This paper's contribution is twofold: (i) surveying state-of-the-art model-based techniques for efficient sensor selection in traffic flow monitoring, emphasizing challenges of sensor placement; and (ii) advocating for data-driven methodologies to enhance sensor deployment efficacy and traffic modeling accuracy.","Further considerations underscore the importance of data-driven approaches for adaptive transportation systems aligned with the IoV paradigm."],"url":"http://arxiv.org/abs/2404.08588v1","category":"cs.NI"}
{"created":"2024-04-12 16:31:38","title":"A Radical Solution to the Hubble Tension Problem","abstract":"The Hubble tension has proven to be stubbornly persistent, despite widespread efforts to relax it. As a possible resolution of this problem we propose a radical alternative to the way in which cosmological models are viewed. Specifically, we consider building cosmological models from spaces that exhibit intrinsic symmetries, rather than as space-times with explicit symmetry. This change in perspective allows statistical homogeneity and isotropy to be maintained, while relaxing some strong mathematical constraints that the standard approach imposes. We show that a Hubble tension arises naturally in our new approach, and that (as a corollary) a prediction can be made for the radial component of the Baryon Acoustic Oscillations. Our prediction appears to be consistent with the DESI first-year data release, which has otherwise been interpreted as evidence for dynamical dark energy.","sentences":["The Hubble tension has proven to be stubbornly persistent, despite widespread efforts to relax it.","As a possible resolution of this problem we propose a radical alternative to the way in which cosmological models are viewed.","Specifically, we consider building cosmological models from spaces that exhibit intrinsic symmetries, rather than as space-times with explicit symmetry.","This change in perspective allows statistical homogeneity and isotropy to be maintained, while relaxing some strong mathematical constraints that the standard approach imposes.","We show that a Hubble tension arises naturally in our new approach, and that (as a corollary) a prediction can be made for the radial component of the Baryon Acoustic Oscillations.","Our prediction appears to be consistent with the DESI first-year data release, which has otherwise been interpreted as evidence for dynamical dark energy."],"url":"http://arxiv.org/abs/2404.08586v1","category":"astro-ph.CO"}
{"created":"2024-04-12 16:30:15","title":"Advanced wood species identification based on multiple anatomical sections and using deep feature transfer and fusion","abstract":"In recent years, we have seen many advancements in wood species identification. Methods like DNA analysis, Near Infrared (NIR) spectroscopy, and Direct Analysis in Real Time (DART) mass spectrometry complement the long-established wood anatomical assessment of cell and tissue morphology. However, most of these methods have some limitations such as high costs, the need for skilled experts for data interpretation, and the lack of good datasets for professional reference. Therefore, most of these methods, and certainly the wood anatomical assessment, may benefit from tools based on Artificial Intelligence. In this paper, we apply two transfer learning techniques with Convolutional Neural Networks (CNNs) to a multi-view Congolese wood species dataset including sections from different orientations and viewed at different microscopic magnifications. We explore two feature extraction methods in detail, namely Global Average Pooling (GAP) and Random Encoding of Aggregated Deep Activation Maps (RADAM), for efficient and accurate wood species identification. Our results indicate superior accuracy on diverse datasets and anatomical sections, surpassing the results of other methods. Our proposal represents a significant advancement in wood species identification, offering a robust tool to support the conservation of forest ecosystems and promote sustainable forestry practices.","sentences":["In recent years, we have seen many advancements in wood species identification.","Methods like DNA analysis, Near Infrared (NIR) spectroscopy, and Direct Analysis in Real Time (DART) mass spectrometry complement the long-established wood anatomical assessment of cell and tissue morphology.","However, most of these methods have some limitations such as high costs, the need for skilled experts for data interpretation, and the lack of good datasets for professional reference.","Therefore, most of these methods, and certainly the wood anatomical assessment, may benefit from tools based on Artificial Intelligence.","In this paper, we apply two transfer learning techniques with Convolutional Neural Networks (CNNs) to a multi-view Congolese wood species dataset including sections from different orientations and viewed at different microscopic magnifications.","We explore two feature extraction methods in detail, namely Global Average Pooling (GAP) and Random Encoding of Aggregated Deep Activation Maps (RADAM), for efficient and accurate wood species identification.","Our results indicate superior accuracy on diverse datasets and anatomical sections, surpassing the results of other methods.","Our proposal represents a significant advancement in wood species identification, offering a robust tool to support the conservation of forest ecosystems and promote sustainable forestry practices."],"url":"http://arxiv.org/abs/2404.08585v1","category":"cs.CV"}
{"created":"2024-04-12 16:29:49","title":"Pathological Primitive Segmentation Based on Visual Foundation Model with Zero-Shot Mask Generation","abstract":"Medical image processing usually requires a model trained with carefully crafted datasets due to unique image characteristics and domain-specific challenges, especially in pathology. Primitive detection and segmentation in digitized tissue samples are essential for objective and automated diagnosis and prognosis of cancer. SAM (Segment Anything Model) has recently been developed to segment general objects from natural images with high accuracy, but it requires human prompts to generate masks. In this work, we present a novel approach that adapts pre-trained natural image encoders of SAM for detection-based region proposals. Regions proposed by a pre-trained encoder are sent to cascaded feature propagation layers for projection. Then, local semantic and global context is aggregated from multi-scale for bounding box localization and classification. Finally, the SAM decoder uses the identified bounding boxes as essential prompts to generate a comprehensive primitive segmentation map. The entire base framework, SAM, requires no additional training or fine-tuning but could produce an end-to-end result for two fundamental segmentation tasks in pathology. Our method compares with state-of-the-art models in F1 score for nuclei detection and binary/multiclass panoptic(bPQ/mPQ) and mask quality(dice) for segmentation quality on the PanNuke dataset while offering end-to-end efficiency. Our model also achieves remarkable Average Precision (+4.5%) on the secondary dataset (HuBMAP Kidney) compared to Faster RCNN. The code is publicly available at https://github.com/learner-codec/autoprom_sam.","sentences":["Medical image processing usually requires a model trained with carefully crafted datasets due to unique image characteristics and domain-specific challenges, especially in pathology.","Primitive detection and segmentation in digitized tissue samples are essential for objective and automated diagnosis and prognosis of cancer.","SAM (Segment Anything Model) has recently been developed to segment general objects from natural images with high accuracy, but it requires human prompts to generate masks.","In this work, we present a novel approach that adapts pre-trained natural image encoders of SAM for detection-based region proposals.","Regions proposed by a pre-trained encoder are sent to cascaded feature propagation layers for projection.","Then, local semantic and global context is aggregated from multi-scale for bounding box localization and classification.","Finally, the SAM decoder uses the identified bounding boxes as essential prompts to generate a comprehensive primitive segmentation map.","The entire base framework, SAM, requires no additional training or fine-tuning but could produce an end-to-end result for two fundamental segmentation tasks in pathology.","Our method compares with state-of-the-art models in F1 score for nuclei detection and binary/multiclass panoptic(bPQ/mPQ) and mask quality(dice) for segmentation quality on the PanNuke dataset while offering end-to-end efficiency.","Our model also achieves remarkable Average Precision (+4.5%) on the secondary dataset (HuBMAP Kidney) compared to Faster RCNN.","The code is publicly available at https://github.com/learner-codec/autoprom_sam."],"url":"http://arxiv.org/abs/2404.08584v1","category":"cs.CV"}
{"created":"2024-04-12 16:28:30","title":"FashionFail: Addressing Failure Cases in Fashion Object Detection and Segmentation","abstract":"In the realm of fashion object detection and segmentation for online shopping images, existing state-of-the-art fashion parsing models encounter limitations, particularly when exposed to non-model-worn apparel and close-up shots. To address these failures, we introduce FashionFail; a new fashion dataset with e-commerce images for object detection and segmentation. The dataset is efficiently curated using our novel annotation tool that leverages recent foundation models. The primary objective of FashionFail is to serve as a test bed for evaluating the robustness of models. Our analysis reveals the shortcomings of leading models, such as Attribute-Mask R-CNN and Fashionformer. Additionally, we propose a baseline approach using naive data augmentation to mitigate common failure cases and improve model robustness. Through this work, we aim to inspire and support further research in fashion item detection and segmentation for industrial applications. The dataset, annotation tool, code, and models are available at \\url{https://rizavelioglu.github.io/fashionfail/}.","sentences":["In the realm of fashion object detection and segmentation for online shopping images, existing state-of-the-art fashion parsing models encounter limitations, particularly when exposed to non-model-worn apparel and close-up shots.","To address these failures, we introduce FashionFail; a new fashion dataset with e-commerce images for object detection and segmentation.","The dataset is efficiently curated using our novel annotation tool that leverages recent foundation models.","The primary objective of FashionFail is to serve as a test bed for evaluating the robustness of models.","Our analysis reveals the shortcomings of leading models, such as Attribute-Mask R-CNN and Fashionformer.","Additionally, we propose a baseline approach using naive data augmentation to mitigate common failure cases and improve model robustness.","Through this work, we aim to inspire and support further research in fashion item detection and segmentation for industrial applications.","The dataset, annotation tool, code, and models are available at \\url{https://rizavelioglu.github.io/fashionfail/}."],"url":"http://arxiv.org/abs/2404.08582v1","category":"cs.CV"}
{"created":"2024-04-12 16:26:23","title":"Emulating generator coordinate method with extended eigenvector continuation: Lipkin-Meshkov-Glick model","abstract":"We present a benchmark study of generator coordinate method (GCM) combined with eigenvector continuation (EC) in two different schemes for the low-lying states of Lipkin-Meshkov-Glick (LMG) model, where the interaction strength is treated as a controlling parameter, simulating quantum many-body systems with the phase transition from non-collective to collective states. We demonstrate that the EC$_{\\rm kmax}$ scheme accurately reproduces the low-lying states of the LMG model. In this scheme, the EC basis consists of the wave functions of low-lying states up to the $k_{\\rm max}$-th state of sampling Hamiltonians. Compared to EC$_1$, which only includes the wave functions of the $k$-th state of sampling Hamiltonians for the $k$-th state of a target Hamiltonian, the EC$_{\\rm kmax}$ scheme exhibits significantly improved efficiency and accuracy. This study suggests the potential utilization of the extended EC scheme as an efficient emulator for GCM calculations.","sentences":["We present a benchmark study of generator coordinate method (GCM) combined with eigenvector continuation (EC) in two different schemes for the low-lying states of Lipkin-Meshkov-Glick (LMG) model, where the interaction strength is treated as a controlling parameter, simulating quantum many-body systems with the phase transition from non-collective to collective states.","We demonstrate that the EC$_{\\rm kmax}$ scheme accurately reproduces the low-lying states of the LMG model.","In this scheme, the EC basis consists of the wave functions of low-lying states up to the $k_{\\rm max}$-th state of sampling Hamiltonians.","Compared to EC$_1$, which only includes the wave functions of the $k$-th state of sampling Hamiltonians for the $k$-th state of a target Hamiltonian, the EC$_{\\rm kmax}$ scheme exhibits significantly improved efficiency and accuracy.","This study suggests the potential utilization of the extended EC scheme as an efficient emulator for GCM calculations."],"url":"http://arxiv.org/abs/2404.08581v1","category":"nucl-th"}
{"created":"2024-04-12 16:23:42","title":"Lossy Image Compression with Foundation Diffusion Models","abstract":"Incorporating diffusion models in the image compression domain has the potential to produce realistic and detailed reconstructions, especially at extremely low bitrates. Previous methods focus on using diffusion models as expressive decoders robust to quantization errors in the conditioning signals, yet achieving competitive results in this manner requires costly training of the diffusion model and long inference times due to the iterative generative process. In this work we formulate the removal of quantization error as a denoising task, using diffusion to recover lost information in the transmitted image latent. Our approach allows us to perform less than 10\\% of the full diffusion generative process and requires no architectural changes to the diffusion model, enabling the use of foundation models as a strong prior without additional fine tuning of the backbone. Our proposed codec outperforms previous methods in quantitative realism metrics, and we verify that our reconstructions are qualitatively preferred by end users, even when other methods use twice the bitrate.","sentences":["Incorporating diffusion models in the image compression domain has the potential to produce realistic and detailed reconstructions, especially at extremely low bitrates.","Previous methods focus on using diffusion models as expressive decoders robust to quantization errors in the conditioning signals, yet achieving competitive results in this manner requires costly training of the diffusion model and long inference times due to the iterative generative process.","In this work we formulate the removal of quantization error as a denoising task, using diffusion to recover lost information in the transmitted image latent.","Our approach allows us to perform less than 10\\% of the full diffusion generative process and requires no architectural changes to the diffusion model, enabling the use of foundation models as a strong prior without additional fine tuning of the backbone.","Our proposed codec outperforms previous methods in quantitative realism metrics, and we verify that our reconstructions are qualitatively preferred by end users, even when other methods use twice the bitrate."],"url":"http://arxiv.org/abs/2404.08580v1","category":"eess.IV"}
{"created":"2024-04-12 16:23:41","title":"Small Models Are (Still) Effective Cross-Domain Argument Extractors","abstract":"Effective ontology transfer has been a major goal of recent work on event argument extraction (EAE). Two methods in particular -- question answering (QA) and template infilling (TI) -- have emerged as promising approaches to this problem. However, detailed explorations of these techniques' ability to actually enable this transfer are lacking. In this work, we provide such a study, exploring zero-shot transfer using both techniques on six major EAE datasets at both the sentence and document levels. Further, we challenge the growing reliance on LLMs for zero-shot extraction, showing that vastly smaller models trained on an appropriate source ontology can yield zero-shot performance superior to that of GPT-3.5 or GPT-4.","sentences":["Effective ontology transfer has been a major goal of recent work on event argument extraction (EAE).","Two methods in particular -- question answering (QA) and template infilling (TI) -- have emerged as promising approaches to this problem.","However, detailed explorations of these techniques' ability to actually enable this transfer are lacking.","In this work, we provide such a study, exploring zero-shot transfer using both techniques on six major EAE datasets at both the sentence and document levels.","Further, we challenge the growing reliance on LLMs for zero-shot extraction, showing that vastly smaller models trained on an appropriate source ontology can yield zero-shot performance superior to that of GPT-3.5 or GPT-4."],"url":"http://arxiv.org/abs/2404.08579v1","category":"cs.CL"}
{"created":"2024-04-12 16:22:08","title":"Fast Waveform Generation for Gravitational Waves using Evolutionary Algorithms","abstract":"Gravitational-wave analyses depend heavily on waveforms that model the evolution of compact binary coalescences as seen by observing detectors. In many cases these waveforms are given by waveform approximants, models that approximate the power of the waveform at a set of frequencies. Because of their omnipresence, improving the speed at which approximants can generate waveforms is crucial to accelerating the overall analysis of gravitational-wave detections. An optimisation algorithm is proposed that can select at which frequencies in the spectrum an approximant should compute the power of a waveform, and at which frequencies the power can be safely interpolated at a minor loss in accuracy. The algorithm used is an evolutionary algorithm modeled after the principle of natural selection, iterating frequency arrays that perform better at every iteration. As an application, the candidates proposed by the algorithm are used to reconstruct signal-to-noise ratios. It is shown that the IMRPhenomXPHM approximant can be sped up by at least 30% at a loss of at most 2.87% on the drawn samples, measured by the accuracy of the reconstruction of signal-to-noise ratios. The behaviour of the algorithm as well as lower bounds on both speedup and error are explored, leading to a proposed proof of concept candidate that obtains a speedup of 46% with a maximum error of 0.5% on a sample of the parameter space used.","sentences":["Gravitational-wave analyses depend heavily on waveforms that model the evolution of compact binary coalescences as seen by observing detectors.","In many cases these waveforms are given by waveform approximants, models that approximate the power of the waveform at a set of frequencies.","Because of their omnipresence, improving the speed at which approximants can generate waveforms is crucial to accelerating the overall analysis of gravitational-wave detections.","An optimisation algorithm is proposed that can select at which frequencies in the spectrum an approximant should compute the power of a waveform, and at which frequencies the power can be safely interpolated at a minor loss in accuracy.","The algorithm used is an evolutionary algorithm modeled after the principle of natural selection, iterating frequency arrays that perform better at every iteration.","As an application, the candidates proposed by the algorithm are used to reconstruct signal-to-noise ratios.","It is shown that the IMRPhenomXPHM approximant can be sped up by at least 30% at a loss of at most 2.87% on the drawn samples, measured by the accuracy of the reconstruction of signal-to-noise ratios.","The behaviour of the algorithm as well as lower bounds on both speedup and error are explored, leading to a proposed proof of concept candidate that obtains a speedup of 46% with a maximum error of 0.5% on a sample of the parameter space used."],"url":"http://arxiv.org/abs/2404.08576v1","category":"gr-qc"}
{"created":"2024-04-12 16:21:57","title":"Hybrid Statistics of a Random Model of Zeta over Intervals of Varying Length","abstract":"Arguin, Dubach & Hartung recently conjectured that an intermediate regime exists between IID and log-correlated statistics for extreme values of a random model of the Riemann zeta function. For the same model, we prove a matching upper and lower tail for the distribution of its maximum. This tail interpolates between that of the two aforementioned regimes. We apply the result to yield a new sharp estimate on moments over short intervals, generalizing a result by Harper. In particular, we observe a hybrid regime for moments with a distinctive transition to the IID regime for intervals of length larger than $\\exp(\\sqrt{\\log \\log T})$.","sentences":["Arguin, Dubach & Hartung recently conjectured that an intermediate regime exists between IID and log-correlated statistics for extreme values of a random model of the Riemann zeta function.","For the same model, we prove a matching upper and lower tail for the distribution of its maximum.","This tail interpolates between that of the two aforementioned regimes.","We apply the result to yield a new sharp estimate on moments over short intervals, generalizing a result by Harper.","In particular, we observe a hybrid regime for moments with a distinctive transition to the IID regime for intervals of length larger than $\\exp(\\sqrt{\\log \\log T})$."],"url":"http://arxiv.org/abs/2404.08575v1","category":"math.PR"}
{"created":"2024-04-12 16:21:49","title":"Cosmic variance of the Hellings and Downs correlation for ensembles of universes having non-zero angular power spectra","abstract":"Gravitational waves induce correlated perturbations to the arrival times of pulses from an array of galactic millisecond pulsars. The expected correlations, obtained by averaging over many pairs of pulsars having the same angular separation (pulsar averaging) and over an ensemble of model universes (ensemble averaging), are described by the Hellings and Downs curve. As shown by Allen {\\tt arXiv:2205.05637v7 [gr-qc]}, the pulsar-averaged correlation will not agree exactly with the expected Hellings and Downs prediction if the gravitational-wave sources interfere with one another, differing instead by a \"cosmic variance\" contribution. The precise shape and size of the cosmic variance depends on the statistical properties of the ensemble of universes used to model the background. Here, we extend the calculations of the cosmic variance for the standard Gaussian ensemble to an ensemble of model universes which collectively has rotationally-invariant correlations in the GW power on different angular scales (described by an angular power spectrum, $C_\\ell$ for $\\ell=0,1,\\cdots$.). We obtain an analytic form for the cosmic variance in terms of the $C_\\ell$'s and show that for realistic values $C_{\\ell}/C_0\\lesssim 10^{-3}$, there is virtually no difference in the cosmic variance compared to that for the standard Gaussian ensemble (which has zero angular power spectra).","sentences":["Gravitational waves induce correlated perturbations to the arrival times of pulses from an array of galactic millisecond pulsars.","The expected correlations, obtained by averaging over many pairs of pulsars having the same angular separation (pulsar averaging) and over an ensemble of model universes (ensemble averaging), are described by the Hellings and Downs curve.","As shown by Allen {\\tt arXiv:2205.05637v7","[gr-qc]}, the pulsar-averaged correlation will not agree exactly with the expected Hellings and Downs prediction if the gravitational-wave sources interfere with one another, differing instead by a \"cosmic variance\" contribution.","The precise shape and size of the cosmic variance depends on the statistical properties of the ensemble of universes used to model the background.","Here, we extend the calculations of the cosmic variance for the standard Gaussian ensemble to an ensemble of model universes which collectively has rotationally-invariant correlations in the GW power on different angular scales (described by an angular power spectrum, $C_\\ell$ for $\\ell=0,1,\\cdots$.).","We obtain an analytic form for the cosmic variance in terms of the $C_\\ell$'s and show that for realistic values $C_{\\ell}/C_0\\lesssim 10^{-3}$, there is virtually no difference in the cosmic variance compared to that for the standard Gaussian ensemble (which has zero angular power spectra)."],"url":"http://arxiv.org/abs/2404.08574v1","category":"gr-qc"}
{"created":"2024-04-12 16:16:32","title":"A Coordinate-Independent Formalism for Detecting High-Frequency Gravitational Waves","abstract":"In an external electric or magnetic field, a gravitational wave (GW) may be converted into electromagnetic radiation. We present a coordinate-invariant framework to describe the GW signal in a detector that is based on this effect, such as cavities for axion searches. In this framework, we pay special attention to the definition of manifestly coordinate-independent expressions for the electromagnetic fields that an external observer would detect. A careful assessment of the detector's perceived motion allows us to treat both its mechanical and its electromagnetic response to the GW consistently. We further introduce well-defined approximations for which this motion may be neglected, and hence provide suggestions on which coordinate frame is suitable to characterise the GW signal in practice. We illustrate our findings in two examples, an infinitesimally thin rod and a spherical electromagnetic cavity.","sentences":["In an external electric or magnetic field, a gravitational wave (GW) may be converted into electromagnetic radiation.","We present a coordinate-invariant framework to describe the GW signal in a detector that is based on this effect, such as cavities for axion searches.","In this framework, we pay special attention to the definition of manifestly coordinate-independent expressions for the electromagnetic fields that an external observer would detect.","A careful assessment of the detector's perceived motion allows us to treat both its mechanical and its electromagnetic response to the GW consistently.","We further introduce well-defined approximations for which this motion may be neglected, and hence provide suggestions on which coordinate frame is suitable to characterise the GW signal in practice.","We illustrate our findings in two examples, an infinitesimally thin rod and a spherical electromagnetic cavity."],"url":"http://arxiv.org/abs/2404.08572v1","category":"gr-qc"}
{"created":"2024-04-12 16:13:10","title":"Enhancing Autonomous Vehicle Training with Language Model Integration and Critical Scenario Generation","abstract":"This paper introduces CRITICAL, a novel closed-loop framework for autonomous vehicle (AV) training and testing. CRITICAL stands out for its ability to generate diverse scenarios, focusing on critical driving situations that target specific learning and performance gaps identified in the Reinforcement Learning (RL) agent. The framework achieves this by integrating real-world traffic dynamics, driving behavior analysis, surrogate safety measures, and an optional Large Language Model (LLM) component. It is proven that the establishment of a closed feedback loop between the data generation pipeline and the training process can enhance the learning rate during training, elevate overall system performance, and augment safety resilience. Our evaluations, conducted using the Proximal Policy Optimization (PPO) and the HighwayEnv simulation environment, demonstrate noticeable performance improvements with the integration of critical case generation and LLM analysis, indicating CRITICAL's potential to improve the robustness of AV systems and streamline the generation of critical scenarios. This ultimately serves to hasten the development of AV agents, expand the general scope of RL training, and ameliorate validation efforts for AV safety.","sentences":["This paper introduces CRITICAL, a novel closed-loop framework for autonomous vehicle (AV) training and testing.","CRITICAL stands out for its ability to generate diverse scenarios, focusing on critical driving situations that target specific learning and performance gaps identified in the Reinforcement Learning (RL) agent.","The framework achieves this by integrating real-world traffic dynamics, driving behavior analysis, surrogate safety measures, and an optional Large Language Model (LLM) component.","It is proven that the establishment of a closed feedback loop between the data generation pipeline and the training process can enhance the learning rate during training, elevate overall system performance, and augment safety resilience.","Our evaluations, conducted using the Proximal Policy Optimization (PPO) and the HighwayEnv simulation environment, demonstrate noticeable performance improvements with the integration of critical case generation and LLM analysis, indicating CRITICAL's potential to improve the robustness of AV systems and streamline the generation of critical scenarios.","This ultimately serves to hasten the development of AV agents, expand the general scope of RL training, and ameliorate validation efforts for AV safety."],"url":"http://arxiv.org/abs/2404.08570v1","category":"cs.RO"}
{"created":"2024-04-12 16:13:02","title":"A Gaussian model of fluctuating membrane and its scattering properties","abstract":"A mathematical model is developed, to jointly analyze elastic and inelastic scattering data of fluctuating membranes within a single theoretical framework. The model builds on a non-homogeneously clipped time-dependent Gaussian random field. This specific approach provides one with general analytical expressions for the intermediate scattering function, for any number of sublayers in the membrane and arbitrary contrasts. The model is illustrated with the analysis of small-angle x-ray and neutron scattering as well as with neutron spin-echo data measured on unilamellar vesicles prepared from phospholipids extracted from porcine brain tissues. The parameters fitted on the entire dataset are the lengths of the chain and head of the molecules that make up the membrane, the amplitude and lateral sizes of the bending deformations, the thickness fluctuation, and a single parameter characterizing the dynamics.","sentences":["A mathematical model is developed, to jointly analyze elastic and inelastic scattering data of fluctuating membranes within a single theoretical framework.","The model builds on a non-homogeneously clipped time-dependent Gaussian random field.","This specific approach provides one with general analytical expressions for the intermediate scattering function, for any number of sublayers in the membrane and arbitrary contrasts.","The model is illustrated with the analysis of small-angle x-ray and neutron scattering as well as with neutron spin-echo data measured on unilamellar vesicles prepared from phospholipids extracted from porcine brain tissues.","The parameters fitted on the entire dataset are the lengths of the chain and head of the molecules that make up the membrane, the amplitude and lateral sizes of the bending deformations, the thickness fluctuation, and a single parameter characterizing the dynamics."],"url":"http://arxiv.org/abs/2404.08569v1","category":"physics.chem-ph"}
{"created":"2024-04-12 16:08:32","title":"Mitigating Receiver Impact on Radio Frequency Fingerprint Identification via Domain Adaptation","abstract":"Radio Frequency Fingerprint Identification (RFFI), which exploits non-ideal hardware-induced unique distortion resident in the transmit signals to identify an emitter, is emerging as a means to enhance the security of communication systems. Recently, machine learning has achieved great success in developing state-of-the-art RFFI models. However, few works consider cross-receiver RFFI problems, where the RFFI model is trained and deployed on different receivers. Due to altered receiver characteristics, direct deployment of RFFI model on a new receiver leads to significant performance degradation. To address this issue, we formulate the cross-receiver RFFI as a model adaptation problem, which adapts the trained model to unlabeled signals from a new receiver. We first develop a theoretical generalization error bound for the adaptation model. Motivated by the bound, we propose a novel method to solve the cross-receiver RFFI problem, which includes domain alignment and adaptive pseudo-labeling. The former aims at finding a feature space where both domains exhibit similar distributions, effectively reducing the domain discrepancy. Meanwhile, the latter employs a dynamic pseudo-labeling scheme to implicitly transfer the label information from the labeled receiver to the new receiver. Experimental results indicate that the proposed method can effectively mitigate the receiver impact and improve the cross-receiver RFFI performance.","sentences":["Radio Frequency Fingerprint Identification (RFFI), which exploits non-ideal hardware-induced unique distortion resident in the transmit signals to identify an emitter, is emerging as a means to enhance the security of communication systems.","Recently, machine learning has achieved great success in developing state-of-the-art RFFI models.","However, few works consider cross-receiver RFFI problems, where the RFFI model is trained and deployed on different receivers.","Due to altered receiver characteristics, direct deployment of RFFI model on a new receiver leads to significant performance degradation.","To address this issue, we formulate the cross-receiver RFFI as a model adaptation problem, which adapts the trained model to unlabeled signals from a new receiver.","We first develop a theoretical generalization error bound for the adaptation model.","Motivated by the bound, we propose a novel method to solve the cross-receiver RFFI problem, which includes domain alignment and adaptive pseudo-labeling.","The former aims at finding a feature space where both domains exhibit similar distributions, effectively reducing the domain discrepancy.","Meanwhile, the latter employs a dynamic pseudo-labeling scheme to implicitly transfer the label information from the labeled receiver to the new receiver.","Experimental results indicate that the proposed method can effectively mitigate the receiver impact and improve the cross-receiver RFFI performance."],"url":"http://arxiv.org/abs/2404.08566v1","category":"eess.SP"}
{"created":"2024-04-12 16:01:02","title":"FusionPortableV2: A Unified Multi-Sensor Dataset for Generalized SLAM Across Diverse Platforms and Scalable Environments","abstract":"Simultaneous Localization and Mapping (SLAM) technology has been widely applied in various robotic scenarios, from rescue operations to autonomous driving. However, the generalization of SLAM algorithms remains a significant challenge, as current datasets often lack scalability in terms of platforms and environments. To address this limitation, we present FusionPortableV2, a multi-sensor SLAM dataset featuring notable sensor diversity, varied motion patterns, and a wide range of environmental scenarios. Our dataset comprises $27$ sequences, spanning over $2.5$ hours and collected from four distinct platforms: a handheld suite, wheeled and legged robots, and vehicles. These sequences cover diverse settings, including buildings, campuses, and urban areas, with a total length of $38.7km$. Additionally, the dataset includes ground-truth (GT) trajectories and RGB point cloud maps covering approximately $0.3km^2$. To validate the utility of our dataset in advancing SLAM research, we assess several state-of-the-art (SOTA) SLAM algorithms. Furthermore, we demonstrate the dataset's broad applicability beyond traditional SLAM tasks by investigating its potential for monocular depth estimation. The complete dataset, including sensor data, GT, and calibration details, is accessible at https://fusionportable.github.io/dataset/fusionportable_v2.","sentences":["Simultaneous Localization and Mapping (SLAM) technology has been widely applied in various robotic scenarios, from rescue operations to autonomous driving.","However, the generalization of SLAM algorithms remains a significant challenge, as current datasets often lack scalability in terms of platforms and environments.","To address this limitation, we present FusionPortableV2, a multi-sensor SLAM dataset featuring notable sensor diversity, varied motion patterns, and a wide range of environmental scenarios.","Our dataset comprises $27$ sequences, spanning over $2.5$ hours and collected from four distinct platforms: a handheld suite, wheeled and legged robots, and vehicles.","These sequences cover diverse settings, including buildings, campuses, and urban areas, with a total length of $38.7km$. Additionally, the dataset includes ground-truth (GT) trajectories and RGB point cloud maps covering approximately $0.3km^2$. To validate the utility of our dataset in advancing SLAM research, we assess several state-of-the-art (SOTA) SLAM algorithms.","Furthermore, we demonstrate the dataset's broad applicability beyond traditional SLAM tasks by investigating its potential for monocular depth estimation.","The complete dataset, including sensor data, GT, and calibration details, is accessible at https://fusionportable.github.io/dataset/fusionportable_v2."],"url":"http://arxiv.org/abs/2404.08563v1","category":"cs.RO"}
{"created":"2024-04-12 16:00:03","title":"IDD-X: A Multi-View Dataset for Ego-relative Important Object Localization and Explanation in Dense and Unstructured Traffic","abstract":"Intelligent vehicle systems require a deep understanding of the interplay between road conditions, surrounding entities, and the ego vehicle's driving behavior for safe and efficient navigation. This is particularly critical in developing countries where traffic situations are often dense and unstructured with heterogeneous road occupants. Existing datasets, predominantly geared towards structured and sparse traffic scenarios, fall short of capturing the complexity of driving in such environments. To fill this gap, we present IDD-X, a large-scale dual-view driving video dataset. With 697K bounding boxes, 9K important object tracks, and 1-12 objects per video, IDD-X offers comprehensive ego-relative annotations for multiple important road objects covering 10 categories and 19 explanation label categories. The dataset also incorporates rearview information to provide a more complete representation of the driving environment. We also introduce custom-designed deep networks aimed at multiple important object localization and per-object explanation prediction. Overall, our dataset and introduced prediction models form the foundation for studying how road conditions and surrounding entities affect driving behavior in complex traffic situations.","sentences":["Intelligent vehicle systems require a deep understanding of the interplay between road conditions, surrounding entities, and the ego vehicle's driving behavior for safe and efficient navigation.","This is particularly critical in developing countries where traffic situations are often dense and unstructured with heterogeneous road occupants.","Existing datasets, predominantly geared towards structured and sparse traffic scenarios, fall short of capturing the complexity of driving in such environments.","To fill this gap, we present IDD-X, a large-scale dual-view driving video dataset.","With 697K bounding boxes, 9K important object tracks, and 1-12 objects per video, IDD-X offers comprehensive ego-relative annotations for multiple important road objects covering 10 categories and 19 explanation label categories.","The dataset also incorporates rearview information to provide a more complete representation of the driving environment.","We also introduce custom-designed deep networks aimed at multiple important object localization and per-object explanation prediction.","Overall, our dataset and introduced prediction models form the foundation for studying how road conditions and surrounding entities affect driving behavior in complex traffic situations."],"url":"http://arxiv.org/abs/2404.08561v1","category":"cs.CV"}
{"created":"2024-04-12 15:54:48","title":"Scalability in Building Component Data Annotation: Enhancing Facade Material Classification with Synthetic Data","abstract":"Computer vision models trained on Google Street View images can create material cadastres. However, current approaches need manually annotated datasets that are difficult to obtain and often have class imbalance. To address these challenges, this paper fine-tuned a Swin Transformer model on a synthetic dataset generated with DALL-E and compared the performance to a similar manually annotated dataset. Although manual annotation remains the gold standard, the synthetic dataset performance demonstrates a reasonable alternative. The findings will ease annotation needed to develop material cadastres, offering architects insights into opportunities for material reuse, thus contributing to the reduction of demolition waste.","sentences":["Computer vision models trained on Google Street View images can create material cadastres.","However, current approaches need manually annotated datasets that are difficult to obtain and often have class imbalance.","To address these challenges, this paper fine-tuned a Swin Transformer model on a synthetic dataset generated with DALL-E and compared the performance to a similar manually annotated dataset.","Although manual annotation remains the gold standard, the synthetic dataset performance demonstrates a reasonable alternative.","The findings will ease annotation needed to develop material cadastres, offering architects insights into opportunities for material reuse, thus contributing to the reduction of demolition waste."],"url":"http://arxiv.org/abs/2404.08557v1","category":"cs.CV"}
{"created":"2024-04-12 15:54:37","title":"Quantum entropy couples matter with geometry","abstract":"We propose a theory for coupling matter fields with discrete geometry on higher-order networks, i.e. cell complexes. The key idea of the approach is to associate to a higher-order network the quantum entropy of its metric. Specifically we propose an action given by the quantum relative entropy between the metric of the higher-order network and the metric induced by the matter and gauge fields. The induced metric is defined in terms of the topological spinors and the discrete Dirac operators. The topological spinors, defined on nodes, edges and higher-dimensional cells, encode for the matter fields. The discrete Dirac operators act on topological spinors, and depend on the metric of the higher-order network as well as on the gauge fields via a discrete version of the minimal substitution. We derive the coupled dynamical equations for the metric, the matter and the gauge fields, providing an information theory principle to obtain the field theory equations in discrete curved space.","sentences":["We propose a theory for coupling matter fields with discrete geometry on higher-order networks, i.e. cell complexes.","The key idea of the approach is to associate to a higher-order network the quantum entropy of its metric.","Specifically we propose an action given by the quantum relative entropy between the metric of the higher-order network and the metric induced by the matter and gauge fields.","The induced metric is defined in terms of the topological spinors and the discrete Dirac operators.","The topological spinors, defined on nodes, edges and higher-dimensional cells, encode for the matter fields.","The discrete Dirac operators act on topological spinors, and depend on the metric of the higher-order network as well as on the gauge fields via a discrete version of the minimal substitution.","We derive the coupled dynamical equations for the metric, the matter and the gauge fields, providing an information theory principle to obtain the field theory equations in discrete curved space."],"url":"http://arxiv.org/abs/2404.08556v1","category":"cond-mat.dis-nn"}
{"created":"2024-04-12 15:54:15","title":"RLHF Deciphered: A Critical Analysis of Reinforcement Learning from Human Feedback for LLMs","abstract":"State-of-the-art large language models (LLMs) have become indispensable tools for various tasks. However, training LLMs to serve as effective assistants for humans requires careful consideration. A promising approach is reinforcement learning from human feedback (RLHF), which leverages human feedback to update the model in accordance with human preferences and mitigate issues like toxicity and hallucinations. Yet, an understanding of RLHF for LLMs is largely entangled with initial design choices that popularized the method and current research focuses on augmenting those choices rather than fundamentally improving the framework. In this paper, we analyze RLHF through the lens of reinforcement learning principles to develop an understanding of its fundamentals, dedicating substantial focus to the core component of RLHF -- the reward model. Our study investigates modeling choices, caveats of function approximation, and their implications on RLHF training algorithms, highlighting the underlying assumptions made about the expressivity of reward. Our analysis improves the understanding of the role of reward models and methods for their training, concurrently revealing limitations of the current methodology. We characterize these limitations, including incorrect generalization, model misspecification, and the sparsity of feedback, along with their impact on the performance of a language model. The discussion and analysis are substantiated by a categorical review of current literature, serving as a reference for researchers and practitioners to understand the challenges of RLHF and build upon existing efforts.","sentences":["State-of-the-art large language models (LLMs) have become indispensable tools for various tasks.","However, training LLMs to serve as effective assistants for humans requires careful consideration.","A promising approach is reinforcement learning from human feedback (RLHF), which leverages human feedback to update the model in accordance with human preferences and mitigate issues like toxicity and hallucinations.","Yet, an understanding of RLHF for LLMs is largely entangled with initial design choices that popularized the method and current research focuses on augmenting those choices rather than fundamentally improving the framework.","In this paper, we analyze RLHF through the lens of reinforcement learning principles to develop an understanding of its fundamentals, dedicating substantial focus to the core component of RLHF -- the reward model.","Our study investigates modeling choices, caveats of function approximation, and their implications on RLHF training algorithms, highlighting the underlying assumptions made about the expressivity of reward.","Our analysis improves the understanding of the role of reward models and methods for their training, concurrently revealing limitations of the current methodology.","We characterize these limitations, including incorrect generalization, model misspecification, and the sparsity of feedback, along with their impact on the performance of a language model.","The discussion and analysis are substantiated by a categorical review of current literature, serving as a reference for researchers and practitioners to understand the challenges of RLHF and build upon existing efforts."],"url":"http://arxiv.org/abs/2404.08555v1","category":"cs.LG"}
{"created":"2024-04-12 15:51:41","title":"Abelian Group Quantum Error Correction in Kitaev's Model","abstract":"In this paper, we present a detailed mathematical description of the error correction process for Kitaev's model for finite Abelian groups. The number of errors Kitaev's model can correct depends on the lattice and its topology. Although there is a theoretical maximum number of errors that can be corrected, we prove that correcting this number of errors, in general, is an NP-complete problem. Consequently, we introduce a polynomial-time correction algorithm that corrects a number of errors below the theoretical maximum.","sentences":["In this paper, we present a detailed mathematical description of the error correction process for Kitaev's model for finite Abelian groups.","The number of errors Kitaev's model can correct depends on the lattice and its topology.","Although there is a theoretical maximum number of errors that can be corrected, we prove that correcting this number of errors, in general, is an NP-complete problem.","Consequently, we introduce a polynomial-time correction algorithm that corrects a number of errors below the theoretical maximum."],"url":"http://arxiv.org/abs/2404.08552v1","category":"math.QA"}
{"created":"2024-04-12 15:39:49","title":"Functional reducibility of higher-order networks","abstract":"Empirical complex systems are widely assumed to be characterized not only by pairwise interactions, but also by higher-order (group) interactions that affect collective phenomena, from metabolic reactions to epidemics. Nevertheless, higher-order networks' superior descriptive power -- compared to classical pairwise networks -- comes with a much increased model complexity and computational cost. Consequently, it is of paramount importance to establish a quantitative method to determine when such a modeling framework is advantageous with respect to pairwise models, and to which extent it provides a parsimonious description of empirical systems. Here, we propose a principled method, based on information compression, to analyze the reducibility of higher-order networks to lower-order interactions, by identifying redundancies in diffusion processes while preserving the relevant functional information. The analysis of a broad spectrum of empirical systems shows that, although some networks contain non-compressible group interactions, others can be effectively approximated by lower-order interactions -- some technological and biological systems even just by pairwise interactions. More generally, our findings mark a significant step towards minimizing the dimensionality of models for complex systems","sentences":["Empirical complex systems are widely assumed to be characterized not only by pairwise interactions, but also by higher-order (group) interactions that affect collective phenomena, from metabolic reactions to epidemics.","Nevertheless, higher-order networks' superior descriptive power -- compared to classical pairwise networks -- comes with a much increased model complexity and computational cost.","Consequently, it is of paramount importance to establish a quantitative method to determine when such a modeling framework is advantageous with respect to pairwise models, and to which extent it provides a parsimonious description of empirical systems.","Here, we propose a principled method, based on information compression, to analyze the reducibility of higher-order networks to lower-order interactions, by identifying redundancies in diffusion processes while preserving the relevant functional information.","The analysis of a broad spectrum of empirical systems shows that, although some networks contain non-compressible group interactions, others can be effectively approximated by lower-order interactions -- some technological and biological systems even just by pairwise interactions.","More generally, our findings mark a significant step towards minimizing the dimensionality of models for complex systems"],"url":"http://arxiv.org/abs/2404.08547v1","category":"physics.soc-ph"}
{"created":"2024-04-12 15:39:18","title":"On the homotopy type of the space of fiberings of $S^1 \\times S^2$ by simple closed curves","abstract":"For most aspherical Seifert-fibered 3-manifolds $M$, the space of Seifert fiberings $SF(M)$ is known to have contractible components. It is also known that the space of Hopf fiberings of the three-sphere is noncontractible. We provide the second example of a non-aspherical 3-manifold $M$ such that $SF(M)$ has noncontractible components. In particular, we show that certain components of $SF(S^1 \\times S^2)$ are homotopy equivalent to a subspace homeomorphic to the identity-based loop space $\\Omega SO(3)$, and we exhibit second homology generators for both connected components of $SF(S^1 \\times S^2)$.","sentences":["For most aspherical Seifert-fibered 3-manifolds $M$, the space of Seifert fiberings $SF(M)$ is known to have contractible components.","It is also known that the space of Hopf fiberings of the three-sphere is noncontractible.","We provide the second example of a non-aspherical 3-manifold $M$ such that $SF(M)$ has noncontractible components.","In particular, we show that certain components of $SF(S^1 \\times S^2)$ are homotopy equivalent to a subspace homeomorphic to the identity-based loop space $\\Omega SO(3)$, and we exhibit second homology generators for both connected components of $SF(S^1 \\times S^2)$."],"url":"http://arxiv.org/abs/2404.08545v1","category":"math.GT"}
{"created":"2024-04-12 15:37:53","title":"Analyzing Decades-Long Environmental Changes in Namibia Using Archival Aerial Photography and Deep Learning","abstract":"This study explores object detection in historical aerial photographs of Namibia to identify long-term environmental changes. Specifically, we aim to identify key objects -- \\textit{Waterholes}, \\textit{Omuti homesteads}, and \\textit{Big trees} -- around Oshikango in Namibia using sub-meter gray-scale aerial imagery from 1943 and 1972. In this work, we propose a workflow for analyzing historical aerial imagery using a deep semantic segmentation model on sparse hand-labels. To this end, we employ a number of strategies including class-weighting, pseudo-labeling and empirical p-value-based filtering to balance skewed and sparse representations of objects in the ground truth data. Results demonstrate the benefits of these different training strategies resulting in an average $F_1=0.661$ and $F_1=0.755$ over the three objects of interest for the 1943 and 1972 imagery, respectively. We also identified that the average size of Waterhole and Big trees increased while the average size of Omutis decreased between 1943 and 1972 reflecting some of the local effects of the massive post-Second World War economic, agricultural, demographic, and environmental changes. This work also highlights the untapped potential of historical aerial photographs in understanding long-term environmental changes beyond Namibia (and Africa). With the lack of adequate satellite technology in the past, archival aerial photography offers a great alternative to uncover decades-long environmental changes.","sentences":["This study explores object detection in historical aerial photographs of Namibia to identify long-term environmental changes.","Specifically, we aim to identify key objects -- \\textit{Waterholes}, \\textit{Omuti homesteads}, and \\textit{Big trees} -- around Oshikango in Namibia using sub-meter gray-scale aerial imagery from 1943 and 1972.","In this work, we propose a workflow for analyzing historical aerial imagery using a deep semantic segmentation model on sparse hand-labels.","To this end, we employ a number of strategies including class-weighting, pseudo-labeling and empirical p-value-based filtering to balance skewed and sparse representations of objects in the ground truth data.","Results demonstrate the benefits of these different training strategies resulting in an average $F_1=0.661$ and $F_1=0.755$ over the three objects of interest for the 1943 and 1972 imagery, respectively.","We also identified that the average size of Waterhole and Big trees increased while the average size of Omutis decreased between 1943 and 1972 reflecting some of the local effects of the massive post-Second World War economic, agricultural, demographic, and environmental changes.","This work also highlights the untapped potential of historical aerial photographs in understanding long-term environmental changes beyond Namibia (and Africa).","With the lack of adequate satellite technology in the past, archival aerial photography offers a great alternative to uncover decades-long environmental changes."],"url":"http://arxiv.org/abs/2404.08544v1","category":"cs.CV"}
{"created":"2024-04-12 15:37:35","title":"Memory Traces: Are Transformers Tulving Machines?","abstract":"Memory traces--changes in the memory system that result from the perception and encoding of an event--were measured in pioneering studies by Endel Tulving and Michael J. Watkins in 1975. These and further experiments informed the maturation of Tulving's memory model, from the GAPS (General Abstract Processing System} to the SPI (Serial-Parallel Independent) model. Having current top of the line LLMs revisit the original Tulving-Watkins tests may help in assessing whether foundation models completely instantiate or not this class of psychological models.","sentences":["Memory traces--changes in the memory system that result from the perception and encoding of an event--were measured in pioneering studies by Endel Tulving and Michael J. Watkins in 1975.","These and further experiments informed the maturation of Tulving's memory model, from the GAPS (General Abstract Processing System} to the SPI (Serial-Parallel Independent) model.","Having current top of the line LLMs revisit the original Tulving-Watkins tests may help in assessing whether foundation models completely instantiate or not this class of psychological models."],"url":"http://arxiv.org/abs/2404.08543v1","category":"cs.AI"}
{"created":"2024-04-12 15:35:20","title":"On the Robustness of Language Guidance for Low-Level Vision Tasks: Findings from Depth Estimation","abstract":"Recent advances in monocular depth estimation have been made by incorporating natural language as additional guidance. Although yielding impressive results, the impact of the language prior, particularly in terms of generalization and robustness, remains unexplored. In this paper, we address this gap by quantifying the impact of this prior and introduce methods to benchmark its effectiveness across various settings. We generate \"low-level\" sentences that convey object-centric, three-dimensional spatial relationships, incorporate them as additional language priors and evaluate their downstream impact on depth estimation. Our key finding is that current language-guided depth estimators perform optimally only with scene-level descriptions and counter-intuitively fare worse with low level descriptions. Despite leveraging additional data, these methods are not robust to directed adversarial attacks and decline in performance with an increase in distribution shift. Finally, to provide a foundation for future research, we identify points of failures and offer insights to better understand these shortcomings. With an increasing number of methods using language for depth estimation, our findings highlight the opportunities and pitfalls that require careful consideration for effective deployment in real-world settings","sentences":["Recent advances in monocular depth estimation have been made by incorporating natural language as additional guidance.","Although yielding impressive results, the impact of the language prior, particularly in terms of generalization and robustness, remains unexplored.","In this paper, we address this gap by quantifying the impact of this prior and introduce methods to benchmark its effectiveness across various settings.","We generate \"low-level\" sentences that convey object-centric, three-dimensional spatial relationships, incorporate them as additional language priors and evaluate their downstream impact on depth estimation.","Our key finding is that current language-guided depth estimators perform optimally only with scene-level descriptions and counter-intuitively fare worse with low level descriptions.","Despite leveraging additional data, these methods are not robust to directed adversarial attacks and decline in performance with an increase in distribution shift.","Finally, to provide a foundation for future research, we identify points of failures and offer insights to better understand these shortcomings.","With an increasing number of methods using language for depth estimation, our findings highlight the opportunities and pitfalls that require careful consideration for effective deployment in real-world settings"],"url":"http://arxiv.org/abs/2404.08540v1","category":"cs.CV"}
{"created":"2024-04-12 15:33:34","title":"Relativistic SZ temperatures and hydrostatic mass bias for massive clusters in the FLAMINGO simulations","abstract":"The relativistic Sunyaev-Zel'dovich (SZ) effect can be used to measure intracluster gas temperatures independently of X-ray spectroscopy. Here, we use the large-volume FLAMINGO simulation suite to determine whether SZ $y$-weighted temperatures lead to more accurate hydrostatic mass estimates in massive ($M_{\\rm 500c} > 7.5\\times 10^{14}\\,{\\rm M}_{\\odot}$) clusters than when using X-ray spectroscopic-like temperatures. We find this to be the case, on average. The median bias in the SZ mass at redshift zero is $\\left< b \\right> \\equiv 1-\\left< M_{\\rm 500c,hse}/M_{\\rm 500c,true} \\right> = -0.05 \\pm 0.01$, over 4 times smaller in magnitude than the X-ray spectroscopic-like case, $\\left< b \\right> = 0.22 \\pm 0.01$. However, the scatter in the SZ bias, $\\sigma_{b} \\approx 0.2$, is around 40 per cent larger than for the X-ray case. We show that this difference is strongly affected by clusters with large pressure fluctuations, as expected from shocks in ongoing mergers. Selecting the clusters with the best-fitting generalized NFW pressure profiles, the median SZ bias almost vanishes, $\\left< b \\right> = -0.009 \\pm 0.005$, and the scatter is halved to $\\sigma_{b} \\approx 0.1$. We study the origin of the SZ/X-ray difference and find that, at $R_{\\rm 500c}$ and in the outskirts, SZ weighted gas better reflects the hot, hydrostatic atmosphere than the X-ray weighted gas. The SZ/X-ray temperature ratio increases with radius, a result we find to be insensitive to variations in baryonic physics, cosmology and numerical resolution.","sentences":["The relativistic Sunyaev-Zel'dovich (SZ) effect can be used to measure intracluster gas temperatures independently of X-ray spectroscopy.","Here, we use the large-volume FLAMINGO simulation suite to determine whether SZ $y$-weighted temperatures lead to more accurate hydrostatic mass estimates in massive ($M_{\\rm 500c} > 7.5\\times","10^{14}\\,{\\rm M}_{\\odot}$) clusters than when using X-ray spectroscopic-like temperatures.","We find this to be the case, on average.","The median bias in the SZ mass at redshift zero is $\\left< b \\right> \\equiv 1-\\left<","M_{\\rm 500c,hse}/M_{\\rm 500c,true} \\right> = -0.05 \\pm 0.01$, over 4 times smaller in magnitude than the X-ray spectroscopic-like case, $\\left< b \\right> = 0.22 \\pm 0.01$.","However, the scatter in the SZ bias, $\\sigma_{b} \\approx 0.2$, is around 40 per cent larger than for the X-ray case.","We show that this difference is strongly affected by clusters with large pressure fluctuations, as expected from shocks in ongoing mergers.","Selecting the clusters with the best-fitting generalized NFW pressure profiles, the median SZ bias almost vanishes, $\\left< b \\right> = -0.009 \\pm 0.005$, and the scatter is halved to $\\sigma_{b} \\approx 0.1$.","We study the origin of the SZ/X-ray difference and find that, at $R_{\\rm 500c}$ and in the outskirts, SZ weighted gas better reflects the hot, hydrostatic atmosphere than the X-ray weighted gas.","The SZ/X-ray temperature ratio increases with radius, a result we find to be insensitive to variations in baryonic physics, cosmology and numerical resolution."],"url":"http://arxiv.org/abs/2404.08539v1","category":"astro-ph.CO"}
{"created":"2024-04-12 15:30:03","title":"Generalized Contrastive Learning for Multi-Modal Retrieval and Ranking","abstract":"Contrastive learning has gained widespread adoption for retrieval tasks due to its minimal requirement for manual annotations. However, popular contrastive frameworks typically learn from binary relevance, making them ineffective at incorporating direct fine-grained rankings. In this paper, we curate a large-scale dataset featuring detailed relevance scores for each query-document pair to facilitate future research and evaluation. Subsequently, we propose Generalized Contrastive Learning for Multi-Modal Retrieval and Ranking (GCL), which is designed to learn from fine-grained rankings beyond binary relevance scores. Our results show that GCL achieves a 94.5% increase in NDCG@10 for in-domain and 26.3 to 48.8% increases for cold-start evaluations, all relative to the CLIP baseline and involving ground truth rankings.","sentences":["Contrastive learning has gained widespread adoption for retrieval tasks due to its minimal requirement for manual annotations.","However, popular contrastive frameworks typically learn from binary relevance, making them ineffective at incorporating direct fine-grained rankings.","In this paper, we curate a large-scale dataset featuring detailed relevance scores for each query-document pair to facilitate future research and evaluation.","Subsequently, we propose Generalized Contrastive Learning for Multi-Modal Retrieval and Ranking (GCL), which is designed to learn from fine-grained rankings beyond binary relevance scores.","Our results show that GCL achieves a 94.5% increase in NDCG@10 for in-domain and 26.3 to 48.8% increases for cold-start evaluations, all relative to the CLIP baseline and involving ground truth rankings."],"url":"http://arxiv.org/abs/2404.08535v1","category":"cs.IR"}
{"created":"2024-04-12 15:24:19","title":"A Data Fusion Model for Meteorological Data using the INLA-SPDE method","abstract":"This work aims to combine two primary meteorological data sources in the Philippines: data from a sparse network of weather stations and outcomes of a numerical weather prediction model. To this end, we propose a data fusion model which is primarily motivated by the problem of sparsity in the observational data and the use of a numerical prediction model as an additional data source in order to obtain better predictions for the variables of interest. The proposed data fusion model assumes that the different data sources are error-prone realizations of a common latent process. The outcomes from the weather stations follow the classical error model while the outcomes of the numerical weather prediction model involves a constant multiplicative bias parameter and an additive bias which is spatially-structured and time-varying. We use a Bayesian model averaging approach with the integrated nested Laplace approximation (INLA) for doing inference. The proposed data fusion model outperforms the stations-only model and the regression calibration approach, when assessed using leave-group-out cross-validation (LGOCV). We assess the benefits of data fusion and evaluate the accuracy of predictions and parameter estimation through a simulation study. The results show that the proposed data fusion model generally gives better predictions compared to the stations-only approach especially with sparse observational data.","sentences":["This work aims to combine two primary meteorological data sources in the Philippines: data from a sparse network of weather stations and outcomes of a numerical weather prediction model.","To this end, we propose a data fusion model which is primarily motivated by the problem of sparsity in the observational data and the use of a numerical prediction model as an additional data source in order to obtain better predictions for the variables of interest.","The proposed data fusion model assumes that the different data sources are error-prone realizations of a common latent process.","The outcomes from the weather stations follow the classical error model while the outcomes of the numerical weather prediction model involves a constant multiplicative bias parameter and an additive bias which is spatially-structured and time-varying.","We use a Bayesian model averaging approach with the integrated nested Laplace approximation (INLA) for doing inference.","The proposed data fusion model outperforms the stations-only model and the regression calibration approach, when assessed using leave-group-out cross-validation (LGOCV).","We assess the benefits of data fusion and evaluate the accuracy of predictions and parameter estimation through a simulation study.","The results show that the proposed data fusion model generally gives better predictions compared to the stations-only approach especially with sparse observational data."],"url":"http://arxiv.org/abs/2404.08533v1","category":"stat.AP"}
{"created":"2024-04-12 15:18:25","title":"Text Prompt with Normality Guidance for Weakly Supervised Video Anomaly Detection","abstract":"Weakly supervised video anomaly detection (WSVAD) is a challenging task. Generating fine-grained pseudo-labels based on weak-label and then self-training a classifier is currently a promising solution. However, since the existing methods use only RGB visual modality and the utilization of category text information is neglected, thus limiting the generation of more accurate pseudo-labels and affecting the performance of self-training. Inspired by the manual labeling process based on the event description, in this paper, we propose a novel pseudo-label generation and self-training framework based on Text Prompt with Normality Guidance (TPWNG) for WSVAD. Our idea is to transfer the rich language-visual knowledge of the contrastive language-image pre-training (CLIP) model for aligning the video event description text and corresponding video frames to generate pseudo-labels. Specifically, We first fine-tune the CLIP for domain adaptation by designing two ranking losses and a distributional inconsistency loss. Further, we propose a learnable text prompt mechanism with the assist of a normality visual prompt to further improve the matching accuracy of video event description text and video frames. Then, we design a pseudo-label generation module based on the normality guidance to infer reliable frame-level pseudo-labels. Finally, we introduce a temporal context self-adaptive learning module to learn the temporal dependencies of different video events more flexibly and accurately. Extensive experiments show that our method achieves state-of-the-art performance on two benchmark datasets, UCF-Crime and XD-Viole","sentences":["Weakly supervised video anomaly detection (WSVAD) is a challenging task.","Generating fine-grained pseudo-labels based on weak-label and then self-training a classifier is currently a promising solution.","However, since the existing methods use only RGB visual modality and the utilization of category text information is neglected, thus limiting the generation of more accurate pseudo-labels and affecting the performance of self-training.","Inspired by the manual labeling process based on the event description, in this paper, we propose a novel pseudo-label generation and self-training framework based on Text Prompt with Normality Guidance (TPWNG) for WSVAD.","Our idea is to transfer the rich language-visual knowledge of the contrastive language-image pre-training (CLIP) model for aligning the video event description text and corresponding video frames to generate pseudo-labels.","Specifically, We first fine-tune the CLIP for domain adaptation by designing two ranking losses and a distributional inconsistency loss.","Further, we propose a learnable text prompt mechanism with the assist of a normality visual prompt to further improve the matching accuracy of video event description text and video frames.","Then, we design a pseudo-label generation module based on the normality guidance to infer reliable frame-level pseudo-labels.","Finally, we introduce a temporal context self-adaptive learning module to learn the temporal dependencies of different video events more flexibly and accurately.","Extensive experiments show that our method achieves state-of-the-art performance on two benchmark datasets, UCF-Crime and XD-Viole"],"url":"http://arxiv.org/abs/2404.08531v1","category":"cs.CV"}
{"created":"2024-04-12 15:16:21","title":"Spin-resolved nonlocal transport in proximitized Rashba nanowires","abstract":"Non-equilibrium transport in hybrid semiconductor-superconductor nanowires is crucial for many quantum phenomena such as generating entangled states via cross Andreev reflection (CAR) processes, detecting topological superconductivity, reading out Andreev spin qubits, coupling spin qubits over long distances and so on. Here, we investigate numerically transport properties of a proximitized Rashba nanowire that hosts spin-polarized low-energy quasiparticle states. We show that the spin polarization in such one-dimensional Andreev bands, extended over the entire nanowire length, can be detected in nonlocal transport measurements with tunnel-coupled side leads that are spin polarized. Remarkably, we find an exact correspondence between the sign of the nonlocal conductance and the spin density of the superconducting quasiparticles at the side lead position. We demonstrate that this feature is robust to moderate static disorder. As an example, we show that such a method can be used to detect spin inversion of the bands, accompanying the topological phase transition (TPT) for realistic system parameters. Furthermore, we show that such effects can be used to switch between CAR and elastic cotunneling (ECT) processes by tuning the strength of either the electric or the magnetic field. These findings hold significant practical implications for state-of-the-art transport experiments in such hybrid systems.","sentences":["Non-equilibrium transport in hybrid semiconductor-superconductor nanowires is crucial for many quantum phenomena such as generating entangled states via cross Andreev reflection (CAR) processes, detecting topological superconductivity, reading out Andreev spin qubits, coupling spin qubits over long distances and so on.","Here, we investigate numerically transport properties of a proximitized Rashba nanowire that hosts spin-polarized low-energy quasiparticle states.","We show that the spin polarization in such one-dimensional Andreev bands, extended over the entire nanowire length, can be detected in nonlocal transport measurements with tunnel-coupled side leads that are spin polarized.","Remarkably, we find an exact correspondence between the sign of the nonlocal conductance and the spin density of the superconducting quasiparticles at the side lead position.","We demonstrate that this feature is robust to moderate static disorder.","As an example, we show that such a method can be used to detect spin inversion of the bands, accompanying the topological phase transition (TPT) for realistic system parameters.","Furthermore, we show that such effects can be used to switch between CAR and elastic cotunneling (ECT) processes by tuning the strength of either the electric or the magnetic field.","These findings hold significant practical implications for state-of-the-art transport experiments in such hybrid systems."],"url":"http://arxiv.org/abs/2404.08527v1","category":"cond-mat.mes-hall"}
{"created":"2024-04-12 15:15:39","title":"Masked Image Modeling as a Framework for Self-Supervised Learning across Eye Movements","abstract":"To make sense of their surroundings, intelligent systems must transform complex sensory inputs to structured codes that are reduced to task-relevant information such as object category. Biological agents achieve this in a largely autonomous manner, presumably via self-\\allowbreak super-\\allowbreak vised learning. Whereas previous attempts to model the underlying mechanisms were largely discriminative in nature, there is ample evidence that the brain employs a generative model of the world. Here, we propose that eye movements, in combination with the focused nature of primate vision, constitute a generative, self-supervised task of predicting and revealing visual information. We construct a proof-of-principle model starting from the framework of masked image modeling (MIM), a common approach in deep representation learning. To do so, we analyze how core components of MIM such as masking technique and data augmentation influence the formation of category-specific representations. This allows us not only to better understand the principles behind MIM, but to then reassemble a MIM more in line with the focused nature of biological perception. From a theoretical angle, we find that MIM disentangles neurons in latent space, a property that has been suggested to structure visual representations in primates, without explicit regulation. Together with previous findings of invariance learning, this highlights an interesting connection of MIM to latent regularization approaches for self-supervised learning. The source code is available under https://github.com/RobinWeiler/FocusMIM","sentences":["To make sense of their surroundings, intelligent systems must transform complex sensory inputs to structured codes that are reduced to task-relevant information such as object category.","Biological agents achieve this in a largely autonomous manner, presumably via self-\\allowbreak super-\\allowbreak vised learning.","Whereas previous attempts to model the underlying mechanisms were largely discriminative in nature, there is ample evidence that the brain employs a generative model of the world.","Here, we propose that eye movements, in combination with the focused nature of primate vision, constitute a generative, self-supervised task of predicting and revealing visual information.","We construct a proof-of-principle model starting from the framework of masked image modeling (MIM), a common approach in deep representation learning.","To do so, we analyze how core components of MIM such as masking technique and data augmentation influence the formation of category-specific representations.","This allows us not only to better understand the principles behind MIM, but to then reassemble a MIM more in line with the focused nature of biological perception.","From a theoretical angle, we find that MIM disentangles neurons in latent space, a property that has been suggested to structure visual representations in primates, without explicit regulation.","Together with previous findings of invariance learning, this highlights an interesting connection of MIM to latent regularization approaches for self-supervised learning.","The source code is available under https://github.com/RobinWeiler/FocusMIM"],"url":"http://arxiv.org/abs/2404.08526v1","category":"cs.CV"}
{"created":"2024-04-12 15:14:01","title":"Active nematic liquid crytals under a quenched random field","abstract":"Coupling between flow and orientation is a central issue in understanding the collective dynamics of active biofilaments and cells. Active stressess generated by motor activity destroy (quasi-)long-range orientational order and induce chaotic vortex flows. In cellular and subcellular environment, alignment is also hindered by heterogeneous filamentous structures in extracellular matrix and various organelles in a cell. Here we address the effects of a quenched random field on the flow patterns and orientational order in two-dimensional active nematic liquid crystals. We found that the director dynamics is frozen above a critical disorder strength. For sufficiently strong randomness, the orientational correlation function decays exponentially with the distance, reproducing the behavior of passive random-field nematics. In contrast, the flow velocity decreases only gradually as the randomness is increased, and develops a logarithmic spatial correlation for strong disorder. The threshold between the activity- and disorder-dominated regimes is specified and its dependence on the activity parameter is discussed.","sentences":["Coupling between flow and orientation is a central issue in understanding the collective dynamics of active biofilaments and cells.","Active stressess generated by motor activity destroy (quasi-)long-range orientational order and induce chaotic vortex flows.","In cellular and subcellular environment, alignment is also hindered by heterogeneous filamentous structures in extracellular matrix and various organelles in a cell.","Here we address the effects of a quenched random field on the flow patterns and orientational order in two-dimensional active nematic liquid crystals.","We found that the director dynamics is frozen above a critical disorder strength.","For sufficiently strong randomness, the orientational correlation function decays exponentially with the distance, reproducing the behavior of passive random-field nematics.","In contrast, the flow velocity decreases only gradually as the randomness is increased, and develops a logarithmic spatial correlation for strong disorder.","The threshold between the activity- and disorder-dominated regimes is specified and its dependence on the activity parameter is discussed."],"url":"http://arxiv.org/abs/2404.08524v1","category":"cond-mat.soft"}
{"created":"2024-04-12 15:10:57","title":"Advancing Forest Fire Prevention: Deep Reinforcement Learning for Effective Firebreak Placement","abstract":"Over the past decades, the increase in both frequency and intensity of large-scale wildfires due to climate change has emerged as a significant natural threat. The pressing need to design resilient landscapes capable of withstanding such disasters has become paramount, requiring the development of advanced decision-support tools. Existing methodologies, including Mixed Integer Programming, Stochastic Optimization, and Network Theory, have proven effective but are hindered by computational demands, limiting their applicability.   In response to this challenge, we propose using artificial intelligence techniques, specifically Deep Reinforcement Learning, to address the complex problem of firebreak placement in the landscape. We employ value-function based approaches like Deep Q-Learning, Double Deep Q-Learning, and Dueling Double Deep Q-Learning. Utilizing the Cell2Fire fire spread simulator combined with Convolutional Neural Networks, we have successfully implemented a computational agent capable of learning firebreak locations within a forest environment, achieving good results.   Furthermore, we incorporate a pre-training loop, initially teaching our agent to mimic a heuristic-based algorithm and observe that it consistently exceeds the performance of these solutions. Our findings underscore the immense potential of Deep Reinforcement Learning for operational research challenges, especially in fire prevention. Our approach demonstrates convergence with highly favorable results in problem instances as large as 40 x 40 cells, marking a significant milestone in applying Reinforcement Learning to this critical issue.   To the best of our knowledge, this study represents a pioneering effort in using Reinforcement Learning to address the aforementioned problem, offering promising perspectives in fire prevention and landscape management","sentences":["Over the past decades, the increase in both frequency and intensity of large-scale wildfires due to climate change has emerged as a significant natural threat.","The pressing need to design resilient landscapes capable of withstanding such disasters has become paramount, requiring the development of advanced decision-support tools.","Existing methodologies, including Mixed Integer Programming, Stochastic Optimization, and Network Theory, have proven effective but are hindered by computational demands, limiting their applicability.   ","In response to this challenge, we propose using artificial intelligence techniques, specifically Deep Reinforcement Learning, to address the complex problem of firebreak placement in the landscape.","We employ value-function based approaches like Deep Q-Learning, Double Deep Q-Learning, and Dueling Double Deep Q-Learning.","Utilizing the Cell2Fire fire spread simulator combined with Convolutional Neural Networks, we have successfully implemented a computational agent capable of learning firebreak locations within a forest environment, achieving good results.   ","Furthermore, we incorporate a pre-training loop, initially teaching our agent to mimic a heuristic-based algorithm and observe that it consistently exceeds the performance of these solutions.","Our findings underscore the immense potential of Deep Reinforcement Learning for operational research challenges, especially in fire prevention.","Our approach demonstrates convergence with highly favorable results in problem instances as large as 40 x 40 cells, marking a significant milestone in applying Reinforcement Learning to this critical issue.   ","To the best of our knowledge, this study represents a pioneering effort in using Reinforcement Learning to address the aforementioned problem, offering promising perspectives in fire prevention and landscape management"],"url":"http://arxiv.org/abs/2404.08523v1","category":"cs.LG"}
{"created":"2024-04-12 15:02:14","title":"Fuxi-DA: A Generalized Deep Learning Data Assimilation Framework for Assimilating Satellite Observations","abstract":"Data assimilation (DA), as an indispensable component within contemporary Numerical Weather Prediction (NWP) systems, plays a crucial role in generating the analysis that significantly impacts forecast performance. Nevertheless, the development of an efficient DA system poses significant challenges, particularly in establishing intricate relationships between the background data and the vast amount of multi-source observation data within limited time windows in operational settings. To address these challenges, researchers design complex pre-processing methods for each observation type, leveraging approximate modeling and the power of super-computing clusters to expedite solutions. The emergence of deep learning (DL) models has been a game-changer, offering unified multi-modal modeling, enhanced nonlinear representation capabilities, and superior parallelization. These advantages have spurred efforts to integrate DL models into various domains of weather modeling. Remarkably, DL models have shown promise in matching, even surpassing, the forecast accuracy of leading operational NWP models worldwide. This success motivates the exploration of DL-based DA frameworks tailored for weather forecasting models. In this study, we introduces FuxiDA, a generalized DL-based DA framework for assimilating satellite observations. By assimilating data from Advanced Geosynchronous Radiation Imager (AGRI) aboard Fengyun-4B, FuXi-DA consistently mitigates analysis errors and significantly improves forecast performance. Furthermore, through a series of single-observation experiments, Fuxi-DA has been validated against established atmospheric physics, demonstrating its consistency and reliability.","sentences":["Data assimilation (DA), as an indispensable component within contemporary Numerical Weather Prediction (NWP) systems, plays a crucial role in generating the analysis that significantly impacts forecast performance.","Nevertheless, the development of an efficient DA system poses significant challenges, particularly in establishing intricate relationships between the background data and the vast amount of multi-source observation data within limited time windows in operational settings.","To address these challenges, researchers design complex pre-processing methods for each observation type, leveraging approximate modeling and the power of super-computing clusters to expedite solutions.","The emergence of deep learning (DL) models has been a game-changer, offering unified multi-modal modeling, enhanced nonlinear representation capabilities, and superior parallelization.","These advantages have spurred efforts to integrate DL models into various domains of weather modeling.","Remarkably, DL models have shown promise in matching, even surpassing, the forecast accuracy of leading operational NWP models worldwide.","This success motivates the exploration of DL-based DA frameworks tailored for weather forecasting models.","In this study, we introduces FuxiDA, a generalized DL-based DA framework for assimilating satellite observations.","By assimilating data from Advanced Geosynchronous Radiation Imager (AGRI) aboard Fengyun-4B, FuXi-DA consistently mitigates analysis errors and significantly improves forecast performance.","Furthermore, through a series of single-observation experiments, Fuxi-DA has been validated against established atmospheric physics, demonstrating its consistency and reliability."],"url":"http://arxiv.org/abs/2404.08522v1","category":"cs.LG"}
{"created":"2024-04-12 14:59:58","title":"Non-discrimination law in Europe: a primer. Introducing European non-discrimination law to non-lawyers","abstract":"This brief paper provides an introduction to non-discrimination law in Europe. It answers the questions: What are the key characteristics of non-discrimination law in Europe, and how do the different statutes relate to one another? Our main target group is computer scientists and users of artificial intelligence (AI) interested in an introduction to non-discrimination law in Europe. Notably, non-discrimination law in Europe differs significantly from non-discrimination law in other countries, such as the US. We aim to describe the law in such a way that non-lawyers and non-European lawyers can easily grasp its contents and challenges. The paper shows that the human right to non-discrimination, to some extent, protects individuals against private actors, such as companies. We introduce the EU-wide non-discrimination rules which are included in a number of EU directives, and also explain the difference between direct and indirect discrimination. Significantly, an organization can be fined for indirect discrimination even if the company, or its AI system, discriminated by accident. The last section broadens the horizon to include bias-relevant law and cases from the GDPR, the EU AI Act, and related statutes. Finally, we give reading tips for those inclined to learn more about non-discrimination law in Europe.","sentences":["This brief paper provides an introduction to non-discrimination law in Europe.","It answers the questions: What are the key characteristics of non-discrimination law in Europe, and how do the different statutes relate to one another?","Our main target group is computer scientists and users of artificial intelligence (AI) interested in an introduction to non-discrimination law in Europe.","Notably, non-discrimination law in Europe differs significantly from non-discrimination law in other countries, such as the US.","We aim to describe the law in such a way that non-lawyers and non-European lawyers can easily grasp its contents and challenges.","The paper shows that the human right to non-discrimination, to some extent, protects individuals against private actors, such as companies.","We introduce the EU-wide non-discrimination rules which are included in a number of EU directives, and also explain the difference between direct and indirect discrimination.","Significantly, an organization can be fined for indirect discrimination even if the company, or its AI system, discriminated by accident.","The last section broadens the horizon to include bias-relevant law and cases from the GDPR, the EU AI Act, and related statutes.","Finally, we give reading tips for those inclined to learn more about non-discrimination law in Europe."],"url":"http://arxiv.org/abs/2404.08519v1","category":"cs.CY"}
{"created":"2024-04-12 14:56:38","title":"A systematic approach to Diophantine equations: open problems","abstract":"This paper collects polynomial Diophantine equations that are amazingly simple to write down but are apparently difficult to solve.","sentences":["This paper collects polynomial Diophantine equations that are amazingly simple to write down but are apparently difficult to solve."],"url":"http://arxiv.org/abs/2404.08518v1","category":"math.GM"}
{"created":"2024-04-12 14:55:16","title":"Online Safety Analysis for LLMs: a Benchmark, an Assessment, and a Path Forward","abstract":"While Large Language Models (LLMs) have seen widespread applications across numerous fields, their limited interpretability poses concerns regarding their safe operations from multiple aspects, e.g., truthfulness, robustness, and fairness. Recent research has started developing quality assurance methods for LLMs, introducing techniques such as offline detector-based or uncertainty estimation methods. However, these approaches predominantly concentrate on post-generation analysis, leaving the online safety analysis for LLMs during the generation phase an unexplored area. To bridge this gap, we conduct in this work a comprehensive evaluation of the effectiveness of existing online safety analysis methods on LLMs. We begin with a pilot study that validates the feasibility of detecting unsafe outputs in the early generation process. Following this, we establish the first publicly available benchmark of online safety analysis for LLMs, including a broad spectrum of methods, models, tasks, datasets, and evaluation metrics. Utilizing this benchmark, we extensively analyze the performance of state-of-the-art online safety analysis methods on both open-source and closed-source LLMs. This analysis reveals the strengths and weaknesses of individual methods and offers valuable insights into selecting the most appropriate method based on specific application scenarios and task requirements. Furthermore, we also explore the potential of using hybridization methods, i.e., combining multiple methods to derive a collective safety conclusion, to enhance the efficacy of online safety analysis for LLMs. Our findings indicate a promising direction for the development of innovative and trustworthy quality assurance methodologies for LLMs, facilitating their reliable deployments across diverse domains.","sentences":["While Large Language Models (LLMs) have seen widespread applications across numerous fields, their limited interpretability poses concerns regarding their safe operations from multiple aspects, e.g., truthfulness, robustness, and fairness.","Recent research has started developing quality assurance methods for LLMs, introducing techniques such as offline detector-based or uncertainty estimation methods.","However, these approaches predominantly concentrate on post-generation analysis, leaving the online safety analysis for LLMs during the generation phase an unexplored area.","To bridge this gap, we conduct in this work a comprehensive evaluation of the effectiveness of existing online safety analysis methods on LLMs.","We begin with a pilot study that validates the feasibility of detecting unsafe outputs in the early generation process.","Following this, we establish the first publicly available benchmark of online safety analysis for LLMs, including a broad spectrum of methods, models, tasks, datasets, and evaluation metrics.","Utilizing this benchmark, we extensively analyze the performance of state-of-the-art online safety analysis methods on both open-source and closed-source LLMs.","This analysis reveals the strengths and weaknesses of individual methods and offers valuable insights into selecting the most appropriate method based on specific application scenarios and task requirements.","Furthermore, we also explore the potential of using hybridization methods, i.e., combining multiple methods to derive a collective safety conclusion, to enhance the efficacy of online safety analysis for LLMs.","Our findings indicate a promising direction for the development of innovative and trustworthy quality assurance methodologies for LLMs, facilitating their reliable deployments across diverse domains."],"url":"http://arxiv.org/abs/2404.08517v1","category":"cs.SE"}
{"created":"2024-04-12 14:54:34","title":"ChatGPT and general-purpose AI count fruits in pictures surprisingly well","abstract":"Object counting is a popular task in deep learning applications in various domains, including agriculture. A conventional deep learning approach requires a large amount of training data, often a logistic problem in a real-world application. To address this issue, we examined how well ChatGPT (GPT4V) and a general-purpose AI (foundation model for object counting, T-Rex) can count the number of fruit bodies (coffee cherries) in 100 images. The foundation model with few-shot learning outperformed the trained YOLOv8 model (R2 = 0.923 and 0.900, respectively). ChatGPT also showed some interesting potential, especially when few-shot learning with human feedback was applied (R2 = 0.360 and 0.460, respectively). Moreover, we examined the time required for implementation as a practical question. Obtaining the results with the foundation model and ChatGPT were much shorter than the YOLOv8 model (0.83 hrs, 1.75 hrs, and 161 hrs). We interpret these results as two surprises for deep learning users in applied domains: a foundation model with few-shot domain-specific learning can drastically save time and effort compared to the conventional approach, and ChatGPT can reveal a relatively good performance. Both approaches do not need coding skills, which can foster AI education and dissemination.","sentences":["Object counting is a popular task in deep learning applications in various domains, including agriculture.","A conventional deep learning approach requires a large amount of training data, often a logistic problem in a real-world application.","To address this issue, we examined how well ChatGPT (GPT4V) and a general-purpose AI (foundation model for object counting, T-Rex) can count the number of fruit bodies (coffee cherries) in 100 images.","The foundation model with few-shot learning outperformed the trained YOLOv8 model (R2 = 0.923 and 0.900, respectively).","ChatGPT also showed some interesting potential, especially when few-shot learning with human feedback was applied (R2 = 0.360 and 0.460, respectively).","Moreover, we examined the time required for implementation as a practical question.","Obtaining the results with the foundation model and ChatGPT were much shorter than the YOLOv8 model (0.83 hrs, 1.75 hrs, and 161 hrs).","We interpret these results as two surprises for deep learning users in applied domains: a foundation model with few-shot domain-specific learning can drastically save time and effort compared to the conventional approach, and ChatGPT can reveal a relatively good performance.","Both approaches do not need coding skills, which can foster AI education and dissemination."],"url":"http://arxiv.org/abs/2404.08515v1","category":"cs.CV"}
{"created":"2024-04-12 14:53:36","title":"Adversarial Imitation Learning via Boosting","abstract":"Adversarial imitation learning (AIL) has stood out as a dominant framework across various imitation learning (IL) applications, with Discriminator Actor Critic (DAC) (Kostrikov et al.,, 2019) demonstrating the effectiveness of off-policy learning algorithms in improving sample efficiency and scalability to higher-dimensional observations. Despite DAC's empirical success, the original AIL objective is on-policy and DAC's ad-hoc application of off-policy training does not guarantee successful imitation (Kostrikov et al., 2019; 2020). Follow-up work such as ValueDICE (Kostrikov et al., 2020) tackles this issue by deriving a fully off-policy AIL objective. Instead in this work, we develop a novel and principled AIL algorithm via the framework of boosting. Like boosting, our new algorithm, AILBoost, maintains an ensemble of properly weighted weak learners (i.e., policies) and trains a discriminator that witnesses the maximum discrepancy between the distributions of the ensemble and the expert policy. We maintain a weighted replay buffer to represent the state-action distribution induced by the ensemble, allowing us to train discriminators using the entire data collected so far. In the weighted replay buffer, the contribution of the data from older policies are properly discounted with the weight computed based on the boosting framework. Empirically, we evaluate our algorithm on both controller state-based and pixel-based environments from the DeepMind Control Suite. AILBoost outperforms DAC on both types of environments, demonstrating the benefit of properly weighting replay buffer data for off-policy training. On state-based environments, DAC outperforms ValueDICE and IQ-Learn (Gary et al., 2021), achieving competitive performance with as little as one expert trajectory.","sentences":["Adversarial imitation learning (AIL) has stood out as a dominant framework across various imitation learning (IL) applications, with Discriminator Actor Critic (DAC) (Kostrikov et al.,, 2019) demonstrating the effectiveness of off-policy learning algorithms in improving sample efficiency and scalability to higher-dimensional observations.","Despite DAC's empirical success, the original AIL objective is on-policy and DAC's ad-hoc application of off-policy training does not guarantee successful imitation (Kostrikov et al., 2019; 2020).","Follow-up work such as ValueDICE (Kostrikov et al., 2020) tackles this issue by deriving a fully off-policy AIL objective.","Instead in this work, we develop a novel and principled AIL algorithm via the framework of boosting.","Like boosting, our new algorithm, AILBoost, maintains an ensemble of properly weighted weak learners (i.e., policies) and trains a discriminator that witnesses the maximum discrepancy between the distributions of the ensemble and the expert policy.","We maintain a weighted replay buffer to represent the state-action distribution induced by the ensemble, allowing us to train discriminators using the entire data collected so far.","In the weighted replay buffer, the contribution of the data from older policies are properly discounted with the weight computed based on the boosting framework.","Empirically, we evaluate our algorithm on both controller state-based and pixel-based environments from the DeepMind Control Suite.","AILBoost outperforms DAC on both types of environments, demonstrating the benefit of properly weighting replay buffer data for off-policy training.","On state-based environments, DAC outperforms ValueDICE and IQ-Learn (Gary et al., 2021), achieving competitive performance with as little as one expert trajectory."],"url":"http://arxiv.org/abs/2404.08513v1","category":"cs.LG"}
{"created":"2024-04-12 14:50:41","title":"Leveraging Multi-AI Agents for Cross-Domain Knowledge Discovery","abstract":"In the rapidly evolving field of artificial intelligence, the ability to harness and integrate knowledge across various domains stands as a paramount challenge and opportunity. This study introduces a novel approach to cross-domain knowledge discovery through the deployment of multi-AI agents, each specialized in distinct knowledge domains. These AI agents, designed to function as domain-specific experts, collaborate in a unified framework to synthesize and provide comprehensive insights that transcend the limitations of single-domain expertise. By facilitating seamless interaction among these agents, our platform aims to leverage the unique strengths and perspectives of each, thereby enhancing the process of knowledge discovery and decision-making. We present a comparative analysis of the different multi-agent workflow scenarios evaluating their performance in terms of efficiency, accuracy, and the breadth of knowledge integration. Through a series of experiments involving complex, interdisciplinary queries, our findings demonstrate the superior capability of domain specific multi-AI agent system in identifying and bridging knowledge gaps. This research not only underscores the significance of collaborative AI in driving innovation but also sets the stage for future advancements in AI-driven, cross-disciplinary research and application. Our methods were evaluated on a small pilot data and it showed a trend we expected, if we increase the amount of data we custom train the agents, the trend is expected to be more smooth.","sentences":["In the rapidly evolving field of artificial intelligence, the ability to harness and integrate knowledge across various domains stands as a paramount challenge and opportunity.","This study introduces a novel approach to cross-domain knowledge discovery through the deployment of multi-AI agents, each specialized in distinct knowledge domains.","These AI agents, designed to function as domain-specific experts, collaborate in a unified framework to synthesize and provide comprehensive insights that transcend the limitations of single-domain expertise.","By facilitating seamless interaction among these agents, our platform aims to leverage the unique strengths and perspectives of each, thereby enhancing the process of knowledge discovery and decision-making.","We present a comparative analysis of the different multi-agent workflow scenarios evaluating their performance in terms of efficiency, accuracy, and the breadth of knowledge integration.","Through a series of experiments involving complex, interdisciplinary queries, our findings demonstrate the superior capability of domain specific multi-AI agent system in identifying and bridging knowledge gaps.","This research not only underscores the significance of collaborative AI in driving innovation but also sets the stage for future advancements in AI-driven, cross-disciplinary research and application.","Our methods were evaluated on a small pilot data and it showed a trend we expected, if we increase the amount of data we custom train the agents, the trend is expected to be more smooth."],"url":"http://arxiv.org/abs/2404.08511v1","category":"cs.AI"}
{"created":"2024-04-12 14:46:15","title":"Efficient Interactive LLM Serving with Proxy Model-based Sequence Length Prediction","abstract":"Large language models (LLMs) have been driving a new wave of interactive AI applications across numerous domains. However, efficiently serving LLM inference requests is challenging due to their unpredictable execution times originating from the autoregressive nature of generative models. Existing LLM serving systems exploit first-come-first-serve (FCFS) scheduling, suffering from head-of-line blocking issues. To address the non-deterministic nature of LLMs and enable efficient interactive LLM serving, we present a speculative shortest-job-first (SSJF) scheduler that uses a light proxy model to predict LLM output sequence lengths. Our open-source SSJF implementation does not require changes to memory management or batching strategies. Evaluations on real-world datasets and production workload traces show that SSJF reduces average job completion times by 30.5-39.6% and increases throughput by 2.2-3.6x compared to FCFS schedulers, across no batching, dynamic batching, and continuous batching settings.","sentences":["Large language models (LLMs) have been driving a new wave of interactive AI applications across numerous domains.","However, efficiently serving LLM inference requests is challenging due to their unpredictable execution times originating from the autoregressive nature of generative models.","Existing LLM serving systems exploit first-come-first-serve (FCFS) scheduling, suffering from head-of-line blocking issues.","To address the non-deterministic nature of LLMs and enable efficient interactive LLM serving, we present a speculative shortest-job-first (SSJF) scheduler that uses a light proxy model to predict LLM output sequence lengths.","Our open-source SSJF implementation does not require changes to memory management or batching strategies.","Evaluations on real-world datasets and production workload traces show that SSJF reduces average job completion times by 30.5-39.6% and increases throughput by 2.2-3.6x compared to FCFS schedulers, across no batching, dynamic batching, and continuous batching settings."],"url":"http://arxiv.org/abs/2404.08509v1","category":"cs.DC"}
{"created":"2024-04-12 14:40:45","title":"LaSagnA: Language-based Segmentation Assistant for Complex Queries","abstract":"Recent advancements have empowered Large Language Models for Vision (vLLMs) to generate detailed perceptual outcomes, including bounding boxes and masks. Nonetheless, there are two constraints that restrict the further application of these vLLMs: the incapability of handling multiple targets per query and the failure to identify the absence of query objects in the image. In this study, we acknowledge that the main cause of these problems is the insufficient complexity of training queries. Consequently, we define the general sequence format for complex queries. Then we incorporate a semantic segmentation task in the current pipeline to fulfill the requirements of training data. Furthermore, we present three novel strategies to effectively handle the challenges arising from the direct integration of the proposed format. The effectiveness of our model in processing complex queries is validated by the comparable results with conventional methods on both close-set and open-set semantic segmentation datasets. Additionally, we outperform a series of vLLMs in reasoning and referring segmentation, showcasing our model's remarkable capabilities. We release the code at https://github.com/congvvc/LaSagnA.","sentences":["Recent advancements have empowered Large Language Models for Vision (vLLMs) to generate detailed perceptual outcomes, including bounding boxes and masks.","Nonetheless, there are two constraints that restrict the further application of these vLLMs: the incapability of handling multiple targets per query and the failure to identify the absence of query objects in the image.","In this study, we acknowledge that the main cause of these problems is the insufficient complexity of training queries.","Consequently, we define the general sequence format for complex queries.","Then we incorporate a semantic segmentation task in the current pipeline to fulfill the requirements of training data.","Furthermore, we present three novel strategies to effectively handle the challenges arising from the direct integration of the proposed format.","The effectiveness of our model in processing complex queries is validated by the comparable results with conventional methods on both close-set and open-set semantic segmentation datasets.","Additionally, we outperform a series of vLLMs in reasoning and referring segmentation, showcasing our model's remarkable capabilities.","We release the code at https://github.com/congvvc/LaSagnA."],"url":"http://arxiv.org/abs/2404.08506v1","category":"cs.CV"}
{"created":"2024-04-12 14:29:45","title":"Analyzing and Overcoming Local Optima in Complex Multi-Objective Optimization by Decomposition-Based Evolutionary Algorithms","abstract":"When addressing the challenge of complex multi-objective optimization problems, particularly those with non-convex and non-uniform Pareto fronts, Decomposition-based Multi-Objective Evolutionary Algorithms (MOEADs) often converge to local optima, thereby limiting solution diversity. Despite its significance, this issue has received limited theoretical exploration. Through a comprehensive geometric analysis, we identify that the traditional method of Reference Point (RP) selection fundamentally contributes to this challenge. In response, we introduce an innovative RP selection strategy, the Weight Vector-Guided and Gaussian-Hybrid method, designed to overcome the local optima issue. This approach employs a novel RP type that aligns with weight vector directions and integrates a Gaussian distribution to combine three distinct RP categories. Our research comprises two main experimental components: an ablation study involving 14 algorithms within the MOEADs framework, spanning from 2014 to 2022, to validate our theoretical framework, and a series of empirical tests to evaluate the effectiveness of our proposed method against both traditional and cutting-edge alternatives. Results demonstrate that our method achieves remarkable improvements in both population diversity and convergence.","sentences":["When addressing the challenge of complex multi-objective optimization problems, particularly those with non-convex and non-uniform Pareto fronts, Decomposition-based Multi-Objective Evolutionary Algorithms (MOEADs) often converge to local optima, thereby limiting solution diversity.","Despite its significance, this issue has received limited theoretical exploration.","Through a comprehensive geometric analysis, we identify that the traditional method of Reference Point (RP) selection fundamentally contributes to this challenge.","In response, we introduce an innovative RP selection strategy, the Weight Vector-Guided and Gaussian-Hybrid method, designed to overcome the local optima issue.","This approach employs a novel RP type that aligns with weight vector directions and integrates a Gaussian distribution to combine three distinct RP categories.","Our research comprises two main experimental components: an ablation study involving 14 algorithms within the MOEADs framework, spanning from 2014 to 2022, to validate our theoretical framework, and a series of empirical tests to evaluate the effectiveness of our proposed method against both traditional and cutting-edge alternatives.","Results demonstrate that our method achieves remarkable improvements in both population diversity and convergence."],"url":"http://arxiv.org/abs/2404.08501v1","category":"cs.NE"}
{"created":"2024-04-12 14:28:56","title":"Generalized Hydrodynamics for the Volterra lattice: Ballistic and nonballistic behavior of correlation functions","abstract":"In recent years, a lot of effort has been put in describing the hydrodynamic behavior of integrable systems. In this paper, we describe such picture for the Volterra lattice. Specifically, we are able to explicitly compute the susceptibility matrix and the current-field correlation matrix in terms of the density of states of the Volterra lattice endowed with a Generalized Gibbs ensemble. Furthermore, we apply the theory of linear Generalized Hydrodynamics to describe the Euler scale behavior of the correlation functions. We anticipate that the solution to the Generalized Hydrodynamics equations develops shocks at $\\xi_0=\\frac{x}{t}$; so this linear approximation does not fully describe the behavior of correlation functions. Intrigued but this fact, we performed several numerical investigations which show that, exactly when the solution to the hydrodynamic equations develops shock, the correlation functions show an highly oscillatory behavior. In view of this empirical observation, we believe that at this point $\\xi_0$ the diffusive contribution are not sub-leading corrections to the ballistic transport, but they are of the same order.","sentences":["In recent years, a lot of effort has been put in describing the hydrodynamic behavior of integrable systems.","In this paper, we describe such picture for the Volterra lattice.","Specifically, we are able to explicitly compute the susceptibility matrix and the current-field correlation matrix in terms of the density of states of the Volterra lattice endowed with a Generalized Gibbs ensemble.","Furthermore, we apply the theory of linear Generalized Hydrodynamics to describe the Euler scale behavior of the correlation functions.","We anticipate that the solution to the Generalized Hydrodynamics equations develops shocks at $\\xi_0=\\frac{x}{t}$; so this linear approximation does not fully describe the behavior of correlation functions.","Intrigued but this fact, we performed several numerical investigations which show that, exactly when the solution to the hydrodynamic equations develops shock, the correlation functions show an highly oscillatory behavior.","In view of this empirical observation, we believe that at this point $\\xi_0$ the diffusive contribution are not sub-leading corrections to the ballistic transport, but they are of the same order."],"url":"http://arxiv.org/abs/2404.08499v1","category":"math-ph"}
{"created":"2024-04-12 14:25:49","title":"Dataset Reset Policy Optimization for RLHF","abstract":"Reinforcement Learning (RL) from Human Preference-based feedback is a popular paradigm for fine-tuning generative models, which has produced impressive models such as GPT-4 and Claude3 Opus. This framework often consists of two steps: learning a reward model from an offline preference dataset followed by running online RL to optimize the learned reward model. In this work, leveraging the idea of reset, we propose a new RLHF algorithm with provable guarantees. Motivated by the fact that offline preference dataset provides informative states (i.e., data that is preferred by the labelers), our new algorithm, Dataset Reset Policy Optimization (DR-PO), integrates the existing offline preference dataset into the online policy training procedure via dataset reset: it directly resets the policy optimizer to the states in the offline dataset, instead of always starting from the initial state distribution. In theory, we show that DR-PO learns to perform at least as good as any policy that is covered by the offline dataset under general function approximation with finite sample complexity. In experiments, we demonstrate that on both the TL;DR summarization and the Anthropic Helpful Harmful (HH) dataset, the generation from DR-PO is better than that from Proximal Policy Optimization (PPO) and Direction Preference Optimization (DPO), under the metric of GPT4 win-rate. Code for this work can be found at https://github.com/Cornell-RL/drpo.","sentences":["Reinforcement Learning (RL) from Human Preference-based feedback is a popular paradigm for fine-tuning generative models, which has produced impressive models such as GPT-4 and Claude3 Opus.","This framework often consists of two steps: learning a reward model from an offline preference dataset followed by running online RL to optimize the learned reward model.","In this work, leveraging the idea of reset, we propose a new RLHF algorithm with provable guarantees.","Motivated by the fact that offline preference dataset provides informative states (i.e., data that is preferred by the labelers), our new algorithm, Dataset Reset Policy Optimization (DR-PO), integrates the existing offline preference dataset into the online policy training procedure via dataset reset: it directly resets the policy optimizer to the states in the offline dataset, instead of always starting from the initial state distribution.","In theory, we show that DR-PO learns to perform at least as good as any policy that is covered by the offline dataset under general function approximation with finite sample complexity.","In experiments, we demonstrate that on both the TL;DR summarization and the Anthropic Helpful Harmful (HH) dataset, the generation from DR-PO is better than that from Proximal Policy Optimization (PPO) and Direction Preference Optimization (DPO), under the metric of GPT4 win-rate.","Code for this work can be found at https://github.com/Cornell-RL/drpo."],"url":"http://arxiv.org/abs/2404.08495v1","category":"cs.LG"}
{"created":"2024-04-12 14:25:38","title":"Almost-Sure Termination by Guarded Refinement","abstract":"Almost-sure termination is an important correctness property for probabilistic programs, and a number of program logics have been developed for establishing it. However, these logics have mostly been developed for first-order programs written in languages with specific syntactic patterns for looping. In this paper, we consider almost-sure termination for higher-order probabilistic programs with general references. This combination of features allows for recursion and looping to be encoded through a variety of patterns. Therefore, rather than developing proof rules for reasoning about particular recursion patterns, we instead propose an approach based on proving refinement between a higher-order program and a simpler probabilistic model, in such a way that the refinement preserves termination behavior. By proving a refinement, almost-sure termination behavior of the program can then be established by analyzing the simpler model. We present this approach in the form of Caliper, a higher-order separation logic for proving termination-preserving refinements. Caliper uses probabilistic couplings to carry out relational reasoning between a program and a model. To handle the range of recursion patterns found in higher-order programs, Caliper uses guarded recursion, in particular the principle of L\\\"ob induction. A technical novelty is that Caliper does not require the use of transfinite step indexing or other technical restrictions found in prior work on guarded recursion for termination-preservation refinement. We demonstrate the flexibility of this approach by proving almost-sure termination of several examples, including first-order loop constructs, a random list generator, treaps, and a sampler for Galton-Watson trees that uses higher-order store. All the results have been mechanized in the Coq proof assistant.","sentences":["Almost-sure termination is an important correctness property for probabilistic programs, and a number of program logics have been developed for establishing it.","However, these logics have mostly been developed for first-order programs written in languages with specific syntactic patterns for looping.","In this paper, we consider almost-sure termination for higher-order probabilistic programs with general references.","This combination of features allows for recursion and looping to be encoded through a variety of patterns.","Therefore, rather than developing proof rules for reasoning about particular recursion patterns, we instead propose an approach based on proving refinement between a higher-order program and a simpler probabilistic model, in such a way that the refinement preserves termination behavior.","By proving a refinement, almost-sure termination behavior of the program can then be established by analyzing the simpler model.","We present this approach in the form of Caliper, a higher-order separation logic for proving termination-preserving refinements.","Caliper uses probabilistic couplings to carry out relational reasoning between a program and a model.","To handle the range of recursion patterns found in higher-order programs, Caliper uses guarded recursion, in particular the principle of L\\\"ob induction.","A technical novelty is that Caliper does not require the use of transfinite step indexing or other technical restrictions found in prior work on guarded recursion for termination-preservation refinement.","We demonstrate the flexibility of this approach by proving almost-sure termination of several examples, including first-order loop constructs, a random list generator, treaps, and a sampler for Galton-Watson trees that uses higher-order store.","All the results have been mechanized in the Coq proof assistant."],"url":"http://arxiv.org/abs/2404.08494v1","category":"cs.LO"}
{"created":"2024-04-12 14:20:57","title":"Strategic Interactions between Large Language Models-based Agents in Beauty Contests","abstract":"The growing adoption of large language models (LLMs) presents substantial potential for deeper understanding of human behaviours within game theory frameworks through simulations. Leveraging on the diverse pool of LLM types and addressing the gap in research on competitive games, this paper examines the strategic interactions among multiple types of LLM-based agents in a classical game of beauty contest. Drawing parallels to experiments involving human subjects, LLM-based agents are assessed similarly in terms of strategic levels. They demonstrate varying depth of reasoning that falls within a range of level-0 and 1, and show convergence in actions in repeated settings. Furthermore, I also explore how variations in group composition of agent types influence strategic behaviours, where I found higher proportion of fixed-strategy opponents enhances convergence for LLM-based agents, and having a mixed environment with agents of differing relative strategic levels accelerates convergence for all agents. There could also be higher average payoffs for the more intelligent agents, albeit at the expense of the less intelligent agents. These results not only provide insights into outcomes for simulated agents under specified scenarios, it also offer valuable implications for understanding strategic interactions between algorithms.","sentences":["The growing adoption of large language models (LLMs) presents substantial potential for deeper understanding of human behaviours within game theory frameworks through simulations.","Leveraging on the diverse pool of LLM types and addressing the gap in research on competitive games, this paper examines the strategic interactions among multiple types of LLM-based agents in a classical game of beauty contest.","Drawing parallels to experiments involving human subjects, LLM-based agents are assessed similarly in terms of strategic levels.","They demonstrate varying depth of reasoning that falls within a range of level-0 and 1, and show convergence in actions in repeated settings.","Furthermore, I also explore how variations in group composition of agent types influence strategic behaviours, where I found higher proportion of fixed-strategy opponents enhances convergence for LLM-based agents, and having a mixed environment with agents of differing relative strategic levels accelerates convergence for all agents.","There could also be higher average payoffs for the more intelligent agents, albeit at the expense of the less intelligent agents.","These results not only provide insights into outcomes for simulated agents under specified scenarios, it also offer valuable implications for understanding strategic interactions between algorithms."],"url":"http://arxiv.org/abs/2404.08492v1","category":"econ.GN"}
{"created":"2024-04-12 14:19:16","title":"Mitigating Language-Level Performance Disparity in mPLMs via Teacher Language Selection and Cross-lingual Self-Distillation","abstract":"Large-scale multilingual Pretrained Language Models (mPLMs) yield impressive performance on cross-language tasks, yet significant performance disparities exist across different languages within the same mPLM. Previous studies endeavored to narrow these disparities by supervise fine-tuning the mPLMs with multilingual data. However, obtaining labeled multilingual data is time-consuming, and fine-tuning mPLM with limited labeled multilingual data merely encapsulates the knowledge specific to the labeled data. Therefore, we introduce ALSACE to leverage the learned knowledge from the well-performing languages to guide under-performing ones within the same mPLM, eliminating the need for additional labeled multilingual data. Experiments show that ALSACE effectively mitigates language-level performance disparity across various mPLMs while showing the competitive performance on different multilingual NLU tasks, ranging from full resource to limited resource settings. The code for our approach is available at https://github.com/pkunlp-icler/ALSACE.","sentences":["Large-scale multilingual Pretrained Language Models (mPLMs) yield impressive performance on cross-language tasks, yet significant performance disparities exist across different languages within the same mPLM.","Previous studies endeavored to narrow these disparities by supervise fine-tuning the mPLMs with multilingual data.","However, obtaining labeled multilingual data is time-consuming, and fine-tuning mPLM with limited labeled multilingual data merely encapsulates the knowledge specific to the labeled data.","Therefore, we introduce ALSACE to leverage the learned knowledge from the well-performing languages to guide under-performing ones within the same mPLM, eliminating the need for additional labeled multilingual data.","Experiments show that ALSACE effectively mitigates language-level performance disparity across various mPLMs while showing the competitive performance on different multilingual NLU tasks, ranging from full resource to limited resource settings.","The code for our approach is available at https://github.com/pkunlp-icler/ALSACE."],"url":"http://arxiv.org/abs/2404.08491v1","category":"cs.CL"}
{"created":"2024-04-12 14:14:17","title":"SemHARQ: Semantic-Aware HARQ for Multi-task Semantic Communications","abstract":"Intelligent task-oriented semantic communications (SemComs) have witnessed great progress with the development of deep learning (DL). In this paper, we propose a semantic-aware hybrid automatic repeat request (SemHARQ) framework for the robust and efficient transmissions of semantic features. First, to improve the robustness and effectiveness of semantic coding, a multi-task semantic encoder is proposed. Meanwhile, a feature importance ranking (FIR) method is investigated to ensure the important features delivery under limited channel resources. Then, to accurately detect the possible transmission errors, a novel feature distortion evaluation (FDE) network is designed to identify the distortion level of each feature, based on which an efficient HARQ method is proposed. Specifically, the corrupted features are retransmitted, where the remaining channel resources are used for incremental transmissions. The system performance is evaluated under different channel conditions in multi-task scenarios in Internet of Vehicles. Extensive experiments show that the proposed framework outperforms state-of-the-art works by more than 20% in rank-1 accuracy for vehicle re-identification, and 10% in vehicle color classification accuracy in the low signal-to-noise ratio regime.","sentences":["Intelligent task-oriented semantic communications (SemComs) have witnessed great progress with the development of deep learning (DL).","In this paper, we propose a semantic-aware hybrid automatic repeat request (SemHARQ) framework for the robust and efficient transmissions of semantic features.","First, to improve the robustness and effectiveness of semantic coding, a multi-task semantic encoder is proposed.","Meanwhile, a feature importance ranking (FIR) method is investigated to ensure the important features delivery under limited channel resources.","Then, to accurately detect the possible transmission errors, a novel feature distortion evaluation (FDE) network is designed to identify the distortion level of each feature, based on which an efficient HARQ method is proposed.","Specifically, the corrupted features are retransmitted, where the remaining channel resources are used for incremental transmissions.","The system performance is evaluated under different channel conditions in multi-task scenarios in Internet of Vehicles.","Extensive experiments show that the proposed framework outperforms state-of-the-art works by more than 20% in rank-1 accuracy for vehicle re-identification, and 10% in vehicle color classification accuracy in the low signal-to-noise ratio regime."],"url":"http://arxiv.org/abs/2404.08490v1","category":"eess.SP"}
{"created":"2024-04-12 14:04:58","title":"An Interior Penalty coupling strategy for Isogeometric non-conformal Kirchhoff-Love shell patches","abstract":"This work focuses on the coupling of trimmed shell patches using Isogeometric Analysis, based on higher continuity splines that seamlessly meet the $C^1$ requirement of Kirchhoff-Love-based discretizations. Weak enforcement of coupling conditions is achieved through the symmetric interior penalty method, where the fluxes are computed using their correct variationally consistent expression that was only recently proposed and is unprecedentedly adopted herein in the context of coupling conditions. The constitutive relationships account for generically laminated materials, although the proposed tests are conducted under the assumption of uniform thickness and lamination sequence. Numerical experiments assess the method for an isotropic and a laminated plate, as well as an isotropic hyperbolic paraboloid shell from the new shell obstacle course. The boundary conditions and domain force are chosen to reproduce manufactured analytical solutions, which are taken as reference to compute rigorous convergence curves in the $L^2$, $H^1$, and $H^2$ norms, that closely approach optimal ones predicted by theory. Additionally, we conduct a final test on a complex structure comprising five intersecting laminated cylindrical shells, whose geometry is directly imported from a STEP file. The results exhibit excellent agreement with those obtained through commercial software, showcasing the method's potential for real-world industrial applications.","sentences":["This work focuses on the coupling of trimmed shell patches using Isogeometric Analysis, based on higher continuity splines that seamlessly meet the $C^1$ requirement of Kirchhoff-Love-based discretizations.","Weak enforcement of coupling conditions is achieved through the symmetric interior penalty method, where the fluxes are computed using their correct variationally consistent expression that was only recently proposed and is unprecedentedly adopted herein in the context of coupling conditions.","The constitutive relationships account for generically laminated materials, although the proposed tests are conducted under the assumption of uniform thickness and lamination sequence.","Numerical experiments assess the method for an isotropic and a laminated plate, as well as an isotropic hyperbolic paraboloid shell from the new shell obstacle course.","The boundary conditions and domain force are chosen to reproduce manufactured analytical solutions, which are taken as reference to compute rigorous convergence curves in the $L^2$, $H^1$, and $H^2$ norms, that closely approach optimal ones predicted by theory.","Additionally, we conduct a final test on a complex structure comprising five intersecting laminated cylindrical shells, whose geometry is directly imported from a STEP file.","The results exhibit excellent agreement with those obtained through commercial software, showcasing the method's potential for real-world industrial applications."],"url":"http://arxiv.org/abs/2404.08485v1","category":"math.NA"}
{"created":"2024-04-12 14:03:58","title":"Symplectic mapping class relations from pencil pairs","abstract":"We describe symplectic mapping class relations between products of positive Dehn twists along Lagrangian spheres in Weinstein $4$-manifolds, all of which are affine $\\mathbb{C}$ varieties. The relations are obtained by applying classification results for Fano $3$-folds and polarized $K_{3}$ surfaces of small genus to a general methodology -- finding pencil pairs.","sentences":["We describe symplectic mapping class relations between products of positive Dehn twists along Lagrangian spheres in Weinstein $4$-manifolds, all of which are affine $\\mathbb{C}$ varieties.","The relations are obtained by applying classification results for Fano $3$-folds and polarized $K_{3}$ surfaces of small genus to a general methodology -- finding pencil pairs."],"url":"http://arxiv.org/abs/2404.08484v1","category":"math.SG"}
{"created":"2024-04-12 14:03:41","title":"Semantic Communication for Cooperative Multi-Task Processing over Wireless Networks","abstract":"In this paper, we have expanded the current status of semantic communication limited to processing one task to a more general system that can handle multiple tasks concurrently. In pursuit of this, we first introduced our definition of the \"semantic source\", enabling the interpretation of multiple semantics based on a single observation. A semantic encoder design is then introduced, featuring the division of the encoder into a common unit and multiple specific units enabling cooperative multi-task processing. Simulation results demonstrate the effectiveness of the proposed semantic source and the system design. Our approach employs information maximization (infomax) and end-to-end design principles.","sentences":["In this paper, we have expanded the current status of semantic communication limited to processing one task to a more general system that can handle multiple tasks concurrently.","In pursuit of this, we first introduced our definition of the \"semantic source\", enabling the interpretation of multiple semantics based on a single observation.","A semantic encoder design is then introduced, featuring the division of the encoder into a common unit and multiple specific units enabling cooperative multi-task processing.","Simulation results demonstrate the effectiveness of the proposed semantic source and the system design.","Our approach employs information maximization (infomax) and end-to-end design principles."],"url":"http://arxiv.org/abs/2404.08483v1","category":"eess.SP"}
{"created":"2024-04-12 13:57:30","title":"Decoding AI: The inside story of data analysis in ChatGPT","abstract":"As a result of recent advancements in generative AI, the field of Data Science is prone to various changes. This review critically examines the Data Analysis (DA) capabilities of ChatGPT assessing its performance across a wide range of tasks. While DA provides researchers and practitioners with unprecedented analytical capabilities, it is far from being perfect, and it is important to recognize and address its limitations.","sentences":["As a result of recent advancements in generative AI, the field of Data Science is prone to various changes.","This review critically examines the Data Analysis (DA) capabilities of ChatGPT assessing its performance across a wide range of tasks.","While DA provides researchers and practitioners with unprecedented analytical capabilities, it is far from being perfect, and it is important to recognize and address its limitations."],"url":"http://arxiv.org/abs/2404.08480v1","category":"cs.LG"}
{"created":"2024-04-12 13:54:21","title":"Combining Statistical Depth and Fermat Distance for Uncertainty Quantification","abstract":"We measure the Out-of-domain uncertainty in the prediction of Neural Networks using a statistical notion called ``Lens Depth'' (LD) combined with Fermat Distance, which is able to capture precisely the ``depth'' of a point with respect to a distribution in feature space, without any assumption about the form of distribution. Our method has no trainable parameter. The method is applicable to any classification model as it is applied directly in feature space at test time and does not intervene in training process. As such, it does not impact the performance of the original model. The proposed method gives excellent qualitative result on toy datasets and can give competitive or better uncertainty estimation on standard deep learning datasets compared to strong baseline methods.","sentences":["We measure the Out-of-domain uncertainty in the prediction of Neural Networks using a statistical notion called ``Lens Depth'' (LD) combined with Fermat Distance, which is able to capture precisely the ``depth'' of a point with respect to a distribution in feature space, without any assumption about the form of distribution.","Our method has no trainable parameter.","The method is applicable to any classification model as it is applied directly in feature space at test time and does not intervene in training process.","As such, it does not impact the performance of the original model.","The proposed method gives excellent qualitative result on toy datasets and can give competitive or better uncertainty estimation on standard deep learning datasets compared to strong baseline methods."],"url":"http://arxiv.org/abs/2404.08476v1","category":"stat.ML"}
{"created":"2024-04-12 13:39:56","title":"Variations of the $\u03b1$-Eulerian polynomials and gamma positivity","abstract":"We prove a connection formula between two multivariate generalizations of the Eulerian polynomials $A^{\\cyc}_n(x,y, t\\,|\\,\\alpha)$ and $A_n(u_1,u_2,u_3,u_4, f, g, t\\,|\\,\\alpha, \\beta)$, which enumerate permutations related to excedance and descent based statistics respectively. By exploring this connection, we derive the exponential generating function of the latter polynomials and several   $\\gamma$-positivity formulas for variants of Eulerian polynomials. In particular, our results generalise the main results in two recent papers by Ji \\cite{Ji23} and Ji-Lin \\cite{JL23}. Our proofs are combinatorial in nature and involve Foata's fundamental transformation and a cyclic analogue of valley-hopping.","sentences":["We prove a connection formula between two multivariate generalizations of the Eulerian polynomials $A^{\\cyc}_n(x,y, t\\,|\\,\\alpha)$ and $A_n(u_1,u_2,u_3,u_4, f, g, t\\,|\\,\\alpha, \\beta)$, which enumerate permutations related to excedance and descent based statistics respectively.","By exploring this connection, we derive the exponential generating function of the latter polynomials and several   $\\gamma$-positivity formulas for variants of Eulerian polynomials.","In particular, our results generalise the main results in two recent papers by Ji \\cite{Ji23} and Ji-Lin \\cite{JL23}.","Our proofs are combinatorial in nature and involve Foata's fundamental transformation and a cyclic analogue of valley-hopping."],"url":"http://arxiv.org/abs/2404.08470v1","category":"math.CO"}
{"created":"2024-04-12 13:32:11","title":"Tight Bounds for Sorting Under Partial Information","abstract":"Sorting has a natural generalization where the input consists of: (1) a ground set $X$ of size $n$, (2) a partial oracle $O_P$ specifying some fixed partial order $P$ on $X$ and (3) a linear oracle $O_L$ specifying a linear order $L$ that extends $P$. The goal is to recover the linear order $L$ on $X$ using the fewest number of linear oracle queries.   In this problem, we measure algorithmic complexity through three metrics: oracle queries to $O_L$, oracle queries to $O_P$, and the time spent. Any algorithm requires worst-case $\\log_2 e(P)$ linear oracle queries to recover the linear order on $X$.   Kahn and Saks presented the first algorithm that uses $\\Theta(\\log e(P))$ linear oracle queries (using $O(n^2)$ partial oracle queries and exponential time). The state-of-the-art for the general problem is by Cardinal, Fiorini, Joret, Jungers and Munro who at STOC'10 manage to separate the linear and partial oracle queries into a preprocessing and query phase. They can preprocess $P$ using $O(n^2)$ partial oracle queries and $O(n^{2.5})$ time. Then, given $O_L$, they uncover the linear order on $X$ in $\\Theta(\\log e(P))$ linear oracle queries and $O(n + \\log e(P))$ time -- which is worst-case optimal in the number of linear oracle queries but not in the time spent.   For $c \\geq 1$, our algorithm can preprocess $O_P$ using $O(n^{1 + \\frac{1}{c}})$ queries and time. Given $O_L$, we uncover $L$ using $\\Theta(c \\log e(P))$ queries and time. We show a matching lower bound, as there exist positive constants $(\\alpha, \\beta)$ where for any constant $c \\geq 1$, any algorithm that uses at most $\\alpha \\cdot n^{1 + \\frac{1}{c}}$ preprocessing must use worst-case at least $\\beta \\cdot c \\log e(P)$ linear oracle queries. Thus, we solve the problem of sorting under partial information through an algorithm that is asymptotically tight across all three metrics.","sentences":["Sorting has a natural generalization where the input consists of: (1) a ground set $X$ of size $n$, (2) a partial oracle $O_P$ specifying some fixed partial order $P$ on $X$ and (3) a linear oracle $O_L$ specifying a linear order $L$ that extends $P$.","The goal is to recover the linear order $L$ on $X$ using the fewest number of linear oracle queries.   ","In this problem, we measure algorithmic complexity through three metrics: oracle queries to $O_L$, oracle queries to $O_P$, and the time spent.","Any algorithm requires worst-case $\\log_2 e(P)$ linear oracle queries to recover the linear order on $X$.   Kahn and Saks presented the first algorithm that uses $\\Theta(\\log e(P))$ linear oracle queries (using $O(n^2)$ partial oracle queries and exponential time).","The state-of-the-art for the general problem is by Cardinal, Fiorini, Joret, Jungers and Munro who at STOC'10 manage to separate the linear and partial oracle queries into a preprocessing and query phase.","They can preprocess $P$ using $O(n^2)$ partial oracle queries and $O(n^{2.5})$ time.","Then, given $O_L$, they uncover the linear order on $X$ in $\\Theta(\\log e(P))$ linear oracle queries and $O(n + \\log e(P))$ time -- which is worst-case optimal in the number of linear oracle queries but not in the time spent.   ","For $c \\geq 1$, our algorithm can preprocess $O_P$ using $O(n^{1 + \\frac{1}{c}})$ queries and time.","Given $O_L$, we uncover $L$ using $\\Theta(c \\log e(P))$ queries and time.","We show a matching lower bound, as there exist positive constants $(\\alpha, \\beta)$ where for any constant $c \\geq 1$, any algorithm that uses at most $\\alpha \\cdot n^{1 + \\frac{1}{c}}$ preprocessing must use worst-case at least $\\beta \\cdot c \\log e(P)$ linear oracle queries.","Thus, we solve the problem of sorting under partial information through an algorithm that is asymptotically tight across all three metrics."],"url":"http://arxiv.org/abs/2404.08468v1","category":"cs.DS"}
{"created":"2024-04-12 13:18:47","title":"OTTER: Improving Zero-Shot Classification via Optimal Transport","abstract":"Popular zero-shot models suffer due to artifacts inherited from pretraining. A particularly detrimental artifact, caused by unbalanced web-scale pretraining data, is mismatched label distribution. Existing approaches that seek to repair the label distribution are not suitable in zero-shot settings, as they have incompatible requirements such as access to labeled downstream task data or knowledge of the true label balance in the pretraining distribution. We sidestep these challenges and introduce a simple and lightweight approach to adjust pretrained model predictions via optimal transport. Our technique requires only an estimate of the label distribution of a downstream task. Theoretically, we characterize the improvement produced by our procedure under certain mild conditions and provide bounds on the error caused by misspecification. Empirically, we validate our method in a wide array of zero-shot image and text classification tasks, improving accuracy by 4.8% and 15.9% on average, and beating baselines like Prior Matching -- often by significant margins -- in 17 out of 21 datasets.","sentences":["Popular zero-shot models suffer due to artifacts inherited from pretraining.","A particularly detrimental artifact, caused by unbalanced web-scale pretraining data, is mismatched label distribution.","Existing approaches that seek to repair the label distribution are not suitable in zero-shot settings, as they have incompatible requirements such as access to labeled downstream task data or knowledge of the true label balance in the pretraining distribution.","We sidestep these challenges and introduce a simple and lightweight approach to adjust pretrained model predictions via optimal transport.","Our technique requires only an estimate of the label distribution of a downstream task.","Theoretically, we characterize the improvement produced by our procedure under certain mild conditions and provide bounds on the error caused by misspecification.","Empirically, we validate our method in a wide array of zero-shot image and text classification tasks, improving accuracy by 4.8% and 15.9% on average, and beating baselines like Prior Matching -- often by significant margins -- in 17 out of 21 datasets."],"url":"http://arxiv.org/abs/2404.08461v1","category":"cs.LG"}
{"created":"2024-04-12 13:10:46","title":"Observation of Fine Structure in Channeling of Particles in Bent Crystals","abstract":"Using the newly developed 530 MeV positron beam from the Mainz Microtron MAMI and employing a bent silicon crystal, we demonstrate the first successful manipulation with high efficiencies of the trajectories of positrons through planar channeling and volume reflection. This uncovered the presence of fine structure within the angular distribution of charged particles when they are channeled between the planes of bent crystals. The alignment of our experimental findings with simulation results not only demonstrates a deeper understanding of the interactions between charged particle beams and bent crystals but also signals a new phase in the development of innovative methodologies for slow extraction in circular accelerators operating in the GeV range, with implications for worldwide accelerators. Our results also mark a considerable progression in the generation of advanced x-ray sources through the channeling process in periodically bent crystals, rooted in a comprehensive understanding of the interactions between positron beams and such crystals.","sentences":["Using the newly developed 530 MeV positron beam from the Mainz Microtron MAMI and employing a bent silicon crystal, we demonstrate the first successful manipulation with high efficiencies of the trajectories of positrons through planar channeling and volume reflection.","This uncovered the presence of fine structure within the angular distribution of charged particles when they are channeled between the planes of bent crystals.","The alignment of our experimental findings with simulation results not only demonstrates a deeper understanding of the interactions between charged particle beams and bent crystals but also signals a new phase in the development of innovative methodologies for slow extraction in circular accelerators operating in the GeV range, with implications for worldwide accelerators.","Our results also mark a considerable progression in the generation of advanced x-ray sources through the channeling process in periodically bent crystals, rooted in a comprehensive understanding of the interactions between positron beams and such crystals."],"url":"http://arxiv.org/abs/2404.08459v1","category":"physics.acc-ph"}
{"created":"2024-04-12 13:09:48","title":"On the Independence Assumption in Neurosymbolic Learning","abstract":"State-of-the-art neurosymbolic learning systems use probabilistic reasoning to guide neural networks towards predictions that conform to logical constraints over symbols. Many such systems assume that the probabilities of the considered symbols are conditionally independent given the input to simplify learning and reasoning. We study and criticise this assumption, highlighting how it can hinder optimisation and prevent uncertainty quantification. We prove that loss functions bias conditionally independent neural networks to become overconfident in their predictions. As a result, they are unable to represent uncertainty over multiple valid options. Furthermore, we prove that these loss functions are difficult to optimise: they are non-convex, and their minima are usually highly disconnected. Our theoretical analysis gives the foundation for replacing the conditional independence assumption and designing more expressive neurosymbolic probabilistic models.","sentences":["State-of-the-art neurosymbolic learning systems use probabilistic reasoning to guide neural networks towards predictions that conform to logical constraints over symbols.","Many such systems assume that the probabilities of the considered symbols are conditionally independent given the input to simplify learning and reasoning.","We study and criticise this assumption, highlighting how it can hinder optimisation and prevent uncertainty quantification.","We prove that loss functions bias conditionally independent neural networks to become overconfident in their predictions.","As a result, they are unable to represent uncertainty over multiple valid options.","Furthermore, we prove that these loss functions are difficult to optimise: they are non-convex, and their minima are usually highly disconnected.","Our theoretical analysis gives the foundation for replacing the conditional independence assumption and designing more expressive neurosymbolic probabilistic models."],"url":"http://arxiv.org/abs/2404.08458v1","category":"stat.ML"}
{"created":"2024-04-12 13:03:10","title":"Gravitational waves for eccentric extreme mass ratio inspirals of self-dual spacetime","abstract":"In this paper, we calculate the frequencies of geodesic orbits in self-dual spacetime on the equatorial plane and obtain the leading-order effects of loop quantum parameters $P$ on the energy flux and angular momentum flux in eccentric extreme mass ratio inspirals. The gravitational waveform under different eccentricity is carried out by improved \"analytic-kludge\" method. Through the calculation of waveform mismatches for the LISA detector, the constraints on loop quantum parameters will be improved by 1 to 2 orders of magnitude, compared to the weak field experiments in the solar system, and can reach the level of $10^{-8}$.","sentences":["In this paper, we calculate the frequencies of geodesic orbits in self-dual spacetime on the equatorial plane and obtain the leading-order effects of loop quantum parameters $P$ on the energy flux and angular momentum flux in eccentric extreme mass ratio inspirals.","The gravitational waveform under different eccentricity is carried out by improved \"analytic-kludge\" method.","Through the calculation of waveform mismatches for the LISA detector, the constraints on loop quantum parameters will be improved by 1 to 2 orders of magnitude, compared to the weak field experiments in the solar system, and can reach the level of $10^{-8}$."],"url":"http://arxiv.org/abs/2404.08454v1","category":"gr-qc"}
{"created":"2024-04-12 13:02:08","title":"MoE-FFD: Mixture of Experts for Generalized and Parameter-Efficient Face Forgery Detection","abstract":"Deepfakes have recently raised significant trust issues and security concerns among the public. Compared to CNN face forgery detectors, ViT-based methods take advantage of the expressivity of transformers, achieving superior detection performance. However, these approaches still exhibit the following limitations: (1). Fully fine-tuning ViT-based models from ImageNet weights demands substantial computational and storage resources; (2). ViT-based methods struggle to capture local forgery clues, leading to model bias and limited generalizability. To tackle these challenges, this work introduces Mixture-of-Experts modules for Face Forgery Detection (MoE-FFD), a generalized yet parameter-efficient ViT-based approach. MoE-FFD only updates lightweight Low-Rank Adaptation (LoRA) and Adapter layers while keeping the ViT backbone frozen, thereby achieving parameter-efficient training. Moreover, MoE-FFD leverages the expressivity of transformers and local priors of CNNs to simultaneously extract global and local forgery clues. Additionally, novel MoE modules are designed to scale the model's capacity and select optimal forgery experts, further enhancing forgery detection performance. The proposed MoE learning scheme can be seamlessly adapted to various transformer backbones in a plug-and-play manner. Extensive experimental results demonstrate that the proposed method achieves state-of-the-art face forgery detection performance with reduced parameter overhead. The code will be released upon acceptance.","sentences":["Deepfakes have recently raised significant trust issues and security concerns among the public.","Compared to CNN face forgery detectors, ViT-based methods take advantage of the expressivity of transformers, achieving superior detection performance.","However, these approaches still exhibit the following limitations: (1).","Fully fine-tuning ViT-based models from ImageNet weights demands substantial computational and storage resources; (2).","ViT-based methods struggle to capture local forgery clues, leading to model bias and limited generalizability.","To tackle these challenges, this work introduces Mixture-of-Experts modules for Face Forgery Detection (MoE-FFD), a generalized yet parameter-efficient ViT-based approach.","MoE-FFD only updates lightweight Low-Rank Adaptation (LoRA) and Adapter layers while keeping the ViT backbone frozen, thereby achieving parameter-efficient training.","Moreover, MoE-FFD leverages the expressivity of transformers and local priors of CNNs to simultaneously extract global and local forgery clues.","Additionally, novel MoE modules are designed to scale the model's capacity and select optimal forgery experts, further enhancing forgery detection performance.","The proposed MoE learning scheme can be seamlessly adapted to various transformer backbones in a plug-and-play manner.","Extensive experimental results demonstrate that the proposed method achieves state-of-the-art face forgery detection performance with reduced parameter overhead.","The code will be released upon acceptance."],"url":"http://arxiv.org/abs/2404.08452v1","category":"cs.CV"}
{"created":"2024-04-12 13:01:53","title":"Path differences between quasistatic and fatigue cracks in anisotropic media","abstract":"The propagation path of quasistatic cracks under monotonic loading is known to be strongly influenced by the anisotropy of the fracture energy in crystalline solids or engineered materials with a regular microstructure. Such cracks generally follow directions close to minima of the fracture energy. Here we demonstrate both experimentally and computationally that fatigue cracks under cyclic loading follow dramatically different paths that are predominantly dictated by the symmetry of the loading with the microstructure playing a negligible or subdominant role.","sentences":["The propagation path of quasistatic cracks under monotonic loading is known to be strongly influenced by the anisotropy of the fracture energy in crystalline solids or engineered materials with a regular microstructure.","Such cracks generally follow directions close to minima of the fracture energy.","Here we demonstrate both experimentally and computationally that fatigue cracks under cyclic loading follow dramatically different paths that are predominantly dictated by the symmetry of the loading with the microstructure playing a negligible or subdominant role."],"url":"http://arxiv.org/abs/2404.08451v1","category":"cond-mat.mtrl-sci"}
{"created":"2024-04-12 13:01:22","title":"Joint Physical-Digital Facial Attack Detection Via Simulating Spoofing Clues","abstract":"Face recognition systems are frequently subjected to a variety of physical and digital attacks of different types. Previous methods have achieved satisfactory performance in scenarios that address physical attacks and digital attacks, respectively. However, few methods are considered to integrate a model that simultaneously addresses both physical and digital attacks, implying the necessity to develop and maintain multiple models. To jointly detect physical and digital attacks within a single model, we propose an innovative approach that can adapt to any network architecture. Our approach mainly contains two types of data augmentation, which we call Simulated Physical Spoofing Clues augmentation (SPSC) and Simulated Digital Spoofing Clues augmentation (SDSC). SPSC and SDSC augment live samples into simulated attack samples by simulating spoofing clues of physical and digital attacks, respectively, which significantly improve the capability of the model to detect \"unseen\" attack types. Extensive experiments show that SPSC and SDSC can achieve state-of-the-art generalization in Protocols 2.1 and 2.2 of the UniAttackData dataset, respectively. Our method won first place in \"Unified Physical-Digital Face Attack Detection\" of the 5th Face Anti-spoofing Challenge@CVPR2024. Our final submission obtains 3.75% APCER, 0.93% BPCER, and 2.34% ACER, respectively. Our code is available at https://github.com/Xianhua-He/cvpr2024-face-anti-spoofing-challenge.","sentences":["Face recognition systems are frequently subjected to a variety of physical and digital attacks of different types.","Previous methods have achieved satisfactory performance in scenarios that address physical attacks and digital attacks, respectively.","However, few methods are considered to integrate a model that simultaneously addresses both physical and digital attacks, implying the necessity to develop and maintain multiple models.","To jointly detect physical and digital attacks within a single model, we propose an innovative approach that can adapt to any network architecture.","Our approach mainly contains two types of data augmentation, which we call Simulated Physical Spoofing Clues augmentation (SPSC) and Simulated Digital Spoofing Clues augmentation (SDSC).","SPSC and SDSC augment live samples into simulated attack samples by simulating spoofing clues of physical and digital attacks, respectively, which significantly improve the capability of the model to detect \"unseen\" attack types.","Extensive experiments show that SPSC and SDSC can achieve state-of-the-art generalization in Protocols 2.1 and 2.2 of the UniAttackData dataset, respectively.","Our method won first place in \"Unified Physical-Digital Face Attack Detection\" of the 5th Face Anti-spoofing Challenge@CVPR2024.","Our final submission obtains 3.75% APCER, 0.93% BPCER, and 2.34% ACER, respectively.","Our code is available at https://github.com/Xianhua-He/cvpr2024-face-anti-spoofing-challenge."],"url":"http://arxiv.org/abs/2404.08450v1","category":"cs.CV"}
{"created":"2024-04-12 12:57:21","title":"Growth of two-inch free-standing heteroepitaxial diamond on Ir/YSZ/Si (001) substrates via laser-patterned templates","abstract":"In this paper, 2-inch free-standing diamonds were prepared by using heteroepitaxy on composite Ir/YSZ/Si (001) substrates. To release stress, patterned templates were fabricated using laser etching after the initial growth of 50-nm-diamond. Then, the subsequent growth was completed on a patterned template. The full width at half maximum of the diamond (400) and (311) X-ray rocking curves were 313.5 and 359.3 arcsecs, respectively. Strong band-edge emission in the cathodoluminescence spectrum of the resulting diamond revealed excellent crystalline quality. Furthermore, the 2D mapping of Raman spectra was conducted on a $2 mm \\times 2 mm$ area located at the center of the 2-inch sample with a thickness of $400 {\\mu}m$. The result showed an average peak width of $2.85 \\pm 0.36 cm^{-1}$ and residual stress of $-0.03 \\pm 0.37 GPa$. The dislocation density, determined by counting etching pits generated from $ H_2/O_2$ plasma etching, was estimated to be around $2.2 \\times 10^7 cm^{-2}$. These results evidence that the laser-patterned method can effectively release stress during the growth of large-size diamonds, offering a simpler and more cost-effective alternative to the traditional photolithography-patterned scheme.","sentences":["In this paper, 2-inch free-standing diamonds were prepared by using heteroepitaxy on composite Ir/YSZ/Si (001) substrates.","To release stress, patterned templates were fabricated using laser etching after the initial growth of 50-nm-diamond.","Then, the subsequent growth was completed on a patterned template.","The full width at half maximum of the diamond (400) and (311) X-ray rocking curves were 313.5 and 359.3 arcsecs, respectively.","Strong band-edge emission in the cathodoluminescence spectrum of the resulting diamond revealed excellent crystalline quality.","Furthermore, the 2D mapping of Raman spectra was conducted on a $2 mm \\times 2 mm$ area located at the center of the 2-inch sample with a thickness of $400 {\\mu}m$. The result showed an average peak width of $2.85 \\pm 0.36 cm^{-1}$ and residual stress of $-0.03 \\pm 0.37 GPa$.","The dislocation density, determined by counting etching pits generated from $ H_2/O_2$ plasma etching, was estimated to be around $2.2 \\times 10^7","cm^{-2}$. These results evidence that the laser-patterned method can effectively release stress during the growth of large-size diamonds, offering a simpler and more cost-effective alternative to the traditional photolithography-patterned scheme."],"url":"http://arxiv.org/abs/2404.08446v1","category":"cond-mat.mtrl-sci"}
{"created":"2024-04-12 12:31:06","title":"An improved tabular data generator with VAE-GMM integration","abstract":"The rising use of machine learning in various fields requires robust methods to create synthetic tabular data. Data should preserve key characteristics while addressing data scarcity challenges. Current approaches based on Generative Adversarial Networks, such as the state-of-the-art CTGAN model, struggle with the complex structures inherent in tabular data. These data often contain both continuous and discrete features with non-Gaussian distributions. Therefore, we propose a novel Variational Autoencoder (VAE)-based model that addresses these limitations. Inspired by the TVAE model, our approach incorporates a Bayesian Gaussian Mixture model (BGM) within the VAE architecture. This avoids the limitations imposed by assuming a strictly Gaussian latent space, allowing for a more accurate representation of the underlying data distribution during data generation. Furthermore, our model offers enhanced flexibility by allowing the use of various differentiable distributions for individual features, making it possible to handle both continuous and discrete data types. We thoroughly validate our model on three real-world datasets with mixed data types, including two medically relevant ones, based on their resemblance and utility. This evaluation demonstrates significant outperformance against CTGAN and TVAE, establishing its potential as a valuable tool for generating synthetic tabular data in various domains, particularly in healthcare.","sentences":["The rising use of machine learning in various fields requires robust methods to create synthetic tabular data.","Data should preserve key characteristics while addressing data scarcity challenges.","Current approaches based on Generative Adversarial Networks, such as the state-of-the-art CTGAN model, struggle with the complex structures inherent in tabular data.","These data often contain both continuous and discrete features with non-Gaussian distributions.","Therefore, we propose a novel Variational Autoencoder (VAE)-based model that addresses these limitations.","Inspired by the TVAE model, our approach incorporates a Bayesian Gaussian Mixture model (BGM) within the VAE architecture.","This avoids the limitations imposed by assuming a strictly Gaussian latent space, allowing for a more accurate representation of the underlying data distribution during data generation.","Furthermore, our model offers enhanced flexibility by allowing the use of various differentiable distributions for individual features, making it possible to handle both continuous and discrete data types.","We thoroughly validate our model on three real-world datasets with mixed data types, including two medically relevant ones, based on their resemblance and utility.","This evaluation demonstrates significant outperformance against CTGAN and TVAE, establishing its potential as a valuable tool for generating synthetic tabular data in various domains, particularly in healthcare."],"url":"http://arxiv.org/abs/2404.08434v1","category":"cs.LG"}
{"created":"2024-04-12 12:30:48","title":"MSSTNet: A Multi-Scale Spatio-Temporal CNN-Transformer Network for Dynamic Facial Expression Recognition","abstract":"Unlike typical video action recognition, Dynamic Facial Expression Recognition (DFER) does not involve distinct moving targets but relies on localized changes in facial muscles. Addressing this distinctive attribute, we propose a Multi-Scale Spatio-temporal CNN-Transformer network (MSSTNet). Our approach takes spatial features of different scales extracted by CNN and feeds them into a Multi-scale Embedding Layer (MELayer). The MELayer extracts multi-scale spatial information and encodes these features before sending them into a Temporal Transformer (T-Former). The T-Former simultaneously extracts temporal information while continually integrating multi-scale spatial information. This process culminates in the generation of multi-scale spatio-temporal features that are utilized for the final classification. Our method achieves state-of-the-art results on two in-the-wild datasets. Furthermore, a series of ablation experiments and visualizations provide further validation of our approach's proficiency in leveraging spatio-temporal information within DFER.","sentences":["Unlike typical video action recognition, Dynamic Facial Expression Recognition (DFER) does not involve distinct moving targets but relies on localized changes in facial muscles.","Addressing this distinctive attribute, we propose a Multi-Scale Spatio-temporal CNN-Transformer network (MSSTNet).","Our approach takes spatial features of different scales extracted by CNN and feeds them into a Multi-scale Embedding Layer (MELayer).","The MELayer extracts multi-scale spatial information and encodes these features before sending them into a Temporal Transformer (T-Former).","The T-Former simultaneously extracts temporal information while continually integrating multi-scale spatial information.","This process culminates in the generation of multi-scale spatio-temporal features that are utilized for the final classification.","Our method achieves state-of-the-art results on two in-the-wild datasets.","Furthermore, a series of ablation experiments and visualizations provide further validation of our approach's proficiency in leveraging spatio-temporal information within DFER."],"url":"http://arxiv.org/abs/2404.08433v1","category":"cs.CV"}
{"created":"2024-04-12 12:25:43","title":"A Topologically Enriched Probability Monad on the Cartesian Closed Category of CGWH Spaces","abstract":"Probability monads on categories of topological spaces are classical objects of study in the categorical approach to probability theory. We construct a probability monad on the category of compactly generated weakly Hausdorff (CGWH) spaces, a (if not the) standard choice of convenient category of topological spaces. Because a novel version of the Riesz representation theorem plays a fundamental role in our construction, we name it the Riesz probability monad. We show that the Riesz probability monad is a simultaneous extension of the classical Radon and Giry monads that is topologically enriched. Topological enrichment corresponds to a strengthened continuous mapping theorem (in the sense of probability theory). In addition, restricting the Riesz probability monad to the cartesian closed subcategory of weakly Hausdorff quotients of countably based (QCB) spaces results in a probability monad which is strongly affine, ensuring that the notions of independence and determinism interact as we would expect.","sentences":["Probability monads on categories of topological spaces are classical objects of study in the categorical approach to probability theory.","We construct a probability monad on the category of compactly generated weakly Hausdorff (CGWH) spaces, a (if not the) standard choice of convenient category of topological spaces.","Because a novel version of the Riesz representation theorem plays a fundamental role in our construction, we name it the Riesz probability monad.","We show that the Riesz probability monad is a simultaneous extension of the classical Radon and Giry monads that is topologically enriched.","Topological enrichment corresponds to a strengthened continuous mapping theorem (in the sense of probability theory).","In addition, restricting the Riesz probability monad to the cartesian closed subcategory of weakly Hausdorff quotients of countably based (QCB) spaces results in a probability monad which is strongly affine, ensuring that the notions of independence and determinism interact as we would expect."],"url":"http://arxiv.org/abs/2404.08430v1","category":"math.CT"}
{"created":"2024-04-12 12:21:49","title":"Hopf Bifurcation in Asymmetric Ring Networks: Constraints on Phase Shifts","abstract":"Hopf bifurcation in networks of coupled ODEs creates periodic states in which the relative phases of nodes are well defined near bifurcation. When the network is a fully inhomogeneous nearest-neighbour coupled unidirectional ring, and node spaces are 1-dimensional, we derive constraints on these phase shifts that apply to any ODE that respects the ring topology. We begin with a 3-node ring and generalise the results to any number of nodes. The main point is that such constraints exist even when the only structure present is the network topology. We also prove that the usual nondegeneracy conditions in the classical Hopf Bifurcation Theorem are valid generically for ring networks, by perturbing only coupling terms.","sentences":["Hopf bifurcation in networks of coupled ODEs creates periodic states in which the relative phases of nodes are well defined near bifurcation.","When the network is a fully inhomogeneous nearest-neighbour coupled unidirectional ring, and node spaces are 1-dimensional, we derive constraints on these phase shifts that apply to any ODE that respects the ring topology.","We begin with a 3-node ring and generalise the results to any number of nodes.","The main point is that such constraints exist even when the only structure present is the network topology.","We also prove that the usual nondegeneracy conditions in the classical Hopf Bifurcation Theorem are valid generically for ring networks, by perturbing only coupling terms."],"url":"http://arxiv.org/abs/2404.08428v1","category":"math.DS"}
{"created":"2024-04-12 12:15:14","title":"Comparing Apples to Oranges: LLM-powered Multimodal Intention Prediction in an Object Categorization Task","abstract":"Intention-based Human-Robot Interaction (HRI) systems allow robots to perceive and interpret user actions to proactively interact with humans and adapt to their behavior. Therefore, intention prediction is pivotal in creating a natural interactive collaboration between humans and robots. In this paper, we examine the use of Large Language Models (LLMs) for inferring human intention during a collaborative object categorization task with a physical robot. We introduce a hierarchical approach for interpreting user non-verbal cues, like hand gestures, body poses, and facial expressions and combining them with environment states and user verbal cues captured using an existing Automatic Speech Recognition (ASR) system. Our evaluation demonstrates the potential of LLMs to interpret non-verbal cues and to combine them with their context-understanding capabilities and real-world knowledge to support intention prediction during human-robot interaction.","sentences":["Intention-based Human-Robot Interaction (HRI) systems allow robots to perceive and interpret user actions to proactively interact with humans and adapt to their behavior.","Therefore, intention prediction is pivotal in creating a natural interactive collaboration between humans and robots.","In this paper, we examine the use of Large Language Models (LLMs) for inferring human intention during a collaborative object categorization task with a physical robot.","We introduce a hierarchical approach for interpreting user non-verbal cues, like hand gestures, body poses, and facial expressions and combining them with environment states and user verbal cues captured using an existing Automatic Speech Recognition (ASR) system.","Our evaluation demonstrates the potential of LLMs to interpret non-verbal cues and to combine them with their context-understanding capabilities and real-world knowledge to support intention prediction during human-robot interaction."],"url":"http://arxiv.org/abs/2404.08424v1","category":"cs.RO"}
{"created":"2024-04-12 12:10:53","title":"Adapting the Segment Anything Model During Usage in Novel Situations","abstract":"The interactive segmentation task consists in the creation of object segmentation masks based on user interactions. The most common way to guide a model towards producing a correct segmentation consists in clicks on the object and background. The recently published Segment Anything Model (SAM) supports a generalized version of the interactive segmentation problem and has been trained on an object segmentation dataset which contains 1.1B masks. Though being trained extensively and with the explicit purpose of serving as a foundation model, we show significant limitations of SAM when being applied for interactive segmentation on novel domains or object types. On the used datasets, SAM displays a failure rate $\\text{FR}_{30}@90$ of up to $72.6 \\%$. Since we still want such foundation models to be immediately applicable, we present a framework that can adapt SAM during immediate usage. For this we will leverage the user interactions and masks, which are constructed during the interactive segmentation process. We use this information to generate pseudo-labels, which we use to compute a loss function and optimize a part of the SAM model. The presented method causes a relative reduction of up to $48.1 \\%$ in the $\\text{FR}_{20}@85$ and $46.6 \\%$ in the $\\text{FR}_{30}@90$ metrics.","sentences":["The interactive segmentation task consists in the creation of object segmentation masks based on user interactions.","The most common way to guide a model towards producing a correct segmentation consists in clicks on the object and background.","The recently published Segment Anything Model (SAM) supports a generalized version of the interactive segmentation problem and has been trained on an object segmentation dataset which contains 1.1B masks.","Though being trained extensively and with the explicit purpose of serving as a foundation model, we show significant limitations of SAM when being applied for interactive segmentation on novel domains or object types.","On the used datasets, SAM displays a failure rate $\\text{FR}_{30}@90$ of up to $72.6 \\%$. Since we still want such foundation models to be immediately applicable, we present a framework that can adapt SAM during immediate usage.","For this we will leverage the user interactions and masks, which are constructed during the interactive segmentation process.","We use this information to generate pseudo-labels, which we use to compute a loss function and optimize a part of the SAM model.","The presented method causes a relative reduction of up to $48.1 \\%$ in the $\\text{FR}_{20}@85$ and $46.6 \\%$ in the $\\text{FR}_{30}@90$ metrics."],"url":"http://arxiv.org/abs/2404.08421v1","category":"cs.CV"}
{"created":"2024-04-12 12:08:06","title":"Direct May Not Be the Best: An Incremental Evolution View of Pose Generation","abstract":"Pose diversity is an inherent representative characteristic of 2D images. Due to the 3D to 2D projection mechanism, there is evident content discrepancy among distinct pose images. This is the main obstacle bothering pose transformation related researches. To deal with this challenge, we propose a fine-grained incremental evolution centered pose generation framework, rather than traditional direct one-to-one in a rush. Since proposed approach actually bypasses the theoretical difficulty of directly modeling dramatic non-linear variation, the incurred content distortion and blurring could be effectively constrained, at the same time the various individual pose details, especially clothes texture, could be precisely maintained. In order to systematically guide the evolution course, both global and incremental evolution constraints are elaborately designed and merged into the overall frame?work. And a novel triple-path knowledge fusion structure is worked out to take full advantage of all available valuable knowledge to conduct high-quality pose synthesis. In addition, our framework could generate a series of valuable byproducts, namely the various intermediate poses. Extensive experiments have been conducted to verify the effectiveness of the proposed approach. Code is available at https://github.com/Xiaofei-CN/Incremental-Evolution-Pose-Generation.","sentences":["Pose diversity is an inherent representative characteristic of 2D images.","Due to the 3D to 2D projection mechanism, there is evident content discrepancy among distinct pose images.","This is the main obstacle bothering pose transformation related researches.","To deal with this challenge, we propose a fine-grained incremental evolution centered pose generation framework, rather than traditional direct one-to-one in a rush.","Since proposed approach actually bypasses the theoretical difficulty of directly modeling dramatic non-linear variation, the incurred content distortion and blurring could be effectively constrained, at the same time the various individual pose details, especially clothes texture, could be precisely maintained.","In order to systematically guide the evolution course, both global and incremental evolution constraints are elaborately designed and merged into the overall frame?work.","And a novel triple-path knowledge fusion structure is worked out to take full advantage of all available valuable knowledge to conduct high-quality pose synthesis.","In addition, our framework could generate a series of valuable byproducts, namely the various intermediate poses.","Extensive experiments have been conducted to verify the effectiveness of the proposed approach.","Code is available at https://github.com/Xiaofei-CN/Incremental-Evolution-Pose-Generation."],"url":"http://arxiv.org/abs/2404.08419v1","category":"cs.CV"}
{"created":"2024-04-12 12:07:40","title":"MINCE II. Neutron capture elements","abstract":"The MINCE (Measuring at Intermediate metallicity Neutron-Capture Elements) project aims to gather the abundances of neutron-capture elements but also of light elements and iron peak elements in a large sample of giant stars in this metallicity range. T The aim of this work is to study the chemical evolution of galactic sub-components recently identified (i.e. Gaia Sausage Enceladus (GSE), Sequoia). We used high signal-to-noise ratios, high-resolution spectra and standard 1D LTE spectrum synthesis to determine the detailed abundances. We could determine the abundances for up to 10 neutron-capture elements (Sr, Y, Zr, Ba, La, Ce, Pr, Nd, Sm and Eu) in 33 stars. The general trends of abundance ratios [n-capture element/Fe] versus [Fe/H] are in agreement with the results found in the literature. When our sample is divided in sub-groups depending on their kinematics, we found that the run of [Sr/Ba] vs [Ba/H] for the stars belonging to the GSE accretion event shows a tight anti-correlation. The results for the Sequoia stars, although based on a very limited sample, shows a [Sr/Ba] systematically higher than the [Sr/Ba] found in the GSE stars at a given [Ba/H] hinting at a different nucleosynthetic history. Stochastic chemical evolution models have been computed to understand the evolution of the GSE chemical composition of Sr and Ba. The first conclusions are that the GSE chemical evolution is similar to the evolution of a dwarf galaxy with galactic winds and inefficient star formation.   Detailed abundances of neutron-capture elements have been measured in high-resolution, high signal-to-noise spectra of intermediate metal-poor stars, the metallicity range covered by the MINCE project. These abundances have been compared to detailed stochastic models of galactic chemical evolution.","sentences":["The MINCE (Measuring at Intermediate metallicity Neutron-Capture Elements) project aims to gather the abundances of neutron-capture elements but also of light elements and iron peak elements in a large sample of giant stars in this metallicity range.","T","The aim of this work is to study the chemical evolution of galactic sub-components recently identified (i.e. Gaia Sausage Enceladus (GSE), Sequoia).","We used high signal-to-noise ratios, high-resolution spectra and standard 1D LTE spectrum synthesis to determine the detailed abundances.","We could determine the abundances for up to 10 neutron-capture elements (Sr, Y, Zr, Ba, La, Ce, Pr, Nd, Sm and Eu) in 33 stars.","The general trends of abundance ratios [n-capture element/Fe] versus [Fe/H] are in agreement with the results found in the literature.","When our sample is divided in sub-groups depending on their kinematics, we found that the run of [Sr/Ba] vs [Ba/H] for the stars belonging to the GSE accretion event shows a tight anti-correlation.","The results for the Sequoia stars, although based on a very limited sample, shows a [Sr/Ba] systematically higher than the [Sr/Ba] found in the GSE stars at a given [Ba/H] hinting at a different nucleosynthetic history.","Stochastic chemical evolution models have been computed to understand the evolution of the GSE chemical composition of Sr and Ba.","The first conclusions are that the GSE chemical evolution is similar to the evolution of a dwarf galaxy with galactic winds and inefficient star formation.   ","Detailed abundances of neutron-capture elements have been measured in high-resolution, high signal-to-noise spectra of intermediate metal-poor stars, the metallicity range covered by the MINCE project.","These abundances have been compared to detailed stochastic models of galactic chemical evolution."],"url":"http://arxiv.org/abs/2404.08418v1","category":"astro-ph.SR"}
{"created":"2024-04-12 12:06:02","title":"AdapterSwap: Continuous Training of LLMs with Data Removal and Access-Control Guarantees","abstract":"Large language models (LLMs) are increasingly capable of completing knowledge intensive tasks by recalling information from a static pretraining corpus. Here we are concerned with LLMs in the context of evolving data requirements. For instance: batches of new data that are introduced periodically; subsets of data with user-based access controls; or requirements on dynamic removal of documents with guarantees that associated knowledge cannot be recalled. We wish to satisfy these requirements while at the same time ensuring a model does not forget old information when new data becomes available. To address these issues, we introduce AdapterSwap, a training and inference scheme that organizes knowledge from a data collection into a set of low-rank adapters, which are dynamically composed during inference. Our experiments demonstrate AdapterSwap's ability to support efficient continual learning, while also enabling organizations to have fine-grained control over data access and deletion.","sentences":["Large language models (LLMs) are increasingly capable of completing knowledge intensive tasks by recalling information from a static pretraining corpus.","Here we are concerned with LLMs in the context of evolving data requirements.","For instance: batches of new data that are introduced periodically; subsets of data with user-based access controls; or requirements on dynamic removal of documents with guarantees that associated knowledge cannot be recalled.","We wish to satisfy these requirements while at the same time ensuring a model does not forget old information when new data becomes available.","To address these issues, we introduce AdapterSwap, a training and inference scheme that organizes knowledge from a data collection into a set of low-rank adapters, which are dynamically composed during inference.","Our experiments demonstrate AdapterSwap's ability to support efficient continual learning, while also enabling organizations to have fine-grained control over data access and deletion."],"url":"http://arxiv.org/abs/2404.08417v1","category":"cs.LG"}
{"created":"2024-04-12 12:01:59","title":"Asymptotics of relaxed $k$-ary trees","abstract":"A relaxed $k$-ary tree is an ordered directed acyclic graph with a unique source and sink in which every node has out-degree $k$. These objects arise in the compression of trees in which some repeated subtrees are factored and repeated appearances are replaced by pointers. We prove an asymptotic theta-result for the number of relaxed $k$-ary tree with $n$ nodes for $n \\to \\infty$. This generalizes the previously proved binary case to arbitrary finite arity, and shows that the seldom observed phenomenon of a stretched exponential term $e^{c n^{1/3}}$ appears in all these cases. We also derive the recurrences for compacted $k$-ary trees in which all subtrees are unique and minimal deterministic finite automata accepting a finite language over a finite alphabet.","sentences":["A relaxed $k$-ary tree is an ordered directed acyclic graph with a unique source and sink in which every node has out-degree $k$.","These objects arise in the compression of trees in which some repeated subtrees are factored and repeated appearances are replaced by pointers.","We prove an asymptotic theta-result for the number of relaxed $k$-ary tree with $n$ nodes for $n \\to \\infty$. This generalizes the previously proved binary case to arbitrary finite arity, and shows that the seldom observed phenomenon of a stretched exponential term $e^{c n^{1/3}}$ appears in all these cases.","We also derive the recurrences for compacted $k$-ary trees in which all subtrees are unique and minimal deterministic finite automata accepting a finite language over a finite alphabet."],"url":"http://arxiv.org/abs/2404.08415v1","category":"math.CO"}
{"created":"2024-04-12 11:58:13","title":"Evolutionary Preference Sampling for Pareto Set Learning","abstract":"Recently, Pareto Set Learning (PSL) has been proposed for learning the entire Pareto set using a neural network. PSL employs preference vectors to scalarize multiple objectives, facilitating the learning of mappings from preference vectors to specific Pareto optimal solutions. Previous PSL methods have shown their effectiveness in solving artificial multi-objective optimization problems (MOPs) with uniform preference vector sampling. The quality of the learned Pareto set is influenced by the sampling strategy of the preference vector, and the sampling of the preference vector needs to be decided based on the Pareto front shape. However, a fixed preference sampling strategy cannot simultaneously adapt the Pareto front of multiple MOPs. To address this limitation, this paper proposes an Evolutionary Preference Sampling (EPS) strategy to efficiently sample preference vectors. Inspired by evolutionary algorithms, we consider preference sampling as an evolutionary process to generate preference vectors for neural network training. We integrate the EPS strategy into five advanced PSL methods. Extensive experiments demonstrate that our proposed method has a faster convergence speed than baseline algorithms on 7 testing problems. Our implementation is available at https://github.com/rG223/EPS.","sentences":["Recently, Pareto Set Learning (PSL) has been proposed for learning the entire Pareto set using a neural network.","PSL employs preference vectors to scalarize multiple objectives, facilitating the learning of mappings from preference vectors to specific Pareto optimal solutions.","Previous PSL methods have shown their effectiveness in solving artificial multi-objective optimization problems (MOPs) with uniform preference vector sampling.","The quality of the learned Pareto set is influenced by the sampling strategy of the preference vector, and the sampling of the preference vector needs to be decided based on the Pareto front shape.","However, a fixed preference sampling strategy cannot simultaneously adapt the Pareto front of multiple MOPs.","To address this limitation, this paper proposes an Evolutionary Preference Sampling (EPS) strategy to efficiently sample preference vectors.","Inspired by evolutionary algorithms, we consider preference sampling as an evolutionary process to generate preference vectors for neural network training.","We integrate the EPS strategy into five advanced PSL methods.","Extensive experiments demonstrate that our proposed method has a faster convergence speed than baseline algorithms on 7 testing problems.","Our implementation is available at https://github.com/rG223/EPS."],"url":"http://arxiv.org/abs/2404.08414v1","category":"cs.NE"}
{"created":"2024-04-12 11:45:51","title":"PiRD: Physics-informed Residual Diffusion for Flow Field Reconstruction","abstract":"The use of machine learning in fluid dynamics is becoming more common to expedite the computation when solving forward and inverse problems of partial differential equations. Yet, a notable challenge with existing convolutional neural network (CNN)-based methods for data fidelity enhancement is their reliance on specific low-fidelity data patterns and distributions during the training phase. In addition, the CNN-based method essentially treats the flow reconstruction task as a computer vision task that prioritizes the element-wise precision which lacks a physical and mathematical explanation. This dependence can dramatically affect the models' effectiveness in real-world scenarios, especially when the low-fidelity input deviates from the training data or contains noise not accounted for during training. The introduction of diffusion models in this context shows promise for improving performance and generalizability. Unlike direct mapping from a specific low-fidelity to a high-fidelity distribution, diffusion models learn to transition from any low-fidelity distribution towards a high-fidelity one. Our proposed model - Physics-informed Residual Diffusion, demonstrates the capability to elevate the quality of data from both standard low-fidelity inputs, to low-fidelity inputs with injected Gaussian noise, and randomly collected samples. By integrating physics-based insights into the objective function, it further refines the accuracy and the fidelity of the inferred high-quality data. Experimental results have shown that our approach can effectively reconstruct high-quality outcomes for two-dimensional turbulent flows from a range of low-fidelity input conditions without requiring retraining.","sentences":["The use of machine learning in fluid dynamics is becoming more common to expedite the computation when solving forward and inverse problems of partial differential equations.","Yet, a notable challenge with existing convolutional neural network (CNN)-based methods for data fidelity enhancement is their reliance on specific low-fidelity data patterns and distributions during the training phase.","In addition, the CNN-based method essentially treats the flow reconstruction task as a computer vision task that prioritizes the element-wise precision which lacks a physical and mathematical explanation.","This dependence can dramatically affect the models' effectiveness in real-world scenarios, especially when the low-fidelity input deviates from the training data or contains noise not accounted for during training.","The introduction of diffusion models in this context shows promise for improving performance and generalizability.","Unlike direct mapping from a specific low-fidelity to a high-fidelity distribution, diffusion models learn to transition from any low-fidelity distribution towards a high-fidelity one.","Our proposed model - Physics-informed Residual Diffusion, demonstrates the capability to elevate the quality of data from both standard low-fidelity inputs, to low-fidelity inputs with injected Gaussian noise, and randomly collected samples.","By integrating physics-based insights into the objective function, it further refines the accuracy and the fidelity of the inferred high-quality data.","Experimental results have shown that our approach can effectively reconstruct high-quality outcomes for two-dimensional turbulent flows from a range of low-fidelity input conditions without requiring retraining."],"url":"http://arxiv.org/abs/2404.08412v1","category":"physics.flu-dyn"}
{"created":"2024-04-12 11:36:24","title":"Seismic First Break Picking in a Higher Dimension Using Deep Graph Learning","abstract":"Contemporary automatic first break (FB) picking methods typically analyze 1D signals, 2D source gathers, or 3D source-receiver gathers. Utilizing higher-dimensional data, such as 2D or 3D, incorporates global features, improving the stability of local picking. Despite the benefits, high-dimensional data requires structured input and increases computational demands. Addressing this, we propose a novel approach using deep graph learning called DGL-FB, constructing a large graph to efficiently extract information. In this graph, each seismic trace is represented as a node, connected by edges that reflect similarities. To manage the size of the graph, we develop a subgraph sampling technique to streamline model training and inference. Our proposed framework, DGL-FB, leverages deep graph learning for FB picking. It encodes subgraphs into global features using a deep graph encoder. Subsequently, the encoded global features are combined with local node signals and fed into a ResUNet-based 1D segmentation network for FB detection. Field survey evaluations of DGL-FB show superior accuracy and stability compared to a 2D U-Net-based benchmark method.","sentences":["Contemporary automatic first break (FB) picking methods typically analyze 1D signals, 2D source gathers, or 3D source-receiver gathers.","Utilizing higher-dimensional data, such as 2D or 3D, incorporates global features, improving the stability of local picking.","Despite the benefits, high-dimensional data requires structured input and increases computational demands.","Addressing this, we propose a novel approach using deep graph learning called DGL-FB, constructing a large graph to efficiently extract information.","In this graph, each seismic trace is represented as a node, connected by edges that reflect similarities.","To manage the size of the graph, we develop a subgraph sampling technique to streamline model training and inference.","Our proposed framework, DGL-FB, leverages deep graph learning for FB picking.","It encodes subgraphs into global features using a deep graph encoder.","Subsequently, the encoded global features are combined with local node signals and fed into a ResUNet-based 1D segmentation network for FB detection.","Field survey evaluations of DGL-FB show superior accuracy and stability compared to a 2D U-Net-based benchmark method."],"url":"http://arxiv.org/abs/2404.08408v1","category":"cs.LG"}
{"created":"2024-04-12 11:33:26","title":"MambaDFuse: A Mamba-based Dual-phase Model for Multi-modality Image Fusion","abstract":"Multi-modality image fusion (MMIF) aims to integrate complementary information from different modalities into a single fused image to represent the imaging scene and facilitate downstream visual tasks comprehensively. In recent years, significant progress has been made in MMIF tasks due to advances in deep neural networks. However, existing methods cannot effectively and efficiently extract modality-specific and modality-fused features constrained by the inherent local reductive bias (CNN) or quadratic computational complexity (Transformers). To overcome this issue, we propose a Mamba-based Dual-phase Fusion (MambaDFuse) model. Firstly, a dual-level feature extractor is designed to capture long-range features from single-modality images by extracting low and high-level features from CNN and Mamba blocks. Then, a dual-phase feature fusion module is proposed to obtain fusion features that combine complementary information from different modalities. It uses the channel exchange method for shallow fusion and the enhanced Multi-modal Mamba (M3) blocks for deep fusion. Finally, the fused image reconstruction module utilizes the inverse transformation of the feature extraction to generate the fused result. Through extensive experiments, our approach achieves promising fusion results in infrared-visible image fusion and medical image fusion. Additionally, in a unified benchmark, MambaDFuse has also demonstrated improved performance in downstream tasks such as object detection. Code with checkpoints will be available after the peer-review process.","sentences":["Multi-modality image fusion (MMIF) aims to integrate complementary information from different modalities into a single fused image to represent the imaging scene and facilitate downstream visual tasks comprehensively.","In recent years, significant progress has been made in MMIF tasks due to advances in deep neural networks.","However, existing methods cannot effectively and efficiently extract modality-specific and modality-fused features constrained by the inherent local reductive bias (CNN) or quadratic computational complexity (Transformers).","To overcome this issue, we propose a Mamba-based Dual-phase Fusion (MambaDFuse) model.","Firstly, a dual-level feature extractor is designed to capture long-range features from single-modality images by extracting low and high-level features from CNN and Mamba blocks.","Then, a dual-phase feature fusion module is proposed to obtain fusion features that combine complementary information from different modalities.","It uses the channel exchange method for shallow fusion and the enhanced Multi-modal Mamba (M3) blocks for deep fusion.","Finally, the fused image reconstruction module utilizes the inverse transformation of the feature extraction to generate the fused result.","Through extensive experiments, our approach achieves promising fusion results in infrared-visible image fusion and medical image fusion.","Additionally, in a unified benchmark, MambaDFuse has also demonstrated improved performance in downstream tasks such as object detection.","Code with checkpoints will be available after the peer-review process."],"url":"http://arxiv.org/abs/2404.08406v1","category":"cs.CV"}
{"created":"2024-04-12 11:32:02","title":"Unconventional superconducting diode effects via antisymmetry and antisymmetry breaking","abstract":"Symmetry-breaking plays a pivotal role in unlocking intriguing properties and functionalities in material systems. For example, the breaking of spatial and temporal symmetries leads to a fascinating phenomenon of superconducting diode effect. However, generating and precisely controlling the superconducting diode effect poses significant challenges. Here, we take a novel route with deliberate manipulation of magnetic charge potentials to realize unconventional superconducting flux-quantum diode effects. We achieve this through suitably tailored nanoengineered arrays of nanobar magnets on top of a superconducting thin film. We demonstrate the vital roles of inversion antisymmetry and its breaking in evoking unconventional superconducting effects-a magnetically symmetric diode effect and an odd-parity magnetotransport effect. These effects are non-volatilely controllable through in-situ magnetization switching of the nanobar magnets. Our findings promote the use of antisymmetry (breaking) for initiating unconventional superconducting properties, paving the way for exciting prospects and innovative functionalities in superconducting electronics.","sentences":["Symmetry-breaking plays a pivotal role in unlocking intriguing properties and functionalities in material systems.","For example, the breaking of spatial and temporal symmetries leads to a fascinating phenomenon of superconducting diode effect.","However, generating and precisely controlling the superconducting diode effect poses significant challenges.","Here, we take a novel route with deliberate manipulation of magnetic charge potentials to realize unconventional superconducting flux-quantum diode effects.","We achieve this through suitably tailored nanoengineered arrays of nanobar magnets on top of a superconducting thin film.","We demonstrate the vital roles of inversion antisymmetry and its breaking in evoking unconventional superconducting effects-a magnetically symmetric diode effect and an odd-parity magnetotransport effect.","These effects are non-volatilely controllable through in-situ magnetization switching of the nanobar magnets.","Our findings promote the use of antisymmetry (breaking) for initiating unconventional superconducting properties, paving the way for exciting prospects and innovative functionalities in superconducting electronics."],"url":"http://arxiv.org/abs/2404.08405v1","category":"cond-mat.supr-con"}
{"created":"2024-04-12 11:31:37","title":"Complexity of Probabilistic Reasoning for Neurosymbolic Classification Techniques","abstract":"Neurosymbolic artificial intelligence is a growing field of research aiming to combine neural network learning capabilities with the reasoning abilities of symbolic systems. Informed multi-label classification is a sub-field of neurosymbolic AI which studies how to leverage prior knowledge to improve neural classification systems. A well known family of neurosymbolic techniques for informed classification use probabilistic reasoning to integrate this knowledge during learning, inference or both. Therefore, the asymptotic complexity of probabilistic reasoning is of cardinal importance to assess the scalability of such techniques. However, this topic is rarely tackled in the neurosymbolic literature, which can lead to a poor understanding of the limits of probabilistic neurosymbolic techniques. In this paper, we introduce a formalism for informed supervised classification tasks and techniques. We then build upon this formalism to define three abstract neurosymbolic techniques based on probabilistic reasoning. Finally, we show computational complexity results on several representation languages for prior knowledge commonly found in the neurosymbolic literature.","sentences":["Neurosymbolic artificial intelligence is a growing field of research aiming to combine neural network learning capabilities with the reasoning abilities of symbolic systems.","Informed multi-label classification is a sub-field of neurosymbolic AI which studies how to leverage prior knowledge to improve neural classification systems.","A well known family of neurosymbolic techniques for informed classification use probabilistic reasoning to integrate this knowledge during learning, inference or both.","Therefore, the asymptotic complexity of probabilistic reasoning is of cardinal importance to assess the scalability of such techniques.","However, this topic is rarely tackled in the neurosymbolic literature, which can lead to a poor understanding of the limits of probabilistic neurosymbolic techniques.","In this paper, we introduce a formalism for informed supervised classification tasks and techniques.","We then build upon this formalism to define three abstract neurosymbolic techniques based on probabilistic reasoning.","Finally, we show computational complexity results on several representation languages for prior knowledge commonly found in the neurosymbolic literature."],"url":"http://arxiv.org/abs/2404.08404v1","category":"cs.AI"}
{"created":"2024-04-12 11:15:15","title":"No Bells, Just Whistles: Sports Field Registration by Leveraging Geometric Properties","abstract":"Broadcast sports field registration is traditionally addressed as a homography estimation task, mapping the visible image area to a planar field model, predominantly focusing on the main camera shot. Addressing the shortcomings of previous approaches, we propose a novel calibration pipeline enabling camera calibration using a 3D soccer field model and extending the process to assess the multiple-view nature of broadcast videos. Our approach begins with a keypoint generation pipeline derived from SoccerNet dataset annotations, leveraging the geometric properties of the court. Subsequently, we execute classical camera calibration through DLT algorithm in a minimalist fashion, without further refinement. Through extensive experimentation on real-world soccer broadcast datasets such as SoccerNet-Calibration, WorldCup 2014 and TS- WorldCup, our method demonstrates superior performance in both multiple- and single-view 3D camera calibration while maintaining competitive results in homography estimation compared to state-of-the-art techniques.","sentences":["Broadcast sports field registration is traditionally addressed as a homography estimation task, mapping the visible image area to a planar field model, predominantly focusing on the main camera shot.","Addressing the shortcomings of previous approaches, we propose a novel calibration pipeline enabling camera calibration using a 3D soccer field model and extending the process to assess the multiple-view nature of broadcast videos.","Our approach begins with a keypoint generation pipeline derived from SoccerNet dataset annotations, leveraging the geometric properties of the court.","Subsequently, we execute classical camera calibration through DLT algorithm in a minimalist fashion, without further refinement.","Through extensive experimentation on real-world soccer broadcast datasets such as SoccerNet-Calibration, WorldCup 2014 and TS- WorldCup, our method demonstrates superior performance in both multiple- and single-view 3D camera calibration while maintaining competitive results in homography estimation compared to state-of-the-art techniques."],"url":"http://arxiv.org/abs/2404.08401v1","category":"cs.CV"}
{"created":"2024-04-12 11:08:26","title":"Mitigating Challenges of the Space Environment for Onboard Artificial Intelligence: Design Overview of the Imaging Payload on SpIRIT","abstract":"Artificial intelligence (AI) and autonomous edge computing in space are emerging areas of interest to augment capabilities of nanosatellites, where modern sensors generate orders of magnitude more data than can typically be transmitted to mission control. Here, we present the hardware and software design of an onboard AI subsystem hosted on SpIRIT. The system is optimised for on-board computer vision experiments based on visible light and long wave infrared cameras. This paper highlights the key design choices made to maximise the robustness of the system in harsh space conditions, and their motivation relative to key mission requirements, such as limited compute resources, resilience to cosmic radiation, extreme temperature variations, distribution shifts, and very low transmission bandwidths. The payload, called Loris, consists of six visible light cameras, three infrared cameras, a camera control board and a Graphics Processing Unit (GPU) system-on-module. Loris enables the execution of AI models with on-orbit fine-tuning as well as a next-generation image compression algorithm, including progressive coding. This innovative approach not only enhances the data processing capabilities of nanosatellites but also lays the groundwork for broader applications to remote sensing from space.","sentences":["Artificial intelligence (AI) and autonomous edge computing in space are emerging areas of interest to augment capabilities of nanosatellites, where modern sensors generate orders of magnitude more data than can typically be transmitted to mission control.","Here, we present the hardware and software design of an onboard AI subsystem hosted on SpIRIT.","The system is optimised for on-board computer vision experiments based on visible light and long wave infrared cameras.","This paper highlights the key design choices made to maximise the robustness of the system in harsh space conditions, and their motivation relative to key mission requirements, such as limited compute resources, resilience to cosmic radiation, extreme temperature variations, distribution shifts, and very low transmission bandwidths.","The payload, called Loris, consists of six visible light cameras, three infrared cameras, a camera control board and a Graphics Processing Unit (GPU) system-on-module.","Loris enables the execution of AI models with on-orbit fine-tuning as well as a next-generation image compression algorithm, including progressive coding.","This innovative approach not only enhances the data processing capabilities of nanosatellites but also lays the groundwork for broader applications to remote sensing from space."],"url":"http://arxiv.org/abs/2404.08399v1","category":"cs.CV"}
{"created":"2024-04-12 11:07:10","title":"Multi-Agent eXperimenter (MAX)","abstract":"We present a novel multi-agent simulator named Multi-Agent eXperimenter (MAX) that is designed to simulate blockchain experiments involving large numbers of agents of different types acting in one or several environments. The architecture of MAX is highly modular, enabling easy addition of new models.","sentences":["We present a novel multi-agent simulator named Multi-Agent eXperimenter (MAX) that is designed to simulate blockchain experiments involving large numbers of agents of different types acting in one or several environments.","The architecture of MAX is highly modular, enabling easy addition of new models."],"url":"http://arxiv.org/abs/2404.08398v1","category":"cs.MA"}
{"created":"2024-04-12 10:52:55","title":"On trapping geometry for cold atoms in a radio-frequency (rf) dressed potential","abstract":"We have investigated the atom trapping geometry for trapping of $^{87}{Rb}$ atoms in a radio-frequency (rf) dressed potential generated after superposing a strong linearly polarized rf-field on a static magnetic trap. For this, laser cooled atoms in a magneto-optical trap (MOT) in an ultra-high vacuum (UHV) chamber (pressure $\\sim$ 1.5 $\\times$ $10^{-10}$ Torr) were trapped in a quadrupole magnetic trap and evaporatively cooled before transferring them to the rf-dressed potential. The experimentally observed hollow shell type atom trapping geometry has been explained by theoretical modelling of the trapping potential.","sentences":["We have investigated the atom trapping geometry for trapping of $^{87}{Rb}$ atoms in a radio-frequency (rf) dressed potential generated after superposing a strong linearly polarized rf-field on a static magnetic trap.","For this, laser cooled atoms in a magneto-optical trap (MOT) in an ultra-high vacuum (UHV) chamber (pressure $\\sim$ 1.5 $\\times$ $10^{-10}$ Torr) were trapped in a quadrupole magnetic trap and evaporatively cooled before transferring them to the rf-dressed potential.","The experimentally observed hollow shell type atom trapping geometry has been explained by theoretical modelling of the trapping potential."],"url":"http://arxiv.org/abs/2404.08391v1","category":"physics.atom-ph"}
{"created":"2024-04-12 10:43:38","title":"The asymptotic distribution of the scaled remainder for pseudo golden ratio expansions of a continuous random variable","abstract":"Let $X=\\sum_{k=1}^\\infty X_k \\beta^{-k}$ be the base-$\\beta$ expansion of a continuous random variable $X$ on the unit interval where $\\beta$ is the positive solution to $\\beta^n = 1 + \\beta + \\cdots + \\beta^{n-1}$ for an integer $n\\ge 2$ (i.e., $\\beta$ is a generalization of the golden mean for which $n=2$). We study the asymptotic distribution and convergence rate of the scaled remainder $\\sum_{k=1}^\\infty X_{m+k} \\beta^{-k}$ when $m$ tends to infinity.","sentences":["Let $X=\\sum_{k=1}^\\infty X_k \\beta^{-k}$","be the base-$\\beta$ expansion of a continuous random variable $X$ on the unit interval where $\\beta$ is the positive solution to $\\beta^n = 1 + \\beta + \\cdots + \\beta^{n-1}$ for an integer $n\\ge 2$ (i.e., $\\beta$ is a generalization of the golden mean for which $n=2$).","We study the asymptotic distribution and convergence rate of the scaled remainder $\\sum_{k=1}^\\infty X_{m+k} \\beta^{-k}$ when $m$ tends to infinity."],"url":"http://arxiv.org/abs/2404.08387v1","category":"math.PR"}
{"created":"2024-04-12 10:37:24","title":"Optimal Transport for Mixtures of Radial Functions","abstract":"Recently, a relaxed formulation of optimal transport for Gaussian mixtures has been proposed, which is based on the explicit formulation between Gaussians. The Gaussian distributions can be viewed as special elliptical contoured distributions generated from exponential function. In literature, there are few research about optimal transport between elliptical contoured distributions generated from different functions. In this paper, we first study optimal transport between radial contoured distributions generated from different functions and show theirWasserstein barycenter is still radial. Then we introduce a relaxed Wasserstein-type distance for mixtures with radial contoured components. We also consider the corresponding barycenter problem and connect it with a multimarginal problem.","sentences":["Recently, a relaxed formulation of optimal transport for Gaussian mixtures has been proposed, which is based on the explicit formulation between Gaussians.","The Gaussian distributions can be viewed as special elliptical contoured distributions generated from exponential function.","In literature, there are few research about optimal transport between elliptical contoured distributions generated from different functions.","In this paper, we first study optimal transport between radial contoured distributions generated from different functions and show theirWasserstein barycenter is still radial.","Then we introduce a relaxed Wasserstein-type distance for mixtures with radial contoured components.","We also consider the corresponding barycenter problem and connect it with a multimarginal problem."],"url":"http://arxiv.org/abs/2404.08383v1","category":"math.OC"}
{"created":"2024-04-12 10:36:15","title":"Look at the Text: Instruction-Tuned Language Models are More Robust Multiple Choice Selectors than You Think","abstract":"Multiple choice questions (MCQs) are commonly used to evaluate the capabilities of large language models (LLMs). One common way to evaluate the model response is to rank the candidate answers based on the log probability of the first token prediction. An alternative way is to examine the text output. Prior work has shown that first token probabilities lack robustness to changes in MCQ phrasing, and that first token probabilities do not match text answers for instruction-tuned models. Therefore, in this paper, we investigate the robustness of text answers. We show that the text answers are more robust to question perturbations than the first token probabilities, when the first token answers mismatch the text answers. The difference in robustness increases as the mismatch rate becomes greater. As the mismatch reaches over 50\\%, the text answer is more robust to option order changes than the debiased first token probabilities using state-of-the-art debiasing methods such as PriDe. Our findings provide further evidence for the benefits of text answer evaluation over first token probability evaluation.","sentences":["Multiple choice questions (MCQs) are commonly used to evaluate the capabilities of large language models (LLMs).","One common way to evaluate the model response is to rank the candidate answers based on the log probability of the first token prediction.","An alternative way is to examine the text output.","Prior work has shown that first token probabilities lack robustness to changes in MCQ phrasing, and that first token probabilities do not match text answers for instruction-tuned models.","Therefore, in this paper, we investigate the robustness of text answers.","We show that the text answers are more robust to question perturbations than the first token probabilities, when the first token answers mismatch the text answers.","The difference in robustness increases as the mismatch rate becomes greater.","As the mismatch reaches over 50\\%, the text answer is more robust to option order changes than the debiased first token probabilities using state-of-the-art debiasing methods such as PriDe.","Our findings provide further evidence for the benefits of text answer evaluation over first token probability evaluation."],"url":"http://arxiv.org/abs/2404.08382v1","category":"cs.CL"}
{"created":"2024-04-12 10:33:56","title":"Influence of the cosmological constant on $\u03ba$-deformed Neutron Star","abstract":"We study a model of the neutron star in $\\kappa$-deformed space-time in the presence of the cosmological constant ($\\Lambda$). The Einstein tensor and the energy-momentum tensor are generalized to $\\kappa$-deformed space-time and we construct the field equations with the cosmological constant. Considering the interior of the star to be a perfect fluid as in the commutative case, we find the Tolman-Oppenheimer-Volkoff equations with the inclusion of the cosmological constant in $\\kappa$-deformed space-time. The behavior of the maximum allowed mass of the star and its radius are studied with the variation in the cosmological constant as well as the deformation parameter. We see that the non-commutativity enhances the mass of the star and its maximum mass increases with a decrease in the cosmological constant. The maximum mass varies from $3.44M_{\\odot}$ to $3.68M_{\\odot}$ as $\\Lambda$ varies from $10^{-10}m^{-2}$ to $10^{-15}m^{-2}$. We also obtain the compactness factor and surface redshift of the star. We observe that the compactness of the star increases as the cosmological constant decreases, whereas the surface redshift of the star decreases with a decrease in the cosmological constant. The compactness factor and surface redshift corresponding to the maximum mass of the neutron star remains almost constant as $\\Lambda$ decreases.","sentences":["We study a model of the neutron star in $\\kappa$-deformed space-time in the presence of the cosmological constant ($\\Lambda$).","The Einstein tensor and the energy-momentum tensor are generalized to $\\kappa$-deformed space-time and we construct the field equations with the cosmological constant.","Considering the interior of the star to be a perfect fluid as in the commutative case, we find the Tolman-Oppenheimer-Volkoff equations with the inclusion of the cosmological constant in $\\kappa$-deformed space-time.","The behavior of the maximum allowed mass of the star and its radius are studied with the variation in the cosmological constant as well as the deformation parameter.","We see that the non-commutativity enhances the mass of the star and its maximum mass increases with a decrease in the cosmological constant.","The maximum mass varies from $3.44M_{\\odot}$ to $3.68M_{\\odot}$ as $\\Lambda$ varies from $10^{-10}m^{-2}$ to $10^{-15}m^{-2}$. We also obtain the compactness factor and surface redshift of the star.","We observe that the compactness of the star increases as the cosmological constant decreases, whereas the surface redshift of the star decreases with a decrease in the cosmological constant.","The compactness factor and surface redshift corresponding to the maximum mass of the neutron star remains almost constant as $\\Lambda$ decreases."],"url":"http://arxiv.org/abs/2404.08381v1","category":"gr-qc"}
{"created":"2024-04-12 10:26:50","title":"Prospects for detection of ultra high frequency gravitational waves from hyperbolic encounters with resonant cavities","abstract":"In this brief note, we pursue the systematic investigation of possible gravitational wave sources in the gigahertz band. We focus on hyperbolic encounters of light black holes and evaluate precisely the expected signal when accounting for the detailed characteristics of haloscope experiments. Considering the GraHal setup as a benchmark, we insist on the correct signal-to-noise ratio expression taking into account the appropriate timescales. The associated maximum distance - of the order of a few hundreds of astronomical units - at which an event can be detected is calculated for optimal, sub-optimal, and general trajectories.","sentences":["In this brief note, we pursue the systematic investigation of possible gravitational wave sources in the gigahertz band.","We focus on hyperbolic encounters of light black holes and evaluate precisely the expected signal when accounting for the detailed characteristics of haloscope experiments.","Considering the GraHal setup as a benchmark, we insist on the correct signal-to-noise ratio expression taking into account the appropriate timescales.","The associated maximum distance - of the order of a few hundreds of astronomical units - at which an event can be detected is calculated for optimal, sub-optimal, and general trajectories."],"url":"http://arxiv.org/abs/2404.08379v1","category":"gr-qc"}
{"created":"2024-04-12 10:24:43","title":"Direct numerical simulations of microlayer formation during heterogeneous bubble nucleation","abstract":"In this article, we present direct numerical simulation results for the expansion of spherical cap bubbles attached to a rigid wall due to a sudden drop in the ambient pressure. The critical pressure drop beyond which the bubble growth becomes unstable is found to match well with the predictions from classical theory of heterogeneous nucleation imposing a quasi-static bubble evolution. When the pressure drop is significantly higher than the critical value, a liquid microlayer appears between the bubble and the wall. In this regime, the interface outside the microlayer grows at an asymptotic velocity that can be predicted from the Rayleigh--Plesset equation, while the contact line evolves with another asymptotic velocity that scales with a visco-capillary velocity that obeys the Cox--Voinov law. In general, three distinctive regions can be distinguished: the region very close to the contact line where dynamics is governed by visco-capillary effects, an intermediate region controlled by inertio-viscous effects away from the contact line yet inside the viscous boundary layer, and the region outside the boundary layer dominated by inertial effects. The microlayer forms in a regime where the capillary effects are confined in a region much smaller than the viscous boundary layer thickness. In this regime, the global capillary number takes values much larger then the critical capillary number for bubble nucleation, and the microlayer height is controlled by viscous effects and not surface tension.","sentences":["In this article, we present direct numerical simulation results for the expansion of spherical cap bubbles attached to a rigid wall due to a sudden drop in the ambient pressure.","The critical pressure drop beyond which the bubble growth becomes unstable is found to match well with the predictions from classical theory of heterogeneous nucleation imposing a quasi-static bubble evolution.","When the pressure drop is significantly higher than the critical value, a liquid microlayer appears between the bubble and the wall.","In this regime, the interface outside the microlayer grows at an asymptotic velocity that can be predicted from the Rayleigh--Plesset equation, while the contact line evolves with another asymptotic velocity that scales with a visco-capillary velocity that obeys the Cox--Voinov law.","In general, three distinctive regions can be distinguished: the region very close to the contact line where dynamics is governed by visco-capillary effects, an intermediate region controlled by inertio-viscous effects away from the contact line yet inside the viscous boundary layer, and the region outside the boundary layer dominated by inertial effects.","The microlayer forms in a regime where the capillary effects are confined in a region much smaller than the viscous boundary layer thickness.","In this regime, the global capillary number takes values much larger then the critical capillary number for bubble nucleation, and the microlayer height is controlled by viscous effects and not surface tension."],"url":"http://arxiv.org/abs/2404.08377v1","category":"physics.flu-dyn"}
{"created":"2024-04-12 10:24:43","title":"On-chip quantum interference between independent lithium niobate-on-insulator photon-pair sources","abstract":"Generating and interfering non-classical states of light is fundamental to optical quantum information science and technology. Quantum photonic integrated circuits provide one pathway towards scalability by combining nonlinear sources of non-classical light and programmable circuits in centimeter-scale devices. The key requirements for quantum applications include efficient generation of indistinguishable photon-pairs and high-visibility programmable quantum interference. Here, we demonstrate a lithium niobate-on-insulator (LNOI) integrated photonic circuit that generates a two-photon path-entangled state, and a programmable interferometer for quantum interference. We generate entangled photons with $\\sim2.3\\times10^8$ pairs/s/mW brightness and perform quantum interference experiments on the chip with $96.8\\pm3.6\\%$ visibility. LNOI is an emerging photonics technology that has revolutionized high-speed modulators and efficient frequency conversion. Our results provide a path towards large-scale integrated quantum photonics including efficient photon-pair generation and programmable circuits for applications such as boson sampling and quantum communications.","sentences":["Generating and interfering non-classical states of light is fundamental to optical quantum information science and technology.","Quantum photonic integrated circuits provide one pathway towards scalability by combining nonlinear sources of non-classical light and programmable circuits in centimeter-scale devices.","The key requirements for quantum applications include efficient generation of indistinguishable photon-pairs and high-visibility programmable quantum interference.","Here, we demonstrate a lithium niobate-on-insulator (LNOI) integrated photonic circuit that generates a two-photon path-entangled state, and a programmable interferometer for quantum interference.","We generate entangled photons with $\\sim2.3\\times10^8$ pairs/s/mW brightness and perform quantum interference experiments on the chip with $96.8\\pm3.6\\%$ visibility.","LNOI is an emerging photonics technology that has revolutionized high-speed modulators and efficient frequency conversion.","Our results provide a path towards large-scale integrated quantum photonics including efficient photon-pair generation and programmable circuits for applications such as boson sampling and quantum communications."],"url":"http://arxiv.org/abs/2404.08378v1","category":"quant-ph"}
{"created":"2024-04-12 10:22:55","title":"Graph data augmentation with Gromow-Wasserstein Barycenters","abstract":"Graphs are ubiquitous in various fields, and deep learning methods have been successful applied in graph classification tasks. However, building large and diverse graph datasets for training can be expensive. While augmentation techniques exist for structured data like images or numerical data, the augmentation of graph data remains challenging. This is primarily due to the complex and non-Euclidean nature of graph data. In this paper, it has been proposed a novel augmentation strategy for graphs that operates in a non-Euclidean space. This approach leverages graphon estimation, which models the generative mechanism of networks sequences. Computational results demonstrate the effectiveness of the proposed augmentation framework in improving the performance of graph classification models. Additionally, using a non-Euclidean distance, specifically the Gromow-Wasserstein distance, results in better approximations of the graphon. This framework also provides a means to validate different graphon estimation approaches, particularly in real-world scenarios where the true graphon is unknown.","sentences":["Graphs are ubiquitous in various fields, and deep learning methods have been successful applied in graph classification tasks.","However, building large and diverse graph datasets for training can be expensive.","While augmentation techniques exist for structured data like images or numerical data, the augmentation of graph data remains challenging.","This is primarily due to the complex and non-Euclidean nature of graph data.","In this paper, it has been proposed a novel augmentation strategy for graphs that operates in a non-Euclidean space.","This approach leverages graphon estimation, which models the generative mechanism of networks sequences.","Computational results demonstrate the effectiveness of the proposed augmentation framework in improving the performance of graph classification models.","Additionally, using a non-Euclidean distance, specifically the Gromow-Wasserstein distance, results in better approximations of the graphon.","This framework also provides a means to validate different graphon estimation approaches, particularly in real-world scenarios where the true graphon is unknown."],"url":"http://arxiv.org/abs/2404.08376v1","category":"cs.LG"}
{"created":"2024-04-12 10:20:29","title":"Detecting a Gravitational-Wave Background from Null Energy Condition Violation: Prospects for Taiji","abstract":"The null energy condition (NEC) is a fundamental principle in general relativity, and its violation could leave discernible signatures in gravitational waves (GWs). A violation of the NEC during the primordial era would imprint a blue-tilted spectrum on the stochastic gravitational wave background (SGWB) at nanohertz frequencies, potentially accounting for the recently detected signal by pulsar timing arrays. Remarkably, models of NEC violation during inflation also predict a nearly scale-invariant GW spectrum in the millihertz frequency range, which could be detectable by upcoming space-based GW detectors such as Taiji. The observation of this distinctive spectrum would provide compelling evidence for new physics beyond the standard cosmological paradigm. In this study, we explore Taiji's ability to detect an SGWB arising from NEC violation during inflation, considering various foregrounds and noise sources, including an extragalactic foreground from binary black hole mergers throughout the universe, a galactic foreground from white dwarf binaries, and the intrinsic noise of the Taiji detector. Employing comprehensive Bayesian parameter estimation techniques to analyze simulated Taiji data, we demonstrate a remarkable precision improvement of three orders of magnitude compared to the NANOGrav 15-year data set for measuring the tensor power spectrum amplitude, $P_{T,2}$, during the second inflationary stage. This substantial enhancement in measurement capabilities underscores Taiji's potential as a powerful probe for investigating the NEC violation in the early Universe.","sentences":["The null energy condition (NEC) is a fundamental principle in general relativity, and its violation could leave discernible signatures in gravitational waves (GWs).","A violation of the NEC during the primordial era would imprint a blue-tilted spectrum on the stochastic gravitational wave background (SGWB) at nanohertz frequencies, potentially accounting for the recently detected signal by pulsar timing arrays.","Remarkably, models of NEC violation during inflation also predict a nearly scale-invariant GW spectrum in the millihertz frequency range, which could be detectable by upcoming space-based GW detectors such as Taiji.","The observation of this distinctive spectrum would provide compelling evidence for new physics beyond the standard cosmological paradigm.","In this study, we explore Taiji's ability to detect an SGWB arising from NEC violation during inflation, considering various foregrounds and noise sources, including an extragalactic foreground from binary black hole mergers throughout the universe, a galactic foreground from white dwarf binaries, and the intrinsic noise of the Taiji detector.","Employing comprehensive Bayesian parameter estimation techniques to analyze simulated Taiji data, we demonstrate a remarkable precision improvement of three orders of magnitude compared to the NANOGrav 15-year data set for measuring the tensor power spectrum amplitude, $P_{T,2}$, during the second inflationary stage.","This substantial enhancement in measurement capabilities underscores Taiji's potential as a powerful probe for investigating the NEC violation in the early Universe."],"url":"http://arxiv.org/abs/2404.08375v1","category":"gr-qc"}
{"created":"2024-04-12 10:15:46","title":"Code Generation and Performance Engineering for Matrix-Free Finite Element Methods on Hybrid Tetrahedral Grids","abstract":"This paper introduces a code generator designed for node-level optimized, extreme-scalable, matrix-free finite element operators on hybrid tetrahedral grids. It optimizes the local evaluation of bilinear forms through various techniques including tabulation, relocation of loop invariants, and inter-element vectorization - implemented as transformations of an abstract syntax tree. A key contribution is the development, analysis, and generation of efficient loop patterns that leverage the local structure of the underlying tetrahedral grid. These significantly enhance cache locality and arithmetic intensity, mitigating bandwidth-pressure associated with compute-sparse, low-order operators. The paper demonstrates the generator's capabilities through a comprehensive educational cycle of performance analysis, bottleneck identification, and emission of dedicated optimizations. For three differential operators ($-\\Delta$, $-\\nabla \\cdot (k(\\mathbf{x})\\, \\nabla\\,)$, $\\alpha(\\mathbf{x})\\, \\mathbf{curl}\\ \\mathbf{curl} + \\beta(\\mathbf{x}) $), we determine the set of most effective optimizations. Applied by the generator, they result in speed-ups of up to 58$\\times$ compared to reference implementations. Detailed node-level performance analysis yields matrix-free operators with a throughput of 1.3 to 2.1 GDoF/s, achieving up to 62% peak performance on a 36-core Intel Ice Lake socket. Finally, the solution of the curl-curl problem with more than a trillion ($ 10^{12}$) degrees of freedom on 21504 processes in less than 50 seconds demonstrates the generated operators' performance and extreme-scalability as part of a full multigrid solver.","sentences":["This paper introduces a code generator designed for node-level optimized, extreme-scalable, matrix-free finite element operators on hybrid tetrahedral grids.","It optimizes the local evaluation of bilinear forms through various techniques including tabulation, relocation of loop invariants, and inter-element vectorization - implemented as transformations of an abstract syntax tree.","A key contribution is the development, analysis, and generation of efficient loop patterns that leverage the local structure of the underlying tetrahedral grid.","These significantly enhance cache locality and arithmetic intensity, mitigating bandwidth-pressure associated with compute-sparse, low-order operators.","The paper demonstrates the generator's capabilities through a comprehensive educational cycle of performance analysis, bottleneck identification, and emission of dedicated optimizations.","For three differential operators ($-\\Delta$, $-\\nabla \\cdot (k(\\mathbf{x})\\, \\nabla\\,)$, $\\alpha(\\mathbf{x})\\, \\mathbf{curl}\\ \\mathbf{curl} + \\beta(\\mathbf{x}) $), we determine the set of most effective optimizations.","Applied by the generator, they result in speed-ups of up to 58$\\times$ compared to reference implementations.","Detailed node-level performance analysis yields matrix-free operators with a throughput of 1.3 to 2.1 GDoF/s, achieving up to 62% peak performance on a 36-core Intel Ice Lake socket.","Finally, the solution of the curl-curl problem with more than a trillion ($ 10^{12}$) degrees of freedom on 21504 processes in less than 50 seconds demonstrates the generated operators' performance and extreme-scalability as part of a full multigrid solver."],"url":"http://arxiv.org/abs/2404.08371v1","category":"cs.CE"}
{"created":"2024-04-12 10:13:18","title":"Resolution Over Linear Equations: Combinatorial Games for Tree-like Size and Space","abstract":"We consider the proof system Res($\\oplus$) introduced by Itsykson and Sokolov (Ann. Pure Appl. Log.'20), which is an extension of the resolution proof system and operates with disjunctions of linear equations over $\\mathbb{F}_2$.   We study characterizations of tree-like size and space of Res($\\oplus$) refutations using combinatorial games. Namely, we introduce a class of extensible formulas and prove tree-like size lower bounds on it using Prover-Delayer games, as well as space lower bounds. This class is of particular interest since it contains many classical combinatorial principles, including the pigeonhole, ordering, and dense linear ordering principles.   Furthermore, we present the width-space relation for Res($\\oplus$) generalizing the results by Atserias and Dalmau (J. Comput. Syst. Sci.'08) and their variant of Spoiler-Duplicator games.","sentences":["We consider the proof system Res($\\oplus$) introduced by Itsykson and Sokolov (Ann.","Pure Appl.","Log.'20), which is an extension of the resolution proof system and operates with disjunctions of linear equations over $\\mathbb{F}_2$.   We study characterizations of tree-like size and space of Res($\\oplus$) refutations using combinatorial games.","Namely, we introduce a class of extensible formulas and prove tree-like size lower bounds on it using Prover-Delayer games, as well as space lower bounds.","This class is of particular interest since it contains many classical combinatorial principles, including the pigeonhole, ordering, and dense linear ordering principles.   ","Furthermore, we present the width-space relation for Res($\\oplus$) generalizing the results by Atserias and Dalmau (J. Comput.","Syst. Sci.'08) and their variant of Spoiler-Duplicator games."],"url":"http://arxiv.org/abs/2404.08370v1","category":"cs.CC"}
{"created":"2024-04-12 10:13:13","title":"Optic Fingerprint: Enhancing Security in Visible Light Communication Networks","abstract":"In addressing physical layer security issues, hardware fingerprinting has been proven to be a reliable method. Additionally, Visible Light Communication (VLC) technology offers a solution to the spectrum congestion in next-generation wireless communications and is noteworthy for its high security. However, there is currently a lack of a comprehensive and systematic description of the hardware fingerprints and their extraction mechanisms for VLC devices. This study aims to bridge this gap by thoroughly analyzing the hardware fingerprints of VLC devices and proposing an innovative extraction mechanism, thereby enhancing the security and reliability of the physical layer. An Optic Fingerprint (OF) model is proposed based on the LED's inherent circuit characteristics, capable of extracting and processing unique feature vectors with high precision. Through extensive experiments, we demonstrate the model's efficacy, achieving up to 99.3% accuracy in identifying the same manufactured white LEDs under variable conditions, marking a significant improvement in authentication robustness and interference resistance.","sentences":["In addressing physical layer security issues, hardware fingerprinting has been proven to be a reliable method.","Additionally, Visible Light Communication (VLC) technology offers a solution to the spectrum congestion in next-generation wireless communications and is noteworthy for its high security.","However, there is currently a lack of a comprehensive and systematic description of the hardware fingerprints and their extraction mechanisms for VLC devices.","This study aims to bridge this gap by thoroughly analyzing the hardware fingerprints of VLC devices and proposing an innovative extraction mechanism, thereby enhancing the security and reliability of the physical layer.","An Optic Fingerprint (OF) model is proposed based on the LED's inherent circuit characteristics, capable of extracting and processing unique feature vectors with high precision.","Through extensive experiments, we demonstrate the model's efficacy, achieving up to 99.3% accuracy in identifying the same manufactured white LEDs under variable conditions, marking a significant improvement in authentication robustness and interference resistance."],"url":"http://arxiv.org/abs/2404.08369v1","category":"eess.SP"}
{"created":"2024-04-12 10:12:24","title":"An Iterative Refinement Approach for the Rolling Stock Rotation Problem with Predictive Maintenance","abstract":"The rolling stock rotation problem with predictive maintenance (RSRP-PdM) involves the assignment of trips to a fleet of vehicles with integrated maintenance scheduling based on the predicted failure probability of the vehicles. These probabilities are determined by the health states of the vehicles, which are considered to be random variables distributed by a parameterized family of probability distribution functions. During the operation of the trips, the corresponding parameters get updated. In this article, we present a dual solution approach for RSRP-PdM and generalize a linear programming based lower bound for this problem to families of probability distribution functions with more than one parameter. For this purpose, we define a rounding function that allows for a consistent underestimation of the parameters and model the problem by a state-expanded event-graph in which the possible states are restricted to a discrete set. This induces a flow problem that is solved by an integer linear program. We show that the iterative refinement of the underlying discretization leads to solutions that converge from below to an optimal solution of the original instance. Thus, the linear relaxation of the considered integer linear program results in a lower bound for RSRP-PdM. Finally, we report on the results of computational experiments conducted on a library of test instances.","sentences":["The rolling stock rotation problem with predictive maintenance (RSRP-PdM) involves the assignment of trips to a fleet of vehicles with integrated maintenance scheduling based on the predicted failure probability of the vehicles.","These probabilities are determined by the health states of the vehicles, which are considered to be random variables distributed by a parameterized family of probability distribution functions.","During the operation of the trips, the corresponding parameters get updated.","In this article, we present a dual solution approach for RSRP-PdM and generalize a linear programming based lower bound for this problem to families of probability distribution functions with more than one parameter.","For this purpose, we define a rounding function that allows for a consistent underestimation of the parameters and model the problem by a state-expanded event-graph in which the possible states are restricted to a discrete set.","This induces a flow problem that is solved by an integer linear program.","We show that the iterative refinement of the underlying discretization leads to solutions that converge from below to an optimal solution of the original instance.","Thus, the linear relaxation of the considered integer linear program results in a lower bound for RSRP-PdM. Finally, we report on the results of computational experiments conducted on a library of test instances."],"url":"http://arxiv.org/abs/2404.08367v1","category":"math.OC"}
{"created":"2024-04-12 10:11:29","title":"Intelligent Reflecting Surface-Enabled Anti-Detection for Secure Sensing and Communications","abstract":"The ever-increasing reliance on wireless communication and sensing has led to growing concerns over the vulnerability of sensitive information to unauthorized detection and interception. Traditional anti-detection methods are often inadequate, suffering from limited adaptability and diminished effectiveness against advanced detection technologies. To overcome these challenges, this article presents the intelligent reflecting surface (IRS) as a groundbreaking technology for enabling flexible electromagnetic manipulation, which has the potential to revolutionize anti-detection in both electromagnetic stealth/spoofing (evading radar detection) and covert communications (facilitating secure information exchange). We explore the fundamental principles of IRS and its advantages over traditional anti-detection techniques and discuss various design challenges associated with implementing IRS-based anti-detection systems. Through the examination of case studies and future research directions, we provide a comprehensive overview of the potential of IRS technology to serve as a formidable shield in the modern wireless landscape.","sentences":["The ever-increasing reliance on wireless communication and sensing has led to growing concerns over the vulnerability of sensitive information to unauthorized detection and interception.","Traditional anti-detection methods are often inadequate, suffering from limited adaptability and diminished effectiveness against advanced detection technologies.","To overcome these challenges, this article presents the intelligent reflecting surface (IRS) as a groundbreaking technology for enabling flexible electromagnetic manipulation, which has the potential to revolutionize anti-detection in both electromagnetic stealth/spoofing (evading radar detection) and covert communications (facilitating secure information exchange).","We explore the fundamental principles of IRS and its advantages over traditional anti-detection techniques and discuss various design challenges associated with implementing IRS-based anti-detection systems.","Through the examination of case studies and future research directions, we provide a comprehensive overview of the potential of IRS technology to serve as a formidable shield in the modern wireless landscape."],"url":"http://arxiv.org/abs/2404.08366v1","category":"eess.SP"}
{"created":"2024-04-12 09:57:17","title":"Large-Scale Multi-Domain Recommendation: an Automatic Domain Feature Extraction and Personalized Integration Framework","abstract":"Feed recommendation is currently the mainstream mode for many real-world applications (e.g., TikTok, Dianping), it is usually necessary to model and predict user interests in multiple scenarios (domains) within and even outside the application. Multi-domain learning is a typical solution in this regard. While considerable efforts have been made in this regard, there are still two long-standing challenges: (1) Accurately depicting the differences among domains using domain features is crucial for enhancing the performance of each domain. However, manually designing domain features and models for numerous domains can be a laborious task. (2) Users typically have limited impressions in only a few domains. Extracting features automatically from other domains and leveraging them to improve the predictive capabilities of each domain has consistently posed a challenging problem. In this paper, we propose an Automatic Domain Feature Extraction and Personalized Integration (DFEI) framework for the large-scale multi-domain recommendation. The framework automatically transforms the behavior of each individual user into an aggregation of all user behaviors within the domain, which serves as the domain features. Unlike offline feature engineering methods, the extracted domain features are higher-order representations and directly related to the target label. Besides, by personalized integration of domain features from other domains for each user and the innovation in the training mode, the DFEI framework can yield more accurate conversion identification. Experimental results on both public and industrial datasets, consisting of over 20 domains, clearly demonstrate that the proposed framework achieves significantly better performance compared with SOTA baselines. Furthermore, we have released the source code of the proposed framework at https://github.com/xidongbo/DFEI.","sentences":["Feed recommendation is currently the mainstream mode for many real-world applications (e.g., TikTok, Dianping), it is usually necessary to model and predict user interests in multiple scenarios (domains) within and even outside the application.","Multi-domain learning is a typical solution in this regard.","While considerable efforts have been made in this regard, there are still two long-standing challenges: (1) Accurately depicting the differences among domains using domain features is crucial for enhancing the performance of each domain.","However, manually designing domain features and models for numerous domains can be a laborious task.","(2) Users typically have limited impressions in only a few domains.","Extracting features automatically from other domains and leveraging them to improve the predictive capabilities of each domain has consistently posed a challenging problem.","In this paper, we propose an Automatic Domain Feature Extraction and Personalized Integration (DFEI) framework for the large-scale multi-domain recommendation.","The framework automatically transforms the behavior of each individual user into an aggregation of all user behaviors within the domain, which serves as the domain features.","Unlike offline feature engineering methods, the extracted domain features are higher-order representations and directly related to the target label.","Besides, by personalized integration of domain features from other domains for each user and the innovation in the training mode, the DFEI framework can yield more accurate conversion identification.","Experimental results on both public and industrial datasets, consisting of over 20 domains, clearly demonstrate that the proposed framework achieves significantly better performance compared with SOTA baselines.","Furthermore, we have released the source code of the proposed framework at https://github.com/xidongbo/DFEI."],"url":"http://arxiv.org/abs/2404.08361v1","category":"cs.IR"}
{"created":"2024-04-12 09:56:37","title":"Maximal electric power generation from varying ocean waves with LC-tuned reactive PTO force","abstract":"The reactive Power Take Off (PTO) force is the key to maximizing mechanical power absorption and electric power generation of Wave Energy Converters (WECs) from ocean waves with variable frequency, but its study is limited due to its difficulty in physical realization. This paper presents a simple yet effective $LC$-tuned WEC that generates a tunable reactive PTO force from tunable inductor $L$ and capacitor $C$ in the WEC. A complete closed loop system model of the WEC is derived first, then three quantitative rules are obtained from analyzing the model. These rules are used to tune the $LC$ network, and hence the reactive PTO force that drives the WEC, to resonate with the input wave force and generate maximal electric power over a range of wave frequencies. Mathematical analysis of the WEC and tuning rules reveals the analytical and quantitative descriptions of the WEC's mechanical power absorption, active and reactive electric power generation and power factor, optimal electric resistance load, and the generator and $LC$ capacity requirements. Simulation results show the effectiveness and advantages of the proposed WEC and verify the analysis results.","sentences":["The reactive Power Take Off (PTO) force is the key to maximizing mechanical power absorption and electric power generation of Wave Energy Converters (WECs) from ocean waves with variable frequency, but its study is limited due to its difficulty in physical realization.","This paper presents a simple yet effective $LC$-tuned WEC that generates a tunable reactive PTO force from tunable inductor $L$ and capacitor $C$ in the WEC.","A complete closed loop system model of the WEC is derived first, then three quantitative rules are obtained from analyzing the model.","These rules are used to tune the $LC$ network, and hence the reactive PTO force that drives the WEC, to resonate with the input wave force and generate maximal electric power over a range of wave frequencies.","Mathematical analysis of the WEC and tuning rules reveals the analytical and quantitative descriptions of the WEC's mechanical power absorption, active and reactive electric power generation and power factor, optimal electric resistance load, and the generator and $LC$ capacity requirements.","Simulation results show the effectiveness and advantages of the proposed WEC and verify the analysis results."],"url":"http://arxiv.org/abs/2404.08360v1","category":"eess.SY"}
{"created":"2024-04-12 09:56:12","title":"Improving Health Question Answering with Reliable and Time-Aware Evidence Retrieval","abstract":"In today's digital world, seeking answers to health questions on the Internet is a common practice. However, existing question answering (QA) systems often rely on using pre-selected and annotated evidence documents, thus making them inadequate for addressing novel questions. Our study focuses on the open-domain QA setting, where the key challenge is to first uncover relevant evidence in large knowledge bases. By utilizing the common retrieve-then-read QA pipeline and PubMed as a trustworthy collection of medical research documents, we answer health questions from three diverse datasets. We modify different retrieval settings to observe their influence on the QA pipeline's performance, including the number of retrieved documents, sentence selection process, the publication year of articles, and their number of citations. Our results reveal that cutting down on the amount of retrieved documents and favoring more recent and highly cited documents can improve the final macro F1 score up to 10%. We discuss the results, highlight interesting examples, and outline challenges for future research, like managing evidence disagreement and crafting user-friendly explanations.","sentences":["In today's digital world, seeking answers to health questions on the Internet is a common practice.","However, existing question answering (QA) systems often rely on using pre-selected and annotated evidence documents, thus making them inadequate for addressing novel questions.","Our study focuses on the open-domain QA setting, where the key challenge is to first uncover relevant evidence in large knowledge bases.","By utilizing the common retrieve-then-read QA pipeline and PubMed as a trustworthy collection of medical research documents, we answer health questions from three diverse datasets.","We modify different retrieval settings to observe their influence on the QA pipeline's performance, including the number of retrieved documents, sentence selection process, the publication year of articles, and their number of citations.","Our results reveal that cutting down on the amount of retrieved documents and favoring more recent and highly cited documents can improve the final macro F1 score up to 10%.","We discuss the results, highlight interesting examples, and outline challenges for future research, like managing evidence disagreement and crafting user-friendly explanations."],"url":"http://arxiv.org/abs/2404.08359v1","category":"cs.CL"}
{"created":"2024-04-12 09:49:44","title":"Variational Solvers for Irreversible Evolutionary Systems","abstract":"We study irreversible evolutionary processes with a general energetic notion of stability. We dedicate this contribution to releasing three nonlinear variational solvers as modular components (based on FEniCSx/dolfinx) that address three mathematical optimisation problems. They are general enough to apply, in principle, to evolutionary systems with instabilities, jumps, and emergence of patterns which is commonplace in diverse arenas spanning from quantum to continuum mechanics, economy, social sciences, and ecology. Our motivation proceeds from fracture mechanics, with the ultimate goal of deploying a transparent numerical platform for scientific validation and prediction of large scale natural fracture phenomena. Our solvers are used to compute one solution to a problem encoded in a system of two inequalities: one (pointwise almost-everywhere) constraint of irreversibility and one global energy statement. As part of our commitment to open science, our solvers are released as free software.","sentences":["We study irreversible evolutionary processes with a general energetic notion of stability.","We dedicate this contribution to releasing three nonlinear variational solvers as modular components (based on FEniCSx/dolfinx) that address three mathematical optimisation problems.","They are general enough to apply, in principle, to evolutionary systems with instabilities, jumps, and emergence of patterns which is commonplace in diverse arenas spanning from quantum to continuum mechanics, economy, social sciences, and ecology.","Our motivation proceeds from fracture mechanics, with the ultimate goal of deploying a transparent numerical platform for scientific validation and prediction of large scale natural fracture phenomena.","Our solvers are used to compute one solution to a problem encoded in a system of two inequalities: one (pointwise almost-everywhere) constraint of irreversibility and one global energy statement.","As part of our commitment to open science, our solvers are released as free software."],"url":"http://arxiv.org/abs/2404.08356v1","category":"math.AP"}
{"created":"2024-04-12 09:48:58","title":"Gaining More Insight into Neural Semantic Parsing with Challenging Benchmarks","abstract":"The Parallel Meaning Bank (PMB) serves as a corpus for semantic processing with a focus on semantic parsing and text generation. Currently, we witness an excellent performance of neural parsers and generators on the PMB. This might suggest that such semantic processing tasks have by and large been solved. We argue that this is not the case and that performance scores from the past on the PMB are inflated by non-optimal data splits and test sets that are too easy. In response, we introduce several changes. First, instead of the prior random split, we propose a more systematic splitting approach to improve the reliability of the standard test data. Second, except for the standard test set, we also propose two challenge sets: one with longer texts including discourse structure, and one that addresses compositional generalization. We evaluate five neural models for semantic parsing and meaning-to-text generation. Our results show that model performance declines (in some cases dramatically) on the challenge sets, revealing the limitations of neural models when confronting such challenges.","sentences":["The Parallel Meaning Bank (PMB) serves as a corpus for semantic processing with a focus on semantic parsing and text generation.","Currently, we witness an excellent performance of neural parsers and generators on the PMB.","This might suggest that such semantic processing tasks have by and large been solved.","We argue that this is not the case and that performance scores from the past on the PMB are inflated by non-optimal data splits and test sets that are too easy.","In response, we introduce several changes.","First, instead of the prior random split, we propose a more systematic splitting approach to improve the reliability of the standard test data.","Second, except for the standard test set, we also propose two challenge sets: one with longer texts including discourse structure, and one that addresses compositional generalization.","We evaluate five neural models for semantic parsing and meaning-to-text generation.","Our results show that model performance declines (in some cases dramatically) on the challenge sets, revealing the limitations of neural models when confronting such challenges."],"url":"http://arxiv.org/abs/2404.08354v1","category":"cs.CL"}
{"created":"2024-04-12 09:44:18","title":"TDANet: Target-Directed Attention Network For Object-Goal Visual Navigation With Zero-Shot Ability","abstract":"The generalization of the end-to-end deep reinforcement learning (DRL) for object-goal visual navigation is a long-standing challenge since object classes and placements vary in new test environments. Learning domain-independent visual representation is critical for enabling the trained DRL agent with the ability to generalize to unseen scenes and objects. In this letter, a target-directed attention network (TDANet) is proposed to learn the end-to-end object-goal visual navigation policy with zero-shot ability. TDANet features a novel target attention (TA) module that learns both the spatial and semantic relationships among objects to help TDANet focus on the most relevant observed objects to the target. With the Siamese architecture (SA) design, TDANet distinguishes the difference between the current and target states and generates the domain-independent visual representation. To evaluate the navigation performance of TDANet, extensive experiments are conducted in the AI2-THOR embodied AI environment. The simulation results demonstrate a strong generalization ability of TDANet to unseen scenes and target objects, with higher navigation success rate (SR) and success weighted by length (SPL) than other state-of-the-art models.","sentences":["The generalization of the end-to-end deep reinforcement learning (DRL) for object-goal visual navigation is a long-standing challenge since object classes and placements vary in new test environments.","Learning domain-independent visual representation is critical for enabling the trained DRL agent with the ability to generalize to unseen scenes and objects.","In this letter, a target-directed attention network (TDANet) is proposed to learn the end-to-end object-goal visual navigation policy with zero-shot ability.","TDANet features a novel target attention (TA) module that learns both the spatial and semantic relationships among objects to help TDANet focus on the most relevant observed objects to the target.","With the Siamese architecture (SA) design, TDANet distinguishes the difference between the current and target states and generates the domain-independent visual representation.","To evaluate the navigation performance of TDANet, extensive experiments are conducted in the AI2-THOR embodied AI environment.","The simulation results demonstrate a strong generalization ability of TDANet to unseen scenes and target objects, with higher navigation success rate (SR) and success weighted by length (SPL) than other state-of-the-art models."],"url":"http://arxiv.org/abs/2404.08353v1","category":"cs.CV"}
{"created":"2024-04-12 09:21:52","title":"New instanton on a warped Kerr spacetime","abstract":"We find an exact time-dependent instanton solution on a vacuum Kerr-like warped spacetime in conformal dilaton gravity. Remarkably, the metric solution results from a first-order PDE, allowing the connection with self-duality. The antipodal boundary condition on the hypersurface of a Klein bottle $\\sim \\mathbb{C}^1\\times\\mathbb{C}^1$ is applied to describe the Hawking particles. We used the Hopf fibration to get $S^2$ as the black hole horizon, where the centrix is not in a torus but in the Klein bottle. The twist fits very well with the antipodal identification of the point on the horizon. No \"cut and past\" is necessary, so the Hawing particles remain pure without instantaneous information transport. A local observer passing the horizon will not notice a central singularity in suitable coordinates. The black hole paradoxes are also revisited in our new black hole model. A connection is made with the geomeric quantization of $\\mathbb{C}^1\\times\\mathbb{C}^1\\sim S^3$, by considering the symplectic 2-form. The model can be easily extended to the non-vacuum situation by including a scalar field. Both the dilaton and the scalar field can be treated as quantum fields when approaching the Planck area.","sentences":["We find an exact time-dependent instanton solution on a vacuum Kerr-like warped spacetime in conformal dilaton gravity.","Remarkably, the metric solution results from a first-order PDE, allowing the connection with self-duality.","The antipodal boundary condition on the hypersurface of a Klein bottle $\\sim \\mathbb{C}^1\\times\\mathbb{C}^1$ is applied to describe the Hawking particles.","We used the Hopf fibration to get $S^2$ as the black hole horizon, where the centrix is not in a torus but in the Klein bottle.","The twist fits very well with the antipodal identification of the point on the horizon.","No \"cut and past\" is necessary, so the Hawing particles remain pure without instantaneous information transport.","A local observer passing the horizon will not notice a central singularity in suitable coordinates.","The black hole paradoxes are also revisited in our new black hole model.","A connection is made with the geomeric quantization of $\\mathbb{C}^1\\times\\mathbb{C}^1\\sim S^3$, by considering the symplectic 2-form.","The model can be easily extended to the non-vacuum situation by including a scalar field.","Both the dilaton and the scalar field can be treated as quantum fields when approaching the Planck area."],"url":"http://arxiv.org/abs/2404.08346v1","category":"hep-th"}
{"created":"2024-04-12 09:13:37","title":"Counterfactual Explanations for Face Forgery Detection via Adversarial Removal of Artifacts","abstract":"Highly realistic AI generated face forgeries known as deepfakes have raised serious social concerns. Although DNN-based face forgery detection models have achieved good performance, they are vulnerable to latest generative methods that have less forgery traces and adversarial attacks. This limitation of generalization and robustness hinders the credibility of detection results and requires more explanations. In this work, we provide counterfactual explanations for face forgery detection from an artifact removal perspective. Specifically, we first invert the forgery images into the StyleGAN latent space, and then adversarially optimize their latent representations with the discrimination supervision from the target detection model. We verify the effectiveness of the proposed explanations from two aspects: (1) Counterfactual Trace Visualization: the enhanced forgery images are useful to reveal artifacts by visually contrasting the original images and two different visualization methods; (2) Transferable Adversarial Attacks: the adversarial forgery images generated by attacking the detection model are able to mislead other detection models, implying the removed artifacts are general. Extensive experiments demonstrate that our method achieves over 90% attack success rate and superior attack transferability. Compared with naive adversarial noise methods, our method adopts both generative and discriminative model priors, and optimize the latent representations in a synthesis-by-analysis way, which forces the search of counterfactual explanations on the natural face manifold. Thus, more general counterfactual traces can be found and better adversarial attack transferability can be achieved.","sentences":["Highly realistic AI generated face forgeries known as deepfakes have raised serious social concerns.","Although DNN-based face forgery detection models have achieved good performance, they are vulnerable to latest generative methods that have less forgery traces and adversarial attacks.","This limitation of generalization and robustness hinders the credibility of detection results and requires more explanations.","In this work, we provide counterfactual explanations for face forgery detection from an artifact removal perspective.","Specifically, we first invert the forgery images into the StyleGAN latent space, and then adversarially optimize their latent representations with the discrimination supervision from the target detection model.","We verify the effectiveness of the proposed explanations from two aspects: (1) Counterfactual Trace Visualization: the enhanced forgery images are useful to reveal artifacts by visually contrasting the original images and two different visualization methods; (2) Transferable Adversarial Attacks: the adversarial forgery images generated by attacking the detection model are able to mislead other detection models, implying the removed artifacts are general.","Extensive experiments demonstrate that our method achieves over 90% attack success rate and superior attack transferability.","Compared with naive adversarial noise methods, our method adopts both generative and discriminative model priors, and optimize the latent representations in a synthesis-by-analysis way, which forces the search of counterfactual explanations on the natural face manifold.","Thus, more general counterfactual traces can be found and better adversarial attack transferability can be achieved."],"url":"http://arxiv.org/abs/2404.08341v1","category":"cs.CV"}
{"created":"2024-04-12 09:05:10","title":"Photoacoustic effect from an oscillating source in a one-dimensional resonator","abstract":"Although the photoacoustic effect is most commonly generated by pulsed or amplitude modulated continuous optical sources, it is possible to generate acoustic waves by moving a constant amplitude, continuous light beam. If the light beam moves at the speed of sound, an amplification effect takes place which can be used in trace gas detection. Here, the properties of the photoacoustic effect are investigated for a continuous optical beam moving in a one-dimensional resonator. The solution shows the additive effects of sweeping the optical beam the length of the cell and back.","sentences":["Although the photoacoustic effect is most commonly generated by pulsed or amplitude modulated continuous optical sources, it is possible to generate acoustic waves by moving a constant amplitude, continuous light beam.","If the light beam moves at the speed of sound, an amplification effect takes place which can be used in trace gas detection.","Here, the properties of the photoacoustic effect are investigated for a continuous optical beam moving in a one-dimensional resonator.","The solution shows the additive effects of sweeping the optical beam the length of the cell and back."],"url":"http://arxiv.org/abs/2404.08339v1","category":"physics.app-ph"}
{"created":"2024-04-12 09:01:14","title":"Toward a Theory of Tokenization in LLMs","abstract":"While there has been a large body of research attempting to circumvent tokenization for language modeling (Clark et al., 2022; Xue et al., 2022), the current consensus is that it is a necessary initial step for designing state-of-the-art performant language models. In this paper, we investigate tokenization from a theoretical point of view by studying the behavior of transformers on simple data generating processes. When trained on data drawn from certain simple $k^{\\text{th}}$-order Markov processes for $k > 1$, transformers exhibit a surprising phenomenon - in the absence of tokenization, they empirically fail to learn the right distribution and predict characters according to a unigram model (Makkuva et al., 2024). With the addition of tokenization, however, we empirically observe that transformers break through this barrier and are able to model the probabilities of sequences drawn from the source near-optimally, achieving small cross-entropy loss. With this observation as starting point, we study the end-to-end cross-entropy loss achieved by transformers with and without tokenization. With the appropriate tokenization, we show that even the simplest unigram models (over tokens) learnt by transformers are able to model the probability of sequences drawn from $k^{\\text{th}}$-order Markov sources near optimally. Our analysis provides a justification for the use of tokenization in practice through studying the behavior of transformers on Markovian data.","sentences":["While there has been a large body of research attempting to circumvent tokenization for language modeling (Clark et al., 2022; Xue et al., 2022), the current consensus is that it is a necessary initial step for designing state-of-the-art performant language models.","In this paper, we investigate tokenization from a theoretical point of view by studying the behavior of transformers on simple data generating processes.","When trained on data drawn from certain simple $k^{\\text{th}}$-order Markov processes for $k > 1$, transformers exhibit a surprising phenomenon - in the absence of tokenization, they empirically fail to learn the right distribution and predict characters according to a unigram model (Makkuva et al., 2024).","With the addition of tokenization, however, we empirically observe that transformers break through this barrier and are able to model the probabilities of sequences drawn from the source near-optimally, achieving small cross-entropy loss.","With this observation as starting point, we study the end-to-end cross-entropy loss achieved by transformers with and without tokenization.","With the appropriate tokenization, we show that even the simplest unigram models (over tokens) learnt by transformers are able to model the probability of sequences drawn from $k^{\\text{th}}$-order Markov sources near optimally.","Our analysis provides a justification for the use of tokenization in practice through studying the behavior of transformers on Markovian data."],"url":"http://arxiv.org/abs/2404.08335v1","category":"cs.CL"}
{"created":"2024-04-12 08:52:15","title":"OTFS Channel Estimation and Detection for Channels with Very Large Delay Spread","abstract":"In low latency applications and in general, for overspread channels, channel delay spread is a large percentage of the transmission frame duration. In this paper, we consider OTFS in an overspread channel exhibiting a delay spread that exceeds the block duration in a frame, where traditional channel estimation (CE) fails. We propose a two-stage CE method based on a delay-Doppler (DD) training frame, consisting of a dual chirp converted from time domain and a higher power pilot. The first stage employs a DD domain embedded pilot CE to estimate the aliased delays (due to modulo operation) and Doppler shifts, followed by identifying all the underspread paths not coinciding with any overspread path. The second stage utilizes time domain dual chirp correlation to estimate the actual delays and Doppler shifts of the remaining paths. This stage also resolves ambiguity in estimating delays and Doppler shifts for paths sharing same aliased delay. Furthermore, we present a modified low-complexity maximum ratio combining (MRC) detection algorithm for OTFS in overspread channels. Finally, we evaluate performance of OTFS using the proposed CE and the modified MRC detection in terms of normalized mean square error (NMSE) and bit error rate (BER).","sentences":["In low latency applications and in general, for overspread channels, channel delay spread is a large percentage of the transmission frame duration.","In this paper, we consider OTFS in an overspread channel exhibiting a delay spread that exceeds the block duration in a frame, where traditional channel estimation (CE) fails.","We propose a two-stage CE method based on a delay-Doppler (DD) training frame, consisting of a dual chirp converted from time domain and a higher power pilot.","The first stage employs a DD domain embedded pilot CE to estimate the aliased delays (due to modulo operation) and Doppler shifts, followed by identifying all the underspread paths not coinciding with any overspread path.","The second stage utilizes time domain dual chirp correlation to estimate the actual delays and Doppler shifts of the remaining paths.","This stage also resolves ambiguity in estimating delays and Doppler shifts for paths sharing same aliased delay.","Furthermore, we present a modified low-complexity maximum ratio combining (MRC) detection algorithm for OTFS in overspread channels.","Finally, we evaluate performance of OTFS using the proposed CE and the modified MRC detection in terms of normalized mean square error (NMSE) and bit error rate (BER)."],"url":"http://arxiv.org/abs/2404.08333v1","category":"cs.IT"}
{"created":"2024-04-12 08:47:52","title":"A Balanced Statistical Boosting Approach for GAMLSS via New Step Lengths","abstract":"Component-wise gradient boosting algorithms are popular for their intrinsic variable selection and implicit regularization, which can be especially beneficial for very flexible model classes. When estimating generalized additive models for location, scale and shape (GAMLSS) by means of a component-wise gradient boosting algorithm, an important part of the estimation procedure is to determine the relative complexity of the submodels corresponding to the different distribution parameters. Existing methods either suffer from a computationally expensive tuning procedure or can be biased by structural differences in the negative gradients' sizes, which, if encountered, lead to imbalances between the different submodels. Shrunk optimal step lengths have been suggested to replace the typical small fixed step lengths for a non-cyclical boosting algorithm limited to a Gaussian response variable in order to address this issue. In this article, we propose a new adaptive step length approach that accounts for the relative size of the fitted base-learners to ensure a natural balance between the different submodels. The new balanced boosting approach thus represents a computationally efficient and easily generalizable alternative to shrunk optimal step lengths. We implemented the balanced non-cyclical boosting algorithm for a Gaussian, a negative binomial as well as a Weibull distributed response variable and demonstrate the competitive performance of the new adaptive step length approach by means of a simulation study, in the analysis of count data modeling the number of doctor's visits as well as for survival data in an oncological trial.","sentences":["Component-wise gradient boosting algorithms are popular for their intrinsic variable selection and implicit regularization, which can be especially beneficial for very flexible model classes.","When estimating generalized additive models for location, scale and shape (GAMLSS) by means of a component-wise gradient boosting algorithm, an important part of the estimation procedure is to determine the relative complexity of the submodels corresponding to the different distribution parameters.","Existing methods either suffer from a computationally expensive tuning procedure or can be biased by structural differences in the negative gradients' sizes, which, if encountered, lead to imbalances between the different submodels.","Shrunk optimal step lengths have been suggested to replace the typical small fixed step lengths for a non-cyclical boosting algorithm limited to a Gaussian response variable in order to address this issue.","In this article, we propose a new adaptive step length approach that accounts for the relative size of the fitted base-learners to ensure a natural balance between the different submodels.","The new balanced boosting approach thus represents a computationally efficient and easily generalizable alternative to shrunk optimal step lengths.","We implemented the balanced non-cyclical boosting algorithm for a Gaussian, a negative binomial as well as a Weibull distributed response variable and demonstrate the competitive performance of the new adaptive step length approach by means of a simulation study, in the analysis of count data modeling the number of doctor's visits as well as for survival data in an oncological trial."],"url":"http://arxiv.org/abs/2404.08331v1","category":"stat.ME"}
{"created":"2024-04-12 08:44:21","title":"Realization of two-qubit gates and multi-body entanglement states in an asymmetric superconducting circuits","abstract":"In recent years, the tunable coupling scheme has become the mainstream scheme for designing superconducting quan tum circuits. By working in the dispersive regime, the ZZ coupling and high-energy level leakage can be effectively suppressed and realize a high fidelity quantum gate. We propose a tunable fluxonium-transmon-transmon (FTT) cou pling scheme. In our system, the coupler is a frequency tunable transmon qubit. Both qubits and coupler are capacitively coupled. The asymmetric structure composed of fluxonium and transmon will optimize the frequency space and form a high fidelity two-qubit quantum gate. By decoupling, the effective coupling strength can be easily adjusted to close to the net coupling between qubits. We numerical simulation the master equation to reduce the quantum noise to zero. We study the performance of this scheme by simulating the general single-qubit X{\\pi}/2 gate and two-qubit (iSWAP) gate. In the bias point of the qubits, we achieve a single qubit gate with 99.99% fidelity and a two-qubit gate with 99.95% fidelity. By adjusting the nonlinear Kerr coefficient of fluxonium to an appropriate value, we can achieve a multi-body entanglement state. We consider the correlation between the two qubits and the coupler, and the magnetic flux passing through one qubit has an effect on the other qubit and the coupler. Finally, we analyze the quantum correlation of the two-body entanglement state.","sentences":["In recent years, the tunable coupling scheme has become the mainstream scheme for designing superconducting quan tum circuits.","By working in the dispersive regime, the ZZ coupling and high-energy level leakage can be effectively suppressed and realize a high fidelity quantum gate.","We propose a tunable fluxonium-transmon-transmon (FTT) cou pling scheme.","In our system, the coupler is a frequency tunable transmon qubit.","Both qubits and coupler are capacitively coupled.","The asymmetric structure composed of fluxonium and transmon will optimize the frequency space and form a high fidelity two-qubit quantum gate.","By decoupling, the effective coupling strength can be easily adjusted to close to the net coupling between qubits.","We numerical simulation the master equation to reduce the quantum noise to zero.","We study the performance of this scheme by simulating the general single-qubit X{\\pi}/2 gate and two-qubit (iSWAP) gate.","In the bias point of the qubits, we achieve a single qubit gate with 99.99% fidelity and a two-qubit gate with 99.95% fidelity.","By adjusting the nonlinear Kerr coefficient of fluxonium to an appropriate value, we can achieve a multi-body entanglement state.","We consider the correlation between the two qubits and the coupler, and the magnetic flux passing through one qubit has an effect on the other qubit and the coupler.","Finally, we analyze the quantum correlation of the two-body entanglement state."],"url":"http://arxiv.org/abs/2404.08328v1","category":"quant-ph"}
{"created":"2024-04-12 08:30:39","title":"Optimal Domain of generalized Volterra operators","abstract":"For g in BMOA, we consider the generalized Volterra operator T_g acting on Hardy spaces H^p. This article aims to study the largest space of analytic functions, which is mapped by T_g into the Hardy space H^p. We call this space the optimal domain of T_g and we describe its structural properties. Motivation for this comes from the work of G. Curbera and W. Ricker who studied the optimal domain of the classical Ces\\'aro operator.","sentences":["For g in BMOA, we consider the generalized Volterra operator T_g acting on Hardy spaces H^p.","This article aims to study the largest space of analytic functions, which is mapped by T_g into the Hardy space H^p.","We call this space the optimal domain of T_g and we describe its structural properties.","Motivation for this comes from the work of G. Curbera and W. Ricker who studied the optimal domain of the classical Ces\\'aro operator."],"url":"http://arxiv.org/abs/2404.08323v1","category":"math.CV"}
{"created":"2024-04-12 08:28:52","title":"BOND: Bootstrapping From-Scratch Name Disambiguation with Multi-task Promoting","abstract":"From-scratch name disambiguation is an essential task for establishing a reliable foundation for academic platforms. It involves partitioning documents authored by identically named individuals into groups representing distinct real-life experts. Canonically, the process is divided into two decoupled tasks: locally estimating the pairwise similarities between documents followed by globally grouping these documents into appropriate clusters. However, such a decoupled approach often inhibits optimal information exchange between these intertwined tasks. Therefore, we present BOND, which bootstraps the local and global informative signals to promote each other in an end-to-end regime. Specifically, BOND harnesses local pairwise similarities to drive global clustering, subsequently generating pseudo-clustering labels. These global signals further refine local pairwise characterizations. The experimental results establish BOND's superiority, outperforming other advanced baselines by a substantial margin. Moreover, an enhanced version, BOND+, incorporating ensemble and post-match techniques, rivals the top methods in the WhoIsWho competition.","sentences":["From-scratch name disambiguation is an essential task for establishing a reliable foundation for academic platforms.","It involves partitioning documents authored by identically named individuals into groups representing distinct real-life experts.","Canonically, the process is divided into two decoupled tasks: locally estimating the pairwise similarities between documents followed by globally grouping these documents into appropriate clusters.","However, such a decoupled approach often inhibits optimal information exchange between these intertwined tasks.","Therefore, we present BOND, which bootstraps the local and global informative signals to promote each other in an end-to-end regime.","Specifically, BOND harnesses local pairwise similarities to drive global clustering, subsequently generating pseudo-clustering labels.","These global signals further refine local pairwise characterizations.","The experimental results establish BOND's superiority, outperforming other advanced baselines by a substantial margin.","Moreover, an enhanced version, BOND+, incorporating ensemble and post-match techniques, rivals the top methods in the WhoIsWho competition."],"url":"http://arxiv.org/abs/2404.08322v1","category":"cs.SI"}
{"created":"2024-04-12 08:25:13","title":"A general functional version of Gr\u00fcnbaum's inequality","abstract":"A classical inequality by Gr\\\"unbaum provides a sharp lower bound for the ratio $\\mathrm{vol}(K^{-})/\\mathrm{vol}(K)$, where $K^{-}$ denotes the intersection of a convex body with non-empty interior $K\\subset\\mathbb{R}^n$ with a halfspace bounded by a hyperplane $H$ passing through the centroid $\\mathrm{g}(K)$ of $K$.   In this paper we extend this result to the case in which the hyperplane $H$ passes by any of the points lying in a whole uniparametric family of $r$-powered centroids associated to $K$ (depending on a real parameter $r\\geq0$), by proving a more general functional result on concave functions.   The latter result further connects (and allows one to recover) various inequalities involving the centroid, such as a classical inequality (due to Minkowski and Radon) that relates the distance of $\\mathrm{g}(K)$ to a supporting hyperplane of $K$, or a result for volume sections of convex bodies proven independently by Makai Jr. & Martini and Fradelizi.","sentences":["A classical inequality by Gr\\\"unbaum provides a sharp lower bound for the ratio $\\mathrm{vol}(K^{-})/\\mathrm{vol}(K)$, where $K^{-}$ denotes the intersection of a convex body with non-empty interior $K\\subset\\mathbb{R}^n$ with a halfspace bounded by a hyperplane $H$ passing through the centroid $\\mathrm{g}(K)$ of $K$.   In this paper we extend this result to the case in which the hyperplane $H$ passes by any of the points lying in a whole uniparametric family of $r$-powered centroids associated to $K$ (depending on a real parameter $r\\geq0$), by proving a more general functional result on concave functions.   ","The latter result further connects (and allows one to recover) various inequalities involving the centroid, such as a classical inequality (due to Minkowski and Radon) that relates the distance of $\\mathrm{g}(K)$ to a supporting hyperplane of $K$, or a result for volume sections of convex bodies proven independently by Makai Jr. & Martini and Fradelizi."],"url":"http://arxiv.org/abs/2404.08319v1","category":"math.MG"}
{"created":"2024-04-12 08:22:58","title":"Non-Gaussianity from primordial black holes","abstract":"We study the effects of non-Gaussianity from primordial black holes (PBHs). The formation of PBHs is in general a rare event and the number of PBHs fluctuates following the Poisson distribution function, which is independent from the pre-existing inflationary adiabatic fluctuations. Such fluctuations can dominate over the adiabatic mode on small scales. We focus on the non-Gaussianity of matter density fluctuations induced by the Poisson fluctuation of PBHs and discuss the potentially observable consequences such as the skewness, kurtosis and the scale-dependent bias.","sentences":["We study the effects of non-Gaussianity from primordial black holes (PBHs).","The formation of PBHs is in general a rare event and the number of PBHs fluctuates following the Poisson distribution function, which is independent from the pre-existing inflationary adiabatic fluctuations.","Such fluctuations can dominate over the adiabatic mode on small scales.","We focus on the non-Gaussianity of matter density fluctuations induced by the Poisson fluctuation of PBHs and discuss the potentially observable consequences such as the skewness, kurtosis and the scale-dependent bias."],"url":"http://arxiv.org/abs/2404.08318v1","category":"astro-ph.CO"}
{"created":"2024-04-12 08:17:44","title":"The Integration of Semantic and Structural Knowledge in Knowledge Graph Entity Typing","abstract":"The Knowledge Graph Entity Typing (KGET) task aims to predict missing type annotations for entities in knowledge graphs. Recent works only utilize the \\textit{\\textbf{structural knowledge}} in the local neighborhood of entities, disregarding \\textit{\\textbf{semantic knowledge}} in the textual representations of entities, relations, and types that are also crucial for type inference. Additionally, we observe that the interaction between semantic and structural knowledge can be utilized to address the false-negative problem. In this paper, we propose a novel \\textbf{\\underline{S}}emantic and \\textbf{\\underline{S}}tructure-aware KG \\textbf{\\underline{E}}ntity \\textbf{\\underline{T}}yping~{(SSET)} framework, which is composed of three modules. First, the \\textit{Semantic Knowledge Encoding} module encodes factual knowledge in the KG with a Masked Entity Typing task. Then, the \\textit{Structural Knowledge Aggregation} module aggregates knowledge from the multi-hop neighborhood of entities to infer missing types. Finally, the \\textit{Unsupervised Type Re-ranking} module utilizes the inference results from the two models above to generate type predictions that are robust to false-negative samples. Extensive experiments show that SSET significantly outperforms existing state-of-the-art methods.","sentences":["The Knowledge Graph Entity Typing (KGET) task aims to predict missing type annotations for entities in knowledge graphs.","Recent works only utilize the \\textit{\\textbf{structural knowledge}} in the local neighborhood of entities, disregarding \\textit{\\textbf{semantic knowledge}} in the textual representations of entities, relations, and types that are also crucial for type inference.","Additionally, we observe that the interaction between semantic and structural knowledge can be utilized to address the false-negative problem.","In this paper, we propose a novel \\textbf{\\underline{S}}emantic and \\textbf{\\underline{S}}tructure-aware KG \\textbf{\\underline{E}}ntity \\textbf{\\underline{T}}yping~{(SSET)} framework, which is composed of three modules.","First, the \\textit{Semantic Knowledge Encoding} module encodes factual knowledge in the KG with a Masked Entity Typing task.","Then, the \\textit{Structural Knowledge Aggregation} module aggregates knowledge from the multi-hop neighborhood of entities to infer missing types.","Finally, the \\textit{Unsupervised Type Re-ranking} module utilizes the inference results from the two models above to generate type predictions that are robust to false-negative samples.","Extensive experiments show that SSET significantly outperforms existing state-of-the-art methods."],"url":"http://arxiv.org/abs/2404.08313v1","category":"cs.CL"}
{"created":"2024-04-12 08:14:17","title":"GPN: Generative Point-based NeRF","abstract":"Scanning real-life scenes with modern registration devices typically gives incomplete point cloud representations, primarily due to the limitations of partial scanning, 3D occlusions, and dynamic light conditions. Recent works on processing incomplete point clouds have always focused on point cloud completion. However, these approaches do not ensure consistency between the completed point cloud and the captured images regarding color and geometry. We propose using Generative Point-based NeRF (GPN) to reconstruct and repair a partial cloud by fully utilizing the scanning images and the corresponding reconstructed cloud. The repaired point cloud can achieve multi-view consistency with the captured images at high spatial resolution. For the finetunes of a single scene, we optimize the global latent condition by incorporating an Auto-Decoder architecture while retaining multi-view consistency. As a result, the generated point clouds are smooth, plausible, and geometrically consistent with the partial scanning images. Extensive experiments on ShapeNet demonstrate that our works achieve competitive performances to the other state-of-the-art point cloud-based neural scene rendering and editing performances.","sentences":["Scanning real-life scenes with modern registration devices typically gives incomplete point cloud representations, primarily due to the limitations of partial scanning, 3D occlusions, and dynamic light conditions.","Recent works on processing incomplete point clouds have always focused on point cloud completion.","However, these approaches do not ensure consistency between the completed point cloud and the captured images regarding color and geometry.","We propose using Generative Point-based NeRF (GPN) to reconstruct and repair a partial cloud by fully utilizing the scanning images and the corresponding reconstructed cloud.","The repaired point cloud can achieve multi-view consistency with the captured images at high spatial resolution.","For the finetunes of a single scene, we optimize the global latent condition by incorporating an Auto-Decoder architecture while retaining multi-view consistency.","As a result, the generated point clouds are smooth, plausible, and geometrically consistent with the partial scanning images.","Extensive experiments on ShapeNet demonstrate that our works achieve competitive performances to the other state-of-the-art point cloud-based neural scene rendering and editing performances."],"url":"http://arxiv.org/abs/2404.08312v1","category":"cs.CV"}
{"created":"2024-04-12 08:11:45","title":"emucxl: an emulation framework for CXL-based disaggregated memory applications","abstract":"The emergence of CXL (Compute Express Link) promises to transform the status of interconnects between host and devices and in turn impact the design of all software layers. With its low overhead, low latency, and memory coherency capabilities, CXL has the potential to improve the performance of existing devices while making viable new operational use cases (e.g., disaggregated memory pools, cache coherent memory across devices etc.). The focus of this work is design of applications and middleware with use of CXL for supporting disaggregated memory. A vital building block for solutions in this space is the availability of a standard CXL hardware and software platform. Currently, CXL devices are not commercially available, and researchers often rely on custom-built hardware or emulation techniques and/or use customized software interfaces and abstractions. These techniques do not provide a standard usage model and abstraction layer for CXL usage, and developers and researchers have to reinvent the CXL setup to design and test their solutions, our work aims to provide a standardized view of the CXL emulation platform and the software interfaces and abstractions for disaggregated memory. This standardization is designed and implemented as a user space library, emucxl and is available as a virtual appliance. The library provides a user space API and is coupled with a NUMA-based CXL emulation backend. Further, we demonstrate usage of the standardized API for different use cases relying on disaggregated memory and show that generalized functionality can be built using the open source emucxl library.","sentences":["The emergence of CXL (Compute Express Link) promises to transform the status of interconnects between host and devices and in turn impact the design of all software layers.","With its low overhead, low latency, and memory coherency capabilities, CXL has the potential to improve the performance of existing devices while making viable new operational use cases (e.g., disaggregated memory pools, cache coherent memory across devices etc.).","The focus of this work is design of applications and middleware with use of CXL for supporting disaggregated memory.","A vital building block for solutions in this space is the availability of a standard CXL hardware and software platform.","Currently, CXL devices are not commercially available, and researchers often rely on custom-built hardware or emulation techniques and/or use customized software interfaces and abstractions.","These techniques do not provide a standard usage model and abstraction layer for CXL usage, and developers and researchers have to reinvent the CXL setup to design and test their solutions, our work aims to provide a standardized view of the CXL emulation platform and the software interfaces and abstractions for disaggregated memory.","This standardization is designed and implemented as a user space library, emucxl and is available as a virtual appliance.","The library provides a user space API and is coupled with a NUMA-based CXL emulation backend.","Further, we demonstrate usage of the standardized API for different use cases relying on disaggregated memory and show that generalized functionality can be built using the open source emucxl library."],"url":"http://arxiv.org/abs/2404.08311v1","category":"cs.DC"}
{"created":"2024-04-12 08:08:44","title":"Subtoxic Questions: Dive Into Attitude Change of LLM's Response in Jailbreak Attempts","abstract":"As Large Language Models (LLMs) of Prompt Jailbreaking are getting more and more attention, it is of great significance to raise a generalized research paradigm to evaluate attack strengths and a basic model to conduct subtler experiments. In this paper, we propose a novel approach by focusing on a set of target questions that are inherently more sensitive to jailbreak prompts, aiming to circumvent the limitations posed by enhanced LLM security. Through designing and analyzing these sensitive questions, this paper reveals a more effective method of identifying vulnerabilities in LLMs, thereby contributing to the advancement of LLM security. This research not only challenges existing jailbreaking methodologies but also fortifies LLMs against potential exploits.","sentences":["As Large Language Models (LLMs) of Prompt Jailbreaking are getting more and more attention, it is of great significance to raise a generalized research paradigm to evaluate attack strengths and a basic model to conduct subtler experiments.","In this paper, we propose a novel approach by focusing on a set of target questions that are inherently more sensitive to jailbreak prompts, aiming to circumvent the limitations posed by enhanced LLM security.","Through designing and analyzing these sensitive questions, this paper reveals a more effective method of identifying vulnerabilities in LLMs, thereby contributing to the advancement of LLM security.","This research not only challenges existing jailbreaking methodologies but also fortifies LLMs against potential exploits."],"url":"http://arxiv.org/abs/2404.08309v1","category":"cs.CR"}
{"created":"2024-04-12 08:06:32","title":"Composing Codensity Bisimulations","abstract":"Proving compositionality of behavioral equivalence on state-based systems with respect to algebraic operations is a classical and widely studied problem. We study a categorical formulation of this problem, where operations on state-based systems modeled as coalgebras can be elegantly captured through distributive laws between functors. To prove compositionality, it then suffices to show that this distributive law lifts from sets to relations, giving an explanation of how behavioral equivalence on smaller systems can be combined to obtain behavioral equivalence on the composed system.   In this paper, we refine this approach by focusing on so-called codensity lifting of functors, which gives a very generic presentation of various notions of (bi)similarity as well as quantitative notions such as behavioral metrics on probabilistic systems. The key idea is to use codensity liftings both at the level of algebras and coalgebras, using a new generalization of the codensity lifting. The problem of lifting distributive laws then reduces to the abstract problem of constructing distributive laws between codensity liftings, for which we propose a simplified sufficient condition. Our sufficient condition instantiates to concrete proof methods for compositionality of algebraic operations on various types of state-based systems. We instantiate our results to prove compositionality of qualitative and quantitative properties of deterministic automata. We also explore the limits of our approach by including an example of probabilistic systems, where it is unclear whether the sufficient condition holds, and instead we use our setting to give a direct proof of compositionality. ...","sentences":["Proving compositionality of behavioral equivalence on state-based systems with respect to algebraic operations is a classical and widely studied problem.","We study a categorical formulation of this problem, where operations on state-based systems modeled as coalgebras can be elegantly captured through distributive laws between functors.","To prove compositionality, it then suffices to show that this distributive law lifts from sets to relations, giving an explanation of how behavioral equivalence on smaller systems can be combined to obtain behavioral equivalence on the composed system.   ","In this paper, we refine this approach by focusing on so-called codensity lifting of functors, which gives a very generic presentation of various notions of (bi)similarity as well as quantitative notions such as behavioral metrics on probabilistic systems.","The key idea is to use codensity liftings both at the level of algebras and coalgebras, using a new generalization of the codensity lifting.","The problem of lifting distributive laws then reduces to the abstract problem of constructing distributive laws between codensity liftings, for which we propose a simplified sufficient condition.","Our sufficient condition instantiates to concrete proof methods for compositionality of algebraic operations on various types of state-based systems.","We instantiate our results to prove compositionality of qualitative and quantitative properties of deterministic automata.","We also explore the limits of our approach by including an example of probabilistic systems, where it is unclear whether the sufficient condition holds, and instead we use our setting to give a direct proof of compositionality. ..."],"url":"http://arxiv.org/abs/2404.08308v1","category":"cs.LO"}
{"created":"2024-04-12 08:01:32","title":"Solid-State Electrochemical Thermal Transistors with Large Thermal Conductivity Switching Widths","abstract":"Thermal transistors that switch the thermal conductivity (\\k{appa}) of the active layers are attracting increasing attention as thermal management devices. For electrochemical thermal transistors, several transition metal oxides (TMOs) have been proposed as active layers. After electrochemical redox treatment, the crystal structure of the TMO is modulated, which results in the \\k{appa} switching. However, the \\k{appa} switching width is still small (< 4 W/mK). In this study, we demonstrate that LaNiOx-based solid-state electrochemical thermal transistors have a \\k{appa} switching width of 4.3 W/mK. Fully oxidised LaNiO3 (on state) has a \\k{appa} of 6.0 W/mK due to the large contribution of electron thermal conductivity (\\k{appa}ele, 3.1 W/mK). In contrast, reduced LaNiO2.72 (off state) has a \\k{appa} of 1.7 W/mK because the phonons are scattered by the oxygen vacancies. The LaNiOx-based electrochemical thermal transistor exhibits excellent cyclability of \\k{appa} and the crystalline lattice of LaNiOx. This electrochemical thermal transistor may be a promising platform for next-generation devices such as thermal displays.","sentences":["Thermal transistors that switch the thermal conductivity (\\k{appa}) of the active layers are attracting increasing attention as thermal management devices.","For electrochemical thermal transistors, several transition metal oxides (TMOs) have been proposed as active layers.","After electrochemical redox treatment, the crystal structure of the TMO is modulated, which results in the \\k{appa} switching.","However, the \\k{appa} switching width is still small (< 4 W/mK).","In this study, we demonstrate that LaNiOx-based solid-state electrochemical thermal transistors have a \\k{appa} switching width of 4.3 W/mK. Fully oxidised LaNiO3 (on state) has a \\k{appa} of 6.0 W/mK due to the large contribution of electron thermal conductivity (\\k{appa}ele, 3.1 W/mK).","In contrast, reduced LaNiO2.72 (off state) has a \\k{appa} of 1.7 W/mK because the phonons are scattered by the oxygen vacancies.","The LaNiOx-based electrochemical thermal transistor exhibits excellent cyclability of \\k{appa} and the crystalline lattice of LaNiOx.","This electrochemical thermal transistor may be a promising platform for next-generation devices such as thermal displays."],"url":"http://arxiv.org/abs/2404.08307v1","category":"cond-mat.mtrl-sci"}
{"created":"2024-04-12 07:51:21","title":"A Large Scale Survey of Motivation in Software Development and Analysis of its Validity","abstract":"Context: Motivation is known to improve performance. In software development in particular, there has been considerable interest in the motivation of contributors to open source. Objective: We identify 11 motivators from the literature (enjoying programming, ownership of code, learning, self use, etc.), and evaluate their relative effect on motivation. Since motivation is an internal subjective feeling, we also analyze the validity of the answers. Method: We conducted a survey with 66 questions on motivation which was completed by 521 developers. Most of the questions used an 11 point scale. We evaluated the validity of the answers validity by comparing related questions, comparing to actual behavior on GitHub, and comparison with the same developer in a follow up survey. Results: Validity problems include moderate correlations between answers to related questions, as well as self promotion and mistakes in the answers. Despite these problems, predictive analysis, investigating how diverse motivators influence the probability of high motivation, provided valuable insights. The correlations between the different motivators are low, implying their independence. High values in all 11 motivators predict increased probability of high motivation. In addition, improvement analysis shows that an increase in most motivators predicts an increase in general motivation.","sentences":["Context: Motivation is known to improve performance.","In software development in particular, there has been considerable interest in the motivation of contributors to open source.","Objective: We identify 11 motivators from the literature (enjoying programming, ownership of code, learning, self use, etc.), and evaluate their relative effect on motivation.","Since motivation is an internal subjective feeling, we also analyze the validity of the answers.","Method: We conducted a survey with 66 questions on motivation which was completed by 521 developers.","Most of the questions used an 11 point scale.","We evaluated the validity of the answers validity by comparing related questions, comparing to actual behavior on GitHub, and comparison with the same developer in a follow up survey.","Results:","Validity problems include moderate correlations between answers to related questions, as well as self promotion and mistakes in the answers.","Despite these problems, predictive analysis, investigating how diverse motivators influence the probability of high motivation, provided valuable insights.","The correlations between the different motivators are low, implying their independence.","High values in all 11 motivators predict increased probability of high motivation.","In addition, improvement analysis shows that an increase in most motivators predicts an increase in general motivation."],"url":"http://arxiv.org/abs/2404.08303v1","category":"cs.SE"}
{"created":"2024-04-12 07:40:26","title":"High-Speed Interception Multicopter Control by Image-based Visual Servoing","abstract":"In recent years, reports of illegal drones threatening public safety have increased. For the invasion of fully autonomous drones, traditional methods such as radio frequency interference and GPS shielding may fail. This paper proposes a scheme that uses an autonomous multicopter with a strapdown camera to intercept a maneuvering intruder UAV. The interceptor multicopter can autonomously detect and intercept intruders moving at high speed in the air. The strapdown camera avoids the complex mechanical structure of the electro-optical pod, making the interceptor multicopter compact. However, the coupling of the camera and multicopter motion makes interception tasks difficult. To solve this problem, an Image-Based Visual Servoing (IBVS) controller is proposed to make the interception fast and accurate. Then, in response to the time delay of sensor imaging and image processing relative to attitude changes in high-speed scenarios, a Delayed Kalman Filter (DKF) observer is generalized to predict the current image position and increase the update frequency. Finally, Hardware-in-the-Loop (HITL) simulations and outdoor flight experiments verify that this method has a high interception accuracy and success rate. In the flight experiments, a high-speed interception is achieved with a terminal speed of 20 m/s.","sentences":["In recent years, reports of illegal drones threatening public safety have increased.","For the invasion of fully autonomous drones, traditional methods such as radio frequency interference and GPS shielding may fail.","This paper proposes a scheme that uses an autonomous multicopter with a strapdown camera to intercept a maneuvering intruder UAV.","The interceptor multicopter can autonomously detect and intercept intruders moving at high speed in the air.","The strapdown camera avoids the complex mechanical structure of the electro-optical pod, making the interceptor multicopter compact.","However, the coupling of the camera and multicopter motion makes interception tasks difficult.","To solve this problem, an Image-Based Visual Servoing (IBVS) controller is proposed to make the interception fast and accurate.","Then, in response to the time delay of sensor imaging and image processing relative to attitude changes in high-speed scenarios, a Delayed Kalman Filter (DKF) observer is generalized to predict the current image position and increase the update frequency.","Finally, Hardware-in-the-Loop (HITL) simulations and outdoor flight experiments verify that this method has a high interception accuracy and success rate.","In the flight experiments, a high-speed interception is achieved with a terminal speed of 20 m/s."],"url":"http://arxiv.org/abs/2404.08296v1","category":"cs.RO"}
{"created":"2024-04-12 07:34:46","title":"Study of Emotion Concept Formation by Integrating Vision, Physiology, and Word Information using Multilayered Multimodal Latent Dirichlet Allocation","abstract":"How are emotions formed? Through extensive debate and the promulgation of diverse theories , the theory of constructed emotion has become prevalent in recent research on emotions. According to this theory, an emotion concept refers to a category formed by interoceptive and exteroceptive information associated with a specific emotion. An emotion concept stores past experiences as knowledge and can predict unobserved information from acquired information. Therefore, in this study, we attempted to model the formation of emotion concepts using a constructionist approach from the perspective of the constructed emotion theory. Particularly, we constructed a model using multilayered multimodal latent Dirichlet allocation , which is a probabilistic generative model. We then trained the model for each subject using vision, physiology, and word information obtained from multiple people who experienced different visual emotion-evoking stimuli. To evaluate the model, we verified whether the formed categories matched human subjectivity and determined whether unobserved information could be predicted via categories. The verification results exceeded chance level, suggesting that emotion concept formation can be explained by the proposed model.","sentences":["How are emotions formed?","Through extensive debate and the promulgation of diverse theories , the theory of constructed emotion has become prevalent in recent research on emotions.","According to this theory, an emotion concept refers to a category formed by interoceptive and exteroceptive information associated with a specific emotion.","An emotion concept stores past experiences as knowledge and can predict unobserved information from acquired information.","Therefore, in this study, we attempted to model the formation of emotion concepts using a constructionist approach from the perspective of the constructed emotion theory.","Particularly, we constructed a model using multilayered multimodal latent Dirichlet allocation , which is a probabilistic generative model.","We then trained the model for each subject using vision, physiology, and word information obtained from multiple people who experienced different visual emotion-evoking stimuli.","To evaluate the model, we verified whether the formed categories matched human subjectivity and determined whether unobserved information could be predicted via categories.","The verification results exceeded chance level, suggesting that emotion concept formation can be explained by the proposed model."],"url":"http://arxiv.org/abs/2404.08295v1","category":"cs.AI"}
{"created":"2024-04-12 07:31:48","title":"Strongly robustness of toric ideals of weighted oriented cycles sharing a single vertex","abstract":"In this article, we study the strongly robust property of toric ideals of weighted oriented graphs. Let $D$ be a weighted oriented graph consists of weighted oriented cycles (balanced or unbalanced) sharing a single vertex $v$ and $D^{\\prime}$ be a weighted oriented graph consists of $D$ and a finite number of disjoint cycles such that each of these cycles is connected by a path at the sharing vertex $v$ of $D$. Then we show that the toric ideals $I_D,I_{D^{\\prime}}$ of $D$ and $D^{\\prime}$ respectively, are strongly robust and hence robust. That is, for the toric ideal $I_D$, of $D$, its Graver basis is a minimal generating set of $I_D$. We explicitly give a unique minimal generating set of primitive binomials of $I_D$. We explicitly describe the circuit binomials in any weighted oriented graph.","sentences":["In this article, we study the strongly robust property of toric ideals of weighted oriented graphs.","Let $D$ be a weighted oriented graph consists of weighted oriented cycles (balanced or unbalanced) sharing a single vertex $v$ and $D^{\\prime}$ be a weighted oriented graph consists of $D$ and a finite number of disjoint cycles such that each of these cycles is connected by a path at the sharing vertex $v$ of $D$. Then we show that the toric ideals $I_D,I_{D^{\\prime}}$ of $D$ and $D^{\\prime}$ respectively, are strongly robust and hence robust.","That is, for the toric ideal $I_D$, of $D$, its Graver basis is a minimal generating set of $I_D$. We explicitly give a unique minimal generating set of primitive binomials of $I_D$. We explicitly describe the circuit binomials in any weighted oriented graph."],"url":"http://arxiv.org/abs/2404.08294v1","category":"math.AC"}
{"created":"2024-04-12 07:28:47","title":"On the controllability in projections for linear quantum systems","abstract":"We present sufficient conditions for the exact controllability in projection of the linear Schr{\\\"o}dinger equations in the case where the spectrum of the free Hamiltonian is pure point. We consider the general case in which the Hamiltonian may be nonlinear with respect to the control. The controllability result applies, in particular, to Schr{\\\"o}dinger equations with a polarizability term.","sentences":["We present sufficient conditions for the exact controllability in projection of the linear Schr{\\\"o}dinger equations in the case where the spectrum of the free Hamiltonian is pure point.","We consider the general case in which the Hamiltonian may be nonlinear with respect to the control.","The controllability result applies, in particular, to Schr{\\\"o}dinger equations with a polarizability term."],"url":"http://arxiv.org/abs/2404.08290v1","category":"math.OC"}
{"created":"2024-04-12 07:27:25","title":"Generic controllability of equivariant systems and applications to particle systems and neural networks","abstract":"There exist many examples of systems which have some symmetries, and which one may monitor with symmetry preserving controls. Since symmetries are preserved along the evolution, full controllability is not possible, and controllability has to be considered inside sets of states with same symmetries. We prove that generic systems with symmetries are controllable in this sense. This result has several applications, for instance: (i) generic controllability of particle systems when the kernel of interaction between particles plays the role of a mean-field control; (ii) generic controllability for families of vector fields on manifolds with boundary; (iii) universal interpolation for neural networks architectures with \"generic\" self attention-type layers - a type of layers ubiquitous in recent neural networks architectures, e.g., in the Transformers architecture. The tools we develop could help address various other questions of control of equivariant systems.","sentences":["There exist many examples of systems which have some symmetries, and which one may monitor with symmetry preserving controls.","Since symmetries are preserved along the evolution, full controllability is not possible, and controllability has to be considered inside sets of states with same symmetries.","We prove that generic systems with symmetries are controllable in this sense.","This result has several applications, for instance: (i) generic controllability of particle systems when the kernel of interaction between particles plays the role of a mean-field control; (ii) generic controllability for families of vector fields on manifolds with boundary; (iii) universal interpolation for neural networks architectures with \"generic\" self attention-type layers - a type of layers ubiquitous in recent neural networks architectures, e.g., in the Transformers architecture.","The tools we develop could help address various other questions of control of equivariant systems."],"url":"http://arxiv.org/abs/2404.08289v1","category":"math.DS"}
{"created":"2024-04-12 07:19:16","title":"A Survey of Neural Network Robustness Assessment in Image Recognition","abstract":"In recent years, there has been significant attention given to the robustness assessment of neural networks. Robustness plays a critical role in ensuring reliable operation of artificial intelligence (AI) systems in complex and uncertain environments. Deep learning's robustness problem is particularly significant, highlighted by the discovery of adversarial attacks on image classification models. Researchers have dedicated efforts to evaluate robustness in diverse perturbation conditions for image recognition tasks. Robustness assessment encompasses two main techniques: robustness verification/ certification for deliberate adversarial attacks and robustness testing for random data corruptions. In this survey, we present a detailed examination of both adversarial robustness (AR) and corruption robustness (CR) in neural network assessment. Analyzing current research papers and standards, we provide an extensive overview of robustness assessment in image recognition. Three essential aspects are analyzed: concepts, metrics, and assessment methods. We investigate the perturbation metrics and range representations used to measure the degree of perturbations on images, as well as the robustness metrics specifically for the robustness conditions of classification models. The strengths and limitations of the existing methods are also discussed, and some potential directions for future research are provided.","sentences":["In recent years, there has been significant attention given to the robustness assessment of neural networks.","Robustness plays a critical role in ensuring reliable operation of artificial intelligence (AI) systems in complex and uncertain environments.","Deep learning's robustness problem is particularly significant, highlighted by the discovery of adversarial attacks on image classification models.","Researchers have dedicated efforts to evaluate robustness in diverse perturbation conditions for image recognition tasks.","Robustness assessment encompasses two main techniques: robustness verification/ certification for deliberate adversarial attacks and robustness testing for random data corruptions.","In this survey, we present a detailed examination of both adversarial robustness (AR) and corruption robustness (CR) in neural network assessment.","Analyzing current research papers and standards, we provide an extensive overview of robustness assessment in image recognition.","Three essential aspects are analyzed: concepts, metrics, and assessment methods.","We investigate the perturbation metrics and range representations used to measure the degree of perturbations on images, as well as the robustness metrics specifically for the robustness conditions of classification models.","The strengths and limitations of the existing methods are also discussed, and some potential directions for future research are provided."],"url":"http://arxiv.org/abs/2404.08285v1","category":"cs.CV"}
{"created":"2024-04-12 07:17:28","title":"A unified generalization of inverse regression via adaptive column selection","abstract":"A bottleneck of sufficient dimension reduction (SDR) in the modern era is that, among numerous methods, only the sliced inverse regression (SIR) is generally applicable under the high-dimensional settings. The higher-order inverse regression methods, which form a major family of SDR methods that are superior to SIR in the population level, suffer from the dimensionality of their intermediate matrix-valued parameters that have an excessive number of columns. In this paper, we propose the generic idea of using a small subset of columns of the matrix-valued parameter for SDR estimation, which breaks the convention of using the ambient matrix for the higher-order inverse regression methods. With the aid of a quick column selection procedure, we then generalize these methods as well as their ensembles towards sparsity under the ultrahigh-dimensional settings, in a uniform manner that resembles sparse SIR and without additional assumptions. This is the first promising attempt in the literature to free the higher-order inverse regression methods from their dimensionality, which facilitates the applicability of SDR. The gain of column selection with respect to SDR estimation efficiency is also studied under the fixed-dimensional settings. Simulation studies and a real data example are provided at the end.","sentences":["A bottleneck of sufficient dimension reduction (SDR) in the modern era is that, among numerous methods, only the sliced inverse regression (SIR) is generally applicable under the high-dimensional settings.","The higher-order inverse regression methods, which form a major family of SDR methods that are superior to SIR in the population level, suffer from the dimensionality of their intermediate matrix-valued parameters that have an excessive number of columns.","In this paper, we propose the generic idea of using a small subset of columns of the matrix-valued parameter for SDR estimation, which breaks the convention of using the ambient matrix for the higher-order inverse regression methods.","With the aid of a quick column selection procedure, we then generalize these methods as well as their ensembles towards sparsity under the ultrahigh-dimensional settings, in a uniform manner that resembles sparse SIR and without additional assumptions.","This is the first promising attempt in the literature to free the higher-order inverse regression methods from their dimensionality, which facilitates the applicability of SDR.","The gain of column selection with respect to SDR estimation efficiency is also studied under the fixed-dimensional settings.","Simulation studies and a real data example are provided at the end."],"url":"http://arxiv.org/abs/2404.08284v1","category":"stat.ME"}
{"created":"2024-04-12 07:13:32","title":"Calibration & Reconstruction: Deep Integrated Language for Referring Image Segmentation","abstract":"Referring image segmentation aims to segment an object referred to by natural language expression from an image. The primary challenge lies in the efficient propagation of fine-grained semantic information from textual features to visual features. Many recent works utilize a Transformer to address this challenge. However, conventional transformer decoders can distort linguistic information with deeper layers, leading to suboptimal results. In this paper, we introduce CRFormer, a model that iteratively calibrates multi-modal features in the transformer decoder. We start by generating language queries using vision features, emphasizing different aspects of the input language. Then, we propose a novel Calibration Decoder (CDec) wherein the multi-modal features can iteratively calibrated by the input language features. In the Calibration Decoder, we use the output of each decoder layer and the original language features to generate new queries for continuous calibration, which gradually updates the language features. Based on CDec, we introduce a Language Reconstruction Module and a reconstruction loss. This module leverages queries from the final layer of the decoder to reconstruct the input language and compute the reconstruction loss. This can further prevent the language information from being lost or distorted. Our experiments consistently show the superior performance of our approach across RefCOCO, RefCOCO+, and G-Ref datasets compared to state-of-the-art methods.","sentences":["Referring image segmentation aims to segment an object referred to by natural language expression from an image.","The primary challenge lies in the efficient propagation of fine-grained semantic information from textual features to visual features.","Many recent works utilize a Transformer to address this challenge.","However, conventional transformer decoders can distort linguistic information with deeper layers, leading to suboptimal results.","In this paper, we introduce CRFormer, a model that iteratively calibrates multi-modal features in the transformer decoder.","We start by generating language queries using vision features, emphasizing different aspects of the input language.","Then, we propose a novel Calibration Decoder (CDec)","wherein the multi-modal features can iteratively calibrated by the input language features.","In the Calibration Decoder, we use the output of each decoder layer and the original language features to generate new queries for continuous calibration, which gradually updates the language features.","Based on CDec, we introduce a Language Reconstruction Module and a reconstruction loss.","This module leverages queries from the final layer of the decoder to reconstruct the input language and compute the reconstruction loss.","This can further prevent the language information from being lost or distorted.","Our experiments consistently show the superior performance of our approach across RefCOCO, RefCOCO+, and G-Ref datasets compared to state-of-the-art methods."],"url":"http://arxiv.org/abs/2404.08281v1","category":"cs.CV"}
{"created":"2024-04-12 07:09:39","title":"On set systems with strongly restricted intersections","abstract":"Set systems with strongly restricted intersections, called $\\alpha$-intersecting families for a vector $\\alpha$, were introduced recently as a generalization of several well-studied intersecting families including the classical oddtown and eventown. Given a binary vector $\\alpha=(a_1, \\ldots, a_k)$, a collection $\\mathcal F$ of subsets over an $n$ element set is an $\\alpha$-intersecting family modulo $2$ if for each $i=1,2,\\ldots,k$, all $i$-wise intersections of distinct members in $\\mathcal F$ have sizes with the same parity as $a_i$. Let $f_\\alpha(n)$ denote the maximum size of such a family. In this paper, we study the asymptotic behavior of $f_\\alpha(n)$ when $n$ goes to infinity. We show that if $t$ is the maximum integer such that $a_t=1$ and $2t\\leq k$, then $f_{\\alpha(n)} \\sim {(t! n)}^{\\frac 1 t}$. More importantly, we show that for any constant $c$, as the length $k$ goes larger, $f_\\alpha(n)$ is upper bounded by $O (n^c)$ for almost all $\\alpha$. Equivalently, no matter what $k$ is, there are only finitely many $\\alpha$ satisfying $f_\\alpha(n)=\\Omega (n^c)$. This answers an open problem raised by Johnston and O'Neill in 2023. All of our results can be generalized to modulo $p$ setting for any prime $p$ smoothly.","sentences":["Set systems with strongly restricted intersections, called $\\alpha$-intersecting families for a vector $\\alpha$, were introduced recently as a generalization of several well-studied intersecting families including the classical oddtown and eventown.","Given a binary vector $\\alpha=(a_1, \\ldots, a_k)$, a collection $\\mathcal F$ of subsets over an $n$ element set is an $\\alpha$-intersecting family modulo $2$ if for each $i=1,2,\\ldots,k$, all $i$-wise intersections of distinct members in $\\mathcal F$ have sizes with the same parity as $a_i$. Let $f_\\alpha(n)$ denote the maximum size of such a family.","In this paper, we study the asymptotic behavior of $f_\\alpha(n)$ when $n$ goes to infinity.","We show that if $t$ is the maximum integer such that $a_t=1$ and $2t\\leq k$, then $f_{\\alpha(n)} \\sim {(t!","n)}^{\\frac 1 t}$. More importantly, we show that for any constant $c$, as the length $k$ goes larger, $f_\\alpha(n)$ is upper bounded by $O (n^c)$ for almost all $\\alpha$. Equivalently, no matter what $k$ is, there are only finitely many $\\alpha$ satisfying $f_\\alpha(n)=\\Omega (n^c)$. This answers an open problem raised by Johnston and O'Neill in 2023.","All of our results can be generalized to modulo $p$ setting for any prime $p$ smoothly."],"url":"http://arxiv.org/abs/2404.08280v1","category":"math.CO"}
{"created":"2024-04-12 07:06:12","title":"Minimax Optimal Goodness-of-Fit Testing with Kernel Stein Discrepancy","abstract":"We explore the minimax optimality of goodness-of-fit tests on general domains using the kernelized Stein discrepancy (KSD). The KSD framework offers a flexible approach for goodness-of-fit testing, avoiding strong distributional assumptions, accommodating diverse data structures beyond Euclidean spaces, and relying only on partial knowledge of the reference distribution, while maintaining computational efficiency. We establish a general framework and an operator-theoretic representation of the KSD, encompassing many existing KSD tests in the literature, which vary depending on the domain. We reveal the characteristics and limitations of KSD and demonstrate its non-optimality under a certain alternative space, defined over general domains when considering $\\chi^2$-divergence as the separation metric. To address this issue of non-optimality, we propose a modified, minimax optimal test by incorporating a spectral regularizer, thereby overcoming the shortcomings of standard KSD tests. Our results are established under a weak moment condition on the Stein kernel, which relaxes the bounded kernel assumption required by prior work in the analysis of kernel-based hypothesis testing. Additionally, we introduce an adaptive test capable of achieving minimax optimality up to a logarithmic factor by adapting to unknown parameters. Through numerical experiments, we illustrate the superior performance of our proposed tests across various domains compared to their unregularized counterparts.","sentences":["We explore the minimax optimality of goodness-of-fit tests on general domains using the kernelized Stein discrepancy (KSD).","The KSD framework offers a flexible approach for goodness-of-fit testing, avoiding strong distributional assumptions, accommodating diverse data structures beyond Euclidean spaces, and relying only on partial knowledge of the reference distribution, while maintaining computational efficiency.","We establish a general framework and an operator-theoretic representation of the KSD, encompassing many existing KSD tests in the literature, which vary depending on the domain.","We reveal the characteristics and limitations of KSD and demonstrate its non-optimality under a certain alternative space, defined over general domains when considering $\\chi^2$-divergence as the separation metric.","To address this issue of non-optimality, we propose a modified, minimax optimal test by incorporating a spectral regularizer, thereby overcoming the shortcomings of standard KSD tests.","Our results are established under a weak moment condition on the Stein kernel, which relaxes the bounded kernel assumption required by prior work in the analysis of kernel-based hypothesis testing.","Additionally, we introduce an adaptive test capable of achieving minimax optimality up to a logarithmic factor by adapting to unknown parameters.","Through numerical experiments, we illustrate the superior performance of our proposed tests across various domains compared to their unregularized counterparts."],"url":"http://arxiv.org/abs/2404.08278v1","category":"math.ST"}
{"created":"2024-04-12 07:04:56","title":"FaceFilterSense: A Filter-Resistant Face Recognition and Facial Attribute Analysis Framework","abstract":"With the advent of social media, fun selfie filters have come into tremendous mainstream use affecting the functioning of facial biometric systems as well as image recognition systems. These filters vary from beautification filters and Augmented Reality (AR)-based filters to filters that modify facial landmarks. Hence, there is a need to assess the impact of such filters on the performance of existing face recognition systems. The limitation associated with existing solutions is that these solutions focus more on the beautification filters. However, the current AR-based filters and filters which distort facial key points are in vogue recently and make the faces highly unrecognizable even to the naked eye. Also, the filters considered are mostly obsolete with limited variations. To mitigate these limitations, we aim to perform a holistic impact analysis of the latest filters and propose an user recognition model with the filtered images. We have utilized a benchmark dataset for baseline images, and applied the latest filters over them to generate a beautified/filtered dataset. Next, we have introduced a model FaceFilterNet for beautified user recognition. In this framework, we also utilize our model to comment on various attributes of the person including age, gender, and ethnicity. In addition, we have also presented a filter-wise impact analysis on face recognition, age estimation, gender, and ethnicity prediction. The proposed method affirms the efficacy of our dataset with an accuracy of 87.25% and an optimal accuracy for facial attribute analysis.","sentences":["With the advent of social media, fun selfie filters have come into tremendous mainstream use affecting the functioning of facial biometric systems as well as image recognition systems.","These filters vary from beautification filters and Augmented Reality (AR)-based filters to filters that modify facial landmarks.","Hence, there is a need to assess the impact of such filters on the performance of existing face recognition systems.","The limitation associated with existing solutions is that these solutions focus more on the beautification filters.","However, the current AR-based filters and filters which distort facial key points are in vogue recently and make the faces highly unrecognizable even to the naked eye.","Also, the filters considered are mostly obsolete with limited variations.","To mitigate these limitations, we aim to perform a holistic impact analysis of the latest filters and propose an user recognition model with the filtered images.","We have utilized a benchmark dataset for baseline images, and applied the latest filters over them to generate a beautified/filtered dataset.","Next, we have introduced a model FaceFilterNet for beautified user recognition.","In this framework, we also utilize our model to comment on various attributes of the person including age, gender, and ethnicity.","In addition, we have also presented a filter-wise impact analysis on face recognition, age estimation, gender, and ethnicity prediction.","The proposed method affirms the efficacy of our dataset with an accuracy of 87.25% and an optimal accuracy for facial attribute analysis."],"url":"http://arxiv.org/abs/2404.08277v1","category":"cs.CV"}
{"created":"2024-04-12 06:58:02","title":"Machine Learning Assisted Sorting of Active Microswimmers","abstract":"Active matter systems being in a non-equilibrium state, exhibit complex behaviors such as self-organization and giving rise to emergent phenomena. There are many examples of active particles with biological origins, including bacteria and spermatozoa, or with artificial origins, such as self-propelled swimmers and Janus particles. The ability to manipulate active particles is vital for their effective application e.g. separating motile spermatozoa from nonmotile and dead ones, to increase fertilization chance. In this study, we proposed a mechanism -- an apparatus -- to sort and demix active particles based on their motility values (P\\`eclet number). Initially, using Brownian simulations we demonstrated the feasibility of sorting self-propelled particles. Following this, we employed machine learning methods, supplemented with data from comprehensive simulations that we conducted for this study, to model the complex behavior of active particles. This enabled us to sort them based on their P\\`eclet number. Finally, we evaluated the performance of the developed models and showed their effectiveness in demixing and sorting the active particles. Our findings can find applications in various fields, including physics, biology, and biomedical science, where the sorting and manipulation of active particles play a pivotal role.","sentences":["Active matter systems being in a non-equilibrium state, exhibit complex behaviors such as self-organization and giving rise to emergent phenomena.","There are many examples of active particles with biological origins, including bacteria and spermatozoa, or with artificial origins, such as self-propelled swimmers and Janus particles.","The ability to manipulate active particles is vital for their effective application e.g. separating motile spermatozoa from nonmotile and dead ones, to increase fertilization chance.","In this study, we proposed a mechanism -- an apparatus -- to sort and demix active particles based on their motility values (P\\`eclet number).","Initially, using Brownian simulations we demonstrated the feasibility of sorting self-propelled particles.","Following this, we employed machine learning methods, supplemented with data from comprehensive simulations that we conducted for this study, to model the complex behavior of active particles.","This enabled us to sort them based on their P\\`eclet number.","Finally, we evaluated the performance of the developed models and showed their effectiveness in demixing and sorting the active particles.","Our findings can find applications in various fields, including physics, biology, and biomedical science, where the sorting and manipulation of active particles play a pivotal role."],"url":"http://arxiv.org/abs/2404.08275v1","category":"cond-mat.soft"}
{"created":"2024-04-12 06:52:40","title":"Struggle with Adversarial Defense? Try Diffusion","abstract":"Adversarial attacks induce misclassification by introducing subtle perturbations. Recently, diffusion models are applied to the image classifiers to improve adversarial robustness through adversarial training or by purifying adversarial noise. However, diffusion-based adversarial training often encounters convergence challenges and high computational expenses. Additionally, diffusion-based purification inevitably causes data shift and is deemed susceptible to stronger adaptive attacks. To tackle these issues, we propose the Truth Maximization Diffusion Classifier (TMDC), a generative Bayesian classifier that builds upon pre-trained diffusion models and the Bayesian theorem. Unlike data-driven classifiers, TMDC, guided by Bayesian principles, utilizes the conditional likelihood from diffusion models to determine the class probabilities of input images, thereby insulating against the influences of data shift and the limitations of adversarial training. Moreover, to enhance TMDC's resilience against more potent adversarial attacks, we propose an optimization strategy for diffusion classifiers. This strategy involves post-training the diffusion model on perturbed datasets with ground-truth labels as conditions, guiding the diffusion model to learn the data distribution and maximizing the likelihood under the ground-truth labels. The proposed method achieves state-of-the-art performance on the CIFAR10 dataset against heavy white-box attacks and strong adaptive attacks. Specifically, TMDC achieves robust accuracies of 82.81% against $l_{\\infty}$ norm-bounded perturbations and 86.05% against $l_{2}$ norm-bounded perturbations, respectively, with $\\epsilon=0.05$.","sentences":["Adversarial attacks induce misclassification by introducing subtle perturbations.","Recently, diffusion models are applied to the image classifiers to improve adversarial robustness through adversarial training or by purifying adversarial noise.","However, diffusion-based adversarial training often encounters convergence challenges and high computational expenses.","Additionally, diffusion-based purification inevitably causes data shift and is deemed susceptible to stronger adaptive attacks.","To tackle these issues, we propose the Truth Maximization Diffusion Classifier (TMDC), a generative Bayesian classifier that builds upon pre-trained diffusion models and the Bayesian theorem.","Unlike data-driven classifiers, TMDC, guided by Bayesian principles, utilizes the conditional likelihood from diffusion models to determine the class probabilities of input images, thereby insulating against the influences of data shift and the limitations of adversarial training.","Moreover, to enhance TMDC's resilience against more potent adversarial attacks, we propose an optimization strategy for diffusion classifiers.","This strategy involves post-training the diffusion model on perturbed datasets with ground-truth labels as conditions, guiding the diffusion model to learn the data distribution and maximizing the likelihood under the ground-truth labels.","The proposed method achieves state-of-the-art performance on the CIFAR10 dataset against heavy white-box attacks and strong adaptive attacks.","Specifically, TMDC achieves robust accuracies of 82.81% against $l_{\\infty}$ norm-bounded perturbations and 86.05% against $l_{2}$ norm-bounded perturbations, respectively, with $\\epsilon=0.05$."],"url":"http://arxiv.org/abs/2404.08273v1","category":"cs.CV"}
{"created":"2024-04-12 06:51:47","title":"Infinitely many solutions for two generalized poly-Laplacian systems on weighted graphs","abstract":"We investigate the multiplicity of solutions for a generalized poly-Laplacian system on weighted finite graphs and a generalized poly-Laplacian system with Dirichlet boundary value on weighted locally finite graphs, respectively, via the variational methods which are based on mountain pass theorem and topological degree theory. We obtain that these two systems have a sequence of minimax type solutions $\\{(u_n,v_n)\\}$ satisfying the energy functional $\\varphi(u_n,v_n)\\to +\\infty$ as $n\\to +\\infty$ and a sequence of local minimum type solutions $\\{(u_m^*,v_m^*)\\}$ satisfying the energy functional $\\varphi(u_m^*,v_m^*)\\to -\\infty$ as $m\\to +\\infty$.","sentences":["We investigate the multiplicity of solutions for a generalized poly-Laplacian system on weighted finite graphs and a generalized poly-Laplacian system with Dirichlet boundary value on weighted locally finite graphs, respectively, via the variational methods which are based on mountain pass theorem and topological degree theory.","We obtain that these two systems have a sequence of minimax type solutions $\\{(u_n,v_n)\\}$ satisfying the energy functional $\\varphi(u_n,v_n)\\to +\\infty$ as $n\\to +\\infty$ and a sequence of local minimum type solutions $\\{(u_m^*,v_m^*)\\}$ satisfying the energy functional $\\varphi(u_m^*,v_m^*)\\to -\\infty$ as $m\\to +\\infty$."],"url":"http://arxiv.org/abs/2404.08272v1","category":"math.AP"}
{"created":"2024-04-12 06:50:32","title":"Transfer Learning Study of Motion Transformer-based Trajectory Predictions","abstract":"Trajectory planning in autonomous driving is highly dependent on predicting the emergent behavior of other road users. Learning-based methods are currently showing impressive results in simulation-based challenges, with transformer-based architectures technologically leading the way. Ultimately, however, predictions are needed in the real world. In addition to the shifts from simulation to the real world, many vehicle- and country-specific shifts, i.e. differences in sensor systems, fusion and perception algorithms as well as traffic rules and laws, are on the agenda. Since models that can cover all system setups and design domains at once are not yet foreseeable, model adaptation plays a central role. Therefore, a simulation-based study on transfer learning techniques is conducted on basis of a transformer-based model. Furthermore, the study aims to provide insights into possible trade-offs between computational time and performance to support effective transfers into the real world.","sentences":["Trajectory planning in autonomous driving is highly dependent on predicting the emergent behavior of other road users.","Learning-based methods are currently showing impressive results in simulation-based challenges, with transformer-based architectures technologically leading the way.","Ultimately, however, predictions are needed in the real world.","In addition to the shifts from simulation to the real world, many vehicle- and country-specific shifts, i.e. differences in sensor systems, fusion and perception algorithms as well as traffic rules and laws, are on the agenda.","Since models that can cover all system setups and design domains at once are not yet foreseeable, model adaptation plays a central role.","Therefore, a simulation-based study on transfer learning techniques is conducted on basis of a transformer-based model.","Furthermore, the study aims to provide insights into possible trade-offs between computational time and performance to support effective transfers into the real world."],"url":"http://arxiv.org/abs/2404.08271v1","category":"cs.LG"}
{"created":"2024-04-12 06:23:07","title":"Relational Prompt-based Pre-trained Language Models for Social Event Detection","abstract":"Social Event Detection (SED) aims to identify significant events from social streams, and has a wide application ranging from public opinion analysis to risk management. In recent years, Graph Neural Network (GNN) based solutions have achieved state-of-the-art performance. However, GNN-based methods often struggle with noisy and missing edges between messages, affecting the quality of learned message embedding. Moreover, these methods statically initialize node embedding before training, which, in turn, limits the ability to learn from message texts and relations simultaneously. In this paper, we approach social event detection from a new perspective based on Pre-trained Language Models (PLMs), and present RPLM_SED (Relational prompt-based Pre-trained Language Models for Social Event Detection). We first propose a new pairwise message modeling strategy to construct social messages into message pairs with multi-relational sequences. Secondly, a new multi-relational prompt-based pairwise message learning mechanism is proposed to learn more comprehensive message representation from message pairs with multi-relational prompts using PLMs. Thirdly, we design a new clustering constraint to optimize the encoding process by enhancing intra-cluster compactness and inter-cluster dispersion, making the message representation more distinguishable. We evaluate the RPLM_SED on three real-world datasets, demonstrating that the RPLM_SED model achieves state-of-the-art performance in offline, online, low-resource, and long-tail distribution scenarios for social event detection tasks.","sentences":["Social Event Detection (SED) aims to identify significant events from social streams, and has a wide application ranging from public opinion analysis to risk management.","In recent years, Graph Neural Network (GNN) based solutions have achieved state-of-the-art performance.","However, GNN-based methods often struggle with noisy and missing edges between messages, affecting the quality of learned message embedding.","Moreover, these methods statically initialize node embedding before training, which, in turn, limits the ability to learn from message texts and relations simultaneously.","In this paper, we approach social event detection from a new perspective based on Pre-trained Language Models (PLMs), and present RPLM_SED (Relational prompt-based Pre-trained Language Models for Social Event Detection).","We first propose a new pairwise message modeling strategy to construct social messages into message pairs with multi-relational sequences.","Secondly, a new multi-relational prompt-based pairwise message learning mechanism is proposed to learn more comprehensive message representation from message pairs with multi-relational prompts using PLMs.","Thirdly, we design a new clustering constraint to optimize the encoding process by enhancing intra-cluster compactness and inter-cluster dispersion, making the message representation more distinguishable.","We evaluate the RPLM_SED on three real-world datasets, demonstrating that the RPLM_SED model achieves state-of-the-art performance in offline, online, low-resource, and long-tail distribution scenarios for social event detection tasks."],"url":"http://arxiv.org/abs/2404.08263v1","category":"cs.CL"}
{"created":"2024-04-12 06:21:48","title":"Pretraining and Updating Language- and Domain-specific Large Language Model: A Case Study in Japanese Business Domain","abstract":"Several previous studies have considered language- and domain-specific large language models (LLMs) as separate topics. This study explores the combination of a non-English language and a high-demand industry domain, focusing on a Japanese business-specific LLM. This type of a model requires expertise in the business domain, strong language skills, and regular updates of its knowledge. We trained a 13-billion-parameter LLM from scratch using a new dataset of business texts and patents, and continually pretrained it with the latest business documents. Further we propose a new benchmark for Japanese business domain question answering (QA) and evaluate our models on it. The results show that our pretrained model improves QA accuracy without losing general knowledge, and that continual pretraining enhances adaptation to new information. Our pretrained model and business domain benchmark are publicly available.","sentences":["Several previous studies have considered language- and domain-specific large language models (LLMs) as separate topics.","This study explores the combination of a non-English language and a high-demand industry domain, focusing on a Japanese business-specific LLM.","This type of a model requires expertise in the business domain, strong language skills, and regular updates of its knowledge.","We trained a 13-billion-parameter LLM from scratch using a new dataset of business texts and patents, and continually pretrained it with the latest business documents.","Further we propose a new benchmark for Japanese business domain question answering (QA) and evaluate our models on it.","The results show that our pretrained model improves QA accuracy without losing general knowledge, and that continual pretraining enhances adaptation to new information.","Our pretrained model and business domain benchmark are publicly available."],"url":"http://arxiv.org/abs/2404.08262v1","category":"cs.CL"}
{"created":"2024-04-12 06:17:34","title":"Weakly o-minimal types","abstract":"We introduce and study weak o-minimality in the context of complete types in an arbitrary first-order theory. A type $p\\in S(A)$ is weakly o-minimal with respect to $<$, a relatively $A$-definable linear order on $p(\\mathfrak C)$, if every relatively definable subset has finitely many convex components; we prove that in that case the latter holds for all orders. Notably, we prove: (i) a monotonicity theorem for relatively definable functions on the locus of a weakly o-minimal type; (ii) weakly o-minimal types are dp-minimal, and the weak and forking non-orthogonality are equivalence relations on weakly o-minimal types. For a weakly o-minimal pair $\\mathbf p=(p,<)$, we introduce the notions of the left- and right-$\\mathbf p$-genericity of $a\\models p$ over $B$; the latter is denoted by $B\\triangleleft^{\\mathbf p}a$. We prove that $\\triangleleft^{\\mathbf p}$ behaves particularly well on realizations of $p$: the $\\triangleleft^{\\mathbf p}$-incomparability and forking-dependence of $x$ and $y$ over the domain of $p$ are the same equivalence relation and the quotient order is dense linear. We show that this naturally generalizes to the set of realizations of weakly o-minimal types from a fixed $\\not\\perp^w$-class.","sentences":["We introduce and study weak o-minimality in the context of complete types in an arbitrary first-order theory.","A type $p\\in S(A)$ is weakly o-minimal with respect to $<$, a relatively $A$-definable linear order on $p(\\mathfrak C)$, if every relatively definable subset has finitely many convex components; we prove that in that case the latter holds for all orders.","Notably, we prove: (i) a monotonicity theorem for relatively definable functions on the locus of a weakly o-minimal type; (ii) weakly o-minimal types are dp-minimal, and the weak and forking non-orthogonality are equivalence relations on weakly o-minimal types.","For a weakly o-minimal pair $\\mathbf p=(p,<)$, we introduce the notions of the left- and right-$\\mathbf p$-genericity of $a\\models p$ over $B$; the latter is denoted by $B\\triangleleft^{\\mathbf p}a$.","We prove that $\\triangleleft^{\\mathbf p}$ behaves particularly well on realizations of $p$: the $\\triangleleft^{\\mathbf p}$-incomparability and forking-dependence of $x$ and $y$ over the domain of $p$ are the same equivalence relation and the quotient order is dense linear.","We show that this naturally generalizes to the set of realizations of weakly o-minimal types from a fixed $\\not\\perp^w$-class."],"url":"http://arxiv.org/abs/2404.08260v1","category":"math.LO"}
{"created":"2024-04-12 06:16:26","title":"Investigating Neural Machine Translation for Low-Resource Languages: Using Bavarian as a Case Study","abstract":"Machine Translation has made impressive progress in recent years offering close to human-level performance on many languages, but studies have primarily focused on high-resource languages with broad online presence and resources. With the help of growing Large Language Models, more and more low-resource languages achieve better results through the presence of other languages. However, studies have shown that not all low-resource languages can benefit from multilingual systems, especially those with insufficient training and evaluation data. In this paper, we revisit state-of-the-art Neural Machine Translation techniques to develop automatic translation systems between German and Bavarian. We investigate conditions of low-resource languages such as data scarcity and parameter sensitivity and focus on refined solutions that combat low-resource difficulties and creative solutions such as harnessing language similarity. Our experiment entails applying Back-translation and Transfer Learning to automatically generate more training data and achieve higher translation performance. We demonstrate noisiness in the data and present our approach to carry out text preprocessing extensively. Evaluation was conducted using combined metrics: BLEU, chrF and TER. Statistical significance results with Bonferroni correction show surprisingly high baseline systems, and that Back-translation leads to significant improvement. Furthermore, we present a qualitative analysis of translation errors and system limitations.","sentences":["Machine Translation has made impressive progress in recent years offering close to human-level performance on many languages, but studies have primarily focused on high-resource languages with broad online presence and resources.","With the help of growing Large Language Models, more and more low-resource languages achieve better results through the presence of other languages.","However, studies have shown that not all low-resource languages can benefit from multilingual systems, especially those with insufficient training and evaluation data.","In this paper, we revisit state-of-the-art Neural Machine Translation techniques to develop automatic translation systems between German and Bavarian.","We investigate conditions of low-resource languages such as data scarcity and parameter sensitivity and focus on refined solutions that combat low-resource difficulties and creative solutions such as harnessing language similarity.","Our experiment entails applying Back-translation and Transfer Learning to automatically generate more training data and achieve higher translation performance.","We demonstrate noisiness in the data and present our approach to carry out text preprocessing extensively.","Evaluation was conducted using combined metrics: BLEU, chrF and TER.","Statistical significance results with Bonferroni correction show surprisingly high baseline systems, and that Back-translation leads to significant improvement.","Furthermore, we present a qualitative analysis of translation errors and system limitations."],"url":"http://arxiv.org/abs/2404.08259v1","category":"cs.CL"}
{"created":"2024-04-12 06:15:41","title":"Vibrational heating and photodissociation of admolecules induced by plasmonic hot carriers","abstract":"The hot carriers generated by plasmon damping hold significant potential for photoelectric conversion and photocatalysis. Despite numerous experiments and theoretical analyses, the precise role of plasmonic hot carriers in such dynamical processes has not been well understood. Here we present a theory of plasmonic photocatalysis based on the microscopic model of electron-vibrational coupling and the vibrational heating mechanism. The nonthermal hot carrier distribution was derived and treated on equal footing with the thermal Fermi-Dirac distribution. The inelastic rates of vibrational excitations were calculated including the effect of multiple electronic transitions. As an example of application, the O$_2$ dissociation on silver nanoparticles was explored with focus on the temperature- and light-intensity dependences. The dissociation rate evolves from a linear regime into a superlinear regime due to the onset of vibrational heating induced by hot carriers. In the nonlinear regime, nonthermal hot carriers greatly promote molecular dissociation. Our findings provide insight into plasmonic photocatalysis, and paves the way for harnessing light energies in the nonthermal regime.","sentences":["The hot carriers generated by plasmon damping hold significant potential for photoelectric conversion and photocatalysis.","Despite numerous experiments and theoretical analyses, the precise role of plasmonic hot carriers in such dynamical processes has not been well understood.","Here we present a theory of plasmonic photocatalysis based on the microscopic model of electron-vibrational coupling and the vibrational heating mechanism.","The nonthermal hot carrier distribution was derived and treated on equal footing with the thermal Fermi-Dirac distribution.","The inelastic rates of vibrational excitations were calculated including the effect of multiple electronic transitions.","As an example of application, the O$_2$ dissociation on silver nanoparticles was explored with focus on the temperature- and light-intensity dependences.","The dissociation rate evolves from a linear regime into a superlinear regime due to the onset of vibrational heating induced by hot carriers.","In the nonlinear regime, nonthermal hot carriers greatly promote molecular dissociation.","Our findings provide insight into plasmonic photocatalysis, and paves the way for harnessing light energies in the nonthermal regime."],"url":"http://arxiv.org/abs/2404.08258v1","category":"cond-mat.mtrl-sci"}
{"created":"2024-04-12 06:13:33","title":"The $C^0$-inextendibility of some spatially flat FLRW spacetimes","abstract":"Utilizing some of Sbierski's recent $C^0$-inextendibility techniques [13], we prove the $C^0$-inextendibility of a class of spatially flat FLRW spacetimes without particle horizons.","sentences":["Utilizing some of Sbierski's recent $C^0$-inextendibility techniques [13], we prove the $C^0$-inextendibility of a class of spatially flat FLRW spacetimes without particle horizons."],"url":"http://arxiv.org/abs/2404.08257v1","category":"gr-qc"}
{"created":"2024-04-12 06:08:43","title":"Balanced Mixed-Type Tabular Data Synthesis with Diffusion Models","abstract":"Diffusion models have emerged as a robust framework for various generative tasks, such as image and audio synthesis, and have also demonstrated a remarkable ability to generate mixed-type tabular data comprising both continuous and discrete variables. However, current approaches to training diffusion models on mixed-type tabular data tend to inherit the imbalanced distributions of features present in the training dataset, which can result in biased sampling. In this research, we introduce a fair diffusion model designed to generate balanced data on sensitive attributes. We present empirical evidence demonstrating that our method effectively mitigates the class imbalance in training data while maintaining the quality of the generated samples. Furthermore, we provide evidence that our approach outperforms existing methods for synthesizing tabular data in terms of performance and fairness.","sentences":["Diffusion models have emerged as a robust framework for various generative tasks, such as image and audio synthesis, and have also demonstrated a remarkable ability to generate mixed-type tabular data comprising both continuous and discrete variables.","However, current approaches to training diffusion models on mixed-type tabular data tend to inherit the imbalanced distributions of features present in the training dataset, which can result in biased sampling.","In this research, we introduce a fair diffusion model designed to generate balanced data on sensitive attributes.","We present empirical evidence demonstrating that our method effectively mitigates the class imbalance in training data while maintaining the quality of the generated samples.","Furthermore, we provide evidence that our approach outperforms existing methods for synthesizing tabular data in terms of performance and fairness."],"url":"http://arxiv.org/abs/2404.08254v1","category":"cs.LG"}
{"created":"2024-04-12 05:37:42","title":"A Systematic Construction Approach for All $4\\times 4$ Involutory MDS Matrices","abstract":"Maximum distance separable (MDS) matrices play a crucial role not only in coding theory but also in the design of block ciphers and hash functions. Of particular interest are involutory MDS matrices, which facilitate the use of a single circuit for both encryption and decryption in hardware implementations. In this article, we present several characterizations of involutory MDS matrices of even order. Additionally, we introduce a new matrix form for obtaining all involutory MDS matrices of even order and compare it with other matrix forms available in the literature. We then propose a technique to systematically construct all $4 \\times 4$ involutory MDS matrices over a finite field $\\mathbb{F}_{2^m}$. This method significantly reduces the search space by focusing on involutory MDS class representative matrices, leading to the generation of all such matrices within a substantially smaller set compared to considering all $4 \\times 4$ involutory matrices. Specifically, our approach involves searching for these representative matrices within a set of cardinality $(2^m-1)^5$. Through this method, we provide an explicit enumeration of the total number of $4 \\times 4$ involutory MDS matrices over $\\mathbb{F}_{2^m}$ for $m=3,4,\\ldots,8$.","sentences":["Maximum distance separable (MDS) matrices play a crucial role not only in coding theory but also in the design of block ciphers and hash functions.","Of particular interest are involutory MDS matrices, which facilitate the use of a single circuit for both encryption and decryption in hardware implementations.","In this article, we present several characterizations of involutory MDS matrices of even order.","Additionally, we introduce a new matrix form for obtaining all involutory MDS matrices of even order and compare it with other matrix forms available in the literature.","We then propose a technique to systematically construct all $4 \\times 4$ involutory MDS matrices over a finite field $\\mathbb{F}_{2^m}$. This method significantly reduces the search space by focusing on involutory MDS class representative matrices, leading to the generation of all such matrices within a substantially smaller set compared to considering all $4 \\times 4$ involutory matrices.","Specifically, our approach involves searching for these representative matrices within a set of cardinality $(2^m-1)^5$. Through this method, we provide an explicit enumeration of the total number of $4 \\times 4$ involutory MDS matrices over $\\mathbb{F}_{2^m}$ for $m=3,4,\\ldots,8$."],"url":"http://arxiv.org/abs/2404.08250v1","category":"cs.CR"}
{"created":"2024-04-12 05:25:03","title":"Agile and versatile bipedal robot tracking control through reinforcement learning","abstract":"The remarkable athletic intelligence displayed by humans in complex dynamic movements such as dancing and gymnastics suggests that the balance mechanism in biological beings is decoupled from specific movement patterns. This decoupling allows for the execution of both learned and unlearned movements under certain constraints while maintaining balance through minor whole-body coordination. To replicate this balance ability and body agility, this paper proposes a versatile controller for bipedal robots. This controller achieves ankle and body trajectory tracking across a wide range of gaits using a single small-scale neural network, which is based on a model-based IK solver and reinforcement learning. We consider a single step as the smallest control unit and design a universally applicable control input form suitable for any single-step variation. Highly flexible gait control can be achieved by combining these minimal control units with high-level policy through our extensible control interface. To enhance the trajectory-tracking capability of our controller, we utilize a three-stage training curriculum. After training, the robot can move freely between target footholds at varying distances and heights. The robot can also maintain static balance without repeated stepping to adjust posture. Finally, we evaluate the tracking accuracy of our controller on various bipedal tasks, and the effectiveness of our control framework is verified in the simulation environment.","sentences":["The remarkable athletic intelligence displayed by humans in complex dynamic movements such as dancing and gymnastics suggests that the balance mechanism in biological beings is decoupled from specific movement patterns.","This decoupling allows for the execution of both learned and unlearned movements under certain constraints while maintaining balance through minor whole-body coordination.","To replicate this balance ability and body agility, this paper proposes a versatile controller for bipedal robots.","This controller achieves ankle and body trajectory tracking across a wide range of gaits using a single small-scale neural network, which is based on a model-based IK solver and reinforcement learning.","We consider a single step as the smallest control unit and design a universally applicable control input form suitable for any single-step variation.","Highly flexible gait control can be achieved by combining these minimal control units with high-level policy through our extensible control interface.","To enhance the trajectory-tracking capability of our controller, we utilize a three-stage training curriculum.","After training, the robot can move freely between target footholds at varying distances and heights.","The robot can also maintain static balance without repeated stepping to adjust posture.","Finally, we evaluate the tracking accuracy of our controller on various bipedal tasks, and the effectiveness of our control framework is verified in the simulation environment."],"url":"http://arxiv.org/abs/2404.08246v1","category":"cs.RO"}
{"created":"2024-04-12 05:24:55","title":"A Distributed Approach for Persistent Homology Computation on a Large Scale","abstract":"Persistent homology (PH) is a powerful mathematical method to automatically extract relevant insights from images, such as those obtained by high-resolution imaging devices like electron microscopes or new-generation telescopes. However, the application of this method comes at a very high computational cost, that is bound to explode more because new imaging devices generate an ever-growing amount of data. In this paper we present PixHomology, a novel algorithm for efficiently computing $0$-dimensional PH on 2D images, optimizing memory and processing time. By leveraging the Apache Spark framework, we also present a distributed version of our algorithm with several optimized variants, able to concurrently process large batches of astronomical images. Finally, we present the results of an experimental analysis showing that our algorithm and its distributed version are efficient in terms of required memory, execution time, and scalability, consistently outperforming existing state-of-the-art PH computation tools when used to process large datasets.","sentences":["Persistent homology (PH) is a powerful mathematical method to automatically extract relevant insights from images, such as those obtained by high-resolution imaging devices like electron microscopes or new-generation telescopes.","However, the application of this method comes at a very high computational cost, that is bound to explode more because new imaging devices generate an ever-growing amount of data.","In this paper we present PixHomology, a novel algorithm for efficiently computing $0$-dimensional PH on 2D images, optimizing memory and processing time.","By leveraging the Apache Spark framework, we also present a distributed version of our algorithm with several optimized variants, able to concurrently process large batches of astronomical images.","Finally, we present the results of an experimental analysis showing that our algorithm and its distributed version are efficient in terms of required memory, execution time, and scalability, consistently outperforming existing state-of-the-art PH computation tools when used to process large datasets."],"url":"http://arxiv.org/abs/2404.08245v1","category":"cs.DC"}
{"created":"2024-04-12 05:12:22","title":"Thermodynamic topology of Phantom AdS Black Holes in Massive Gravity","abstract":"In this work, we explore the thermodynamic topology of phantom AdS black holes in the context of massive gravity. To this end, we evaluate these black holes in two distinct ensembles: the canonical and grand canonical ensembles (GCE). We begin by examining the topological charge linked to the critical point and confirming the existence of a conventional critical point $(CP_{1})$ in the canonical ensemble (CE), this critical point has a topological charge of $-1$ and acts as a point of phase annihilation, this situation can only be considered within the context of the classical Einstein-Maxwell (CEM) theory $(\\eta=1)$, while no critical point is identified in the GCE. Furthermore, we consider black holes as a topological defect within the thermodynamic space. To gain an understanding of the local and global topological configuration of this defect, we will analyze its winding numbers, and observe that the total topological charge in the CE consistently remains at $1$. When the system experiences a pressure below the critical threshold, it gives rise to the occurrence of annihilation and generation points. The value of electric potential determines whether the total topological charge in the GCE is zero or one. As a result, we detect a point of generation point or absence of generation/annihilation point. Based on our analysis, it can be inferred that ensembles significantly impact the topological class of phantom AdS black holes in massive gravity.","sentences":["In this work, we explore the thermodynamic topology of phantom AdS black holes in the context of massive gravity.","To this end, we evaluate these black holes in two distinct ensembles: the canonical and grand canonical ensembles (GCE).","We begin by examining the topological charge linked to the critical point and confirming the existence of a conventional critical point $(CP_{1})$ in the canonical ensemble (CE), this critical point has a topological charge of $-1$ and acts as a point of phase annihilation, this situation can only be considered within the context of the classical Einstein-Maxwell (CEM) theory $(\\eta=1)$, while no critical point is identified in the GCE.","Furthermore, we consider black holes as a topological defect within the thermodynamic space.","To gain an understanding of the local and global topological configuration of this defect, we will analyze its winding numbers, and observe that the total topological charge in the CE consistently remains at $1$. When the system experiences a pressure below the critical threshold, it gives rise to the occurrence of annihilation and generation points.","The value of electric potential determines whether the total topological charge in the GCE is zero or one.","As a result, we detect a point of generation point or absence of generation/annihilation point.","Based on our analysis, it can be inferred that ensembles significantly impact the topological class of phantom AdS black holes in massive gravity."],"url":"http://arxiv.org/abs/2404.08243v1","category":"gr-qc"}
{"created":"2024-04-12 05:02:49","title":"RLEMMO: Evolutionary Multimodal Optimization Assisted By Deep Reinforcement Learning","abstract":"Solving multimodal optimization problems (MMOP) requires finding all optimal solutions, which is challenging in limited function evaluations. Although existing works strike the balance of exploration and exploitation through hand-crafted adaptive strategies, they require certain expert knowledge, hence inflexible to deal with MMOP with different properties. In this paper, we propose RLEMMO, a Meta-Black-Box Optimization framework, which maintains a population of solutions and incorporates a reinforcement learning agent for flexibly adjusting individual-level searching strategies to match the up-to-date optimization status, hence boosting the search performance on MMOP. Concretely, we encode landscape properties and evolution path information into each individual and then leverage attention networks to advance population information sharing. With a novel reward mechanism that encourages both quality and diversity, RLEMMO can be effectively trained using a policy gradient algorithm. The experimental results on the CEC2013 MMOP benchmark underscore the competitive optimization performance of RLEMMO against several strong baselines.","sentences":["Solving multimodal optimization problems (MMOP) requires finding all optimal solutions, which is challenging in limited function evaluations.","Although existing works strike the balance of exploration and exploitation through hand-crafted adaptive strategies, they require certain expert knowledge, hence inflexible to deal with MMOP with different properties.","In this paper, we propose RLEMMO, a Meta-Black-Box Optimization framework, which maintains a population of solutions and incorporates a reinforcement learning agent for flexibly adjusting individual-level searching strategies to match the up-to-date optimization status, hence boosting the search performance on MMOP.","Concretely, we encode landscape properties and evolution path information into each individual and then leverage attention networks to advance population information sharing.","With a novel reward mechanism that encourages both quality and diversity, RLEMMO can be effectively trained using a policy gradient algorithm.","The experimental results on the CEC2013 MMOP benchmark underscore the competitive optimization performance of RLEMMO against several strong baselines."],"url":"http://arxiv.org/abs/2404.08242v1","category":"cs.NE"}
{"created":"2024-04-12 04:48:32","title":"Auto-configuring Exploration-Exploitation Tradeoff in Evolutionary Computation via Deep Reinforcement Learning","abstract":"Evolutionary computation (EC) algorithms, renowned as powerful black-box optimizers, leverage a group of individuals to cooperatively search for the optimum. The exploration-exploitation tradeoff (EET) plays a crucial role in EC, which, however, has traditionally been governed by manually designed rules. In this paper, we propose a deep reinforcement learning-based framework that autonomously configures and adapts the EET throughout the EC search process. The framework allows different individuals of the population to selectively attend to the global and local exemplars based on the current search state, maximizing the cooperative search outcome. Our proposed framework is characterized by its simplicity, effectiveness, and generalizability, with the potential to enhance numerous existing EC algorithms. To validate its capabilities, we apply our framework to several representative EC algorithms and conduct extensive experiments on the augmented CEC2021 benchmark. The results demonstrate significant improvements in the performance of the backbone algorithms, as well as favorable generalization across diverse problem classes, dimensions, and population sizes. Additionally, we provide an in-depth analysis of the EET issue by interpreting the learned behaviors of EC.","sentences":["Evolutionary computation (EC) algorithms, renowned as powerful black-box optimizers, leverage a group of individuals to cooperatively search for the optimum.","The exploration-exploitation tradeoff (EET) plays a crucial role in EC, which, however, has traditionally been governed by manually designed rules.","In this paper, we propose a deep reinforcement learning-based framework that autonomously configures and adapts the EET throughout the EC search process.","The framework allows different individuals of the population to selectively attend to the global and local exemplars based on the current search state, maximizing the cooperative search outcome.","Our proposed framework is characterized by its simplicity, effectiveness, and generalizability, with the potential to enhance numerous existing EC algorithms.","To validate its capabilities, we apply our framework to several representative EC algorithms and conduct extensive experiments on the augmented CEC2021 benchmark.","The results demonstrate significant improvements in the performance of the backbone algorithms, as well as favorable generalization across diverse problem classes, dimensions, and population sizes.","Additionally, we provide an in-depth analysis of the EET issue by interpreting the learned behaviors of EC."],"url":"http://arxiv.org/abs/2404.08239v1","category":"cs.NE"}
{"created":"2024-04-12 04:44:11","title":"IFViT: Interpretable Fixed-Length Representation for Fingerprint Matching via Vision Transformer","abstract":"Determining dense feature points on fingerprints used in constructing deep fixed-length representations for accurate matching, particularly at the pixel level, is of significant interest. To explore the interpretability of fingerprint matching, we propose a multi-stage interpretable fingerprint matching network, namely Interpretable Fixed-length Representation for Fingerprint Matching via Vision Transformer (IFViT), which consists of two primary modules. The first module, an interpretable dense registration module, establishes a Vision Transformer (ViT)-based Siamese Network to capture long-range dependencies and the global context in fingerprint pairs. It provides interpretable dense pixel-wise correspondences of feature points for fingerprint alignment and enhances the interpretability in the subsequent matching stage. The second module takes into account both local and global representations of the aligned fingerprint pair to achieve an interpretable fixed-length representation extraction and matching. It employs the ViTs trained in the first module with the additional fully connected layer and retrains them to simultaneously produce the discriminative fixed-length representation and interpretable dense pixel-wise correspondences of feature points. Extensive experimental results on diverse publicly available fingerprint databases demonstrate that the proposed framework not only exhibits superior performance on dense registration and matching but also significantly promotes the interpretability in deep fixed-length representations-based fingerprint matching.","sentences":["Determining dense feature points on fingerprints used in constructing deep fixed-length representations for accurate matching, particularly at the pixel level, is of significant interest.","To explore the interpretability of fingerprint matching, we propose a multi-stage interpretable fingerprint matching network, namely Interpretable Fixed-length Representation for Fingerprint Matching via Vision Transformer (IFViT), which consists of two primary modules.","The first module, an interpretable dense registration module, establishes a Vision Transformer (ViT)-based Siamese Network to capture long-range dependencies and the global context in fingerprint pairs.","It provides interpretable dense pixel-wise correspondences of feature points for fingerprint alignment and enhances the interpretability in the subsequent matching stage.","The second module takes into account both local and global representations of the aligned fingerprint pair to achieve an interpretable fixed-length representation extraction and matching.","It employs the ViTs trained in the first module with the additional fully connected layer and retrains them to simultaneously produce the discriminative fixed-length representation and interpretable dense pixel-wise correspondences of feature points.","Extensive experimental results on diverse publicly available fingerprint databases demonstrate that the proposed framework not only exhibits superior performance on dense registration and matching but also significantly promotes the interpretability in deep fixed-length representations-based fingerprint matching."],"url":"http://arxiv.org/abs/2404.08237v1","category":"cs.CV"}
{"created":"2024-04-12 04:23:20","title":"Generalized Population-Based Training for Hyperparameter Optimization in Reinforcement Learning","abstract":"Hyperparameter optimization plays a key role in the machine learning domain. Its significance is especially pronounced in reinforcement learning (RL), where agents continuously interact with and adapt to their environments, requiring dynamic adjustments in their learning trajectories. To cater to this dynamicity, the Population-Based Training (PBT) was introduced, leveraging the collective intelligence of a population of agents learning simultaneously. However, PBT tends to favor high-performing agents, potentially neglecting the explorative potential of agents on the brink of significant advancements. To mitigate the limitations of PBT, we present the Generalized Population-Based Training (GPBT), a refined framework designed for enhanced granularity and flexibility in hyperparameter adaptation. Complementing GPBT, we further introduce Pairwise Learning (PL). Instead of merely focusing on elite agents, PL employs a comprehensive pairwise strategy to identify performance differentials and provide holistic guidance to underperforming agents. By integrating the capabilities of GPBT and PL, our approach significantly improves upon traditional PBT in terms of adaptability and computational efficiency. Rigorous empirical evaluations across a range of RL benchmarks confirm that our approach consistently outperforms not only the conventional PBT but also its Bayesian-optimized variant.","sentences":["Hyperparameter optimization plays a key role in the machine learning domain.","Its significance is especially pronounced in reinforcement learning (RL), where agents continuously interact with and adapt to their environments, requiring dynamic adjustments in their learning trajectories.","To cater to this dynamicity, the Population-Based Training (PBT) was introduced, leveraging the collective intelligence of a population of agents learning simultaneously.","However, PBT tends to favor high-performing agents, potentially neglecting the explorative potential of agents on the brink of significant advancements.","To mitigate the limitations of PBT, we present the Generalized Population-Based Training (GPBT), a refined framework designed for enhanced granularity and flexibility in hyperparameter adaptation.","Complementing GPBT, we further introduce Pairwise Learning (PL).","Instead of merely focusing on elite agents, PL employs a comprehensive pairwise strategy to identify performance differentials and provide holistic guidance to underperforming agents.","By integrating the capabilities of GPBT and PL, our approach significantly improves upon traditional PBT in terms of adaptability and computational efficiency.","Rigorous empirical evaluations across a range of RL benchmarks confirm that our approach consistently outperforms not only the conventional PBT but also its Bayesian-optimized variant."],"url":"http://arxiv.org/abs/2404.08233v1","category":"cs.LG"}
{"created":"2024-04-12 04:08:21","title":"Enhancing Traffic Safety with Parallel Dense Video Captioning for End-to-End Event Analysis","abstract":"This paper introduces our solution for Track 2 in AI City Challenge 2024. The task aims to solve traffic safety description and analysis with the dataset of Woven Traffic Safety (WTS), a real-world Pedestrian-Centric Traffic Video Dataset for Fine-grained Spatial-Temporal Understanding. Our solution mainly focuses on the following points: 1) To solve dense video captioning, we leverage the framework of dense video captioning with parallel decoding (PDVC) to model visual-language sequences and generate dense caption by chapters for video. 2) Our work leverages CLIP to extract visual features to more efficiently perform cross-modality training between visual and textual representations. 3) We conduct domain-specific model adaptation to mitigate domain shift problem that poses recognition challenge in video understanding. 4) Moreover, we leverage BDD-5K captioned videos to conduct knowledge transfer for better understanding WTS videos and more accurate captioning. Our solution has yielded on the test set, achieving 6th place in the competition. The open source code will be available at https://github.com/UCF-SST-Lab/AICity2024CVPRW","sentences":["This paper introduces our solution for Track 2 in AI City Challenge 2024.","The task aims to solve traffic safety description and analysis with the dataset of Woven Traffic Safety (WTS), a real-world Pedestrian-Centric Traffic Video Dataset for Fine-grained Spatial-Temporal Understanding.","Our solution mainly focuses on the following points: 1) To solve dense video captioning, we leverage the framework of dense video captioning with parallel decoding (PDVC) to model visual-language sequences and generate dense caption by chapters for video.","2) Our work leverages CLIP to extract visual features to more efficiently perform cross-modality training between visual and textual representations.","3) We conduct domain-specific model adaptation to mitigate domain shift problem that poses recognition challenge in video understanding.","4) Moreover, we leverage BDD-5K captioned videos to conduct knowledge transfer for better understanding WTS videos and more accurate captioning.","Our solution has yielded on the test set, achieving 6th place in the competition.","The open source code will be available at https://github.com/UCF-SST-Lab/AICity2024CVPRW"],"url":"http://arxiv.org/abs/2404.08229v1","category":"cs.CV"}
{"created":"2024-04-12 03:43:37","title":"Improving Continuous Sign Language Recognition with Adapted Image Models","abstract":"The increase of web-scale weakly labelled image-text pairs have greatly facilitated the development of large-scale vision-language models (e.g., CLIP), which have shown impressive generalization performance over a series of downstream tasks. However, the massive model size and scarcity of available data limit their applications to fine-tune the whole model in downstream tasks. Besides, fully fine-tuning the model easily forgets the generic essential knowledge acquired in the pretraining stage and overfits the downstream data. To enable high efficiency when adapting these large vision-language models (e.g., CLIP) to performing continuous sign language recognition (CSLR) while preserving their generalizability, we propose a novel strategy (AdaptSign). Especially, CLIP is adopted as the visual backbone to extract frame-wise features whose parameters are fixed, and a set of learnable modules are introduced to model spatial sign variations or capture temporal sign movements. The introduced additional modules are quite lightweight, only owning 3.2% extra computations with high efficiency. The generic knowledge acquired in the pretraining stage is well-preserved in the frozen CLIP backbone in this process. Extensive experiments show that despite being efficient, AdaptSign is able to demonstrate superior performance across a series of CSLR benchmarks including PHOENIX14, PHOENIX14-T, CSL-Daily and CSL compared to existing methods. Visualizations show that AdaptSign could learn to dynamically pay major attention to the informative spatial regions and cross-frame trajectories in sign videos.","sentences":["The increase of web-scale weakly labelled image-text pairs have greatly facilitated the development of large-scale vision-language models (e.g., CLIP), which have shown impressive generalization performance over a series of downstream tasks.","However, the massive model size and scarcity of available data limit their applications to fine-tune the whole model in downstream tasks.","Besides, fully fine-tuning the model easily forgets the generic essential knowledge acquired in the pretraining stage and overfits the downstream data.","To enable high efficiency when adapting these large vision-language models (e.g., CLIP) to performing continuous sign language recognition (CSLR) while preserving their generalizability, we propose a novel strategy (AdaptSign).","Especially, CLIP is adopted as the visual backbone to extract frame-wise features whose parameters are fixed, and a set of learnable modules are introduced to model spatial sign variations or capture temporal sign movements.","The introduced additional modules are quite lightweight, only owning 3.2% extra computations with high efficiency.","The generic knowledge acquired in the pretraining stage is well-preserved in the frozen CLIP backbone in this process.","Extensive experiments show that despite being efficient, AdaptSign is able to demonstrate superior performance across a series of CSLR benchmarks including PHOENIX14, PHOENIX14-T, CSL-Daily and CSL compared to existing methods.","Visualizations show that AdaptSign could learn to dynamically pay major attention to the informative spatial regions and cross-frame trajectories in sign videos."],"url":"http://arxiv.org/abs/2404.08226v1","category":"cs.CV"}
{"created":"2024-04-12 03:39:33","title":"HCL-MTSAD: Hierarchical Contrastive Consistency Learning for Accurate Detection of Industrial Multivariate Time Series Anomalies","abstract":"Multivariate Time Series (MTS) anomaly detection focuses on pinpointing samples that diverge from standard operational patterns, which is crucial for ensuring the safety and security of industrial applications. The primary challenge in this domain is to develop representations capable of discerning anomalies effectively. The prevalent methods for anomaly detection in the literature are predominantly reconstruction-based and predictive in nature. However, they typically concentrate on a single-dimensional instance level, thereby not fully harnessing the complex associations inherent in industrial MTS. To address this issue, we propose a novel self-supervised hierarchical contrastive consistency learning method for detecting anomalies in MTS, named HCL-MTSAD. It innovatively leverages data consistency at multiple levels inherent in industrial MTS, systematically capturing consistent associations across four latent levels-measurement, sample, channel, and process. By developing a multi-layer contrastive loss, HCL-MTSAD can extensively mine data consistency and spatio-temporal association, resulting in more informative representations. Subsequently, an anomaly discrimination module, grounded in self-supervised hierarchical contrastive learning, is designed to detect timestamp-level anomalies by calculating multi-scale data consistency. Extensive experiments conducted on six diverse MTS datasets retrieved from real cyber-physical systems and server machines, in comparison with 20 baselines, indicate that HCL-MTSAD's anomaly detection capability outperforms the state-of-the-art benchmark models by an average of 1.8\\% in terms of F1 score.","sentences":["Multivariate Time Series (MTS) anomaly detection focuses on pinpointing samples that diverge from standard operational patterns, which is crucial for ensuring the safety and security of industrial applications.","The primary challenge in this domain is to develop representations capable of discerning anomalies effectively.","The prevalent methods for anomaly detection in the literature are predominantly reconstruction-based and predictive in nature.","However, they typically concentrate on a single-dimensional instance level, thereby not fully harnessing the complex associations inherent in industrial MTS.","To address this issue, we propose a novel self-supervised hierarchical contrastive consistency learning method for detecting anomalies in MTS, named HCL-MTSAD.","It innovatively leverages data consistency at multiple levels inherent in industrial MTS, systematically capturing consistent associations across four latent levels-measurement, sample, channel, and process.","By developing a multi-layer contrastive loss, HCL-MTSAD can extensively mine data consistency and spatio-temporal association, resulting in more informative representations.","Subsequently, an anomaly discrimination module, grounded in self-supervised hierarchical contrastive learning, is designed to detect timestamp-level anomalies by calculating multi-scale data consistency.","Extensive experiments conducted on six diverse MTS datasets retrieved from real cyber-physical systems and server machines, in comparison with 20 baselines, indicate that HCL-MTSAD's anomaly detection capability outperforms the state-of-the-art benchmark models by an average of 1.8\\% in terms of F1 score."],"url":"http://arxiv.org/abs/2404.08224v1","category":"cs.LG"}
{"created":"2024-04-12 03:37:27","title":"Subspace method based on neural networks for solving the partial differential equation","abstract":"We present a subspace method based on neural networks (SNN) for solving the partial differential equation with high accuracy. The basic idea of our method is to use some functions based on neural networks as base functions to span a subspace, then find an approximate solution in this subspace. We design two special algorithms in the strong form of partial differential equation. One algorithm enforces the equation and initial boundary conditions to hold on some collocation points, and another algorithm enforces $L^2$-norm of the residual of the equation and initial boundary conditions to be $0$. Our method can achieve high accuracy with low cost of training. Moreover, our method is free of parameters that need to be artificially adjusted. Numerical examples show that the cost of training these base functions of subspace is low, and only one hundred to two thousand epochs are needed for most tests. The error of our method can even fall below the level of $10^{-10}$ for some tests. The performance of our method significantly surpasses the performance of PINN and DGM in terms of the accuracy and computational cost.","sentences":["We present a subspace method based on neural networks (SNN) for solving the partial differential equation with high accuracy.","The basic idea of our method is to use some functions based on neural networks as base functions to span a subspace, then find an approximate solution in this subspace.","We design two special algorithms in the strong form of partial differential equation.","One algorithm enforces the equation and initial boundary conditions to hold on some collocation points, and another algorithm enforces $L^2$-norm of the residual of the equation and initial boundary conditions to be $0$.","Our method can achieve high accuracy with low cost of training.","Moreover, our method is free of parameters that need to be artificially adjusted.","Numerical examples show that the cost of training these base functions of subspace is low, and only one hundred to two thousand epochs are needed for most tests.","The error of our method can even fall below the level of $10^{-10}$ for some tests.","The performance of our method significantly surpasses the performance of PINN and DGM in terms of the accuracy and computational cost."],"url":"http://arxiv.org/abs/2404.08223v1","category":"math.NA"}
{"created":"2024-04-12 02:56:41","title":"Role of nonlocal heat transport on the laser ablative Rayleigh-Taylor instability","abstract":"Ablative Rayleigh-Taylor instability (ARTI) and nonlocal heat transport are the critical problems in laser-driven inertial confinement fusion, while their coupling with each other is not completely understood yet. Here the ARTI in the presence of nonlocal heat transport is studied self-consistently for the first time theoretically and by using radiation hydrodynamic simulations. It is found that the nonlocal heat flux generated by the hot electron transport tends to attenuate the growth of instability, especially for short wavelength perturbations. A linear theory of the ARTI coupled with the nonlocal heat flux is developed, and a prominent stabilization of the ablation front via the nonlocal heat flux is found, in good agreement with numerical simulations. This effect becomes more significant as the laser intensity increases. Our results should have important references for the target designing for inertial confinement fusion.","sentences":["Ablative Rayleigh-Taylor instability (ARTI) and nonlocal heat transport are the critical problems in laser-driven inertial confinement fusion, while their coupling with each other is not completely understood yet.","Here the ARTI in the presence of nonlocal heat transport is studied self-consistently for the first time theoretically and by using radiation hydrodynamic simulations.","It is found that the nonlocal heat flux generated by the hot electron transport tends to attenuate the growth of instability, especially for short wavelength perturbations.","A linear theory of the ARTI coupled with the nonlocal heat flux is developed, and a prominent stabilization of the ablation front via the nonlocal heat flux is found, in good agreement with numerical simulations.","This effect becomes more significant as the laser intensity increases.","Our results should have important references for the target designing for inertial confinement fusion."],"url":"http://arxiv.org/abs/2404.08216v1","category":"physics.plasm-ph"}
{"created":"2024-04-12 02:55:08","title":"Stability and noncentered PT symmetry of real topological phases","abstract":"Real topological phases protected by the spacetime inversion (P T) symmetry are a current research focus. The basis is that the P T symmetry endows a real structure in momentum space, which leads to Z2 topological classifications in 1D and 2D. Here, we provide solutions to two outstanding problems in the diagnosis of real topology. First, based on the stable equivalence in K-theory, we clarify that the 2D topological invariant remains well defined in the presence of nontrivial 1D invariant, and we develop a general numerical approach for its evaluation, which was hitherto unavailable. Second, under the unit-cell convention, noncentered P T symmetries assume momentum dependence, which violates the presumption in previous methods for computing the topological invariants. We clarify the classifications for this case and formulate the invariants by introducing a twisted Wilson-loop operator for both 1D and 2D. A simple model on a rectangular lattice is constructed to demonstrate our theory, which can be readily realized using artificial crystals.","sentences":["Real topological phases protected by the spacetime inversion (P T) symmetry are a current research focus.","The basis is that the P T symmetry endows a real structure in momentum space, which leads to Z2 topological classifications in 1D and 2D. Here, we provide solutions to two outstanding problems in the diagnosis of real topology.","First, based on the stable equivalence in K-theory, we clarify that the 2D topological invariant remains well defined in the presence of nontrivial 1D invariant, and we develop a general numerical approach for its evaluation, which was hitherto unavailable.","Second, under the unit-cell convention, noncentered P T symmetries assume momentum dependence, which violates the presumption in previous methods for computing the topological invariants.","We clarify the classifications for this case and formulate the invariants by introducing a twisted Wilson-loop operator for both 1D and 2D. A simple model on a rectangular lattice is constructed to demonstrate our theory, which can be readily realized using artificial crystals."],"url":"http://arxiv.org/abs/2404.08215v1","category":"cond-mat.mes-hall"}
{"created":"2024-04-12 02:48:48","title":"Mental Stress Detection: Development and Evaluation of a Wearable In-Ear Plethysmography","abstract":"Mental stress is a prevalent condition that can have negative impacts on one's health. Early detection and treatment are crucial for preventing related illnesses and maintaining overall wellness. This study presents a new method for identifying mental stress using a wearable biosensor worn in the ear. Data was gathered from 14 participants in a controlled environment using stress-inducing tasks such as memory and math tests. The raw photoplethysmography data was then processed by filtering, segmenting, and transforming it into scalograms using a continuous wavelet transform (CWT) which are based on two different mother wavelets, namely, a generalized Morse wavelet and the analytic Morlet (Gabor) wavelet. The scalograms were then passed through a convolutional neural network classifier, GoogLeNet, to classify the signals as stressed or non-stressed. The method achieved an outstanding result using the generalized Morse wavelet with an accuracy of 91.02% and an F1-score of 90.95%. This method demonstrates promise as a reliable tool for early detection and treatment of mental stress by providing real-time monitoring and allowing for preventive measures to be taken before it becomes a serious issue.","sentences":["Mental stress is a prevalent condition that can have negative impacts on one's health.","Early detection and treatment are crucial for preventing related illnesses and maintaining overall wellness.","This study presents a new method for identifying mental stress using a wearable biosensor worn in the ear.","Data was gathered from 14 participants in a controlled environment using stress-inducing tasks such as memory and math tests.","The raw photoplethysmography data was then processed by filtering, segmenting, and transforming it into scalograms using a continuous wavelet transform (CWT) which are based on two different mother wavelets, namely, a generalized Morse wavelet and the analytic Morlet (Gabor) wavelet.","The scalograms were then passed through a convolutional neural network classifier, GoogLeNet, to classify the signals as stressed or non-stressed.","The method achieved an outstanding result using the generalized Morse wavelet with an accuracy of 91.02% and an F1-score of 90.95%.","This method demonstrates promise as a reliable tool for early detection and treatment of mental stress by providing real-time monitoring and allowing for preventive measures to be taken before it becomes a serious issue."],"url":"http://arxiv.org/abs/2404.08212v1","category":"eess.SP"}
{"created":"2024-04-12 02:48:37","title":"Fractal spectrum in twisted bilayer optical lattice","abstract":"The translation symmetry of a lattice is greatly modified when subjected to a perpendicular magnetic field [Zak, Phys. Rev. \\textbf{134}, A1602 (1964)]. This change in symmetry can lead to magnetic unit cells that are substantially larger than the original ones. Similarly, the translation properties of a double-layered lattice alters drastically while two monolayers are relatively twisted by a small angle, resulting in large-scale moir\\'{e} unit cells. Intrigued by the resemblance, we calculate the complete band structures of a twisted bilayer optical lattice and show that the geometric moir\\'{e} effect can induce fractal band structures. The fractals are controlled by the twist angle between two monolayers and are closely connected to the celebrated butterfly spectrum of two-dimensional Bloch electrons in a magnetic field [Hofstadter, Phys. Rev. B \\textbf{14}, 2239 (1976)]. We demonstrate this by proving that the twisted bilayer optical lattice can be mapped to a generalized Hofstadter's model with long-range hopping. Furthermore, we provide numerical evidence on the infinite recursive structures of the spectrum and give an algorithm for computing these structures.","sentences":["The translation symmetry of a lattice is greatly modified when subjected to a perpendicular magnetic field","[Zak, Phys. Rev. \\textbf{134}, A1602 (1964)].","This change in symmetry can lead to magnetic unit cells that are substantially larger than the original ones.","Similarly, the translation properties of a double-layered lattice alters drastically while two monolayers are relatively twisted by a small angle, resulting in large-scale moir\\'{e} unit cells.","Intrigued by the resemblance, we calculate the complete band structures of a twisted bilayer optical lattice and show that the geometric moir\\'{e} effect can induce fractal band structures.","The fractals are controlled by the twist angle between two monolayers and are closely connected to the celebrated butterfly spectrum of two-dimensional Bloch electrons in a magnetic field","[Hofstadter, Phys.","Rev. B \\textbf{14}, 2239 (1976)].","We demonstrate this by proving that the twisted bilayer optical lattice can be mapped to a generalized Hofstadter's model with long-range hopping.","Furthermore, we provide numerical evidence on the infinite recursive structures of the spectrum and give an algorithm for computing these structures."],"url":"http://arxiv.org/abs/2404.08211v1","category":"cond-mat.mes-hall"}
{"created":"2024-04-12 17:46:13","title":"Accessibility in Information Retrieval","abstract":"This paper introduces the concept of accessibility from the field of transportation planning and adopts it within the context of Information Retrieval (IR). An analogy is drawn between the fields, which motivates the development of document accessibility measures for IR systems. Considering the accessibility of documents within a collection given an IR System provides a different perspective on the analysis and evaluation of such systems which could be used to inform the design, tuning and management of current and future IR systems.","sentences":["This paper introduces the concept of accessibility from the field of transportation planning and adopts it within the context of Information Retrieval (IR).","An analogy is drawn between the fields, which motivates the development of document accessibility measures for IR systems.","Considering the accessibility of documents within a collection given an IR System provides a different perspective on the analysis and evaluation of such systems which could be used to inform the design, tuning and management of current and future IR systems."],"url":"http://arxiv.org/abs/2404.08628v1","category":"cs.IR"}
{"created":"2024-04-12 14:26:48","title":"Prescribing Optimal Health-Aware Operation for Urban Air Mobility with Deep Reinforcement Learning","abstract":"Urban Air Mobility (UAM) aims to expand existing transportation networks in metropolitan areas by offering short flights either to transport passengers or cargo. Electric vertical takeoff and landing aircraft powered by lithium-ion battery packs are considered promising for such applications. Efficient mission planning is cru-cial, maximizing the number of flights per battery charge while ensuring completion even under unforeseen events. As batteries degrade, precise mission planning becomes challenging due to uncertainties in the end-of-discharge prediction. This often leads to adding safety margins, reducing the number or duration of po-tential flights on one battery charge. While predicting the end of discharge can support decision-making, it remains insufficient in case of unforeseen events, such as adverse weather conditions. This necessitates health-aware real-time control to address any unexpected events and extend the time until the end of charge while taking the current degradation state into account. This paper addresses the joint problem of mission planning and health-aware real-time control of opera-tional parameters to prescriptively control the duration of one discharge cycle of the battery pack. We pro-pose an algorithm that proactively prescribes operational parameters to extend the discharge cycle based on the battery's current health status while optimizing the mission. The proposed deep reinforcement learn-ing algorithm facilitates operational parameter optimization and path planning while accounting for the degradation state, even in the presence of uncertainties. Evaluation of simulated flights of a NASA concep-tual multirotor aircraft model, collected from Hardware-in-the-loop experiments, demonstrates the algo-rithm's near-optimal performance across various operational scenarios, allowing adaptation to changed en-vironmental conditions.","sentences":["Urban Air Mobility (UAM) aims to expand existing transportation networks in metropolitan areas by offering short flights either to transport passengers or cargo.","Electric vertical takeoff and landing aircraft powered by lithium-ion battery packs are considered promising for such applications.","Efficient mission planning is cru-cial, maximizing the number of flights per battery charge while ensuring completion even under unforeseen events.","As batteries degrade, precise mission planning becomes challenging due to uncertainties in the end-of-discharge prediction.","This often leads to adding safety margins, reducing the number or duration of po-tential flights on one battery charge.","While predicting the end of discharge can support decision-making, it remains insufficient in case of unforeseen events, such as adverse weather conditions.","This necessitates health-aware real-time control to address any unexpected events and extend the time until the end of charge while taking the current degradation state into account.","This paper addresses the joint problem of mission planning and health-aware real-time control of opera-tional parameters to prescriptively control the duration of one discharge cycle of the battery pack.","We pro-pose an algorithm that proactively prescribes operational parameters to extend the discharge cycle based on the battery's current health status while optimizing the mission.","The proposed deep reinforcement learn-ing algorithm facilitates operational parameter optimization and path planning while accounting for the degradation state, even in the presence of uncertainties.","Evaluation of simulated flights of a NASA concep-tual multirotor aircraft model, collected from Hardware-in-the-loop experiments, demonstrates the algo-rithm's near-optimal performance across various operational scenarios, allowing adaptation to changed en-vironmental conditions."],"url":"http://arxiv.org/abs/2404.08497v1","category":"eess.SY"}
{"created":"2024-04-12 13:19:38","title":"Search for Higgs boson pair production with one associated vector boson in proton-proton collisions at $\\sqrt{s}$ = 13 TeV","abstract":"A search for Higgs boson pair (HH) production in association with a vector boson V (W or Z boson) is presented. The search is based on proton-proton collision data at a center-of-mass energy of 13 TeV, collected with the CMS detector at the LHC, corresponding to an integrated luminosity of 138 fb$^{-1}$. All hadronic and leptonic decays of V bosons are used. The leptons considered are electrons, muons, and neutrinos. The HH production is searched for in the $\\mathrm{b\\bar{b}b\\bar{b}}$ decay channel. An observed (expected) upper limit at 95% confidence level of VHH production cross section is set at 294 (124) times the standard model prediction. Constraints are also set on the modifiers of the Higgs boson trilinear self-coupling, $\\kappa_{\\lambda}$, assuming $\\kappa_{2\\mathrm{V}}$ = 1 and vice versa on the coupling of two Higgs bosons with two vector bosons, $\\kappa_{2\\mathrm{V}}$. The observed (expected) 95% confidence intervals of these coupling modifiers are -37.7 $\\lt$ $\\kappa_{\\lambda}$ $\\lt$ 37.2 (-30.1 $\\lt$ $\\kappa_{\\lambda}$ $\\lt$ 8.9) and -12.2 $\\lt$ $\\kappa_{2\\mathrm{V}}$ $\\lt$ 13.5 (-7.2 $\\lt$ $\\kappa_{2\\mathrm{V}}$ $\\lt$ 8.9), respectively.","sentences":["A search for Higgs boson pair (HH) production in association with a vector boson V (W or Z boson) is presented.","The search is based on proton-proton collision data at a center-of-mass energy of 13 TeV, collected with the CMS detector at the LHC, corresponding to an integrated luminosity of 138 fb$^{-1}$. All hadronic and leptonic decays of V bosons are used.","The leptons considered are electrons, muons, and neutrinos.","The HH production is searched for in the $\\mathrm{b\\bar{b}b\\bar{b}}$ decay channel.","An observed (expected) upper limit at 95% confidence level of VHH production cross section is set at 294 (124) times the standard model prediction.","Constraints are also set on the modifiers of the Higgs boson trilinear self-coupling, $\\kappa_{\\lambda}$, assuming $\\kappa_{2\\mathrm{V}}$ = 1 and vice versa on the coupling of two Higgs bosons with two vector bosons, $\\kappa_{2\\mathrm{V}}$. The observed (expected) 95% confidence intervals of these coupling modifiers are -37.7 $\\lt$ $\\kappa_{\\lambda}$ $\\lt$ 37.2 (-30.1 $\\lt$ $\\kappa_{\\lambda}$ $\\lt$ 8.9) and -12.2 $\\lt$ $\\kappa_{2\\mathrm{V}}$ $\\lt$ 13.5 (-7.2 $\\lt$ $\\kappa_{2\\mathrm{V}}$ $\\lt$ 8.9), respectively."],"url":"http://arxiv.org/abs/2404.08462v1","category":"hep-ex"}
{"created":"2024-04-12 10:48:59","title":"Collective Bayesian Decision-Making in a Swarm of Miniaturized Robots for Surface Inspection","abstract":"Robot swarms can effectively serve a variety of sensing and inspection applications. Certain inspection tasks require a binary classification decision. This work presents an experimental setup for a surface inspection task based on vibration sensing and studies a Bayesian two-outcome decision-making algorithm in a swarm of miniaturized wheeled robots. The robots are tasked with individually inspecting and collectively classifying a 1mx1m tiled surface consisting of vibrating and non-vibrating tiles based on the majority type of tiles. The robots sense vibrations using onboard IMUs and perform collision avoidance using a set of IR sensors. We develop a simulation and optimization framework leveraging the Webots robotic simulator and a Particle Swarm Optimization (PSO) method. We consider two existing information sharing strategies and propose a new one that allows the swarm to rapidly reach accurate classification decisions. We first find optimal parameters that allow efficient sampling in simulation and then evaluate our proposed strategy against the two existing ones using 100 randomized simulation and 10 real experiments. We find that our proposed method compels the swarm to make decisions at an accelerated rate, with an improvement of up to 20.52% in mean decision time at only 0.78% loss in accuracy.","sentences":["Robot swarms can effectively serve a variety of sensing and inspection applications.","Certain inspection tasks require a binary classification decision.","This work presents an experimental setup for a surface inspection task based on vibration sensing and studies a Bayesian two-outcome decision-making algorithm in a swarm of miniaturized wheeled robots.","The robots are tasked with individually inspecting and collectively classifying a 1mx1m tiled surface consisting of vibrating and non-vibrating tiles based on the majority type of tiles.","The robots sense vibrations using onboard IMUs and perform collision avoidance using a set of IR sensors.","We develop a simulation and optimization framework leveraging the Webots robotic simulator and a Particle Swarm Optimization (PSO) method.","We consider two existing information sharing strategies and propose a new one that allows the swarm to rapidly reach accurate classification decisions.","We first find optimal parameters that allow efficient sampling in simulation and then evaluate our proposed strategy against the two existing ones using 100 randomized simulation and 10 real experiments.","We find that our proposed method compels the swarm to make decisions at an accelerated rate, with an improvement of up to 20.52% in mean decision time at only 0.78% loss in accuracy."],"url":"http://arxiv.org/abs/2404.08390v1","category":"cs.RO"}
{"created":"2024-04-12 09:20:23","title":"Data-driven Interval MDP for Robust Control Synthesis","abstract":"The abstraction of dynamical systems is a powerful tool that enables the design of feedback controllers using a correct-by-design framework. We investigate a novel scheme to obtain data-driven abstractions of discrete-time stochastic processes in terms of richer discrete stochastic models, whose actions lead to nondeterministic transitions over the space of probability measures. The data-driven component of the proposed methodology lies in the fact that we only assume samples from an unknown probability distribution. We also rely on the model of the underlying dynamics to build our abstraction through backward reachability computations. The nondeterminism in the probability space is captured by a collection of Markov Processes, and we identify how this model can improve upon existing abstraction techniques in terms of satisfying temporal properties, such as safety or reach-avoid. The connection between the discrete and the underlying dynamics is made formal through the use of the scenario approach theory. Numerical experiments illustrate the advantages and main limitations of the proposed techniques with respect to existing approaches.","sentences":["The abstraction of dynamical systems is a powerful tool that enables the design of feedback controllers using a correct-by-design framework.","We investigate a novel scheme to obtain data-driven abstractions of discrete-time stochastic processes in terms of richer discrete stochastic models, whose actions lead to nondeterministic transitions over the space of probability measures.","The data-driven component of the proposed methodology lies in the fact that we only assume samples from an unknown probability distribution.","We also rely on the model of the underlying dynamics to build our abstraction through backward reachability computations.","The nondeterminism in the probability space is captured by a collection of Markov Processes, and we identify how this model can improve upon existing abstraction techniques in terms of satisfying temporal properties, such as safety or reach-avoid.","The connection between the discrete and the underlying dynamics is made formal through the use of the scenario approach theory.","Numerical experiments illustrate the advantages and main limitations of the proposed techniques with respect to existing approaches."],"url":"http://arxiv.org/abs/2404.08344v1","category":"eess.SY"}
{"created":"2024-04-12 09:04:01","title":"Evidence of ferroelectric features in low-density supercooled water from ab initio deep neural-network simulations","abstract":"Over the last decade, an increasing body of evidence has emerged, supporting the existence of a metastable liquid-liquid critical point in supercooled water, whereby two distinct liquid phases of different densities coexist. Analysing long molecular dynamics simulations performed using deep neural-network force fields trained to accurate quantum mechanical data, we demonstrate that the low-density liquid phase displays a strong propensity toward spontaneous polarization, as witnessed by large and long-lived collective dipole fluctuations. Our findings suggest that the dynamical stability of the low-density phase, and hence the transition from high-density to low-density liquid, is triggered by a collective process involving an accumulation of rotational angular jumps, which could ignite large dipole fluctuations. This dynamical transition involves subtle changes in the electronic polarizability of water molecules which affects their rotational mobility within the two phases. These findings hold the potential for catalyzing new activity in the search for dielectric-based probes of the putative second critical point.","sentences":["Over the last decade, an increasing body of evidence has emerged, supporting the existence of a metastable liquid-liquid critical point in supercooled water, whereby two distinct liquid phases of different densities coexist.","Analysing long molecular dynamics simulations performed using deep neural-network force fields trained to accurate quantum mechanical data, we demonstrate that the low-density liquid phase displays a strong propensity toward spontaneous polarization, as witnessed by large and long-lived collective dipole fluctuations.","Our findings suggest that the dynamical stability of the low-density phase, and hence the transition from high-density to low-density liquid, is triggered by a collective process involving an accumulation of rotational angular jumps, which could ignite large dipole fluctuations.","This dynamical transition involves subtle changes in the electronic polarizability of water molecules which affects their rotational mobility within the two phases.","These findings hold the potential for catalyzing new activity in the search for dielectric-based probes of the putative second critical point."],"url":"http://arxiv.org/abs/2404.08338v1","category":"cond-mat.soft"}
{"created":"2024-04-12 06:53:05","title":"(C$_5$H$_9$NH$_3$)$_2$CuBr$_4$: a metal-organic two-ladder quantum magnet","abstract":"Low-dimensional quantum magnets are a versatile materials platform for studying the emergent many-body physics and collective excitations that can arise even in systems with only short-range interactions. Understanding their low-temperature structure and spin Hamiltonian is key to explaining their magnetic properties, including unconventional quantum phases, phase transitions, and excited states. We study the metal-organic coordination compound (C$_5$H$_9$NH$_3$)$_2$CuBr$_4$ and its deuterated counterpart, which upon its discovery was identified as a candidate two-leg quantum ($S = 1/2$) spin ladder in the strong-leg coupling regime. By growing large single crystals and probing them with both bulk and microscopic techniques, we deduce that two previously unknown structural phase transitions take place between 136 K and 113 K. The low-temperature structure has a monoclinic unit cell giving rise to two inequivalent spin ladders. We further confirm the absence of long-range magnetic order down to 30 mK and discuss the implications of this two-ladder structure for the magnetic properties of (C$_5$H$_9$NH$_3$)$_2$CuBr$_4$.","sentences":["Low-dimensional quantum magnets are a versatile materials platform for studying the emergent many-body physics and collective excitations that can arise even in systems with only short-range interactions.","Understanding their low-temperature structure and spin Hamiltonian is key to explaining their magnetic properties, including unconventional quantum phases, phase transitions, and excited states.","We study the metal-organic coordination compound (C$_5$H$_9$NH$_3$)$_2$CuBr$_4$ and its deuterated counterpart, which upon its discovery was identified as a candidate two-leg quantum ($S = 1/2$) spin ladder in the strong-leg coupling regime.","By growing large single crystals and probing them with both bulk and microscopic techniques, we deduce that two previously unknown structural phase transitions take place between 136 K and 113 K. The low-temperature structure has a monoclinic unit cell giving rise to two inequivalent spin ladders.","We further confirm the absence of long-range magnetic order down to 30 mK and discuss the implications of this two-ladder structure for the magnetic properties of (C$_5$H$_9$NH$_3$)$_2$CuBr$_4$."],"url":"http://arxiv.org/abs/2404.08274v1","category":"cond-mat.str-el"}
{"created":"2024-04-12 04:01:54","title":"Modulo-$(2^{2n}+1)$ Arithmetic via Two Parallel n-bit Residue Channels","abstract":"Augmenting the balanced residue number system moduli-set $\\{m_1=2^n,m_2=2^n-1,m_3=2^n+1\\}$, with the co-prime modulo $m_4=2^{2n}+1$, increases the dynamic range (DR) by around 70%. The Mersenne form of product $m_2 m_3 m_4=2^{4n}-1$, in the moduli-set $\\{m_1,m_2,m_3,m_4\\}$, leads to a very efficient reverse convertor, based on the New Chinese remainder theorem. However, the double bit-width of the m_4 residue channel is counter-productive and jeopardizes the speed balance in $\\{m_1,m_2,m_3\\}$. Therefore, we decompose $m_4$ to two complex-number n-bit moduli $2^n\\pm\\sqrt{-1}$, which preserves the DR and the co-primality across the augmented moduli set. The required forward modulo-$(2^{2n}+1)$ to moduli-$(2^n\\pm\\sqrt{-1}) $conversion, and the reverse are immediate and cost-free. The proposed unified moduli-$(2^n\\pm\\sqrt{-1})$ adder and multiplier, are tested and synthesized using Spartan 7S100 FPGA. The 6-bit look-up tables (LUT), therein, promote the LUT realizations of adders and multipliers, for $n=5$, where the DR equals $2^{25}-2^5$. However, the undertaken experiments show that to cover all the 32-bit numbers, the power-of-two channel $m_1$ can be as wide as 12 bits with no harm to the speed balance across the five moduli. The results also show that the moduli-$(2^5\\pm\\sqrt{-1})$ add and multiply operations are advantageous vs. moduli-$(2^5\\pm1)$ in speed, cost, and energy measures and collectively better than those of modulo-$(2^{10}+1)$.","sentences":["Augmenting the balanced residue number system moduli-set $\\{m_1=2^n,m_2=2^n-1,m_3=2^n+1\\}$, with the co-prime modulo $m_4=2^{2n}+1$, increases the dynamic range (DR) by around 70%.","The Mersenne form of product $m_2 m_3 m_4=2^{4n}-1$, in the moduli-set $\\{m_1,m_2,m_3,m_4\\}$, leads to a very efficient reverse convertor, based on the New Chinese remainder theorem.","However, the double bit-width of the m_4 residue channel is counter-productive and jeopardizes the speed balance in $\\{m_1,m_2,m_3\\}$. Therefore, we decompose $m_4$ to two complex-number n-bit moduli $2^n\\pm\\sqrt{-1}$, which preserves the DR and the co-primality across the augmented moduli set.","The required forward modulo-$(2^{2n}+1)$ to moduli-$(2^n\\pm\\sqrt{-1}) $conversion, and the reverse are immediate and cost-free.","The proposed unified moduli-$(2^n\\pm\\sqrt{-1})$ adder and multiplier, are tested and synthesized using Spartan 7S100 FPGA.","The 6-bit look-up tables (LUT), therein, promote the LUT realizations of adders and multipliers, for $n=5$, where the DR equals $2^{25}-2^5$.","However, the undertaken experiments show that to cover all the 32-bit numbers, the power-of-two channel $m_1$ can be as wide as 12 bits with no harm to the speed balance across the five moduli.","The results also show that the moduli-$(2^5\\pm\\sqrt{-1})$ add and multiply operations are advantageous vs. moduli-$(2^5\\pm1)$ in speed, cost, and energy measures and collectively better than those of modulo-$(2^{10}+1)$."],"url":"http://arxiv.org/abs/2404.08228v1","category":"cs.AR"}
{"created":"2024-04-12 03:08:19","title":"Thermally activated intermittent flow in amorphous solids","abstract":"Using mean field theory and a mesoscale elastoplastic model, we analyze the steady state shear rheology of thermally activated amorphous solids. At sufficiently high temperature and driving rates, flow is continuous and described by well-established rheological flow laws such as Herschel-Bulkley and logarithmic rate dependence. However, we find that these flow laws change in the regime of intermittent flow, were collective events no longer overlap and serrated flow becomes pronounced. In this regime, we identify a thermal activation stress scale, $x_{a}(T,\\dot{\\gamma})$, that wholly captures the effect of driving rate $\\dot{\\gamma}$ and temperature $T$ on average flow stress, stress drop (avalanche) size and correlation lengths. Different rheological regimes are summarized in a dynamic phase diagram for the amorphous yielding transition. Theoretical predictions call for a need to re-examine the rheology of very slowly sheared amorphous matter much below the glass transition.","sentences":["Using mean field theory and a mesoscale elastoplastic model, we analyze the steady state shear rheology of thermally activated amorphous solids.","At sufficiently high temperature and driving rates, flow is continuous and described by well-established rheological flow laws such as Herschel-Bulkley and logarithmic rate dependence.","However, we find that these flow laws change in the regime of intermittent flow, were collective events no longer overlap and serrated flow becomes pronounced.","In this regime, we identify a thermal activation stress scale, $x_{a}(T,\\dot{\\gamma})$, that wholly captures the effect of driving rate $\\dot{\\gamma}$ and temperature $T$ on average flow stress, stress drop (avalanche) size and correlation lengths.","Different rheological regimes are summarized in a dynamic phase diagram for the amorphous yielding transition.","Theoretical predictions call for a need to re-examine the rheology of very slowly sheared amorphous matter much below the glass transition."],"url":"http://arxiv.org/abs/2404.08220v1","category":"cond-mat.soft"}
{"created":"2024-04-12 17:59:40","title":"COCONut: Modernizing COCO Segmentation","abstract":"In recent decades, the vision community has witnessed remarkable progress in visual recognition, partially owing to advancements in dataset benchmarks. Notably, the established COCO benchmark has propelled the development of modern detection and segmentation systems. However, the COCO segmentation benchmark has seen comparatively slow improvement over the last decade. Originally equipped with coarse polygon annotations for thing instances, it gradually incorporated coarse superpixel annotations for stuff regions, which were subsequently heuristically amalgamated to yield panoptic segmentation annotations. These annotations, executed by different groups of raters, have resulted not only in coarse segmentation masks but also in inconsistencies between segmentation types. In this study, we undertake a comprehensive reevaluation of the COCO segmentation annotations. By enhancing the annotation quality and expanding the dataset to encompass 383K images with more than 5.18M panoptic masks, we introduce COCONut, the COCO Next Universal segmenTation dataset. COCONut harmonizes segmentation annotations across semantic, instance, and panoptic segmentation with meticulously crafted high-quality masks, and establishes a robust benchmark for all segmentation tasks. To our knowledge, COCONut stands as the inaugural large-scale universal segmentation dataset, verified by human raters. We anticipate that the release of COCONut will significantly contribute to the community's ability to assess the progress of novel neural networks.","sentences":["In recent decades, the vision community has witnessed remarkable progress in visual recognition, partially owing to advancements in dataset benchmarks.","Notably, the established COCO benchmark has propelled the development of modern detection and segmentation systems.","However, the COCO segmentation benchmark has seen comparatively slow improvement over the last decade.","Originally equipped with coarse polygon annotations for thing instances, it gradually incorporated coarse superpixel annotations for stuff regions, which were subsequently heuristically amalgamated to yield panoptic segmentation annotations.","These annotations, executed by different groups of raters, have resulted not only in coarse segmentation masks but also in inconsistencies between segmentation types.","In this study, we undertake a comprehensive reevaluation of the COCO segmentation annotations.","By enhancing the annotation quality and expanding the dataset to encompass 383K images with more than 5.18M panoptic masks, we introduce COCONut, the COCO Next Universal segmenTation dataset.","COCONut harmonizes segmentation annotations across semantic, instance, and panoptic segmentation with meticulously crafted high-quality masks, and establishes a robust benchmark for all segmentation tasks.","To our knowledge, COCONut stands as the inaugural large-scale universal segmentation dataset, verified by human raters.","We anticipate that the release of COCONut will significantly contribute to the community's ability to assess the progress of novel neural networks."],"url":"http://arxiv.org/abs/2404.08639v1","category":"cs.CV"}
{"created":"2024-04-12 17:59:27","title":"Age of Information Optimization and State Error Analysis for Correlated Multi-Process Multi-Sensor Systems","abstract":"In this paper, we examine a multi-sensor system where each sensor may monitor more than one time-varying information process and send status updates to a remote monitor over a single channel. We consider that each sensor's status update may contain information about more than one information process in the system subject to the system's constraints. To investigate the impact of this correlation on the overall system's performance, we conduct an analysis of both the average Age of Information and source state estimation error at the monitor. Building upon this analysis, we subsequently explore the impact of the packet arrivals, correlation probabilities, and rate of processes' state change on the system's performance. Next, we consider the case where sensors have limited sensing abilities and distribute a portion of their sensing abilities for different processes. We optimize this distribution to minimize the total AoI of the system. Interestingly, we show that monitoring multiple processes from a single source may not always be beneficial. Additionally, our results highlight that the optimal sensing distribution for diverse arrival rates may exhibit a fast regime change instead of undergoing smooth changes.","sentences":["In this paper, we examine a multi-sensor system where each sensor may monitor more than one time-varying information process and send status updates to a remote monitor over a single channel.","We consider that each sensor's status update may contain information about more than one information process in the system subject to the system's constraints.","To investigate the impact of this correlation on the overall system's performance, we conduct an analysis of both the average Age of Information and source state estimation error at the monitor.","Building upon this analysis, we subsequently explore the impact of the packet arrivals, correlation probabilities, and rate of processes' state change on the system's performance.","Next, we consider the case where sensors have limited sensing abilities and distribute a portion of their sensing abilities for different processes.","We optimize this distribution to minimize the total AoI of the system.","Interestingly, we show that monitoring multiple processes from a single source may not always be beneficial.","Additionally, our results highlight that the optimal sensing distribution for diverse arrival rates may exhibit a fast regime change instead of undergoing smooth changes."],"url":"http://arxiv.org/abs/2404.08638v1","category":"cs.IT"}
{"created":"2024-04-12 17:39:51","title":"Automated distribution of high-rate, high-fidelity polarization entangled photons using deployed metropolitan fibers","abstract":"Distributing high-fidelity, high-rate entanglement over telecommunication infrastructure is one of the main paths towards large-scale quantum networks, enabling applications such as quantum encryption and network protection, blind quantum computing, distributed quantum computing, and distributed quantum sensing. However, the fragile nature of entangled photons operating in real-world fiber infrastructure has historically limited continuous operation of such networks. Here, we present a fully automated system capable of distributing polarization entangled photons over a 34 km deployed fiber in New York City. We achieve end-to-end pair rates of nearly $5\\times10^5$ pairs/s and entanglement fidelity of approximately $99\\%$. Separately, we achieve 15 days of continuous distribution, with a network up-time of $99.84\\%$. Our work paves the way for practical deployment of 24/7 entanglement-based networks with rates and fidelity adequate for many current and future use-cases.","sentences":["Distributing high-fidelity, high-rate entanglement over telecommunication infrastructure is one of the main paths towards large-scale quantum networks, enabling applications such as quantum encryption and network protection, blind quantum computing, distributed quantum computing, and distributed quantum sensing.","However, the fragile nature of entangled photons operating in real-world fiber infrastructure has historically limited continuous operation of such networks.","Here, we present a fully automated system capable of distributing polarization entangled photons over a 34 km deployed fiber in New York City.","We achieve end-to-end pair rates of nearly $5\\times10^5$ pairs/s and entanglement fidelity of approximately $99\\%$. Separately, we achieve 15 days of continuous distribution, with a network up-time of $99.84\\%$. Our work paves the way for practical deployment of 24/7 entanglement-based networks with rates and fidelity adequate for many current and future use-cases."],"url":"http://arxiv.org/abs/2404.08626v1","category":"quant-ph"}
{"created":"2024-04-12 17:36:51","title":"Mixing Modes: Active and Passive Integration of Speech, Text, and Visualization for Communicating Data Uncertainty","abstract":"Interpreting uncertain data can be difficult, particularly if the data presentation is complex. We investigate the efficacy of different modalities for representing data and how to combine the strengths of each modality to facilitate the communication of data uncertainty. We implemented two multimodal prototypes to explore the design space of integrating speech, text, and visualization elements. A preliminary evaluation with 20 participants from academic and industry communities demonstrates that there exists no one-size-fits-all approach for uncertainty communication strategies; rather, the effectiveness of conveying uncertain data is intertwined with user preferences and situational context, necessitating a more refined, multimodal strategy for future interface design.","sentences":["Interpreting uncertain data can be difficult, particularly if the data presentation is complex.","We investigate the efficacy of different modalities for representing data and how to combine the strengths of each modality to facilitate the communication of data uncertainty.","We implemented two multimodal prototypes to explore the design space of integrating speech, text, and visualization elements.","A preliminary evaluation with 20 participants from academic and industry communities demonstrates that there exists no one-size-fits-all approach for uncertainty communication strategies; rather, the effectiveness of conveying uncertain data is intertwined with user preferences and situational context, necessitating a more refined, multimodal strategy for future interface design."],"url":"http://arxiv.org/abs/2404.08623v1","category":"cs.HC"}
{"created":"2024-04-12 17:29:22","title":"Using Information Flow to estimate interference between developers same method contributions","abstract":"This work's main goal is to understand if Information Flow Control (IFC), a security technique used for discovering leaks in software, could be used to indicate the presence of dynamic semantic conflicts between developers contributions in merge scenarios. However, as defining if a dynamic semantic conflict exists involves understanding the expected behaviour of a system, and as such behavioural specifications are often hard to capture, formalize and reason about, we instead try to detect a code level adaptation of the notion of interference from Goguen and Meseguer. We limit our scope to interference caused by developers contributions on the same method. Therefore, we conduct an evaluation to understand if information flow may be used to estimate interference. In particular, we use Java Object-sensitive Analysis (JOANA) to do the IFC for Java programs. JOANA does the IFC of Java programs by using a System Dependence Graph (SDG), a directed graph representing the information flow through a program. Additionally, we bring evidence that information flow between developers same-method contributions occurred for around 64% of the scenarios we evaluated. Finally, we conducted a manual analysis, on 35 scenarios with information flow between developers same-method contributions, to understand the limitations of using information flow to estimate interference between same-method contributions. From the 35 analysed scenarios, for only 15 we considered that an interference in fact existed. We found three different major reasons for detecting information flow and no interference: cases related to the nature of changes, to excessive annotation from our strategy and to the conservativeness of the flows identified by JOANA. We conclude that information flow may be used to estimate interference, but, ideally, the number of false positives should be reduced.","sentences":["This work's main goal is to understand if Information Flow Control (IFC), a security technique used for discovering leaks in software, could be used to indicate the presence of dynamic semantic conflicts between developers contributions in merge scenarios.","However, as defining if a dynamic semantic conflict exists involves understanding the expected behaviour of a system, and as such behavioural specifications are often hard to capture, formalize and reason about, we instead try to detect a code level adaptation of the notion of interference from Goguen and Meseguer.","We limit our scope to interference caused by developers contributions on the same method.","Therefore, we conduct an evaluation to understand if information flow may be used to estimate interference.","In particular, we use Java Object-sensitive Analysis (JOANA) to do the IFC for Java programs.","JOANA does the IFC of Java programs by using a System Dependence Graph (SDG), a directed graph representing the information flow through a program.","Additionally, we bring evidence that information flow between developers same-method contributions occurred for around 64% of the scenarios we evaluated.","Finally, we conducted a manual analysis, on 35 scenarios with information flow between developers same-method contributions, to understand the limitations of using information flow to estimate interference between same-method contributions.","From the 35 analysed scenarios, for only 15 we considered that an interference in fact existed.","We found three different major reasons for detecting information flow and no interference: cases related to the nature of changes, to excessive annotation from our strategy and to the conservativeness of the flows identified by JOANA.","We conclude that information flow may be used to estimate interference, but, ideally, the number of false positives should be reduced."],"url":"http://arxiv.org/abs/2404.08619v1","category":"cs.SE"}
{"created":"2024-04-12 17:22:22","title":"Analytic approximations for massive close post-mass transfer binary systems","abstract":"Massive binary evolution models are needed to predict massive star populations in star forming galaxies, the supernova diversity, and the number and properties of gravitational wave sources. Such models are often computed using so called rapid binary evolution codes, which approximate the evolution of the binary components based on detailed single star models. However, about one third of the interacting massive binary stars undergo mass transfer during core hydrogen burning (Case A mass transfer), whose outcome is difficult to derive from single star models. Here, we use a large grid of detailed binary evolution models for primaries in the initial mass range 10 to 40 Solar masses of LMC and SMC composition, to derive analytic fits for the key quantities needed in rapid binary evolution codes, i.e., the duration of core hydrogen burning, and the resulting donor star mass. Systems with shorter orbital periods produce up to 50% lighter stripped donors and have a up to 30% larger lifetime than wider systems. We find that both quantities depend strongly on the initial binary orbital period, but that the initial mass ratio and the mass transfer efficiency of the binary have little impact on the outcome. Our results are easily parameterisable and can be used to capture the effects of Case A mass transfer more accurately in rapid binary evolution codes.","sentences":["Massive binary evolution models are needed to predict massive star populations in star forming galaxies, the supernova diversity, and the number and properties of gravitational wave sources.","Such models are often computed using so called rapid binary evolution codes, which approximate the evolution of the binary components based on detailed single star models.","However, about one third of the interacting massive binary stars undergo mass transfer during core hydrogen burning (Case A mass transfer), whose outcome is difficult to derive from single star models.","Here, we use a large grid of detailed binary evolution models for primaries in the initial mass range 10 to 40 Solar masses of LMC and SMC composition, to derive analytic fits for the key quantities needed in rapid binary evolution codes, i.e., the duration of core hydrogen burning, and the resulting donor star mass.","Systems with shorter orbital periods produce up to 50% lighter stripped donors and have a up to 30% larger lifetime than wider systems.","We find that both quantities depend strongly on the initial binary orbital period, but that the initial mass ratio and the mass transfer efficiency of the binary have little impact on the outcome.","Our results are easily parameterisable and can be used to capture the effects of Case A mass transfer more accurately in rapid binary evolution codes."],"url":"http://arxiv.org/abs/2404.08612v1","category":"astro-ph.SR"}
{"created":"2024-04-12 17:15:49","title":"Full-Duplex Beyond Self-Interference: The Unlimited Sensing Way","abstract":"The success of full-stack full-duplex communication systems depends on how effectively one can achieve digital self-interference cancellation (SIC). Towards this end, in this paper, we consider unlimited sensing framework (USF) enabled full-duplex system. We show that by injecting folding non-linearities in the sensing pipeline, one can not only suppress self-interference but also recover the signal of interest (SoI). This approach leads to novel design of the receiver architecture that is complemented by a modulo-domain channel estimation method. Numerical experiments show that the USF enabled receiver structure can achieve up to 40 dB digital SIC by using as few as 4-bits per sample. Our method outperforms the previous approach based on adaptive filters when it comes to SoI reconstruction, detection, and digital SIC performance.","sentences":["The success of full-stack full-duplex communication systems depends on how effectively one can achieve digital self-interference cancellation (SIC).","Towards this end, in this paper, we consider unlimited sensing framework (USF) enabled full-duplex system.","We show that by injecting folding non-linearities in the sensing pipeline, one can not only suppress self-interference but also recover the signal of interest (SoI).","This approach leads to novel design of the receiver architecture that is complemented by a modulo-domain channel estimation method.","Numerical experiments show that the USF enabled receiver structure can achieve up to 40 dB digital SIC by using as few as 4-bits per sample.","Our method outperforms the previous approach based on adaptive filters when it comes to SoI reconstruction, detection, and digital SIC performance."],"url":"http://arxiv.org/abs/2404.08610v1","category":"eess.SP"}
{"created":"2024-04-12 16:53:25","title":"Interaction networks in persistent Lotka-Volterra communities","abstract":"A central concern of community ecology is the interdependence between interaction strengths and the underlying structure of the network upon which species interact. In this work we present a solvable example of such a feedback mechanism in a generalised Lotka-Volterra dynamical system. Beginning with a community of species interacting on a network with arbitrary degree distribution, we provide an analytical framework from which properties of the eventual `surviving community' can be derived. We find that highly-connected species are less likely to survive than their poorly connected counterparts, which skews the eventual degree distribution towards a preponderance of species with low degree, a pattern commonly observed in real ecosystems. Further, the average abundance of the neighbours of a species in the surviving community is lower than the community average (reminiscent of the famed friendship paradox). Finally, we show that correlations emerge between the connectivity of a species and its interactions with its neighbours. More precisely, we find that highly-connected species tend to benefit from their neighbours more than their neighbours benefit from them. These correlations are not present in the initial pool of species and are a result of the dynamics.","sentences":["A central concern of community ecology is the interdependence between interaction strengths and the underlying structure of the network upon which species interact.","In this work we present a solvable example of such a feedback mechanism in a generalised Lotka-Volterra dynamical system.","Beginning with a community of species interacting on a network with arbitrary degree distribution, we provide an analytical framework from which properties of the eventual `surviving community' can be derived.","We find that highly-connected species are less likely to survive than their poorly connected counterparts, which skews the eventual degree distribution towards a preponderance of species with low degree, a pattern commonly observed in real ecosystems.","Further, the average abundance of the neighbours of a species in the surviving community is lower than the community average (reminiscent of the famed friendship paradox).","Finally, we show that correlations emerge between the connectivity of a species and its interactions with its neighbours.","More precisely, we find that highly-connected species tend to benefit from their neighbours more than their neighbours benefit from them.","These correlations are not present in the initial pool of species and are a result of the dynamics."],"url":"http://arxiv.org/abs/2404.08600v1","category":"q-bio.PE"}
{"created":"2024-04-12 16:53:09","title":"Destroying Densest Subgraphs is Hard","abstract":"We analyze the computational complexity of the following computational problems called Bounded-Density Edge Deletion and Bounded-Density Vertex Deletion: Given a graph $G$, a budget $k$ and a target density $\\tau_\\rho$, are there $k$ edges ($k$ vertices) whose removal from $G$ results in a graph where the densest subgraph has density at most $\\tau_\\rho$? Here, the density of a graph is the number of its edges divided by the number of its vertices. We prove that both problems are polynomial-time solvable on trees and cliques but are NP-complete on planar bipartite graphs and split graphs. From a parameterized point of view, we show that both problems are fixed-parameter tractable with respect to the vertex cover number but W[1]-hard with respect to the solution size. Furthermore, we prove that Bounded-Density Edge Deletion is W[1]-hard with respect to the feedback edge number, demonstrating that the problem remains hard on very sparse graphs.","sentences":["We analyze the computational complexity of the following computational problems called Bounded-Density Edge Deletion and Bounded-Density Vertex Deletion:","Given a graph $G$, a budget $k$ and a target density $\\tau_\\rho$, are there $k$ edges ($k$ vertices) whose removal from $G$ results in a graph where the densest subgraph has density at most $\\tau_\\rho$?","Here, the density of a graph is the number of its edges divided by the number of its vertices.","We prove that both problems are polynomial-time solvable on trees and cliques but are NP-complete on planar bipartite graphs and split graphs.","From a parameterized point of view, we show that both problems are fixed-parameter tractable with respect to the vertex cover number but W[1]-hard with respect to the solution size.","Furthermore, we prove that Bounded-Density Edge Deletion is W[1]-hard with respect to the feedback edge number, demonstrating that the problem remains hard on very sparse graphs."],"url":"http://arxiv.org/abs/2404.08599v1","category":"cs.DS"}
{"created":"2024-04-12 16:50:29","title":"Harmonic Riemannian submersions between Riemannian symmetric spaces of noncompact type","abstract":"We construct harmonic Riemannian submersions that are retractions from symmetric spaces of noncompact type onto their rank-one totally geodesic subspaces. Among the consequences, we prove the existence of a non-constant, globally defined complex-valued harmonic morphism from the Riemannian symmetric space associated to a split real semisimple Lie group. This completes an affirmative proof of a conjecture of Gudmundsson.","sentences":["We construct harmonic Riemannian submersions that are retractions from symmetric spaces of noncompact type onto their rank-one totally geodesic subspaces.","Among the consequences, we prove the existence of a non-constant, globally defined complex-valued harmonic morphism from the Riemannian symmetric space associated to a split real semisimple Lie group.","This completes an affirmative proof of a conjecture of Gudmundsson."],"url":"http://arxiv.org/abs/2404.08596v1","category":"math.DG"}
{"created":"2024-04-12 16:48:05","title":"Absolute dimensions of solar-type eclipsing binaries. NY Hya: A test for magnetic stellar evolution models","abstract":"The binary star NY Hya is a bright, detached, double-lined eclipsing system with an orbital period of just under five days with two components each nearly identical to the Sun and located in the solar neighbourhood.   The objective of this study is to test and confront various stellar evolution models for solar-type stars based on accurate measurements of stellar mass and radius.   We present new ground-based spectroscopic and photometric as well as high-precision space-based photometric and astrometric data from which we derive orbital as well as physical properties of the components via the method of least-squares minimisation based on a standard binary model valid for two detached components. Classic statistical techniques were invoked to test the significance of model parameters. Additional empirical evidence was compiled from the public domain; the derived system properties were compared with archival broad-band photometry data enabling a measurement of the system's spectral energy distribution that allowed an independent estimate of stellar properties. We also utilised semi-empirical calibration methods to derive atmospheric properties from Str\\\"{o}mgren photometry and related colour indices. Data was used to confront the observed physical properties with classic and magnetic stellar evolution models.","sentences":["The binary star NY Hya is a bright, detached, double-lined eclipsing system with an orbital period of just under five days with two components each nearly identical to the Sun and located in the solar neighbourhood.   ","The objective of this study is to test and confront various stellar evolution models for solar-type stars based on accurate measurements of stellar mass and radius.   ","We present new ground-based spectroscopic and photometric as well as high-precision space-based photometric and astrometric data from which we derive orbital as well as physical properties of the components via the method of least-squares minimisation based on a standard binary model valid for two detached components.","Classic statistical techniques were invoked to test the significance of model parameters.","Additional empirical evidence was compiled from the public domain; the derived system properties were compared with archival broad-band photometry data enabling a measurement of the system's spectral energy distribution that allowed an independent estimate of stellar properties.","We also utilised semi-empirical calibration methods to derive atmospheric properties from Str\\\"{o}mgren photometry and related colour indices.","Data was used to confront the observed physical properties with classic and magnetic stellar evolution models."],"url":"http://arxiv.org/abs/2404.08594v1","category":"astro-ph.SR"}
{"created":"2024-04-12 16:39:29","title":"QCD bounds on leading-order hadronic vacuum polarization contributions to the muon anomalous magnetic moment","abstract":"QCD bounds on the leading-order (LO) hadronic vacuum polarization (HVP) contribution to the anomalous magnetic moment of the muon ($a_\\mu^{\\mathrm{HVP,LO}}$, $a_\\mu=\\left(g-2\\right)_\\mu/2$) are determined by imposing H\\\"older inequalities and related inequality constraints on systems of Finite-Energy QCD sum-rules. This novel methodology is complementary to lattice QCD and data-driven approaches to determining $a_\\mu^{\\mathrm{HVP,LO}}$. For the light-quark ($u,d,s$) contributions up to five-loop order in perturbation theory in the chiral limit, LO in light-quark mass corrections, next-to-leading order in dimension-four QCD condensates, and to LO in dimension-six QCD condensates, we find that $\\left(673.0\\pm 40.0\\right)\\times 10^{-10}\\leq a_\\mu^{\\mathrm{HVP,LO}} \\leq \\left(807.5\\pm 48.0\\right)\\times10^{-10}\\,$, bridging the range between lattice QCD and data-driven values.","sentences":["QCD bounds on the leading-order (LO) hadronic vacuum polarization (HVP) contribution to the anomalous magnetic moment of the muon ($a_\\mu^{\\mathrm{HVP,LO}}$, $a_\\mu=\\left(g-2\\right)_\\mu/2$) are determined by imposing H\\\"older inequalities and related inequality constraints on systems of Finite-Energy QCD sum-rules.","This novel methodology is complementary to lattice QCD and data-driven approaches to determining $a_\\mu^{\\mathrm{HVP,LO}}$. For the light-quark ($u,d,s$) contributions up to five-loop order in perturbation theory in the chiral limit, LO in light-quark mass corrections, next-to-leading order in dimension-four QCD condensates, and to LO in dimension-six QCD condensates, we find that $\\left(673.0\\pm 40.0\\right)\\times 10^{-10}\\leq a_\\mu^{\\mathrm{HVP,LO}} \\leq \\left(807.5\\pm","48.0\\right)\\times10^{-10}\\,$, bridging the range between lattice QCD and data-driven values."],"url":"http://arxiv.org/abs/2404.08591v1","category":"hep-ph"}
{"created":"2024-04-12 16:28:43","title":"Nonlinearly dispersive nature of Galerkin-regularization and longon turbulence","abstract":"With derivatives for physical insights and with mathematical analyses, technical variations and many applications though, the dynamical nature of Galerkin truncation in nonlinear systems is still not clear. Here, I show with such Galerkin-regularized Burgers-Hopf (GrBH) equation that the truncation corresponds to a nonlinear dispersion, supporting solitons and soliton-like structures (called \"longons\") and rhyming with recent expositions of dispersive objects. The formulation and scenarios resemble those of soliton turbulence, thus suggesting \"longon turbulence\" with large degree of freedoms (finite though). I also argue and numerically demonstrate that appropriate linearly dispersion models with an asymptotic large jump converge to the GrBH dynamics.","sentences":["With derivatives for physical insights and with mathematical analyses, technical variations and many applications though, the dynamical nature of Galerkin truncation in nonlinear systems is still not clear.","Here, I show with such Galerkin-regularized Burgers-Hopf (GrBH) equation that the truncation corresponds to a nonlinear dispersion, supporting solitons and soliton-like structures (called \"longons\") and rhyming with recent expositions of dispersive objects.","The formulation and scenarios resemble those of soliton turbulence, thus suggesting \"longon turbulence\" with large degree of freedoms (finite though).","I also argue and numerically demonstrate that appropriate linearly dispersion models with an asymptotic large jump converge to the GrBH dynamics."],"url":"http://arxiv.org/abs/2404.08583v1","category":"nlin.CD"}
{"created":"2024-04-12 16:23:21","title":"Non-existence of tensor t-structures on singular noetherian schemes","abstract":"We show that there are no non-trivial tensor t-structures on the category of perfect complexes of a singular irreducible finite-dimensional noetherian scheme. To achieve this, we establish some technical results on Thomason filtrations and corresponding tensor t-structures.","sentences":["We show that there are no non-trivial tensor t-structures on the category of perfect complexes of a singular irreducible finite-dimensional noetherian scheme.","To achieve this, we establish some technical results on Thomason filtrations and corresponding tensor t-structures."],"url":"http://arxiv.org/abs/2404.08578v1","category":"math.AG"}
{"created":"2024-04-12 16:07:49","title":"Enhancing initial state overlap through orbital optimization for faster molecular electronic ground-state energy estimation","abstract":"The quantum phase estimation algorithm stands as the primary method for determining the ground state energy of a molecular electronic Hamiltonian on a quantum computer. In this context, the ability to initialize a classically tractable state that has a strong overlap with the desired ground state is critical as it directly affects the runtime of the algorithm. However, several numerical studies have shown that this overlap decays exponentially with system size. In this work, we demonstrate that this decay can be alleviated by optimizing the molecular orbital basis, for an initial state constructed from a single Slater determinant. We propose a practical method to achieve this optimization without knowledge of the true molecular ground state and test this method numerically. By comparing the resulting optimized orbitals to the natural orbitals, we find improved overlap. Specifically, for four iron-sulfur molecules, which are known to suffer from the mentioned decay, we show that our method yields one to two orders of magnitude improvement compared to localized molecular orbitals.","sentences":["The quantum phase estimation algorithm stands as the primary method for determining the ground state energy of a molecular electronic Hamiltonian on a quantum computer.","In this context, the ability to initialize a classically tractable state that has a strong overlap with the desired ground state is critical as it directly affects the runtime of the algorithm.","However, several numerical studies have shown that this overlap decays exponentially with system size.","In this work, we demonstrate that this decay can be alleviated by optimizing the molecular orbital basis, for an initial state constructed from a single Slater determinant.","We propose a practical method to achieve this optimization without knowledge of the true molecular ground state and test this method numerically.","By comparing the resulting optimized orbitals to the natural orbitals, we find improved overlap.","Specifically, for four iron-sulfur molecules, which are known to suffer from the mentioned decay, we show that our method yields one to two orders of magnitude improvement compared to localized molecular orbitals."],"url":"http://arxiv.org/abs/2404.08565v1","category":"quant-ph"}
{"created":"2024-04-12 15:45:26","title":"Benchmarking the Cell Image Segmentation Models Robustness under the Microscope Optical Aberrations","abstract":"Cell segmentation is essential in biomedical research for analyzing cellular morphology and behavior. Deep learning methods, particularly convolutional neural networks (CNNs), have revolutionized cell segmentation by extracting intricate features from images. However, the robustness of these methods under microscope optical aberrations remains a critical challenge. This study comprehensively evaluates the performance of cell instance segmentation models under simulated aberration conditions using the DynamicNuclearNet (DNN) and LIVECell datasets. Aberrations, including Astigmatism, Coma, Spherical, and Trefoil, were simulated using Zernike polynomial equations. Various segmentation models, such as Mask R-CNN with different network heads (FPN, C3) and backbones (ResNet, VGG19, SwinS), were trained and tested under aberrated conditions. Results indicate that FPN combined with SwinS demonstrates superior robustness in handling simple cell images affected by minor aberrations. Conversely, Cellpose2.0 proves effective for complex cell images under similar conditions. Our findings provide insights into selecting appropriate segmentation models based on cell morphology and aberration severity, enhancing the reliability of cell segmentation in biomedical applications. Further research is warranted to validate these methods with diverse aberration types and emerging segmentation models. Overall, this research aims to guide researchers in effectively utilizing cell segmentation models in the presence of minor optical aberrations.","sentences":["Cell segmentation is essential in biomedical research for analyzing cellular morphology and behavior.","Deep learning methods, particularly convolutional neural networks (CNNs), have revolutionized cell segmentation by extracting intricate features from images.","However, the robustness of these methods under microscope optical aberrations remains a critical challenge.","This study comprehensively evaluates the performance of cell instance segmentation models under simulated aberration conditions using the DynamicNuclearNet (DNN) and LIVECell datasets.","Aberrations, including Astigmatism, Coma, Spherical, and Trefoil, were simulated using Zernike polynomial equations.","Various segmentation models, such as Mask R-CNN with different network heads (FPN, C3) and backbones (ResNet, VGG19, SwinS), were trained and tested under aberrated conditions.","Results indicate that FPN combined with SwinS demonstrates superior robustness in handling simple cell images affected by minor aberrations.","Conversely, Cellpose2.0 proves effective for complex cell images under similar conditions.","Our findings provide insights into selecting appropriate segmentation models based on cell morphology and aberration severity, enhancing the reliability of cell segmentation in biomedical applications.","Further research is warranted to validate these methods with diverse aberration types and emerging segmentation models.","Overall, this research aims to guide researchers in effectively utilizing cell segmentation models in the presence of minor optical aberrations."],"url":"http://arxiv.org/abs/2404.08549v1","category":"eess.IV"}
{"created":"2024-04-12 15:36:35","title":"Large scale simulations of photosynthetic antenna systems: interplay of cooperativity and disorder","abstract":"Large scale simulations of light-matter interaction in natural photosynthetic antenna complexes containing more than one hundred thousands chlorophyll molecules, comparable with natural size, have been performed. Photosynthetic antenna complexes present in Green sulfur bacteria and Purple bacteria have been analyzed using a radiative non-Hermitian Hamiltonian, well known in the field of quantum optics, instead of the widely used dipole-dipole Frenkel Hamiltonian. This approach allows to study ensembles of emitters beyond the small volume limit (system size much smaller than the absorbed wavelength), where the Frenkel Hamiltonian fails. When analyzed on a large scale, such structures display superradiant states much brighter then their single components. An analysis of the robustness to static disorder and dynamical (thermal) noise, shows that exciton coherence in the whole photosynthetic complex is larger than the coherence found in its parts. This provides evidence that the photosynthetic complex as a whole has a predominant role in sustaining coherences in the system even at room temperature. Our results allow a better understanding of natural photosynthetic antennae and could drive experiments to verify how the response to the electromagnetic radiation depends on the size of the photosynthetic antenna.","sentences":["Large scale simulations of light-matter interaction in natural photosynthetic antenna complexes containing more than one hundred thousands chlorophyll molecules, comparable with natural size, have been performed.","Photosynthetic antenna complexes present in Green sulfur bacteria and Purple bacteria have been analyzed using a radiative non-Hermitian Hamiltonian, well known in the field of quantum optics, instead of the widely used dipole-dipole Frenkel Hamiltonian.","This approach allows to study ensembles of emitters beyond the small volume limit (system size much smaller than the absorbed wavelength), where the Frenkel Hamiltonian fails.","When analyzed on a large scale, such structures display superradiant states much brighter then their single components.","An analysis of the robustness to static disorder and dynamical (thermal) noise, shows that exciton coherence in the whole photosynthetic complex is larger than the coherence found in its parts.","This provides evidence that the photosynthetic complex as a whole has a predominant role in sustaining coherences in the system even at room temperature.","Our results allow a better understanding of natural photosynthetic antennae and could drive experiments to verify how the response to the electromagnetic radiation depends on the size of the photosynthetic antenna."],"url":"http://arxiv.org/abs/2404.08542v1","category":"cond-mat.mes-hall"}
{"created":"2024-04-12 15:32:17","title":"VertAttack: Taking advantage of Text Classifiers' horizontal vision","abstract":"Text classification systems have continuously improved in performance over the years. However, nearly all current SOTA classifiers have a similar shortcoming, they process text in a horizontal manner. Vertically written words will not be recognized by a classifier. In contrast, humans are easily able to recognize and read words written both horizontally and vertically. Hence, a human adversary could write problematic words vertically and the meaning would still be preserved to other humans. We simulate such an attack, VertAttack. VertAttack identifies which words a classifier is reliant on and then rewrites those words vertically. We find that VertAttack is able to greatly drop the accuracy of 4 different transformer models on 5 datasets. For example, on the SST2 dataset, VertAttack is able to drop RoBERTa's accuracy from 94 to 13%. Furthermore, since VertAttack does not replace the word, meaning is easily preserved. We verify this via a human study and find that crowdworkers are able to correctly label 77% perturbed texts perturbed, compared to 81% of the original texts. We believe VertAttack offers a look into how humans might circumvent classifiers in the future and thus inspire a look into more robust algorithms.","sentences":["Text classification systems have continuously improved in performance over the years.","However, nearly all current SOTA classifiers have a similar shortcoming, they process text in a horizontal manner.","Vertically written words will not be recognized by a classifier.","In contrast, humans are easily able to recognize and read words written both horizontally and vertically.","Hence, a human adversary could write problematic words vertically and the meaning would still be preserved to other humans.","We simulate such an attack, VertAttack.","VertAttack identifies which words a classifier is reliant on and then rewrites those words vertically.","We find that VertAttack is able to greatly drop the accuracy of 4 different transformer models on 5 datasets.","For example, on the SST2 dataset, VertAttack is able to drop RoBERTa's accuracy from 94 to 13%.","Furthermore, since VertAttack does not replace the word, meaning is easily preserved.","We verify this via a human study and find that crowdworkers are able to correctly label 77% perturbed texts perturbed, compared to 81% of the original texts.","We believe VertAttack offers a look into how humans might circumvent classifiers in the future and thus inspire a look into more robust algorithms."],"url":"http://arxiv.org/abs/2404.08538v1","category":"cs.CL"}
{"created":"2024-04-12 15:31:12","title":"Complete K\u00e4hler manifolds with nonnegative Ricci curvature","abstract":"We consider complete K\\\"ahler manifolds with nonnegative Ricci curvature. The main results are: 1. When the manifold has nonnegative bisectional curvature, we show that $\\lim\\limits_{r\\to\\infty}\\frac{r^{2}}{vol(B(p, r))}\\int_{B(p, r)}S$ exists. In other words, it depends only on the manifold. This solves a question of Ni. Also, we establish estimates among volume growth ratio, integral of scalar curvature, and the degree of polynomial growth holomorphic functions. The new point is that the estimates are sharp for any prescribed volume growth rate. 2. We discover a strong rigidity for complete Ricci flat K\\\"ahler metrics. Let $M^n (n\\geq 2)$ be a complete K\\\"ahler manifold with nonnegative Ricci curvature and Euclidean volume growth. Assume either the curvature has quadratic decay, or the K\\\"ahler metric is $dd^c$-exact with quadratic decay of scalar curvature. If one tangent cone at infinity is Ricci flat, then $M$ is Ricci flat. In particular, the tangent cone is unique. In other words, we can test Ricci flatness of the manifold by checking one single tangent cone. This seems unexpected, since apriori, there is no equation on $M$ and the Bishop-Gromov volume comparison is not sharp on Ricci flat (nonflat) manifolds. Such result is in sharp contrast to the Riemannian setting: Colding and Naber showed that tangent cones are quite flexible when $Ric\\geq 0$ and $|Rm|r^2<C$. This reveals subtle differences between Riemannian case and K\\\"ahler case. The result contains lots of examples, such as all noncompact Ricci flat K\\\"ahler surfaces of Euclidean volume growth (hyper-K\\\"ahler ALE 4-manifolds classified by Kronheimer), higher dimensional examples of Tian-Yau type, as well as an example with irregular cross section. It also covers Ricci flat K\\\"ahler metrics of Euclidean volume growth on Stein manifolds with $b_2 = 0$(e.g., $\\mathbb{C}^n$).","sentences":["We consider complete K\\\"ahler manifolds with nonnegative Ricci curvature.","The main results are: 1.","When the manifold has nonnegative bisectional curvature, we show that $\\lim\\limits_{r\\to\\infty}\\frac{r^{2}}{vol(B(p, r))}\\int_{B(p, r)}S$ exists.","In other words, it depends only on the manifold.","This solves a question of Ni.","Also, we establish estimates among volume growth ratio, integral of scalar curvature, and the degree of polynomial growth holomorphic functions.","The new point is that the estimates are sharp for any prescribed volume growth rate.","2.","We discover a strong rigidity for complete Ricci flat K\\\"ahler metrics.","Let $M^n (n\\geq 2)$ be a complete K\\\"ahler manifold with nonnegative Ricci curvature and Euclidean volume growth.","Assume either the curvature has quadratic decay, or the K\\\"ahler metric is $dd^c$-exact with quadratic decay of scalar curvature.","If one tangent cone at infinity is Ricci flat, then $M$ is Ricci flat.","In particular, the tangent cone is unique.","In other words, we can test Ricci flatness of the manifold by checking one single tangent cone.","This seems unexpected, since apriori, there is no equation on $M$ and the Bishop-Gromov volume comparison is not sharp on Ricci flat (nonflat) manifolds.","Such result is in sharp contrast to the Riemannian setting: Colding and Naber showed that tangent cones are quite flexible when $Ric\\geq 0$ and $|Rm|r^2<C$.","This reveals subtle differences between Riemannian case and K\\\"ahler case.","The result contains lots of examples, such as all noncompact Ricci flat K\\\"ahler surfaces of Euclidean volume growth (hyper-K\\\"ahler ALE 4-manifolds classified by Kronheimer), higher dimensional examples of Tian-Yau type, as well as an example with irregular cross section.","It also covers Ricci flat K\\\"ahler metrics of Euclidean volume growth on Stein manifolds with $b_2 = 0$(e.g., $\\mathbb{C}^n$)."],"url":"http://arxiv.org/abs/2404.08537v1","category":"math.DG"}
{"created":"2024-04-12 15:18:01","title":"Scaling regimes of the one-dimensional phase turbulence in the deterministic complex Ginzburg-Landau equation","abstract":"We study the phase turbulence of the one-dimensional complex Ginzburg-Landau equation, in which the defect-free chaotic dynamics of the order parameter maps to a phase equation well approximated by the Kuramoto-Sivashinsky model. In this regime, the behaviour of the large wavelength modes is captured by the Kardar-Parisi-Zhang equation, determining universal scaling and statistical properties. We present numerical evidence of the existence of an additional scale-invariant regime, with dynamical scaling exponent $z=1$, emerging at scales which are intermediate between the microscopic, intrinsic to the modulational instability, and the macroscopic ones. We argue that this new regime is a signature of the universality class corresponding to the inviscid limit of the Kardar-Parisi-Zhang equation.","sentences":["We study the phase turbulence of the one-dimensional complex Ginzburg-Landau equation, in which the defect-free chaotic dynamics of the order parameter maps to a phase equation well approximated by the Kuramoto-Sivashinsky model.","In this regime, the behaviour of the large wavelength modes is captured by the Kardar-Parisi-Zhang equation, determining universal scaling and statistical properties.","We present numerical evidence of the existence of an additional scale-invariant regime, with dynamical scaling exponent $z=1$, emerging at scales which are intermediate between the microscopic, intrinsic to the modulational instability, and the macroscopic ones.","We argue that this new regime is a signature of the universality class corresponding to the inviscid limit of the Kardar-Parisi-Zhang equation."],"url":"http://arxiv.org/abs/2404.08530v1","category":"cond-mat.stat-mech"}
{"created":"2024-04-12 15:17:12","title":"The 2D Gray-Scott system of equations: constructive proofs of existence of localized stationary patterns","abstract":"In this article, we develop a method to perform constructive proofs of existence of smooth planar localized patterns in the Gray-Scott model. Specifically, we construct a natural Hilbert space $H^l$ for the study of systems of autonomous semi-linear PDEs, on which products and differential operators are well-defined. Then, given an approximate solution $\\mathbf{u}_0$, we derive a Newton-Kantorovich approach based on the construction of an approximate inverse of the linearization around $\\mathbf{u}_0$. In particular, we derive a condition under which we prove the existence of a unique solution in a neighborhood of $\\mathbf{u}_0$. Such a condition can be verified thanks to the explicit computation of different upper bounds, for which analytical details are presented. Furthermore, we provide an extra condition under which localized patterns are proven to be the limit of an unbounded branch of (spatially) periodic solutions as the period tends to infinity. We then demonstrate our approach by proving (constructively) the existence of four different localized patterns in the 2D Gray-Scott model. In addition, these solutions are proven to satisfy the $D_4$-symmetry. That is, the symmetry of the square. The algorithmic details to perform the computer-assisted proofs are available at \\cite{julia_cadiot_blanco_GS}.","sentences":["In this article, we develop a method to perform constructive proofs of existence of smooth planar localized patterns in the Gray-Scott model.","Specifically, we construct a natural Hilbert space $H^l$ for the study of systems of autonomous semi-linear PDEs, on which products and differential operators are well-defined.","Then, given an approximate solution $\\mathbf{u}_0$, we derive a Newton-Kantorovich approach based on the construction of an approximate inverse of the linearization around $\\mathbf{u}_0$. In particular, we derive a condition under which we prove the existence of a unique solution in a neighborhood of $\\mathbf{u}_0$. Such a condition can be verified thanks to the explicit computation of different upper bounds, for which analytical details are presented.","Furthermore, we provide an extra condition under which localized patterns are proven to be the limit of an unbounded branch of (spatially) periodic solutions as the period tends to infinity.","We then demonstrate our approach by proving (constructively) the existence of four different localized patterns in the 2D Gray-Scott model.","In addition, these solutions are proven to satisfy the $D_4$-symmetry.","That is, the symmetry of the square.","The algorithmic details to perform the computer-assisted proofs are available at \\cite{julia_cadiot_blanco_GS}."],"url":"http://arxiv.org/abs/2404.08529v1","category":"math.AP"}
{"created":"2024-04-12 15:14:38","title":"Automatic Recommendations for Evolving Relational Databases Schema","abstract":"Relational databases play a central role in many information systems. Their schema contains structural (e.g. tables and columns) and behavioral (e.g. stored procedures or views) entity descriptions. Then, just like for ``normal'' software, changes in legislation, offered functionalities, or functional contexts, impose to evolve databases and their schemas. But in some scenarios, it is not so easy to deconstruct a wished evolution of the schema into a precise sequence of operations. Changing a database schema may impose manually dropping and recreating dependent entities, or manually searching for dependencies in stored procedures. This is important because getting even the order of application of the operators can be difficult and have profound consequences. This meta-model allows us to compute the impact of planned changes and recommend additional changes that will ensure that the RDBMS constraints are always verified. The recommendations can then be compiled into a valid SQL patch actually updating the database schema in an orderly way. We replicated a past evolution showing that, without detailed knowledge of the database, we could perform the same change in 75\\% less time than the expert database architect. We also exemplify the use of our approach on other planned changes.","sentences":["Relational databases play a central role in many information systems.","Their schema contains structural (e.g. tables and columns) and behavioral (e.g. stored procedures or views) entity descriptions.","Then, just like for ``normal'' software, changes in legislation, offered functionalities, or functional contexts, impose to evolve databases and their schemas.","But in some scenarios, it is not so easy to deconstruct a wished evolution of the schema into a precise sequence of operations.","Changing a database schema may impose manually dropping and recreating dependent entities, or manually searching for dependencies in stored procedures.","This is important because getting even the order of application of the operators can be difficult and have profound consequences.","This meta-model allows us to compute the impact of planned changes and recommend additional changes that will ensure that the RDBMS constraints are always verified.","The recommendations can then be compiled into a valid SQL patch actually updating the database schema in an orderly way.","We replicated a past evolution showing that, without detailed knowledge of the database, we could perform the same change in 75\\% less time than the expert database architect.","We also exemplify the use of our approach on other planned changes."],"url":"http://arxiv.org/abs/2404.08525v1","category":"cs.SE"}
{"created":"2024-04-12 14:52:52","title":"Convergence properties of dynamic mode decomposition for analytic interval maps","abstract":"Extended dynamic mode decomposition (EDMD) is a data-driven algorithm for approximating spectral data of the Koopman operator associated to a dynamical system, combining a Galerkin method of order N and collocation method of order M. Spectral convergence of this method subtly depends on appropriate choice of the space of observables. For chaotic analytic full branch maps of the interval, we derive a constraint between M and N guaranteeing spectral convergence of EDMD.","sentences":["Extended dynamic mode decomposition (EDMD) is a data-driven algorithm for approximating spectral data of the Koopman operator associated to a dynamical system, combining a Galerkin method of order N and collocation method of order M. Spectral convergence of this method subtly depends on appropriate choice of the space of observables.","For chaotic analytic full branch maps of the interval, we derive a constraint between M and N guaranteeing spectral convergence of EDMD."],"url":"http://arxiv.org/abs/2404.08512v1","category":"math.DS"}
{"created":"2024-04-12 14:41:24","title":"A generalizable method for estimating meteor shower false positives","abstract":"Context. The determination of meteor shower or parent body associations is inherently a statistical problem. Traditional methods, primarily the similarity discriminants, have limitations, particularly in handling the increasing volume and complexity of meteoroid orbit data.   Aims. We aim to introduce a new, more statistically robust and generalizable method for estimating false positive detections in meteor shower identification, leveraging Kernel Density Estimation (KDE).   Methods. Utilizing a dataset of 824 fireballs observed by the European Fireball Network, we apply a multivariate Gaussian kernel within KDE and z-score data normalization. Our method analyzes the parameter space of meteoroid orbits and geocentric impact characteristics, focusing on four different similarity discriminants: DSH, D', DH, and DN.   Results. The KDE methodology consistently converges towards a true established shower-associated fireball rate within the EFN dataset of 18-25% for all criteria. This indicates that the approach provides a more statistically robust estimate of the shower-associated component.   Conclusions. Our findings highlight the potential of KDE, combined with appropriate data normalization, in enhancing the accuracy and reliability of meteor shower analysis. This method addresses the existing challenges posed by traditional similarity discriminants and offers a versatile solution adaptable to varying datasets and parameters.","sentences":["Context.","The determination of meteor shower or parent body associations is inherently a statistical problem.","Traditional methods, primarily the similarity discriminants, have limitations, particularly in handling the increasing volume and complexity of meteoroid orbit data.   Aims.","We aim to introduce a new, more statistically robust and generalizable method for estimating false positive detections in meteor shower identification, leveraging Kernel Density Estimation (KDE).   ","Methods.","Utilizing a dataset of 824 fireballs observed by the European Fireball Network, we apply a multivariate Gaussian kernel within KDE and z-score data normalization.","Our method analyzes the parameter space of meteoroid orbits and geocentric impact characteristics, focusing on four different similarity discriminants: DSH, D', DH, and DN.   Results.","The KDE methodology consistently converges towards a true established shower-associated fireball rate within the EFN dataset of 18-25% for all criteria.","This indicates that the approach provides a more statistically robust estimate of the shower-associated component.   Conclusions.","Our findings highlight the potential of KDE, combined with appropriate data normalization, in enhancing the accuracy and reliability of meteor shower analysis.","This method addresses the existing challenges posed by traditional similarity discriminants and offers a versatile solution adaptable to varying datasets and parameters."],"url":"http://arxiv.org/abs/2404.08507v1","category":"astro-ph.EP"}
{"created":"2024-04-12 14:35:31","title":"Hamiltonian Carleman Approximation of the Calogero-Moser Space","abstract":"We derive the Hamiltonian tangential Carleman approximation for the complex Calogero-Moser space $\\mathcal{C}_n$ with a non-compact real form $\\mathcal{C}_n^{\\mathbb{R}}$, using the symplectic density property of $\\mathcal{C}_n$. The Hamiltonian tangential Carleman approximation means to approximate symplectic diffeomorphisms of $\\mathcal{C}_n^{\\mathbb{R}}$ which are smoothly isotopic to the identity by symplectic holomorphic automorphisms of $\\mathcal{C}_n$ which in addition preserve the real form $\\mathcal{C}_n^{\\mathbb{R}}$. This appproximation is in the strongest topology, in the fine Whitney topology.","sentences":["We derive the Hamiltonian tangential Carleman approximation for the complex Calogero-Moser space $\\mathcal{C}_n$ with a non-compact real form $\\mathcal{C}_n^{\\mathbb{R}}$, using the symplectic density property of $\\mathcal{C}_n$. The Hamiltonian tangential Carleman approximation means to approximate symplectic diffeomorphisms of $\\mathcal{C}_n^{\\mathbb{R}}$ which are smoothly isotopic to the identity by symplectic holomorphic automorphisms of $\\mathcal{C}_n$ which in addition preserve the real form $\\mathcal{C}_n^{\\mathbb{R}}$. This appproximation is in the strongest topology, in the fine Whitney topology."],"url":"http://arxiv.org/abs/2404.08505v1","category":"math.CV"}
{"created":"2024-04-12 14:29:38","title":"Algebraic rates of stability for front-type modulated waves in Ginzburg Landau equations","abstract":"We consider the stability of front-type modulated waves in the complex Ginzburg-Landau equation (CGL). The waves occur in the bistable regime (e.g. of the quintic CGL) and connect the zero state to a spatially homogenous state oscillating in time. For initial perturbations that decay at a certain algebraic rate, we prove convergence to the wave with asymptotic phase. The convergence holds in algebraically weighted Sobolev norms and with an algebraic rate in time, where the asymptotic phase is approached by one order less than the profile. On the technical side we use the theory of exponential trichotomies to separate the spatial modes into growing, weakly decaying, and strongly decaying ones. This allows us to derive resolvent and semigroup estimates in weighted Sobolev norms and to close the argument with a Gronwall lemma involving algebraic weights.","sentences":["We consider the stability of front-type modulated waves in the complex Ginzburg-Landau equation (CGL).","The waves occur in the bistable regime (e.g. of the quintic CGL) and connect the zero state to a spatially homogenous state oscillating in time.","For initial perturbations that decay at a certain algebraic rate, we prove convergence to the wave with asymptotic phase.","The convergence holds in algebraically weighted Sobolev norms and with an algebraic rate in time, where the asymptotic phase is approached by one order less than the profile.","On the technical side we use the theory of exponential trichotomies to separate the spatial modes into growing, weakly decaying, and strongly decaying ones.","This allows us to derive resolvent and semigroup estimates in weighted Sobolev norms and to close the argument with a Gronwall lemma involving algebraic weights."],"url":"http://arxiv.org/abs/2404.08500v1","category":"math.AP"}
{"created":"2024-04-12 14:28:18","title":"Two-dimensional XY Ferromagnet Induced by Long-range Interaction","abstract":"The crossover between short-range and long-range (LR) universal behaviors remains a central theme in the physics of long-range interacting systems. The competition between LR coupling and the Berezinskii-Kosterlitz-Thouless mechanism makes the problem more subtle and less understood in the two-dimensional (2D) XY model, a cornerstone for investigating low-dimensional phenomena and their implications in quantum computation. We study the 2D XY model with algebraically decaying interaction $\\sim1/r^{2+\\sigma}$. Utilizing an advanced update strategy, we conduct large-scale Monte Carlo simulations of the model up to a linear size of $L=8192$. Our results demonstrate continuous phase transitions into a ferromagnetic phase for $\\sigma \\leq 2$, which exhibits the simultaneous emergence of a long-ranged order and a power-law decaying correlation function due to the Goldstone mode. Furthermore, we find logarithmic scaling behaviors in the low-temperature phase at $\\sigma = 2$. The observed scaling behaviors in the low-temperature phase for $\\sigma \\le 2$ agree with our theoretical analysis. Our findings request further theoretical understandings and can be of practical application in cutting-edge experiments like Rydberg atom arrays.","sentences":["The crossover between short-range and long-range (LR) universal behaviors remains a central theme in the physics of long-range interacting systems.","The competition between LR coupling and the Berezinskii-Kosterlitz-Thouless mechanism makes the problem more subtle and less understood in the two-dimensional (2D) XY model, a cornerstone for investigating low-dimensional phenomena and their implications in quantum computation.","We study the 2D XY model with algebraically decaying interaction $\\sim1/r^{2+\\sigma}$. Utilizing an advanced update strategy, we conduct large-scale Monte Carlo simulations of the model up to a linear size of $L=8192$. Our results demonstrate continuous phase transitions into a ferromagnetic phase for $\\sigma \\leq 2$, which exhibits the simultaneous emergence of a long-ranged order and a power-law decaying correlation function due to the Goldstone mode.","Furthermore, we find logarithmic scaling behaviors in the low-temperature phase at $\\sigma = 2$.","The observed scaling behaviors in the low-temperature phase for $\\sigma \\le 2$ agree with our theoretical analysis.","Our findings request further theoretical understandings and can be of practical application in cutting-edge experiments like Rydberg atom arrays."],"url":"http://arxiv.org/abs/2404.08498v1","category":"cond-mat.stat-mech"}
{"created":"2024-04-12 14:05:55","title":"Data-driven stabilization of an oscillating flow with LTI controllers","abstract":"This paper presents advances towards the data-based control of periodic oscillator flows, from their fully-developed regime to their equilibrium stabilized in closed-loop, with linear time-invariant (LTI) controllers. The proposed approach directly builds upon Leclercq et al. (2019) and provides several improvements for an efficient online implementation, aimed at being applicable in experiments. First, we use input-output data to construct an LTI mean transfer functions of the flow. The model is subsequently used for the design of an LTI controller with Linear Quadratic Gaussian (LQG) synthesis, that is practical to automate online. Then, using the controller in a feedback loop, the flow shifts in phase space and oscillations are damped. The procedure is repeated until equilibrium is reached, by stacking controllers and performing balanced truncation to deal with the increasing order of the compound controller. In this article, we illustrate the method on the classic flow past a cylinder at Reynolds number Re=100. Care has been taken such that the method may be fully automated and hopefully used as a valuable tool in a forthcoming experiment.","sentences":["This paper presents advances towards the data-based control of periodic oscillator flows, from their fully-developed regime to their equilibrium stabilized in closed-loop, with linear time-invariant (LTI) controllers.","The proposed approach directly builds upon Leclercq et al. (2019) and provides several improvements for an efficient online implementation, aimed at being applicable in experiments.","First, we use input-output data to construct an LTI mean transfer functions of the flow.","The model is subsequently used for the design of an LTI controller with Linear Quadratic Gaussian (LQG) synthesis, that is practical to automate online.","Then, using the controller in a feedback loop, the flow shifts in phase space and oscillations are damped.","The procedure is repeated until equilibrium is reached, by stacking controllers and performing balanced truncation to deal with the increasing order of the compound controller.","In this article, we illustrate the method on the classic flow past a cylinder at Reynolds number Re=100.","Care has been taken such that the method may be fully automated and hopefully used as a valuable tool in a forthcoming experiment."],"url":"http://arxiv.org/abs/2404.08487v1","category":"physics.flu-dyn"}
{"created":"2024-04-12 14:05:39","title":"Compactly supported $\\mathbb{A}^1$-Euler characteristics of symmetric powers of cellular varieties","abstract":"The compactly supported $\\mathbb{A}^1$-Euler characteristic, introduced by Hoyois and later refined by Levine and others, is an anologue in motivic homotopy theory of the classical Euler characteristic of complex topological manifolds. It is an invariant on the Grothendieck ring of varieties $\\mathrm{K}_0(\\mathrm{Var}_k)$ taking values in the Grothendieck-Witt ring $\\mathrm{GW}(k)$ of the base field $k$. The former ring has a natural power structure induced by symmetric powers of varieties. In a recent preprint, Pajwani and P\\'al construct a power structure on $\\mathrm{GW}(k)$ and show that the compactly supported $\\mathbb{A}^1$-Euler characteristic respects these two power structures for $0$-dimensional varieties, or equivalently \\'etale $k$-algebras. In this paper, we define the class $\\mathrm{Sym}_k$ of symmetrisable varieties to be those varieties for which the compactly supported $\\mathbb{A}^1$-Euler characteristic respects the power structures and study the algebraic properties of $\\mathrm{K}_0(\\mathrm{Sym}_k)$. We show that it includes all cellular varieties, and even linear varieties as introduced by Totaro. Moreover, we show that it includes non-linear varieties such as elliptic curves. As an application of our main result, we compute the compactly supported $\\mathbb{A}^1$-Euler characteristics of symmetric powers of Grassmannians and certain del Pezzo surfaces.","sentences":["The compactly supported $\\mathbb{A}^1$-Euler characteristic, introduced by Hoyois and later refined by Levine and others, is an anologue in motivic homotopy theory of the classical Euler characteristic of complex topological manifolds.","It is an invariant on the Grothendieck ring of varieties $\\mathrm{K}_0(\\mathrm{Var}_k)$ taking values in the Grothendieck-Witt ring $\\mathrm{GW}(k)$ of the base field $k$.","The former ring has a natural power structure induced by symmetric powers of varieties.","In a recent preprint, Pajwani and P\\'al construct a power structure on $\\mathrm{GW}(k)$ and show that the compactly supported $\\mathbb{A}^1$-Euler characteristic respects these two power structures for $0$-dimensional varieties, or equivalently \\'etale $k$-algebras.","In this paper, we define the class $\\mathrm{Sym}_k$ of symmetrisable varieties to be those varieties for which the compactly supported $\\mathbb{A}^1$-Euler characteristic respects the power structures and study the algebraic properties of $\\mathrm{K}_0(\\mathrm{Sym}_k)$. We show that it includes all cellular varieties, and even linear varieties as introduced by Totaro.","Moreover, we show that it includes non-linear varieties such as elliptic curves.","As an application of our main result, we compute the compactly supported $\\mathbb{A}^1$-Euler characteristics of symmetric powers of Grassmannians and certain del Pezzo surfaces."],"url":"http://arxiv.org/abs/2404.08486v1","category":"math.AG"}
{"created":"2024-04-12 14:02:57","title":"Floquet-driven crossover from density-assisted tunneling to enhanced pair tunneling","abstract":"We investigate the experimental control of pair tunneling in a double-well potential using Floquet engineering. We demonstrate a crossover from a regime with density-assisted tunneling to dominant pair tunneling by tuning the effective interactions. Furthermore, we show that the pair tunneling rate can be enhanced not only compared to the Floquet-reduced single-particle tunneling but even beyond the static superexchange rate, while keeping the effective interaction in a relevant range. This opens possibilities to realize models with explicit pair tunneling in ultracold atomic systems.","sentences":["We investigate the experimental control of pair tunneling in a double-well potential using Floquet engineering.","We demonstrate a crossover from a regime with density-assisted tunneling to dominant pair tunneling by tuning the effective interactions.","Furthermore, we show that the pair tunneling rate can be enhanced not only compared to the Floquet-reduced single-particle tunneling but even beyond the static superexchange rate, while keeping the effective interaction in a relevant range.","This opens possibilities to realize models with explicit pair tunneling in ultracold atomic systems."],"url":"http://arxiv.org/abs/2404.08482v1","category":"cond-mat.quant-gas"}
{"created":"2024-04-12 13:55:29","title":"Swing-Up of a Weakly Actuated Double Pendulum via Nonlinear Normal Modes","abstract":"We identify the nonlinear normal modes spawning from the stable equilibrium of a double pendulum under gravity, and we establish their connection to homoclinic orbits through the unstable upright position as energy increases. This result is exploited to devise an efficient swing-up strategy for a double pendulum with weak, saturating actuators. Our approach involves stabilizing the system onto periodic orbits associated with the nonlinear modes while gradually injecting energy. Since these modes are autonomous system evolutions, the required control effort for stabilization is minimal. Even with actuator limitations of less than 1% of the maximum gravitational torque, the proposed method accomplishes the swing-up of the double pendulum by allowing sufficient time.","sentences":["We identify the nonlinear normal modes spawning from the stable equilibrium of a double pendulum under gravity, and we establish their connection to homoclinic orbits through the unstable upright position as energy increases.","This result is exploited to devise an efficient swing-up strategy for a double pendulum with weak, saturating actuators.","Our approach involves stabilizing the system onto periodic orbits associated with the nonlinear modes while gradually injecting energy.","Since these modes are autonomous system evolutions, the required control effort for stabilization is minimal.","Even with actuator limitations of less than 1% of the maximum gravitational torque, the proposed method accomplishes the swing-up of the double pendulum by allowing sufficient time."],"url":"http://arxiv.org/abs/2404.08478v1","category":"eess.SY"}
{"created":"2024-04-12 13:55:05","title":"New Efficient Visual OILU Markers","abstract":"Basic patterns are the source of a wide range of more or less complex geometric structures. We will exploit such patterns to develop new efficient visual markers. Besides being projective invariants, the proposed markers allow producing rich panel of unique identifiers, highly required for resource-intensive navigation and augmented reality applications. The spiral topology of our markers permits the validation of an accurate identification scheme, which is based on level set methods. The robustness of the markers against acquisition and geometric distortions is validated by extensive experimental tests.","sentences":["Basic patterns are the source of a wide range of more or less complex geometric structures.","We will exploit such patterns to develop new efficient visual markers.","Besides being projective invariants, the proposed markers allow producing rich panel of unique identifiers, highly required for resource-intensive navigation and augmented reality applications.","The spiral topology of our markers permits the validation of an accurate identification scheme, which is based on level set methods.","The robustness of the markers against acquisition and geometric distortions is validated by extensive experimental tests."],"url":"http://arxiv.org/abs/2404.08477v1","category":"cs.CV"}
{"created":"2024-04-12 13:41:29","title":"TSLANet: Rethinking Transformers for Time Series Representation Learning","abstract":"Time series data, characterized by its intrinsic long and short-range dependencies, poses a unique challenge across analytical applications. While Transformer-based models excel at capturing long-range dependencies, they face limitations in noise sensitivity, computational efficiency, and overfitting with smaller datasets. In response, we introduce a novel Time Series Lightweight Adaptive Network (TSLANet), as a universal convolutional model for diverse time series tasks. Specifically, we propose an Adaptive Spectral Block, harnessing Fourier analysis to enhance feature representation and to capture both long-term and short-term interactions while mitigating noise via adaptive thresholding. Additionally, we introduce an Interactive Convolution Block and leverage self-supervised learning to refine the capacity of TSLANet for decoding complex temporal patterns and improve its robustness on different datasets. Our comprehensive experiments demonstrate that TSLANet outperforms state-of-the-art models in various tasks spanning classification, forecasting, and anomaly detection, showcasing its resilience and adaptability across a spectrum of noise levels and data sizes. The code is available at \\url{https://github.com/emadeldeen24/TSLANet}","sentences":["Time series data, characterized by its intrinsic long and short-range dependencies, poses a unique challenge across analytical applications.","While Transformer-based models excel at capturing long-range dependencies, they face limitations in noise sensitivity, computational efficiency, and overfitting with smaller datasets.","In response, we introduce a novel Time Series Lightweight Adaptive Network (TSLANet), as a universal convolutional model for diverse time series tasks.","Specifically, we propose an Adaptive Spectral Block, harnessing Fourier analysis to enhance feature representation and to capture both long-term and short-term interactions while mitigating noise via adaptive thresholding.","Additionally, we introduce an Interactive Convolution Block and leverage self-supervised learning to refine the capacity of TSLANet for decoding complex temporal patterns and improve its robustness on different datasets.","Our comprehensive experiments demonstrate that TSLANet outperforms state-of-the-art models in various tasks spanning classification, forecasting, and anomaly detection, showcasing its resilience and adaptability across a spectrum of noise levels and data sizes.","The code is available at \\url{https://github.com/emadeldeen24/TSLANet}"],"url":"http://arxiv.org/abs/2404.08472v1","category":"cs.LG"}
{"created":"2024-04-12 13:38:28","title":"Supervisory Control Theory with Event Forcing","abstract":"In the Ramadge-Wonham supervisory control theory the only interaction mechanism between supervisor and plant is that the supervisor may enable/disable events from the plant and the plant makes a final decision about which of the enabled events is actually taking place. In this paper, the interaction between supervisor and plant is enriched by allowing the supervisor to force specific events (called forcible events) that are allowed to preempt uncontrollable events. A notion of forcible-controllability is defined that captures the interplay between controllability of a supervisor w.r.t. the uncontrollable events provided by a plant in the setting with event forcing. Existence of a maximally permissive, forcibly-controllable, nonblocking supervisor is shown and an algorithm is provided that computes such a supervisor. The approach is illustrated by two small case studies.","sentences":["In the Ramadge-Wonham supervisory control theory the only interaction mechanism between supervisor and plant is that the supervisor may enable/disable events from the plant and the plant makes a final decision about which of the enabled events is actually taking place.","In this paper, the interaction between supervisor and plant is enriched by allowing the supervisor to force specific events (called forcible events) that are allowed to preempt uncontrollable events.","A notion of forcible-controllability is defined that captures the interplay between controllability of a supervisor w.r.t.","the uncontrollable events provided by a plant in the setting with event forcing.","Existence of a maximally permissive, forcibly-controllable, nonblocking supervisor is shown and an algorithm is provided that computes such a supervisor.","The approach is illustrated by two small case studies."],"url":"http://arxiv.org/abs/2404.08469v1","category":"cs.FL"}
{"created":"2024-04-12 13:31:38","title":"Electron-phonon coupling induced topological phase transition in an $\u03b1$-$T_{3}$ Haldane-Holstein model","abstract":"We present impelling evidence of topological phase transitions induced by electron-phonon (e-ph) coupling in an $\\alpha$-$T_3$ Haldane-Holstein model that presents smooth tunability between graphene ($\\alpha=0$) and a dice lattice $(\\alpha=1)$. The e-ph coupling has been incorporated via the Lang-Firsov transformation which adequately captures the polaron physics in the high frequency (anti-adiabatic) regime, and yields an effective Hamiltonian of the system through zero phonon averaging at $T=0$. While exploring the signature of the phase transition driven by polaron and its interplay with the parameter $\\alpha$, we identify two regions based on the values of $\\alpha$, namely, the low to intermediate range $(0 < \\alpha \\le 0.6)$ and larger values of $\\alpha~(0.6 < \\alpha < 1)$ where the topological transitions show distinct behaviour. There exists a single critical e-ph coupling strength for the former, below which the system behaves as a topological insulator characterized by edge modes, finite Chern number, and Hall conductivity, with all of them vanishing above this value, and the system undergoes a spectral gap closing transition. Further, the critical coupling strength depends upon $\\alpha$. For the latter case $(0.6 < \\alpha < 1)$, the scenario is more interesting where there are two critical values of the e-ph coupling at which trivial-topological-trivial and topological-topological-trivial phase transitions occur for $\\alpha$ in the range $[0.6:1]$. Our studies on e-ph coupling induced phase transitions show a significant difference with regard to the well-known unique transition occurring at $\\alpha = 0.5$ (or at $0.7$) in the absence of the e-ph coupling, and thus underscore the importance of interaction effects on the topological phase transitions.","sentences":["We present impelling evidence of topological phase transitions induced by electron-phonon (e-ph) coupling in an $\\alpha$-$T_3$ Haldane-Holstein model that presents smooth tunability between graphene ($\\alpha=0$) and a dice lattice $(\\alpha=1)$. The e-ph coupling has been incorporated via the Lang-Firsov transformation which adequately captures the polaron physics in the high frequency (anti-adiabatic) regime, and yields an effective Hamiltonian of the system through zero phonon averaging at $T=0$. While exploring the signature of the phase transition driven by polaron and its interplay with the parameter $\\alpha$, we identify two regions based on the values of $\\alpha$, namely, the low to intermediate range $(0 < \\alpha \\le 0.6)$ and larger values of $\\alpha~(0.6 < \\alpha < 1)$ where the topological transitions show distinct behaviour.","There exists a single critical e-ph coupling strength for the former, below which the system behaves as a topological insulator characterized by edge modes, finite Chern number, and Hall conductivity, with all of them vanishing above this value, and the system undergoes a spectral gap closing transition.","Further, the critical coupling strength depends upon $\\alpha$. For the latter case $(0.6 < \\alpha < 1)$, the scenario is more interesting where there are two critical values of the e-ph coupling at which trivial-topological-trivial and topological-topological-trivial phase transitions occur for $\\alpha$ in the range $[0.6:1]$. Our studies on e-ph coupling induced phase transitions show a significant difference with regard to the well-known unique transition occurring at $\\alpha = 0.5$ (or at $0.7$) in the absence of the e-ph coupling, and thus underscore the importance of interaction effects on the topological phase transitions."],"url":"http://arxiv.org/abs/2404.08467v1","category":"cond-mat.mes-hall"}
{"created":"2024-04-12 13:05:35","title":"A backward differential deep learning-based algorithm for solving high-dimensional nonlinear backward stochastic differential equations","abstract":"In this work, we propose a novel backward differential deep learning-based algorithm for solving high-dimensional nonlinear backward stochastic differential equations (BSDEs), where the deep neural network (DNN) models are trained not only on the inputs and labels but also the differentials of the corresponding labels. This is motivated by the fact that differential deep learning can provide an efficient approximation of the labels and their derivatives with respect to inputs. The BSDEs are reformulated as differential deep learning problems by using Malliavin calculus. The Malliavin derivatives of solution to a BSDE satisfy themselves another BSDE, resulting thus in a system of BSDEs. Such formulation requires the estimation of the solution, its gradient, and the Hessian matrix, represented by the triple of processes $\\left(Y, Z, \\Gamma\\right).$ All the integrals within this system are discretized by using the Euler-Maruyama method. Subsequently, DNNs are employed to approximate the triple of these unknown processes. The DNN parameters are backwardly optimized at each time step by minimizing a differential learning type loss function, which is defined as a weighted sum of the dynamics of the discretized BSDE system, with the first term providing the dynamics of the process $Y$ and the other the process $Z$. An error analysis is carried out to show the convergence of the proposed algorithm. Various numerical experiments up to $50$ dimensions are provided to demonstrate the high efficiency. Both theoretically and numerically, it is demonstrated that our proposed scheme is more efficient compared to other contemporary deep learning-based methodologies, especially in the computation of the process $\\Gamma$.","sentences":["In this work, we propose a novel backward differential deep learning-based algorithm for solving high-dimensional nonlinear backward stochastic differential equations (BSDEs), where the deep neural network (DNN) models are trained not only on the inputs and labels but also the differentials of the corresponding labels.","This is motivated by the fact that differential deep learning can provide an efficient approximation of the labels and their derivatives with respect to inputs.","The BSDEs are reformulated as differential deep learning problems by using Malliavin calculus.","The Malliavin derivatives of solution to a BSDE satisfy themselves another BSDE, resulting thus in a system of BSDEs.","Such formulation requires the estimation of the solution, its gradient, and the Hessian matrix, represented by the triple of processes $\\left(Y, Z, \\Gamma\\right).$ All the integrals within this system are discretized by using the Euler-Maruyama method.","Subsequently, DNNs are employed to approximate the triple of these unknown processes.","The DNN parameters are backwardly optimized at each time step by minimizing a differential learning type loss function, which is defined as a weighted sum of the dynamics of the discretized BSDE system, with the first term providing the dynamics of the process $Y$ and the other the process $Z$. An error analysis is carried out to show the convergence of the proposed algorithm.","Various numerical experiments up to $50$ dimensions are provided to demonstrate the high efficiency.","Both theoretically and numerically, it is demonstrated that our proposed scheme is more efficient compared to other contemporary deep learning-based methodologies, especially in the computation of the process $\\Gamma$."],"url":"http://arxiv.org/abs/2404.08456v1","category":"math.NA"}
{"created":"2024-04-12 13:02:33","title":"Lightweight Multi-System Multivariate Interconnection and Divergence Discovery","abstract":"Identifying outlier behavior among sensors and subsystems is essential for discovering faults and facilitating diagnostics in large systems. At the same time, exploring large systems with numerous multivariate data sets is challenging. This study presents a lightweight interconnection and divergence discovery mechanism (LIDD) to identify abnormal behavior in multi-system environments. The approach employs a multivariate analysis technique that first estimates the similarity heatmaps among the sensors for each system and then applies information retrieval algorithms to provide relevant multi-level interconnection and discrepancy details. Our experiment on the readout systems of the Hadron Calorimeter of the Compact Muon Solenoid (CMS) experiment at CERN demonstrates the effectiveness of the proposed method. Our approach clusters readout systems and their sensors consistent with the expected calorimeter interconnection configurations, while capturing unusual behavior in divergent clusters and estimating their root causes.","sentences":["Identifying outlier behavior among sensors and subsystems is essential for discovering faults and facilitating diagnostics in large systems.","At the same time, exploring large systems with numerous multivariate data sets is challenging.","This study presents a lightweight interconnection and divergence discovery mechanism (LIDD) to identify abnormal behavior in multi-system environments.","The approach employs a multivariate analysis technique that first estimates the similarity heatmaps among the sensors for each system and then applies information retrieval algorithms to provide relevant multi-level interconnection and discrepancy details.","Our experiment on the readout systems of the Hadron Calorimeter of the Compact Muon Solenoid (CMS) experiment at CERN demonstrates the effectiveness of the proposed method.","Our approach clusters readout systems and their sensors consistent with the expected calorimeter interconnection configurations, while capturing unusual behavior in divergent clusters and estimating their root causes."],"url":"http://arxiv.org/abs/2404.08453v1","category":"cs.LG"}
{"created":"2024-04-12 12:57:53","title":"Construction of low regularity strong solutions to the viscous surface wave equations","abstract":"We construct in the paper the low-regularity strong solutions to the viscous surface wave equations in anisotropic Sobolev spaces. Here we use the Lagrangian structure of the system to homogenize the free boundary conditions, and establish a new iteration scheme on a known equilibrium domain to get the low-regularity strong solutions, in which no nonlinear compatibility conditions on the initial data are required.","sentences":["We construct in the paper the low-regularity strong solutions to the viscous surface wave equations in anisotropic Sobolev spaces.","Here we use the Lagrangian structure of the system to homogenize the free boundary conditions, and establish a new iteration scheme on a known equilibrium domain to get the low-regularity strong solutions, in which no nonlinear compatibility conditions on the initial data are required."],"url":"http://arxiv.org/abs/2404.08448v1","category":"math.AP"}
{"created":"2024-04-12 12:57:43","title":"Federated Optimization with Doubly Regularized Drift Correction","abstract":"Federated learning is a distributed optimization paradigm that allows training machine learning models across decentralized devices while keeping the data localized. The standard method, FedAvg, suffers from client drift which can hamper performance and increase communication costs over centralized methods. Previous works proposed various strategies to mitigate drift, yet none have shown uniformly improved communication-computation trade-offs over vanilla gradient descent.   In this work, we revisit DANE, an established method in distributed optimization. We show that (i) DANE can achieve the desired communication reduction under Hessian similarity constraints. Furthermore, (ii) we present an extension, DANE+, which supports arbitrary inexact local solvers and has more freedom to choose how to aggregate the local updates. We propose (iii) a novel method, FedRed, which has improved local computational complexity and retains the same communication complexity compared to DANE/DANE+. This is achieved by using doubly regularized drift correction.","sentences":["Federated learning is a distributed optimization paradigm that allows training machine learning models across decentralized devices while keeping the data localized.","The standard method, FedAvg, suffers from client drift which can hamper performance and increase communication costs over centralized methods.","Previous works proposed various strategies to mitigate drift, yet none have shown uniformly improved communication-computation trade-offs over vanilla gradient descent.   ","In this work, we revisit DANE, an established method in distributed optimization.","We show that (i) DANE can achieve the desired communication reduction under Hessian similarity constraints.","Furthermore, (ii) we present an extension, DANE+, which supports arbitrary inexact local solvers and has more freedom to choose how to aggregate the local updates.","We propose (iii) a novel method, FedRed, which has improved local computational complexity and retains the same communication complexity compared to DANE/DANE+.","This is achieved by using doubly regularized drift correction."],"url":"http://arxiv.org/abs/2404.08447v1","category":"cs.LG"}
{"created":"2024-04-12 12:56:16","title":"Anti-Byzantine Attacks Enabled Vehicle Selection for Asynchronous Federated Learning in Vehicular Edge Computing","abstract":"In vehicle edge computing (VEC), asynchronous federated learning (AFL) is used, where the edge receives a local model and updates the global model, effectively reducing the global aggregation latency.Due to different amounts of local data,computing capabilities and locations of the vehicles, renewing the global model with same weight is inappropriate.The above factors will affect the local calculation time and upload time of the local model, and the vehicle may also be affected by Byzantine attacks, leading to the deterioration of the vehicle data. However, based on deep reinforcement learning (DRL), we can consider these factors comprehensively to eliminate vehicles with poor performance as much as possible and exclude vehicles that have suffered Byzantine attacks before AFL. At the same time, when aggregating AFL, we can focus on those vehicles with better performance to improve the accuracy and safety of the system. In this paper, we proposed a vehicle selection scheme based on DRL in VEC. In this scheme, vehicle s mobility, channel conditions with temporal variations, computational resources with temporal variations, different data amount, transmission channel status of vehicles as well as Byzantine attacks were taken into account.Simulation results show that the proposed scheme effectively improves the safety and accuracy of the global model.","sentences":["In vehicle edge computing (VEC), asynchronous federated learning (AFL) is used, where the edge receives a local model and updates the global model, effectively reducing the global aggregation latency.","Due to different amounts of local data,computing capabilities and locations of the vehicles, renewing the global model with same weight is inappropriate.","The above factors will affect the local calculation time and upload time of the local model, and the vehicle may also be affected by Byzantine attacks, leading to the deterioration of the vehicle data.","However, based on deep reinforcement learning (DRL), we can consider these factors comprehensively to eliminate vehicles with poor performance as much as possible and exclude vehicles that have suffered Byzantine attacks before AFL.","At the same time, when aggregating AFL, we can focus on those vehicles with better performance to improve the accuracy and safety of the system.","In this paper, we proposed a vehicle selection scheme based on DRL in VEC.","In this scheme, vehicle s mobility, channel conditions with temporal variations, computational resources with temporal variations, different data amount, transmission channel status of vehicles as well as Byzantine attacks were taken into account.","Simulation results show that the proposed scheme effectively improves the safety and accuracy of the global model."],"url":"http://arxiv.org/abs/2404.08444v1","category":"cs.LG"}
{"created":"2024-04-12 12:45:37","title":"Numerical Discretization Methods for Linear Quadratic Control Problems with Time Delays","abstract":"This paper presents the numerical discretization methods of the continuous-time linear-quadratic optimal control problems (LQ-OCPs) with time delays. We describe the weight matrices of the LQ-OCPs as differential equations systems, allowing us to derive the discrete equivalent of the continuous-time LQ-OCPs. Three numerical methods are introduced for solving proposed differential equations systems: 1) the ordinary differential equation (ODE) method, 2) the matrix exponential method, and 3) the step-doubling method. We implement a continuous-time model predictive control (CT-MPC) on a simulated cement mill system, and the objective function of the CT-MPC is discretized using the proposed LQ discretization scheme. The closed-loop results indicate that the CT-MPC successfully stabilizes and controls the simulated cement mill system, ensuring the viability and effectiveness of LQ discretization.","sentences":["This paper presents the numerical discretization methods of the continuous-time linear-quadratic optimal control problems (LQ-OCPs) with time delays.","We describe the weight matrices of the LQ-OCPs as differential equations systems, allowing us to derive the discrete equivalent of the continuous-time LQ-OCPs.","Three numerical methods are introduced for solving proposed differential equations systems: 1) the ordinary differential equation (ODE) method, 2) the matrix exponential method, and 3) the step-doubling method.","We implement a continuous-time model predictive control (CT-MPC) on a simulated cement mill system, and the objective function of the CT-MPC is discretized using the proposed LQ discretization scheme.","The closed-loop results indicate that the CT-MPC successfully stabilizes and controls the simulated cement mill system, ensuring the viability and effectiveness of LQ discretization."],"url":"http://arxiv.org/abs/2404.08440v1","category":"eess.SY"}
{"created":"2024-04-12 12:43:09","title":"Maturity of Vehicle Digital Twins: From Monitoring to Enabling Autonomous Driving","abstract":"Digital twinning of vehicles is an iconic application of digital twins, as the concept of twinning dates back to the twinning of NASA space vehicles. Although digital twins (DTs) in the automotive industry have been recognized for their ability to improve efficiency in design and manufacturing, their potential to enhance land vehicle operation has yet to be fully explored. Most existing DT research on vehicle operations, aside from the existing body of work on autonomous guided vehicles (AGVs), focuses on electrified passenger cars. However, the use and value of twinning varies depending on the goal, whether it is to provide cost-efficient and sustainable freight transport without disruptions, sustainable public transport focused on passenger well-being, or fully autonomous vehicle operation. In this context, DTs are used for a range of applications, from real-time battery health monitoring to enabling fully autonomous vehicle operations. This leads to varying requirements, complexities, and maturities of the implemented DT solutions. This paper analyzes recent trends in DT-driven efficiency gains for freight, public, and autonomous vehicles and discusses their required level of maturity based on a maturity tool. The application of our DT maturity tool reveals that most DTs have reached level 3 and enable real-time monitoring. Additionally, DTs of level 5 already exist in closed environments, allowing for restricted autonomous operation.","sentences":["Digital twinning of vehicles is an iconic application of digital twins, as the concept of twinning dates back to the twinning of NASA space vehicles.","Although digital twins (DTs) in the automotive industry have been recognized for their ability to improve efficiency in design and manufacturing, their potential to enhance land vehicle operation has yet to be fully explored.","Most existing DT research on vehicle operations, aside from the existing body of work on autonomous guided vehicles (AGVs), focuses on electrified passenger cars.","However, the use and value of twinning varies depending on the goal, whether it is to provide cost-efficient and sustainable freight transport without disruptions, sustainable public transport focused on passenger well-being, or fully autonomous vehicle operation.","In this context, DTs are used for a range of applications, from real-time battery health monitoring to enabling fully autonomous vehicle operations.","This leads to varying requirements, complexities, and maturities of the implemented DT solutions.","This paper analyzes recent trends in DT-driven efficiency gains for freight, public, and autonomous vehicles and discusses their required level of maturity based on a maturity tool.","The application of our DT maturity tool reveals that most DTs have reached level 3 and enable real-time monitoring.","Additionally, DTs of level 5 already exist in closed environments, allowing for restricted autonomous operation."],"url":"http://arxiv.org/abs/2404.08438v1","category":"cs.ET"}
{"created":"2024-04-12 12:16:23","title":"Universal time and length scales of polar active polymer melts","abstract":"We present an in-depth multi-scale analysis of the conformations and dynamics of polar active polymers, comparing very dilute and very dense conditions. We unveil characteristic length and time scales, common to both dilute and dense systems, that recapitulate the conformational and dynamical properties of these active polymers upon varying both the polymer size and the strength of the activity. Specifically, we find that a correlation (or looping) length characterises the polymer conformations and the monomer dynamics. Instead, the dynamics of the center of mass can be fully characterised by the end-to-end mean-square distance and by the associated relaxation time. As such, we show that the dynamics in melts of polar active polymers are not controlled by entanglements but only by the strength of the self-propulsion.","sentences":["We present an in-depth multi-scale analysis of the conformations and dynamics of polar active polymers, comparing very dilute and very dense conditions.","We unveil characteristic length and time scales, common to both dilute and dense systems, that recapitulate the conformational and dynamical properties of these active polymers upon varying both the polymer size and the strength of the activity.","Specifically, we find that a correlation (or looping) length characterises the polymer conformations and the monomer dynamics.","Instead, the dynamics of the center of mass can be fully characterised by the end-to-end mean-square distance and by the associated relaxation time.","As such, we show that the dynamics in melts of polar active polymers are not controlled by entanglements but only by the strength of the self-propulsion."],"url":"http://arxiv.org/abs/2404.08425v1","category":"cond-mat.soft"}
{"created":"2024-04-12 11:54:06","title":"Lowering the Exponential Wall: Accelerating High-Entropy Alloy Catalysts Screening using Local Surface Energy Descriptors from Neural Network Potentials","abstract":"Computational screening is indispensable for the efficient design of high-entropy alloys (HEAs), which hold great potential for catalytic applications. However, the chemical space of HEAs is exponentially vast with respect to the number of constituent elements, and even screening calculations using machine learning potentials can be enormously time-consuming. To address this challenge, we propose a method to rapidly construct models that predict the properties of HEAs from data on monometallic systems (or few-component alloys). The core of our approach is a newly-introduced descriptor called local surface energy ($LSE$), which reflects the local reactivity of solid surfaces at atomic resolution. We successfully created a model using linear regression to screen the adsorption energies of molecules on HEAs based on LSEs from monometallic systems. Furthermore, we made high-precision model development by employing both classical machine learning and quantum machine learning. Using our method, we were able to complete the adsorption energy calculations of CO molecules on 1000 patterns of quinary nanoparticles consisting of 201 atoms within a few hours. These calculations would have taken hundreds of years and hundreds of days using density functional theory and a neural network potential, respectively. Our approach allows accelerated exploration of the vast chemical space of HEAs facilitating the design of novel catalysts.","sentences":["Computational screening is indispensable for the efficient design of high-entropy alloys (HEAs), which hold great potential for catalytic applications.","However, the chemical space of HEAs is exponentially vast with respect to the number of constituent elements, and even screening calculations using machine learning potentials can be enormously time-consuming.","To address this challenge, we propose a method to rapidly construct models that predict the properties of HEAs from data on monometallic systems (or few-component alloys).","The core of our approach is a newly-introduced descriptor called local surface energy ($LSE$), which reflects the local reactivity of solid surfaces at atomic resolution.","We successfully created a model using linear regression to screen the adsorption energies of molecules on HEAs based on LSEs from monometallic systems.","Furthermore, we made high-precision model development by employing both classical machine learning and quantum machine learning.","Using our method, we were able to complete the adsorption energy calculations of CO molecules on 1000 patterns of quinary nanoparticles consisting of 201 atoms within a few hours.","These calculations would have taken hundreds of years and hundreds of days using density functional theory and a neural network potential, respectively.","Our approach allows accelerated exploration of the vast chemical space of HEAs facilitating the design of novel catalysts."],"url":"http://arxiv.org/abs/2404.08413v1","category":"quant-ph"}
{"created":"2024-04-12 11:45:00","title":"Conformal field theory with composite defect","abstract":"We explore higher-dimensional conformal field theories (CFTs) in the presence of a conformal defect that itself hosts another sub-dimensional defect. We refer to this new kind of conformal defect as the composite defect. We elaborate on the various conformal properties of the composite defect CFTs, including correlation functions, operator expansions, and conformal block expansions. As an example, we present a free O(N) vector model in the presence of a composite defect. Assuming the averaged null energy condition (ANEC) does hold even for the defect systems, we conclude that some boundary conditions can be excluded. Our investigations shed light on the rich phenomenology arising from hierarchical defect structures, paving the way for a deeper understanding of critical phenomena in nature.","sentences":["We explore higher-dimensional conformal field theories (CFTs) in the presence of a conformal defect that itself hosts another sub-dimensional defect.","We refer to this new kind of conformal defect as the composite defect.","We elaborate on the various conformal properties of the composite defect CFTs, including correlation functions, operator expansions, and conformal block expansions.","As an example, we present a free O(N) vector model in the presence of a composite defect.","Assuming the averaged null energy condition (ANEC) does hold even for the defect systems, we conclude that some boundary conditions can be excluded.","Our investigations shed light on the rich phenomenology arising from hierarchical defect structures, paving the way for a deeper understanding of critical phenomena in nature."],"url":"http://arxiv.org/abs/2404.08411v1","category":"hep-th"}
{"created":"2024-04-12 11:03:48","title":"Room-Temperature Polariton Lasing from CdSe core-only Nanoplatelets","abstract":"This paper reports how CdSe core-only nanoplatelets coupled with plasmonic Al nanoparticle lattices can exhibit exciton-polariton lasing. By improving a procedure to synthesize monodisperse 4-monolayer CdSe nanoplatelets, we could resolve polariton decay dynamics and pathways. Experiment and theory confirmed that the system is in the strong coupling regime based on anti-crossings in the dispersion diagrams and magnitude of the Rabi splitting values. Notably, polariton lasing is observed only for cavity lattice periodicities that exhibit specific dispersive characteristics that enable polariton accumulation. The threshold of polariton lasing is 25-fold lower than reported photon lasing values from CdSe nanoplatelets in similar cavity designs. This open-cavity platform offers a simple approach to control exciton polaritons anticipated to benefit quantum information processing, optoelectronics, and chemical reactions.","sentences":["This paper reports how CdSe core-only nanoplatelets coupled with plasmonic Al nanoparticle lattices can exhibit exciton-polariton lasing.","By improving a procedure to synthesize monodisperse 4-monolayer CdSe nanoplatelets, we could resolve polariton decay dynamics and pathways.","Experiment and theory confirmed that the system is in the strong coupling regime based on anti-crossings in the dispersion diagrams and magnitude of the Rabi splitting values.","Notably, polariton lasing is observed only for cavity lattice periodicities that exhibit specific dispersive characteristics that enable polariton accumulation.","The threshold of polariton lasing is 25-fold lower than reported photon lasing values from CdSe nanoplatelets in similar cavity designs.","This open-cavity platform offers a simple approach to control exciton polaritons anticipated to benefit quantum information processing, optoelectronics, and chemical reactions."],"url":"http://arxiv.org/abs/2404.08395v1","category":"physics.optics"}
{"created":"2024-04-12 10:58:09","title":"Floquet SYK wormholes","abstract":"We study the non-equilibrium dynamics of two coupled SYK models, conjectured to be holographically dual to an eternal traversable wormhole in AdS$_2$. We consider different periodic drivings of the parameters of the system. We analyze the energy flows in the wormhole and black hole phases of the model as a function of the driving frequency. Our numerical results show a series of resonant frequencies in which the energy absorption and heating are enhanced significantly and the transmission coefficients drop, signalling a closure of the wormhole. These frequencies correspond to part of the conformal tower of states and to the boundary graviton of the dual gravitational theory. Furthermore, we provide evidence supporting the existence of a hot wormhole phase between the black hole and wormhole phases. When driving the strength of the separate SYK terms we find that the transmission can be enhanced by suitably tuning the driving.","sentences":["We study the non-equilibrium dynamics of two coupled SYK models, conjectured to be holographically dual to an eternal traversable wormhole in","AdS$_2$.","We consider different periodic drivings of the parameters of the system.","We analyze the energy flows in the wormhole and black hole phases of the model as a function of the driving frequency.","Our numerical results show a series of resonant frequencies in which the energy absorption and heating are enhanced significantly and the transmission coefficients drop, signalling a closure of the wormhole.","These frequencies correspond to part of the conformal tower of states and to the boundary graviton of the dual gravitational theory.","Furthermore, we provide evidence supporting the existence of a hot wormhole phase between the black hole and wormhole phases.","When driving the strength of the separate SYK terms we find that the transmission can be enhanced by suitably tuning the driving."],"url":"http://arxiv.org/abs/2404.08394v1","category":"hep-th"}
{"created":"2024-04-12 10:45:38","title":"R\u00e9nyi entropy of the permutationally invariant part of the ground state across a quantum phase transition","abstract":"We investigate the role of the permutationally invariant part of the density matrix (PIDM) in capturing the properties of the ground state of the system during a quantum phase transition. In the context of quantum state tomography, PIDM is known to be obtainable with only a low number of measurement settings, namely $\\mathcal{O}(L^2)$, where $L$ is the system size. Considering the transverse-field Ising chain as an example, we compute the second-order R\\'enyi entropy of PIDM for the ground state by using the density matrix renormalization group algorithm. In the ferromagnetic case, the ground state is permutationally invariant both in the limits of zero and infinite field, leading to vanishing R\\'enyi entropy of PIDM. The latter exhibits a broad peak as a function of the transverse field around the quantum critical point, which gets more pronounced for larger system size. In the antiferromagnetic case, the peak structure disappears and the R\\'enyi entropy diverges like $\\mathcal{O}(L)$ in the whole field range of the ordered phase. We discuss the cause of these behaviors of the R\\'enyi entropy of PIDM, examining the possible application of this experimentally tractable quantity to the analysis of phase transition phenomena.","sentences":["We investigate the role of the permutationally invariant part of the density matrix (PIDM) in capturing the properties of the ground state of the system during a quantum phase transition.","In the context of quantum state tomography, PIDM is known to be obtainable with only a low number of measurement settings, namely $\\mathcal{O}(L^2)$, where $L$ is the system size.","Considering the transverse-field Ising chain as an example, we compute the second-order R\\'enyi entropy of PIDM for the ground state by using the density matrix renormalization group algorithm.","In the ferromagnetic case, the ground state is permutationally invariant both in the limits of zero and infinite field, leading to vanishing R\\'enyi entropy of PIDM.","The latter exhibits a broad peak as a function of the transverse field around the quantum critical point, which gets more pronounced for larger system size.","In the antiferromagnetic case, the peak structure disappears and the R\\'enyi entropy diverges like $\\mathcal{O}(L)$ in the whole field range of the ordered phase.","We discuss the cause of these behaviors of the R\\'enyi entropy of PIDM, examining the possible application of this experimentally tractable quantity to the analysis of phase transition phenomena."],"url":"http://arxiv.org/abs/2404.08389v1","category":"cond-mat.stat-mech"}
{"created":"2024-04-12 10:42:48","title":"Criteria for algebraic operators to be unitary","abstract":"Criteria for an algebraic operator $T$ on a complex Hilbert space $\\mathcal{H}$ to be unitary are established. The main one is written in terms of the convergence of sequences of the form $\\{\\|T^nh\\|\\}_{n=0}^{\\infty}$ with $h\\in \\mathcal{H}$. Related questions are also discussed.","sentences":["Criteria for an algebraic operator $T$ on a complex Hilbert space $\\mathcal{H}$ to be unitary are established.","The main one is written in terms of the convergence of sequences of the form $\\{\\|T^nh\\|\\}_{n=0}^{\\infty}$ with $h\\in \\mathcal{H}$. Related questions are also discussed."],"url":"http://arxiv.org/abs/2404.08386v1","category":"math.FA"}
{"created":"2024-04-12 10:41:23","title":"$Ab$-$initio$ nucleon-nucleon correlations and their impact on high energy $^{16}$O+$^{16}$O collisions","abstract":"Investigating nucleon-nucleon correlations inherent to the strong nuclear force is one of the core goals in nuclear physics research. We showcase the unique opportunities offered by collisions of $^{16}$O nuclei at high-energy facilities to reveal detailed many-body properties of the nuclear ground state. We interface existing knowledge about the geometry of $^{16}$O coming from \\textit{ab-initio} calculations of nuclear structure with transport simulations of high-energy $^{16}$O+$^{16}$O collisions. Bulk observables in these processes, such as the elliptic flow or the fluctuations of the mean transverse momentum, are found to depend significantly on the input nuclear model and to be sensitive to realistic clustering and short-range repulsive correlations, effectively opening a new avenue to probe these features experimentally. This finding demonstrates collisions of oxygen nuclei as a tool to elucidate initial conditions of small collision systems while fostering connections with effective field theories of nuclei rooted in quantum chromodynamics (QCD).","sentences":["Investigating nucleon-nucleon correlations inherent to the strong nuclear force is one of the core goals in nuclear physics research.","We showcase the unique opportunities offered by collisions of $^{16}$O nuclei at high-energy facilities to reveal detailed many-body properties of the nuclear ground state.","We interface existing knowledge about the geometry of $^{16}$O coming from \\textit{ab-initio} calculations of nuclear structure with transport simulations of high-energy $^{16}$O+$^{16}$O collisions.","Bulk observables in these processes, such as the elliptic flow or the fluctuations of the mean transverse momentum, are found to depend significantly on the input nuclear model and to be sensitive to realistic clustering and short-range repulsive correlations, effectively opening a new avenue to probe these features experimentally.","This finding demonstrates collisions of oxygen nuclei as a tool to elucidate initial conditions of small collision systems while fostering connections with effective field theories of nuclei rooted in quantum chromodynamics (QCD)."],"url":"http://arxiv.org/abs/2404.08385v1","category":"nucl-th"}
{"created":"2024-04-12 10:38:47","title":"High-fidelity Nuclear Coherent Population Transfer via the Mixed-State Inverse Engineering","abstract":"Nuclear coherent population transfer (NCPT) plays an important role in the exploration and application of atomic nuclei. How to achieve high-fidelity NCPT remains so far challenging. Here, we investigate the complete population transfer of nuclear states. We first consider a cyclic three-level system, based on the mixed-state inverse engineering scheme by adding additional laser fields in an open three-level nuclear system with spontaneous emission. We find the amplitude of the additional field is related to the ratio of the pump and Stokes field amplitudes. As long as an appropriate additional field is selected, complete transfer can be achieved even when the intensities of the pump and Stokes fields are exceedingly low. The transfer efficiency exhibits excellent robustness with respect to laser peak intensity and pulse delay. We demonstrate the effectiveness through examples such as $^{229}$Th, $^{223}$Ra, $^{113}$Cd, and $^{97}$Tc, which have a long lifetime excited state, as well as $^{187}$Re, $^{172}$Yb, $^{168}$Er and $^{154}$Gd with a short lifetime excited state. Focusing on the case without additional coupling, we further reduce the three-level system to an effective two-level problem. We modify the pump and Stokes pulses by using counterdiabatic driving to implement high-fidelity population transfer. The schemes open up new possibilities for controlling nuclear states.","sentences":["Nuclear coherent population transfer (NCPT) plays an important role in the exploration and application of atomic nuclei.","How to achieve high-fidelity NCPT remains so far challenging.","Here, we investigate the complete population transfer of nuclear states.","We first consider a cyclic three-level system, based on the mixed-state inverse engineering scheme by adding additional laser fields in an open three-level nuclear system with spontaneous emission.","We find the amplitude of the additional field is related to the ratio of the pump and Stokes field amplitudes.","As long as an appropriate additional field is selected, complete transfer can be achieved even when the intensities of the pump and Stokes fields are exceedingly low.","The transfer efficiency exhibits excellent robustness with respect to laser peak intensity and pulse delay.","We demonstrate the effectiveness through examples such as $^{229}$Th, $^{223}$Ra, $^{113}$Cd, and $^{97}$Tc, which have a long lifetime excited state, as well as $^{187}$Re, $^{172}$Yb, $^{168}$Er and $^{154}$Gd with a short lifetime excited state.","Focusing on the case without additional coupling, we further reduce the three-level system to an effective two-level problem.","We modify the pump and Stokes pulses by using counterdiabatic driving to implement high-fidelity population transfer.","The schemes open up new possibilities for controlling nuclear states."],"url":"http://arxiv.org/abs/2404.08384v1","category":"nucl-th"}
{"created":"2024-04-12 10:20:24","title":"Probing spontaneously symmetry-broken phases with spin-charge separation through noise correlation measurements","abstract":"Spontaneously symmetry-broken (SSB) phases are locally ordered states of matter characterizing a large variety of physical systems. Because of their specific ordering, their presence is usually witnessed by means of local order parameters. Here, we propose an alternative approach based on statistical correlations of noise after the ballistic expansion of an atomic cloud. We indeed demonstrate that probing such noise correlators allows one to discriminate among different SSB phases characterized by spin-charge separation. As a particular example, we test our prediction on a 1D extended Fermi-Hubbard model, where the competition between local and nonlocal couplings gives rise to three different SSB phases: a charge density wave, a bond-ordering wave, and an antiferromagnet. Our numerical analysis shows that this approach can accurately capture the presence of these different SSB phases, thus representing an alternative and powerful strategy to characterize strongly interacting quantum matter.","sentences":["Spontaneously symmetry-broken (SSB) phases are locally ordered states of matter characterizing a large variety of physical systems.","Because of their specific ordering, their presence is usually witnessed by means of local order parameters.","Here, we propose an alternative approach based on statistical correlations of noise after the ballistic expansion of an atomic cloud.","We indeed demonstrate that probing such noise correlators allows one to discriminate among different SSB phases characterized by spin-charge separation.","As a particular example, we test our prediction on a 1D extended Fermi-Hubbard model, where the competition between local and nonlocal couplings gives rise to three different SSB phases: a charge density wave, a bond-ordering wave, and an antiferromagnet.","Our numerical analysis shows that this approach can accurately capture the presence of these different SSB phases, thus representing an alternative and powerful strategy to characterize strongly interacting quantum matter."],"url":"http://arxiv.org/abs/2404.08374v1","category":"cond-mat.quant-gas"}
{"created":"2024-04-12 10:16:57","title":"Opinion dynamics on signed graphs and graphons: Beyond the piece-wise constant case","abstract":"In this paper we make use of graphon theory to study opinion dynamics on large networks. The opinion dynamics models that we take into consideration allow for negative interactions between the individual, i.e. competing entities whose opinions can grow apart. We consider both the repelling model and the opposing model that are studied in the literature. We define the repelling and the opposing dynamics on graphons and we show that their initial value problem's solutions exist and are unique. We then show that the graphon dynamics well approximate the dynamics on large graphs that converge to a graphon. This result applies to large random graphs that are sampled according to a graphon. All these facts are illustrated in an extended numerical example.","sentences":["In this paper we make use of graphon theory to study opinion dynamics on large networks.","The opinion dynamics models that we take into consideration allow for negative interactions between the individual, i.e. competing entities whose opinions can grow apart.","We consider both the repelling model and the opposing model that are studied in the literature.","We define the repelling and the opposing dynamics on graphons and we show that their initial value problem's solutions exist and are unique.","We then show that the graphon dynamics well approximate the dynamics on large graphs that converge to a graphon.","This result applies to large random graphs that are sampled according to a graphon.","All these facts are illustrated in an extended numerical example."],"url":"http://arxiv.org/abs/2404.08372v1","category":"physics.soc-ph"}
{"created":"2024-04-12 10:12:38","title":"ASR advancements for indigenous languages: Quechua, Guarani, Bribri, Kotiria, and Wa'ikhana","abstract":"Indigenous languages are a fundamental legacy in the development of human communication, embodying the unique identity and culture of local communities of America. The Second AmericasNLP Competition Track 1 of NeurIPS 2022 proposed developing automatic speech recognition (ASR) systems for five indigenous languages: Quechua, Guarani, Bribri, Kotiria, and Wa'ikhana. In this paper, we propose a reliable ASR model for each target language by crawling speech corpora spanning diverse sources and applying data augmentation methods that resulted in the winning approach in this competition. To achieve this, we systematically investigated the impact of different hyperparameters by a Bayesian search on the performance of the language models, specifically focusing on the variants of the Wav2vec2.0 XLS-R model: 300M and 1B parameters. Moreover, we performed a global sensitivity analysis to assess the contribution of various hyperparametric configurations to the performances of our best models. Importantly, our results show that freeze fine-tuning updates and dropout rate are more vital parameters than the total number of epochs of lr. Additionally, we liberate our best models -- with no other ASR model reported until now for two Wa'ikhana and Kotiria -- and the many experiments performed to pave the way to other researchers to continue improving ASR in minority languages. This insight opens up interesting avenues for future work, allowing for the advancement of ASR techniques in the preservation of minority indigenous and acknowledging the complexities involved in this important endeavour.","sentences":["Indigenous languages are a fundamental legacy in the development of human communication, embodying the unique identity and culture of local communities of America.","The Second AmericasNLP Competition Track 1 of NeurIPS 2022 proposed developing automatic speech recognition (ASR) systems for five indigenous languages: Quechua, Guarani, Bribri, Kotiria, and Wa'ikhana.","In this paper, we propose a reliable ASR model for each target language by crawling speech corpora spanning diverse sources and applying data augmentation methods that resulted in the winning approach in this competition.","To achieve this, we systematically investigated the impact of different hyperparameters by a Bayesian search on the performance of the language models, specifically focusing on the variants of the Wav2vec2.0 XLS-R model: 300M and 1B parameters.","Moreover, we performed a global sensitivity analysis to assess the contribution of various hyperparametric configurations to the performances of our best models.","Importantly, our results show that freeze fine-tuning updates and dropout rate are more vital parameters than the total number of epochs of lr.","Additionally, we liberate our best models -- with no other ASR model reported until now for two Wa'ikhana and Kotiria -- and the many experiments performed to pave the way to other researchers to continue improving ASR in minority languages.","This insight opens up interesting avenues for future work, allowing for the advancement of ASR techniques in the preservation of minority indigenous and acknowledging the complexities involved in this important endeavour."],"url":"http://arxiv.org/abs/2404.08368v1","category":"cs.CL"}
{"created":"2024-04-12 10:08:54","title":"FlowWalker: A Memory-efficient and High-performance GPU-based Dynamic Graph Random Walk Framework","abstract":"Dynamic graph random walk (DGRW) emerges as a practical tool for capturing structural relations within a graph. Effectively executing DGRW on GPU presents certain challenges. First, existing sampling methods demand a pre-processing buffer, causing substantial space complexity. Moreover, the power-law distribution of graph vertex degrees introduces workload imbalance issues, rendering DGRW embarrassed to parallelize. In this paper, we propose FlowWalker, a GPU-based dynamic graph random walk framework. FlowWalker implements an efficient parallel sampling method to fully exploit the GPU parallelism and reduce space complexity. Moreover, it employs a sampler-centric paradigm alongside a dynamic scheduling strategy to handle the huge amounts of walking queries. FlowWalker stands as a memory-efficient framework that requires no auxiliary data structures in GPU global memory. We examine the performance of FlowWalker extensively on ten datasets, and experiment results show that FlowWalker achieves up to 752.2x, 72.1x, and 16.4x speedup compared with existing CPU, GPU, and FPGA random walk frameworks, respectively. Case study shows that FlowWalker diminishes random walk time from 35% to 3% in a pipeline of ByteDance friend recommendation GNN training.","sentences":["Dynamic graph random walk (DGRW) emerges as a practical tool for capturing structural relations within a graph.","Effectively executing DGRW on GPU presents certain challenges.","First, existing sampling methods demand a pre-processing buffer, causing substantial space complexity.","Moreover, the power-law distribution of graph vertex degrees introduces workload imbalance issues, rendering DGRW embarrassed to parallelize.","In this paper, we propose FlowWalker, a GPU-based dynamic graph random walk framework.","FlowWalker implements an efficient parallel sampling method to fully exploit the GPU parallelism and reduce space complexity.","Moreover, it employs a sampler-centric paradigm alongside a dynamic scheduling strategy to handle the huge amounts of walking queries.","FlowWalker stands as a memory-efficient framework that requires no auxiliary data structures in GPU global memory.","We examine the performance of FlowWalker extensively on ten datasets, and experiment results show that FlowWalker achieves up to 752.2x, 72.1x, and 16.4x speedup compared with existing CPU, GPU, and FPGA random walk frameworks, respectively.","Case study shows that FlowWalker diminishes random walk time from 35% to 3% in a pipeline of ByteDance friend recommendation GNN training."],"url":"http://arxiv.org/abs/2404.08364v1","category":"cs.DC"}
{"created":"2024-04-12 09:57:28","title":"Optimization-Based System Identification and Moving Horizon Estimation Using Low-Cost Sensors for a Miniature Car-Like Robot","abstract":"This paper presents an open-source miniature car-like robot with low-cost sensing and a pipeline for optimization-based system identification, state estimation, and control. The overall robotics platform comes at a cost of less than $700 and thus significantly simplifies the verification of advanced algorithms in a realistic setting. We present a modified bicycle model with Pacejka tire forces to model the dynamics of the considered all-wheel drive vehicle and to prevent singularities of the model at low velocities. Furthermore, we provide an optimization-based system identification approach and a moving horizon estimation (MHE) scheme. In extensive hardware experiments, we show that the presented system identification approach results in a model with high prediction accuracy, while the MHE results in accurate state estimates. Finally, the overall closed-loop system is shown to perform well even in the presence of sensor failure for limited time intervals. All hardware, firmware, and control and estimation software is released under a BSD 2-clause license to promote widespread adoption and collaboration within the community.","sentences":["This paper presents an open-source miniature car-like robot with low-cost sensing and a pipeline for optimization-based system identification, state estimation, and control.","The overall robotics platform comes at a cost of less than $700 and thus significantly simplifies the verification of advanced algorithms in a realistic setting.","We present a modified bicycle model with Pacejka tire forces to model the dynamics of the considered all-wheel drive vehicle and to prevent singularities of the model at low velocities.","Furthermore, we provide an optimization-based system identification approach and a moving horizon estimation (MHE) scheme.","In extensive hardware experiments, we show that the presented system identification approach results in a model with high prediction accuracy, while the MHE results in accurate state estimates.","Finally, the overall closed-loop system is shown to perform well even in the presence of sensor failure for limited time intervals.","All hardware, firmware, and control and estimation software is released under a BSD 2-clause license to promote widespread adoption and collaboration within the community."],"url":"http://arxiv.org/abs/2404.08362v1","category":"cs.RO"}
{"created":"2024-04-12 09:23:46","title":"Theory of time-bin entangled photons from quantum emitters","abstract":"Entangled photon pairs form the foundation for many applications in the realm of quantum communication. For fiber-optic transfer of entangled photon pairs, time-bin encoding can potentially offer an improved stability compared to polarization encoded qubits. Here, we lay the theoretical foundations to describe the measurement of time-bin entangled photons. We derive multi-time correlation functions of the time-bin encoded photon pairs, corresponding to quantum state tomographic measurements. Our theory can be the starting point to extend the simulations to include all kinds of loss or decoherence effects that apply in a specific quantum system for realistic simulation for time-bin entanglement from quantum emitters.","sentences":["Entangled photon pairs form the foundation for many applications in the realm of quantum communication.","For fiber-optic transfer of entangled photon pairs, time-bin encoding can potentially offer an improved stability compared to polarization encoded qubits.","Here, we lay the theoretical foundations to describe the measurement of time-bin entangled photons.","We derive multi-time correlation functions of the time-bin encoded photon pairs, corresponding to quantum state tomographic measurements.","Our theory can be the starting point to extend the simulations to include all kinds of loss or decoherence effects that apply in a specific quantum system for realistic simulation for time-bin entanglement from quantum emitters."],"url":"http://arxiv.org/abs/2404.08348v1","category":"quant-ph"}
{"created":"2024-04-12 09:02:52","title":"On geometric properties of $\\ell^{p}$-spaces on unitary duals of compact groups","abstract":"In this paper, we study geometric properties of $\\ell^{p}$-spaces associated with the unitary dual of a compact group. More precisely, we prove uniform smoothness, uniform convexity, Clarkson type inequalities, Kadec-Klee property, as well as type and cotype properties of such spaces. We also present duality and complex interpolation results.","sentences":["In this paper, we study geometric properties of $\\ell^{p}$-spaces associated with the unitary dual of a compact group.","More precisely, we prove uniform smoothness, uniform convexity, Clarkson type inequalities, Kadec-Klee property, as well as type and cotype properties of such spaces.","We also present duality and complex interpolation results."],"url":"http://arxiv.org/abs/2404.08337v1","category":"math.FA"}
{"created":"2024-04-12 08:56:16","title":"Guaranteed Completion of Complex Tasks via Temporal Logic Trees and Hamilton-Jacobi Reachability","abstract":"In this paper, we present an approach for guaranteeing the completion of complex tasks with cyber-physical systems (CPS). Specifically, we leverage temporal logic trees constructed using Hamilton-Jacobi reachability analysis to (1) check for the existence of control policies that complete a specified task and (2) develop a computationally-efficient approach to synthesize the full set of control inputs the CPS can implement in real-time to ensure the task is completed. We show that, by checking the approximation directions of each state set in the temporal logic tree, we can check if the temporal logic tree suffers from the \"leaking corner issue,\" where the intersection of reachable sets yields an incorrect approximation. By ensuring a temporal logic tree has no leaking corners, we know the temporal logic tree correctly verifies the existence of control policies that satisfy the specified task. After confirming the existence of control policies, we show that we can leverage the value functions obtained through Hamilton-Jacobi reachability analysis to efficiently compute the set of control inputs the CPS can implement throughout the deployment time horizon to guarantee the completion of the specified task. Finally, we use a newly released Python toolbox to evaluate the presented approach on a simulated driving task.","sentences":["In this paper, we present an approach for guaranteeing the completion of complex tasks with cyber-physical systems (CPS).","Specifically, we leverage temporal logic trees constructed using Hamilton-Jacobi reachability analysis to (1) check for the existence of control policies that complete a specified task and (2) develop a computationally-efficient approach to synthesize the full set of control inputs the CPS can implement in real-time to ensure the task is completed.","We show that, by checking the approximation directions of each state set in the temporal logic tree, we can check if the temporal logic tree suffers from the \"leaking corner issue,\" where the intersection of reachable sets yields an incorrect approximation.","By ensuring a temporal logic tree has no leaking corners, we know the temporal logic tree correctly verifies the existence of control policies that satisfy the specified task.","After confirming the existence of control policies, we show that we can leverage the value functions obtained through Hamilton-Jacobi reachability analysis to efficiently compute the set of control inputs the CPS can implement throughout the deployment time horizon to guarantee the completion of the specified task.","Finally, we use a newly released Python toolbox to evaluate the presented approach on a simulated driving task."],"url":"http://arxiv.org/abs/2404.08334v1","category":"eess.SY"}
{"created":"2024-04-12 08:35:49","title":"Quaternion-Based Attitude Stabilization Using Synergistic Hybrid Feedback With Minimal Potential Functions","abstract":"This paper investigates the robust global attitude stabilization problem for a rigid-body system using quaternion-based feedback. We propose a novel synergistic hybrid feedback with the following notable features: (1) It demonstrates central synergism by utilizing a minimal number of potential functions; (2) It ensures consistency with respect to the unit quaternion representation of rigid-body attitude; (3) Its state-feedback laws incorporate a shared action term that steers the system toward the desired attitude. We demonstrate that the proposed hybrid feedback method effectively solves the problem at hand and guarantees robust uniform global asymptotic stability.","sentences":["This paper investigates the robust global attitude stabilization problem for a rigid-body system using quaternion-based feedback.","We propose a novel synergistic hybrid feedback with the following notable features: (1) It demonstrates central synergism by utilizing a minimal number of potential functions; (2) It ensures consistency with respect to the unit quaternion representation of rigid-body attitude; (3) Its state-feedback laws incorporate a shared action term that steers the system toward the desired attitude.","We demonstrate that the proposed hybrid feedback method effectively solves the problem at hand and guarantees robust uniform global asymptotic stability."],"url":"http://arxiv.org/abs/2404.08326v1","category":"eess.SY"}
{"created":"2024-04-12 08:27:55","title":"Improved parameter selection strategy for the iterated Arnoldi-Tikhonov method","abstract":"The iterated Arnoldi-Tikhonov (iAT) method is a regularization technique particularly suited for solving large-scale ill-posed linear inverse problems. Indeed, it reduces the computational complexity through the projection of the discretized problem into a lower-dimensional Krylov subspace, where the problem is then solved.   This paper studies iAT under an additional hypothesis on the discretized operator. It presents a theoretical analysis of the approximation errors, leading to an a posteriori rule for choosing the regularization parameter. Our proposed rule results in more accurate computed approximate solutions compared to the a posteriori rule recently proposed in arXiv:2311.11823. The numerical results confirm the theoretical analysis, providing accurate computed solutions even when the new assumption is not satisfied.","sentences":["The iterated Arnoldi-Tikhonov (iAT) method is a regularization technique particularly suited for solving large-scale ill-posed linear inverse problems.","Indeed, it reduces the computational complexity through the projection of the discretized problem into a lower-dimensional Krylov subspace, where the problem is then solved.   ","This paper studies iAT under an additional hypothesis on the discretized operator.","It presents a theoretical analysis of the approximation errors, leading to an a posteriori rule for choosing the regularization parameter.","Our proposed rule results in more accurate computed approximate solutions compared to the a posteriori rule recently proposed in arXiv:2311.11823.","The numerical results confirm the theoretical analysis, providing accurate computed solutions even when the new assumption is not satisfied."],"url":"http://arxiv.org/abs/2404.08321v1","category":"math.NA"}
{"created":"2024-04-12 08:27:06","title":"A splitting, discontinuous Galerkin solver for the cell-by-cell electroneutral Nernst-Planck framework","abstract":"Mathematical models for excitable tissue with explicit representation of individual cells are highly detailed and can, unlike classical homogenized models, represent complex cellular geometries and local membrane variations. However, these cell-based models are challenging to approximate numerically, partly due to their mixed-dimensional nature with unknowns both in the bulk and at the lower-dimensional cellular membranes. We here develop and evaluate a novel solution strategy for the cell-based KNP-EMI model describing ionic electrodiffusion in and between intra- and extracellular compartments with explicit representation of individual cells. The strategy is based on operator splitting, a multiplier-free formulation of the coupled dynamics across sub-regions, and a discontinuous Galerkin discretization. In addition to desirable theoretical properties, such as local mass conservation, the scheme is practical as it requires no specialized functionality in the finite element assembly and order optimal solvers for the resulting linear systems can be realized with black-box algebraic multigrid preconditioners. Numerical investigations show that the proposed solution strategy is accurate, robust with respect to discretization parameters, and that the parallel scalability of the solver is close to optimal - both for idealized and realistic two and three dimensional geometries.","sentences":["Mathematical models for excitable tissue with explicit representation of individual cells are highly detailed and can, unlike classical homogenized models, represent complex cellular geometries and local membrane variations.","However, these cell-based models are challenging to approximate numerically, partly due to their mixed-dimensional nature with unknowns both in the bulk and at the lower-dimensional cellular membranes.","We here develop and evaluate a novel solution strategy for the cell-based KNP-EMI model describing ionic electrodiffusion in and between intra- and extracellular compartments with explicit representation of individual cells.","The strategy is based on operator splitting, a multiplier-free formulation of the coupled dynamics across sub-regions, and a discontinuous Galerkin discretization.","In addition to desirable theoretical properties, such as local mass conservation, the scheme is practical as it requires no specialized functionality in the finite element assembly and order optimal solvers for the resulting linear systems can be realized with black-box algebraic multigrid preconditioners.","Numerical investigations show that the proposed solution strategy is accurate, robust with respect to discretization parameters, and that the parallel scalability of the solver is close to optimal - both for idealized and realistic two and three dimensional geometries."],"url":"http://arxiv.org/abs/2404.08320v1","category":"cs.CE"}
{"created":"2024-04-12 08:22:39","title":"Finite State Mean Field Games with Common Shocks","abstract":"We present a novel framework for mean field games with finite state space and common noise, where the common noise is given through shocks that occur at random times. We first analyze the game for up to $n$ shocks, in which case we are able to characterize mean field equilibria through a system of parameterized and coupled forward-backward equations. We establish existence and uniqueness of solutions to this system for small time horizons. In addition, we show that mean field equilibria for the $n$-shock setting constitute approximate equilibria for the corresponding mean field game with infinitely many common shocks. Our results are illustrated in a corruption detection model with random audits.","sentences":["We present a novel framework for mean field games with finite state space and common noise, where the common noise is given through shocks that occur at random times.","We first analyze the game for up to $n$ shocks, in which case we are able to characterize mean field equilibria through a system of parameterized and coupled forward-backward equations.","We establish existence and uniqueness of solutions to this system for small time horizons.","In addition, we show that mean field equilibria for the $n$-shock setting constitute approximate equilibria for the corresponding mean field game with infinitely many common shocks.","Our results are illustrated in a corruption detection model with random audits."],"url":"http://arxiv.org/abs/2404.08316v1","category":"math.OC"}
{"created":"2024-04-12 08:22:05","title":"Enabling Science from the Rubin Alert Stream with Lasair","abstract":"Lasair is the UK Community Broker for transient alerts from the Legacy Survey of Space and Time (LSST) from the Vera C. Rubin Observatory. We explain the system's capabilities, how users can achieve their scientific goals, and how Lasair is implemented. Lasair offers users a kit of parts that they can use to build filters to concentrate their desired alerts. The kit has novel lightcurve features, sky context, watchlists of special sky objects and regions of the sky, dynamic crossmatching with catalogues of known astronomical sources, and classifications and annotations from other users and partner projects. These resources can be shared with other users, copied, and modified. Lasair offers real-time machine-to-machine notifications of filtered transient alerts. Even though the Rubin Observatory is not yet complete, Lasair is a mature system: it has been processing and serving data from the similarly formatted stream of the Zwicky Transient Facility (ZTF) alerts.","sentences":["Lasair is the UK Community Broker for transient alerts from the Legacy Survey of Space and Time (LSST) from the Vera C. Rubin Observatory.","We explain the system's capabilities, how users can achieve their scientific goals, and how Lasair is implemented.","Lasair offers users a kit of parts that they can use to build filters to concentrate their desired alerts.","The kit has novel lightcurve features, sky context, watchlists of special sky objects and regions of the sky, dynamic crossmatching with catalogues of known astronomical sources, and classifications and annotations from other users and partner projects.","These resources can be shared with other users, copied, and modified.","Lasair offers real-time machine-to-machine notifications of filtered transient alerts.","Even though the Rubin Observatory is not yet complete, Lasair is a mature system: it has been processing and serving data from the similarly formatted stream of the Zwicky Transient Facility (ZTF) alerts."],"url":"http://arxiv.org/abs/2404.08315v1","category":"astro-ph.IM"}
{"created":"2024-04-12 08:00:38","title":"Performance Analysis of Decentralized Physical Infrastructure Networks and Centralized Clouds","abstract":"The advent of Decentralized Physical Infrastructure Networks (DePIN) represents a shift in the digital infrastructure of today's Internet. While Centralized Service Providers (CSP) monopolize cloud computing, DePINs aim to enhance data sovereignty and confidentiality and increase resilience against a single point of failure. Due to the novelty of the emerging field of DePIN, this work focuses on the potential of DePINs to disrupt traditional centralized architectures by taking advantage of the Internet of Things (IoT) devices and crypto-economic design in combination with blockchains. This combination yields Acurast, a more distributed, resilient, and user-centric physical infrastructure deployment. Through comparative analysis with centralized systems, particularly in serverless computing contexts, this work seeks to lay the first steps in scientifically evaluating DePINs and quantitatively comparing them in terms of efficiency and effectiveness in real-world applications. The findings suggest DePINs' potential to (i) reduce trust assumptions and physically decentralized infrastructure, (ii) increase efficiency and performance simultaneously while improving the computation's (iii) confidentiality and verifiability.","sentences":["The advent of Decentralized Physical Infrastructure Networks (DePIN) represents a shift in the digital infrastructure of today's Internet.","While Centralized Service Providers (CSP) monopolize cloud computing, DePINs aim to enhance data sovereignty and confidentiality and increase resilience against a single point of failure.","Due to the novelty of the emerging field of DePIN, this work focuses on the potential of DePINs to disrupt traditional centralized architectures by taking advantage of the Internet of Things (IoT) devices and crypto-economic design in combination with blockchains.","This combination yields Acurast, a more distributed, resilient, and user-centric physical infrastructure deployment.","Through comparative analysis with centralized systems, particularly in serverless computing contexts, this work seeks to lay the first steps in scientifically evaluating DePINs and quantitatively comparing them in terms of efficiency and effectiveness in real-world applications.","The findings suggest DePINs' potential to (i) reduce trust assumptions and physically decentralized infrastructure, (ii) increase efficiency and performance simultaneously while improving the computation's (iii) confidentiality and verifiability."],"url":"http://arxiv.org/abs/2404.08306v1","category":"cs.CR"}
{"created":"2024-04-12 07:45:55","title":"Topological insulators based on $p$-wave altermagnets, electrical control and detection of the altermagnetic domain wall","abstract":"We study a one-dimensional hybrid system made of a $p$-wave altermagnet and a metal possessing the orbital degree of freedom. The hybrid system is a topological insulator without the spin-orbit interaction. There emerge two edge states per one edge, because the system is mapped to a set of two copies of a topological insulator. Each copy resembles the long-range Su-Schrieffer-Heeger model but it is topologically different. Topological interface states emerge at a domain wall of the $p$-wave altermagnet, which are charged due to the Jackiw-Rebbi mechanism. Hence, the domain wall of the $p$-wave is controllable and detectable by purely electrical means.","sentences":["We study a one-dimensional hybrid system made of a $p$-wave altermagnet and a metal possessing the orbital degree of freedom.","The hybrid system is a topological insulator without the spin-orbit interaction.","There emerge two edge states per one edge, because the system is mapped to a set of two copies of a topological insulator.","Each copy resembles the long-range Su-Schrieffer-Heeger model but it is topologically different.","Topological interface states emerge at a domain wall of the $p$-wave altermagnet, which are charged due to the Jackiw-Rebbi mechanism.","Hence, the domain wall of the $p$-wave is controllable and detectable by purely electrical means."],"url":"http://arxiv.org/abs/2404.08300v1","category":"cond-mat.mes-hall"}
{"created":"2024-04-12 07:41:17","title":"Interference Motion Removal for Doppler Radar Vital Sign Detection Using Variational Encoder-Decoder Neural Network","abstract":"The treatment of interfering motion contributions remains one of the key challenges in the domain of radar-based vital sign monitoring. Removal of the interference to extract the vital sign contributions is demanding due to overlapping Doppler bands, the complex structure of the interference motions and significant variations in the power levels of their contributions. A novel approach to the removal of interference through the use of a probabilistic deep learning model is presented. Results show that a convolutional encoder-decoder neural network with a variational objective is capable of learning a meaningful representation space of vital sign Doppler-time distribution facilitating their extraction from a mixture signal. The approach is tested on semi-experimental data containing real vital sign signatures and simulated returns from interfering body motions. The application of the proposed network enhances the extraction of the micro-Doppler frequency corresponding to the respiration rate is demonstrated.","sentences":["The treatment of interfering motion contributions remains one of the key challenges in the domain of radar-based vital sign monitoring.","Removal of the interference to extract the vital sign contributions is demanding due to overlapping Doppler bands, the complex structure of the interference motions and significant variations in the power levels of their contributions.","A novel approach to the removal of interference through the use of a probabilistic deep learning model is presented.","Results show that a convolutional encoder-decoder neural network with a variational objective is capable of learning a meaningful representation space of vital sign Doppler-time distribution facilitating their extraction from a mixture signal.","The approach is tested on semi-experimental data containing real vital sign signatures and simulated returns from interfering body motions.","The application of the proposed network enhances the extraction of the micro-Doppler frequency corresponding to the respiration rate is demonstrated."],"url":"http://arxiv.org/abs/2404.08298v1","category":"cs.CV"}
{"created":"2024-04-12 07:41:13","title":"Towards a representer theorem for identification of passive systems","abstract":"A major problem in system identification is the incorporation of prior knowledge about the physical properties of the given system, such as stability, positivity and passivity. In this paper, we present first steps towards tackling this problem for passive systems. In particular, using ideas from the theory of reproducing kernel Hilbert spaces, we solve the problem of identifying a nonnegative input-output operator from data consisting of input-output trajectories of the system. We prove a representer theorem for this problem in the case where the input space is finite-dimensional. This provides a computationally tractable solution, which we show can be obtained by solving an associated semidefinite program.","sentences":["A major problem in system identification is the incorporation of prior knowledge about the physical properties of the given system, such as stability, positivity and passivity.","In this paper, we present first steps towards tackling this problem for passive systems.","In particular, using ideas from the theory of reproducing kernel Hilbert spaces, we solve the problem of identifying a nonnegative input-output operator from data consisting of input-output trajectories of the system.","We prove a representer theorem for this problem in the case where the input space is finite-dimensional.","This provides a computationally tractable solution, which we show can be obtained by solving an associated semidefinite program."],"url":"http://arxiv.org/abs/2404.08297v1","category":"math.OC"}
{"created":"2024-04-12 07:30:24","title":"AdaContour: Adaptive Contour Descriptor with Hierarchical Representation","abstract":"Existing angle-based contour descriptors suffer from lossy representation for non-starconvex shapes. By and large, this is the result of the shape being registered with a single global inner center and a set of radii corresponding to a polar coordinate parameterization. In this paper, we propose AdaContour, an adaptive contour descriptor that uses multiple local representations to desirably characterize complex shapes. After hierarchically encoding object shapes in a training set and constructing a contour matrix of all subdivided regions, we compute a robust low-rank robust subspace and approximate each local contour by linearly combining the shared basis vectors to represent an object. Experiments show that AdaContour is able to represent shapes more accurately and robustly than other descriptors while retaining effectiveness. We validate AdaContour by integrating it into off-the-shelf detectors to enable instance segmentation which demonstrates faithful performance. The code is available at https://github.com/tding1/AdaContour.","sentences":["Existing angle-based contour descriptors suffer from lossy representation for non-starconvex shapes.","By and large, this is the result of the shape being registered with a single global inner center and a set of radii corresponding to a polar coordinate parameterization.","In this paper, we propose AdaContour, an adaptive contour descriptor that uses multiple local representations to desirably characterize complex shapes.","After hierarchically encoding object shapes in a training set and constructing a contour matrix of all subdivided regions, we compute a robust low-rank robust subspace and approximate each local contour by linearly combining the shared basis vectors to represent an object.","Experiments show that AdaContour is able to represent shapes more accurately and robustly than other descriptors while retaining effectiveness.","We validate AdaContour by integrating it into off-the-shelf detectors to enable instance segmentation which demonstrates faithful performance.","The code is available at https://github.com/tding1/AdaContour."],"url":"http://arxiv.org/abs/2404.08292v1","category":"cs.CV"}
{"created":"2024-04-12 07:30:08","title":"On Input Formats for Radar Micro-Doppler Signature Processing by Convolutional Neural Networks","abstract":"Convolutional neural networks have often been proposed for processing radar Micro-Doppler signatures, most commonly with the goal of classifying the signals. The majority of works tend to disregard phase information from the complex time-frequency representation. Here, the utility of the phase information, as well as the optimal format of the Doppler-time input for a convolutional neural network, is analysed. It is found that the performance achieved by convolutional neural network classifiers is heavily influenced by the type of input representation, even across formats with equivalent information. Furthermore, it is demonstrated that the phase component of the Doppler-time representation contains rich information useful for classification and that unwrapping the phase in the temporal dimension can improve the results compared to a magnitude-only solution, improving accuracy from 0.920 to 0.938 on the tested human activity dataset. Further improvement of 0.947 is achieved by training a linear classifier on embeddings from multiple-formats.","sentences":["Convolutional neural networks have often been proposed for processing radar Micro-Doppler signatures, most commonly with the goal of classifying the signals.","The majority of works tend to disregard phase information from the complex time-frequency representation.","Here, the utility of the phase information, as well as the optimal format of the Doppler-time input for a convolutional neural network, is analysed.","It is found that the performance achieved by convolutional neural network classifiers is heavily influenced by the type of input representation, even across formats with equivalent information.","Furthermore, it is demonstrated that the phase component of the Doppler-time representation contains rich information useful for classification and that unwrapping the phase in the temporal dimension can improve the results compared to a magnitude-only solution, improving accuracy from 0.920 to 0.938 on the tested human activity dataset.","Further improvement of 0.947 is achieved by training a linear classifier on embeddings from multiple-formats."],"url":"http://arxiv.org/abs/2404.08291v1","category":"cs.CV"}
{"created":"2024-04-12 07:14:12","title":"SNAKE-fMRI: A modular fMRI data simulator from the space-time domain to k-space and back","abstract":"We propose a new, modular, open-source, Python-based 3D+time fMRI data simulation software, \\emph{SNAKE-fMRI}, which stands for \\emph{S}imulator from \\emph{N}eurovascular coupling to \\emph{A}cquisition of \\emph{K}-space data for \\emph{E}xploration of fMRI acquisition techniques.Unlike existing tools, the goal here is to simulate the complete chain of fMRI data acquisition, from the spatio-temporal design of evoked brain responses to various multi-coil k-space data 3D sampling strategies, with the possibility of extending the forward acquisition model to various noise and artifact sources while remaining memory-efficient.By using this \\emph{in silico} setup, we are thus able to provide realistic and reproducible ground truth for fMRI reconstruction methods in 3D accelerated acquisition settings and explore the influence of critical parameters, such as the acceleration factor and signal-to-noise ratio~(SNR), on downstream tasks of image reconstruction and statistical analysis of evoked brain activity.We present three scenarios of increasing complexity to showcase the flexibility, versatility, and fidelity of \\emph{SNAKE-fMRI}: From a temporally-fixed full 3D Cartesian to various 3D non-Cartesian sampling patterns, we can compare -- with reproducibility guarantees -- how experimental paradigms, acquisition strategies and reconstruction methods contribute and interact together, affecting the downstream statistical analysis.","sentences":["We propose a new, modular, open-source, Python-based 3D+time fMRI data simulation software, \\emph{SNAKE-fMRI}, which stands for \\emph{S}imulator from \\emph{N}eurovascular coupling to \\emph{A}cquisition of \\emph{K}-space data for \\emph{E}xploration of fMRI acquisition techniques.","Unlike existing tools, the goal here is to simulate the complete chain of fMRI data acquisition, from the spatio-temporal design of evoked brain responses to various multi-coil k-space data 3D sampling strategies, with the possibility of extending the forward acquisition model to various noise and artifact sources while remaining memory-efficient.","By using this \\emph{in silico} setup, we are thus able to provide realistic and reproducible ground truth for fMRI reconstruction methods in 3D accelerated acquisition settings and explore the influence of critical parameters, such as the acceleration factor and signal-to-noise ratio~(SNR), on downstream tasks of image reconstruction and statistical analysis of evoked brain activity.","We present three scenarios of increasing complexity to showcase the flexibility, versatility, and fidelity of \\emph{SNAKE-fMRI}: From a temporally-fixed full 3D Cartesian to various 3D non-Cartesian sampling patterns, we can compare -- with reproducibility guarantees -- how experimental paradigms, acquisition strategies and reconstruction methods contribute and interact together, affecting the downstream statistical analysis."],"url":"http://arxiv.org/abs/2404.08282v1","category":"eess.SP"}
{"created":"2024-04-12 06:35:03","title":"Amenable graphs and the spectral radius of extensions of Markov maps","abstract":"We discuss relations between the amenability of a graph and spectral properties of a random walk driven by a dynamical system. In order to include graphs which are not locally compact, we introduce the concept of amenability of weighted graphs, which generalises the usual notion as the new definition is shown to be equivalent to Foelner's condition. As a first result, we obtain the following generalisation of Kesten's amenability criterion to graphs and non-independent increments: If the random walk is driven by a full-branched Gibbs-Markov map, the graph is amenable with respect to the weight induced by the random walk if and only if the spectral radius of the associated Markov operator is equal to one. By employing inducing schemes, one then obtains criteria for amenability through Markov maps with less regularity. We conclude the paper with the following applications to Schreier graphs. If the random walk is driven by an uniformly expanding map with non-Markovian increments, then, under certain conditions, the Schreier graph is amenable if the probability of a return in time n does not decay exponentially in n. Furthermore, in the context of geometrically finite Kleinian groups, one obtains a version of Brooks's amenability criterion for not necessarily normal subgroups.","sentences":["We discuss relations between the amenability of a graph and spectral properties of a random walk driven by a dynamical system.","In order to include graphs which are not locally compact, we introduce the concept of amenability of weighted graphs, which generalises the usual notion as the new definition is shown to be equivalent to Foelner's condition.","As a first result, we obtain the following generalisation of Kesten's amenability criterion to graphs and non-independent increments: If the random walk is driven by a full-branched Gibbs-Markov map, the graph is amenable with respect to the weight induced by the random walk if and only if the spectral radius of the associated Markov operator is equal to one.","By employing inducing schemes, one then obtains criteria for amenability through Markov maps with less regularity.","We conclude the paper with the following applications to Schreier graphs.","If the random walk is driven by an uniformly expanding map with non-Markovian increments, then, under certain conditions, the Schreier graph is amenable if the probability of a return in time n does not decay exponentially in n.","Furthermore, in the context of geometrically finite Kleinian groups, one obtains a version of Brooks's amenability criterion for not necessarily normal subgroups."],"url":"http://arxiv.org/abs/2404.08270v1","category":"math.DS"}
{"created":"2024-04-12 06:32:08","title":"Joint Design of Self-Tuning UHF RFID Antenna and Microfluidic Channel for Liquid Sensing","abstract":"Microfluidic has been an enabling technology for over a decade, particularly in the field of medical and wearable devices, allowing for the manipulation of small amounts of fluid in confined spaces. Micro-channels can also be used for wireless sensing thanks to the variations in antenna properties when the fluid flows near it. However, up to now, microfluidic channels and sensing antennas have always been designed separately; instead, since the liquid flow and the antenna geometry both contribute to the overall performance, they should be considered simultaneously when optimizing the antenna-microfluidic system. In this paper, the joint design of the antenna and microfluidic channels is investigated for liquid quantification. Self-tuning RFID microchips are exploited to minimize communication degradation due to the increase of lossy liquid amount over the sensing antenna while digitalizing the impedance mismatch itself. To experimentally corroborate the joint design technique, two different geometries are obtained and prototyped starting from a given antenna-microfluidic layout by setting different goals for an optimization function. The two flexible RFID prototypes returned performance in agreement with the simulated ones, achieving a maximum sensitivity of about 20 units of the digital metric per milligram increase of water.","sentences":["Microfluidic has been an enabling technology for over a decade, particularly in the field of medical and wearable devices, allowing for the manipulation of small amounts of fluid in confined spaces.","Micro-channels can also be used for wireless sensing thanks to the variations in antenna properties when the fluid flows near it.","However, up to now, microfluidic channels and sensing antennas have always been designed separately; instead, since the liquid flow and the antenna geometry both contribute to the overall performance, they should be considered simultaneously when optimizing the antenna-microfluidic system.","In this paper, the joint design of the antenna and microfluidic channels is investigated for liquid quantification.","Self-tuning RFID microchips are exploited to minimize communication degradation due to the increase of lossy liquid amount over the sensing antenna while digitalizing the impedance mismatch itself.","To experimentally corroborate the joint design technique, two different geometries are obtained and prototyped starting from a given antenna-microfluidic layout by setting different goals for an optimization function.","The two flexible RFID prototypes returned performance in agreement with the simulated ones, achieving a maximum sensitivity of about 20 units of the digital metric per milligram increase of water."],"url":"http://arxiv.org/abs/2404.08268v1","category":"eess.SY"}
{"created":"2024-04-12 06:30:05","title":"An XRISM observation proposal: Gas velocity in the merging cluster Abell 2256","abstract":"One of the XRISM mission goals is to measure the gas dynamics of galaxy clusters with Resolve spectroscopy. To archive these, we propose an observation of the X-ray bright galaxy cluster Abell 2256 at z=0.06. This hosts 2nd brightest diffuse radio relic. Suzaku revealed a gas bulk motion at 1500 km/s, for the first time i\\ n a cluster. This X-ray gas velocity is consistent with those measured in galaxy velocities, indicating that gas and galaxies are moving together. These and other observations make this system the most suitable for the XRISM spectral mapping of gas bulk and tur\\ bulent motions and related physics. We propose two pointings to cover the central ~400kpc region.","sentences":["One of the XRISM mission goals is to measure the gas dynamics of galaxy clusters with Resolve spectroscopy.","To archive these, we propose an observation of the X-ray bright galaxy cluster Abell 2256 at z=0.06.","This hosts 2nd brightest diffuse radio relic.","Suzaku revealed a gas bulk motion at 1500 km/s, for the first time i\\ n a cluster.","This X-ray gas velocity is consistent with those measured in galaxy velocities, indicating that gas and galaxies are moving together.","These and other observations make this system the most suitable for the XRISM spectral mapping of gas bulk and tur\\ bulent motions and related physics.","We propose two pointings to cover the central ~400kpc region."],"url":"http://arxiv.org/abs/2404.08267v1","category":"astro-ph.HE"}
{"created":"2024-04-12 06:23:48","title":"Guided Masked Self-Distillation Modeling for Distributed Multimedia Sensor Event Analysis","abstract":"Observations with distributed sensors are essential in analyzing a series of human and machine activities (referred to as 'events' in this paper) in complex and extensive real-world environments. This is because the information obtained from a single sensor is often missing or fragmented in such an environment; observations from multiple locations and modalities should be integrated to analyze events comprehensively. However, a learning method has yet to be established to extract joint representations that effectively combine such distributed observations. Therefore, we propose Guided Masked sELf-Distillation modeling (Guided-MELD) for inter-sensor relationship modeling. The basic idea of Guided-MELD is to learn to supplement the information from the masked sensor with information from other sensors needed to detect the event. Guided-MELD is expected to enable the system to effectively distill the fragmented or redundant target event information obtained by the sensors without being overly dependent on any specific sensors. To validate the effectiveness of the proposed method in novel tasks of distributed multimedia sensor event analysis, we recorded two new datasets that fit the problem setting: MM-Store and MM-Office. These datasets consist of human activities in a convenience store and an office, recorded using distributed cameras and microphones. Experimental results on these datasets show that the proposed Guided-MELD improves event tagging and detection performance and outperforms conventional inter-sensor relationship modeling methods. Furthermore, the proposed method performed robustly even when sensors were reduced.","sentences":["Observations with distributed sensors are essential in analyzing a series of human and machine activities (referred to as 'events' in this paper) in complex and extensive real-world environments.","This is because the information obtained from a single sensor is often missing or fragmented in such an environment; observations from multiple locations and modalities should be integrated to analyze events comprehensively.","However, a learning method has yet to be established to extract joint representations that effectively combine such distributed observations.","Therefore, we propose Guided Masked sELf-Distillation modeling (Guided-MELD) for inter-sensor relationship modeling.","The basic idea of Guided-MELD is to learn to supplement the information from the masked sensor with information from other sensors needed to detect the event.","Guided-MELD is expected to enable the system to effectively distill the fragmented or redundant target event information obtained by the sensors without being overly dependent on any specific sensors.","To validate the effectiveness of the proposed method in novel tasks of distributed multimedia sensor event analysis, we recorded two new datasets that fit the problem setting: MM-Store and MM-Office.","These datasets consist of human activities in a convenience store and an office, recorded using distributed cameras and microphones.","Experimental results on these datasets show that the proposed Guided-MELD improves event tagging and detection performance and outperforms conventional inter-sensor relationship modeling methods.","Furthermore, the proposed method performed robustly even when sensors were reduced."],"url":"http://arxiv.org/abs/2404.08264v1","category":"cs.MM"}
{"created":"2024-04-12 05:49:53","title":"Higher order $\\mathcal{S}^{p}$-differentiability: The unitary case","abstract":"Consider the set of unitary operators on a complex separable Hilbert space $\\mathcal{H}$, denoted as $\\mathcal{U}(\\mathcal{H})$. Consider $1<p<\\infty$. We establish that $f$ is $n$ times continuously Fr\\'echet $\\mathcal{S}^{p}$-differentiable at every point in $\\mathcal{U}(\\mathcal{H})$ if and only if $f\\in C^n(\\mathbb{T})$. Take $U :\\mathbb{R}\\rightarrow\\mathcal{U}(\\mathcal{H})$ such that $\\tilde{U}:t\\in\\mathbb{R}\\mapsto U(t)-U(0)$ is $n$ times continuously $\\mathcal{S}^p$-differentiable on $\\mathbb{R}$. Consequently, for $f\\in C^n(\\mathbb{T})$, we prove that $f$ is $n$ times continuously G\\^ateaux $\\mathcal{S}^p$-differentiable at $U(t)$. We provide explicit expressions for both types of derivatives of $f$ in terms of multiple operator integrals. In the domain of unitary operators, these results closely follow the $n$th order successes for self-adjoint operators achieved by the second author, Le Merdy, Skripka, and Sukochev. Furthermore, as for application, we derive a formula and $\\mathcal{S}^{p}$-estimates for operator Taylor remainders for a broader class of functions. Our results extend those of Peller, Potapov, Skripka, Sukochev and Tomskova.","sentences":["Consider the set of unitary operators on a complex separable Hilbert space $\\mathcal{H}$, denoted as $\\mathcal{U}(\\mathcal{H})$. Consider $1<p<\\infty$. We establish that $f$ is $n$ times continuously Fr\\'echet $\\mathcal{S}^{p}$-differentiable at every point in $\\mathcal{U}(\\mathcal{H})$ if and only if $f\\in C^n(\\mathbb{T})$. Take $U :\\mathbb{R}\\rightarrow\\mathcal{U}(\\mathcal{H})$ such that $\\tilde{U}:t\\in\\mathbb{R}\\mapsto U(t)-U(0)$ is $n$ times continuously $\\mathcal{S}^p$-differentiable on $\\mathbb{R}$. Consequently, for $f\\in C^n(\\mathbb{T})$, we prove that $f$ is $n$ times continuously G\\^ateaux $\\mathcal{S}^p$-differentiable at $U(t)$. We provide explicit expressions for both types of derivatives of $f$ in terms of multiple operator integrals.","In the domain of unitary operators, these results closely follow the $n$th order successes for self-adjoint operators achieved by the second author, Le Merdy, Skripka, and Sukochev.","Furthermore, as for application, we derive a formula and $\\mathcal{S}^{p}$-estimates for operator Taylor remainders for a broader class of functions.","Our results extend those of Peller, Potapov, Skripka, Sukochev and Tomskova."],"url":"http://arxiv.org/abs/2404.08253v1","category":"math.FA"}
{"created":"2024-04-12 05:39:22","title":"Interplay Between Single-Photon Ionization and the Auger Process in Argon Ion Formation","abstract":"We explore the interactions between Argon and extreme ultraviolet (XUV) laser pulses across photon energies of 200 eV, 260 eV, and 315 eV, scrutinizing the influence of photon energy on Argon ion yields and unraveling the associated ionization pathways. Utilizing pulse durations of 10 fs and 30 fs, we spotlight a notable increase in Argon's ionization propensity with escalating laser intensities, especially within the \\(5 \\times 10^{14}\\, \\text{W/cm}^2\\) to \\(1.2 \\times 10^{16}\\, \\text{W/cm}^2\\) range. While direct ionization predominated at 200 eV, the 260 eV and 315 eV spectra revealed complex interactions, prominently featuring the Auger process. A consistent overshadowing of odd-charged ions by even-charged Argon ions, particularly at 315 eV, paves the way for future research. The findings provide crucial insights into atomic interactions with intense light, establishing a groundwork for further exploration into similar atomic systems.","sentences":["We explore the interactions between Argon and extreme ultraviolet (XUV) laser pulses across photon energies of 200 eV, 260 eV, and 315 eV, scrutinizing the influence of photon energy on Argon ion yields and unraveling the associated ionization pathways.","Utilizing pulse durations of 10 fs and 30 fs, we spotlight a notable increase in Argon's ionization propensity with escalating laser intensities, especially within the \\(5 \\times 10^{14}\\, \\text{W/cm}^2\\) to \\(1.2 \\times 10^{16}\\, \\text{W/cm}^2\\) range.","While direct ionization predominated at 200 eV, the 260 eV and 315 eV spectra revealed complex interactions, prominently featuring the Auger process.","A consistent overshadowing of odd-charged ions by even-charged Argon ions, particularly at 315 eV, paves the way for future research.","The findings provide crucial insights into atomic interactions with intense light, establishing a groundwork for further exploration into similar atomic systems."],"url":"http://arxiv.org/abs/2404.08251v1","category":"physics.atom-ph"}
{"created":"2024-04-12 05:32:53","title":"An Asymptotically-Correct Implicit-Explicit Time Integration Scheme for Finite Volume Radiation-Hydrodynamics","abstract":"Numerical radiation-hydrodynamics (RHD) for non-relativistic flows is a challenging problem because it encompasses processes acting over a very broad range of timescales, and where the relative importance of these processes often varies by orders of magnitude across the computational domain. Here we present a new implicit-explicit (IMEX) method for numerical RHD that has a number of desirable properties that have not previously been combined in a single method. Our scheme is based on moments and allows machine-precision conservation of energy and momentum, making it highly suitable for adaptive mesh refinement applications; it requires no more communication than hydrodynamics and includes no non-local iterative steps, making it highly suitable for massively parallel and GPU-based systems where communication is a bottleneck; and we show that it is asymptotically-accurate in the streaming, static diffusion, and dynamic diffusion limits, including in the so-called asymptotic diffusion regime where the computational grid does not resolve the photon mean free path. We implement our method in the GPU-accelerated RHD code QUOKKA and show that it passes a wide range of numerical tests.","sentences":["Numerical radiation-hydrodynamics (RHD) for non-relativistic flows is a challenging problem because it encompasses processes acting over a very broad range of timescales, and where the relative importance of these processes often varies by orders of magnitude across the computational domain.","Here we present a new implicit-explicit (IMEX) method for numerical RHD that has a number of desirable properties that have not previously been combined in a single method.","Our scheme is based on moments and allows machine-precision conservation of energy and momentum, making it highly suitable for adaptive mesh refinement applications; it requires no more communication than hydrodynamics and includes no non-local iterative steps, making it highly suitable for massively parallel and GPU-based systems where communication is a bottleneck; and we show that it is asymptotically-accurate in the streaming, static diffusion, and dynamic diffusion limits, including in the so-called asymptotic diffusion regime where the computational grid does not resolve the photon mean free path.","We implement our method in the GPU-accelerated RHD code QUOKKA and show that it passes a wide range of numerical tests."],"url":"http://arxiv.org/abs/2404.08247v1","category":"astro-ph.IM"}
{"created":"2024-04-12 04:51:32","title":"Adaptive Anomaly Detection Disruption Prediction Starting from First Discharge","abstract":"Plasma disruption presents a significant challenge in tokamak fusion, where it can cause severe damage and economic losses. Current disruption predictors mainly rely on data-driven methods, requiring extensive discharge data for training. However, future tokamaks require disruption prediction from the first shot, posing challenges of data scarcity during the early operation period. In this period disruption prediction aims to support safe exploration of operation range and accumulate necessary data to develop advanced prediction models. Thus, predictors must adapt to evolving plasma environments during this exploration phase. To address these issues, this study proposes a cross-tokamak adaptive deployment method using the Enhanced Convolutional Autoencoder Anomaly Detection (E-CAAD) predictor, enabling disruption prediction from the first shot of new devices. Experimental results indicate the ability of E-CAAD model trained on existing devices to effectively differentiate between disruption precursors and non-disruption samples on new devices, proving the feasibility of model cross-device transfer. Building upon this, adaptive learning from scratch and threshold adaptive adjustment strategies are proposed to achieve model cross-device transfer. The adaptive learning from scratch strategy enables the predictor to use scarce data during the early operation of the new device while rapidly adapting to changes in operation environment. The threshold adaptive adjustment strategy addresses the challenge of selecting warning thresholds on new devices where validation set is lacking, ensuring that the warning thresholds adapt to changes in the operation environment. Finally, experiments transferring the model from J-TEXT to EAST exhibit comparable performance to EAST models trained with ample data, achieving a TPR of 85.88% and a FPR of 6.15%, with a 20ms reserved MGI system reaction time.","sentences":["Plasma disruption presents a significant challenge in tokamak fusion, where it can cause severe damage and economic losses.","Current disruption predictors mainly rely on data-driven methods, requiring extensive discharge data for training.","However, future tokamaks require disruption prediction from the first shot, posing challenges of data scarcity during the early operation period.","In this period disruption prediction aims to support safe exploration of operation range and accumulate necessary data to develop advanced prediction models.","Thus, predictors must adapt to evolving plasma environments during this exploration phase.","To address these issues, this study proposes a cross-tokamak adaptive deployment method using the Enhanced Convolutional Autoencoder Anomaly Detection (E-CAAD) predictor, enabling disruption prediction from the first shot of new devices.","Experimental results indicate the ability of E-CAAD model trained on existing devices to effectively differentiate between disruption precursors and non-disruption samples on new devices, proving the feasibility of model cross-device transfer.","Building upon this, adaptive learning from scratch and threshold adaptive adjustment strategies are proposed to achieve model cross-device transfer.","The adaptive learning from scratch strategy enables the predictor to use scarce data during the early operation of the new device while rapidly adapting to changes in operation environment.","The threshold adaptive adjustment strategy addresses the challenge of selecting warning thresholds on new devices where validation set is lacking, ensuring that the warning thresholds adapt to changes in the operation environment.","Finally, experiments transferring the model from J-TEXT to EAST exhibit comparable performance to EAST models trained with ample data, achieving a TPR of 85.88% and a FPR of 6.15%, with a 20ms reserved MGI system reaction time."],"url":"http://arxiv.org/abs/2404.08241v1","category":"physics.plasm-ph"}
{"created":"2024-04-12 04:45:51","title":"Simulation of a Vision Correction Display System","abstract":"Eyes serve as our primary sensory organs, responsible for processing up to 80\\% of our sensory input. However, common visual aberrations like myopia and hyperopia affect a significant portion of the global population. This paper focuses on simulating a Vision Correction Display (VCD) to enhance the visual experience of individuals with various visual impairments. Utilising Blender, we digitally model the functionality of a VCD in correcting refractive errors such as myopia and hyperopia. With these simulations we can see potential improvements in visual acuity and comfort. These simulations provide valuable insights for the design and development of future VCD technologies, ultimately advancing accessibility and usability for individuals with visual challenges.","sentences":["Eyes serve as our primary sensory organs, responsible for processing up to 80\\% of our sensory input.","However, common visual aberrations like myopia and hyperopia affect a significant portion of the global population.","This paper focuses on simulating a Vision Correction Display (VCD) to enhance the visual experience of individuals with various visual impairments.","Utilising Blender, we digitally model the functionality of a VCD in correcting refractive errors such as myopia and hyperopia.","With these simulations we can see potential improvements in visual acuity and comfort.","These simulations provide valuable insights for the design and development of future VCD technologies, ultimately advancing accessibility and usability for individuals with visual challenges."],"url":"http://arxiv.org/abs/2404.08238v1","category":"eess.IV"}
{"created":"2024-04-12 04:18:58","title":"Evaluation Framework for Quantum Security Risk Assessment: A Comprehensive Study for Quantum-Safe Migration","abstract":"The rise of large-scale quantum computing poses a significant threat to traditional cryptographic security measures. Quantum attacks undermine current asymmetric cryptographic algorithms, rendering them ineffective. Even symmetric key cryptography is vulnerable, albeit to a lesser extent, suggesting longer keys or extended hash functions for security. Thus, current cryptographic solutions are inadequate against emerging quantum threats. Organizations must transition to quantum-safe environments with robust continuity plans and meticulous risk management. This study explores the challenges of migrating to quantum-safe cryptographic states, introducing a comprehensive security risk assessment framework. We propose a security risk assessment framework that examines vulnerabilities across algorithms, certificates, and protocols throughout the migration process (pre-migration, during migration, post-migration). We link these vulnerabilities to the STRIDE threat model to assess their impact and likelihood. Then, we discuss practical mitigation strategies for critical components like algorithms, public key infrastructures, and protocols. Our study not only identifies potential attacks and vulnerabilities at each layer and migration stage but also suggests possible countermeasures and alternatives to enhance system resilience, empowering organizations to construct a secure infrastructure for the quantum era. Through these efforts, we establish the foundation for enduring security in networked systems amid the challenges of the quantum era.","sentences":["The rise of large-scale quantum computing poses a significant threat to traditional cryptographic security measures.","Quantum attacks undermine current asymmetric cryptographic algorithms, rendering them ineffective.","Even symmetric key cryptography is vulnerable, albeit to a lesser extent, suggesting longer keys or extended hash functions for security.","Thus, current cryptographic solutions are inadequate against emerging quantum threats.","Organizations must transition to quantum-safe environments with robust continuity plans and meticulous risk management.","This study explores the challenges of migrating to quantum-safe cryptographic states, introducing a comprehensive security risk assessment framework.","We propose a security risk assessment framework that examines vulnerabilities across algorithms, certificates, and protocols throughout the migration process (pre-migration, during migration, post-migration).","We link these vulnerabilities to the STRIDE threat model to assess their impact and likelihood.","Then, we discuss practical mitigation strategies for critical components like algorithms, public key infrastructures, and protocols.","Our study not only identifies potential attacks and vulnerabilities at each layer and migration stage but also suggests possible countermeasures and alternatives to enhance system resilience, empowering organizations to construct a secure infrastructure for the quantum era.","Through these efforts, we establish the foundation for enduring security in networked systems amid the challenges of the quantum era."],"url":"http://arxiv.org/abs/2404.08231v1","category":"cs.CR"}
{"created":"2024-04-12 03:44:50","title":"A Passively Bendable, Compliant Tactile Palm with RObotic Modular Endoskeleton Optical (ROMEO) Fingers","abstract":"Many robotic hands currently rely on extremely dexterous robotic fingers and a thumb joint to envelop themselves around an object. Few hands focus on the palm even though human hands greatly benefit from their central fold and soft surface. As such, we develop a novel structurally compliant soft palm, which enables more surface area contact for the objects that are pressed into it. Moreover, this design, along with the development of a new low-cost, flexible illumination system, is able to incorporate a high-resolution tactile sensing system inspired by the GelSight sensors. Concurrently, we design RObotic Modular Endoskeleton Optical (ROMEO) fingers, which are underactuated two-segment soft fingers that are able to house the new illumination system, and we integrate them into these various palm configurations. The resulting robotic hand is slightly bigger than a baseball and represents one of the first soft robotic hands with actuated fingers and a passively compliant palm, all of which have high-resolution tactile sensing. This design also potentially helps researchers discover and explore more soft-rigid tactile robotic hand designs with greater capabilities in the future.   The supplementary video can be found here: https://youtu.be/RKfIFiewqsg","sentences":["Many robotic hands currently rely on extremely dexterous robotic fingers and a thumb joint to envelop themselves around an object.","Few hands focus on the palm even though human hands greatly benefit from their central fold and soft surface.","As such, we develop a novel structurally compliant soft palm, which enables more surface area contact for the objects that are pressed into it.","Moreover, this design, along with the development of a new low-cost, flexible illumination system, is able to incorporate a high-resolution tactile sensing system inspired by the GelSight sensors.","Concurrently, we design RObotic Modular Endoskeleton Optical (ROMEO) fingers, which are underactuated two-segment soft fingers that are able to house the new illumination system, and we integrate them into these various palm configurations.","The resulting robotic hand is slightly bigger than a baseball and represents one of the first soft robotic hands with actuated fingers and a passively compliant palm, all of which have high-resolution tactile sensing.","This design also potentially helps researchers discover and explore more soft-rigid tactile robotic hand designs with greater capabilities in the future.   ","The supplementary video can be found here: https://youtu.be/RKfIFiewqsg"],"url":"http://arxiv.org/abs/2404.08227v1","category":"cs.RO"}
{"created":"2024-04-12 03:42:09","title":"A decomposition theorem for the affine Springer fibers","abstract":"According to Laumon, an affine Springer fiber is homeomorphic to the universal abelian covering of the compactified Jacobian of a spectral curve. We construct equivariant deformations $f_{n}:\\overline{\\mathcal{P}}_{n}\\to \\mathcal{B}_{n}$ of the finite abelian coverings of this compactified Jacobian, and decompose the complex $Rf_{n,*}\\mathbf{Q}_{\\ell}$ as direct sum of intersection complexes. Pass to the limit, we obtain a similar expression for the homology of the affine Springer fibers. A quite surprising consequence is that we can reduce the homology to its $\\Lambda^{0}$-invariant subspace. As an application, we get a sheaf-theoretic reformulation of the purity hypothesis of Goresky, Kottwitz and MacPherson. In an attempt to solve it, we propose a conjecture about the punctural weight of the intermediate extension of a smooth $\\ell$-adic sheaf of pure weight.","sentences":["According to Laumon, an affine Springer fiber is homeomorphic to the universal abelian covering of the compactified Jacobian of a spectral curve.","We construct equivariant deformations $f_{n}:\\overline{\\mathcal{P}}_{n}\\to \\mathcal{B}_{n}$ of the finite abelian coverings of this compactified Jacobian, and decompose the complex $Rf_{n,*}\\mathbf{Q}_{\\ell}$ as direct sum of intersection complexes.","Pass to the limit, we obtain a similar expression for the homology of the affine Springer fibers.","A quite surprising consequence is that we can reduce the homology to its $\\Lambda^{0}$-invariant subspace.","As an application, we get a sheaf-theoretic reformulation of the purity hypothesis of Goresky, Kottwitz and MacPherson.","In an attempt to solve it, we propose a conjecture about the punctural weight of the intermediate extension of a smooth $\\ell$-adic sheaf of pure weight."],"url":"http://arxiv.org/abs/2404.08225v1","category":"math.AG"}
{"created":"2024-04-12 03:03:00","title":"Escape with Your Self: Expressive Reachability Types with Sound and Decidable Bidirectional Type Checking","abstract":"Despite Rust's success in systems programming, its \"shared XOR mutable\" principle significantly restricts how mutable values can be used, precluding many useful functional programming idioms. Reachability types are a recent proposal to address the key limitations of Rust-style \"shared XOR mutable\" approaches by tracking lifetimes and reachability of shared, escaping, and mutable data, even in the presence of higher-order functions and polymorphic types. The key to enable such expressiveness is the notion of self-references in reachability qualifiers. However, self-references present major challenges in designing expressive subtyping and decidable type checking algorithms, since self-references are neither fully covariant nor fully contravariant, yet still need to vary in certain circumstances. Thus, making reachability types practical and bringing the benefits of programming with lifetimes and sharing to higher-level languages remains an open challenge.   In this paper, we investigate the issues of subtyping and type checking of self-references for reachability types. We address key gaps in previous work by presenting the $\\lambda^{\\blacklozenge}_R$-calculus of reachability types with a refined notion of subtyping, which is more expressive compared to prior work, and more smoothly supports features such as Church-encoded datatypes. We also develop a sound and decidable bidirectional type checking algorithm, which is implemented and verified in the Coq proof assistant.","sentences":["Despite Rust's success in systems programming, its \"shared XOR mutable\" principle significantly restricts how mutable values can be used, precluding many useful functional programming idioms.","Reachability types are a recent proposal to address the key limitations of Rust-style \"shared XOR mutable\" approaches by tracking lifetimes and reachability of shared, escaping, and mutable data, even in the presence of higher-order functions and polymorphic types.","The key to enable such expressiveness is the notion of self-references in reachability qualifiers.","However, self-references present major challenges in designing expressive subtyping and decidable type checking algorithms, since self-references are neither fully covariant nor fully contravariant, yet still need to vary in certain circumstances.","Thus, making reachability types practical and bringing the benefits of programming with lifetimes and sharing to higher-level languages remains an open challenge.   ","In this paper, we investigate the issues of subtyping and type checking of self-references for reachability types.","We address key gaps in previous work by presenting the $\\lambda^{\\blacklozenge}_R$-calculus of reachability types with a refined notion of subtyping, which is more expressive compared to prior work, and more smoothly supports features such as Church-encoded datatypes.","We also develop a sound and decidable bidirectional type checking algorithm, which is implemented and verified in the Coq proof assistant."],"url":"http://arxiv.org/abs/2404.08217v1","category":"cs.PL"}
{"created":"2024-04-12 02:50:43","title":"GazePointAR: A Context-Aware Multimodal Voice Assistant for Pronoun Disambiguation in Wearable Augmented Reality","abstract":"Voice assistants (VAs) like Siri and Alexa are transforming human-computer interaction; however, they lack awareness of users' spatiotemporal context, resulting in limited performance and unnatural dialogue. We introduce GazePointAR, a fully-functional context-aware VA for wearable augmented reality that leverages eye gaze, pointing gestures, and conversation history to disambiguate speech queries. With GazePointAR, users can ask \"what's over there?\" or \"how do I solve this math problem?\" simply by looking and/or pointing. We evaluated GazePointAR in a three-part lab study (N=12): (1) comparing GazePointAR to two commercial systems; (2) examining GazePointAR's pronoun disambiguation across three tasks; (3) and an open-ended phase where participants could suggest and try their own context-sensitive queries. Participants appreciated the naturalness and human-like nature of pronoun-driven queries, although sometimes pronoun use was counter-intuitive. We then iterated on GazePointAR and conducted a first-person diary study examining how GazePointAR performs in-the-wild. We conclude by enumerating limitations and design considerations for future context-aware VAs.","sentences":["Voice assistants (VAs) like Siri and Alexa are transforming human-computer interaction; however, they lack awareness of users' spatiotemporal context, resulting in limited performance and unnatural dialogue.","We introduce GazePointAR, a fully-functional context-aware VA for wearable augmented reality that leverages eye gaze, pointing gestures, and conversation history to disambiguate speech queries.","With GazePointAR, users can ask \"what's over there?\" or \"how do I solve this math problem?\" simply by looking and/or pointing.","We evaluated GazePointAR in a three-part lab study (N=12): (1) comparing GazePointAR to two commercial systems; (2) examining GazePointAR's pronoun disambiguation across three tasks; (3) and an open-ended phase where participants could suggest and try their own context-sensitive queries.","Participants appreciated the naturalness and human-like nature of pronoun-driven queries, although sometimes pronoun use was counter-intuitive.","We then iterated on GazePointAR and conducted a first-person diary study examining how GazePointAR performs in-the-wild.","We conclude by enumerating limitations and design considerations for future context-aware VAs."],"url":"http://arxiv.org/abs/2404.08213v1","category":"cs.HC"}
{"created":"2024-04-12 17:59:47","title":"EventEgo3D: 3D Human Motion Capture from Egocentric Event Streams","abstract":"Monocular egocentric 3D human motion capture is a challenging and actively researched problem. Existing methods use synchronously operating visual sensors (e.g. RGB cameras) and often fail under low lighting and fast motions, which can be restricting in many applications involving head-mounted devices. In response to the existing limitations, this paper 1) introduces a new problem, i.e., 3D human motion capture from an egocentric monocular event camera with a fisheye lens, and 2) proposes the first approach to it called EventEgo3D (EE3D). Event streams have high temporal resolution and provide reliable cues for 3D human motion capture under high-speed human motions and rapidly changing illumination. The proposed EE3D framework is specifically tailored for learning with event streams in the LNES representation, enabling high 3D reconstruction accuracy. We also design a prototype of a mobile head-mounted device with an event camera and record a real dataset with event observations and the ground-truth 3D human poses (in addition to the synthetic dataset). Our EE3D demonstrates robustness and superior 3D accuracy compared to existing solutions across various challenging experiments while supporting real-time 3D pose update rates of 140Hz.","sentences":["Monocular egocentric 3D human motion capture is a challenging and actively researched problem.","Existing methods use synchronously operating visual sensors (e.g. RGB cameras) and often fail under low lighting and fast motions, which can be restricting in many applications involving head-mounted devices.","In response to the existing limitations, this paper 1) introduces a new problem, i.e., 3D human motion capture from an egocentric monocular event camera with a fisheye lens, and 2) proposes the first approach to it called EventEgo3D (EE3D).","Event streams have high temporal resolution and provide reliable cues for 3D human motion capture under high-speed human motions and rapidly changing illumination.","The proposed EE3D framework is specifically tailored for learning with event streams in the LNES representation, enabling high 3D reconstruction accuracy.","We also design a prototype of a mobile head-mounted device with an event camera and record a real dataset with event observations and the ground-truth 3D human poses (in addition to the synthetic dataset).","Our EE3D demonstrates robustness and superior 3D accuracy compared to existing solutions across various challenging experiments while supporting real-time 3D pose update rates of 140Hz."],"url":"http://arxiv.org/abs/2404.08640v1","category":"cs.CV"}
{"created":"2024-04-12 17:59:02","title":"Optimal Slicing and Scheduling with Service Guarantees in Multi-Hop Wireless Networks","abstract":"We analyze the problem of scheduling in wireless networks for service guarantees. We show that under regular schedules, the problem can be simplified and service guarantees can be made in polynomial time.","sentences":["We analyze the problem of scheduling in wireless networks for service guarantees.","We show that under regular schedules, the problem can be simplified and service guarantees can be made in polynomial time."],"url":"http://arxiv.org/abs/2404.08637v1","category":"cs.NI"}
{"created":"2024-04-12 16:34:02","title":"Cooling of an objetct by forced convection","abstract":"We present an experiment on forced convection where a previously heated object is cooled under the effect of a controlled stream of air. We consider a square copper plate in which temperature variations can be considered negligible and we measure the cooling rate as a function of the average velocity of the air stream. We use a thermal camera to measure the temperature field and the cooling curves as a function of time for different conditions. An empirical relation between the characteristic cooling time and the mean velocity of the air stream is reported. The results obtained are discussed in the framework of simple dimensional models and their limits of validity.","sentences":["We present an experiment on forced convection where a previously heated object is cooled under the effect of a controlled stream of air.","We consider a square copper plate in which temperature variations can be considered negligible and we measure the cooling rate as a function of the average velocity of the air stream.","We use a thermal camera to measure the temperature field and the cooling curves as a function of time for different conditions.","An empirical relation between the characteristic cooling time and the mean velocity of the air stream is reported.","The results obtained are discussed in the framework of simple dimensional models and their limits of validity."],"url":"http://arxiv.org/abs/2404.08587v1","category":"physics.ed-ph"}
{"created":"2024-04-12 15:43:18","title":"Qubit frugal entanglement determination with the deep multi-scale entanglement renormalization ansatz","abstract":"We study the deep multi-scale entanglement renormalization ansatz (DMERA) on quantum hardware and the causal cone of a subset of the qubits which make up the ansatz. This causal cone spans $O(M+\\log{N})$ physical qubits on a quantum device, where $M$ and $N$ are the subset size and the total number qubits in the ansatz respectively. This allows for the determination of the von Neumann entanglement entropy of the $N$ qubit wave-function using $O(M+\\log{N})$ qubits by diagonalization of the reduced density matrix (RDM). We show this by randomly initializing a 16-qubit DMERA and diagonalizing the resulting RDM of the $M$-qubit subsystem using density matrix simulation. As an example of practical interest, we also encode the variational ground state of the quantum critical long-range transverse field Ising model (LRTIM) on 8 spins using DMERA. We perform density matrix simulation with and without noise to obtain entanglement entropies in separate experiments using only 4 qubits. Finally we repeat the experiment on the IBM Kyoto backend reproducing simulation results.","sentences":["We study the deep multi-scale entanglement renormalization ansatz (DMERA) on quantum hardware and the causal cone of a subset of the qubits which make up the ansatz.","This causal cone spans $O(M+\\log{N})$ physical qubits on a quantum device, where $M$ and $N$ are the subset size and the total number qubits in the ansatz respectively.","This allows for the determination of the von Neumann entanglement entropy of the $N$ qubit wave-function using $O(M+\\log{N})$ qubits by diagonalization of the reduced density matrix (RDM).","We show this by randomly initializing a 16-qubit DMERA and diagonalizing the resulting RDM of the $M$-qubit subsystem using density matrix simulation.","As an example of practical interest, we also encode the variational ground state of the quantum critical long-range transverse field Ising model (LRTIM) on 8 spins using DMERA.","We perform density matrix simulation with and without noise to obtain entanglement entropies in separate experiments using only 4 qubits.","Finally we repeat the experiment on the IBM Kyoto backend reproducing simulation results."],"url":"http://arxiv.org/abs/2404.08548v1","category":"quant-ph"}
{"created":"2024-04-12 15:01:38","title":"The magnetism measurements of the two-dimensional van der Waals antiferromagnet CrPS4 using dynamic cantilever magnetometry","abstract":"The exploration of van der Waals (vdWs) magnetic materials has sparked great interest in spintronics. However, conventional methods often face challenges in characterizing the magnetic properties of small-sized vdWs materials, especially for antiferromagnets with extremely small magnetic moments. Here, we demonstrate the efficacy of dynamic cantilever magnetometry (DCM) in characterizing the magnetic properties of vdWs magnets, using an antiferromagnetic semiconductor CrPS4. We observe continuous spin axis rotation under a magnetic field, accurately modelled by considering the existance of marked magnetic anisotropies. Furthermore, the dominance of out-of-plane magnetic anisotropy in spin reorientation behavior at low temperatures transitions to the prevalence of in-plane anisotropy with increasing temperature, leading to a sign reversal of the frequency shift in measurements. The peculiar magnetic phase transitions make CrPS4 an intriguing platform for studying two-dimensional magnetism. Our findings underscore the effectiveness of DCM in characterizing magnetic anisotropies and phase transitions in vdWs magnets.","sentences":["The exploration of van der Waals (vdWs) magnetic materials has sparked great interest in spintronics.","However, conventional methods often face challenges in characterizing the magnetic properties of small-sized vdWs materials, especially for antiferromagnets with extremely small magnetic moments.","Here, we demonstrate the efficacy of dynamic cantilever magnetometry (DCM) in characterizing the magnetic properties of vdWs magnets, using an antiferromagnetic semiconductor CrPS4.","We observe continuous spin axis rotation under a magnetic field, accurately modelled by considering the existance of marked magnetic anisotropies.","Furthermore, the dominance of out-of-plane magnetic anisotropy in spin reorientation behavior at low temperatures transitions to the prevalence of in-plane anisotropy with increasing temperature, leading to a sign reversal of the frequency shift in measurements.","The peculiar magnetic phase transitions make CrPS4 an intriguing platform for studying two-dimensional magnetism.","Our findings underscore the effectiveness of DCM in characterizing magnetic anisotropies and phase transitions in vdWs magnets."],"url":"http://arxiv.org/abs/2404.08521v1","category":"cond-mat.mes-hall"}
{"created":"2024-04-12 14:44:11","title":"Parton Distribution Functions and Their Impact on Precision of the Current Theory Calculations","abstract":"The unprecedented precision of experimental measurements at the Large Hadron Collider (LHC) and the increased statistics that will be reached in the High-Luminosity phase of the LHC (HL-LHC) are pushing the phenomenology community to a new precision frontier, in which new challenges present themselves and new questions arise. A key ingredients of theoretical predictions at hadron colliders are the Parton Distribution Functions (PDFs) of the proton. This contribution highlights some of the new developments in the determination of PDFs from a global set of experimental data, from approximate N3LO PDFs and the inclusion of theory uncertainties in PDF fits, to the realisation of the non trivial interplay between parton densities at large-x and possible signals of New Physics in high energy tails of the distributions, which highlights the synergy between high energy and low energy experimental programs.","sentences":["The unprecedented precision of experimental measurements at the Large Hadron Collider (LHC) and the increased statistics that will be reached in the High-Luminosity phase of the LHC (HL-LHC) are pushing the phenomenology community to a new precision frontier, in which new challenges present themselves and new questions arise.","A key ingredients of theoretical predictions at hadron colliders are the Parton Distribution Functions (PDFs) of the proton.","This contribution highlights some of the new developments in the determination of PDFs from a global set of experimental data, from approximate N3LO PDFs and the inclusion of theory uncertainties in PDF fits, to the realisation of the non trivial interplay between parton densities at large-x and possible signals of New Physics in high energy tails of the distributions, which highlights the synergy between high energy and low energy experimental programs."],"url":"http://arxiv.org/abs/2404.08508v1","category":"hep-ph"}
{"created":"2024-04-12 14:32:19","title":"A modified Polak-Ribiere-Polyak type conjugate gradient method with two stepsize strategies for vector optimization","abstract":"In this paper, in order to find critical points of vector-valued functions with respect to the partial order induced by a closed, convex, and pointed cone with nonempty interior, we propose a nonlinear modified Polak-Ribiere-Polyak type conjugate gradient method with a nonnegative conjugate parameter. We show that the search direction in our method satisfies the sufficient descent condition independent of any line search. Furthermore, under mild assumptions, we obtain the results of global convergence with the standard Wolfe line search conditions as well as the standard Armijo line search strategy without convexity assumption of the objective functions. Computational experiments are given to show the effectiveness of the proposed method.","sentences":["In this paper, in order to find critical points of vector-valued functions with respect to the partial order induced by a closed, convex, and pointed cone with nonempty interior, we propose a nonlinear modified Polak-Ribiere-Polyak type conjugate gradient method with a nonnegative conjugate parameter.","We show that the search direction in our method satisfies the sufficient descent condition independent of any line search.","Furthermore, under mild assumptions, we obtain the results of global convergence with the standard Wolfe line search conditions as well as the standard Armijo line search strategy without convexity assumption of the objective functions.","Computational experiments are given to show the effectiveness of the proposed method."],"url":"http://arxiv.org/abs/2404.08503v1","category":"math.OC"}
{"created":"2024-04-12 13:57:26","title":"21cm signal from Dark Ages collapsing halos with detailed molecular cooling treatment","abstract":"Context. In order to understand the formation of the first stars, which set the transition between the Dark Ages and Cosmic Dawn epochs, it is necessary to provide a detailed description of the physics at work within the first clouds of gas which, during their gravitational collapse, will set the conditions for stars to be form through the mechanism of thermal instability.   Aims. Our objective is to study in detail the molecular cooling of gas in the halos preceding the formation of the first stars. We are furthermore assessing the sensitivity of the 21cm hydrogen line to this cooling channel.   Results. We present the CHEMFAST code, that we developed to compute the cosmological 21cm neutral hydrogen line inside collapsing matter overdensity. We precisely track evolution in the abundances of ions, atoms and molecules through a network of chemical reactions. Computing the molecular thermal function due to the excitation of the rotational levels of the H2 molecule, we find it strongly affects the gas temperature inside collapsing clouds of $10^8$ M$_\\odot$. The gas temperature falls at the end of the collapse, when the molecular cooling takes over the heating due to gravitation.   Conclusions. We find that the 21cm brightness temperature inside the collapsing cloud presents an emission feature, different from the one predicted in expansion scenario. It moreover follows the same behavior as the gas temperature, as it is also strongly affected by the molecular cooling. This makes it a promising probe in order to map the collapsing halos and thermal processes at work inside them.","sentences":["Context.","In order to understand the formation of the first stars, which set the transition between the Dark Ages and Cosmic Dawn epochs, it is necessary to provide a detailed description of the physics at work within the first clouds of gas which, during their gravitational collapse, will set the conditions for stars to be form through the mechanism of thermal instability.   ","Aims.","Our objective is to study in detail the molecular cooling of gas in the halos preceding the formation of the first stars.","We are furthermore assessing the sensitivity of the 21cm hydrogen line to this cooling channel.   Results.","We present the CHEMFAST code, that we developed to compute the cosmological 21cm neutral hydrogen line inside collapsing matter overdensity.","We precisely track evolution in the abundances of ions, atoms and molecules through a network of chemical reactions.","Computing the molecular thermal function due to the excitation of the rotational levels of the H2 molecule, we find it strongly affects the gas temperature inside collapsing clouds of $10^8","$ M$_\\odot$. The gas temperature falls at the end of the collapse, when the molecular cooling takes over the heating due to gravitation.   ","Conclusions.","We find that the 21cm brightness temperature inside the collapsing cloud presents an emission feature, different from the one predicted in expansion scenario.","It moreover follows the same behavior as the gas temperature, as it is also strongly affected by the molecular cooling.","This makes it a promising probe in order to map the collapsing halos and thermal processes at work inside them."],"url":"http://arxiv.org/abs/2404.08479v1","category":"astro-ph.GA"}
{"created":"2024-04-12 13:28:16","title":"Inverted band gap trend through octahedral ordering in Cs$_2$Au$_2$X$_6$ (X=Cl, Br, I)","abstract":"Double perovskites Cs$_2$Au$_2$X$_6$ (X=Cl, Br, I) are prototypical materials that exhibit charge disproportionation of gold into 1+ and 3+ states. It is known that the disproportionation is resolved under high pressures, and this has stimulated many studies into the pressurization of these materials. At present, the phase changes in these materials are still strongly contested. Here, we use density functional theory to study the pressure-dependent behavior of Cs$_2$Au$_2$X$_6$. We find that a tetragonal--cubic transition occurs directly from the ground state $I4/mmm$ structure. Even so, we also found an intermediate tetragonal $P4/mmm$ structure to be very close in energy, suggesting it to be observable. We also find several other competing metastable phases, which explains some of the controversies in the literature. Focusing on one of the metastable phases, we suggest that Cs$_2$Au$_2$X$_6$ can be prepared in a $P4_2/mnm$ structure, analogous to that of KCuF$_3$. The band gap in the $P4_2/mnm$ structure widened as atomic number of the halide was increased, which is the inverse trend compared to the ground state structure. We explain this by the different octahedral distortion ordering in the two structural phases. Furthermore, we show that the conduction band in $P4_2/mnm$ is three dimensionally connected, which is favorable for opto-electronic applications. We submit that this work demonstrates that octahedral distortion ordering is a promising avenue for developing new double perovskites and suggests it to be particular effective in tuning the electronic structure properties.","sentences":["Double perovskites Cs$_2$Au$_2$X$_6$ (X=Cl, Br, I) are prototypical materials that exhibit charge disproportionation of gold into 1+ and 3+ states.","It is known that the disproportionation is resolved under high pressures, and this has stimulated many studies into the pressurization of these materials.","At present, the phase changes in these materials are still strongly contested.","Here, we use density functional theory to study the pressure-dependent behavior of Cs$_2$Au$_2$X$_6$. We find that a tetragonal--cubic transition occurs directly from the ground state $I4/mmm$ structure.","Even so, we also found an intermediate tetragonal $P4/mmm$ structure to be very close in energy, suggesting it to be observable.","We also find several other competing metastable phases, which explains some of the controversies in the literature.","Focusing on one of the metastable phases, we suggest that Cs$_2$Au$_2$X$_6$ can be prepared in a $P4_2/mnm$ structure, analogous to that of KCuF$_3$. The band gap in the $P4_2/mnm$ structure widened as atomic number of the halide was increased, which is the inverse trend compared to the ground state structure.","We explain this by the different octahedral distortion ordering in the two structural phases.","Furthermore, we show that the conduction band in $P4_2/mnm$ is three dimensionally connected, which is favorable for opto-electronic applications.","We submit that this work demonstrates that octahedral distortion ordering is a promising avenue for developing new double perovskites and suggests it to be particular effective in tuning the electronic structure properties."],"url":"http://arxiv.org/abs/2404.08465v1","category":"cond-mat.mtrl-sci"}
{"created":"2024-04-12 13:23:22","title":"Riemannian optimization on the symplectic Stiefel manifold using second-order information","abstract":"Riemannian optimization is concerned with problems, where the independent variable lies on a smooth manifold. There is a number of problems from numerical linear algebra that fall into this category, where the manifold is usually specified by special matrix structures, such as orthogonality or definiteness. Following this line of research, we investigate tools for Riemannian optimization on the symplectic Stiefel manifold. We complement the existing set of numerical optimization algorithms with a Riemannian trust region method tailored to the symplectic Stiefel manifold. To this end, we derive a matrix formula for the Riemannian Hessian under a right-invariant metric. Moreover, we propose a novel retraction for approximating the Riemannian geodesics. Finally, we conduct a comparative study in which we juxtapose the performance of the Riemannian variants of the steepest descent, conjugate gradients, and trust region methods on selected matrix optimization problems that feature symplectic constraints.","sentences":["Riemannian optimization is concerned with problems, where the independent variable lies on a smooth manifold.","There is a number of problems from numerical linear algebra that fall into this category, where the manifold is usually specified by special matrix structures, such as orthogonality or definiteness.","Following this line of research, we investigate tools for Riemannian optimization on the symplectic Stiefel manifold.","We complement the existing set of numerical optimization algorithms with a Riemannian trust region method tailored to the symplectic Stiefel manifold.","To this end, we derive a matrix formula for the Riemannian Hessian under a right-invariant metric.","Moreover, we propose a novel retraction for approximating the Riemannian geodesics.","Finally, we conduct a comparative study in which we juxtapose the performance of the Riemannian variants of the steepest descent, conjugate gradients, and trust region methods on selected matrix optimization problems that feature symplectic constraints."],"url":"http://arxiv.org/abs/2404.08463v1","category":"math.NA"}
{"created":"2024-04-12 12:50:37","title":"Conforming virtual element method for nondivergence form linear elliptic equations with Cordes coefficients","abstract":"We propose and analyze an $H^2$-conforming Virtual Element Method (VEM) for the simplest linear elliptic PDEs in nondivergence form with Cordes coefficients. The VEM hinges on a hierarchical construction valid for any dimension $d \\ge 2$. The analysis relies on the continuous Miranda-Talenti estimate for convex domains $\\Omega$ and is rather elementary. We prove stability and error estimates in $H^2(\\Omega)$, including the effect of quadrature, under minimal regularity of the data. Numerical experiments illustrate the interplay of coefficient regularity and convergence rates in $H^2(\\Omega)$.","sentences":["We propose and analyze an $H^2$-conforming Virtual Element Method (VEM) for the simplest linear elliptic PDEs in nondivergence form with Cordes coefficients.","The VEM hinges on a hierarchical construction valid for any dimension $d \\ge 2$.","The analysis relies on the continuous Miranda-Talenti estimate for convex domains $\\Omega$ and is rather elementary.","We prove stability and error estimates in $H^2(\\Omega)$, including the effect of quadrature, under minimal regularity of the data.","Numerical experiments illustrate the interplay of coefficient regularity and convergence rates in $H^2(\\Omega)$."],"url":"http://arxiv.org/abs/2404.08442v1","category":"math.NA"}
{"created":"2024-04-12 12:30:43","title":"Great Observatory for Long Wavelengths (GO-LoW) NIAC Phase I Final Report","abstract":"The low-frequency sky below $\\sim$15 MHz (20 m) is obscured by the Earth's ionosphere, the layer of charged particles above the neutral atmosphere. Single spacecraft have made measurements in this band, but cannot achieve high or even moderate angular resolution because a telescope's resolution ($\\theta$) is set by $\\theta = \\lambda/D$, where $\\lambda$ is the wavelength and $D$ is the telescope diameter. For wavelengths that range from tens of meters to kilometers, a telescope must be hundreds of meters to many kilometers in diameter for even moderate resolution.   The Great Observatory for Long Wavelengths (GO-LoW) is an interferometric mega-constellation space telescope operating between 300 kHz and 15 MHz. In a departure from the traditional approach of a single, large, expensive spacecraft (e.g., HST, Chandra, JWST), GO-LoW is an interferometric Great Observatory comprising thousands of small, inexpensive, and reconfigurable nodes.   A distributed constellation of sensing elements provides (1) reliability and robustness to failures, (2) longevity by allowing for growth over time and infusion of new technology via staged replacement of nodes, (3) reduced costs through leveraging mass production, and (4) formation reconfigurability to optimize the observatory for diverse science cases.   A low-frequency mega-constellation revolutionizes a number of compelling science cases: high-resolution all-sky mapping, Dark Ages/Epoch of Reionization cosmology, interstellar medium mapping, solar/planetary magnetic activity, and exoplanetary magnetospheric radio emission.   This report summarizes GO-LoW's concept development under NASA's NIAC Phase I program. We discuss antenna design and sensitivity, constellation architecture, including communication and launch infrastructure, interferometric correlation and a technology roadmap.","sentences":["The low-frequency sky below $\\sim$15 MHz (20 m) is obscured by the Earth's ionosphere, the layer of charged particles above the neutral atmosphere.","Single spacecraft have made measurements in this band, but cannot achieve high or even moderate angular resolution because a telescope's resolution ($\\theta$) is set by $\\theta = \\lambda/D$, where $\\lambda$ is the wavelength and $D$ is the telescope diameter.","For wavelengths that range from tens of meters to kilometers, a telescope must be hundreds of meters to many kilometers in diameter for even moderate resolution.   ","The Great Observatory for Long Wavelengths (GO-LoW) is an interferometric mega-constellation space telescope operating between 300 kHz and 15 MHz.","In a departure from the traditional approach of a single, large, expensive spacecraft (e.g., HST, Chandra, JWST), GO-LoW is an interferometric Great Observatory comprising thousands of small, inexpensive, and reconfigurable nodes.   ","A distributed constellation of sensing elements provides (1) reliability and robustness to failures, (2) longevity by allowing for growth over time and infusion of new technology via staged replacement of nodes, (3) reduced costs through leveraging mass production, and (4) formation reconfigurability to optimize the observatory for diverse science cases.   ","A low-frequency mega-constellation revolutionizes a number of compelling science cases: high-resolution all-sky mapping, Dark Ages/Epoch of Reionization cosmology, interstellar medium mapping, solar/planetary magnetic activity, and exoplanetary magnetospheric radio emission.   ","This report summarizes GO-LoW's concept development under NASA's NIAC Phase I program.","We discuss antenna design and sensitivity, constellation architecture, including communication and launch infrastructure, interferometric correlation and a technology roadmap."],"url":"http://arxiv.org/abs/2404.08432v1","category":"astro-ph.IM"}
{"created":"2024-04-12 12:11:51","title":"SIR-RL: Reinforcement Learning for Optimized Policy Control during Epidemiological Outbreaks in Emerging Market and Developing Economies","abstract":"The outbreak of COVID-19 has highlighted the intricate interplay between public health and economic stability on a global scale. This study proposes a novel reinforcement learning framework designed to optimize health and economic outcomes during pandemics. The framework leverages the SIR model, integrating both lockdown measures (via a stringency index) and vaccination strategies to simulate disease dynamics. The stringency index, indicative of the severity of lockdown measures, influences both the spread of the disease and the economic health of a country. Developing nations, which bear a disproportionate economic burden under stringent lockdowns, are the primary focus of our study. By implementing reinforcement learning, we aim to optimize governmental responses and strike a balance between the competing costs associated with public health and economic stability. This approach also enhances transparency in governmental decision-making by establishing a well-defined reward function for the reinforcement learning agent. In essence, this study introduces an innovative and ethical strategy to navigate the challenge of balancing public health and economic stability amidst infectious disease outbreaks.","sentences":["The outbreak of COVID-19 has highlighted the intricate interplay between public health and economic stability on a global scale.","This study proposes a novel reinforcement learning framework designed to optimize health and economic outcomes during pandemics.","The framework leverages the SIR model, integrating both lockdown measures (via a stringency index) and vaccination strategies to simulate disease dynamics.","The stringency index, indicative of the severity of lockdown measures, influences both the spread of the disease and the economic health of a country.","Developing nations, which bear a disproportionate economic burden under stringent lockdowns, are the primary focus of our study.","By implementing reinforcement learning, we aim to optimize governmental responses and strike a balance between the competing costs associated with public health and economic stability.","This approach also enhances transparency in governmental decision-making by establishing a well-defined reward function for the reinforcement learning agent.","In essence, this study introduces an innovative and ethical strategy to navigate the challenge of balancing public health and economic stability amidst infectious disease outbreaks."],"url":"http://arxiv.org/abs/2404.08423v1","category":"cs.LG"}
{"created":"2024-04-12 11:30:16","title":"Learning representations of learning representations","abstract":"The ICLR conference is unique among the top machine learning conferences in that all submitted papers are openly available. Here we present the ICLR dataset consisting of abstracts of all 24 thousand ICLR submissions from 2017-2024 with meta-data, decision scores, and custom keyword-based labels. We find that on this dataset, bag-of-words representation outperforms most dedicated sentence transformer models in terms of $k$NN classification accuracy, and the top performing language models barely outperform TF-IDF. We see this as a challenge for the NLP community. Furthermore, we use the ICLR dataset to study how the field of machine learning has changed over the last seven years, finding some improvement in gender balance. Using a 2D embedding of the abstracts' texts, we describe a shift in research topics from 2017 to 2024 and identify hedgehogs and foxes among the authors with the highest number of ICLR submissions.","sentences":["The ICLR conference is unique among the top machine learning conferences in that all submitted papers are openly available.","Here we present the ICLR dataset consisting of abstracts of all 24 thousand ICLR submissions from 2017-2024 with meta-data, decision scores, and custom keyword-based labels.","We find that on this dataset, bag-of-words representation outperforms most dedicated sentence transformer models in terms of $k$NN classification accuracy, and the top performing language models barely outperform TF-IDF.","We see this as a challenge for the NLP community.","Furthermore, we use the ICLR dataset to study how the field of machine learning has changed over the last seven years, finding some improvement in gender balance.","Using a 2D embedding of the abstracts' texts, we describe a shift in research topics from 2017 to 2024 and identify hedgehogs and foxes among the authors with the highest number of ICLR submissions."],"url":"http://arxiv.org/abs/2404.08403v1","category":"cs.CL"}
{"created":"2024-04-12 10:44:12","title":"Coherence properties of NV-center ensembles in diamond coupled to an electron-spin bath","abstract":"We investigate nitrogen-vacancy center (NV) ensembles in diamond under the influence of strongly-correlated electron-spin baths. We thoroughly calculate the decoherence properties of the NV central spin for bath concentrations of 0.1-100 ppm using the cluster-correlation expansion (CCE) method. We systematically analyze possible origins of the significant deviations in the values of the $T_2$ coherence time reported in literature. We demonstrate that significant variations can originate from the choice of averaging and fitting procedures used for the ensemble average and we point out the respective aspects that need to be considered, when comparing the various theoretical studies. Our study may ease readers to perform reliable and fast simulations on the central spin problem. It provides an understanding and interpretation of the outcome parameters describing the dynamics of the local bath spins.","sentences":["We investigate nitrogen-vacancy center (NV) ensembles in diamond under the influence of strongly-correlated electron-spin baths.","We thoroughly calculate the decoherence properties of the NV central spin for bath concentrations of 0.1-100 ppm using the cluster-correlation expansion (CCE) method.","We systematically analyze possible origins of the significant deviations in the values of the $T_2$ coherence time reported in literature.","We demonstrate that significant variations can originate from the choice of averaging and fitting procedures used for the ensemble average and we point out the respective aspects that need to be considered, when comparing the various theoretical studies.","Our study may ease readers to perform reliable and fast simulations on the central spin problem.","It provides an understanding and interpretation of the outcome parameters describing the dynamics of the local bath spins."],"url":"http://arxiv.org/abs/2404.08388v1","category":"quant-ph"}
{"created":"2024-04-12 10:31:19","title":"Fourier optimization, the least quadratic non-residue, and the least prime in an arithmetic progression","abstract":"By means of a Fourier optimization framework, we improve the current asymptotic bounds under GRH for two classical problems in number theory: the problem of estimating the least quadratic non-residue modulo a prime, and the problem of estimating the least prime in an arithmetic progression.","sentences":["By means of a Fourier optimization framework, we improve the current asymptotic bounds under GRH for two classical problems in number theory: the problem of estimating the least quadratic non-residue modulo a prime, and the problem of estimating the least prime in an arithmetic progression."],"url":"http://arxiv.org/abs/2404.08380v1","category":"math.NT"}
{"created":"2024-04-12 09:31:11","title":"Self-Supervised k-Space Regularization for Motion-Resolved Abdominal MRI Using Neural Implicit k-Space Representation","abstract":"Neural implicit k-space representations have shown promising results for dynamic MRI at high temporal resolutions. Yet, their exclusive training in k-space limits the application of common image regularization methods to improve the final reconstruction. In this work, we introduce the concept of parallel imaging-inspired self-consistency (PISCO), which we incorporate as novel self-supervised k-space regularization enforcing a consistent neighborhood relationship. At no additional data cost, the proposed regularization significantly improves neural implicit k-space reconstructions on simulated data. Abdominal in-vivo reconstructions using PISCO result in enhanced spatio-temporal image quality compared to state-of-the-art methods. Code is available at https://github.com/vjspi/PISCO-NIK.","sentences":["Neural implicit k-space representations have shown promising results for dynamic MRI at high temporal resolutions.","Yet, their exclusive training in k-space limits the application of common image regularization methods to improve the final reconstruction.","In this work, we introduce the concept of parallel imaging-inspired self-consistency (PISCO), which we incorporate as novel self-supervised k-space regularization enforcing a consistent neighborhood relationship.","At no additional data cost, the proposed regularization significantly improves neural implicit k-space reconstructions on simulated data.","Abdominal in-vivo reconstructions using PISCO result in enhanced spatio-temporal image quality compared to state-of-the-art methods.","Code is available at https://github.com/vjspi/PISCO-NIK."],"url":"http://arxiv.org/abs/2404.08350v1","category":"eess.IV"}
{"created":"2024-04-12 09:17:43","title":"Quantum integrated sensing and communication via entanglement","abstract":"Quantum communication and quantum metrology are widely compelling applications in the field of quantum information science, and quantum remote sensing is an intersection of both. Despite their differences, there are notable commonalities between quantum communication and quantum remote sensing, as they achieve their functionalities through the transmission of quantum states. Here we propose a novel quantum integrated sensing and communication (QISAC) protocol, which achieves quantum sensing under the Heisenberg limit while simultaneously enabling quantum secure communication through the transmission of entanglements. We have theoretically proven its security against eavesdroppers. The security of QISAC is characterized by the secrecy capacity for information bit as well as asymmetric Fisher information gain for sensing. Through simulations conducted under the constraints of limited entanglement resources, we illustrate that QISAC maintains high accuracy in the estimation of phase. Hence our QISAC offers a fresh perspective for the applications of future quantum networks.","sentences":["Quantum communication and quantum metrology are widely compelling applications in the field of quantum information science, and quantum remote sensing is an intersection of both.","Despite their differences, there are notable commonalities between quantum communication and quantum remote sensing, as they achieve their functionalities through the transmission of quantum states.","Here we propose a novel quantum integrated sensing and communication (QISAC) protocol, which achieves quantum sensing under the Heisenberg limit while simultaneously enabling quantum secure communication through the transmission of entanglements.","We have theoretically proven its security against eavesdroppers.","The security of QISAC is characterized by the secrecy capacity for information bit as well as asymmetric Fisher information gain for sensing.","Through simulations conducted under the constraints of limited entanglement resources, we illustrate that QISAC maintains high accuracy in the estimation of phase.","Hence our QISAC offers a fresh perspective for the applications of future quantum networks."],"url":"http://arxiv.org/abs/2404.08342v1","category":"quant-ph"}
{"created":"2024-04-12 08:35:38","title":"Uncertainty Aware Tropical Cyclone Wind Speed Estimation from Satellite Data","abstract":"Deep neural networks (DNNs) have been successfully applied to earth observation (EO) data and opened new research avenues. Despite the theoretical and practical advances of these techniques, DNNs are still considered black box tools and by default are designed to give point predictions. However, the majority of EO applications demand reliable uncertainty estimates that can support practitioners in critical decision making tasks. This work provides a theoretical and quantitative comparison of existing uncertainty quantification methods for DNNs applied to the task of wind speed estimation in satellite imagery of tropical cyclones. We provide a detailed evaluation of predictive uncertainty estimates from state-of-the-art uncertainty quantification (UQ) methods for DNNs. We find that predictive uncertainties can be utilized to further improve accuracy and analyze the predictive uncertainties of different methods across storm categories.","sentences":["Deep neural networks (DNNs) have been successfully applied to earth observation (EO) data and opened new research avenues.","Despite the theoretical and practical advances of these techniques, DNNs are still considered black box tools and by default are designed to give point predictions.","However, the majority of EO applications demand reliable uncertainty estimates that can support practitioners in critical decision making tasks.","This work provides a theoretical and quantitative comparison of existing uncertainty quantification methods for DNNs applied to the task of wind speed estimation in satellite imagery of tropical cyclones.","We provide a detailed evaluation of predictive uncertainty estimates from state-of-the-art uncertainty quantification (UQ) methods for DNNs.","We find that predictive uncertainties can be utilized to further improve accuracy and analyze the predictive uncertainties of different methods across storm categories."],"url":"http://arxiv.org/abs/2404.08325v1","category":"physics.ao-ph"}
{"created":"2024-04-12 08:22:57","title":"Technical Design Report of the Spin Physics Detector at NICA","abstract":"The Spin Physics Detector collaboration proposes to install a universal detector in the second interaction point of the NICA collider under construction (JINR, Dubna) to study the spin structure of the proton and deuteron and other spin-related phenomena using a unique possibility to operate with polarized proton and deuteron beams at a collision energy up to 27 GeV and a luminosity up to $10^{32}$ cm$^{-2}$ s$^{-1}$. As the main goal, the experiment aims to provide access to the gluon TMD PDFs in the proton and deuteron, as well as the gluon transversity distribution and tensor PDFs in the deuteron, via the measurement of specific single and double spin asymmetries using different complementary probes such as charmonia, open charm, and prompt photon production processes. Other polarized and unpolarized physics is possible, especially at the first stage of NICA operation with reduced luminosity and collision energy of the proton and ion beams. This document is dedicated exclusively to technical issues of the SPD setup construction.","sentences":["The Spin Physics Detector collaboration proposes to install a universal detector in the second interaction point of the NICA collider under construction (JINR, Dubna) to study the spin structure of the proton and deuteron and other spin-related phenomena using a unique possibility to operate with polarized proton and deuteron beams at a collision energy up to 27 GeV and a luminosity up to $10^{32}$ cm$^{-2}$ s$^{-1}$.","As the main goal, the experiment aims to provide access to the gluon TMD PDFs in the proton and deuteron, as well as the gluon transversity distribution and tensor PDFs in the deuteron, via the measurement of specific single and double spin asymmetries using different complementary probes such as charmonia, open charm, and prompt photon production processes.","Other polarized and unpolarized physics is possible, especially at the first stage of NICA operation with reduced luminosity and collision energy of the proton and ion beams.","This document is dedicated exclusively to technical issues of the SPD setup construction."],"url":"http://arxiv.org/abs/2404.08317v1","category":"hep-ex"}
{"created":"2024-04-12 08:09:26","title":"Manifest V3 Unveiled: Navigating the New Era of Browser Extensions","abstract":"Introduced over a decade ago, Chrome extensions now exceed 200,000 in number. In 2020, Google announced a shift in extension development with Manifest Version 3 (V3), aiming to replace the previous Version 2 (V2) by January 2023. This deadline was later extended to January 2025. The company's decision is grounded in enhancing three main pillars: privacy, security, and performance. This paper presents a comprehensive analysis of the Manifest V3 ecosystem. We start by investigating the adoption rate of V3, detailing the percentage of adoption from its announcement up until 2024. Our findings indicate, prior to the 2023 pause, less than 5% of all extensions had transitioned to V3, despite the looming deadline for the complete removal of V2, while currently nine out of ten new extensions are being uploaded in Manifest V3. Furthermore, we compare the security and privacy enhancements between V2 and V3 and we evaluate the improved security attributable to V3's safer APIs, examining how certain APIs, which were vulnerable or facilitated malicious behavior, have been deprecated or removed in V3. We dynamically execute 517 confirmed malicious extensions and we see a 87.8% removal of APIs related to malicious behavior due to the improvements of V3. We discover that only 154 (29.8%) of these extensions remain functional post-conversion. This analysis leads to the conclusion that V3 reduces the avenues for abuse of such APIs. However, despite the reduction in APIs associated with malicious activities, the new Manifest V3 protocol is not immune to such behavior. Our research demonstrates, through a proof of concept, the adaptability of malicious activities to V3. After the proof of concept changes are applied, we showcase 290 (56%) of the examined malicious extensions retain their capability to conduct harmful activities within the V3 framework.","sentences":["Introduced over a decade ago, Chrome extensions now exceed 200,000 in number.","In 2020, Google announced a shift in extension development with Manifest Version 3 (V3), aiming to replace the previous Version 2 (V2) by January 2023.","This deadline was later extended to January 2025.","The company's decision is grounded in enhancing three main pillars: privacy, security, and performance.","This paper presents a comprehensive analysis of the Manifest V3 ecosystem.","We start by investigating the adoption rate of V3, detailing the percentage of adoption from its announcement up until 2024.","Our findings indicate, prior to the 2023 pause, less than 5% of all extensions had transitioned to V3, despite the looming deadline for the complete removal of V2, while currently nine out of ten new extensions are being uploaded in Manifest V3.","Furthermore, we compare the security and privacy enhancements between V2 and V3 and we evaluate the improved security attributable to V3's safer APIs, examining how certain APIs, which were vulnerable or facilitated malicious behavior, have been deprecated or removed in V3.","We dynamically execute 517 confirmed malicious extensions and we see a 87.8% removal of APIs related to malicious behavior due to the improvements of V3.","We discover that only 154 (29.8%) of these extensions remain functional post-conversion.","This analysis leads to the conclusion that V3 reduces the avenues for abuse of such APIs.","However, despite the reduction in APIs associated with malicious activities, the new Manifest V3 protocol is not immune to such behavior.","Our research demonstrates, through a proof of concept, the adaptability of malicious activities to V3.","After the proof of concept changes are applied, we showcase 290 (56%) of the examined malicious extensions retain their capability to conduct harmful activities within the V3 framework."],"url":"http://arxiv.org/abs/2404.08310v1","category":"cs.CR"}
{"created":"2024-04-12 07:51:54","title":"Uncertainty relations based on the $\u03c1$-absolute variance for quantum channels","abstract":"Uncertainty principle reveals the intrinsic differences between the classical and quantum worlds, which plays a significant role in quantum information theory. By using $\\rho$-absolute variance, we introduce the uncertainty of quantum channels and explore its properties. By using Cauchy-Schwarz inequality and the parallelogram law, we establish the product and summation forms of the uncertainty relations for arbitrary two quantum channels, respectively. The summation form of the uncertainty inequalities based on the $\\rho$-absolute variance for arbitrary $N$ quantum channels are also investigated and the optimal lower bounds are presented. We illustrate our results by several typical examples.","sentences":["Uncertainty principle reveals the intrinsic differences between the classical and quantum worlds, which plays a significant role in quantum information theory.","By using $\\rho$-absolute variance, we introduce the uncertainty of quantum channels and explore its properties.","By using Cauchy-Schwarz inequality and the parallelogram law, we establish the product and summation forms of the uncertainty relations for arbitrary two quantum channels, respectively.","The summation form of the uncertainty inequalities based on the $\\rho$-absolute variance for arbitrary $N$ quantum channels are also investigated and the optimal lower bounds are presented.","We illustrate our results by several typical examples."],"url":"http://arxiv.org/abs/2404.08304v1","category":"quant-ph"}
{"created":"2024-04-12 07:47:02","title":"Collaborative-Enhanced Prediction of Spending on Newly Downloaded Mobile Games under Consumption Uncertainty","abstract":"With the surge in mobile gaming, accurately predicting user spending on newly downloaded games has become paramount for maximizing revenue. However, the inherently unpredictable nature of user behavior poses significant challenges in this endeavor. To address this, we propose a robust model training and evaluation framework aimed at standardizing spending data to mitigate label variance and extremes, ensuring stability in the modeling process. Within this framework, we introduce a collaborative-enhanced model designed to predict user game spending without relying on user IDs, thus ensuring user privacy and enabling seamless online training. Our model adopts a unique approach by separately representing user preferences and game features before merging them as input to the spending prediction module. Through rigorous experimentation, our approach demonstrates notable improvements over production models, achieving a remarkable \\textbf{17.11}\\% enhancement on offline data and an impressive \\textbf{50.65}\\% boost in an online A/B test. In summary, our contributions underscore the importance of stable model training frameworks and the efficacy of collaborative-enhanced models in predicting user spending behavior in mobile gaming.","sentences":["With the surge in mobile gaming, accurately predicting user spending on newly downloaded games has become paramount for maximizing revenue.","However, the inherently unpredictable nature of user behavior poses significant challenges in this endeavor.","To address this, we propose a robust model training and evaluation framework aimed at standardizing spending data to mitigate label variance and extremes, ensuring stability in the modeling process.","Within this framework, we introduce a collaborative-enhanced model designed to predict user game spending without relying on user IDs, thus ensuring user privacy and enabling seamless online training.","Our model adopts a unique approach by separately representing user preferences and game features before merging them as input to the spending prediction module.","Through rigorous experimentation, our approach demonstrates notable improvements over production models, achieving a remarkable \\textbf{17.11}\\% enhancement on offline data and an impressive \\textbf{50.65}\\% boost in an online A/B test.","In summary, our contributions underscore the importance of stable model training frameworks and the efficacy of collaborative-enhanced models in predicting user spending behavior in mobile gaming."],"url":"http://arxiv.org/abs/2404.08301v1","category":"cs.IR"}
{"created":"2024-04-12 07:22:33","title":"Bottom-up Rebalancing Binary Search Trees by Flipping a Coin","abstract":"Rebalancing schemes for dynamic binary search trees are numerous in the literature, where the goal is to maintain trees of low height, either in the worst-case or expected sense. In this paper we study randomized rebalancing schemes for sequences of $n$ insertions into an initially empty binary search tree, under the assumption that a tree only stores the elements and the tree structure without any additional balance information. Seidel~(2009) presented a top-down randomized insertion algorithm, where insertions take expected $O\\big(\\lg^2 n\\big)$ time, and the resulting trees have the same distribution as inserting a uniform random permutation into a binary search tree without rebalancing. Seidel states as an open problem if a similar result can be achieved with bottom-up insertions. In this paper we fail to answer this question.   We consider two simple canonical randomized bottom-up insertion algorithms on binary search trees, assuming that an insertion is given the position where to insert the next element. The subsequent rebalancing is performed bottom-up in expected $O(1)$ time, uses expected $O(1)$ random bits, performs at most two rotations, and the rotations appear with geometrically decreasing probability in the distance from the leaf. For some insertion sequences the expected depth of each node is proved to be $O(\\lg n)$. On the negative side, we prove for both algorithms that there exist simple insertion sequences where the expected depth is $\\Omega(n)$, i.e., the studied rebalancing schemes are \\emph{not} competitive with (most) other rebalancing schemes in the literature.","sentences":["Rebalancing schemes for dynamic binary search trees are numerous in the literature, where the goal is to maintain trees of low height, either in the worst-case or expected sense.","In this paper we study randomized rebalancing schemes for sequences of $n$ insertions into an initially empty binary search tree, under the assumption that a tree only stores the elements and the tree structure without any additional balance information.","Seidel~(2009) presented a top-down randomized insertion algorithm, where insertions take expected $O\\big(\\lg^2 n\\big)$ time, and the resulting trees have the same distribution as inserting a uniform random permutation into a binary search tree without rebalancing.","Seidel states as an open problem if a similar result can be achieved with bottom-up insertions.","In this paper we fail to answer this question.   ","We consider two simple canonical randomized bottom-up insertion algorithms on binary search trees, assuming that an insertion is given the position where to insert the next element.","The subsequent rebalancing is performed bottom-up in expected $O(1)$ time, uses expected $O(1)$ random bits, performs at most two rotations, and the rotations appear with geometrically decreasing probability in the distance from the leaf.","For some insertion sequences the expected depth of each node is proved to be $O(\\lg n)$.","On the negative side, we prove for both algorithms that there exist simple insertion sequences where the expected depth is $\\Omega(n)$, i.e., the studied rebalancing schemes are \\emph{not} competitive with (most) other rebalancing schemes in the literature."],"url":"http://arxiv.org/abs/2404.08287v1","category":"cs.DS"}
{"created":"2024-04-12 06:34:40","title":"Electron-phonon interaction, magnetic phase transition, charge density waves and resistive switching in VS2 and VSe2 revealed by Yanson point contact spectroscopy","abstract":"VS2 and VSe2 have attracted particular attention among the transition metals dichalcogenides because of their promising physical properties concerning magnetic ordering, charge density wave (CDW), emergent superconductivity, etc., which are very sensitive to stoichiometry and dimensionality reduction. Yanson point contact (PC) spectroscopic study reveals metallic and nonmetallic states in VS2 PCs, as well as a magnetic phase transition was detected below 25 K. Analysis of PC spectra of VS2 testifies the realization of the thermal regime in PCs. At the same time, rare PC spectra, where the magnetic phase transition was not visible, shows a broad maximum of around 20 mV, likely connected with electron-phonon interaction (EPI). On the other hand, PC spectra of VSe2 demonstrate metallic behavior, which allowed us to detect features associated with EPI and CDW transition. The Kondo effect appeared for both compounds, apparently due to interlayer vanadium ions. Besides, the resistive switching was observed in PCs on VSe2 between a low resistive, mainly metallic-type state, and a high resistive nonmetallic-type state by applying bias voltage (about 0.4V). In contrast, reverse switching occurs by applying a voltage of opposite polarity (about 0.4V). The reason may be the alteration of stoichiometry in the PC core due to the displacement of V ions to interlayer under a high electric field. The observed resistive switching characterize VSe2 as a potential material, e.g., for non-volatile resistive RAM, neuromorphic engineering, and for other nanoelectronic applications. At the same time, VSe2 attracts attention as a rare layered van der Waals compound with magnetic transition.","sentences":["VS2 and VSe2 have attracted particular attention among the transition metals dichalcogenides because of their promising physical properties concerning magnetic ordering, charge density wave (CDW), emergent superconductivity, etc., which are very sensitive to stoichiometry and dimensionality reduction.","Yanson point contact (PC) spectroscopic study reveals metallic and nonmetallic states in VS2 PCs, as well as a magnetic phase transition was detected below 25 K. Analysis of PC spectra of VS2 testifies the realization of the thermal regime in PCs.","At the same time, rare PC spectra, where the magnetic phase transition was not visible, shows a broad maximum of around 20 mV, likely connected with electron-phonon interaction (EPI).","On the other hand, PC spectra of VSe2 demonstrate metallic behavior, which allowed us to detect features associated with EPI and CDW transition.","The Kondo effect appeared for both compounds, apparently due to interlayer vanadium ions.","Besides, the resistive switching was observed in PCs on VSe2 between a low resistive, mainly metallic-type state, and a high resistive nonmetallic-type state by applying bias voltage (about 0.4V).","In contrast, reverse switching occurs by applying a voltage of opposite polarity (about 0.4V).","The reason may be the alteration of stoichiometry in the PC core due to the displacement of V ions to interlayer under a high electric field.","The observed resistive switching characterize VSe2 as a potential material, e.g., for non-volatile resistive RAM, neuromorphic engineering, and for other nanoelectronic applications.","At the same time, VSe2 attracts attention as a rare layered van der Waals compound with magnetic transition."],"url":"http://arxiv.org/abs/2404.08269v1","category":"cond-mat.mes-hall"}
{"created":"2024-04-12 06:24:45","title":"Quantum molecular docking with quantum-inspired algorithm","abstract":"Molecular docking (MD) is a crucial task in drug design, which predicts the position, orientation, and conformation of the ligand when bound to a target protein. It can be interpreted as a combinatorial optimization problem, where quantum annealing (QA) has shown promising advantage for solving combinatorial optimization. In this work, we propose a novel quantum molecular docking (QMD) approach based on QA-inspired algorithm. We construct two binary encoding methods to efficiently discretize the degrees of freedom with exponentially reduced number of bits and propose a smoothing filter to rescale the rugged objective function. We propose a new quantum-inspired algorithm, hopscotch simulated bifurcation (hSB), showing great advantage in optimizing over extremely rugged energy landscapes. This hSB can be applied to any formulation of objective function under binary variables. An adaptive local continuous search is also introduced for further optimization of the discretized solution from hSB. Concerning the stability of docking, we propose a perturbation detection method to help ranking the candidate poses. We demonstrate our approach on a typical dataset. QMD has shown advantages over the search-based Autodock Vina and the deep-learning DIFFDOCK in both re-docking and self-docking scenarios. These results indicate that quantum-inspired algorithms can be applied to solve practical problems in the drug discovery even before quantum hardware become mature.","sentences":["Molecular docking (MD) is a crucial task in drug design, which predicts the position, orientation, and conformation of the ligand when bound to a target protein.","It can be interpreted as a combinatorial optimization problem, where quantum annealing (QA) has shown promising advantage for solving combinatorial optimization.","In this work, we propose a novel quantum molecular docking (QMD) approach based on QA-inspired algorithm.","We construct two binary encoding methods to efficiently discretize the degrees of freedom with exponentially reduced number of bits and propose a smoothing filter to rescale the rugged objective function.","We propose a new quantum-inspired algorithm, hopscotch simulated bifurcation (hSB), showing great advantage in optimizing over extremely rugged energy landscapes.","This hSB can be applied to any formulation of objective function under binary variables.","An adaptive local continuous search is also introduced for further optimization of the discretized solution from hSB.","Concerning the stability of docking, we propose a perturbation detection method to help ranking the candidate poses.","We demonstrate our approach on a typical dataset.","QMD has shown advantages over the search-based Autodock Vina and the deep-learning DIFFDOCK in both re-docking and self-docking scenarios.","These results indicate that quantum-inspired algorithms can be applied to solve practical problems in the drug discovery even before quantum hardware become mature."],"url":"http://arxiv.org/abs/2404.08265v1","category":"physics.chem-ph"}
{"created":"2024-04-12 06:09:24","title":"Practical Region-level Attack against Segment Anything Models","abstract":"Segment Anything Models (SAM) have made significant advancements in image segmentation, allowing users to segment target portions of an image with a single click (i.e., user prompt). Given its broad applications, the robustness of SAM against adversarial attacks is a critical concern. While recent works have explored adversarial attacks against a pre-defined prompt/click, their threat model is not yet realistic: (1) they often assume the user-click position is known to the attacker (point-based attack), and (2) they often operate under a white-box setting with limited transferability. In this paper, we propose a more practical region-level attack where attackers do not need to know the precise user prompt. The attack remains effective as the user clicks on any point on the target object in the image, hiding the object from SAM. Also, by adapting a spectrum transformation method, we make the attack more transferable under a black-box setting. Both control experiments and testing against real-world SAM services confirm its effectiveness.","sentences":["Segment Anything Models (SAM) have made significant advancements in image segmentation, allowing users to segment target portions of an image with a single click (i.e., user prompt).","Given its broad applications, the robustness of SAM against adversarial attacks is a critical concern.","While recent works have explored adversarial attacks against a pre-defined prompt/click, their threat model is not yet realistic: (1) they often assume the user-click position is known to the attacker (point-based attack), and (2) they often operate under a white-box setting with limited transferability.","In this paper, we propose a more practical region-level attack where attackers do not need to know the precise user prompt.","The attack remains effective as the user clicks on any point on the target object in the image, hiding the object from SAM.","Also, by adapting a spectrum transformation method, we make the attack more transferable under a black-box setting.","Both control experiments and testing against real-world SAM services confirm its effectiveness."],"url":"http://arxiv.org/abs/2404.08255v1","category":"cs.CV"}
{"created":"2024-04-12 04:38:58","title":"Interest Maximization in Social Networks","abstract":"Nowadays, organizations use viral marketing strategies to promote their products through social networks. It is expensive to directly send the product promotional information to all the users in the network. In this context, Kempe et al. \\cite{kempe2003maximizing} introduced the Influence Maximization (IM) problem, which identifies $k$ most influential nodes (spreader nodes), such that the maximum number of people in the network adopts the promotional message.   Many variants of the IM problem have been studied in the literature, namely, Perfect Evangelising Set (PES), Perfect Awareness Problem (PAP), etc. In this work, we propose a maximization version of PAP called the \\IM{} problem. Different people have different levels of interest in a particular product. This is modeled by assigning an interest value to each node in the network. Then, the problem is to select $k$ initial spreaders such that the sum of the interest values of the people (nodes) who become aware of the message is maximized.   We study the \\IM{} problem under two popular diffusion models: the Linear Threshold Model (LTM) and the Independent Cascade Model (ICM). We show that the \\IM{} problem is NP-Hard under LTM. We give linear programming formulation for the problem under LTM. We propose four heuristic algorithms for the \\IM{} problem: \\LBE{} (\\LB{}), Maximum Degree First Heuristic (\\MD{}), \\PBE{} (\\PB{}), and Maximum Profit Based Greedy Heuristic (\\MP{}). Extensive experimentation has been carried out on many real-world benchmark data sets for both diffusion models. The results show that among the proposed heuristics, \\MP{} performs better in maximizing the interest value.","sentences":["Nowadays, organizations use viral marketing strategies to promote their products through social networks.","It is expensive to directly send the product promotional information to all the users in the network.","In this context, Kempe et al. \\cite{kempe2003maximizing} introduced the Influence Maximization (IM) problem, which identifies $k$ most influential nodes (spreader nodes), such that the maximum number of people in the network adopts the promotional message.   ","Many variants of the IM problem have been studied in the literature, namely, Perfect Evangelising Set (PES), Perfect Awareness Problem (PAP), etc.","In this work, we propose a maximization version of PAP called the \\IM{} problem.","Different people have different levels of interest in a particular product.","This is modeled by assigning an interest value to each node in the network.","Then, the problem is to select $k$ initial spreaders such that the sum of the interest values of the people (nodes) who become aware of the message is maximized.   ","We study the \\IM{} problem under two popular diffusion models: the Linear Threshold Model (LTM) and the Independent Cascade Model (ICM).","We show that the \\IM{} problem is NP-Hard under LTM.","We give linear programming formulation for the problem under LTM.","We propose four heuristic algorithms for the \\IM{} problem: \\LBE{} (\\LB{}), Maximum Degree First Heuristic (\\MD{}), \\PBE{} (\\PB{}), and Maximum Profit Based Greedy Heuristic (\\MP{}).","Extensive experimentation has been carried out on many real-world benchmark data sets for both diffusion models.","The results show that among the proposed heuristics, \\MP{} performs better in maximizing the interest value."],"url":"http://arxiv.org/abs/2404.08236v1","category":"cs.SI"}
{"created":"2024-04-12 04:17:50","title":"Enhancing Fairness and Performance in Machine Learning Models: A Multi-Task Learning Approach with Monte-Carlo Dropout and Pareto Optimality","abstract":"This paper considers the need for generalizable bias mitigation techniques in machine learning due to the growing concerns of fairness and discrimination in data-driven decision-making procedures across a range of industries. While many existing methods for mitigating bias in machine learning have succeeded in specific cases, they often lack generalizability and cannot be easily applied to different data types or models. Additionally, the trade-off between accuracy and fairness remains a fundamental tension in the field. To address these issues, we propose a bias mitigation method based on multi-task learning, utilizing the concept of Monte-Carlo dropout and Pareto optimality from multi-objective optimization. This method optimizes accuracy and fairness while improving the model's explainability without using sensitive information. We test this method on three datasets from different domains and show how it can deliver the most desired trade-off between model fairness and performance. This allows for tuning in specific domains where one metric may be more important than another. With the framework we introduce in this paper, we aim to enhance the fairness-performance trade-off and offer a solution to bias mitigation methods' generalizability issues in machine learning.","sentences":["This paper considers the need for generalizable bias mitigation techniques in machine learning due to the growing concerns of fairness and discrimination in data-driven decision-making procedures across a range of industries.","While many existing methods for mitigating bias in machine learning have succeeded in specific cases, they often lack generalizability and cannot be easily applied to different data types or models.","Additionally, the trade-off between accuracy and fairness remains a fundamental tension in the field.","To address these issues, we propose a bias mitigation method based on multi-task learning, utilizing the concept of Monte-Carlo dropout and Pareto optimality from multi-objective optimization.","This method optimizes accuracy and fairness while improving the model's explainability without using sensitive information.","We test this method on three datasets from different domains and show how it can deliver the most desired trade-off between model fairness and performance.","This allows for tuning in specific domains where one metric may be more important than another.","With the framework we introduce in this paper, we aim to enhance the fairness-performance trade-off and offer a solution to bias mitigation methods' generalizability issues in machine learning."],"url":"http://arxiv.org/abs/2404.08230v1","category":"cs.LG"}
{"created":"2024-04-12 03:07:15","title":"Multi-Objective Evolutionary Algorithms with Sliding Window Selection for the Dynamic Chance-Constrained Knapsack Problem","abstract":"Evolutionary algorithms are particularly effective for optimisation problems with dynamic and stochastic components. We propose multi-objective evolutionary approaches for the knapsack problem with stochastic profits under static and dynamic weight constraints. The chance-constrained problem model allows us to effectively capture the stochastic profits and associate a confidence level to the solutions' profits. We consider a bi-objective formulation that maximises expected profit and minimises variance, which allows optimising the problem independent of a specific confidence level on the profit. We derive a three-objective formulation by relaxing the weight constraint into an additional objective. We consider the GSEMO algorithm with standard and a sliding window-based parent selection to evaluate the objective formulations. Moreover, we modify fitness formulations and algorithms for the dynamic problem variant to store some infeasible solutions to cater to future changes. We conduct experimental investigations on both problems using the proposed problem formulations and algorithms. Our results show that three-objective approaches outperform approaches that use bi-objective formulations, and they further improve when GSEMO uses sliding window selection.","sentences":["Evolutionary algorithms are particularly effective for optimisation problems with dynamic and stochastic components.","We propose multi-objective evolutionary approaches for the knapsack problem with stochastic profits under static and dynamic weight constraints.","The chance-constrained problem model allows us to effectively capture the stochastic profits and associate a confidence level to the solutions' profits.","We consider a bi-objective formulation that maximises expected profit and minimises variance, which allows optimising the problem independent of a specific confidence level on the profit.","We derive a three-objective formulation by relaxing the weight constraint into an additional objective.","We consider the GSEMO algorithm with standard and a sliding window-based parent selection to evaluate the objective formulations.","Moreover, we modify fitness formulations and algorithms for the dynamic problem variant to store some infeasible solutions to cater to future changes.","We conduct experimental investigations on both problems using the proposed problem formulations and algorithms.","Our results show that three-objective approaches outperform approaches that use bi-objective formulations, and they further improve when GSEMO uses sliding window selection."],"url":"http://arxiv.org/abs/2404.08219v1","category":"cs.NE"}
{"created":"2024-04-12 03:03:41","title":"Sharp spectral transition for embedded eigenvalues of perturbed periodic Dirac operators","abstract":"We consider the Dirac equation on $L^2(\\mathbb{R})\\oplus L^2(\\mathbb{R})$   \\begin{align}   Ly=   \\begin{pmatrix}   0&-1   1&0   \\end{pmatrix}   \\begin{pmatrix}   y_1   y_2   \\end{pmatrix}'+   \\begin{pmatrix}   p&q   q&-p   \\end{pmatrix}\\begin{pmatrix}   y_1   y_2   \\end{pmatrix}+   V\\begin{pmatrix}   y_1   y_2   \\end{pmatrix}=\\lambda y,\\nonumber   \\end{align}   where $y=y(x,\\lambda)=\\tbinom{y_1(x,\\lambda)}{y_2(x,\\lambda)}$, $p$ and $q$ are real $1$-periodic, and   \\begin{align}   V=\\begin{pmatrix}   V(x)&0   0&-V(x)   \\end{pmatrix}\\nonumber   \\end{align}   is the perturbation which satisfies $V(x)=o(1)$ as $\\abs{x}\\to\\infty.$   Under such perturbation, the essential spectrum of $L$ coincides with that there is no perturbation.   We prove that if $V(x)=\\frac{o(1)}{1+\\abs{x}}$ as $x\\to\\infty$ or $x\\to-\\infty$, then there is no embedded eigenvalues (eigenvalues appear in the essential spectrum). For any given finite set inside of the essential spectrum which satisfies the non-resonance assumption, we construct smooth potentials with $V(x)=\\frac{O(1)}{1+\\abs{x}}$ as $\\abs{x}\\to\\infty$ so that the set becomes embedded eigenvalues. For any given countable set inside of the essential spectrum which satisfies the non-resonance assumption, we construct smooth potentials with $V(x)<\\frac{\\abs{h(x)}}{1+\\abs{x}}$ as $\\abs{x}\\to\\infty$ so that the set becomes embedded eigenvalues, where $h(x)$ is any given function with $\\lim_{x\\to\\pm\\infty}\\abs{h(x)}=\\infty.$","sentences":["We consider the Dirac equation on $L^2(\\mathbb{R})\\oplus L^2(\\mathbb{R})$   \\begin{align}   Ly=   \\begin{pmatrix}   0&-1   1&0   \\end{pmatrix}   \\begin{pmatrix}   y_1   y_2   \\end{pmatrix}'+   \\begin{pmatrix}   p&q   q&-p   \\end{pmatrix}\\begin{pmatrix}   y_1   y_2   \\end{pmatrix}+   V\\begin{pmatrix}   y_1   y_2   \\end{pmatrix}=\\lambda","y,\\nonumber   \\end{align}   where $y=y(x,\\lambda)=\\tbinom{y_1(x,\\lambda)}{y_2(x,\\lambda)}$, $p$ and $q$ are real $1$-periodic, and   \\begin{align}   V=\\begin{pmatrix}   V(x)&0   0&-V(x)   \\end{pmatrix}\\nonumber   \\end{align}   is the perturbation which satisfies $V(x)=o(1)$ as $\\abs{x}\\to\\infty.$   Under such perturbation, the essential spectrum of $L$ coincides with that there is no perturbation.   ","We prove that if $V(x)=\\frac{o(1)}{1+\\abs{x}}$ as $x\\to\\infty$ or $x\\to-\\infty$, then there is no embedded eigenvalues (eigenvalues appear in the essential spectrum).","For any given finite set inside of the essential spectrum which satisfies the non-resonance assumption, we construct smooth potentials with $V(x)=\\frac{O(1)}{1+\\abs{x}}$ as $\\abs{x}\\to\\infty$ so that the set becomes embedded eigenvalues.","For any given countable set inside of the essential spectrum which satisfies the non-resonance assumption, we construct smooth potentials with $V(x)<\\frac{\\abs{h(x)}}{1+\\abs{x}}$ as $\\abs{x}\\to\\infty$ so that the set becomes embedded eigenvalues, where $h(x)$ is any given function with $\\lim_{x\\to\\pm\\infty}\\abs{h(x)}=\\infty.$"],"url":"http://arxiv.org/abs/2404.08218v1","category":"math-ph"}
{"created":"2024-04-12 17:22:34","title":"A Kalman Filter for track reconstruction in very large time projection chambers","abstract":"This study introduces a Kalman Filter tailored for homogeneous gas Time Projection Chambers (TPCs), adapted from the algorithm utilized by the ALICE experiment. In order to describe semi-circular paths in the plane perpendicular to the magnetic field, we introduce a novel mirror rotation technique into the Kalman Filter algorithm, enabling effective tracking of trajectories of varying lengths, including those with multiple circular paths within the detector, also known as \"loopers\". Demonstrated relative improvements of up to 80\\% in electron momentum resolution and up to 50\\% in muon and pion momentum resolution underscore the significance of this enhancement. Such advancements hold promise not only for the future of the ALICE TPC but also for neutrino high-pressure gas TPCs, where loopers become significant owing to the randomness of production points and their relatively low energies in neutrino interactions.","sentences":["This study introduces a Kalman Filter tailored for homogeneous gas Time Projection Chambers (TPCs), adapted from the algorithm utilized by the ALICE experiment.","In order to describe semi-circular paths in the plane perpendicular to the magnetic field, we introduce a novel mirror rotation technique into the Kalman Filter algorithm, enabling effective tracking of trajectories of varying lengths, including those with multiple circular paths within the detector, also known as \"loopers\".","Demonstrated relative improvements of up to 80\\% in electron momentum resolution and up to 50\\% in muon and pion momentum resolution underscore the significance of this enhancement.","Such advancements hold promise not only for the future of the ALICE TPC but also for neutrino high-pressure gas TPCs, where loopers become significant owing to the randomness of production points and their relatively low energies in neutrino interactions."],"url":"http://arxiv.org/abs/2404.08614v1","category":"physics.ins-det"}
{"created":"2024-04-12 11:06:22","title":"Data-Driven Preference Sampling for Pareto Front Learning","abstract":"Pareto front learning is a technique that introduces preference vectors in a neural network to approximate the Pareto front. Previous Pareto front learning methods have demonstrated high performance in approximating simple Pareto fronts. These methods often sample preference vectors from a fixed Dirichlet distribution. However, no fixed sampling distribution can be adapted to diverse Pareto fronts. Efficiently sampling preference vectors and accurately estimating the Pareto front is a challenge. To address this challenge, we propose a data-driven preference vector sampling framework for Pareto front learning. We utilize the posterior information of the objective functions to adjust the parameters of the sampling distribution flexibly. In this manner, the proposed method can sample preference vectors from the location of the Pareto front with a high probability. Moreover, we design the distribution of the preference vector as a mixture of Dirichlet distributions to improve the performance of the model in disconnected Pareto fronts. Extensive experiments validate the superiority of the proposed method compared with state-of-the-art algorithms.","sentences":["Pareto front learning is a technique that introduces preference vectors in a neural network to approximate the Pareto front.","Previous Pareto front learning methods have demonstrated high performance in approximating simple Pareto fronts.","These methods often sample preference vectors from a fixed Dirichlet distribution.","However, no fixed sampling distribution can be adapted to diverse Pareto fronts.","Efficiently sampling preference vectors and accurately estimating the Pareto front is a challenge.","To address this challenge, we propose a data-driven preference vector sampling framework for Pareto front learning.","We utilize the posterior information of the objective functions to adjust the parameters of the sampling distribution flexibly.","In this manner, the proposed method can sample preference vectors from the location of the Pareto front with a high probability.","Moreover, we design the distribution of the preference vector as a mixture of Dirichlet distributions to improve the performance of the model in disconnected Pareto fronts.","Extensive experiments validate the superiority of the proposed method compared with state-of-the-art algorithms."],"url":"http://arxiv.org/abs/2404.08397v1","category":"cs.LG"}
{"created":"2024-04-12 10:54:11","title":"NC-TTT: A Noise Contrastive Approach for Test-Time Training","abstract":"Despite their exceptional performance in vision tasks, deep learning models often struggle when faced with domain shifts during testing. Test-Time Training (TTT) methods have recently gained popularity by their ability to enhance the robustness of models through the addition of an auxiliary objective that is jointly optimized with the main task. Being strictly unsupervised, this auxiliary objective is used at test time to adapt the model without any access to labels. In this work, we propose Noise-Contrastive Test-Time Training (NC-TTT), a novel unsupervised TTT technique based on the discrimination of noisy feature maps. By learning to classify noisy views of projected feature maps, and then adapting the model accordingly on new domains, classification performance can be recovered by an important margin. Experiments on several popular test-time adaptation baselines demonstrate the advantages of our method compared to recent approaches for this task. The code can be found at:https://github.com/GustavoVargasHakim/NCTTT.git","sentences":["Despite their exceptional performance in vision tasks, deep learning models often struggle when faced with domain shifts during testing.","Test-Time Training (TTT) methods have recently gained popularity by their ability to enhance the robustness of models through the addition of an auxiliary objective that is jointly optimized with the main task.","Being strictly unsupervised, this auxiliary objective is used at test time to adapt the model without any access to labels.","In this work, we propose Noise-Contrastive Test-Time Training (NC-TTT), a novel unsupervised TTT technique based on the discrimination of noisy feature maps.","By learning to classify noisy views of projected feature maps, and then adapting the model accordingly on new domains, classification performance can be recovered by an important margin.","Experiments on several popular test-time adaptation baselines demonstrate the advantages of our method compared to recent approaches for this task.","The code can be found at:https://github.com/GustavoVargasHakim/NCTTT.git"],"url":"http://arxiv.org/abs/2404.08392v1","category":"cs.CV"}
{"created":"2024-04-12 10:17:41","title":"Polarisable soft solvent models with applications in dissipative particle dynamics","abstract":"We critically examine a broad class of explicitly polarisable soft solvent models aimed at applications in dissipative particle dynamics. We obtain the dielectric permittivity using the fluctuating box dipole method in linear response theory, and verify the models in relation to several test cases including demonstrating ion desorption from an oil-water interface due to image charge effects. We additionally compute the Kirkwood factor and find it uniformly lies in the range gK approx 0.7-0.8, indicating that dipole-dipole correlations are not negligible in these models. This is supported by measurements of dipole-dipole correlation functions. As a consequence, Onsager theory over-predicts the dielectric permittivity by approximately 20-30 percent. On the other hand, the mean square molecular dipole moment can be accurately estimated with a first-order Wertheim perturbation theory.","sentences":["We critically examine a broad class of explicitly polarisable soft solvent models aimed at applications in dissipative particle dynamics.","We obtain the dielectric permittivity using the fluctuating box dipole method in linear response theory, and verify the models in relation to several test cases including demonstrating ion desorption from an oil-water interface due to image charge effects.","We additionally compute the Kirkwood factor and find it uniformly lies in the range gK approx 0.7-0.8, indicating that dipole-dipole correlations are not negligible in these models.","This is supported by measurements of dipole-dipole correlation functions.","As a consequence, Onsager theory over-predicts the dielectric permittivity by approximately 20-30 percent.","On the other hand, the mean square molecular dipole moment can be accurately estimated with a first-order Wertheim perturbation theory."],"url":"http://arxiv.org/abs/2404.08373v1","category":"cond-mat.soft"}
{"created":"2024-04-12 09:22:24","title":"Learning to Rebalance Multi-Modal Optimization by Adaptively Masking Subnetworks","abstract":"Multi-modal learning aims to enhance performance by unifying models from various modalities but often faces the \"modality imbalance\" problem in real data, leading to a bias towards dominant modalities and neglecting others, thereby limiting its overall effectiveness. To address this challenge, the core idea is to balance the optimization of each modality to achieve a joint optimum. Existing approaches often employ a modal-level control mechanism for adjusting the update of each modal parameter. However, such a global-wise updating mechanism ignores the different importance of each parameter. Inspired by subnetwork optimization, we explore a uniform sampling-based optimization strategy and find it more effective than global-wise updating. According to the findings, we further propose a novel importance sampling-based, element-wise joint optimization method, called Adaptively Mask Subnetworks Considering Modal Significance(AMSS). Specifically, we incorporate mutual information rates to determine the modal significance and employ non-uniform adaptive sampling to select foreground subnetworks from each modality for parameter updates, thereby rebalancing multi-modal learning. Additionally, we demonstrate the reliability of the AMSS strategy through convergence analysis. Building upon theoretical insights, we further enhance the multi-modal mask subnetwork strategy using unbiased estimation, referred to as AMSS+. Extensive experiments reveal the superiority of our approach over comparison methods.","sentences":["Multi-modal learning aims to enhance performance by unifying models from various modalities but often faces the \"modality imbalance\" problem in real data, leading to a bias towards dominant modalities and neglecting others, thereby limiting its overall effectiveness.","To address this challenge, the core idea is to balance the optimization of each modality to achieve a joint optimum.","Existing approaches often employ a modal-level control mechanism for adjusting the update of each modal parameter.","However, such a global-wise updating mechanism ignores the different importance of each parameter.","Inspired by subnetwork optimization, we explore a uniform sampling-based optimization strategy and find it more effective than global-wise updating.","According to the findings, we further propose a novel importance sampling-based, element-wise joint optimization method, called Adaptively Mask Subnetworks Considering Modal Significance(AMSS).","Specifically, we incorporate mutual information rates to determine the modal significance and employ non-uniform adaptive sampling to select foreground subnetworks from each modality for parameter updates, thereby rebalancing multi-modal learning.","Additionally, we demonstrate the reliability of the AMSS strategy through convergence analysis.","Building upon theoretical insights, we further enhance the multi-modal mask subnetwork strategy using unbiased estimation, referred to as AMSS+.","Extensive experiments reveal the superiority of our approach over comparison methods."],"url":"http://arxiv.org/abs/2404.08347v1","category":"cs.CV"}
{"created":"2024-04-12 08:46:53","title":"Emerging Property of Masked Token for Effective Pre-training","abstract":"Driven by the success of Masked Language Modeling (MLM), the realm of self-supervised learning for computer vision has been invigorated by the central role of Masked Image Modeling (MIM) in driving recent breakthroughs. Notwithstanding the achievements of MIM across various downstream tasks, its overall efficiency is occasionally hampered by the lengthy duration of the pre-training phase. This paper presents a perspective that the optimization of masked tokens as a means of addressing the prevailing issue. Initially, we delve into an exploration of the inherent properties that a masked token ought to possess. Within the properties, we principally dedicated to articulating and emphasizing the `data singularity' attribute inherent in masked tokens. Through a comprehensive analysis of the heterogeneity between masked tokens and visible tokens within pre-trained models, we propose a novel approach termed masked token optimization (MTO), specifically designed to improve model efficiency through weight recalibration and the enhancement of the key property of masked tokens. The proposed method serves as an adaptable solution that seamlessly integrates into any MIM approach that leverages masked tokens. As a result, MTO achieves a considerable improvement in pre-training efficiency, resulting in an approximately 50% reduction in pre-training epochs required to attain converged performance of the recent approaches.","sentences":["Driven by the success of Masked Language Modeling (MLM), the realm of self-supervised learning for computer vision has been invigorated by the central role of Masked Image Modeling (MIM) in driving recent breakthroughs.","Notwithstanding the achievements of MIM across various downstream tasks, its overall efficiency is occasionally hampered by the lengthy duration of the pre-training phase.","This paper presents a perspective that the optimization of masked tokens as a means of addressing the prevailing issue.","Initially, we delve into an exploration of the inherent properties that a masked token ought to possess.","Within the properties, we principally dedicated to articulating and emphasizing the `data singularity' attribute inherent in masked tokens.","Through a comprehensive analysis of the heterogeneity between masked tokens and visible tokens within pre-trained models, we propose a novel approach termed masked token optimization (MTO), specifically designed to improve model efficiency through weight recalibration and the enhancement of the key property of masked tokens.","The proposed method serves as an adaptable solution that seamlessly integrates into any MIM approach that leverages masked tokens.","As a result, MTO achieves a considerable improvement in pre-training efficiency, resulting in an approximately 50% reduction in pre-training epochs required to attain converged performance of the recent approaches."],"url":"http://arxiv.org/abs/2404.08330v1","category":"cs.CV"}
{"created":"2024-04-12 08:38:51","title":"Salience-Based Adaptive Masking: Revisiting Token Dynamics for Enhanced Pre-training","abstract":"In this paper, we introduce Saliency-Based Adaptive Masking (SBAM), a novel and cost-effective approach that significantly enhances the pre-training performance of Masked Image Modeling (MIM) approaches by prioritizing token salience. Our method provides robustness against variations in masking ratios, effectively mitigating the performance instability issues common in existing methods. This relaxes the sensitivity of MIM-based pre-training to masking ratios, which in turn allows us to propose an adaptive strategy for `tailored' masking ratios for each data sample, which no existing method can provide. Toward this goal, we propose an Adaptive Masking Ratio (AMR) strategy that dynamically adjusts the proportion of masking for the unique content of each image based on token salience. We show that our method significantly improves over the state-of-the-art in mask-based pre-training on the ImageNet-1K dataset.","sentences":["In this paper, we introduce Saliency-Based Adaptive Masking (SBAM), a novel and cost-effective approach that significantly enhances the pre-training performance of Masked Image Modeling (MIM) approaches by prioritizing token salience.","Our method provides robustness against variations in masking ratios, effectively mitigating the performance instability issues common in existing methods.","This relaxes the sensitivity of MIM-based pre-training to masking ratios, which in turn allows us to propose an adaptive strategy for `tailored' masking ratios for each data sample, which no existing method can provide.","Toward this goal, we propose an Adaptive Masking Ratio (AMR) strategy that dynamically adjusts the proportion of masking for the unique content of each image based on token salience.","We show that our method significantly improves over the state-of-the-art in mask-based pre-training on the ImageNet-1K dataset."],"url":"http://arxiv.org/abs/2404.08327v1","category":"cs.CV"}
{"created":"2024-04-12 08:20:01","title":"Multi-Step Traffic Prediction for Multi-Period Planning in Optical Networks","abstract":"A multi-period planning framework is proposed that exploits multi-step ahead traffic predictions to address service overprovisioning and improve adaptability to traffic changes, while ensuring the necessary quality-of-service (QoS) levels. An encoder-decoder deep learning model is initially leveraged for multi-step ahead prediction by analyzing real-traffic traces. This information is then exploited by multi-period planning heuristics to efficiently utilize available network resources while minimizing undesired service disruptions (caused due to lightpath re-allocations), with these heuristics outperforming a single-step ahead prediction approach.","sentences":["A multi-period planning framework is proposed that exploits multi-step ahead traffic predictions to address service overprovisioning and improve adaptability to traffic changes, while ensuring the necessary quality-of-service (QoS) levels.","An encoder-decoder deep learning model is initially leveraged for multi-step ahead prediction by analyzing real-traffic traces.","This information is then exploited by multi-period planning heuristics to efficiently utilize available network resources while minimizing undesired service disruptions (caused due to lightpath re-allocations), with these heuristics outperforming a single-step ahead prediction approach."],"url":"http://arxiv.org/abs/2404.08314v1","category":"cs.NI"}
{"created":"2024-04-12 07:26:11","title":"Istanbul Flower Auction: The Need for Speed","abstract":"We examine the unique format of the Istanbul Flower Auction and compare it to traditional Dutch and English auctions, emphasizing the need to auction large volumes rapidly. In a model with time costs, we study how this auction format, which cleverly combines Dutch and English auction mechanisms, manages time costs by dynamically adapting to initial bidding behaviors. Our numerical analysis considers specific time cost functions and reveals the high performance of the Istanbul Flower Auction in comparison to standard auction formats, in terms of both auctioneer and bidder utilities. This work highlights the critical role of auction design in improving social welfare, particularly in scenarios demanding the quick sale of numerous lots.","sentences":["We examine the unique format of the Istanbul Flower Auction and compare it to traditional Dutch and English auctions, emphasizing the need to auction large volumes rapidly.","In a model with time costs, we study how this auction format, which cleverly combines Dutch and English auction mechanisms, manages time costs by dynamically adapting to initial bidding behaviors.","Our numerical analysis considers specific time cost functions and reveals the high performance of the Istanbul Flower Auction in comparison to standard auction formats, in terms of both auctioneer and bidder utilities.","This work highlights the critical role of auction design in improving social welfare, particularly in scenarios demanding the quick sale of numerous lots."],"url":"http://arxiv.org/abs/2404.08288v1","category":"econ.TH"}
{"created":"2024-04-12 17:47:18","title":"Classification of Boolean Algebras through von Neumann regular $\\mathcal{C}^{\\infty}-$Rings","abstract":"In this paper, we introduce the concept of a \"von Neumann regular $\\mathcal{C}^{\\infty}$-ring\", which is a model for a specific equational theory. We delve into the characteristics of these rings and demonstrate that each Boolean space can be effectively represented as the image of a von Neumann regular $\\mathcal{C}^{\\infty}$-ring through a specific functor. Additionally, we establish that every homomorphism between Boolean algebras can be expressed through a $\\mathcal{C}^{\\infty}$-ring homomorphism between von Neumann regular $\\mathcal{C}^{\\infty}$-rings.","sentences":["In this paper, we introduce the concept of a \"von Neumann regular $\\mathcal{C}^{\\infty}$-ring\", which is a model for a specific equational theory.","We delve into the characteristics of these rings and demonstrate that each Boolean space can be effectively represented as the image of a von Neumann regular $\\mathcal{C}^{\\infty}$-ring through a specific functor.","Additionally, we establish that every homomorphism between Boolean algebras can be expressed through a $\\mathcal{C}^{\\infty}$-ring homomorphism between von Neumann regular $\\mathcal{C}^{\\infty}$-rings."],"url":"http://arxiv.org/abs/2404.08629v1","category":"math.RA"}
{"created":"2024-04-12 17:37:42","title":"Regularized Gradient Clipping Provably Trains Wide and Deep Neural Networks","abstract":"In this work, we instantiate a regularized form of the gradient clipping algorithm and prove that it can converge to the global minima of deep neural network loss functions provided that the net is of sufficient width. We present empirical evidence that our theoretically founded regularized gradient clipping algorithm is also competitive with the state-of-the-art deep-learning heuristics. Hence the algorithm presented here constitutes a new approach to rigorous deep learning.   The modification we do to standard gradient clipping is designed to leverage the PL* condition, a variant of the Polyak-Lojasiewicz inequality which was recently proven to be true for various neural networks for any depth within a neighborhood of the initialisation.","sentences":["In this work, we instantiate a regularized form of the gradient clipping algorithm and prove that it can converge to the global minima of deep neural network loss functions provided that the net is of sufficient width.","We present empirical evidence that our theoretically founded regularized gradient clipping algorithm is also competitive with the state-of-the-art deep-learning heuristics.","Hence the algorithm presented here constitutes a new approach to rigorous deep learning.   ","The modification we do to standard gradient clipping is designed to leverage the PL* condition, a variant of the Polyak-Lojasiewicz inequality which was recently proven to be true for various neural networks for any depth within a neighborhood of the initialisation."],"url":"http://arxiv.org/abs/2404.08624v1","category":"cs.LG"}
{"created":"2024-04-12 17:13:50","title":"Learning-Based Joint Antenna Selection and Precoding Design for Cell-Free MIMO Networks","abstract":"This paper considers a downlink cell-free multiple-input multiple-output (MIMO) network in which multiple multi-antenna base stations (BSs) serve multiple users via coherent joint transmission. In order to reduce the energy consumption by radio frequency components, each BS selects a subset of antennas for downlink data transmission after estimating the channel state information (CSI). We aim to maximize the sum spectral efficiency by jointly optimizing the antenna selection and precoding design. To alleviate the fronthaul overhead and enable real-time network operation, we propose a distributed scalable machine learning algorithm. In particular, at each BS, we deploy a convolutional neural network (CNN) for antenna selection and a graph neural network (GNN) for precoding design. Different from conventional centralized solutions that require a large amount of CSI and signaling exchange among the BSs, the proposed distributed machine learning algorithm takes only locally estimated CSI as input. With well-trained learning models, it is shown that the proposed algorithm significantly outperforms the distributed baseline schemes and achieves a sum spectral efficiency comparable to its centralized counterpart.","sentences":["This paper considers a downlink cell-free multiple-input multiple-output (MIMO) network in which multiple multi-antenna base stations (BSs) serve multiple users via coherent joint transmission.","In order to reduce the energy consumption by radio frequency components, each BS selects a subset of antennas for downlink data transmission after estimating the channel state information (CSI).","We aim to maximize the sum spectral efficiency by jointly optimizing the antenna selection and precoding design.","To alleviate the fronthaul overhead and enable real-time network operation, we propose a distributed scalable machine learning algorithm.","In particular, at each BS, we deploy a convolutional neural network (CNN) for antenna selection and a graph neural network (GNN) for precoding design.","Different from conventional centralized solutions that require a large amount of CSI and signaling exchange among the BSs, the proposed distributed machine learning algorithm takes only locally estimated CSI as input.","With well-trained learning models, it is shown that the proposed algorithm significantly outperforms the distributed baseline schemes and achieves a sum spectral efficiency comparable to its centralized counterpart."],"url":"http://arxiv.org/abs/2404.08607v1","category":"cs.IT"}
{"created":"2024-04-12 17:08:27","title":"Quantum Iterative Methods for Solving Differential Equations with Application to Computational Fluid Dynamics","abstract":"We propose quantum methods for solving differential equations that are based on a gradual improvement of the solution via an iterative process, and are targeted at applications in fluid dynamics. First, we implement the Jacobi iteration on a quantum register that utilizes a linear combination of unitaries (LCU) approach to store the trajectory information. Second, we extend quantum methods to Gauss-Seidel iterative methods. Additionally, we propose a quantum-suitable resolvent decomposition based on the Woodbury identity. From a technical perspective, we develop and utilize tools for the block encoding of specific matrices as well as their multiplication. We benchmark the approach on paradigmatic fluid dynamics problems. Our results stress that instead of inverting large matrices, one can program quantum computers to perform multigrid-type computations and leverage corresponding advances in scientific computing.","sentences":["We propose quantum methods for solving differential equations that are based on a gradual improvement of the solution via an iterative process, and are targeted at applications in fluid dynamics.","First, we implement the Jacobi iteration on a quantum register that utilizes a linear combination of unitaries (LCU) approach to store the trajectory information.","Second, we extend quantum methods to Gauss-Seidel iterative methods.","Additionally, we propose a quantum-suitable resolvent decomposition based on the Woodbury identity.","From a technical perspective, we develop and utilize tools for the block encoding of specific matrices as well as their multiplication.","We benchmark the approach on paradigmatic fluid dynamics problems.","Our results stress that instead of inverting large matrices, one can program quantum computers to perform multigrid-type computations and leverage corresponding advances in scientific computing."],"url":"http://arxiv.org/abs/2404.08605v1","category":"quant-ph"}
{"created":"2024-04-12 17:01:25","title":"Sliding down the stairs: how correlated latent variables accelerate learning with neural networks","abstract":"Neural networks extract features from data using stochastic gradient descent (SGD). In particular, higher-order input cumulants (HOCs) are crucial for their performance. However, extracting information from the $p$th cumulant of $d$-dimensional inputs is computationally hard: the number of samples required to recover a single direction from an order-$p$ tensor (tensor PCA) using online SGD grows as $d^{p-1}$, which is prohibitive for high-dimensional inputs. This result raises the question of how neural networks extract relevant directions from the HOCs of their inputs efficiently. Here, we show that correlations between latent variables along the directions encoded in different input cumulants speed up learning from higher-order correlations. We show this effect analytically by deriving nearly sharp thresholds for the number of samples required by a single neuron to weakly-recover these directions using online SGD from a random start in high dimensions. Our analytical results are confirmed in simulations of two-layer neural networks and unveil a new mechanism for hierarchical learning in neural networks.","sentences":["Neural networks extract features from data using stochastic gradient descent (SGD).","In particular, higher-order input cumulants (HOCs) are crucial for their performance.","However, extracting information from the $p$th cumulant of $d$-dimensional inputs is computationally hard: the number of samples required to recover a single direction from an order-$p$ tensor (tensor PCA) using online SGD grows as $d^{p-1}$, which is prohibitive for high-dimensional inputs.","This result raises the question of how neural networks extract relevant directions from the HOCs of their inputs efficiently.","Here, we show that correlations between latent variables along the directions encoded in different input cumulants speed up learning from higher-order correlations.","We show this effect analytically by deriving nearly sharp thresholds for the number of samples required by a single neuron to weakly-recover these directions using online SGD from a random start in high dimensions.","Our analytical results are confirmed in simulations of two-layer neural networks and unveil a new mechanism for hierarchical learning in neural networks."],"url":"http://arxiv.org/abs/2404.08602v1","category":"stat.ML"}
{"created":"2024-04-12 16:43:00","title":"Closed $p$-Elastic Curves in Spheres of $\\mathbb{L}^3$","abstract":"For every $p\\in\\mathbb{R}$, we study $p$-elastic curves in the hyperbolic plane $\\mathbb{H}^2$ and in the de Sitter $2$-space $\\mathbb{H}_1^2$. We analyze the existence of closed $p$-elastic curves with nonconstant curvature showing that in the hyperbolic plane $\\mathbb{H}^2$ these curves exist provided that $p>1$, while in the de Sitter $2$-space $\\mathbb{H}_1^2$ the restriction $p<0$ must be satisfied.","sentences":["For every $p\\in\\mathbb{R}$, we study $p$-elastic curves in the hyperbolic plane $\\mathbb{H}^2$ and in the de Sitter $2$-space $\\mathbb{H}_1^2$.","We analyze the existence of closed $p$-elastic curves with nonconstant curvature showing that in the hyperbolic plane $\\mathbb{H}^2$ these curves exist provided that $p>1$, while in the de Sitter $2$-space $\\mathbb{H}_1^2$ the restriction $p<0$ must be satisfied."],"url":"http://arxiv.org/abs/2404.08593v1","category":"math.DG"}
{"created":"2024-04-12 15:46:42","title":"Differentiation of resultants and common roots of pairs of polynomials","abstract":"The well-known mathematical instrument for detection common roots for pairs of polynomials and multiple roots of polynomials are resultants and discriminants. For a pair of polynomials $f$ and $g$ their resultant $R(f,g)$ is a function of their coefficients. Zeros of resultant $R(f,g)$ correspond to the families of coefficients of $f$ and $g$ such that $f$ and $g$ have a common root. Herewith the calculation of this common root is a separate problem.   The principal results on calculation of a unique common root of two polynomials and also about calculating a unique root of multiplicity 2 of a polynomial in terms of the first order partial derivatives of resultants and discriminants are given in the monograph by I.M. Gelfand, M.M. Kapranov, A.V. Zelevinsky [1, Ch. 3, Ch. 12]. A significant development of the ideas of this book in the direction of searching for formulas for multiple roots of polynomials is presented in the paper by I.A. Antipova, E.N. Mikhalkin, A.K. Tsikh [2]. The key result of this article is [2, Theorem 1] where the expression for a unique root of multiplicity $s \\geq 3$ in terms of the first order partial derivatives of resultant of the polynomial and it's derivative of order $s-1$.   In the present article the explicit formulas for higher derivatives of resultants of pairs of polynomials possessing common roots are obtained. On this basis a series of results that differ in ideas from [2, Theorem 1] linking higher derivatives of resultants and common multiple roots are proven. In addition the results obtained are applied for a new transparent proof of a refinement of [2, Theorem 1].","sentences":["The well-known mathematical instrument for detection common roots for pairs of polynomials and multiple roots of polynomials are resultants and discriminants.","For a pair of polynomials $f$ and $g$ their resultant $R(f,g)$ is a function of their coefficients.","Zeros of resultant $R(f,g)$ correspond to the families of coefficients of $f$ and $g$ such that $f$ and $g$ have a common root.","Herewith the calculation of this common root is a separate problem.   ","The principal results on calculation of a unique common root of two polynomials and also about calculating a unique root of multiplicity 2 of a polynomial in terms of the first order partial derivatives of resultants and discriminants are given in the monograph by I.M. Gelfand, M.M. Kapranov,","A.V. Zelevinsky","[1, Ch. 3, Ch. 12].","A significant development of the ideas of this book in the direction of searching for formulas for multiple roots of polynomials is presented in the paper by I.A. Antipova, E.N. Mikhalkin, A.K. Tsikh [2].","The key result of this article is [2, Theorem 1] where the expression for a unique root of multiplicity $s \\geq 3$ in terms of the first order partial derivatives of resultant of the polynomial and it's derivative of order $s-1$.   In the present article the explicit formulas for higher derivatives of resultants of pairs of polynomials possessing common roots are obtained.","On this basis a series of results that differ in ideas from [2, Theorem 1] linking higher derivatives of resultants and common multiple roots are proven.","In addition the results obtained are applied for a new transparent proof of a refinement of [2, Theorem 1]."],"url":"http://arxiv.org/abs/2404.08550v1","category":"math.CA"}
{"created":"2024-04-12 15:39:41","title":"Three circles theorems and Liouville type theorems","abstract":"We establish three circles theorems for subharmonic functions on Riemannian manifolds with nonnegative Ricci curvature, as well as on gradient shrinking Ricci solitons with scalar curvature bounded from below by $\\frac{n-2}{2}$. We also establish a three circiles theorem for holomorphic functions on gradient shrinking K\\\"{a}hler-Ricci solitons with some curvature conditions. As applications, we prove some Liouville type theorems.","sentences":["We establish three circles theorems for subharmonic functions on Riemannian manifolds with nonnegative Ricci curvature, as well as on gradient shrinking Ricci solitons with scalar curvature bounded from below by $\\frac{n-2}{2}$. We also establish a three circiles theorem for holomorphic functions on gradient shrinking K\\\"{a}hler-Ricci solitons with some curvature conditions.","As applications, we prove some Liouville type theorems."],"url":"http://arxiv.org/abs/2404.08546v1","category":"math.DG"}
{"created":"2024-04-12 15:35:30","title":"Existence of monotone Morse flow lines of the expander functional","abstract":"Given a smooth asymptotically conical self-expander that is strictly unstable we construct a (singular) Morse flow line of the expander functional that connects it to a stable self-expander. This flow is monotone in a suitable sense and has small singular set.","sentences":["Given a smooth asymptotically conical self-expander that is strictly unstable we construct a (singular) Morse flow line of the expander functional that connects it to a stable self-expander.","This flow is monotone in a suitable sense and has small singular set."],"url":"http://arxiv.org/abs/2404.08541v1","category":"math.DG"}
{"created":"2024-04-12 15:30:15","title":"On a coarse invertibility spectrum for coarse groups","abstract":"We introduce a coarse algebraic invariant for coarse groups and use it to differentiate various coarsifications of the group of integers. This lets us answer two questions posed by Leitner and the second author. The invariant is obtained by considering the set of exponents n such that taking n-th powers defines a coarse equivalence of the coarse group.","sentences":["We introduce a coarse algebraic invariant for coarse groups and use it to differentiate various coarsifications of the group of integers.","This lets us answer two questions posed by Leitner and the second author.","The invariant is obtained by considering the set of exponents n such that taking n-th powers defines a coarse equivalence of the coarse group."],"url":"http://arxiv.org/abs/2404.08536v1","category":"math.GR"}
{"created":"2024-04-12 14:31:35","title":"Twisted correlations of the divisor function via discrete averages of $\\operatorname{SL}_2(\\mathbb{R})$ Poincar\u00e9 series","abstract":"We prove a theorem that allows one to count solutions to determinant equations twisted by a periodic weight with high uniformity in the modulus. It is obtained by using spectral methods of $\\operatorname{SL}_2(\\mathbb{R})$ automorphic forms to study Poincar\\'e series over congruence subgroups while keeping track of interactions between multiple orbits. In this way we get advantages over the widely used sums of Kloosterman sums techniques. We showcase the method with applications to correlations of the divisor functions twisted by periodic functions and the fourth moment of Dirichlet $L$-functions on the critical line.","sentences":["We prove a theorem that allows one to count solutions to determinant equations twisted by a periodic weight with high uniformity in the modulus.","It is obtained by using spectral methods of $\\operatorname{SL}_2(\\mathbb{R})$ automorphic forms to study Poincar\\'e series over congruence subgroups while keeping track of interactions between multiple orbits.","In this way we get advantages over the widely used sums of Kloosterman sums techniques.","We showcase the method with applications to correlations of the divisor functions twisted by periodic functions and the fourth moment of Dirichlet $L$-functions on the critical line."],"url":"http://arxiv.org/abs/2404.08502v1","category":"math.NT"}
{"created":"2024-04-12 14:12:03","title":"SpectralMamba: Efficient Mamba for Hyperspectral Image Classification","abstract":"Recurrent neural networks and Transformers have recently dominated most applications in hyperspectral (HS) imaging, owing to their capability to capture long-range dependencies from spectrum sequences. However, despite the success of these sequential architectures, the non-ignorable inefficiency caused by either difficulty in parallelization or computationally prohibitive attention still hinders their practicality, especially for large-scale observation in remote sensing scenarios. To address this issue, we herein propose SpectralMamba -- a novel state space model incorporated efficient deep learning framework for HS image classification. SpectralMamba features the simplified but adequate modeling of HS data dynamics at two levels. First, in spatial-spectral space, a dynamical mask is learned by efficient convolutions to simultaneously encode spatial regularity and spectral peculiarity, thus attenuating the spectral variability and confusion in discriminative representation learning. Second, the merged spectrum can then be efficiently operated in the hidden state space with all parameters learned input-dependent, yielding selectively focused responses without reliance on redundant attention or imparallelizable recurrence. To explore the room for further computational downsizing, a piece-wise scanning mechanism is employed in-between, transferring approximately continuous spectrum into sequences with squeezed length while maintaining short- and long-term contextual profiles among hundreds of bands. Through extensive experiments on four benchmark HS datasets acquired by satellite-, aircraft-, and UAV-borne imagers, SpectralMamba surprisingly creates promising win-wins from both performance and efficiency perspectives.","sentences":["Recurrent neural networks and Transformers have recently dominated most applications in hyperspectral (HS) imaging, owing to their capability to capture long-range dependencies from spectrum sequences.","However, despite the success of these sequential architectures, the non-ignorable inefficiency caused by either difficulty in parallelization or computationally prohibitive attention still hinders their practicality, especially for large-scale observation in remote sensing scenarios.","To address this issue, we herein propose SpectralMamba -- a novel state space model incorporated efficient deep learning framework for HS image classification.","SpectralMamba features the simplified but adequate modeling of HS data dynamics at two levels.","First, in spatial-spectral space, a dynamical mask is learned by efficient convolutions to simultaneously encode spatial regularity and spectral peculiarity, thus attenuating the spectral variability and confusion in discriminative representation learning.","Second, the merged spectrum can then be efficiently operated in the hidden state space with all parameters learned input-dependent, yielding selectively focused responses without reliance on redundant attention or imparallelizable recurrence.","To explore the room for further computational downsizing, a piece-wise scanning mechanism is employed in-between, transferring approximately continuous spectrum into sequences with squeezed length while maintaining short- and long-term contextual profiles among hundreds of bands.","Through extensive experiments on four benchmark HS datasets acquired by satellite-, aircraft-, and UAV-borne imagers, SpectralMamba surprisingly creates promising win-wins from both performance and efficiency perspectives."],"url":"http://arxiv.org/abs/2404.08489v1","category":"cs.CV"}
{"created":"2024-04-12 13:29:23","title":"A different perspective on the Landau-Zener dynamics","abstract":"We present two different approaches towards the Landau-Zener problem: (i) The Markov approximation in the integro-differential equation for one of the two probability amplitudes, and (ii) an amplitude-and-phase analysis of the linear second order differential equation for same probability amplitude. Our treatment shows that the Markov approximation neglects the non-linearity of the equation but still provides us with the exact asymptotic result.","sentences":["We present two different approaches towards the Landau-Zener problem: (i) The Markov approximation in the integro-differential equation for one of the two probability amplitudes, and (ii) an amplitude-and-phase analysis of the linear second order differential equation for same probability amplitude.","Our treatment shows that the Markov approximation neglects the non-linearity of the equation but still provides us with the exact asymptotic result."],"url":"http://arxiv.org/abs/2404.08466v1","category":"quant-ph"}
{"created":"2024-04-12 13:24:32","title":"A stable decoupled perfectly matched layer for the 3D wave equation using the nodal discontinuous Galerkin method","abstract":"In outdoor acoustics, the calculations of sound propagating in air can be computationally heavy if the domain is chosen large enough to fulfil the Sommerfeld radiation condition. By strategically truncating the computational domain with a efficient boundary treatment, the computational cost is lowered. One commonly used boundary treatment is the perfectly matched layer (PML) that dampens outgoing waves without polluting the computed solution in the inner domain. The purpose of this study is to propose and assess a new perfectly matched layer formulation for the 3D acoustic wave equation, using the nodal discontinuous Galerkin finite element method. The formulation is based on an efficient PML formulation that can be decoupled to further increase the computational efficiency and guarantee stability without sacrificing accuracy. This decoupled PML formulation is demonstrated to be long-time stable and an optimization procedure of the damping functions is proposed to enhance the performance of the formulation.","sentences":["In outdoor acoustics, the calculations of sound propagating in air can be computationally heavy if the domain is chosen large enough to fulfil the Sommerfeld radiation condition.","By strategically truncating the computational domain with a efficient boundary treatment, the computational cost is lowered.","One commonly used boundary treatment is the perfectly matched layer (PML) that dampens outgoing waves without polluting the computed solution in the inner domain.","The purpose of this study is to propose and assess a new perfectly matched layer formulation for the 3D acoustic wave equation, using the nodal discontinuous Galerkin finite element method.","The formulation is based on an efficient PML formulation that can be decoupled to further increase the computational efficiency and guarantee stability without sacrificing accuracy.","This decoupled PML formulation is demonstrated to be long-time stable and an optimization procedure of the damping functions is proposed to enhance the performance of the formulation."],"url":"http://arxiv.org/abs/2404.08464v1","category":"math.NA"}
{"created":"2024-04-12 12:43:08","title":"Role of Noise in the Fairen-Velarde model of bacterial respiration","abstract":"Following our recent study (Kundu and Acharyya, Int. J. Mod. Phys. C (2024) 2450094), we have introduced stochasticity (random noise) in the Fairen-Velarde deterministic differential equations. The role of such noise on time scales is studied. The probability of reaching the domain of fixed points in a given interval is also calculated. The probability is studied as a function of the width of the noise, and a hyperbolic tangent fitting is proposed. The noise reduces the time scale for bringing the bacteria into an inactive state. The area of the fixed-point domain was found to be asympotically linear with noise. The time to reach the fixed-point domain is fitted to a Gaussian with noise intensity.","sentences":["Following our recent study (Kundu and Acharyya, Int.","J. Mod.","Phys. C (2024) 2450094), we have introduced stochasticity (random noise) in the Fairen-Velarde deterministic differential equations.","The role of such noise on time scales is studied.","The probability of reaching the domain of fixed points in a given interval is also calculated.","The probability is studied as a function of the width of the noise, and a hyperbolic tangent fitting is proposed.","The noise reduces the time scale for bringing the bacteria into an inactive state.","The area of the fixed-point domain was found to be asympotically linear with noise.","The time to reach the fixed-point domain is fitted to a Gaussian with noise intensity."],"url":"http://arxiv.org/abs/2404.08437v1","category":"q-bio.QM"}
{"created":"2024-04-12 12:08:58","title":"Global Large Solution to Navier-Stokes and SQG Equations with Time Oscillation","abstract":"In this paper, we consider the model of 3D incompressible Navier-Stokes equations and 2D supercritical Surface Quasi-Geostrophic equations with time oscillation in the nonlinear term. We obtain that there exists global smooth solution of these two equations for any initial data $u_0\\in H^2$.","sentences":["In this paper, we consider the model of 3D incompressible Navier-Stokes equations and 2D supercritical Surface Quasi-Geostrophic equations with time oscillation in the nonlinear term.","We obtain that there exists global smooth solution of these two equations for any initial data $u_0\\in H^2$."],"url":"http://arxiv.org/abs/2404.08420v1","category":"math.AP"}
{"created":"2024-04-12 11:44:03","title":"On weak inverse mean curvature flow and Minkowski-type inequalities in hyperbolic space","abstract":"We prove that a proper weak solution $\\{ \\Omega_{t} \\}_{0 \\leq t < \\infty}$ to inverse mean curvature flow in $\\mathbb{H}^{n}$, $3\\leq n \\leq 7$, is smooth and star-shaped by the time   \\begin{equation*}   T= (n-1) \\log \\left( \\frac{\\text{sinh} \\left( r_{+} \\right)}{ \\text{sinh} \\left( r_{-} \\right)} \\right), \\end{equation*} where $r_{+}$ and $r_{-}$ are the geodesic out-radius and in-radius of the initial domain $\\Omega_{0}$. The argument is inspired by the Alexandrov reflection method for extrinsic curvature flows in $\\mathbb{R}^{n}$ due to Chow-Gulliver and uses a result of Li-Wei.   As applications, we extend the Minkowski inequalities of Brendle-Hung-Wang and De Lima-Girao to outer-minimizing domains $\\Omega_{0} \\subset \\mathbb{H}^{n}$ in these dimensions. From this, we also extend the asymptotically hyperbolic Riemannian Penrose inequality to balanced asymptotically hyperbolic graphs over the exteriors of outer-minimizing domains of $\\mathbb{H}^{n}$, $3 \\leq n \\leq 7$.","sentences":["We prove that a proper weak solution $\\{ \\Omega_{t} \\}_{0 \\leq t <","\\infty}$ to inverse mean curvature flow in $\\mathbb{H}^{n}$, $3\\leq n \\leq 7$, is smooth and star-shaped by the time   \\begin{equation*}   T= (n-1) \\log \\left( \\frac{\\text{sinh} \\left( r_{+} \\right)}{ \\text{sinh} \\left( r_{-} \\right)} \\right), \\end{equation*} where $r_{+}$ and $r_{-}$ are the geodesic out-radius and in-radius of the initial domain $\\Omega_{0}$. The argument is inspired by the Alexandrov reflection method for extrinsic curvature flows in $\\mathbb{R}^{n}$ due to Chow-Gulliver and uses a result of Li-Wei.   ","As applications, we extend the Minkowski inequalities of Brendle-Hung-Wang and De Lima-Girao to outer-minimizing domains $\\Omega_{0} \\subset \\mathbb{H}^{n}$ in these dimensions.","From this, we also extend the asymptotically hyperbolic Riemannian Penrose inequality to balanced asymptotically hyperbolic graphs over the exteriors of outer-minimizing domains of $\\mathbb{H}^{n}$, $3 \\leq n \\leq 7$."],"url":"http://arxiv.org/abs/2404.08410v1","category":"math.DG"}
{"created":"2024-04-12 11:34:20","title":"Wild solutions of the 3D axisymmetric Euler equations","abstract":"We consider the Cauchy problem for the 3D incompressible axisymmetric swirl-free Euler equations. The convex integration method developed by De Lellis and Sz\\'ekelyhidi rules out the possibility that the Euler equations admit unique admissible weak solutions. It had remained conceivable, though, that axisymmetry of the solution might serve as a selection criterion. Using a surprising link to the 2D isentropic compressible Euler equations, we will show that this is not the case: There exists initial data for which there are infinetely many admissible swirl-free axisymmetric weak solutions of the 3D incompressible Euler equations. Moreover, somewhat conversely, we show that there exists an axisymmetric swirl-free initial velocity for which the axisymmetry breaks down instantaneously.","sentences":["We consider the Cauchy problem for the 3D incompressible axisymmetric swirl-free Euler equations.","The convex integration method developed by De Lellis and Sz\\'ekelyhidi rules out the possibility that the Euler equations admit unique admissible weak solutions.","It had remained conceivable, though, that axisymmetry of the solution might serve as a selection criterion.","Using a surprising link to the 2D isentropic compressible Euler equations, we will show that this is not the case: There exists initial data for which there are infinetely many admissible swirl-free axisymmetric weak solutions of the 3D incompressible Euler equations.","Moreover, somewhat conversely, we show that there exists an axisymmetric swirl-free initial velocity for which the axisymmetry breaks down instantaneously."],"url":"http://arxiv.org/abs/2404.08407v1","category":"math.AP"}
{"created":"2024-04-12 10:04:03","title":"Let It Flow: Simultaneous Optimization of 3D Flow and Object Clustering","abstract":"We study the problem of self-supervised 3D scene flow estimation from real large-scale raw point cloud sequences, which is crucial to various tasks like trajectory prediction or instance segmentation. In the absence of ground truth scene flow labels, contemporary approaches concentrate on deducing optimizing flow across sequential pairs of point clouds by incorporating structure based regularization on flow and object rigidity. The rigid objects are estimated by a variety of 3D spatial clustering methods. While state-of-the-art methods successfully capture overall scene motion using the Neural Prior structure, they encounter challenges in discerning multi-object motions. We identified the structural constraints and the use of large and strict rigid clusters as the main pitfall of the current approaches and we propose a novel clustering approach that allows for combination of overlapping soft clusters as well as non-overlapping rigid clusters representation. Flow is then jointly estimated with progressively growing non-overlapping rigid clusters together with fixed size overlapping soft clusters. We evaluate our method on multiple datasets with LiDAR point clouds, demonstrating the superior performance over the self-supervised baselines reaching new state of the art results. Our method especially excels in resolving flow in complicated dynamic scenes with multiple independently moving objects close to each other which includes pedestrians, cyclists and other vulnerable road users. Our codes will be publicly available.","sentences":["We study the problem of self-supervised 3D scene flow estimation from real large-scale raw point cloud sequences, which is crucial to various tasks like trajectory prediction or instance segmentation.","In the absence of ground truth scene flow labels, contemporary approaches concentrate on deducing optimizing flow across sequential pairs of point clouds by incorporating structure based regularization on flow and object rigidity.","The rigid objects are estimated by a variety of 3D spatial clustering methods.","While state-of-the-art methods successfully capture overall scene motion using the Neural Prior structure, they encounter challenges in discerning multi-object motions.","We identified the structural constraints and the use of large and strict rigid clusters as the main pitfall of the current approaches and we propose a novel clustering approach that allows for combination of overlapping soft clusters as well as non-overlapping rigid clusters representation.","Flow is then jointly estimated with progressively growing non-overlapping rigid clusters together with fixed size overlapping soft clusters.","We evaluate our method on multiple datasets with LiDAR point clouds, demonstrating the superior performance over the self-supervised baselines reaching new state of the art results.","Our method especially excels in resolving flow in complicated dynamic scenes with multiple independently moving objects close to each other which includes pedestrians, cyclists and other vulnerable road users.","Our codes will be publicly available."],"url":"http://arxiv.org/abs/2404.08363v1","category":"cs.CV"}
{"created":"2024-04-12 09:30:04","title":"On some relations between the Perimeter, the Area and the Visual Angle of a Convex Set","abstract":"We establish some relations between the perimeter, the area and the visual angle of a planar compact convex set. Our first result states that Crofton's formula is the unique universal formula relating the visual angle, length and area. After that we give a characterization of convex sets of constant width by means of the behaviour of its isotopic sets at infinity. Also for this class of convex sets we prove that the existence of an isotopic circle is enough to ensure that the considered set is a disc.","sentences":["We establish some relations between the perimeter, the area and the visual angle of a planar compact convex set.","Our first result states that Crofton's formula is the unique universal formula relating the visual angle, length and area.","After that we give a characterization of convex sets of constant width by means of the behaviour of its isotopic sets at infinity.","Also for this class of convex sets we prove that the existence of an isotopic circle is enough to ensure that the considered set is a disc."],"url":"http://arxiv.org/abs/2404.08349v1","category":"math.DG"}
{"created":"2024-04-12 09:21:29","title":"FastSpell: the LangId Magic Spell","abstract":"Language identification is a crucial component in the automated production of language resources, particularly in multilingual and big data contexts. However, commonly used language identifiers struggle to differentiate between similar or closely-related languages. This paper introduces FastSpell, a language identifier that combines fastText (a pre-trained language identifier tool) and Hunspell (a spell checker) with the aim of having a refined second-opinion before deciding which language should be assigned to a text. We provide a description of the FastSpell algorithm along with an explanation on how to use and configure it. To that end, we motivate the need of such a tool and present a benchmark including some popular language identifiers evaluated during the development of FastSpell. We show how FastSpell is useful not only to improve identification of similar languages, but also to identify new ones ignored by other tools.","sentences":["Language identification is a crucial component in the automated production of language resources, particularly in multilingual and big data contexts.","However, commonly used language identifiers struggle to differentiate between similar or closely-related languages.","This paper introduces FastSpell, a language identifier that combines fastText (a pre-trained language identifier tool) and Hunspell (a spell checker) with the aim of having a refined second-opinion before deciding which language should be assigned to a text.","We provide a description of the FastSpell algorithm along with an explanation on how to use and configure it.","To that end, we motivate the need of such a tool and present a benchmark including some popular language identifiers evaluated during the development of FastSpell.","We show how FastSpell is useful not only to improve identification of similar languages, but also to identify new ones ignored by other tools."],"url":"http://arxiv.org/abs/2404.08345v1","category":"cs.CL"}
{"created":"2024-04-12 08:46:39","title":"The Higgs Mechanism with Diagrams: a didactic approach","abstract":"We present a pedagogical treatment of the electroweak Higgs mechanism based solely on Feynman diagrams and S-matrix elements, without recourse to (gauge) symmetry arguments. Throughout, the emphasis is on Feynman rules and the Schwinger-Dyson equations; it is pointed out that particular care is needed in the treatment of tadpole diagrams and their symmetry factors.","sentences":["We present a pedagogical treatment of the electroweak Higgs mechanism based solely on Feynman diagrams and S-matrix elements, without recourse to (gauge) symmetry arguments.","Throughout, the emphasis is on Feynman rules and the Schwinger-Dyson equations; it is pointed out that particular care is needed in the treatment of tadpole diagrams and their symmetry factors."],"url":"http://arxiv.org/abs/2404.08329v1","category":"hep-ph"}
{"created":"2024-04-12 07:08:05","title":"Convolutional neural network classification of cancer cytopathology images: taking breast cancer as an example","abstract":"Breast cancer is a relatively common cancer among gynecological cancers. Its diagnosis often relies on the pathology of cells in the lesion. The pathological diagnosis of breast cancer not only requires professionals and time, but also sometimes involves subjective judgment. To address the challenges of dependence on pathologists expertise and the time-consuming nature of achieving accurate breast pathological image classification, this paper introduces an approach utilizing convolutional neural networks (CNNs) for the rapid categorization of pathological images, aiming to enhance the efficiency of breast pathological image detection. And the approach enables the rapid and automatic classification of pathological images into benign and malignant groups. The methodology involves utilizing a convolutional neural network (CNN) model leveraging the Inceptionv3 architecture and transfer learning algorithm for extracting features from pathological images. Utilizing a neural network with fully connected layers and employing the SoftMax function for image classification. Additionally, the concept of image partitioning is introduced to handle high-resolution images. To achieve the ultimate classification outcome, the classification probabilities of each image block are aggregated using three algorithms: summation, product, and maximum. Experimental validation was conducted on the BreaKHis public dataset, resulting in accuracy rates surpassing 0.92 across all four magnification coefficients (40X, 100X, 200X, and 400X). It demonstrates that the proposed method effectively enhances the accuracy in classifying pathological images of breast cancer.","sentences":["Breast cancer is a relatively common cancer among gynecological cancers.","Its diagnosis often relies on the pathology of cells in the lesion.","The pathological diagnosis of breast cancer not only requires professionals and time, but also sometimes involves subjective judgment.","To address the challenges of dependence on pathologists expertise and the time-consuming nature of achieving accurate breast pathological image classification, this paper introduces an approach utilizing convolutional neural networks (CNNs) for the rapid categorization of pathological images, aiming to enhance the efficiency of breast pathological image detection.","And the approach enables the rapid and automatic classification of pathological images into benign and malignant groups.","The methodology involves utilizing a convolutional neural network (CNN) model leveraging the Inceptionv3 architecture and transfer learning algorithm for extracting features from pathological images.","Utilizing a neural network with fully connected layers and employing the SoftMax function for image classification.","Additionally, the concept of image partitioning is introduced to handle high-resolution images.","To achieve the ultimate classification outcome, the classification probabilities of each image block are aggregated using three algorithms: summation, product, and maximum.","Experimental validation was conducted on the BreaKHis public dataset, resulting in accuracy rates surpassing 0.92 across all four magnification coefficients (40X, 100X, 200X, and 400X).","It demonstrates that the proposed method effectively enhances the accuracy in classifying pathological images of breast cancer."],"url":"http://arxiv.org/abs/2404.08279v1","category":"eess.IV"}
{"created":"2024-04-12 06:18:25","title":"QI-DPFL: Quality-Aware and Incentive-Boosted Federated Learning with Differential Privacy","abstract":"Federated Learning (FL) has increasingly been recognized as an innovative and secure distributed model training paradigm, aiming to coordinate multiple edge clients to collaboratively train a shared model without uploading their private datasets. The challenge of encouraging mobile edge devices to participate zealously in FL model training procedures, while mitigating the privacy leakage risks during wireless transmission, remains comparatively unexplored so far. In this paper, we propose a novel approach, named QI-DPFL (Quality-Aware and Incentive-Boosted Federated Learning with Differential Privacy), to address the aforementioned intractable issue. To select clients with high-quality datasets, we first propose a quality-aware client selection mechanism based on the Earth Mover's Distance (EMD) metric. Furthermore, to attract high-quality data contributors, we design an incentive-boosted mechanism that constructs the interactions between the central server and the selected clients as a two-stage Stackelberg game, where the central server designs the time-dependent reward to minimize its cost by considering the trade-off between accuracy loss and total reward allocated, and each selected client decides the privacy budget to maximize its utility. The Nash Equilibrium of the Stackelberg game is derived to find the optimal solution in each global iteration. The extensive experimental results on different real-world datasets demonstrate the effectiveness of our proposed FL framework, by realizing the goal of privacy protection and incentive compatibility.","sentences":["Federated Learning (FL) has increasingly been recognized as an innovative and secure distributed model training paradigm, aiming to coordinate multiple edge clients to collaboratively train a shared model without uploading their private datasets.","The challenge of encouraging mobile edge devices to participate zealously in FL model training procedures, while mitigating the privacy leakage risks during wireless transmission, remains comparatively unexplored so far.","In this paper, we propose a novel approach, named QI-DPFL (Quality-Aware and Incentive-Boosted Federated Learning with Differential Privacy), to address the aforementioned intractable issue.","To select clients with high-quality datasets, we first propose a quality-aware client selection mechanism based on the Earth Mover's Distance (EMD) metric.","Furthermore, to attract high-quality data contributors, we design an incentive-boosted mechanism that constructs the interactions between the central server and the selected clients as a two-stage Stackelberg game, where the central server designs the time-dependent reward to minimize its cost by considering the trade-off between accuracy loss and total reward allocated, and each selected client decides the privacy budget to maximize its utility.","The Nash Equilibrium of the Stackelberg game is derived to find the optimal solution in each global iteration.","The extensive experimental results on different real-world datasets demonstrate the effectiveness of our proposed FL framework, by realizing the goal of privacy protection and incentive compatibility."],"url":"http://arxiv.org/abs/2404.08261v1","category":"cs.GT"}
{"created":"2024-04-12 05:43:10","title":"MonoPatchNeRF: Improving Neural Radiance Fields with Patch-based Monocular Guidance","abstract":"The latest regularized Neural Radiance Field (NeRF) approaches produce poor geometry and view extrapolation for multiview stereo (MVS) benchmarks such as ETH3D. In this paper, we aim to create 3D models that provide accurate geometry and view synthesis, partially closing the large geometric performance gap between NeRF and traditional MVS methods. We propose a patch-based approach that effectively leverages monocular surface normal and relative depth predictions. The patch-based ray sampling also enables the appearance regularization of normalized cross-correlation (NCC) and structural similarity (SSIM) between randomly sampled virtual and training views. We further show that \"density restrictions\" based on sparse structure-from-motion points can help greatly improve geometric accuracy with a slight drop in novel view synthesis metrics. Our experiments show 4x the performance of RegNeRF and 8x that of FreeNeRF on average F1@2cm for ETH3D MVS benchmark, suggesting a fruitful research direction to improve the geometric accuracy of NeRF-based models, and sheds light on a potential future approach to enable NeRF-based optimization to eventually outperform traditional MVS.","sentences":["The latest regularized Neural Radiance Field (NeRF) approaches produce poor geometry and view extrapolation for multiview stereo (MVS) benchmarks such as ETH3D. In this paper, we aim to create 3D models that provide accurate geometry and view synthesis, partially closing the large geometric performance gap between NeRF and traditional MVS methods.","We propose a patch-based approach that effectively leverages monocular surface normal and relative depth predictions.","The patch-based ray sampling also enables the appearance regularization of normalized cross-correlation (NCC) and structural similarity (SSIM) between randomly sampled virtual and training views.","We further show that \"density restrictions\" based on sparse structure-from-motion points can help greatly improve geometric accuracy with a slight drop in novel view synthesis metrics.","Our experiments show 4x the performance of RegNeRF and 8x that of FreeNeRF on average F1@2cm for ETH3D MVS benchmark, suggesting a fruitful research direction to improve the geometric accuracy of NeRF-based models, and sheds light on a potential future approach to enable NeRF-based optimization to eventually outperform traditional MVS."],"url":"http://arxiv.org/abs/2404.08252v1","category":"cs.CV"}
{"created":"2024-04-12 05:33:56","title":"Nonlinear theory of the modulational instability at the ion-ion hybrid frequency and collapse of ion-ion hybrid waves in two-ion plasmas","abstract":"We study the dynamics of two-dimensional nonlinear ion-ion hybrid waves propagating perpendicular to an external magnetic field in plasmas with two ion species. We derive nonlinear equations for the envelope of electrostatic potential at the ion-ion hybrid frequency to describe the interaction of ion-ion hybrid waves with low frequency acoustic-type disturbances. The resulting nonlinear equations also take into account the contribution of second harmonics of the ion-ion hybrid frequency. A nonlinear dispersion relation is obtained and, for a number of particular cases, the modulational instability growth rates are found. By neglecting the contribution of second harmonics, the phenomenon of collapse of ion-ion hybrid waves is predicted. It is shown that taking into account the interaction with the second harmonics results in the existence of a stable two-dimensional soliton.","sentences":["We study the dynamics of two-dimensional nonlinear ion-ion hybrid waves propagating perpendicular to an external magnetic field in plasmas with two ion species.","We derive nonlinear equations for the envelope of electrostatic potential at the ion-ion hybrid frequency to describe the interaction of ion-ion hybrid waves with low frequency acoustic-type disturbances.","The resulting nonlinear equations also take into account the contribution of second harmonics of the ion-ion hybrid frequency.","A nonlinear dispersion relation is obtained and, for a number of particular cases, the modulational instability growth rates are found.","By neglecting the contribution of second harmonics, the phenomenon of collapse of ion-ion hybrid waves is predicted.","It is shown that taking into account the interaction with the second harmonics results in the existence of a stable two-dimensional soliton."],"url":"http://arxiv.org/abs/2404.08248v1","category":"nlin.PS"}
{"created":"2024-04-12 04:29:59","title":"A classification of constant Gaussian curvature surfaces in the three-dimensional hyperbolic space","abstract":"Weakly complete constant Gaussian curvature $-1<K<0$ surfaces will be classified in terms of holomorphic quadratic differentials. For this purpose, we will first establish a loop group method for constant Gaussian curvature surfaces in $\\mathbb H^3$ with $K>-1$ but $K \\neq 0$ by using harmonicities of Lagrangian and Legendrian Gauss maps. Then we will show that a spectral parameter deformation of the Lagrangian harmonic Gauss map gives a harmonic map into $\\mathbb H^2$ for $-1< K<0$ or $\\mathbb S^2$ for $K>0$, respectively.","sentences":["Weakly complete constant Gaussian curvature $-1<K<0$ surfaces will be classified in terms of holomorphic quadratic differentials.","For this purpose, we will first establish a loop group method for constant Gaussian curvature surfaces in $\\mathbb H^3$ with $K>-1$ but $K \\neq 0$ by using harmonicities of Lagrangian and Legendrian Gauss maps.","Then we will show that a spectral parameter deformation of the Lagrangian harmonic Gauss map gives a harmonic map into $\\mathbb H^2$ for $-1< K<0$ or $\\mathbb S^2$ for $K>0$, respectively."],"url":"http://arxiv.org/abs/2404.08235v1","category":"math.DG"}
{"created":"2024-04-12 02:48:33","title":"The Inverse Carson's Equations Problem: Definition, Implementation and Experiments","abstract":"In recent years, with the increase in renewable energy and storage penetration, power flow studies in low-voltage networks have become of interest in both industry and academia. Many studies use impedance represented by sequence components due to the lack of datasets with fully parameterized impedance matrices. This assumes that the network impedance is balanced, which is typically not the case in the low voltage network and therefore risks the accuracy of the study. This paper proposes a methodology for the recovery of more detailed impedance data from sequence components as an inverse problem, i.e. the inverse Carson's equations problem, for both overhead lines and cables. We consider discrete properties like material and configuration of conductors common in the distribution network and investigate what data can be reliably recovered from only sequence components using nonlinear optimisation models. Presented results include uniqueness of recovered variables and the likelihood of mismatch.","sentences":["In recent years, with the increase in renewable energy and storage penetration, power flow studies in low-voltage networks have become of interest in both industry and academia.","Many studies use impedance represented by sequence components due to the lack of datasets with fully parameterized impedance matrices.","This assumes that the network impedance is balanced, which is typically not the case in the low voltage network and therefore risks the accuracy of the study.","This paper proposes a methodology for the recovery of more detailed impedance data from sequence components as an inverse problem, i.e. the inverse Carson's equations problem, for both overhead lines and cables.","We consider discrete properties like material and configuration of conductors common in the distribution network and investigate what data can be reliably recovered from only sequence components using nonlinear optimisation models.","Presented results include uniqueness of recovered variables and the likelihood of mismatch."],"url":"http://arxiv.org/abs/2404.08210v1","category":"math.OC"}
{"created":"2024-04-12 17:14:58","title":"Hyperbolic Delaunay Geometric Alignment","abstract":"Hyperbolic machine learning is an emerging field aimed at representing data with a hierarchical structure. However, there is a lack of tools for evaluation and analysis of the resulting hyperbolic data representations. To this end, we propose Hyperbolic Delaunay Geometric Alignment (HyperDGA) -- a similarity score for comparing datasets in a hyperbolic space. The core idea is counting the edges of the hyperbolic Delaunay graph connecting datapoints across the given sets. We provide an empirical investigation on synthetic and real-life biological data and demonstrate that HyperDGA outperforms the hyperbolic version of classical distances between sets. Furthermore, we showcase the potential of HyperDGA for evaluating latent representations inferred by a Hyperbolic Variational Auto-Encoder.","sentences":["Hyperbolic machine learning is an emerging field aimed at representing data with a hierarchical structure.","However, there is a lack of tools for evaluation and analysis of the resulting hyperbolic data representations.","To this end, we propose Hyperbolic Delaunay Geometric Alignment (HyperDGA) -- a similarity score for comparing datasets in a hyperbolic space.","The core idea is counting the edges of the hyperbolic Delaunay graph connecting datapoints across the given sets.","We provide an empirical investigation on synthetic and real-life biological data and demonstrate that HyperDGA outperforms the hyperbolic version of classical distances between sets.","Furthermore, we showcase the potential of HyperDGA for evaluating latent representations inferred by a Hyperbolic Variational Auto-Encoder."],"url":"http://arxiv.org/abs/2404.08608v1","category":"cs.LG"}
{"created":"2024-04-12 16:40:29","title":"Scarce Resource Allocations That Rely On Machine Learning Should Be Randomized","abstract":"Contrary to traditional deterministic notions of algorithmic fairness, this paper argues that fairly allocating scarce resources using machine learning often requires randomness. We address why, when, and how to randomize by proposing stochastic procedures that more adequately account for all of the claims that individuals have to allocations of social goods or opportunities.","sentences":["Contrary to traditional deterministic notions of algorithmic fairness, this paper argues that fairly allocating scarce resources using machine learning often requires randomness.","We address why, when, and how to randomize by proposing stochastic procedures that more adequately account for all of the claims that individuals have to allocations of social goods or opportunities."],"url":"http://arxiv.org/abs/2404.08592v1","category":"cs.CY"}
{"created":"2024-04-12 09:31:55","title":"OmniSat: Self-Supervised Modality Fusion for Earth Observation","abstract":"The field of Earth Observations (EO) offers a wealth of data from diverse sensors, presenting a great opportunity for advancing self-supervised multimodal learning. However, current multimodal EO datasets and models focus on a single data type, either mono-date images or time series, which limits their expressivity. We introduce OmniSat, a novel architecture that exploits the spatial alignment between multiple EO modalities to learn expressive multimodal representations without labels. To demonstrate the advantages of combining modalities of different natures, we augment two existing datasets with new modalities. As demonstrated on three downstream tasks: forestry, land cover classification, and crop mapping. OmniSat can learn rich representations in an unsupervised manner, leading to improved performance in the semi- and fully-supervised settings, even when only one modality is available for inference. The code and dataset are available at github.com/gastruc/OmniSat.","sentences":["The field of Earth Observations (EO) offers a wealth of data from diverse sensors, presenting a great opportunity for advancing self-supervised multimodal learning.","However, current multimodal EO datasets and models focus on a single data type, either mono-date images or time series, which limits their expressivity.","We introduce OmniSat, a novel architecture that exploits the spatial alignment between multiple EO modalities to learn expressive multimodal representations without labels.","To demonstrate the advantages of combining modalities of different natures, we augment two existing datasets with new modalities.","As demonstrated on three downstream tasks: forestry, land cover classification, and crop mapping.","OmniSat can learn rich representations in an unsupervised manner, leading to improved performance in the semi- and fully-supervised settings, even when only one modality is available for inference.","The code and dataset are available at github.com/gastruc/OmniSat."],"url":"http://arxiv.org/abs/2404.08351v1","category":"cs.CV"}
{"created":"2024-04-12 08:33:51","title":"Communication-Efficient Model Aggregation with Layer Divergence Feedback in Federated Learning","abstract":"Federated Learning (FL) facilitates collaborative machine learning by training models on local datasets, and subsequently aggregating these local models at a central server. However, the frequent exchange of model parameters between clients and the central server can result in significant communication overhead during the FL training process. To solve this problem, this paper proposes a novel FL framework, the Model Aggregation with Layer Divergence Feedback mechanism (FedLDF). Specifically, we calculate model divergence between the local model and the global model from the previous round. Then through model layer divergence feedback, the distinct layers of each client are uploaded and the amount of data transferred is reduced effectively. Moreover, the convergence bound reveals that the access ratio of clients has a positive correlation with model performance. Simulation results show that our algorithm uploads local models with reduced communication overhead while upholding a superior global model performance.","sentences":["Federated Learning (FL) facilitates collaborative machine learning by training models on local datasets, and subsequently aggregating these local models at a central server.","However, the frequent exchange of model parameters between clients and the central server can result in significant communication overhead during the FL training process.","To solve this problem, this paper proposes a novel FL framework, the Model Aggregation with Layer Divergence Feedback mechanism (FedLDF).","Specifically, we calculate model divergence between the local model and the global model from the previous round.","Then through model layer divergence feedback, the distinct layers of each client are uploaded and the amount of data transferred is reduced effectively.","Moreover, the convergence bound reveals that the access ratio of clients has a positive correlation with model performance.","Simulation results show that our algorithm uploads local models with reduced communication overhead while upholding a superior global model performance."],"url":"http://arxiv.org/abs/2404.08324v1","category":"cs.DC"}
{"created":"2024-04-12 17:32:39","title":"Convexity in Optimal Control Problems","abstract":"This paper investigates the central role played by the Hamiltonian in continuous-time nonlinear optimal control problems. We show that the strict convexity of the Hamiltonian in the control variable is a sufficient condition for the existence of a unique optimal trajectory, and the nonlinearity/non-convexity of the dynamics and the cost are immaterial. The analysis is extended to discrete-time problems, revealing that discretization destroys the convex Hamiltonian structure, leading to multiple spurious optima, unless the time discretization is sufficiently small. We present simulated results comparing the \"indirect\" Iterative Linear Quadratic Regulator (iLQR) and the \"direct\" Sequential Quadratic Programming (SQP) approach for solving the optimal control problem for the cartpole and pendulum models to validate the theoretical analysis. Results show that the ILQR always converges to the \"globally\" optimum solution while the SQP approach gets stuck in spurious minima given multiple random initial guesses for a time discretization that is insufficiently small, while both converge to the same unique solution if the discretization is sufficiently small.","sentences":["This paper investigates the central role played by the Hamiltonian in continuous-time nonlinear optimal control problems.","We show that the strict convexity of the Hamiltonian in the control variable is a sufficient condition for the existence of a unique optimal trajectory, and the nonlinearity/non-convexity of the dynamics and the cost are immaterial.","The analysis is extended to discrete-time problems, revealing that discretization destroys the convex Hamiltonian structure, leading to multiple spurious optima, unless the time discretization is sufficiently small.","We present simulated results comparing the \"indirect\" Iterative Linear Quadratic Regulator (iLQR) and the \"direct\" Sequential Quadratic Programming (SQP) approach for solving the optimal control problem for the cartpole and pendulum models to validate the theoretical analysis.","Results show that the ILQR always converges to the \"globally\" optimum solution while the SQP approach gets stuck in spurious minima given multiple random initial guesses for a time discretization that is insufficiently small, while both converge to the same unique solution if the discretization is sufficiently small."],"url":"http://arxiv.org/abs/2404.08621v1","category":"math.OC"}
{"created":"2024-04-12 13:05:34","title":"Optimized Detection with Analog Beamforming for Monostatic Integrated Sensing and Communication","abstract":"In this paper, we formalize an optimization framework for analog beamforming in the context of monostatic integrated sensing and communication (ISAC), where we also address the problem of self-interference in the analog domain. As a result, we derive semidefinite programs to approach detection-optimal transmit and receive beamformers, and we devise a superiorized iterative projection algorithm to approximate them. Our simulations show that this approach outperforms the detection performance of well-known design techniques for ISAC beamforming, while it achieves satisfactory self-interference suppression.","sentences":["In this paper, we formalize an optimization framework for analog beamforming in the context of monostatic integrated sensing and communication (ISAC), where we also address the problem of self-interference in the analog domain.","As a result, we derive semidefinite programs to approach detection-optimal transmit and receive beamformers, and we devise a superiorized iterative projection algorithm to approximate them.","Our simulations show that this approach outperforms the detection performance of well-known design techniques for ISAC beamforming, while it achieves satisfactory self-interference suppression."],"url":"http://arxiv.org/abs/2404.08455v1","category":"eess.SP"}
{"created":"2024-04-12 12:25:39","title":"Optimized Quantum Autoencoder","abstract":"Quantum autoencoder (QAE) compresses a bipartite quantum state into its subsystem by a self-checking mechanism. How to characterize the lost information in this process is essential to understand the compression mechanism of QAE\\@. Here we investigate how to decrease the lost information in QAE for any input mixed state. We theoretically show that the lost information is the quantum mutual information between the remaining subsystem and the ignorant one, and the encoding unitary transformation is designed to minimize this mutual information. Further more, we show that the optimized unitary transformation can be decomposed as the product of a permutation unitary transformation and a disentanglement unitary transformation, and the permutation unitary transformation can be searched by a regular Young tableau algorithm. Finally we numerically identify that our compression scheme outperforms the quantum variational circuit based QAE\\@.","sentences":["Quantum autoencoder (QAE) compresses a bipartite quantum state into its subsystem by a self-checking mechanism.","How to characterize the lost information in this process is essential to understand the compression mechanism of QAE\\@. Here we investigate how to decrease the lost information in QAE for any input mixed state.","We theoretically show that the lost information is the quantum mutual information between the remaining subsystem and the ignorant one, and the encoding unitary transformation is designed to minimize this mutual information.","Further more, we show that the optimized unitary transformation can be decomposed as the product of a permutation unitary transformation and a disentanglement unitary transformation, and the permutation unitary transformation can be searched by a regular Young tableau algorithm.","Finally we numerically identify that our compression scheme outperforms the quantum variational circuit based QAE\\@."],"url":"http://arxiv.org/abs/2404.08429v1","category":"quant-ph"}
{"created":"2024-04-12 11:08:35","title":"Radio number for the Cartesian product of a tree and a complete graph","abstract":"A radio labelling of a graph $G$ is a mapping $f : V(G) \\rightarrow \\{0, 1, 2,\\ldots\\}$ such that $|f(u)-f(v)|\\geq diam(G) + 1 - d(u,v)$ for every pair of distinct vertices $u,v$ of $G$, where $diam(G)$ is the diameter of $G$ and $d(u,v)$ is the distance between $u$ and $v$ in $G$. The radio number $rn(G)$ of $G$ is the smallest integer $k$ such that $G$ admits a radio labelling $f$ with $\\max\\{f(v):v \\in V(G)\\} = k$. In this paper, we give a lower bound for the radio number of the Cartesian product of a tree and a complete graph and give two necessary and sufficient conditions to achieve the lower bound. We also give three sufficient conditions to achieve the lower bound. We determine the radio number for the Cartesian product of a level-wise regular trees and a complete graph which attains the lower bound. The radio number for the Cartesian product of a path and a complete graph derived in [Radio number for the product of a path and a complete graph, J. Comb. Optim., 30 (2015), 139-149] can be obtained using our results in a short way.","sentences":["A radio labelling of a graph $G$ is a mapping $f : V(G)","\\rightarrow \\{0, 1, 2,\\ldots\\}$ such that $|f(u)-f(v)|\\geq diam(G) + 1 - d(u,v)$ for every pair of distinct vertices $u,v$ of $G$, where $diam(G)$ is the diameter of $G$ and $d(u,v)$ is the distance between $u$ and $v$ in $G$. The radio number $rn(G)$ of $G$ is the smallest integer $k$ such that $G$ admits a radio labelling $f$ with $\\max\\{f(v):v \\in V(G)\\} = k$.","In this paper, we give a lower bound for the radio number of the Cartesian product of a tree and a complete graph and give two necessary and sufficient conditions to achieve the lower bound.","We also give three sufficient conditions to achieve the lower bound.","We determine the radio number for the Cartesian product of a level-wise regular trees and a complete graph which attains the lower bound.","The radio number for the Cartesian product of a path and a complete graph derived in [Radio number for the product of a path and a complete graph, J. Comb.","Optim., 30 (2015), 139-149] can be obtained using our results in a short way."],"url":"http://arxiv.org/abs/2404.08400v1","category":"math.CO"}
{"created":"2024-04-12 11:04:50","title":"Joint Computation Offloading and Target Tracking in Integrated Sensing and Communication Enabled UAV Networks","abstract":"In this paper, we investigate a joint computation offloading and target tracking in Integrated Sensing and Communication (ISAC)-enabled unmanned aerial vehicle (UAV) network. Therein, the UAV has a computing task that is partially offloaded to the ground UE for execution. Meanwhile, the UAV uses the offloading bit sequence to estimate the velocity of a ground target based on an autocorrelation function. The performance of the velocity estimation that is represented by Cramer-Rao lower bound (CRB) depends on the length of the offloading bit sequence and the UAV's location. Thus, we jointly optimize the task size for offloading and the UAV's location to minimize the overall computation latency and the CRB of the mean square error for velocity estimation subject to the UAV's budget. The problem is non-convex, and we propose a genetic algorithm to solve it. Simulation results are provided to demonstrate the effectiveness of the proposed algorithm.","sentences":["In this paper, we investigate a joint computation offloading and target tracking in Integrated Sensing and Communication (ISAC)-enabled unmanned aerial vehicle (UAV) network.","Therein, the UAV has a computing task that is partially offloaded to the ground UE for execution.","Meanwhile, the UAV uses the offloading bit sequence to estimate the velocity of a ground target based on an autocorrelation function.","The performance of the velocity estimation that is represented by Cramer-Rao lower bound (CRB) depends on the length of the offloading bit sequence and the UAV's location.","Thus, we jointly optimize the task size for offloading and the UAV's location to minimize the overall computation latency and the CRB of the mean square error for velocity estimation subject to the UAV's budget.","The problem is non-convex, and we propose a genetic algorithm to solve it.","Simulation results are provided to demonstrate the effectiveness of the proposed algorithm."],"url":"http://arxiv.org/abs/2404.08396v1","category":"cs.IT"}
{"created":"2024-04-12 07:30:52","title":"Overcoming Scene Context Constraints for Object Detection in wild using Defilters","abstract":"This paper focuses on improving object detection performance by addressing the issue of image distortions, commonly encountered in uncontrolled acquisition environments. High-level computer vision tasks such as object detection, recognition, and segmentation are particularly sensitive to image distortion. To address this issue, we propose a novel approach employing an image defilter to rectify image distortion prior to object detection. This method enhances object detection accuracy, as models perform optimally when trained on non-distorted images. Our experiments demonstrate that utilizing defiltered images significantly improves mean average precision compared to training object detection models on distorted images. Consequently, our proposed method offers considerable benefits for real-world applications plagued by image distortion. To our knowledge, the contribution lies in employing distortion-removal paradigm for object detection on images captured in natural settings. We achieved an improvement of 0.562 and 0.564 of mean Average precision on validation and test data.","sentences":["This paper focuses on improving object detection performance by addressing the issue of image distortions, commonly encountered in uncontrolled acquisition environments.","High-level computer vision tasks such as object detection, recognition, and segmentation are particularly sensitive to image distortion.","To address this issue, we propose a novel approach employing an image defilter to rectify image distortion prior to object detection.","This method enhances object detection accuracy, as models perform optimally when trained on non-distorted images.","Our experiments demonstrate that utilizing defiltered images significantly improves mean average precision compared to training object detection models on distorted images.","Consequently, our proposed method offers considerable benefits for real-world applications plagued by image distortion.","To our knowledge, the contribution lies in employing distortion-removal paradigm for object detection on images captured in natural settings.","We achieved an improvement of 0.562 and 0.564 of mean Average precision on validation and test data."],"url":"http://arxiv.org/abs/2404.08293v1","category":"cs.CV"}
{"created":"2024-04-12 04:50:09","title":"Beam dynamics study of the high-power electron beam irradiator using niobium-tin superconducting cavity","abstract":"A compact accelerator design for irradiation purposes is being proposed at KEK. This design targets an energy of 10 MeV and a current of 50 mA. Current design includes a 100 kV thermionic DC electron gun with an RF grid, 1-cell normal-conducting buncher cavity, and Nb$_{3}$Sn superconducting cavities to accelerate the beam to the final energy of 10 MeV. The goal of the present beam dynamics study is the beam loss suppression (to the ppm level), since it results in a thermal load on the cavity. Then the beam performance at the accelerator exit should be confirmed. The main issue was to transport the beam without loss, since the initial electron energy (100 keV) is low, and the beam parameters are intricately correlated. In addition, the space charge effect is considerable. For this reason, simultaneous optimization of multiple parameters was necessary. Here we report optimization results and their effect on the design of the machine.","sentences":["A compact accelerator design for irradiation purposes is being proposed at KEK.","This design targets an energy of 10 MeV and a current of 50 mA. Current design includes a 100 kV thermionic DC electron gun with an RF grid, 1-cell normal-conducting buncher cavity, and Nb$_{3}$Sn superconducting cavities to accelerate the beam to the final energy of 10 MeV.","The goal of the present beam dynamics study is the beam loss suppression (to the ppm level), since it results in a thermal load on the cavity.","Then the beam performance at the accelerator exit should be confirmed.","The main issue was to transport the beam without loss, since the initial electron energy (100 keV) is low, and the beam parameters are intricately correlated.","In addition, the space charge effect is considerable.","For this reason, simultaneous optimization of multiple parameters was necessary.","Here we report optimization results and their effect on the design of the machine."],"url":"http://arxiv.org/abs/2404.08240v1","category":"physics.acc-ph"}
{"created":"2024-04-12 17:38:46","title":"The role of stochastic Fermi-type particle acceleration in the inner jets of Active Galactic Nuclei","abstract":"High-resolution radio observations of nearby active galactic nuclei have revealed extended, limb-brightened structures in their inner jets. This ties in with other multi-wavelength observations from radio to X-ray and gamma-ray, indicating that a structured jet model is required. While electrons need to be kept energized to account for the observed features, the underlying particle acceleration mechanism is still unclear. We explore the role of stochastic Fermi-type particle acceleration, i.e., classical second-order Fermi and shear acceleration, for understanding the multi-wavelength observations of the inner jets of M87. An analytical Fokker-Planck description is adopted to infer characteristic spectral indices and cutoff energies for these two mechanisms. We focus on electron synchrotron radiation as the dominant emission process. We find that the multi-wavelength observations of M87 can be satisfactorily accounted for in a framework, where the X-rays are produced at a larger distance from the core than the radio emission region. This provides further support to multi-zone, broadband emission modelling. We use our findings to also comment on the acceleration of cosmic rays entrained in the sheath.","sentences":["High-resolution radio observations of nearby active galactic nuclei have revealed extended, limb-brightened structures in their inner jets.","This ties in with other multi-wavelength observations from radio to X-ray and gamma-ray, indicating that a structured jet model is required.","While electrons need to be kept energized to account for the observed features, the underlying particle acceleration mechanism is still unclear.","We explore the role of stochastic Fermi-type particle acceleration, i.e., classical second-order Fermi and shear acceleration, for understanding the multi-wavelength observations of the inner jets of M87.","An analytical Fokker-Planck description is adopted to infer characteristic spectral indices and cutoff energies for these two mechanisms.","We focus on electron synchrotron radiation as the dominant emission process.","We find that the multi-wavelength observations of M87 can be satisfactorily accounted for in a framework, where the X-rays are produced at a larger distance from the core than the radio emission region.","This provides further support to multi-zone, broadband emission modelling.","We use our findings to also comment on the acceleration of cosmic rays entrained in the sheath."],"url":"http://arxiv.org/abs/2404.08625v1","category":"astro-ph.HE"}
{"created":"2024-04-12 17:32:58","title":"Transverse Momentum-Dependent Heavy-Quark Fragmentation at Next-to-Leading Order","abstract":"The transverse momentum-dependent fragmentation functions (TMD FFs) of heavy (bottom and charm) quarks, which we recently introduced, are universal building blocks that enter predictions for a large number of observables involving final-state heavy quarks or hadrons. They enable the extension of fixed-order subtraction schemes to quasi-collinear limits, and are of particular interest in their own right as probes of the nonperturbative dynamics of hadronization. In this paper we calculate all TMD FFs involving heavy quarks and the associated TMD matrix element in heavy-quark effective theory (HQET) to next-to-leading order in the strong interaction. Our results confirm the renormalization properties, large-mass, and small-mass consistency relations predicted in our earlier work. We also derive and confirm a prediction for the large-$z$ behavior of the heavy-quark TMD FF by extending, for the first time, the formalism of joint resummation to capture quark mass effects in heavy-quark fragmentation. Our final results in position space agree with those of a recent calculation by another group that used a highly orthogonal organization of singularities in the intermediate momentum-space steps, providing a strong independent cross check. As an immediate application, we present the complete quark mass dependence of the energy-energy correlator (EEC) in the back-to-back limit at $\\mathcal{O}(\\alpha_s)$.","sentences":["The transverse momentum-dependent fragmentation functions (TMD FFs) of heavy (bottom and charm) quarks, which we recently introduced, are universal building blocks that enter predictions for a large number of observables involving final-state heavy quarks or hadrons.","They enable the extension of fixed-order subtraction schemes to quasi-collinear limits, and are of particular interest in their own right as probes of the nonperturbative dynamics of hadronization.","In this paper we calculate all TMD FFs involving heavy quarks and the associated TMD matrix element in heavy-quark effective theory (HQET) to next-to-leading order in the strong interaction.","Our results confirm the renormalization properties, large-mass, and small-mass consistency relations predicted in our earlier work.","We also derive and confirm a prediction for the large-$z$ behavior of the heavy-quark TMD FF by extending, for the first time, the formalism of joint resummation to capture quark mass effects in heavy-quark fragmentation.","Our final results in position space agree with those of a recent calculation by another group that used a highly orthogonal organization of singularities in the intermediate momentum-space steps, providing a strong independent cross check.","As an immediate application, we present the complete quark mass dependence of the energy-energy correlator (EEC) in the back-to-back limit at $\\mathcal{O}(\\alpha_s)$."],"url":"http://arxiv.org/abs/2404.08622v1","category":"hep-ph"}
{"created":"2024-04-12 17:28:21","title":"Jupiter Co-Orbital Comet P/2023 V6 (PANSTARRS): Orbital History and Modern Activity State","abstract":"The discovery of the transient Jupiter co-orbital comet P/2019 LD2 (ATLAS) drew significant interest. Not only will LD2 transition between being a Centaur and a Jupiter Family Comet (JFC) in 2063, the first time this process can be observed as it happens, it is also very active for its large heliocentric distance. We present observations and orbital integrations of the newly discovered transient Jupiter co-orbital comet P/2023 V6 (PANSTARRS), the second such object known. Despite similar modern orbits, V6 is significantly (15 times) less active than LD2 and most JFCs as determined via Afrho measurements at the same heliocentric distance. We find V6 is co-orbital between 2020 and 2044, twice the duration of LD2, but it will not become a JFC soon. We interpret these differences in activity as evolutionary, with V6 having lost a significant fraction of its near-surface ice compared to LD2 by previously being warmer. While V6's pre-encounter orbit was somewhat warmer than LD2's, future thermal modeling will be needed to understand if this can explain their differences or if a more significant difference further into the past is required. This is more evidence that LD2 is a pristine and ice-rich object, and thus it may display very strong activity when it becomes a JFC. We sue the differences between V6 and LD2 to discuss the interpretation of cometary activity at large heliocentric distances as well as the small end of the crater record of the Galilean Satellites. Continuing observations of both objects are highly encouraged.","sentences":["The discovery of the transient Jupiter co-orbital comet P/2019 LD2 (ATLAS) drew significant interest.","Not only will LD2 transition between being a Centaur and a Jupiter Family Comet (JFC) in 2063, the first time this process can be observed as it happens, it is also very active for its large heliocentric distance.","We present observations and orbital integrations of the newly discovered transient Jupiter co-orbital comet P/2023 V6 (PANSTARRS), the second such object known.","Despite similar modern orbits, V6 is significantly (15 times) less active than LD2 and most JFCs as determined via Afrho measurements at the same heliocentric distance.","We find V6 is co-orbital between 2020 and 2044, twice the duration of LD2, but it will not become a JFC soon.","We interpret these differences in activity as evolutionary, with V6 having lost a significant fraction of its near-surface ice compared to LD2 by previously being warmer.","While V6's pre-encounter orbit was somewhat warmer than LD2's, future thermal modeling will be needed to understand if this can explain their differences or if a more significant difference further into the past is required.","This is more evidence that LD2 is a pristine and ice-rich object, and thus it may display very strong activity when it becomes a JFC.","We sue the differences between V6 and LD2 to discuss the interpretation of cometary activity at large heliocentric distances as well as the small end of the crater record of the Galilean Satellites.","Continuing observations of both objects are highly encouraged."],"url":"http://arxiv.org/abs/2404.08618v1","category":"astro-ph.EP"}
{"created":"2024-04-12 16:52:36","title":"Polarized semi-inclusive deep-inelastic scattering at NNLO in QCD","abstract":"Semi-inclusive hadron production in longitudinally polarized deep-inelastic lepton-nucleon scattering is a powerful tool for resolving the quark flavor decomposition of the proton's spin structure. We present the full next-to-next-to-leading order (NNLO) QCD corrections to the coefficient functions of polarized semi-inclusive deep-inelastic scattering (SIDIS) in analytical form, enabling the use of SIDIS measurements in precision studies of the proton spin structure. The numerical impact of these corrections is illustrated by a comparison with data of polarized single-inclusive hadron spectra from the DESY HERMES and CERN COMPASS experiments.","sentences":["Semi-inclusive hadron production in longitudinally polarized deep-inelastic lepton-nucleon scattering is a powerful tool for resolving the quark flavor decomposition of the proton's spin structure.","We present the full next-to-next-to-leading order (NNLO) QCD corrections to the coefficient functions of polarized semi-inclusive deep-inelastic scattering (SIDIS) in analytical form, enabling the use of SIDIS measurements in precision studies of the proton spin structure.","The numerical impact of these corrections is illustrated by a comparison with data of polarized single-inclusive hadron spectra from the DESY HERMES and CERN COMPASS experiments."],"url":"http://arxiv.org/abs/2404.08597v1","category":"hep-ph"}
{"created":"2024-04-12 15:50:06","title":"Quantifier alternation depth in universal Boolean doctrines","abstract":"We introduce the notion of a quantifier-stratified universal Boolean doctrine. This notion requires additional structure on a universal Boolean doctrine, accounting for the quantifier alternation depth of formulas. After proving that every Boolean doctrine over a small base category admits a quantifier completion, we show how to freely add the first layer of quantifier alternation depth to these doctrines. To achieve this, we characterize, within the doctrinal setting, the classes of quantifier-free formulas whose universal closure is valid in some common model.","sentences":["We introduce the notion of a quantifier-stratified universal Boolean doctrine.","This notion requires additional structure on a universal Boolean doctrine, accounting for the quantifier alternation depth of formulas.","After proving that every Boolean doctrine over a small base category admits a quantifier completion, we show how to freely add the first layer of quantifier alternation depth to these doctrines.","To achieve this, we characterize, within the doctrinal setting, the classes of quantifier-free formulas whose universal closure is valid in some common model."],"url":"http://arxiv.org/abs/2404.08551v1","category":"math.LO"}
{"created":"2024-04-12 15:20:49","title":"Tensor factorization in ab initio many-body calculations: Triaxially-deformed (B) MBPT calculations in large bases","abstract":"Whether for fundamental studies or nuclear data evaluations, first-principle calculations of atomic nuclei constitute the path forward. Today, performing \\textit{ab initio} calculations (a) of heavy nuclei, (b) of doubly open-shell nuclei or (c) with a sub-percent accuracy is at the forefront of nuclear structure theory. While combining any two of these features constitutes a major challenge, addressing the three at the same time is currently impossible. From a numerical standpoint, these challenges relate to the necessity to handle (i) very large single bases and (ii) mode-6, \\textit{i.e.} three-body, tensors (iii) that must be stored repeatedly. Performing second-order many-body perturbation theory(ies) calculations based on triaxially deformed and superfluid reference states of doubly open-shell nuclei up to mass $A=72$, the present work achieves a significant step forward by addressing challenge (i). To do so, the memory and computational cost associated with the handling of large tensors is scaled down via the use of tensor factorization techniques. The presently used factorization format is based on a randomized singular value decomposition that does not require the computation and storage of the very large initial tensor. The procedure delivers an inexpensive and controllable approximation to the original problem, as presently illustrated for calculations that could not be performed without tensor factorization. With the presently developed technology at hand, one can envision to perform calculations of yet heavier doubly open-shell nuclei at sub-percent accuracy in a foreseeable future.","sentences":["Whether for fundamental studies or nuclear data evaluations, first-principle calculations of atomic nuclei constitute the path forward.","Today, performing \\textit{ab initio} calculations (a) of heavy nuclei, (b) of doubly open-shell nuclei or (c) with a sub-percent accuracy is at the forefront of nuclear structure theory.","While combining any two of these features constitutes a major challenge, addressing the three at the same time is currently impossible.","From a numerical standpoint, these challenges relate to the necessity to handle (i) very large single bases and (ii) mode-6, \\textit{i.e.}","three-body, tensors (iii) that must be stored repeatedly.","Performing second-order many-body perturbation theory(ies) calculations based on triaxially deformed and superfluid reference states of doubly open-shell nuclei up to mass $A=72$, the present work achieves a significant step forward by addressing challenge (i).","To do so, the memory and computational cost associated with the handling of large tensors is scaled down via the use of tensor factorization techniques.","The presently used factorization format is based on a randomized singular value decomposition that does not require the computation and storage of the very large initial tensor.","The procedure delivers an inexpensive and controllable approximation to the original problem, as presently illustrated for calculations that could not be performed without tensor factorization.","With the presently developed technology at hand, one can envision to perform calculations of yet heavier doubly open-shell nuclei at sub-percent accuracy in a foreseeable future."],"url":"http://arxiv.org/abs/2404.08532v1","category":"nucl-th"}
{"created":"2024-04-12 15:17:11","title":"Echoes of darkness: Supernova-neutrino-boosted dark matter from all galaxies","abstract":"It has been recently proposed that the boosted dark matter (BDM) by supernova neutrinos (SN$\\nu$) from SN1987a or from the next galactic SN can serve as a novel component to probe nonvanishing interaction between DM and the Standard Model leptons. In this work, we extend this concept and evaluate the present-day diffuse flux of SN$\\nu$ BDM originated from all galaxies at higher redshifts. We show that by considering this diffuse BDM (DBDM) component, the best model-independent sensitivity on the product of the DM-$\\nu$ and DM-electron cross sections, $\\sqrt{\\sigma_{\\chi\\nu}\\sigma_{\\chi e}}\\simeq \\mathcal{O}(10^{-37})$~cm$^2$ for sub-MeV DM, can be obtained with large-size neutrino experiments such as Super-Kamiokande or Hyper-Kamiokande, surpassing the estimated SN$\\nu$ BDM bound from SN1987a. We also examine the impact due to the presence of DM spikes around the supermassive black holes in galaxies on SN$\\nu$ BDM and DBDM. Our results suggest that both the DBDM and the SN$\\nu$ BDM probes are insensitive to the uncertain properties of DM spikes, unless the next galactic SN happens to occur at a location extremely close to or right behind the galactic center along the SN line of sight.","sentences":["It has been recently proposed that the boosted dark matter (BDM) by supernova neutrinos (SN$\\nu$) from SN1987a or from the next galactic SN can serve as a novel component to probe nonvanishing interaction between DM and the Standard Model leptons.","In this work, we extend this concept and evaluate the present-day diffuse flux of SN$\\nu$ BDM originated from all galaxies at higher redshifts.","We show that by considering this diffuse BDM (DBDM) component, the best model-independent sensitivity on the product of the DM-$\\nu$ and DM-electron cross sections, $\\sqrt{\\sigma_{\\chi\\nu}\\sigma_{\\chi e}}\\simeq \\mathcal{O}(10^{-37})$~cm$^2$ for sub-MeV DM, can be obtained with large-size neutrino experiments such as Super-Kamiokande or Hyper-Kamiokande, surpassing the estimated SN$\\nu$ BDM bound from SN1987a.","We also examine the impact due to the presence of DM spikes around the supermassive black holes in galaxies on SN$\\nu$ BDM and DBDM.","Our results suggest that both the DBDM and the SN$\\nu$ BDM probes are insensitive to the uncertain properties of DM spikes, unless the next galactic SN happens to occur at a location extremely close to or right behind the galactic center along the SN line of sight."],"url":"http://arxiv.org/abs/2404.08528v1","category":"hep-ph"}
{"created":"2024-04-12 14:46:30","title":"First combined tuning on transverse kinematic imbalance data with and without pion production constraints","abstract":"We present the first global tuning, using GENIE, of four transverse kinematic imbalance measurements of neutrino-hydrocarbon scattering, both with and without pion final states, from the T2K and MINERvA experiments. As a proof of concept, we have simultaneously tuned the initial state and final-state interaction models (SF-LFG and hA, respectively), producing a new effective theory that more accurately describes the data.","sentences":["We present the first global tuning, using GENIE, of four transverse kinematic imbalance measurements of neutrino-hydrocarbon scattering, both with and without pion final states, from the T2K and MINERvA experiments.","As a proof of concept, we have simultaneously tuned the initial state and final-state interaction models (SF-LFG and hA, respectively), producing a new effective theory that more accurately describes the data."],"url":"http://arxiv.org/abs/2404.08510v1","category":"hep-ex"}
{"created":"2024-04-12 13:00:06","title":"OccGaussian: 3D Gaussian Splatting for Occluded Human Rendering","abstract":"Rendering dynamic 3D human from monocular videos is crucial for various applications such as virtual reality and digital entertainment. Most methods assume the people is in an unobstructed scene, while various objects may cause the occlusion of body parts in real-life scenarios. Previous method utilizing NeRF for surface rendering to recover the occluded areas, but it requiring more than one day to train and several seconds to render, failing to meet the requirements of real-time interactive applications. To address these issues, we propose OccGaussian based on 3D Gaussian Splatting, which can be trained within 6 minutes and produces high-quality human renderings up to 160 FPS with occluded input. OccGaussian initializes 3D Gaussian distributions in the canonical space, and we perform occlusion feature query at occluded regions, the aggregated pixel-align feature is extracted to compensate for the missing information. Then we use Gaussian Feature MLP to further process the feature along with the occlusion-aware loss functions to better perceive the occluded area. Extensive experiments both in simulated and real-world occlusions, demonstrate that our method achieves comparable or even superior performance compared to the state-of-the-art method. And we improving training and inference speeds by 250x and 800x, respectively. Our code will be available for research purposes.","sentences":["Rendering dynamic 3D human from monocular videos is crucial for various applications such as virtual reality and digital entertainment.","Most methods assume the people is in an unobstructed scene, while various objects may cause the occlusion of body parts in real-life scenarios.","Previous method utilizing NeRF for surface rendering to recover the occluded areas, but it requiring more than one day to train and several seconds to render, failing to meet the requirements of real-time interactive applications.","To address these issues, we propose OccGaussian based on 3D Gaussian Splatting, which can be trained within 6 minutes and produces high-quality human renderings up to 160 FPS with occluded input.","OccGaussian initializes 3D Gaussian distributions in the canonical space, and we perform occlusion feature query at occluded regions, the aggregated pixel-align feature is extracted to compensate for the missing information.","Then we use Gaussian Feature MLP to further process the feature along with the occlusion-aware loss functions to better perceive the occluded area.","Extensive experiments both in simulated and real-world occlusions, demonstrate that our method achieves comparable or even superior performance compared to the state-of-the-art method.","And we improving training and inference speeds by 250x and 800x, respectively.","Our code will be available for research purposes."],"url":"http://arxiv.org/abs/2404.08449v1","category":"cs.CV"}
{"created":"2024-04-12 12:46:25","title":"Fast giant flares in discs around supermassive black holes","abstract":"We study the thermal stability of non-self-gravitating turbulent $\\alpha$ discs around supermassive black holes (SMBHs) to test a new type of high-amplitude active galactic nuclei (AGN) flares. On calculating discs structures, we compute the critical points of stability curves for discs around SMBH, which cover a wide range of accretion rates and resemble the shape of a $\\xi$ curve. We find that there are values of the disc parameters that favour the transition of a disc ring from a recombined cool state to a hot, fully ionised, advection dominated, geometrically thick state with higher viscosity parameter $\\alpha$. For SMBH with masses $\\sim 10^6-10^8 M_\\odot$, such a flare can occur in the geometrically thin and optically thick neutral disc with convective energy transfer through the disc thickness surrounding a radiatively inefficient accretion flow. When self-gravity effects are negligible, the duration of a flare and the associated mass exhibit a positive correlation with the truncation radius of the geometrically thin disc prior to the flare. According to our rough estimates, $\\sim 4-3000 M_\\odot$ can be involved in a giant flare, i.e. can be accreted or entrained with an outflow lasting 1 to 400 years, if the flare is triggered somewhere between $60$ and $600$ gravitational radii in a disc around SMBH with $10^7 M_\\odot$. The accretion rate on SMBH peaks at a super-Eddington value about ten times faster. The peak effective disc temperature at the trigger radius is $\\sim 10^5\\,$K, but it can be obscured by an optically thick outflow that reprocesses the emission to longer wavelengths. Such a transfer of disc state could trigger a massive outburst, similar to that following a tidal disruption event.","sentences":["We study the thermal stability of non-self-gravitating turbulent $\\alpha$ discs around supermassive black holes (SMBHs) to test a new type of high-amplitude active galactic nuclei (AGN) flares.","On calculating discs structures, we compute the critical points of stability curves for discs around SMBH, which cover a wide range of accretion rates and resemble the shape of a $\\xi$ curve.","We find that there are values of the disc parameters that favour the transition of a disc ring from a recombined cool state to a hot, fully ionised, advection dominated, geometrically thick state with higher viscosity parameter $\\alpha$. For SMBH with masses $\\sim 10^6-10^8 M_\\odot$, such a flare can occur in the geometrically thin and optically thick neutral disc with convective energy transfer through the disc thickness surrounding a radiatively inefficient accretion flow.","When self-gravity effects are negligible, the duration of a flare and the associated mass exhibit a positive correlation with the truncation radius of the geometrically thin disc prior to the flare.","According to our rough estimates, $\\sim 4-3000 M_\\odot$ can be involved in a giant flare, i.e. can be accreted or entrained with an outflow lasting 1 to 400 years, if the flare is triggered somewhere between $60$ and $600$ gravitational radii in a disc around SMBH with $10^7 M_\\odot$.","The accretion rate on SMBH peaks at a super-Eddington value about ten times faster.","The peak effective disc temperature at the trigger radius is $\\sim 10^5\\,$K, but it can be obscured by an optically thick outflow that reprocesses the emission to longer wavelengths.","Such a transfer of disc state could trigger a massive outburst, similar to that following a tidal disruption event."],"url":"http://arxiv.org/abs/2404.08441v1","category":"astro-ph.HE"}
{"created":"2024-04-12 12:43:12","title":"Equilibrium tides and magnetic activity in stars with close-by massive planets. The intriguing case of WASP-18","abstract":"WASP-18 is an F6V star that hosts a planet with a mass of about 10 Jupiter masses and an orbital period of 0.94 days. In spite of its relatively fast rotation and young age, the star remains undetected in X-rays, thus implying a very low level of magnetic activity. To account for such unexpected properties, we propose a mechanism that modifies the internal stratification and the photospheric magnetic activity of a late-type main sequence star with a close-by massive planet based on the action of the equilibrium tide. We speculate that the horizontal flow produced by the equilibrium tide may interact with the convective plumes in the overshoot layer below the stellar outer convective envelope. The interaction is characterized by a very high Reynolds number leading to the development of turbulent boundary layers at the surface of such structures, whereas turbulent wakes extend over most of the overshoot layer that they straddle. We propose that such a tidally induced turbulence can lead to a reduction of the filling factor of the downdrafts in the overshoot layer. As a consequence, the absolute value of the sub-adiabatic gradient increases in that layer hindering the emergence of magnetic flux tubes responsible for the formation of photospheric starspots. We conjecture that this process is occurring in WASP-18, thus providing a possible mechanism to account for the very low level of magnetic activity observed for such a planet host.","sentences":["WASP-18 is an F6V star that hosts a planet with a mass of about 10 Jupiter masses and an orbital period of 0.94 days.","In spite of its relatively fast rotation and young age, the star remains undetected in X-rays, thus implying a very low level of magnetic activity.","To account for such unexpected properties, we propose a mechanism that modifies the internal stratification and the photospheric magnetic activity of a late-type main sequence star with a close-by massive planet based on the action of the equilibrium tide.","We speculate that the horizontal flow produced by the equilibrium tide may interact with the convective plumes in the overshoot layer below the stellar outer convective envelope.","The interaction is characterized by a very high Reynolds number leading to the development of turbulent boundary layers at the surface of such structures, whereas turbulent wakes extend over most of the overshoot layer that they straddle.","We propose that such a tidally induced turbulence can lead to a reduction of the filling factor of the downdrafts in the overshoot layer.","As a consequence, the absolute value of the sub-adiabatic gradient increases in that layer hindering the emergence of magnetic flux tubes responsible for the formation of photospheric starspots.","We conjecture that this process is occurring in WASP-18, thus providing a possible mechanism to account for the very low level of magnetic activity observed for such a planet host."],"url":"http://arxiv.org/abs/2404.08439v1","category":"astro-ph.EP"}
{"created":"2024-04-12 12:32:50","title":"Towards a spatial cat state of a massive pendulum","abstract":"We propose an experiment for constructing a spatial cat state of a suspended mirror with an order of $\\mathcal{O}$(mg). The mirror is set at the center of two mirrors, creating two optical cavities and optical springs. The induced potential exhibits a double-well shape, and its deformation resembles a second-order phase transition as a function of laser power. We estimate an adiabatic condition for the ground state wave function to metamorphose from a localized state at the origin to a spatial cat state within the double-well potential, within a coherence time determined by mechanical and environmental noises. Our estimation suggests that such a construction is possible if we can provide an ultra-high finesse optical cavity with $F = 2.5 \\times 10^5$ and a length of $0.3$ cm, along with a shot-noise-limited laser at $7.9$ nW. The necessary mechanical coherence time is approximately one second.","sentences":["We propose an experiment for constructing a spatial cat state of a suspended mirror with an order of $\\mathcal{O}$(mg).","The mirror is set at the center of two mirrors, creating two optical cavities and optical springs.","The induced potential exhibits a double-well shape, and its deformation resembles a second-order phase transition as a function of laser power.","We estimate an adiabatic condition for the ground state wave function to metamorphose from a localized state at the origin to a spatial cat state within the double-well potential, within a coherence time determined by mechanical and environmental noises.","Our estimation suggests that such a construction is possible if we can provide an ultra-high finesse optical cavity with $F = 2.5 \\times 10^5$ and a length of $0.3$ cm, along with a shot-noise-limited laser at $7.9$ nW. The necessary mechanical coherence time is approximately one second."],"url":"http://arxiv.org/abs/2404.08435v1","category":"quant-ph"}
{"created":"2024-04-12 12:27:06","title":"Electromagnetic fields in low-energy heavy-ion collisions with baryon stopping","abstract":"We investigate the impact of baryon stopping on the temporal evolution of electromagnetic fields in vacuum at low-energy Au+Au collisions with $\\sqrt{s_{NN}} = 4$-$20$ GeV. Baryon stopping is incorporated into the Monte-Carlo Glauber model by employing a parameterized velocity profile of participant nucleons with non-zero deceleration. The presence of these decelerating participants leads to noticeable changes in the centrality and $\\sqrt{s_{NN}}$ dependence of electromagnetic fields compared to scenarios with vanishing deceleration. The influence of baryon stopping differs for electric and magnetic fields, also exhibiting variations across their components. We observe slight alteration in the approximate linear dependency of field strengths with $\\sqrt{s_{NN}}$ in the presence of deceleration. Additionally, the longitudinal component of the electric field at late times becomes significant in the presence of baryon stopping.","sentences":["We investigate the impact of baryon stopping on the temporal evolution of electromagnetic fields in vacuum at low-energy Au+Au collisions with $\\sqrt{s_{NN}} = 4$-$20$ GeV. Baryon stopping is incorporated into the Monte-Carlo Glauber model by employing a parameterized velocity profile of participant nucleons with non-zero deceleration.","The presence of these decelerating participants leads to noticeable changes in the centrality and $\\sqrt{s_{NN}}$ dependence of electromagnetic fields compared to scenarios with vanishing deceleration.","The influence of baryon stopping differs for electric and magnetic fields, also exhibiting variations across their components.","We observe slight alteration in the approximate linear dependency of field strengths with $\\sqrt{s_{NN}}$ in the presence of deceleration.","Additionally, the longitudinal component of the electric field at late times becomes significant in the presence of baryon stopping."],"url":"http://arxiv.org/abs/2404.08431v1","category":"nucl-th"}
{"created":"2024-04-12 12:17:25","title":"confintROB Package: Confindence Intervals in robust linear mixed models","abstract":"Statistical inference is a major scientific endeavor for many researchers. In terms of inferential methods implemented to mixed-effects models, significant progress has been made in the R software. However, these advances primarily concern classical estimators (ML, REML) and mainly focus on fixed effects. In the confintROB package, we have implemented various bootstrap methods for computing confidence intervals (CIs) not only for fixed effects but also for variance components. These methods can be implemented with the widely used lmer function from the lme4 package, as well as with the rlmer function from the robustlmm package and the varComprob function from the robustvarComp package. These functions implement robust estimation methods suitable for data with outliers. The confintROB package implements the Wald method for fixed effects, whereas for both fixed effects and variance components, two bootstrap methods are implemented: the parametric bootstrap and the wild bootstrap. Moreover, the confintROB package can obtain both the percentile and the bias-corrected accelerated versions of CIs.","sentences":["Statistical inference is a major scientific endeavor for many researchers.","In terms of inferential methods implemented to mixed-effects models, significant progress has been made in the R software.","However, these advances primarily concern classical estimators (ML, REML) and mainly focus on fixed effects.","In the confintROB package, we have implemented various bootstrap methods for computing confidence intervals (CIs) not only for fixed effects but also for variance components.","These methods can be implemented with the widely used lmer function from the lme4 package, as well as with the rlmer function from the robustlmm package and the varComprob function from the robustvarComp package.","These functions implement robust estimation methods suitable for data with outliers.","The confintROB package implements the Wald method for fixed effects, whereas for both fixed effects and variance components, two bootstrap methods are implemented: the parametric bootstrap and the wild bootstrap.","Moreover, the confintROB package can obtain both the percentile and the bias-corrected accelerated versions of CIs."],"url":"http://arxiv.org/abs/2404.08426v1","category":"stat.ME"}
{"created":"2024-04-12 12:11:09","title":"The local-to-global principle via topological properties of the Balmer-Favi support","abstract":"Following the theory of stratification of tensor triangulated categories via Balmer-Favi support inaugurated by Barthel, Heard and Sanders, we prove the local versions of the well-known statements that the Balmer spectrum being noetherian or profinite scattered implies the local-to-global principle.   That is, given an object $t$ of a tensor triangulated category $\\mathcal{T}$ we show that if the Balmer-Favi support $\\text{Supp}(t)$ is a noetherian space, then the local-to-global principle holds for $t$. In the case where the Balmer spectrum $\\text{Spc}(\\mathcal{T}^c)$ is profinite, if the support $\\text{Supp}(t)$ is scattered then the local-to-global principle holds for the object $t$.   We conclude with an application of the last result to the examination of the support of injective superdecomposable modules in the derived category of an absolutely flat ring which is not semi-artinian.","sentences":["Following the theory of stratification of tensor triangulated categories via Balmer-Favi support inaugurated by Barthel, Heard and Sanders, we prove the local versions of the well-known statements that the Balmer spectrum being noetherian or profinite scattered implies the local-to-global principle.   ","That is, given an object $t$ of a tensor triangulated category $\\mathcal{T}$ we show that if the Balmer-Favi support $\\text{Supp}(t)$ is a noetherian space, then the local-to-global principle holds for $t$. In the case where the Balmer spectrum $\\text{Spc}(\\mathcal{T}^c)$ is profinite, if the support $\\text{Supp}(t)$ is scattered then the local-to-global principle holds for the object $t$.   We conclude with an application of the last result to the examination of the support of injective superdecomposable modules in the derived category of an absolutely flat ring which is not semi-artinian."],"url":"http://arxiv.org/abs/2404.08422v1","category":"math.CT"}
{"created":"2024-04-12 12:05:30","title":"Formation of primordial black hole binaries and their merger rates","abstract":"We review the theory behind the formation of primordial black hole binaries and their merger rates. We consider the binary formation in the early and late Universe, emphasising the former as it gives the dominant contribution of the present primordial black hole merger rate. The binaries formed in the early Universe are highly eccentric and get easily disrupted by interactions with other primordial black holes. We discuss in detail how the suppression of the merger rate arising from such interactions can be estimated and how such interactions lead to the formation of another, much harder, binary population that contributes to the present merger rate if more than 10% of dark matter consists of primordial black holes with a narrow mass distribution.","sentences":["We review the theory behind the formation of primordial black hole binaries and their merger rates.","We consider the binary formation in the early and late Universe, emphasising the former as it gives the dominant contribution of the present primordial black hole merger rate.","The binaries formed in the early Universe are highly eccentric and get easily disrupted by interactions with other primordial black holes.","We discuss in detail how the suppression of the merger rate arising from such interactions can be estimated and how such interactions lead to the formation of another, much harder, binary population that contributes to the present merger rate if more than 10% of dark matter consists of primordial black holes with a narrow mass distribution."],"url":"http://arxiv.org/abs/2404.08416v1","category":"astro-ph.CO"}
{"created":"2024-04-12 11:43:05","title":"Evidence of the gamma-ray counterpart from nova FM Cir with F ermi-LAT","abstract":"We report the analysis results of X-ray and gamma-ray data of the nova FM Cir taken by Swift and Fermi-LAT. The gamma-ray emission from FM Cir can be identified with a significance level of 3sigma within 40 days after the nova eruption (2018 January 19) while we bin the light curve per day. The significance can further exceed 4 sigma confidence level if we accumulate longer time (i.e., 20 days) to bin the light curve. The gamma-ray counterpart could be identified with a Test Statistic (TS) above 4 until 180 days after the eruption. The duration of the gamma-ray detection was longer than those reported in the previous studies of the other novae detected in the GeV range. The significant X-ray emission was observed after the gamma-ray flux level fell below the sensitivity of Fermi-LAT. The hardness ratio of the X-ray emission decreased rapidly with time, and the spectra were dominated by blackbody radiation from the hot white dwarf. Except for the longer duration of the gamma-ray emission, the multi-wavelength properties of FM Cir closely resemble those of other novae detected in the GeV range.","sentences":["We report the analysis results of X-ray and gamma-ray data of the nova FM Cir taken by Swift and Fermi-LAT.","The gamma-ray emission from FM Cir can be identified with a significance level of 3sigma within 40 days after the nova eruption (2018 January 19) while we bin the light curve per day.","The significance can further exceed 4 sigma confidence level if we accumulate longer time (i.e., 20 days) to bin the light curve.","The gamma-ray counterpart could be identified with a Test Statistic (TS) above 4 until 180 days after the eruption.","The duration of the gamma-ray detection was longer than those reported in the previous studies of the other novae detected in the GeV range.","The significant X-ray emission was observed after the gamma-ray flux level fell below the sensitivity of Fermi-LAT.","The hardness ratio of the X-ray emission decreased rapidly with time, and the spectra were dominated by blackbody radiation from the hot white dwarf.","Except for the longer duration of the gamma-ray emission, the multi-wavelength properties of FM Cir closely resemble those of other novae detected in the GeV range."],"url":"http://arxiv.org/abs/2404.08409v1","category":"astro-ph.HE"}
{"created":"2024-04-12 10:09:06","title":"Estimation and Inference for Three-Dimensional Panel Data Models","abstract":"Hierarchical panel data models have recently garnered significant attention. This study contributes to the relevant literature by introducing a novel three-dimensional (3D) hierarchical panel data model, which integrates panel regression with three sets of latent factor structures: one set of global factors and two sets of local factors. Instead of aggregating latent factors from various nodes, as seen in the literature of distributed principal component analysis (PCA), we propose an estimation approach capable of recovering the parameters of interest and disentangling latent factors at different levels and across different dimensions. We establish an asymptotic theory and provide a bootstrap procedure to obtain inference for the parameters of interest while accommodating various types of cross-sectional dependence and time series autocorrelation. Finally, we demonstrate the applicability of our framework by examining productivity convergence in manufacturing industries worldwide.","sentences":["Hierarchical panel data models have recently garnered significant attention.","This study contributes to the relevant literature by introducing a novel three-dimensional (3D) hierarchical panel data model, which integrates panel regression with three sets of latent factor structures: one set of global factors and two sets of local factors.","Instead of aggregating latent factors from various nodes, as seen in the literature of distributed principal component analysis (PCA), we propose an estimation approach capable of recovering the parameters of interest and disentangling latent factors at different levels and across different dimensions.","We establish an asymptotic theory and provide a bootstrap procedure to obtain inference for the parameters of interest while accommodating various types of cross-sectional dependence and time series autocorrelation.","Finally, we demonstrate the applicability of our framework by examining productivity convergence in manufacturing industries worldwide."],"url":"http://arxiv.org/abs/2404.08365v1","category":"econ.EM"}
{"created":"2024-04-12 09:39:03","title":"Comment on 'Exact-corrected confidence interval for risk difference in noninferiority binomial trials'","abstract":"The article by Hawila & Berg (2023) that is going to be commented presents four relevant problems, apart from other less important ones that are also cited. First, the title is incorrect, since it leads readers to believe that the confidence interval defined is exact when in fact it is asymptotic. Second, contrary to what is assumed by the authors of the article, the statistic that they define is not monotonic in delta. But it is fundamental that this property is verified, as the authors themselves recognize. Third, the inferences provided by the confidence interval proposed may be incoherent, which could lead the scientific community to reach incorrect conclusions in any practical application. For example, for fixed data it might happen that a certain delta value is within the 90%-confidence interval, but outside the 95%-confidence interval. Fourth, the authors do not validate its statistic through a simulation with diverse (and credible) values of the parameters involved. In fact, one of its two examples is for an alpha error of 70%!","sentences":["The article by Hawila & Berg (2023) that is going to be commented presents four relevant problems, apart from other less important ones that are also cited.","First, the title is incorrect, since it leads readers to believe that the confidence interval defined is exact when in fact it is asymptotic.","Second, contrary to what is assumed by the authors of the article, the statistic that they define is not monotonic in delta.","But it is fundamental that this property is verified, as the authors themselves recognize.","Third, the inferences provided by the confidence interval proposed may be incoherent, which could lead the scientific community to reach incorrect conclusions in any practical application.","For example, for fixed data it might happen that a certain delta value is within the 90%-confidence interval, but outside the 95%-confidence interval.","Fourth, the authors do not validate its statistic through a simulation with diverse (and credible) values of the parameters involved.","In fact, one of its two examples is for an alpha error of 70%!"],"url":"http://arxiv.org/abs/2404.08352v1","category":"stat.ME"}
{"created":"2024-04-12 07:48:44","title":"Brane expansions for anti-symmetric line operator index","abstract":"Based on the D5-brane realization of Wilson line operators in anti-symmetric representations, we propose brane expansion formulas for $I_{N,k}$, the Schur index of ${\\cal N}=4$ $U(N)$ SYM decorated by line operators in the anti-symmetric representation of rank $k$. For the large $N$ index $I_{\\infty,k}$ we propose a double-sum expansion, and for finite $N$ index $I_{N,k}$ we propose a quadruple-sum expansion. Objects causing finite $k$ and finite $N$ corrections are disk D3-branes ending on the D5-brane.","sentences":["Based on the D5-brane realization of Wilson line operators in anti-symmetric representations, we propose brane expansion formulas for $I_{N,k}$, the Schur index of ${\\cal N}=4$ $U(N)$ SYM decorated by line operators in the anti-symmetric representation of rank $k$.","For the large $N$ index $I_{\\infty,k}$ we propose a double-sum expansion, and for finite $N$ index $I_{N,k}$ we propose a quadruple-sum expansion.","Objects causing finite $k$ and finite $N$ corrections are disk D3-branes ending on the D5-brane."],"url":"http://arxiv.org/abs/2404.08302v1","category":"hep-th"}
{"created":"2024-04-12 07:44:27","title":"Efficient GPU Implementation of Static and Incrementally Expanding DF-P PageRank for Dynamic Graphs","abstract":"PageRank is a widely used centrality measure that \"ranks\" vertices in a graph by considering the connections and their importance. In this report, we first introduce one of the most efficient GPU implementations of Static PageRank, which recomputes PageRank scores from scratch. It uses a synchronous pull-based atomics-free PageRank computation, with the low and high in-degree vertices being partitioned and processed by two separate kernels. Next, we present our GPU implementation of incrementally expanding (and contracting) Dynamic Frontier with Pruning (DF-P) PageRank, which processes only a subset of vertices likely to change ranks. It is based on Static PageRank, and uses an additional partitioning between low and high out-degree vertices for incremental expansion of the set of affected vertices with two additional kernels. On a server with an NVIDIA A100 GPU, our Static PageRank outperforms Hornet and Gunrock's PageRank implementations by 31x and 5.9x respectively. On top of the above, DF-P PageRank outperforms Static PageRank by 2.1x on real-world dynamic graphs, and by 3.1x on large static graphs with random batch updates.","sentences":["PageRank is a widely used centrality measure that \"ranks\" vertices in a graph by considering the connections and their importance.","In this report, we first introduce one of the most efficient GPU implementations of Static PageRank, which recomputes PageRank scores from scratch.","It uses a synchronous pull-based atomics-free PageRank computation, with the low and high in-degree vertices being partitioned and processed by two separate kernels.","Next, we present our GPU implementation of incrementally expanding (and contracting)","Dynamic Frontier with Pruning (DF-P) PageRank, which processes only a subset of vertices likely to change ranks.","It is based on Static PageRank, and uses an additional partitioning between low and high out-degree vertices for incremental expansion of the set of affected vertices with two additional kernels.","On a server with an NVIDIA A100 GPU, our Static PageRank outperforms Hornet and Gunrock's PageRank implementations by 31x and 5.9x respectively.","On top of the above, DF-P PageRank outperforms Static PageRank by 2.1x on real-world dynamic graphs, and by 3.1x on large static graphs with random batch updates."],"url":"http://arxiv.org/abs/2404.08299v1","category":"cs.DC"}
{"created":"2024-04-12 07:21:11","title":"Energy-modified Leverage Sampling for Radio Map Construction via Matrix Completion","abstract":"This paper explores an energy-modified leverage sampling strategy for matrix completion in radio map construction. The main goal is to address potential identifiability issues in matrix completion with sparse observations by using a probabilistic sampling approach. Although conventional leverage sampling is commonly employed for designing sampling patterns, it often assigns high sampling probability to locations with low received signal strength (RSS) values, leading to a low sampling efficiency. Theoretical analysis demonstrates that the leverage score produces pseudo images of sources, and in the regions around the source locations, the leverage probability is asymptotically consistent with the RSS. Based on this finding, an energy-modified leverage probability-based sampling strategy is investigated for efficient sampling. Numerical demonstrations indicate that the proposed sampling strategy can decrease the normalized mean squared error (NMSE) of radio map construction by more than 10% for both matrix completion and interpolation-assisted matrix completion schemes, compared to conventional methods.","sentences":["This paper explores an energy-modified leverage sampling strategy for matrix completion in radio map construction.","The main goal is to address potential identifiability issues in matrix completion with sparse observations by using a probabilistic sampling approach.","Although conventional leverage sampling is commonly employed for designing sampling patterns, it often assigns high sampling probability to locations with low received signal strength (RSS) values, leading to a low sampling efficiency.","Theoretical analysis demonstrates that the leverage score produces pseudo images of sources, and in the regions around the source locations, the leverage probability is asymptotically consistent with the RSS.","Based on this finding, an energy-modified leverage probability-based sampling strategy is investigated for efficient sampling.","Numerical demonstrations indicate that the proposed sampling strategy can decrease the normalized mean squared error (NMSE) of radio map construction by more than 10% for both matrix completion and interpolation-assisted matrix completion schemes, compared to conventional methods."],"url":"http://arxiv.org/abs/2404.08286v1","category":"eess.SP"}
{"created":"2024-04-12 03:34:56","title":"Quantum geometric tensor and the topological characterization of the extended Su-Schrieffer-Heeger model","abstract":"We investigate the quantum metric and topological Euler number in a cyclically modulated Su-Schrieffer-Heeger (SSH) model with long-range hopping terms. By computing the quantum geometry tensor, we derive exactly expressions for the quantum metric and Berry curvature of the energy band electrons, and we obtain the phase diagram of the model marked by the first Chern number. Furthermore, we also obtain the topological Euler number of the energy band based on the Gauss-Bonnet theorem on the topological characterization of the closed Bloch states manifold in the first Brillouin zone. However, some regions where the Berry curvature is identically zero in the first Brillouin zone results in the degeneracy of the quantum metric, which leads to ill-defined non-integer topological Euler numbers. Nevertheless, the non-integer \"Euler number\" provides valuable insights and provide an upper bound for absolute values of the Chern numbers.","sentences":["We investigate the quantum metric and topological Euler number in a cyclically modulated Su-Schrieffer-Heeger (SSH) model with long-range hopping terms.","By computing the quantum geometry tensor, we derive exactly expressions for the quantum metric and Berry curvature of the energy band electrons, and we obtain the phase diagram of the model marked by the first Chern number.","Furthermore, we also obtain the topological Euler number of the energy band based on the Gauss-Bonnet theorem on the topological characterization of the closed Bloch states manifold in the first Brillouin zone.","However, some regions where the Berry curvature is identically zero in the first Brillouin zone results in the degeneracy of the quantum metric, which leads to ill-defined non-integer topological Euler numbers.","Nevertheless, the non-integer \"Euler number\" provides valuable insights and provide an upper bound for absolute values of the Chern numbers."],"url":"http://arxiv.org/abs/2404.08222v1","category":"cond-mat.str-el"}
