<!doctype html>
<html>
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <script src="https://cdn.tailwindcss.com"></script>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css" integrity="sha384-vKruj+a13U8yHIkAyGgK1J3ArTLzrFGBbBc0tDp4ad/EyewESeXE/Iv67Aj8gKZ0" crossorigin="anonymous">
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.js" integrity="sha384-PwRUT/YqbnEjkZO0zZxNqcxACrXe+j766U2amXcgMg5457rve2Y7I6ZJSm2A0mS4" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/@alpinejs/collapse@3.x.x/dist/cdn.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/alpinejs@3.x.x/dist/cdn.min.js"></script>
  <link href='https://fonts.googleapis.com/css?family=IBM Plex Mono' rel='stylesheet'>
</head>
<style>
  .mono-font {
    font-family: 'IBM Plex Mono';
  }
</style>
<body>
  <div class="relative mx-auto h-full max-w-2xl text-md">
    <table class="table-auto">
      <tbody>
        <tr>
          <td></td>
          <td>
            <h1 class="text-4xl pt-4 font-bold mono-font"><a class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800" href=https://sullivantm.com>Tim's</a> Arxiv FrontPage</h1>
            <br>
            <p>Generated on 2024-04-09.</p><br/>
            <p class="text-sm text-gray-500 pt-2">This frontpage is generated by scraping new papers on Arxiv and using an embedding model to find papers matching topics I'm interested in. Currently, the false positive rate is fairly high. The repo is <a class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm" href=https://github.com/tims457/arxiv-frontpage/>here.</a> Forked and customized from<a class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm" href=https://koaning.github.io/arxiv-frontpage/> this project </a></p>
            <br>
          </td>
        </tr><tr>
          <td></td>
          <td>
            <h2 class="text-2xl tracking-tight pt-4 font-bold">Artificial General Intelligence</h2>
          </td>
        </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-04-08</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Long-horizon Locomotion and Manipulation on a Quadrupedal Robot with Large Language Models
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>We present a large language model (LLM) based system to empower quadrupedal robots with problem-solving abilities for long-horizon tasks beyond short-term motions.Long-horizon tasks for quadrupeds are challenging since they require both a high-level understanding of the semantics of the problem for task planning and a broad range of locomotion and manipulation skills to interact with the environment.<span class='px-1 mx-1 bg-yellow-200'>Our system builds a high-level reasoning layer with large language models, which generates hybrid discrete-continuous plans as robot code from task descriptions. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.836</span></span>It comprises multiple LLM agents: a semantic planner for sketching a plan, a parameter calculator for predicting arguments in the plan, and a code generator to convert the plan into executable robot code.At the low level, we adopt reinforcement learning to train a set of motion planning and control skills to unleash the flexibility of quadrupeds for rich environment interactions.Our system is tested on long-horizon tasks that are infeasible to complete with one single skill.Simulation and real-world experiments show that it successfully figures out multi-step strategies and demonstrates non-trivial behaviors, including building tools or notifying a human for help.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2404.05291v1' target="_blank">
                  link
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-04-08</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Towards Objectively Benchmarking Social Intelligence for Language Agents at Action Level
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p><span class='px-1 mx-1 bg-yellow-200'>Prominent large language models have exhibited human-level performance in many domains, even enabling the derived agents to simulate human and social interactions. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.83</span></span><span class='px-1 mx-1 bg-yellow-200'>While practical works have substantiated the practicability of grounding language agents in sandbox simulation or embodied simulators, current social intelligence benchmarks either stay at the language level or use subjective metrics. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.836</span></span>In pursuit of a more realistic and objective evaluation, we introduce the Social Tasks in Sandbox Simulation (STSS) benchmark, which assesses language agents \textbf{objectively} at the \textbf{action level} by scrutinizing the goal achievements within the multi-agent simulation.Additionally, we sample conversation scenarios to build a language-level benchmark to provide an economically prudent preliminary evaluation and align with prevailing benchmarks.To gauge the significance of agent architecture, we implement a target-driven planning (TDP) module as an adjunct to the existing agent.Our evaluative findings highlight that the STSS benchmark is challenging for state-of-the-art language agents.Furthermore, it effectively discriminates between distinct language agents, suggesting its usefulness as a benchmark for evaluating both language models and agent architectures.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2404.05337v1' target="_blank">
                  link
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-04-08</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                PerkwE_COQA: enhance Persian Conversational Question Answering by combining contextual keyword extraction with Large Language Models
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Smart cities need the involvement of their residents to enhance quality of life.Conversational query-answering is an emerging approach for user engagement.<span class='px-1 mx-1 bg-yellow-200'>There is an increasing demand of an advanced conversational question-answering that goes beyond classic systems. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.821</span></span>Existing approaches have shown that LLMs offer promising capabilities for CQA, but may struggle to capture the nuances of conversational contexts.The new approach involves understanding the content and engaging in a multi-step conversation with the user to fulfill their needs.This paper presents a novel method to elevate the performance of Persian Conversational question-answering (CQA) systems.It combines the strengths of Large Language Models (LLMs) with contextual keyword extraction.Our method extracts keywords specific to the conversational flow, providing the LLM with additional context to understand the user's intent and generate more relevant and coherent responses.We evaluated the effectiveness of this combined approach through various metrics, demonstrating significant improvements in CQA performance compared to an LLM-only baseline.The proposed method effectively handles implicit questions, delivers contextually relevant answers, and tackles complex questions that rely heavily on conversational context.The findings indicate that our method outperformed the evaluation benchmarks up to 8% higher than existing methods and the LLM-only baseline.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2404.05406v1' target="_blank">
                  link
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-04-08</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                360°REA: Towards A Reusable Experience Accumulation with 360° Assessment for Multi-Agent System
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p><span class='px-1 mx-1 bg-yellow-200'>Large language model agents have demonstrated remarkable advancements across various complex tasks. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.822</span></span>Recent works focus on optimizing the agent team or employing self-reflection to iteratively solve complex tasks.Since these agents are all based on the same LLM, only conducting self-evaluation or removing underperforming agents does not substantively enhance the capability of the agents.We argue that a comprehensive evaluation and accumulating experience from evaluation feedback is an effective approach to improving system performance.In this paper, we propose Reusable Experience Accumulation with 360{\deg} Assessment (360{\deg}REA), a hierarchical multi-agent framework inspired by corporate organizational practices.The framework employs a novel 360{\deg} performance assessment method for multi-perspective performance evaluation with fine-grained assessment.To enhance the capability of agents in addressing complex tasks, we introduce dual-level experience pool for agents to accumulate experience through fine-grained assessment.Extensive experiments on complex task datasets demonstrate the effectiveness of 360{\deg}REA.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2404.05569v1' target="_blank">
                  link
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-04-08</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Self-Explainable Affordance Learning with Embodied Caption
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>In the field of visual affordance learning, previous methods mainly used abundant images or videos that delineate human behavior patterns to identify action possibility regions for object manipulation, with a variety of applications in robotic tasks.However, they encounter a main challenge of action ambiguity, illustrated by the vagueness like whether to beat or carry a drum, and the complexities involved in processing intricate scenes.Moreover, it is important for human intervention to rectify robot errors in time.To address these issues, we introduce Self-Explainable Affordance learning (SEA) with embodied caption.<span class='px-1 mx-1 bg-yellow-200'>This innovation enables robots to articulate their intentions and bridge the gap between explainable vision-language caption and visual affordance learning. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.835</span></span>Due to a lack of appropriate dataset, we unveil a pioneering dataset and metrics tailored for this task, which integrates images, heatmaps, and embodied captions.Furthermore, we propose a novel model to effectively combine affordance grounding with self-explanation in a simple but efficient manner.Extensive quantitative and qualitative experiments demonstrate our method's effectiveness.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2404.05603v1' target="_blank">
                  link
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-04-08</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Resistive Memory-based Neural Differential Equation Solver for Score-based Diffusion Model
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Human brains image complicated scenes when reading a novel.<span class='px-1 mx-1 bg-yellow-200'>Replicating this imagination is one of the ultimate goals of AI-Generated Content (AIGC). <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.835</span></span>However, current AIGC methods, such as score-based diffusion, are still deficient in terms of rapidity and efficiency.This deficiency is rooted in the difference between the brain and digital computers.Digital computers have physically separated storage and processing units, resulting in frequent data transfers during iterative calculations, incurring large time and energy overheads.This issue is further intensified by the conversion of inherently continuous and analog generation dynamics, which can be formulated by neural differential equations, into discrete and digital operations.Inspired by the brain, we propose a time-continuous and analog in-memory neural differential equation solver for score-based diffusion, employing emerging resistive memory.The integration of storage and computation within resistive memory synapses surmount the von Neumann bottleneck, benefiting the generative speed and energy efficiency.The closed-loop feedback integrator is time-continuous, analog, and compact, physically implementing an infinite-depth neural network.Moreover, the software-hardware co-design is intrinsically robust to analog noise.We experimentally validate our solution with 180 nm resistive memory in-memory computing macros.Demonstrating equivalent generative quality to the software baseline, our system achieved remarkable enhancements in generative speed for both unconditional and conditional generation tasks, by factors of 64.8 and 156.5, respectively.Moreover, it accomplished reductions in energy consumption by factors of 5.2 and 4.1.Our approach heralds a new horizon for hardware solutions in edge computing for generative AI applications.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2404.05648v1' target="_blank">
                  link
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-04-08</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                David and Goliath: An Empirical Evaluation of Attacks and Defenses for QNNs at the Deep Edge
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>ML is shifting from the cloud to the edge.Edge computing reduces the surface exposing private data and enables reliable throughput guarantees in real-time applications.Of the panoply of devices deployed at the edge, resource-constrained MCUs, e.g., Arm Cortex-M, are more prevalent, orders of magnitude cheaper, and less power-hungry than application processors or GPUs.<span class='px-1 mx-1 bg-yellow-200'>Thus, enabling intelligence at the deep edge is the zeitgeist, with researchers focusing on unveiling novel approaches to deploy ANNs on these constrained devices. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.827</span></span>Quantization is a well-established technique that has proved effective in enabling the deployment of neural networks on MCUs; however, it is still an open question to understand the robustness of QNNs in the face of adversarial examples.   To fill this gap, we empirically evaluate the effectiveness of attacks and defenses from (full-precision) ANNs on (constrained) QNNs.Our evaluation includes three QNNs targeting TinyML applications, ten attacks, and six defenses.With this study, we draw a set of interesting findings.First, quantization increases the point distance to the decision boundary and leads the gradient estimated by some attacks to explode or vanish.Second, quantization can act as a noise attenuator or amplifier, depending on the noise magnitude, and causes gradient misalignment.Regarding adversarial defenses, we conclude that input pre-processing defenses show impressive results on small perturbations; however, they fall short as the perturbation increases.At the same time, train-based defenses increase the average point distance to the decision boundary, which holds after quantization.However, we argue that train-based defenses still need to smooth the quantization-shift and gradient misalignment phenomenons to counteract adversarial example transferability to QNNs.All artifacts are open-sourced to enable independent validation of results.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2404.05688v1' target="_blank">
                  link
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td></td>
          <td>
            <h2 class="text-2xl tracking-tight pt-4 font-bold">Collective Intelligence</h2>
          </td>
        </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-04-08</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Decisioning Workshop 2023
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>In a knowledge society, the term knowledge must be considered a core resource for organizations.So, beyond being a medium to progress and to innovate, knowledge is one of our most important resources: something necessary to decide.Organizations that are embracing knowledge retention activities are gaining a competitive advantage.Organizational rearrangements from companies, notably outsourcing, increase a possible loss of knowledge, making knowledge retention an essential need for them.<span class='px-1 mx-1 bg-yellow-200'>When Knowledge is less shared, collaborative decision-making seems harder to obtain insofar as a ``communication breakdown'' characterizes participants' discourse. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.822</span></span>At best, stakeholders have to finda consensus according to their knowledge.Sharing knowledge ensures its retention and catalyzes the construction of this consensus.   Our vision of collaborative decision-making aims not only at increasing the quality of the first parts of the decision-making process: intelligence and design, but also at increasing the acceptance of the choice.<span class='px-1 mx-1 bg-yellow-200'>Intelligence and design will be done by more than one individual and constructed together; the decision is more easily accepted. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.838</span></span>The decided choice will then be shared.Thereby where decision-making could be seen as a constructed model, collaborative decision-making, for us,is seen as the use of socio-technical media to improve decision-making performance and acceptability.The shared decision making is a core activity in a lot of human activities.For example, the sustainable decision-making is the job of not only governments and institutions but also broader society.Recognizing the urgent need for sustainability, we can argue that to realize sustainable development, it must be considered as a decision-making strategy.<span class='px-1 mx-1 bg-yellow-200'>The location of knowledge in the realization of collaborative decision-making has to be regarded insofar as knowledge sharing leads to improve collaborative decision-making: a ``static view'' has to be structured and constitutes the ``collaborative knowledge.'' <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.822</span></span><span class='px-1 mx-1 bg-yellow-200'>Knowledge has an important role in individual decision-making, and we consider that for collaborative decision-making, knowledge has to be shared. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.826</span></span>What is required is a better understanding of the nature of group work''.Knowledge has to be shared, but how do we share knowledge?</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2404.05495v1' target="_blank">
                  link
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td></td>
          <td>
            <h2 class="text-2xl tracking-tight pt-4 font-bold">Complex Systems</h2>
          </td>
        </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-04-08</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Emergent polar order in non-polar mixtures with non-reciprocal interactions
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p><span class='px-1 mx-1 bg-yellow-200'>Phenomenological rules that govern the collective behaviour of complex physical systems are powerful tools because they can make concrete predictions about their universality class based on generic considerations, such as symmetries, conservation laws, and dimensionality. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.828</span></span><span class='px-1 mx-1 bg-yellow-200'>While in most cases such considerations are manifestly ingrained in the constituents, novel phenomenology can emerge when composite units associated with emergent symmetries dominate the behaviour of the system. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.825</span></span>We study a generic class of active matter systems with non-reciprocal interactions and demonstrate the existence of true long-range polar order in two dimensions and above, both at the linear level and by including all relevant nonlinearities in the Renormalization Group sense.We achieve this by uncovering a mapping of our scalar active mixture theory to the Toner-Tu theory of dry polar active matter by employing a suitably defined polar order parameter.We then demonstrate that the complete effective field theory -- which includes all the soft modes and the relevant nonlinear terms -- belongs to the (Burgers-) Kardar-Parisi-Zhang universality class.This classification allows us to prove the stability of the emergent polar long-range order in scalar non-reciprocal mixtures in two dimensions, and hence a conclusive violation of the Mermin-Wagner theorem.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2404.05396v1' target="_blank">
                  link
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-04-08</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Evaluating Interventional Reasoning Capabilities of Large Language Models
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p><span class='px-1 mx-1 bg-yellow-200'>Numerous decision-making tasks require estimating causal effects under interventions on different parts of a system. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.824</span></span>As practitioners consider using large language models (LLMs) to automate decisions, studying their causal reasoning capabilities becomes crucial.A recent line of work evaluates LLMs ability to retrieve commonsense causal facts, but these evaluations do not sufficiently assess how LLMs reason about interventions.Motivated by the role that interventions play in causal inference, in this paper, we conduct empirical analyses to evaluate whether LLMs can accurately update their knowledge of a data-generating process in response to an intervention.We create benchmarks that span diverse causal graphs (e.g., confounding, mediation) and variable types, and enable a study of intervention-based reasoning.These benchmarks allow us to isolate the ability of LLMs to accurately predict changes resulting from their ability to memorize facts or find other shortcuts.Our analysis on four LLMs highlights that while GPT- 4 models show promising accuracy at predicting the intervention effects, they remain sensitive to distracting factors in the prompts.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2404.05545v1' target="_blank">
                  link
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td></td>
          <td>
            <h2 class="text-2xl tracking-tight pt-4 font-bold">Decision Making Under Uncertainty</h2>
          </td>
        </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-04-08</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                What Are the Odds? Improving the foundations of Statistical Model Checking
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p><span class='px-1 mx-1 bg-yellow-200'>Markov decision processes (MDPs) are a fundamental model for decision making under uncertainty. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.874</span></span><span class='px-1 mx-1 bg-yellow-200'>They exhibit non-deterministic choice as well as probabilistic uncertainty. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.83</span></span>Traditionally, verification algorithms assume exact knowledge of the probabilities that govern the behaviour of an MDP.As this assumption is often unrealistic in practice, statistical model checking (SMC) was developed in the past two decades.It allows to analyse MDPs with unknown transition probabilities and provide probably approximately correct (PAC) guarantees on the result.Model-based SMC algorithms sample the MDP and build a model of it by estimating all transition probabilities, essentially for every transition answering the question: ``What are the odds?''However, so far the statistical methods employed by the state of the art SMC algorithms are quite naive.Our contribution are several fundamental improvements to those methods: On the one hand, we survey statistics literature for better concentration inequalities; on the other hand, we propose specialised approaches that exploit our knowledge of the MDP.Our improvements are generally applicable to many kinds of problem statements because they are largely independent of the setting.Moreover, our experimental evaluation shows that they lead to significant gains, reducing the number of samples that the SMC algorithm has to collect by up to two orders of magnitude.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2404.05424v1' target="_blank">
                  link
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-04-08</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Evaluating Interventional Reasoning Capabilities of Large Language Models
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p><span class='px-1 mx-1 bg-yellow-200'>Numerous decision-making tasks require estimating causal effects under interventions on different parts of a system. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.823</span></span>As practitioners consider using large language models (LLMs) to automate decisions, studying their causal reasoning capabilities becomes crucial.A recent line of work evaluates LLMs ability to retrieve commonsense causal facts, but these evaluations do not sufficiently assess how LLMs reason about interventions.Motivated by the role that interventions play in causal inference, in this paper, we conduct empirical analyses to evaluate whether LLMs can accurately update their knowledge of a data-generating process in response to an intervention.We create benchmarks that span diverse causal graphs (e.g., confounding, mediation) and variable types, and enable a study of intervention-based reasoning.These benchmarks allow us to isolate the ability of LLMs to accurately predict changes resulting from their ability to memorize facts or find other shortcuts.Our analysis on four LLMs highlights that while GPT- 4 models show promising accuracy at predicting the intervention effects, they remain sensitive to distracting factors in the prompts.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2404.05545v1' target="_blank">
                  link
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td></td>
          <td>
            <h2 class="text-2xl tracking-tight pt-4 font-bold">Dissipative Adaptation</h2>
          </td>
        </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-04-08</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Energy exchange statistics and fluctuation theorem for non-thermal asymptotic states
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Exchange energy statistics between two bodies at different thermal equilibrium obey the Jarzynski-W\'ojcik fluctuation theorem.The corresponding energy scale factor is the difference of the inverse temperatures associated to the bodies at equilibrium.<span class='px-1 mx-1 bg-yellow-200'>In this work, we consider a dissipative quantum dynamics leading the quantum system towards a, possibly non-thermal, asymptotic state. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.83</span></span>To generalize the Jarzynski-W\'ojcik theorem to non-thermal states, we identify a sufficient condition ${\cal I}$ for the existence of an energy scale factor $\eta^{*}$ that is unique, finite and time-independent, such that the characteristic function of the exchange energy distribution becomes identically equal to $1$ for any time.This $\eta^*$ plays the role of the difference of inverse temperatures.We discuss the physical interpretation of the condition ${\cal I}$, showing that it amounts to an almost complete memory loss of the initial state.The robustness of our results against quantifiable deviations from the validity of ${\cal I}$ is evaluated by experimental studies on a single nitrogen-vacancy center subjected to a sequence of laser pulses and dissipation.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2404.05310v1' target="_blank">
                  link
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td></td>
          <td>
            <h2 class="text-2xl tracking-tight pt-4 font-bold">Neural Ordinary Differential Equations</h2>
          </td>
        </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-04-08</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Resistive Memory-based Neural Differential Equation Solver for Score-based Diffusion Model
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Human brains image complicated scenes when reading a novel.Replicating this imagination is one of the ultimate goals of AI-Generated Content (AIGC).However, current AIGC methods, such as score-based diffusion, are still deficient in terms of rapidity and efficiency.This deficiency is rooted in the difference between the brain and digital computers.Digital computers have physically separated storage and processing units, resulting in frequent data transfers during iterative calculations, incurring large time and energy overheads.This issue is further intensified by the conversion of inherently continuous and analog generation dynamics, which can be formulated by neural differential equations, into discrete and digital operations.<span class='px-1 mx-1 bg-yellow-200'>Inspired by the brain, we propose a time-continuous and analog in-memory neural differential equation solver for score-based diffusion, employing emerging resistive memory. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.825</span></span>The integration of storage and computation within resistive memory synapses surmount the von Neumann bottleneck, benefiting the generative speed and energy efficiency.The closed-loop feedback integrator is time-continuous, analog, and compact, physically implementing an infinite-depth neural network.Moreover, the software-hardware co-design is intrinsically robust to analog noise.We experimentally validate our solution with 180 nm resistive memory in-memory computing macros.Demonstrating equivalent generative quality to the software baseline, our system achieved remarkable enhancements in generative speed for both unconditional and conditional generation tasks, by factors of 64.8 and 156.5, respectively.Moreover, it accomplished reductions in energy consumption by factors of 5.2 and 4.1.Our approach heralds a new horizon for hardware solutions in edge computing for generative AI applications.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2404.05648v1' target="_blank">
                  link
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td></td>
          <td>
            <h2 class="text-2xl tracking-tight pt-4 font-bold">Reinforcement Learning</h2>
          </td>
        </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-04-08</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Long-horizon Locomotion and Manipulation on a Quadrupedal Robot with Large Language Models
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>We present a large language model (LLM) based system to empower quadrupedal robots with problem-solving abilities for long-horizon tasks beyond short-term motions.Long-horizon tasks for quadrupeds are challenging since they require both a high-level understanding of the semantics of the problem for task planning and a broad range of locomotion and manipulation skills to interact with the environment.Our system builds a high-level reasoning layer with large language models, which generates hybrid discrete-continuous plans as robot code from task descriptions.It comprises multiple LLM agents: a semantic planner for sketching a plan, a parameter calculator for predicting arguments in the plan, and a code generator to convert the plan into executable robot code.<span class='px-1 mx-1 bg-yellow-200'>At the low level, we adopt reinforcement learning to train a set of motion planning and control skills to unleash the flexibility of quadrupeds for rich environment interactions. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.842</span></span>Our system is tested on long-horizon tasks that are infeasible to complete with one single skill.Simulation and real-world experiments show that it successfully figures out multi-step strategies and demonstrates non-trivial behaviors, including building tools or notifying a human for help.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2404.05291v1' target="_blank">
                  link
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-04-08</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Humanoid-Gym: Reinforcement Learning for Humanoid Robot with Zero-Shot Sim2Real Transfer
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p><span class='px-1 mx-1 bg-yellow-200'>Humanoid-Gym is an easy-to-use reinforcement learning (RL) framework based on Nvidia Isaac Gym, designed to train locomotion skills for humanoid robots, emphasizing zero-shot transfer from simulation to the real-world environment. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.825</span></span>Humanoid-Gym also integrates a sim-to-sim framework from Isaac Gym to Mujoco that allows users to verify the trained policies in different physical simulations to ensure the robustness and generalization of the policies.This framework is verified by RobotEra's XBot-S (1.2-meter tall humanoid robot) and XBot-L (1.65-meter tall humanoid robot) in a real-world environment with zero-shot sim-to-real transfer.The project website and source code can be found at: https://sites.google.com/view/humanoid-gym/.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2404.05695v1' target="_blank">
                  link
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td></td>
          <td>
            <h2 class="text-2xl tracking-tight pt-4 font-bold">Trajectory Optimization</h2>
          </td>
        </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-04-08</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Improving Algorithm-Selection and Performance-Prediction via Learning Discriminating Training Samples
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>The choice of input-data used to train algorithm-selection models is recognised as being a critical part of the model success.<span class='px-1 mx-1 bg-yellow-200'>Recently, feature-free methods for algorithm-selection that use short trajectories obtained from running a solver as input have shown promise. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.82</span></span>However, it is unclear to what extent these trajectories reliably discriminate between solvers.We propose a meta approach to generating discriminatory trajectories with respect to a portfolio of solvers.The algorithm-configuration tool irace is used to tune the parameters of a simple Simulated Annealing algorithm (SA) to produce trajectories that maximise the performance metrics of ML models trained on this data.We show that when the trajectories obtained from the tuned SA algorithm are used in ML models for algorithm-selection and performance prediction, we obtain significantly improved performance metrics compared to models trained both on raw trajectory data and on exploratory landscape features.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2404.05359v1' target="_blank">
                  link
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-04-08</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Design and Simulation of Time-energy Optimal Anti-swing Trajectory Planner for Autonomous Tower Cranes
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>For autonomous crane lifting, optimal trajectories of the crane are required as reference inputs to the crane controller to facilitate feedforward control.Reducing the unactuated payload motion is a crucial issue for under-actuated tower cranes with spherical pendulum dynamics.<span class='px-1 mx-1 bg-yellow-200'>The planned trajectory should be optimal in terms of both operating time and energy consumption, to facilitate optimum output spending optimum effort. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.869</span></span>This article proposes an anti-swing tower crane trajectory planner that can provide time-energy optimal solutions for the Computer-Aided Lift Planning (CALP) system developed at Nanyang Technological University, which facilitates collision-free lifting path planning of robotized tower cranes in autonomous construction sites.<span class='px-1 mx-1 bg-yellow-200'>The current work introduces a trajectory planning module to the system that utilizes the geometric outputs from the path planning module and optimally scales them with time information. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.849</span></span>Firstly, analyzing the non-linear dynamics of the crane operations, the tower crane is established as differentially flat.<span class='px-1 mx-1 bg-yellow-200'>Subsequently, the multi-objective trajectory optimization problems for all the crane operations are formulated in the flat output space through consideration of the mechanical and safety constraints. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.841</span></span>Two multi-objective evolutionary algorithms, namely Non-dominated Sorting Genetic Algorithm (NSGA-II) and Generalized Differential Evolution 3 (GDE3), are extensively compared via statistical measures based on the closeness of solutions to the Pareto front, distribution of solutions in the solution space and the runtime, to select the optimization engine of the planner.Finally, the crane operation trajectories are obtained via the corresponding planned flat output trajectories.Studies simulating real-world lifting scenarios are conducted to verify the effectiveness and reliability of the proposed module of the lift planning system.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2404.05581v1' target="_blank">
                  link
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr><tr>
          <td class="inline-block">
            <p class='font-bold text-black px-2 mx-1 text-xs w-24'>2024-04-08</p>
          </td>
          <td>
            <div x-data="{open: false}">
              <span @click="open = ! open" class="hover:underline cursor-pointer decoration-2 decoration-green-600 text-gray-800 text-sm">
                Semi-Infinite Programs for Robust Control and Optimization: Efficient Solutions and Extensions to Existence Constraints
              </span>
              <div x-show="open" x-collapse.duration.500ms class="text-sm text-gray-500 pt-2">
                <div class="text-center pt-2"></div>
                <p class="pt-2">
                  <p>Discrete-time robust optimal control problems generally take a min-max structure over continuous variable spaces, which can be difficult to solve in practice.In this paper, we extend the class of such problems that can be solved through a previously proposed local reduction method to consider those with existence constraints on the uncountable variables.<span class='px-1 mx-1 bg-yellow-200'>We also consider the possibility of non-unique trajectories that satisfy equality and inequality constraints. <span style='font-size: 0.65rem;' class='text-purple-500 font-bold'>0.833</span></span>Crucially, we show that the problems of interest can be cast into a standard semi-infinite program and demonstrate how to generate optimal uncertainty scenario sets in order to obtain numerical solutions.We also include examples on model predictive control for obstacle avoidance with logical conditions, control with input saturation affected by uncertainty, and optimal parameter estimation to highlight the need for the proposed extension.Our method solves each of the examples considered, producing violation-free and locally optimal solutions.</p>
                </p>
              <p class="pb-2 pt-2 text-center">
                <a class="underline decoration-2 text-green-600 text-md pt-2" href='http://arxiv.org/abs/2404.05635v1' target="_blank">
                  link
                </a>
              </p>
            </div>
          </div>
        </td>
      </tr></tbody>
  </table>
  <br><br>
</div>
</div>
<script>
  document.addEventListener("DOMContentLoaded", function() {
    renderMathInElement(document.body, {
      // customised options
      // • auto-render specific keys, e.g.:
      delimiters: [
      {left: '$$', right: '$$', display: true},
      {left: '$', right: '$', display: false},
      {left: '\\(', right: '\\)', display: false},
      {left: '\\[', right: '\\]', display: true}
      ],
      // • rendering keys, e.g.:
      throwOnError : false
    });
  });
</script>
</body>
</html>